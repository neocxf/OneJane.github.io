<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><title>吴恩达机器学习笔记(6-10周) - OneJane</title><meta charset="UTF-8"><meta name="description" content="微服务,高可用,高并发,人工智能"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="msvalidate.01" content="396E9693347B4D18AAE96D9E75B9B686"><link rel="shortcut icon" href="/images/a.ico" type="image/png"><meta name="description" content="吴恩达机器学习笔记"><meta name="keywords" content="nlp"><meta property="og:type" content="article"><meta property="og:title" content="吴恩达机器学习笔记(6-10周)"><meta property="og:url" content="https://onejane.github.io/2019/12/04/new_吴恩达机器学习笔记(6-10周)/index.html"><meta property="og:site_name" content="OneJane"><meta property="og:description" content="吴恩达机器学习笔记"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f49730be98810b869951bbe38b6319ba.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9c769fd59c8a9c9f92200f538d1ab29c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/751e868bebf4c0bf139db173d25e8ec4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1b908480ad78ee54ba7129945015f87f.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7cf1cd9c123a72ca4137ca515871689d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20c6b0ba8375ca496b7557def6c00324.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bca6906add60245bbc24d71e22f8b836.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/64ad47693447761bd005243ae7db0cca.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/25597f0f88208a7e74a3ca028e971852.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2ba317c326547f5b5313489a3f0d66ce.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8f557105250853e1602a78c99b2ef95b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/38eed7de718f44f6bb23727c5a88bf5d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/969281bc9b07e92a0052b17288fb2c52.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/973216c7b01c910cfa1454da936391c6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4a5099b9f4b6aac5785cb0ad05289335.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2977243994d8d28d5ff300680988ec34.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c5cd6fa2eb9aea9c581b2d78f2f4ea57.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ad00c2043ab31f32deb2a1eb456b7246.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/84067e23f2ab0423679379afc6ed6caf.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1a7c575dc1b606b8e6e4de71a14dc005.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/befe860fd4b1aef2f6eebf617baf5877.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/05a3c884505e08028d37a04472d0964a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3d12b07f13a976e916d0c707fd03153c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/66facb7fa8eddc3a860e420588c981d5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b4b43ee98bff9f5e73d841af1fa316bf.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ab372c9161375a4f7b6f0bd4a69560e9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/59541ab1fda4f92d6f1b508c8e29ab1c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4ac1ca54cb0f2c465ab81339baaf9186.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5a63e35db410fdb57c76de97ea888278.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/cc66af7cbd88183efc07c8ddf09cbc73.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/12ebd5973230e8fdf279ae09e187f437.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b1f670fddd9529727aa16a559d49d151.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/01105c3afd1315acf0577f8493137dcc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e68e6ca3275f433330a7981971eb4f16.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dd6239efad3d3ee7a89a28574d7795b3.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f4b6dee99cfb4352b3cac5287002e8de.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b8fbe2f6ac48897cf40497a2d034c691.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/55e05845c636c8c99c03e6e29337d8c4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/44ad37bce4b7e03835095dccbd2a7b7a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/03bd4b3ff69e327f7949c3d2a73eed8a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3cc61c6e5fe85c2a7bf8170f5bbfd8c3.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4510b8fbc90ba2b233bb6996529f2df1.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/912cb43058cee46ddf51598b7538968c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20725ba601c1c90d1024e50fc24c579b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5eab58ad9cb54b3b6fda8f6c96efff24.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/65198a1748fdbe16da34afab9f33d801.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/529b6dbc07c9f39f5266bd0b3f628545.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2516821097bda5dfaf0b94e55de851e0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b9acfc507a54f5ca13a3d50379972535.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3d8959d0d12fe9914dc827d5a074b564.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/eca2571849cc36748c26c68708a7a5bd.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ea31af620b0a0132fe494ebb4a362465.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6709f5ca3cd2240d4e95dcc3d3e808d5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6709f5ca3cd2240d4e95dcc3d3e808d5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ff180f091e9bad9ac185248721437526.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ff1db77ec2e83b592bbe1c4153586120.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/acdb3ac44f1fe61ff3b5a77d5a4895a1.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fe6dd7acf1a1eddcd09da362ecdf976f.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fed50a4e482cf3aae38afeb368141a97.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8605f0826623078a156d30a7782dfc3c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d4d2c3edbdd8915f4e9d254d2a47d9c7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f3ddc6d751cab7aba7a6f8f44794e975.png"><meta property="og:image" content="https://onejane.github.io/Ari11.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2373072a74d97a9f606981ffaf1dd53b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2c95b316a3c61cf076ef132d3d50b51c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8274f0c29314742e9b4f15071ea7624a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8274f0c29314742e9b4f15071ea7624a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/789d90327121d3391735087b9276db2a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/789d90327121d3391735087b9276db2a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a93213474b35ce393320428996aeecd9.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7e1389918ab9358d1432d20ed20f8142.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0918b38594709705723ed34bb74928ba.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/01e1c4a2f29a626b5980a27fc7d6a693.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a4477d787f876ae4e72cb416a2cb0b8a.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0a4edcb9c0d0a3812a50b3e95ef3912a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/66544d8fa1c1639d80948006f7f4a8ff.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/93d6dfe7e5cb8a46923c178171889747.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fe4472adbf6ddd9d9b51d698cc750b68.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/65afdea865d50cba12d4f7674d599de5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fcb35433507a56631dde2b4e543743ee.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ba47767a11ba39a23898b9f1a5a57cc5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/82b90f56570c05966da116c3afe6fc91.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0990d6b7a5ab3c0036f42083fe2718c6.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f406bc738e5e032be79e52b6facfa48e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/598db991a7c930c9021cec5f6ab9beb9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/29df906704d254f18e92a63173dd51e7.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3dbee365617e9264831400e4de247adc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d1a228f2bec262f2206379ed844c7f4a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/015cee3a224dde6da0181215cf91a23d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7104dd2548f1251e4c423e059d1d2594.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f4585239738f2b5149608879fa166889.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c2822f2c28b343d7e6ade5bd40f3a1fc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/747c1fd6bff694c6034da1911aa3314b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/42a92e07b32b593bb826f8f6bc4d9eb3.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c905a6f02e201a4767d869b3791e8aeb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0a8b49da1ab852f2996a02afcaca2322.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54b1f7c3131aed24f9834d62a6835642.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9ec5cb55e14bd1462183e104f8e02b80.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bdf069136b4b661dd14158496d1d1419.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9710a69ba509a9dcbca351fccc6e7aae.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/76fb1df50bdf951f4b880fa66489e367.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f703f371dbb80d22fd5e4aec48aa9fd4.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/919eabe903ef585ec7d08f2895551a1f.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/095e4712376c26ff7ffa260125760140.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/610fffb413d8d577882d6345c166a9fb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1e00d03719e20eeaf1f414f99d7f4109.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bc48a4b0c7257591643eb50f2bf46db6.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0a930f2083bbeb85837f018b74fd0a02.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0bde4f379c8a46c2074336ecce1a955f.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/55d41ee748680a62e755d6aa5b95b53c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f1ecee10884098f98032648da08f8937.jpg"><meta property="og:updated_time" content="2019-12-05T03:53:27.699Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="吴恩达机器学习笔记(6-10周)"><meta name="twitter:description" content="吴恩达机器学习笔记"><meta name="twitter:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f49730be98810b869951bbe38b6319ba.png"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdui@0.4.3/dist/css/mdui.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.15.8/styles/atom-one-dark.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1038733_0xvrvpg9c0r.css"><link rel="stylesheet" href="/css/style.css?v=1578153607606"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js"></script></head><body class="mdui-drawer-body-left"><div id="nexmoe-background"><div class="nexmoe-bg" style="background-image:url(https://www.github.com/OneJane/blog/raw/master/小书匠/1566388885395.png)"></div><div class="mdui-appbar mdui-shadow-0"><div class="mdui-toolbar"> <a mdui-drawer="{target: '#drawer', swipe: true}" title="menu" class="mdui-btn mdui-btn-icon"><i class="mdui-icon material-icons">menu</i></a><div class="mdui-toolbar-spacer"></div> <a href="/" title="OneJane" class="mdui-btn mdui-btn-icon"><img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388846021.png"></a></div></div></div><div id="nexmoe-header"><div class="nexmoe-drawer mdui-drawer" id="drawer"><div class="nexmoe-avatar mdui-ripple"> <a href="/" title="OneJane"><img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388846021.png" alt="OneJane"></a></div><div class="nexmoe-count"><div><span>文章</span>69</div><div><span>标签</span>83</div><div><span>分类</span>12</div></div><ul class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}"><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/" title="回到首页"><i class="mdui-list-item-icon nexmoefont icon-home"></i><div class="mdui-list-item-content"> 回到首页</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/about.html" title="关于博客"><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i><div class="mdui-list-item-content"> 关于博客</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/py.html" title="我的朋友"><i class="mdui-list-item-icon nexmoefont icon-unorderedlist"></i><div class="mdui-list-item-content"> 我的朋友</div></a></ul><aside id="nexmoe-sidebar"><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">社交按钮</h3><div class="nexmoe-widget nexmoe-social"><a class="mdui-ripple" href="https://github.com/OneJane" target="_blank" mdui-tooltip="{content: 'GitHub'}" style="color:#191717;background-color:rgba(25,23,23,.15)"><i class="nexmoefont icon-github"></i></a></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">文章分类</h3><div class="nexmoe-widget"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/人工智能/">人工智能</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/定时器/">定时器</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/持续集成/">持续集成</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/注册中心/">注册中心</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/测试/">测试</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/系统/">系统</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/自然语言处理/">自然语言处理</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目实战/">项目实战</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/高可用/">高可用</a><span class="category-list-count">4</span></li></ul></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">标签云</h3><div class="nexmoe-widget tagcloud"> <a href="/tags/Gensim/" style="font-size:10px">Gensim</a> <a href="/tags/Hanlp/" style="font-size:10px">Hanlp</a> <a href="/tags/NLTK/" style="font-size:10px">NLTK</a> <a href="/tags/OpenCV/" style="font-size:12.86px">OpenCV</a> <a href="/tags/Stanford-NLP/" style="font-size:10px">Stanford NLP</a> <a href="/tags/Tensorflow/" style="font-size:15.71px">Tensorflow</a> <a href="/tags/ant-design/" style="font-size:10px">ant design</a> <a href="/tags/ant-design-pro/" style="font-size:11.43px">ant design pro</a> <a href="/tags/auc/" style="font-size:10px">auc</a> <a href="/tags/bottle/" style="font-size:10px">bottle</a> <a href="/tags/chatterbot/" style="font-size:10px">chatterbot</a> <a href="/tags/cnn/" style="font-size:12.86px">cnn</a> <a href="/tags/crf/" style="font-size:12.86px">crf</a> <a href="/tags/doc2vec/" style="font-size:10px">doc2vec</a> <a href="/tags/docker/" style="font-size:17.14px">docker</a> <a href="/tags/dubbo/" style="font-size:11.43px">dubbo</a> <a href="/tags/elasticsearch/" style="font-size:10px">elasticsearch</a> <a href="/tags/elastisearch/" style="font-size:10px">elastisearch</a> <a href="/tags/email/" style="font-size:10px">email</a> <a href="/tags/es6/" style="font-size:10px">es6</a> <a href="/tags/feign/" style="font-size:10px">feign</a> <a href="/tags/flask/" style="font-size:11.43px">flask</a> <a href="/tags/folium/" style="font-size:10px">folium</a> <a href="/tags/freemarker/" style="font-size:10px">freemarker</a> <a href="/tags/function/" style="font-size:10px">function</a> <a href="/tags/gateway/" style="font-size:10px">gateway</a> <a href="/tags/gensim/" style="font-size:11.43px">gensim</a> <a href="/tags/gitlab/" style="font-size:11.43px">gitlab</a> <a href="/tags/gru/" style="font-size:11.43px">gru</a> <a href="/tags/hanlp/" style="font-size:11.43px">hanlp</a> <a href="/tags/haproxy/" style="font-size:10px">haproxy</a> <a href="/tags/hmm/" style="font-size:10px">hmm</a> <a href="/tags/jenkins/" style="font-size:11.43px">jenkins</a> <a href="/tags/jieba/" style="font-size:15.71px">jieba</a> <a href="/tags/jmeter/" style="font-size:10px">jmeter</a> <a href="/tags/keepalived/" style="font-size:10px">keepalived</a> <a href="/tags/lda/" style="font-size:11.43px">lda</a> <a href="/tags/linux/" style="font-size:10px">linux</a> <a href="/tags/lstm/" style="font-size:12.86px">lstm</a> <a href="/tags/maven/" style="font-size:11.43px">maven</a> <a href="/tags/multi-druid/" style="font-size:10px">multi druid</a> <a href="/tags/mybatis/" style="font-size:10px">mybatis</a> <a href="/tags/mybatisplus/" style="font-size:10px">mybatisplus</a> <a href="/tags/mysql/" style="font-size:10px">mysql</a> <a href="/tags/n-gram/" style="font-size:10px">n-gram</a> <a href="/tags/nacos/" style="font-size:11.43px">nacos</a> <a href="/tags/neo4j/" style="font-size:11.43px">neo4j</a> <a href="/tags/nexmoe/" style="font-size:10px">nexmoe</a> <a href="/tags/nlp/" style="font-size:20px">nlp</a> <a href="/tags/numpy/" style="font-size:10px">numpy</a> <a href="/tags/partition/" style="font-size:10px">partition</a> <a href="/tags/procedure/" style="font-size:10px">procedure</a> <a href="/tags/pxc/" style="font-size:10px">pxc</a> <a href="/tags/pyhanlp/" style="font-size:11.43px">pyhanlp</a> <a href="/tags/python/" style="font-size:10px">python</a> <a href="/tags/rabbitmq/" style="font-size:10px">rabbitmq</a> <a href="/tags/react/" style="font-size:11.43px">react</a> <a href="/tags/redis/" style="font-size:11.43px">redis</a> <a href="/tags/redis-cluster/" style="font-size:10px">redis-cluster</a> <a href="/tags/replication/" style="font-size:11.43px">replication</a> <a href="/tags/rnn/" style="font-size:10px">rnn</a> <a href="/tags/rocketmq/" style="font-size:11.43px">rocketmq</a> <a href="/tags/scrapy/" style="font-size:12.86px">scrapy</a> <a href="/tags/selenium/" style="font-size:12.86px">selenium</a> <a href="/tags/sentinel/" style="font-size:14.29px">sentinel</a> <a href="/tags/seq2seq/" style="font-size:10px">seq2seq</a> <a href="/tags/session/" style="font-size:10px">session</a> <a href="/tags/sklearn/" style="font-size:10px">sklearn</a> <a href="/tags/skywalking/" style="font-size:11.43px">skywalking</a> <a href="/tags/snownlp/" style="font-size:10px">snownlp</a> <a href="/tags/spring-cloud-alibaba/" style="font-size:18.57px">spring cloud alibaba</a> <a href="/tags/springboot/" style="font-size:14.29px">springboot</a> <a href="/tags/svm/" style="font-size:10px">svm</a> <a href="/tags/swagger/" style="font-size:10px">swagger</a> <a href="/tags/textrank/" style="font-size:10px">textrank</a> <a href="/tags/tf-idf/" style="font-size:12.86px">tf-idf</a> <a href="/tags/tk-mybatis/" style="font-size:10px">tk mybatis</a> <a href="/tags/umi/" style="font-size:10px">umi</a> <a href="/tags/validate/" style="font-size:10px">validate</a> <a href="/tags/word2vec/" style="font-size:10px">word2vec</a> <a href="/tags/wordcloud/" style="font-size:10px">wordcloud</a> <a href="/tags/xxl-job/" style="font-size:11.43px">xxl-job</a> <a href="/tags/zookeeper/" style="font-size:10px">zookeeper</a></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">文章归档</h3><div class="nexmoe-widget"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li></ul></div></div></aside><div class="nexmoe-copyright"> &copy; 2020 OneJane</div></div></div><div id="nexmoe-content"><div class="nexmoe-primary"><div class="nexmoe-post"><div class="nexmoe-post-cover"> <img src="https://www.github.com/OneJane/blog/raw/master/小书匠/4f4d553f0840517762a9237a83cb946e_hd.jpg"><h1>吴恩达机器学习笔记(6-10周)</h1></div><div class="nexmoe-post-meta"><a><i class="nexmoefont icon-calendar-fill"></i> 2019年12月04日</a><a><i class="nexmoefont icon-areachart"></i> 42.6k 字</a><a><i class="nexmoefont icon-time-circle-fill"></i> 大概 179 分钟</a> <a class="nexmoefont icon-appstore-fill -link" href="/categories/人工智能/">人工智能</a> <a class="nexmoefont icon-tag-fill -link" href="/tags/nlp/">nlp</a></div><article><p><a href="https://onejane.github.io/">吴恩达机器学习笔记</a></p><a id="more"></a><h2 id="应用机器学习的建议-Advice-for-Applying-Machine-Learning"><a href="#应用机器学习的建议-Advice-for-Applying-Machine-Learning" class="headerlink" title="应用机器学习的建议(Advice for Applying Machine Learning)"></a>应用机器学习的建议(Advice for Applying Machine Learning)</h2><h3 id="决定下一步做什么"><a href="#决定下一步做什么" class="headerlink" title="决定下一步做什么"></a>决定下一步做什么</h3><p>参考视频: 10 - 1 - Deciding What to Try Next (6 min).mkv</p><p>到目前为止，我们已经介绍了许多不同的学习算法，如果你一直跟着这些视频的进度学习，你会发现自己已经不知不觉地成为一个了解许多先进机器学习技术的专家了。</p><p>然而，在懂机器学习的人当中依然存在着很大的差距，一部分人确实掌握了怎样高效有力地运用这些学习算法。而另一些人他们可能对我马上要讲的东西，就不是那么熟悉了。他们可能没有完全理解怎样运用这些算法。因此总是把时间浪费在毫无意义的尝试上。我想做的是确保你在设计机器学习的系统时，你能够明白怎样选择一条最合适、最正确的道路。因此，在这节视频和之后的几段视频中，我将向你介绍一些实用的建议和指导，帮助你明白怎样进行选择。具体来讲，我将重点关注的问题是假如你在开发一个机器学习系统，或者想试着改进一个机器学习系统的性能，你应如何决定接下来应该选择哪条道路？为了解释这一问题，我想仍然使用预测房价的学习例子，假如你已经完成了正则化线性回归，也就是最小化代价函数$J$的值，假如，在你得到你的学习参数以后，如果你要将你的假设函数放到一组新的房屋样本上进行测试，假如说你发现在预测房价时产生了巨大的误差，现在你的问题是要想改进这个算法，接下来应该怎么办？</p><p>实际上你可以想出很多种方法来改进这个算法的性能，其中一种办法是使用更多的训练样本。具体来讲，也许你能想到通过电话调查或上门调查来获取更多的不同的房屋出售数据。遗憾的是，我看到好多人花费了好多时间想收集更多的训练样本。他们总认为，要是我有两倍甚至十倍数量的训练数据，那就一定会解决问题的是吧？但有时候获得更多的训练数据实际上并没有作用。在接下来的几段视频中，我们将解释原因。</p><p>我们也将知道怎样避免把过多的时间浪费在收集更多的训练数据上，这实际上是于事无补的。另一个方法，你也许能想到的是尝试选用更少的特征集。因此如果你有一系列特征比如$x_1,x_2,x_3$等等。也许有很多特征，也许你可以花一点时间从这些特征中仔细挑选一小部分来防止过拟合。或者也许你需要用更多的特征，也许目前的特征集，对你来讲并不是很有帮助。你希望从获取更多特征的角度来收集更多的数据，同样地，你可以把这个问题扩展为一个很大的项目，比如使用电话调查来得到更多的房屋案例，或者再进行土地测量来获得更多有关，这块土地的信息等等，因此这是一个复杂的问题。同样的道理，我们非常希望在花费大量时间完成这些工作之前，我们就能知道其效果如何。我们也可以尝试增加多项式特征的方法，比如$x_1$的平方，$x_2$的平方，$x_1,x_2$的乘积，我们可以花很多时间来考虑这一方法，我们也可以考虑其他方法减小或增大正则化参数$\lambda$的值。我们列出的这个单子，上面的很多方法都可以扩展开来扩展成一个六个月或更长时间的项目。遗憾的是，大多数人用来选择这些方法的标准是凭感觉的，也就是说，大多数人的选择方法是随便从这些方法中选择一种，比如他们会说“噢，我们来多找点数据吧”，然后花上六个月的时间收集了一大堆数据，然后也许另一个人说：“好吧，让我们来从这些房子的数据中多找点特征吧”。我很遗憾不止一次地看到很多人花了至少六个月时间来完成他们随便选择的一种方法，而在六个月或者更长时间后，他们很遗憾地发现自己选择的是一条不归路。幸运的是，有一系列简单的方法能让你事半功倍，排除掉单子上的至少一半的方法，留下那些确实有前途的方法，同时也有一种很简单的方法，只要你使用，就能很轻松地排除掉很多选择，从而为你节省大量不必要花费的时间。最终达到改进机器学习系统性能的目的假设我们需要用一个线性回归模型来预测房价，当我们运用训练好了的模型来预测未知数据的时候发现有较大的误差，我们下一步可以做什么？</p><ol><li><p>获得更多的训练样本——通常是有效的，但代价较大，下面的方法也可能有效，可考虑先采用下面的几种方法。</p></li><li><p>尝试减少特征的数量</p></li><li><p>尝试获得更多的特征</p></li><li><p>尝试增加多项式特征</p></li><li><p>尝试减少正则化程度$\lambda$</p></li><li><p>尝试增加正则化程度$\lambda$</p></li></ol><p>我们不应该随机选择上面的某种方法来改进我们的算法，而是运用一些机器学习诊断法来帮助我们知道上面哪些方法对我们的算法是有效的。</p><p>在接下来的两段视频中，我首先介绍怎样评估机器学习算法的性能，然后在之后的几段视频中，我将开始讨论这些方法，它们也被称为”机器学习诊断法”。“诊断法”的意思是：这是一种测试法，你通过执行这种测试，能够深入了解某种算法到底是否有用。这通常也能够告诉你，要想改进一种算法的效果，什么样的尝试，才是有意义的。在这一系列的视频中我们将介绍具体的诊断法，但我要提前说明一点的是，这些诊断法的执行和实现，是需要花些时间的，有时候确实需要花很多时间来理解和实现，但这样做的确是把时间用在了刀刃上，因为这些方法让你在开发学习算法时，节省了几个月的时间，因此，在接下来几节课中，我将先来介绍如何评价你的学习算法。在此之后，我将介绍一些诊断法，希望能让你更清楚。在接下来的尝试中，如何选择更有意义的方法。</p><h3 id="评估一个假设"><a href="#评估一个假设" class="headerlink" title="评估一个假设"></a>评估一个假设</h3><p>参考视频: 10 - 2 - Evaluating a Hypothesis (8 min).mkv</p><p>在本节视频中我想介绍一下怎样用你学过的算法来评估假设函数。在之后的课程中，我们将以此为基础来讨论如何避免过拟合和欠拟合的问题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f49730be98810b869951bbe38b6319ba.png" alt="f49730be98810b869951bbe38b6319ba"></p><p>当我们确定学习算法的参数的时候，我们考虑的是选择参量来使训练误差最小化，有人认为得到一个非常小的训练误差一定是一件好事，但我们已经知道，仅仅是因为这个假设具有很小的训练误差，并不能说明它就一定是一个好的假设函数。而且我们也学习了过拟合假设函数的例子，所以这推广到新的训练集上是不适用的。</p><p>那么，你该如何判断一个假设函数是过拟合的呢？对于这个简单的例子，我们可以对假设函数$h(x)$进行画图，然后观察图形趋势，但对于特征变量不止一个的这种一般情况，还有像有很多特征变量的问题，想要通过画出假设函数来进行观察，就会变得很难甚至是不可能实现。</p><p>因此，我们需要另一种方法来评估我们的假设函数过拟合检验。</p><p>为了检验算法是否过拟合，我们将数据分成训练集和测试集，通常用70%的数据作为训练集，用剩下30%的数据作为测试集。很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行“洗牌”，然后再分成训练集和测试集。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9c769fd59c8a9c9f92200f538d1ab29c.png" alt="9c769fd59c8a9c9f92200f538d1ab29c"></p><p>测试集评估在通过训练集让我们的模型学习得出其参数后，对测试集运用该模型，我们有两种方式计算误差：</p><ol><li><p>对于线性回归模型，我们利用测试集数据计算代价函数$J$</p></li><li><p>对于逻辑回归模型，我们除了可以利用测试数据集来计算代价函数外：</p></li></ol> $$ J_{test}{(\theta)} = -\frac{1}{ {m}_{test} }\sum_\limits{i=1}^{m_{test} }\log{h_{\theta}(x^{(i)}_{test})}+(1-{y^{(i)}_{test} })\log{h_{\theta}(x^{(i)}_{test})}$$<p>误分类的比率，对于每一个测试集样本，计算：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/751e868bebf4c0bf139db173d25e8ec4.png" alt="751e868bebf4c0bf139db173d25e8ec4"></p><p>然后对计算结果求平均。</p><h3 id="模型选择和交叉验证集"><a href="#模型选择和交叉验证集" class="headerlink" title="模型选择和交叉验证集"></a>模型选择和交叉验证集</h3><p>参考视频: 10 - 3 - Model Selection and Train_Validation_Test Sets (12 min).mkv</p><p>假设我们要在10个不同次数的二项式模型之间进行选择：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1b908480ad78ee54ba7129945015f87f.jpg" alt="1b908480ad78ee54ba7129945015f87f"></p><p>显然越高次数的多项式模型越能够适应我们的训练数据集，但是适应训练数据集并不代表着能推广至一般情况，我们应该选择一个更能适应一般情况的模型。我们需要使用交叉验证集来帮助选择模型。</p><p>即：使用60%的数据作为训练集，使用 20%的数据作为交叉验证集，使用20%的数据作为测试集</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7cf1cd9c123a72ca4137ca515871689d.png" alt="7cf1cd9c123a72ca4137ca515871689d"><br>模型选择的方法为：</p><ol><li><p>使用训练集训练出10个模型</p></li><li><p>用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）</p></li><li><p>选取代价函数值最小的模型</p></li><li><p>用步骤3中选出的模型对测试集计算得出推广误差（代价函数的值）</p></li></ol><p><strong><em>Train/validation/test error</em></strong></p><p><strong>Training error:</strong></p> $J_{train}(\theta) = \frac{1}{2m}\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2$<p><strong>Cross Validation error:</strong></p> $J_{cv}(\theta) = \frac{1}{2m_{cv} }\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)}_{cv})-y^{(i)}_{cv})^2​$<p><strong>Test error:</strong></p> $J_{test}(\theta)=\frac{1}{2m_{test} }\sum_\limits{i=1}^{m_{test} }(h_{\theta}(x^{(i)}_{cv})-y^{(i)}_{cv})^2$<h3 id="诊断偏差和方差"><a href="#诊断偏差和方差" class="headerlink" title="诊断偏差和方差"></a>诊断偏差和方差</h3><p>参考视频: 10 - 4 - Diagnosing Bias vs. Variance (8 min).mkv</p><p>当你运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。那么这两种情况，哪个和偏差有关，哪个和方差有关，或者是不是和两个都有关？搞清楚这一点非常重要，因为能判断出现的情况是这两种情况中的哪一种。其实是一个很有效的指示器，指引着可以改进算法的最有效的方法和途径。在这段视频中，我想更深入地探讨一下有关偏差和方差的问题，希望你能对它们有一个更深入的理解，并且也能弄清楚怎样评价一个学习算法，能够判断一个算法是偏差还是方差有问题，因为这个问题对于弄清如何改进学习算法的效果非常重要，高偏差和高方差的问题基本上来说是欠拟合和过拟合的问题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20c6b0ba8375ca496b7557def6c00324.jpg" alt="20c6b0ba8375ca496b7557def6c00324"></p><p>我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bca6906add60245bbc24d71e22f8b836.png" alt="bca6906add60245bbc24d71e22f8b836"></p><p><strong>Bias/variance</strong></p><p><strong>Training error:</strong> $J_{train}(\theta) = \frac{1}{2m}\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2$</p><p><strong>Cross Validation error:</strong> $J_{cv}(\theta) = \frac{1}{2m_{cv} }\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)}_{cv})-y^{(i)}_{cv})^2$</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/64ad47693447761bd005243ae7db0cca.png" alt="64ad47693447761bd005243ae7db0cca"></p><p>对于训练集，当 $d$ 较小时，模型拟合程度更低，误差较大；随着 $d$ 的增长，拟合程度提高，误差减小。</p><p>对于交叉验证集，当 $d$ 较小时，模型拟合程度低，误差较大；但是随着 $d$ 的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。</p><p>如果我们的交叉验证集误差较大，我们如何判断是方差还是偏差呢？根据上面的图表，我们知道:</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/25597f0f88208a7e74a3ca028e971852.png" alt="25597f0f88208a7e74a3ca028e971852"></p><p>训练集误差和交叉验证集误差近似时：偏差/欠拟合</p><p>交叉验证集误差远大于训练集误差时：方差/过拟合</p><h3 id="正则化和偏差-方差"><a href="#正则化和偏差-方差" class="headerlink" title="正则化和偏差/方差"></a>正则化和偏差/方差</h3><p>参考视频: 10 - 5 - Regularization and Bias_Variance (11 min).mkv</p><p>在我们在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。但是我们可能会正则化的程度太高或太小了，即我们在选择λ的值时也需要思考与刚才选择多项式模型次数类似的问题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2ba317c326547f5b5313489a3f0d66ce.png" alt="2ba317c326547f5b5313489a3f0d66ce"></p><p>我们选择一系列的想要测试的 λ 值，通常是 0-10之间的呈现2倍关系的值（如：$0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10$共12个）。 我们同样把数据分为训练集、交叉验证集和测试集。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8f557105250853e1602a78c99b2ef95b.png" alt="8f557105250853e1602a78c99b2ef95b"></p><p>选择$\lambda$的方法为：</p><ol><li>使用训练集训练出12个不同程度正则化的模型</li><li>用12个模型分别对交叉验证集计算的出交叉验证误差</li><li>选择得出交叉验证误差<strong>最小</strong>的模型</li><li>运用步骤3中选出模型对测试集计算得出推广误差，我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：</li></ol><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/38eed7de718f44f6bb23727c5a88bf5d.png" alt="38eed7de718f44f6bb23727c5a88bf5d"></p><p>• 当 λ 较小时，训练集误差较小（过拟合）而交叉验证集误差较大</p><p>• 随着 λ的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加</p><h3 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h3><p>参考视频: 10 - 6 - Learning Curves (12 min).mkv</p><p>学习曲线就是一种很好的工具，我经常使用学习曲线来判断某一个学习算法是否处于偏差、方差问题。学习曲线是学习算法的一个很好的<strong>合理检验</strong>（<strong>sanity check</strong>）。学习曲线是将训练集误差和交叉验证集误差作为训练集样本数量（$m$）的函数绘制的图表。</p><p>即，如果我们有100行数据，我们从1行数据开始，逐渐学习更多行的数据。思想是：当训练较少行数据的时候，训练的模型将能够非常完美地适应较少的训练数据，但是训练出来的模型却不能很好地适应交叉验证集数据或测试集数据。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/969281bc9b07e92a0052b17288fb2c52.png" alt="969281bc9b07e92a0052b17288fb2c52"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/973216c7b01c910cfa1454da936391c6.png" alt="973216c7b01c910cfa1454da936391c6"></p><p>如何利用学习曲线识别高偏差/欠拟合：作为例子，我们尝试用一条直线来适应下面的数据，可以看出，无论训练集有多么大误差都不会有太大改观：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4a5099b9f4b6aac5785cb0ad05289335.jpg" alt="4a5099b9f4b6aac5785cb0ad05289335"></p><p>也就是说在高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助。</p><p>如何利用学习曲线识别高方差/过拟合：假设我们使用一个非常高次的多项式模型，并且正则化非常小，可以看出，当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2977243994d8d28d5ff300680988ec34.jpg" alt="2977243994d8d28d5ff300680988ec34"></p><p>也就是说在高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果。</p><h3 id="决定下一步做什么-1"><a href="#决定下一步做什么-1" class="headerlink" title="决定下一步做什么"></a>决定下一步做什么</h3><p>参考视频: 10 - 7 - Deciding What to Do Next Revisited (7 min).mkv</p><p>我们已经介绍了怎样评价一个学习算法，我们讨论了模型选择问题，偏差和方差的问题。那么这些诊断法则怎样帮助我们判断，哪些方法可能有助于改进学习算法的效果，而哪些可能是徒劳的呢？</p><p>让我们再次回到最开始的例子，在那里寻找答案，这就是我们之前的例子。回顾 1.1 中提出的六种可选的下一步，让我们来看一看我们在什么情况下应该怎样选择：</p><ol><li><p>获得更多的训练样本——解决高方差</p></li><li><p>尝试减少特征的数量——解决高方差</p></li><li><p>尝试获得更多的特征——解决高偏差</p></li><li><p>尝试增加多项式特征——解决高偏差</p></li><li><p>尝试减少正则化程度λ——解决高偏差</p></li><li><p>尝试增加正则化程度λ——解决高方差</p></li></ol><p>神经网络的方差和偏差：<br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c5cd6fa2eb9aea9c581b2d78f2f4ea57.png" alt="c5cd6fa2eb9aea9c581b2d78f2f4ea57"></p><p>使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。</p><p>通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。</p><p>对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络，</p><p>然后选择交叉验证集代价最小的神经网络。</p><p>好的，以上就是我们介绍的偏差和方差问题，以及诊断该问题的学习曲线方法。在改进学习算法的表现时，你可以充分运用以上这些内容来判断哪些途径可能是有帮助的。而哪些方法可能是无意义的。如果你理解了以上几节视频中介绍的内容，并且懂得如何运用。那么你已经可以使用机器学习方法有效的解决实际问题了。你也能像硅谷的大部分机器学习从业者一样，他们每天的工作就是使用这些学习算法来解决众多实际问题。我希望这几节中提到的一些技巧，关于方差、偏差，以及学习曲线为代表的诊断法能够真正帮助你更有效率地应用机器学习，让它们高效地工作。</p><h2 id="机器学习系统的设计-Machine-Learning-System-Design"><a href="#机器学习系统的设计-Machine-Learning-System-Design" class="headerlink" title="机器学习系统的设计(Machine Learning System Design)"></a>机器学习系统的设计(Machine Learning System Design)</h2><h3 id="首先要做什么"><a href="#首先要做什么" class="headerlink" title="首先要做什么"></a>首先要做什么</h3><p>参考视频: 11 - 1 - Prioritizing What to Work On (10 min).mkv</p><p>在接下来的视频中，我将谈到机器学习系统的设计。这些视频将谈及在设计复杂的机器学习系统时，你将遇到的主要问题。同时我们会试着给出一些关于如何巧妙构建一个复杂的机器学习系统的建议。下面的课程的的数学性可能不是那么强，但是我认为我们将要讲到的这些东西是非常有用的，可能在构建大型的机器学习系统时，节省大量的时间。</p><p>本周以一个垃圾邮件分类器算法为例进行讨论。</p><p>为了解决这样一个问题，我们首先要做的决定是如何选择并表达特征向量$x$。我们可以选择一个由100个最常出现在垃圾邮件中的词所构成的列表，根据这些词是否有在邮件中出现，来获得我们的特征向量（出现为1，不出现为0），尺寸为100×1。</p><p>为了构建这个分类器算法，我们可以做很多事，例如：</p><ol><li><p>收集更多的数据，让我们有更多的垃圾邮件和非垃圾邮件的样本</p></li><li><p>基于邮件的路由信息开发一系列复杂的特征</p></li><li><p>基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理</p></li><li><p>为探测刻意的拼写错误（把<strong>watch</strong> 写成<strong>w4tch</strong>）开发复杂的算法</p></li></ol><p>在上面这些选项中，非常难决定应该在哪一项上花费时间和精力，作出明智的选择，比随着感觉走要更好。当我们使用机器学习时，总是可以“头脑风暴”一下，想出一堆方法来试试。实际上，当你需要通过头脑风暴来想出不同方法来尝试去提高精度的时候，你可能已经超越了很多人了。大部分人并不尝试着列出可能的方法，他们做的只是某天早上醒来，因为某些原因有了一个突发奇想：”让我们来试试用<strong>Honey Pot</strong>项目收集大量的数据吧。”</p><p>我们将在随后的课程中讲误差分析，我会告诉你怎样用一个更加系统性的方法，从一堆不同的方法中，选取合适的那一个。因此，你更有可能选择一个真正的好方法，能让你花上几天几周，甚至是几个月去进行深入的研究。</p><h3 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h3><p>参考视频: 11 - 2 - Error Analysis (13 min).mkv</p><p>在本次课程中，我们将会讲到误差分析（<strong>Error Analysis</strong>）的概念。这会帮助你更系统地做出决定。如果你准备研究机器学习的东西，或者构造机器学习应用程序，最好的实践方法不是建立一个非常复杂的系统，拥有多么复杂的变量；而是构建一个简单的算法，这样你可以很快地实现它。</p><p>每当我研究机器学习的问题时，我最多只会花一天的时间，就是字面意义上的24小时，来试图很快的把结果搞出来，即便效果不好。坦白的说，就是根本没有用复杂的系统，但是只是很快的得到的结果。即便运行得不完美，但是也把它运行一遍，最后通过交叉验证来检验数据。一旦做完，你可以画出学习曲线，通过画出学习曲线，以及检验误差，来找出你的算法是否有高偏差和高方差的问题，或者别的问题。在这样分析之后，再来决定用更多的数据训练，或者加入更多的特征变量是否有用。这么做的原因是：这在你刚接触机器学习问题时是一个很好的方法，你并不能提前知道你是否需要复杂的特征变量，或者你是否需要更多的数据，还是别的什么。提前知道你应该做什么，是非常难的，因为你缺少证据，缺少学习曲线。因此，你很难知道你应该把时间花在什么地方来提高算法的表现。但是当你实践一个非常简单即便不完美的方法时，你可以通过画出学习曲线来做出进一步的选择。你可以用这种方式来避免一种电脑编程里的过早优化问题，这种理念是：我们必须用证据来领导我们的决策，怎样分配自己的时间来优化算法，而不是仅仅凭直觉，凭直觉得出的东西一般总是错误的。除了画出学习曲线之外，一件非常有用的事是误差分析，我的意思是说：当我们在构造垃圾邮件分类器时，我会看一看我的交叉验证数据集，然后亲自看一看哪些邮件被算法错误地分类。因此，通过这些被算法错误分类的垃圾邮件与非垃圾邮件，你可以发现某些系统性的规律：什么类型的邮件总是被错误分类。经常地这样做之后，这个过程能启发你构造新的特征变量，或者告诉你：现在这个系统的短处，然后启发你如何去提高它。</p><p>构建一个学习算法的推荐方法为：</p><ol><li>从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法</li></ol><p>2.绘制学习曲线，决定是增加更多数据，或者添加更多特征，还是其他选择</p><p>3.进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的样本，看看这些样本是否有某种系统化的趋势</p><p>以我们的垃圾邮件过滤器为例，误差分析要做的既是检验交叉验证集中我们的算法产生错误预测的所有邮件，看：是否能将这些邮件按照类分组。例如医药品垃圾邮件，仿冒品垃圾邮件或者密码窃取邮件等。然后看分类器对哪一组邮件的预测误差最大，并着手优化。</p><p>思考怎样能改进分类器。例如，发现是否缺少某些特征，记下这些特征出现的次数。</p><p>例如记录下错误拼写出现了多少次，异常的邮件路由情况出现了多少次等等，然后从出现次数最多的情况开始着手优化。</p><p>误差分析并不总能帮助我们判断应该采取怎样的行动。有时我们需要尝试不同的模型，然后进行比较，在模型比较时，用数值来判断哪一个模型更好更有效，通常我们是看交叉验证集的误差。</p><p>在我们的垃圾邮件分类器例子中，对于“我们是否应该将<strong>discount/discounts/discounted/discounting</strong>处理成同一个词？”如果这样做可以改善我们算法，我们会采用一些截词软件。误差分析不能帮助我们做出这类判断，我们只能尝试采用和不采用截词软件这两种不同方案，然后根据数值检验的结果来判断哪一种更好。</p><p>因此，当你在构造学习算法的时候，你总是会去尝试很多新的想法，实现出很多版本的学习算法，如果每一次你实践新想法的时候，你都要手动地检测这些例子，去看看是表现差还是表现好，那么这很难让你做出决定。到底是否使用词干提取，是否区分大小写。但是通过一个量化的数值评估，你可以看看这个数字，误差是变大还是变小了。你可以通过它更快地实践你的新想法，它基本上非常直观地告诉你：你的想法是提高了算法表现，还是让它变得更坏，这会大大提高你实践算法时的速度。所以我强烈推荐在交叉验证集上来实施误差分析，而不是在测试集上。但是，还是有一些人会在测试集上来做误差分析。即使这从数学上讲是不合适的。所以我还是推荐你在交叉验证向量上来做误差分析。</p><p>总结一下，当你在研究一个新的机器学习问题时，我总是推荐你实现一个较为简单快速、即便不是那么完美的算法。我几乎从未见过人们这样做。大家经常干的事情是：花费大量的时间在构造算法上，构造他们以为的简单的方法。因此，不要担心你的算法太简单，或者太不完美，而是尽可能快地实现你的算法。当你有了初始的实现之后，它会变成一个非常有力的工具，来帮助你决定下一步的做法。因为我们可以先看看算法造成的错误，通过误差分析，来看看他犯了什么错，然后来决定优化的方式。另一件事是：假设你有了一个快速而不完美的算法实现，又有一个数值的评估数据，这会帮助你尝试新的想法，快速地发现你尝试的这些想法是否能够提高算法的表现，从而你会更快地做出决定，在算法中放弃什么，吸收什么误差分析可以帮助我们系统化地选择该做什么。</p><h3 id="类偏斜的误差度量"><a href="#类偏斜的误差度量" class="headerlink" title="类偏斜的误差度量"></a>类偏斜的误差度量</h3><p>参考视频: 11 - 3 - Error Metrics for Skewed Classes (12 min).mkv</p><p>在前面的课程中，我提到了误差分析，以及设定误差度量值的重要性。那就是，设定某个实数来评估你的学习算法，并衡量它的表现，有了算法的评估和误差度量值。有一件重要的事情要注意，就是使用一个合适的误差度量值，这有时会对于你的学习算法造成非常微妙的影响，这件重要的事情就是偏斜类（skewed classes）的问题。类偏斜情况表现为我们的训练集中有非常多的同一种类的样本，只有很少或没有其他类的样本。</p><p>例如我们希望用算法来预测癌症是否是恶性的，在我们的训练集中，只有0.5%的实例是恶性肿瘤。假设我们编写一个非学习而来的算法，在所有情况下都预测肿瘤是良性的，那么误差只有0.5%。然而我们通过训练而得到的神经网络算法却有1%的误差。这时，误差的大小是不能视为评判算法效果的依据的。</p><p><strong>查准率</strong>（<strong>Precision</strong>）和<strong>查全率</strong>（<strong>Recall</strong>） 我们将算法预测的结果分成四种情况：</p><ol><li><strong>正确肯定</strong>（<strong>True Positive,TP</strong>）：预测为真，实际为真</li></ol><p>2.<strong>正确否定</strong>（<strong>True Negative,TN</strong>）：预测为假，实际为假</p><p>3.<strong>错误肯定</strong>（<strong>False Positive,FP</strong>）：预测为真，实际为假</p><p>4.<strong>错误否定</strong>（<strong>False Negative,FN</strong>）：预测为假，实际为真</p><p>则：查准率=<strong>TP/(TP+FP)</strong>。例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。</p><p>查全率=<strong>TP/(TP+FN)</strong>。例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。</p><p>这样，对于我们刚才那个总是预测病人肿瘤为良性的算法，其查全率是0。</p><table><thead><tr><th></th><th></th><th><strong>预测值</strong></th><th></th></tr></thead><tbody><tr><td></td><td></td><td><strong>Positive</strong></td><td><strong>Negtive</strong></td></tr><tr><td><strong>实际值</strong></td><td><strong>Positive</strong></td><td><strong>TP</strong></td><td><strong>FN</strong></td></tr><tr><td></td><td><strong>Negtive</strong></td><td><strong>FP</strong></td><td><strong>TN</strong></td></tr></tbody></table><h3 id="查准率和查全率之间的权衡"><a href="#查准率和查全率之间的权衡" class="headerlink" title="查准率和查全率之间的权衡"></a>查准率和查全率之间的权衡</h3><p>参考视频: 11 - 4 - Trading Off Precision and Recall (14 min).mkv</p><p>在之前的课程中，我们谈到查准率和召回率，作为遇到偏斜类问题的评估度量值。在很多应用中，我们希望能够保证查准率和召回率的相对平衡。</p><p>在这节课中，我将告诉你应该怎么做，同时也向你展示一些查准率和召回率作为算法评估度量值的更有效的方式。继续沿用刚才预测肿瘤性质的例子。假使，我们的算法输出的结果在0-1 之间，我们使用阀值0.5 来预测真和假。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ad00c2043ab31f32deb2a1eb456b7246.png" alt="ad00c2043ab31f32deb2a1eb456b7246"></p><p>查准率<strong>(Precision)=TP/(TP+FP)</strong></p><p>例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。</p><p>查全率<strong>(Recall)=TP/(TP+FN)</strong>例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。</p><p>如果我们希望只在非常确信的情况下预测为真（肿瘤为恶性），即我们希望更高的查准率，我们可以使用比0.5更大的阀值，如0.7，0.9。这样做我们会减少错误预测病人为恶性肿瘤的情况，同时却会增加未能成功预测肿瘤为恶性的情况。</p><p>如果我们希望提高查全率，尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地检查、诊断，我们可以使用比0.5更小的阀值，如0.3。</p><p>我们可以将不同阀值情况下，查全率与查准率的关系绘制成图表，曲线的形状根据数据的不同而不同：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/84067e23f2ab0423679379afc6ed6caf.png" alt="84067e23f2ab0423679379afc6ed6caf"></p><p>我们希望有一个帮助我们选择这个阀值的方法。一种方法是计算<strong>F1 值</strong>（<strong>F1 Score</strong>），其计算公式为：</p> ${ {F}_{1} }Score:2\frac{PR}{P+R}$<p>我们选择使得<strong>F1</strong>值最高的阀值。</p><h3 id="机器学习的数据"><a href="#机器学习的数据" class="headerlink" title="机器学习的数据"></a>机器学习的数据</h3><p>参考视频: 11 - 5 - Data For Machine Learning (11 min).mkv</p><p>在之前的视频中，我们讨论了评价指标。在这个视频中，我要稍微转换一下，讨论一下机器学习系统设计中另一个重要的方面，这往往涉及到用来训练的数据有多少。在之前的一些视频中，我曾告诫大家不要盲目地开始，而是花大量的时间来收集大量的数据，因为数据有时是唯一能实际起到作用的。但事实证明，在一定条件下，我会在这个视频里讲到这些条件是什么。得到大量的数据并在某种类型的学习算法中进行训练，可以是一种有效的方法来获得一个具有良好性能的学习算法。而这种情况往往出现在这些条件对于你的问题都成立。</p><p>并且你能够得到大量数据的情况下。这可以是一个很好的方式来获得非常高性能的学习算法。因此，在这段视频中，让我们一起讨论一下这个问题。</p><p>很多很多年前，我认识的两位研究人员<strong>Michele Banko</strong> 和<strong>Eric Brill</strong>进行了一项有趣的研究，他们尝试通过机器学习算法来区分常见的易混淆的单词，他们尝试了许多种不同的算法，并发现数据量非常大时，这些不同类型的算法效果都很好。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1a7c575dc1b606b8e6e4de71a14dc005.png" alt="1a7c575dc1b606b8e6e4de71a14dc005"></p><p>比如，在这样的句子中：早餐我吃了__个鸡蛋(<strong>to</strong>,<strong>two</strong>,<strong>too</strong>)，在这个例子中，“早餐我吃了2个鸡蛋”，这是一个易混淆的单词的例子。于是他们把诸如这样的机器学习问题，当做一类监督学习问题，并尝试将其分类，什么样的词，在一个英文句子特定的位置，才是合适的。他们用了几种不同的学习算法，这些算法都是在他们2001年进行研究的时候，都已经被公认是比较领先的。因此他们使用了一个方差，用于逻辑回归上的一个方差，被称作”感知器”(<strong>perceptron</strong>)。他们也采取了一些过去常用，但是现在比较少用的算法，比如 <strong>Winnow</strong>算法，很类似于回归问题，但在一些方面又有所不同，过去用得比较多，但现在用得不太多。还有一种基于内存的学习算法，现在也用得比较少了，但是我稍后会讨论一点，而且他们用了一个朴素算法。这些具体算法的细节不那么重要，我们下面希望探讨，什么时候我们会希望获得更多数据，而非修改算法。他们所做的就是改变了训练数据集的大小，并尝试将这些学习算法用于不同大小的训练数据集中，这就是他们得到的结果。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/befe860fd4b1aef2f6eebf617baf5877.jpg" alt="befe860fd4b1aef2f6eebf617baf5877"></p><p>这些趋势非常明显，首先大部分算法，都具有相似的性能，其次，随着训练数据集的增大，在横轴上代表以百万为单位的训练集大小，从0.1个百万到1000百万，也就是到了10亿规模的训练集的样本，这些算法的性能也都对应地增强了。</p><p>事实上，如果你选择任意一个算法，可能是选择了一个”劣等的”算法，如果你给这个劣等算法更多的数据，那么从这些例子中看起来的话，它看上去很有可能会其他算法更好，甚至会比”优等算法”更好。由于这项原始的研究非常具有影响力，因此已经有一系列许多不同的研究显示了类似的结果。这些结果表明，许多不同的学习算法有时倾向于表现出非常相似的表现，这还取决于一些细节，但是真正能提高性能的，是你能够给一个算法大量的训练数据。像这样的结果，引起了一种在机器学习中的普遍共识：”取得成功的人不是拥有最好算法的人，而是拥有最多数据的人”。</p><p>那么这种说法在什么时候是真，什么时候是假呢？因为如果我们有一个学习算法，并且如果这种说法是真的，那么得到大量的数据通常是保证我们具有一个高性能算法的最佳方式，而不是去争辩应该用什么样的算法。</p><p>假如有这样一些假设，在这些假设下有大量我们认为有用的训练集，我们假设在我们的机器学习问题中，特征值$x$包含了足够的信息，这些信息可以帮助我们用来准确地预测$y$，例如，如果我们采用了一些容易混淆的词，如：<strong>two</strong>、<strong>to</strong>、<strong>too</strong>，假如说它能够描述$x$，捕捉到需要填写的空白处周围的词语，那么特征捕捉到之后，我们就希望有对于“早饭我吃了__鸡蛋”，那么这就有大量的信息来告诉我中间我需要填的词是“两个”(<strong>two</strong>)，而不是单词 <strong>to</strong> 或<strong>too</strong>，因此特征捕捉，哪怕是周围词语中的一个词，就能够给我足够的信息来确定出标签 $y$是什么。换句话说，从这三组易混淆的词中，我应该选什么词来填空。</p><p>那么让我们来看一看，大量的数据是有帮助的情况。假设特征值有足够的信息来预测$y$值，假设我们使用一种需要大量参数的学习算法，比如有很多特征的逻辑回归或线性回归，或者用带有许多隐藏单元的神经网络，那又是另外一种带有很多参数的学习算法，这些都是非常强大的学习算法，它们有很多参数，这些参数可以拟合非常复杂的函数，因此我要调用这些，我将把这些算法想象成低偏差算法，因为我们能够拟合非常复杂的函数，而且因为我们有非常强大的学习算法，这些学习算法能够拟合非常复杂的函数。很有可能，如果我们用这些数据运行这些算法，这种算法能很好地拟合训练集，因此，训练误差就会很低了。</p><p>现在假设我们使用了非常非常大的训练集，在这种情况下，尽管我们希望有很多参数，但是如果训练集比参数的数量还大，甚至是更多，那么这些算法就不太可能会过度拟合。也就是说训练误差有希望接近测试误差。</p><p>另一种考虑这个问题的角度是为了有一个高性能的学习算法，我们希望它不要有高的偏差和方差。</p><p>因此偏差问题，我么将通过确保有一个具有很多参数的学习算法来解决，以便我们能够得到一个较低偏差的算法，并且通过用非常大的训练集来保证。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/05a3c884505e08028d37a04472d0964a.png" alt="05a3c884505e08028d37a04472d0964a"></p><p>我们在此没有方差问题，我们的算法将没有方差，并且通过将这两个值放在一起，我们最终可以得到一个低误差和低方差的学习算法。这使得我们能够很好地测试测试数据集。从根本上来说，这是一个关键的假设：特征值有足够的信息量，且我们有一类很好的函数，这是为什么能保证低误差的关键所在。它有大量的训练数据集，这能保证得到更多的方差值，因此这给我们提出了一些可能的条件，如果你有大量的数据，而且你训练了一种带有很多参数的学习算法，那么这将会是一个很好的方式，来提供一个高性能的学习算法。</p><p>我觉得关键的测试：首先，一个人类专家看到了特征值 $x$，能很有信心的预测出$y$值吗？因为这可以证明 $ y$ 可以根据特征值$x$被准确地预测出来。其次，我们实际上能得到一组庞大的训练集，并且在这个训练集中训练一个有很多参数的学习算法吗？如果你不能做到这两者，那么更多时候，你会得到一个性能很好的学习算法。</p><h2 id="支持向量机-Support-Vector-Machines"><a href="#支持向量机-Support-Vector-Machines" class="headerlink" title="支持向量机(Support Vector Machines)"></a>支持向量机(Support Vector Machines)</h2><h3 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h3><p>参考视频: 12 - 1 - Optimization Objective (15 min).mkv</p><p>到目前为止,你已经见过一系列不同的学习算法。在监督学习中，许多学习算法的性能都非常类似，因此，重要的不是你该选择使用学习算法<strong>A</strong>还是学习算法<strong>B</strong>，而更重要的是，应用这些算法时，所创建的大量数据在应用这些算法时，表现情况通常依赖于你的水平。比如：你为学习算法所设计的特征量的选择，以及如何选择正则化参数，诸如此类的事。还有一个更加强大的算法广泛的应用于工业界和学术界，它被称为支持向量机(<strong>Support Vector Machine</strong>)。与逻辑回归和神经网络相比，支持向量机，或者简称<strong>SVM</strong>，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。因此，在接下来的视频中，我会探讨这一算法。在稍后的课程中，我也会对监督学习算法进行简要的总结。当然，仅仅是作简要描述。但对于支持向量机，鉴于该算法的强大和受欢迎度，在本课中，我会花许多时间来讲解它。它也是我们所介绍的最后一个监督学习算法。</p><p>正如我们之前开发的学习算法，我们从优化目标开始。那么，我们开始学习这个算法。为了描述支持向量机，事实上，我将会从逻辑回归开始展示我们如何一点一点修改来得到本质上的支持向量机。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3d12b07f13a976e916d0c707fd03153c.png" alt="3d12b07f13a976e916d0c707fd03153c"><br>那么，在逻辑回归中我们已经熟悉了这里的假设函数形式，和右边的S型激励函数。然而，为了解释一些数学知识.我将用$z$ 表示$\theta^Tx$。</p><p>现在考虑下我们想要逻辑回归做什么：如果有一个 $y=1$的样本，我的意思是不管是在训练集中或是在测试集中，又或者在交叉验证集中，总之是 $y=1$，现在我们希望${ {h}_{\theta } }\left( x \right)$ 趋近1。因为我们想要正确地将此样本分类，这就意味着当 ${ {h}_{\theta } }\left( x \right)$趋近于1时，$\theta^Tx$ 应当远大于0，这里的$>>$意思是远远大于0。这是因为由于 $z$ 表示 $\theta^Tx$，当 $z$远大于0时，即到了该图的右边，你不难发现此时逻辑回归的输出将趋近于1。相反地，如果我们有另一个样本，即$y=0$。我们希望假设函数的输出值将趋近于0，这对应于$\theta^Tx$，或者就是 $z$ 会远小于0，因为对应的假设函数的输出值趋近0。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/66facb7fa8eddc3a860e420588c981d5.png" alt="66facb7fa8eddc3a860e420588c981d5"><br>如果你进一步观察逻辑回归的代价函数，你会发现每个样本 $(x,y)$都会为总代价函数，增加这里的一项，因此，对于总代价函数通常会有对所有的训练样本求和，并且这里还有一个$1/m$项，但是，在逻辑回归中，这里的这一项就是表示一个训练样本所对应的表达式。现在，如果我将完整定义的假设函数代入这里。那么，我们就会得到每一个训练样本都影响这一项。</p><p>现在，先忽略 $1/m$ 这一项，但是这一项是影响整个总代价函数中的这一项的。</p><p>现在，一起来考虑两种情况：</p><p>一种是$y$等于1的情况；另一种是 $y$ 等于0的情况。</p><p>在第一种情况中，假设 $y=1$ ，此时在目标函数中只需有第一项起作用，因为$y=1$时，$(1-y)$项将等于0。因此，当在 $y=1$ 的样本中时，即在 $(x, y) $中 ，我们得到 $y=1$ $-\log(1-\frac{1}{1+e^{-z} })$这样一项，这里同上一张幻灯片一致。</p><p>我用 $z$ 表示$\theta^Tx$，即： $z= \theta^Tx$。当然，在代价函数中，$y$ 前面有负号。我们只是这样表示，如果 $y=1$ 代价函数中，这一项也等于1。这样做是为了简化此处的表达式。如果画出关于$z$ 的函数，你会看到左下角的这条曲线，我们同样可以看到，当$z$ 增大时，也就是相当于$\theta^Tx$增大时，$z$ 对应的值会变的非常小。对整个代价函数而言，影响也非常小。这也就解释了，为什么逻辑回归在观察到正样本$y=1$时，试图将$\theta^Tx$设置得非常大。因为，在代价函数中的这一项会变的非常小。</p><p>现在开始建立支持向量机，我们从这里开始：</p><p>我们会从这个代价函数开始，也就是$-\log(1-\frac{1}{1+e^{-z} })$一点一点修改，让我取这里的$z=1$ 点，我先画出将要用的代价函数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b4b43ee98bff9f5e73d841af1fa316bf.png" alt="b4b43ee98bff9f5e73d841af1fa316bf"><br>新的代价函数将会水平的从这里到右边(图外)，然后我再画一条同逻辑回归非常相似的直线，但是，在这里是一条直线，也就是我用紫红色画的曲线，就是这条紫红色的曲线。那么，到了这里已经非常接近逻辑回归中使用的代价函数了。只是这里是由两条线段组成，即位于右边的水平部分和位于左边的直线部分，先别过多的考虑左边直线部分的斜率，这并不是很重要。但是，这里我们将使用的新的代价函数，是在$y=1$的前提下的。你也许能想到，这应该能做同逻辑回归中类似的事情，但事实上，在之后的优化问题中，这会变得更坚定，并且为支持向量机，带来计算上的优势。例如，更容易计算股票交易的问题等等。</p><p>目前，我们只是讨论了$y=1$的情况，另外一种情况是当$y=0$时，此时如果你仔细观察代价函数只留下了第二项，因为第一项被消除了。如果当$y=0$时，那么这一项也就是0了。所以上述表达式只留下了第二项。因此，这个样本的代价或是代价函数的贡献。将会由这一项表示。并且，如果你将这一项作为$z$的函数，那么，这里就会得到横轴$z$。现在，你完成了支持向量机中的部分内容，同样地，我们要替代这一条蓝色的线，用相似的方法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ab372c9161375a4f7b6f0bd4a69560e9.png" alt="ab372c9161375a4f7b6f0bd4a69560e9"><br>如果我们用一个新的代价函数来代替，即这条从0点开始的水平直线，然后是一条斜线，像上图。那么，现在让我给这两个方程命名，左边的函数，我称之为${\cos}t_1{(z)}$，同时，右边函数我称它为${\cos}t_0{(z)}$。这里的下标是指在代价函数中，对应的 $y=1$ 和 $y=0$ 的情况，拥有了这些定义后，现在，我们就开始构建支持向量机。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/59541ab1fda4f92d6f1b508c8e29ab1c.png" alt="59541ab1fda4f92d6f1b508c8e29ab1c"><br>这是我们在逻辑回归中使用代价函数$J(\theta)$。也许这个方程看起来不是非常熟悉。这是因为之前有个负号在方程外面，但是，这里我所做的是，将负号移到了表达式的里面，这样做使得方程看起来有些不同。对于支持向量机而言，实质上我们要将这替换为${\cos}t_1{(z)}$，也就是${\cos}t_1{(\theta^Tx)}$，同样地，我也将这一项替换为${\cos}t_0{(z)}$，也就是代价${\cos}t_0{(\theta^Tx)}$。这里的代价函数${\cos}t_1$，就是之前所提到的那条线。此外，代价函数${\cos}t_0$，也是上面所介绍过的那条线。因此，对于支持向量机，我们得到了这里的最小化问题，即:</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4ac1ca54cb0f2c465ab81339baaf9186.png" alt="4ac1ca54cb0f2c465ab81339baaf9186"><br>然后，再加上正则化参数。现在，按照支持向量机的惯例，事实上，我们的书写会稍微有些不同，代价函数的参数表示也会稍微有些不同。</p><p>首先，我们要除去$1/m$这一项，当然，这仅仅是由于人们使用支持向量机时，对比于逻辑回归而言，不同的习惯所致，但这里我所说的意思是：你知道，我将要做的是仅仅除去$1/m$这一项，但是，这也会得出同样的 ${ {\theta } }$ 最优值，好的，因为$1/m$ 仅是个常量，因此，你知道在这个最小化问题中，无论前面是否有$1/m$ 这一项，最终我所得到的最优值${ {\theta } }$都是一样的。这里我的意思是，先给你举一个样本，假定有一最小化问题：即要求当$(u-5)^2+1$取得最小值时的$u$值，这时最小值为：当$u=5$时取得最小值。</p><p>现在，如果我们想要将这个目标函数乘上常数10，这里我的最小化问题就变成了：求使得$10×(u-5)^2+10$最小的值$u$，然而，使得这里最小的$u$值仍为5。因此将一些常数乘以你的最小化项，这并不会改变最小化该方程时得到$u$值。因此，这里我所做的是删去常量$m$。也相同的，我将目标函数乘上一个常量$m$，并不会改变取得最小值时的${ {\theta } }$值。</p><p>第二点概念上的变化，我们只是指在使用支持向量机时，一些如下的标准惯例，而不是逻辑回归。因此，对于逻辑回归，在目标函数中，我们有两项：第一个是训练样本的代价，第二个是我们的正则化项，我们不得不去用这一项来平衡。这就相当于我们想要最小化$A$加上正则化参数$\lambda$，然后乘以其他项$B$对吧？这里的$A$表示这里的第一项，同时我用<strong>B</strong>表示第二项，但不包括$\lambda$，我们不是优化这里的$A+\lambda\times B$。我们所做的是通过设置不同正则参数$\lambda$达到优化目的。这样，我们就能够权衡对应的项，是使得训练样本拟合的更好。即最小化$A$。还是保证正则参数足够小，也即是对于<strong>B</strong>项而言，但对于支持向量机，按照惯例，我们将使用一个不同的参数替换这里使用的$\lambda$来权衡这两项。你知道，就是第一项和第二项我们依照惯例使用一个不同的参数称为$C$，同时改为优化目标，$C×A+B$。<br>因此，在逻辑回归中，如果给定$\lambda$，一个非常大的值，意味着给予$B$更大的权重。而这里，就对应于将$C$ 设定为非常小的值，那么，相应的将会给$B$比给$A$更大的权重。因此，这只是一种不同的方式来控制这种权衡或者一种不同的方法，即用参数来决定是更关心第一项的优化，还是更关心第二项的优化。当然你也可以把这里的参数$C$ 考虑成$1/\lambda$，同 $1/\lambda$所扮演的角色相同，并且这两个方程或这两个表达式并不相同，因为$C=1/\lambda$，但是也并不全是这样，如果当$C=1/\lambda$时，这两个优化目标应当得到相同的值，相同的最优值 ${ {\theta } }$。因此，就用它们来代替。那么，我现在删掉这里的$\lambda$，并且用常数$C$来代替。因此，这就得到了在支持向量机中我们的整个优化目标函数。然后最小化这个目标函数，得到<strong>SVM</strong> 学习到的参数$C$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5a63e35db410fdb57c76de97ea888278.png" alt="5a63e35db410fdb57c76de97ea888278"><br>最后有别于逻辑回归输出的概率。在这里，我们的代价函数，当最小化代价函数，获得参数${ {\theta } }$时，支持向量机所做的是它来直接预测$y$的值等于1，还是等于0。因此，这个假设函数会预测1。当$\theta^Tx$大于或者等于0时，或者等于0时，所以学习参数${ {\theta } }$就是支持向量机假设函数的形式。那么，这就是支持向量机数学上的定义。</p><p>在接下来的视频中，让我们再回去从直观的角度看看优化目标，实际上是在做什么，以及SVM的假设函数将会学习什么，同时也会谈谈如何做些许修改，学习更加复杂、非线性的函数。</p><h3 id="大边界的直观理解"><a href="#大边界的直观理解" class="headerlink" title="大边界的直观理解"></a>大边界的直观理解</h3><p>参考视频: 12 - 2 - Large Margin Intuition (11 min).mkv</p><p>人们有时将支持向量机看作是大间距分类器。在这一部分，我将介绍其中的含义，这有助于我们直观理解<strong>SVM</strong>模型的假设是什么样的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/cc66af7cbd88183efc07c8ddf09cbc73.png" alt="cc66af7cbd88183efc07c8ddf09cbc73"><br>这是我的支持向量机模型的代价函数，在左边这里我画出了关于$z$的代价函数${\cos}t_1{(z)}$，此函数用于正样本，而在右边这里我画出了关于$z$的代价函数${\cos}t_0{(z)}$，横轴表示$z$，现在让我们考虑一下，最小化这些代价函数的必要条件是什么。如果你有一个正样本，$y=1$，则只有在$z>=1$时，代价函数${\cos}t_1{(z)}$才等于0。</p><p>换句话说，如果你有一个正样本，我们会希望$\theta^Tx>=1$，反之，如果$y=0$，我们观察一下，函数${\cos}t_0{(z)}$，它只有在$z&lt;=-1$的区间里函数值为0。这是支持向量机的一个有趣性质。事实上，如果你有一个正样本$y=1$，则其实我们仅仅要求$\theta^Tx$大于等于0，就能将该样本恰当分出，这是因为如果$\theta^Tx$&gt;0大的话，我们的模型代价函数值为0，类似地，如果你有一个负样本，则仅需要$\theta^Tx$&amp;lt;=0就会将负例正确分离，但是，支持向量机的要求更高，不仅仅要能正确分开输入的样本，即不仅仅要求$\theta^Tx$&gt;0，我们需要的是比0值大很多，比如大于等于1，我也想这个比0小很多，比如我希望它小于等于-1，这就相当于在支持向量机中嵌入了一个额外的安全因子，或者说安全的间距因子。</p><p>当然，逻辑回归做了类似的事情。但是让我们看一下，在支持向量机中，这个因子会导致什么结果。具体而言，我接下来会考虑一个特例。我们将这个常数$C$设置成一个非常大的值。比如我们假设$C$的值为100000或者其它非常大的数，然后来观察支持向量机会给出什么结果？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/12ebd5973230e8fdf279ae09e187f437.png" alt="12ebd5973230e8fdf279ae09e187f437"><br>如果 $C$非常大，则最小化代价函数的时候，我们将会很希望找到一个使第一项为0的最优解。因此，让我们尝试在代价项的第一项为0的情形下理解该优化问题。比如我们可以把$C$设置成了非常大的常数，这将给我们一些关于支持向量机模型的直观感受。</p> $\min_\limits{\theta}C\sum_\limits{i=1}^{m}\left[y^{(i)}{\cos}t_{1}\left(\theta^{T}x^{(i)}\right)+\left(1-y^{(i)}\right){\cos}t\left(\theta^{T}x^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{i=1}^{n}\theta^{2}_{j}$<p>我们已经看到输入一个训练样本标签为$y=1$，你想令第一项为0，你需要做的是找到一个${ {\theta } }$，使得$\theta^Tx>=1$，类似地，对于一个训练样本，标签为$y=0$，为了使${\cos}t_0{(z)}$ 函数的值为0，我们需要$\theta^Tx&lt;=-1$。因此，现在考虑我们的优化问题。选择参数，使得第一项等于0，就会导致下面的优化问题，因为我们将选择参数使第一项为0，因此这个函数的第一项为0，因此是$C$乘以0加上二分之一乘以第二项。这里第一项是$C$乘以0，因此可以将其删去，因为我知道它是0。</p><p>这将遵从以下的约束：$\theta^Tx^{(i)}>=1$，如果 $y^{(i)}$是等于1 的，$\theta^Tx^{(i)}&lt;=-1$，如果样本$i$是一个负样本，这样当你求解这个优化问题的时候，当你最小化这个关于变量${ {\theta } }$的函数的时候，你会得到一个非常有趣的决策边界。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b1f670fddd9529727aa16a559d49d151.png" alt="b1f670fddd9529727aa16a559d49d151"><br>具体而言，如果你考察这样一个数据集，其中有正样本，也有负样本，可以看到这个数据集是线性可分的。我的意思是，存在一条直线把正负样本分开。当然有多条不同的直线，可以把正样本和负样本完全分开。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/01105c3afd1315acf0577f8493137dcc.png" alt="01105c3afd1315acf0577f8493137dcc"><br>比如，这就是一个决策边界可以把正样本和负样本分开。但是多多少少这个看起来并不是非常自然是么?</p><p>或者我们可以画一条更差的决策界，这是另一条决策边界，可以将正样本和负样本分开，但仅仅是勉强分开，这些决策边界看起来都不是特别好的选择，支持向量机将会选择这个黑色的决策边界，相较于之前我用粉色或者绿色画的决策界。这条黑色的看起来好得多，黑线看起来是更稳健的决策界。在分离正样本和负样本上它显得的更好。数学上来讲，这是什么意思呢？这条黑线有更大的距离，这个距离叫做间距(<strong>margin</strong>)。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e68e6ca3275f433330a7981971eb4f16.png" alt="e68e6ca3275f433330a7981971eb4f16"><br>当画出这两条额外的蓝线，我们看到黑色的决策界和训练样本之间有更大的最短距离。然而粉线和蓝线离训练样本就非常近，在分离样本的时候就会比黑线表现差。因此，这个距离叫做支持向量机的间距，而这是支持向量机具有鲁棒性的原因，因为它努力用一个最大间距来分离样本。因此支持向量机有时被称为<strong>大间距分类器</strong>，而这其实是求解上一页幻灯片上优化问题的结果。</p><p>我知道你也许想知道求解上一页幻灯片中的优化问题为什么会产生这个结果？它是如何产生这个大间距分类器的呢？我知道我还没有解释这一点。</p><p>我将会从直观上略述为什么这个优化问题会产生大间距分类器。总之这个图示有助于你理解支持向量机模型的做法，即努力将正样本和负样本用最大的间距分开。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dd6239efad3d3ee7a89a28574d7795b3.png" alt="dd6239efad3d3ee7a89a28574d7795b3"><br>在本节课中关于大间距分类器，我想讲最后一点：我们将这个大间距分类器中的正则化因子常数$C$设置的非常大，我记得我将其设置为了100000，因此对这样的一个数据集，也许我们将选择这样的决策界，从而最大间距地分离开正样本和负样本。那么在让代价函数最小化的过程中，我们希望找出在$y=1$和$y=0$两种情况下都使得代价函数中左边的这一项尽量为零的参数。如果我们找到了这样的参数，则我们的最小化问题便转变成：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f4b6dee99cfb4352b3cac5287002e8de.png" alt="f4b6dee99cfb4352b3cac5287002e8de"><br>事实上，支持向量机现在要比这个大间距分类器所体现得更成熟，尤其是当你使用大间距分类器的时候，你的学习算法会受异常点(outlier) 的影响。比如我们加入一个额外的正样本。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b8fbe2f6ac48897cf40497a2d034c691.png" alt="b8fbe2f6ac48897cf40497a2d034c691"><br>在这里，如果你加了这个样本，为了将样本用最大间距分开，也许我最终会得到一条类似这样的决策界，对么？就是这条粉色的线，仅仅基于一个异常值，仅仅基于一个样本，就将我的决策界从这条黑线变到这条粉线，这实在是不明智的。而如果正则化参数$C$，设置的非常大，这事实上正是支持向量机将会做的。它将决策界，从黑线变到了粉线，但是如果$C$ 设置的小一点，<strong>如果你将C设置的不要太大，则你最终会得到这条黑线，</strong> 当然数据如果不是线性可分的，如果你在这里有一些正样本或者你在这里有一些负样本，则支持向量机也会将它们恰当分开。因此，大间距分类器的描述，仅仅是从直观上给出了正则化参数$C$非常大的情形，同时，要提醒你$C$的作用类似于$1/\lambda$，$\lambda$是我们之前使用过的正则化参数。这只是$C$非常大的情形，或者等价地 $\lambda$ 非常小的情形。你最终会得到类似粉线这样的决策界，但是实际上应用支持向量机的时候，<strong>当$C$不是非常非常大的时候，它可以忽略掉一些异常点的影响，得到更好的决策界。</strong> 甚至当你的数据不是线性可分的时候，支持向量机也可以给出好的结果。</p><p>回顾 $C=1/\lambda$，因此：</p> $C$ 较大时，相当于 $\lambda$ 较小，可能会导致过拟合，高方差。 $C$ 较小时，相当于$\lambda$较大，可能会导致低拟合，高偏差。<p>我们稍后会介绍支持向量机的偏差和方差，希望在那时候关于如何处理参数的这种平衡会变得更加清晰。我希望，这节课给出了一些关于为什么支持向量机被看做大间距分类器的直观理解。它用最大间距将样本区分开，尽管从技术上讲，这只有当参数$C$是非常大的时候是真的，但是它对于理解支持向量机是有益的。</p><p>本节课中我们略去了一步，那就是我们在幻灯片中给出的优化问题。为什么会是这样的？它是如何得出大间距分类器的？我在本节中没有讲解，在下一节课中，我将略述这些问题背后的数学原理，来解释这个优化问题是如何得到一个大间距分类器的。</p><h3 id="大边界分类背后的数学（选修）"><a href="#大边界分类背后的数学（选修）" class="headerlink" title="大边界分类背后的数学（选修）"></a>大边界分类背后的数学（选修）</h3><p>参考视频: 12 - 3 - Mathematics Behind Large Margin Classification (Optional) (20 min).mkv</p><p>在本节课中，我将介绍一些大间隔分类背后的数学原理。本节为选修部分，你完全可以跳过它，但是听听这节课可能让你对支持向量机中的优化问题，以及如何得到大间距分类器，产生更好的直观理解。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/55e05845c636c8c99c03e6e29337d8c4.png" alt="55e05845c636c8c99c03e6e29337d8c4"><br>首先，让我来给大家复习一下关于向量内积的知识。假设我有两个向量，$u$和$v$，我将它们写在这里。两个都是二维向量，我们看一下，$u^T v$的结果。$u^T v$也叫做向量$u$和$v$之间的内积。由于是二维向量，我可以将它们画在这个图上。我们说，这就是向量$u$即在横轴上，取值为某个${ {u}_{1} }$，而在纵轴上，高度是某个${ {u}_{2} }$作为$u$的第二个分量。现在，很容易计算的一个量就是向量$u$的范数。$\left\| u \right\|$表示$u$的范数，即$u$的长度，即向量$u$的欧几里得长度。根据毕达哥拉斯定理，$\left\| u \right\|=\sqrt{u_{1}^{2}+u_{2}^{2} }$，这是向量$u$的长度，它是一个实数。现在你知道了这个的长度是多少了。我刚刚画的这个向量的长度就知道了。</p><p>现在让我们回头来看向量$v$ ，因为我们想计算内积。$v$是另一个向量，它的两个分量${ {v}_{1} }$和${ {v}_{2} }$是已知的。向量$v$可以画在这里，现在让我们来看看如何计算$u$和$v$之间的内积。这就是具体做法，我们将向量$v$投影到向量$u$上，我们做一个直角投影，或者说一个90度投影将其投影到$u$上，接下来我度量这条红线的长度。我称这条红线的长度为$p$，因此$p$就是长度，或者说是向量$v$投影到向量$u$上的量，我将它写下来，$p$是$v$投影到向量$u$上的长度，因此可以将${ {u}^{T} }v=p\centerdot \left\| u \right\|$，或者说$u$的长度。这是计算内积的一种方法。如果你从几何上画出$p$的值，同时画出$u$的范数，你也会同样地计算出内积，答案是一样的。另一个计算公式是：$u^T v$就是$\left[ { {u}_{1} }\text{ }{ {u}_{2} } \right]$ 这个一行两列的矩阵乘以$v$。因此可以得到${ {u}_{1} }\times { {v}_{1} }+{ {u}_{2} }\times { {v}_{2} }$。根据线性代数的知识，这两个公式会给出同样的结果。顺便说一句，$u^Tv=v^Tu$。因此如果你将$u$和$v$交换位置，将$u$投影到$v$上，而不是将$v$投影到$u$上，然后做同样地计算，只是把$u$和$v$的位置交换一下，你事实上可以得到同样的结果。申明一点，在这个等式中$u$的范数是一个实数，$p$也是一个实数，因此$u^T v$就是两个实数正常相乘。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/44ad37bce4b7e03835095dccbd2a7b7a.png" alt="44ad37bce4b7e03835095dccbd2a7b7a"><br>最后一点，需要注意的就是$p$值，$p$事实上是有符号的，即它可能是正值，也可能是负值。我的意思是说，如果$u$是一个类似这样的向量，$v$是一个类似这样的向量，$u$和$v$之间的夹角大于90度，则如果将$v$投影到$u$上，会得到这样的一个投影，这是$p$的长度，在这个情形下我们仍然有${ {u}^{T} }v$是等于$p$乘以$u$的范数。唯一一点不同的是$p$在这里是负的。在内积计算中，如果$u$和$v$之间的夹角小于90度，那么那条红线的长度$p$是正值。然而如果这个夹角大于90度，则$p$将会是负的。就是这个小线段的长度是负的。如果它们之间的夹角大于90度，两个向量之间的内积也是负的。这就是关于向量内积的知识。我们接下来将会使用这些关于向量内积的性质试图来理解支持向量机中的目标函数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/03bd4b3ff69e327f7949c3d2a73eed8a.png" alt="03bd4b3ff69e327f7949c3d2a73eed8a"><br>这就是我们先前给出的支持向量机模型中的目标函数。为了讲解方便，我做一点简化，仅仅是为了让目标函数更容易被分析。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3cc61c6e5fe85c2a7bf8170f5bbfd8c3.png" alt="3cc61c6e5fe85c2a7bf8170f5bbfd8c3"><br>我接下来忽略掉截距，令${ {\theta }_{0} }=0$，这样更容易画示意图。我将特征数$n$置为2，因此我们仅有两个特征${ {x}_{1} },{ {x}_{2} }$，现在我们来看一下目标函数，支持向量机的优化目标函数。当我们仅有两个特征，即$n=2$时，这个式子可以写作：$\frac{1}{2}\left({\theta_1^2+\theta_2^2}\right)=\frac{1}{2}\left(\sqrt{\theta_1^2+\theta_2^2}\right)^2$，我们只有两个参数${ {\theta }_{1} },{ {\theta }_{2} }$。你可能注意到括号里面的这一项是向量${ {\theta } }$的范数，或者说是向量${ {\theta } }$的长度。我的意思是如果我们将向量${ {\theta } }$写出来，那么我刚刚画红线的这一项就是向量${ {\theta } }$的长度或范数。这里我们用的是之前学过的向量范数的定义，事实上这就等于向量${ {\theta } }$的长度。</p><p>当然你可以将其写作${ {\theta }_{0} }\text{,}{ {\theta }_{1} },{ {\theta }_{2} }$，如果${ {\theta }_{0} }=0$，那就是${ {\theta }_{1} },{ {\theta }_{2} }$的长度。在这里我将忽略${ {\theta }_{0} }$，这样来写$\theta$的范数，它仅仅和${ {\theta }_{1} },{ {\theta }_{2} }$有关。但是，数学上不管你是否包含，其实并没有差别，因此在我们接下来的推导中去掉${ {\theta }_{0} }$不会有影响这意味着我们的目标函数是等于$\frac{1}{2}\left\| \theta \right\|^2$。因此支持向量机做的全部事情，就是<strong>极小化参数向量</strong>${ {\theta } }$<strong>范数的平方，或者说长度的平方</strong>。</p><p>现在我将要看看这些项：$\theta^{T}x$更深入地理解它们的含义。给定参数向量$\theta $给定一个样本$x$，这等于什么呢?在前一页幻灯片上，我们画出了在不同情形下，$u^Tv$的示意图，我们将会使用这些概念，$\theta $和$x^{(i)}$就类似于$u$和$v$ 。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4510b8fbc90ba2b233bb6996529f2df1.png" alt="4510b8fbc90ba2b233bb6996529f2df1"><br>让我们看一下示意图：我们考察一个单一的训练样本，我有一个正样本在这里，用一个叉来表示这个样本$x^{(i)}$，意思是在水平轴上取值为$x_1^{(i)}$，在竖直轴上取值为$x_2^{(i)}$。这就是我画出的训练样本。尽管我没有将其真的看做向量。它事实上就是一个始于原点，终点位置在这个训练样本点的向量。现在，我们有一个参数向量我会将它也画成向量。我将$θ_1$画在横轴这里，将$θ_2$ 画在纵轴这里，那么内积$θ^T x^{(i)}$ 将会是什么呢？</p><p>使用我们之前的方法，我们计算的方式就是我将训练样本投影到参数向量${ {\theta } }$，然后我来看一看这个线段的长度，我将它画成红色。我将它称为$p^{(i)}$用来表示这是第 $i$个训练样本在参数向量${ {\theta } }$上的投影。根据我们之前幻灯片的内容，我们知道的是$θ^Tx^{(i)}$将会等于$p$ 乘以向量 $θ$ 的长度或范数。这就等于$\theta_1\cdot{x_1^{(i)} }+\theta_2\cdot{x_2^{(i)} }$。这两种方式是等价的，都可以用来计算$θ$和$x^{(i)}$之间的内积。</p><p>这告诉了我们什么呢？这里表达的意思是：这个$θ^Tx^{(i)}>=1$ 或者$θ^Tx^{(i)}&lt;-1$的,约束是可以被$p^{(i)}\cdot{x}>=1$这个约束所代替的。因为$θ^Tx^{(i)}=p^{(i)}\cdot{\left\| \theta \right\|}$ ，将其写入我们的优化目标。我们将会得到没有了约束，$θ^Tx^{(i)}$而变成了$p^{(i)}\cdot{\left\| \theta \right\|}$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/912cb43058cee46ddf51598b7538968c.png" alt="912cb43058cee46ddf51598b7538968c"><br>需要提醒一点，我们之前曾讲过这个优化目标函数可以被写成等于$\frac{1}{2}\left\| \theta \right\|^2$。</p><p>现在让我们考虑下面这里的训练样本。现在，继续使用之前的简化，即${ {\theta }_{0} }=0$，我们来看一下支持向量机会选择什么样的决策界。这是一种选择，我们假设支持向量机会选择这个决策边界。这不是一个非常好的选择，因为它的间距很小。这个决策界离训练样本的距离很近。我们来看一下为什么支持向量机不会选择它。</p><p>对于这样选择的参数${ {\theta } }$，可以看到参数向量${ {\theta } }$事实上是和决策界是90度正交的，因此这个绿色的决策界对应着一个参数向量${ {\theta } }$这个方向,顺便提一句${ {\theta }_{0} }=0$的简化仅仅意味着决策界必须通过原点$(0,0)$。现在让我们看一下这对于优化目标函数意味着什么。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20725ba601c1c90d1024e50fc24c579b.png" alt="20725ba601c1c90d1024e50fc24c579b"><br>比如这个样本，我们假设它是我的第一个样本$x^{(1)}$，如果我考察这个样本到参数${ {\theta } }$的投影，投影是这个短的红线段，就等于$p^{(1)}$，它非常短。类似地，这个样本如果它恰好是$x^{(2)}$，我的第二个训练样本，则它到${ {\theta } }$的投影在这里。我将它画成粉色，这个短的粉色线段是$p^{(2)}$，即第二个样本到我的参数向量${ {\theta } }$的投影。因此，这个投影非常短。$p^{(2)}$事实上是一个负值，$p^{(2)}$是在相反的方向，这个向量和参数向量${ {\theta } }$的夹角大于90度，$p^{(2)}$的值小于0。</p><p>我们会发现这些$p^{(i)}$将会是非常小的数，因此当我们考察优化目标函数的时候，对于正样本而言，我们需要$p^{(i)}\cdot{\left\| \theta \right\|}>=1$,但是如果 $p^{(i)}$在这里非常小,那就意味着我们需要${ {\theta } }$的范数非常大.因为如果 $p^{(1)}$ 很小,而我们希望$p^{(1)}\cdot{\left\| \theta \right\|}>=1$,令其实现的唯一的办法就是这两个数较大。如果 $p^{(1)}$ 小，我们就希望${ {\theta } }$的范数大。类似地，对于负样本而言我们需要$p^{(2)}\cdot{\left\|\theta \right\|}&lt;=-1$。我们已经在这个样本中看到$p^{(2)}$会是一个非常小的数，因此唯一的办法就是${ {\theta } }$的范数变大。但是我们的目标函数是希望找到一个参数${ {\theta } }$，它的范数是小的。因此，这看起来不像是一个好的参数向量${ {\theta } }$的选择。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5eab58ad9cb54b3b6fda8f6c96efff24.png" alt="5eab58ad9cb54b3b6fda8f6c96efff24"><br>相反的，来看一个不同的决策边界。比如说，支持向量机选择了这个决策界，现在状况会有很大不同。如果这是决策界，这就是相对应的参数${ {\theta } }$的方向，因此，在这个决策界之下，垂直线是决策界。使用线性代数的知识，可以说明，这个绿色的决策界有一个垂直于它的向量${ {\theta } }$。现在如果你考察你的数据在横轴$x$上的投影，比如这个我之前提到的样本，我的样本$x^{(1)}$，当我将它投影到横轴$x$上，或说投影到${ {\theta } }$上，就会得到这样$p^{(1)}$。它的长度是$p^{(1)}$，另一个样本，那个样本是$x^{(2)}$。我做同样的投影，我会发现，$p^{(2)}$的长度是负值。你会注意到现在$p^{(1)}$ 和$p^{(2)}$这些投影长度是长多了。如果我们仍然要满足这些约束，$P^{(i)}\cdot{\left\| \theta \right\|}$&gt;1，则因为$p^{(1)}$变大了，${ {\theta } }$的范数就可以变小了。因此这意味着通过选择右边的决策界，而不是左边的那个，支持向量机可以使参数${ {\theta } }$的范数变小很多。因此，如果我们想令${ {\theta } }$的范数变小，从而令${ {\theta } }$范数的平方变小，就能让支持向量机选择右边的决策界。这就是支持向量机如何能有效地产生大间距分类的原因。</p><p>看这条绿线，这个绿色的决策界。我们希望正样本和负样本投影到$\theta$的值大。要做到这一点的唯一方式就是选择这条绿线做决策界。这是大间距决策界来区分开正样本和负样本这个间距的值。这个间距的值就是$p^{(1)},p^{(2)},p^{(3)}$等等的值。通过让间距变大，即通过这些$p^{(1)},p^{(2)},p^{(3)}$等等的值，支持向量机最终可以找到一个较小的${ {\theta } }$范数。这正是支持向量机中最小化目标函数的目的。</p><p>以上就是为什么支持向量机最终会找到大间距分类器的原因。因为它试图极大化这些$p^{(i)}$的范数，它们是训练样本到决策边界的距离。最后一点，我们的推导自始至终使用了这个简化假设，就是参数$θ_0=0$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/65198a1748fdbe16da34afab9f33d801.png" alt="65198a1748fdbe16da34afab9f33d801"><br>就像我之前提到的。这个的作用是：$θ_0=0$的意思是我们让决策界通过原点。如果你令$θ_0$不是0的话，含义就是你希望决策界不通过原点。我将不会做全部的推导。实际上，支持向量机产生大间距分类器的结论，会被证明同样成立，证明方式是非常类似的，是我们刚刚做的证明的推广。</p><p>之前视频中说过，即便$θ_0$不等于0，支持向量机要做的事情都是优化这个目标函数对应着$C$值非常大的情况，但是可以说明的是，即便$θ_0$不等于0，支持向量机仍然会找到正样本和负样本之间的大间距分隔。</p><p>总之，我们解释了为什么支持向量机是一个大间距分类器。在下一节我们，将开始讨论如何利用支持向量机的原理，应用它们建立一个复杂的非线性分类器。</p><h3 id="核函数1"><a href="#核函数1" class="headerlink" title="核函数1"></a>核函数1</h3><p>参考视频: 12 - 4 - Kernels I (16 min).mkv</p><p>回顾我们之前讨论过可以使用高级数的多项式模型来解决无法用直线进行分隔的分类问题：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/529b6dbc07c9f39f5266bd0b3f628545.png" alt="529b6dbc07c9f39f5266bd0b3f628545"><br>为了获得上图所示的判定边界，我们的模型可能是${ {\theta }_{0} }+{ {\theta }_{1} }{ {x}_{1} }+{ {\theta }_{2} }{ {x}_{2} }+{ {\theta }_{3} }{ {x}_{1} }{ {x}_{2} }+{ {\theta }_{4} }x_{1}^{2}+{ {\theta }_{5} }x_{2}^{2}+\cdots $的形式。</p><p>我们可以用一系列的新的特征$f$来替换模型中的每一项。例如令：</p> ${ {f}_{1} }={ {x}_{1} },{ {f}_{2} }={ {x}_{2} },{ {f}_{3} }={ {x}_{1} }{ {x}_{2} },{ {f}_{4} }=x_{1}^{2},{ {f}_{5} }=x_{2}^{2}$<p>…得到$h_θ(x)={ {\theta }_{1} }f_1+{ {\theta }_{2} }f_2+...+{ {\theta }_{n} }f_n$。然而，除了对原有的特征进行组合以外，有没有更好的方法来构造$f_1,f_2,f_3$？我们可以利用核函数来计算出新的特征。</p><p>给定一个训练样本$x$，我们利用$x$的各个特征与我们预先选定的<strong>地标</strong>(<strong>landmarks</strong>)$l^{(1)},l^{(2)},l^{(3)}$的近似程度来选取新的特征$f_1,f_2,f_3$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2516821097bda5dfaf0b94e55de851e0.png" alt="2516821097bda5dfaf0b94e55de851e0"><br>例如：${ {f}_{1} }=similarity(x,{ {l}^{(1)} })=e(-\frac{ {{\left\| x-{ {l}^{(1)} } \right\|}^{2} }}{2{ {\sigma }^{2} }})$</p><p>其中：${ {\left\| x-{ {l}^{(1)} } \right\|}^{2} }=\sum{_{j=1}^{n} }{ {({ {x}_{j} }-l_{j}^{(1)})}^{2} }$，为实例$x$中所有特征与地标$l^{(1)}$之间的距离的和。上例中的$similarity(x,{ {l}^{(1)} })$就是核函数，具体而言，这里是一个<strong>高斯核函数</strong>(<strong>Gaussian Kernel</strong>)。 <strong>注：这个函数与正态分布没什么实际上的关系，只是看上去像而已。</strong></p><p>这些地标的作用是什么？如果一个训练样本$x$与地标$l$之间的距离近似于0，则新特征 $f$近似于$e^{-0}=1$，如果训练样本$x$与地标$l$之间距离较远，则$f$近似于$e^{-(一个较大的数)}=0$。</p><p>假设我们的训练样本含有两个特征[$x_{1}$ $x{_2}$]，给定地标$l^{(1)}$与不同的$\sigma$值，见下图：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b9acfc507a54f5ca13a3d50379972535.jpg" alt="b9acfc507a54f5ca13a3d50379972535"><br>图中水平面的坐标为 $x_{1}$，$x_{2}$而垂直坐标轴代表$f$。可以看出，只有当$x$与$l^{(1)}$重合时$f$才具有最大值。随着$x$的改变$f$值改变的速率受到$\sigma^2$的控制。</p><p>在下图中，当样本处于洋红色的点位置处，因为其离$l^{(1)}$更近，但是离$l^{(2)}$和$l^{(3)}$较远，因此$f_1$接近1，而$f_2$,$f_3$接近0。因此$h_θ(x)=θ_0+θ_1f_1+θ_2f_2+θ_1f_3>0$，因此预测$y=1$。同理可以求出，对于离$l^{(2)}$较近的绿色点，也预测$y=1$，但是对于蓝绿色的点，因为其离三个地标都较远，预测$y=0$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3d8959d0d12fe9914dc827d5a074b564.jpg" alt="3d8959d0d12fe9914dc827d5a074b564"><br>这样，图中红色的封闭曲线所表示的范围，便是我们依据一个单一的训练样本和我们选取的地标所得出的判定边界，在预测时，我们采用的特征不是训练样本本身的特征，而是通过核函数计算出的新特征$f_1,f_2,f_3$。</p><h3 id="核函数2"><a href="#核函数2" class="headerlink" title="核函数2"></a>核函数2</h3><p>参考视频: 12 - 5 - Kernels II (16 min).mkv</p><p>在上一节视频里，我们讨论了核函数这个想法，以及怎样利用它去实现支持向量机的一些新特性。在这一节视频中，我将补充一些缺失的细节，并简单的介绍一下怎么在实际中使用应用这些想法。</p><p>如何选择地标？</p><p>我们通常是根据训练集的数量选择地标的数量，即如果训练集中有$m$个样本，则我们选取$m$个地标，并且令:$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},.....,l^{(m)}=x^{(m)}$。这样做的好处在于：现在我们得到的新特征是建立在原有特征与训练集中所有其他特征之间距离的基础之上的，即：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/eca2571849cc36748c26c68708a7a5bd.png" alt="eca2571849cc36748c26c68708a7a5bd"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ea31af620b0a0132fe494ebb4a362465.png" alt="ea31af620b0a0132fe494ebb4a362465"><br>下面我们将核函数运用到支持向量机中，修改我们的支持向量机假设为：</p><p>• 给定$x$，计算新特征$f$，当$θ^Tf>=0$ 时，预测 $y=1$，否则反之。</p><p>相应地修改代价函数为：$\sum{_{j=1}^{n=m} }\theta _{j}^{2}={ {\theta}^{T} }\theta $，</p> $min C\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }cos { {t}_{1} }}( { {\theta }^{T} }{ {f}^{(i)} })+(1-{ {y}^{(i)} })cos { {t}_{0} }( { {\theta }^{T} }{ {f}^{(i)} })]+\frac{1}{2}\sum\limits_{j=1}^{n=m}{\theta _{j}^{2} }$<p>在具体实施过程中，我们还需要对最后的正则化项进行些微调整，在计算$\sum{_{j=1}^{n=m} }\theta _{j}^{2}={ {\theta}^{T} }\theta $时，我们用$θ^TMθ$代替$θ^Tθ$，其中$M$是根据我们选择的核函数而不同的一个矩阵。这样做的原因是为了简化计算。</p><p>理论上讲，我们也可以在逻辑回归中使用核函数，但是上面使用 $M$来简化计算的方法不适用与逻辑回归，因此计算将非常耗费时间。</p><p>在此，我们不介绍最小化支持向量机的代价函数的方法，你可以使用现有的软件包（如<strong>liblinear</strong>,<strong>libsvm</strong>等）。在使用这些软件包最小化我们的代价函数之前，我们通常需要编写核函数，并且如果我们使用高斯核函数，那么在使用之前进行特征缩放是非常必要的。</p><p>另外，支持向量机也可以不使用核函数，不使用核函数又称为<strong>线性核函数</strong>(<strong>linear kernel</strong>)，当我们不采用非常复杂的函数，或者我们的训练集特征非常多而样本非常少的时候，可以采用这种不带核函数的支持向量机。</p><p>下面是支持向量机的两个参数$C$和$\sigma$的影响：</p> $C=1/\lambda$ $C$ 较大时，相当于$\lambda$较小，可能会导致过拟合，高方差； $C$ 较小时，相当于$\lambda$较大，可能会导致低拟合，高偏差； $\sigma$较大时，可能会导致低方差，高偏差； $\sigma$较小时，可能会导致低偏差，高方差。<p>如果你看了本周的编程作业，你就能亲自实现这些想法，并亲眼看到这些效果。这就是利用核函数的支持向量机算法，希望这些关于偏差和方差的讨论，能给你一些对于算法结果预期的直观印象。</p><h3 id="使用支持向量机"><a href="#使用支持向量机" class="headerlink" title="使用支持向量机"></a>使用支持向量机</h3><p>参考视频: 12 - 6 - Using An SVM (21 min).mkv</p><p>目前为止，我们已经讨论了<strong>SVM</strong>比较抽象的层面，在这个视频中我将要讨论到为了运行或者运用<strong>SVM</strong>。你实际上所需要的一些东西：支持向量机算法，提出了一个特别优化的问题。但是就如在之前的视频中我简单提到的，我真的不建议你自己写软件来求解参数${ {\theta } }$，因此由于今天我们中的很少人，或者其实没有人考虑过自己写代码来转换矩阵，或求一个数的平方根等我们只是知道如何去调用库函数来实现这些功能。同样的，用以解决<strong>SVM</strong>最优化问题的软件很复杂，且已经有研究者做了很多年数值优化了。因此你提出好的软件库和好的软件包来做这样一些事儿。然后强烈建议使用高优化软件库中的一个，而不是尝试自己落实一些数据。有许多好的软件库，我正好用得最多的两个是<strong>liblinear</strong>和<strong>libsvm</strong>，但是真的有很多软件库可以用来做这件事儿。你可以连接许多你可能会用来编写学习算法的主要编程语言。</p><p>在高斯核函数之外我们还有其他一些选择，如：</p><p>多项式核函数（<strong>Polynomial Kerne</strong>l）</p><p>字符串核函数（<strong>String kernel</strong>）</p><p>卡方核函数（ <strong>chi-square kernel</strong>）</p><p>直方图交集核函数（<strong>histogram intersection kernel</strong>）</p><p>等等…</p><p>这些核函数的目标也都是根据训练集和地标之间的距离来构建新特征，这些核函数需要满足Mercer’s定理，才能被支持向量机的优化软件正确处理。</p><p>多类分类问题</p><p>假设我们利用之前介绍的一对多方法来解决一个多类分类问题。如果一共有$k$个类，则我们需要$k$个模型，以及$k$个参数向量${ {\theta } }$。我们同样也可以训练$k$个支持向量机来解决多类分类问题。但是大多数支持向量机软件包都有内置的多类分类功能，我们只要直接使用即可。</p><p>尽管你不去写你自己的<strong>SVM</strong>的优化软件，但是你也需要做几件事：</p><p>1、是提出参数$C$的选择。我们在之前的视频中讨论过误差/方差在这方面的性质。</p><p>2、你也需要选择内核参数或你想要使用的相似函数，其中一个选择是：我们选择不需要任何内核参数，没有内核参数的理念，也叫线性核函数。因此，如果有人说他使用了线性核的<strong>SVM</strong>（支持向量机），这就意味这他使用了不带有核函数的<strong>SVM</strong>（支持向量机）。</p><p>从逻辑回归模型，我们得到了支持向量机模型，在两者之间，我们应该如何选择呢？</p><p><strong>下面是一些普遍使用的准则：</strong></p> $n$为特征数，$m$为训练样本数。<p>(1)如果相较于$m$而言，$n$要大许多，即训练集数据量不够支持我们训练一个复杂的非线性模型，我们选用逻辑回归模型或者不带核函数的支持向量机。</p><p>(2)如果$n$较小，而且$m$大小中等，例如$n$在 1-1000 之间，而$m$在10-10000之间，使用高斯核函数的支持向量机。</p><p>(3)如果$n$较小，而$m$较大，例如$n$在1-1000之间，而$m$大于50000，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征，然后使用逻辑回归或不带核函数的支持向量机。</p><p>值得一提的是，神经网络在以上三种情况下都可能会有较好的表现，但是训练神经网络可能非常慢，选择支持向量机的原因主要在于它的代价函数是凸函数，不存在局部最小值。</p><p>今天的<strong>SVM</strong>包会工作得很好，但是它们仍然会有一些慢。当你有非常非常大的训练集，且用高斯核函数是在这种情况下，我经常会做的是尝试手动地创建，拥有更多的特征变量，然后用逻辑回归或者不带核函数的支持向量机。如果你看到这个幻灯片，看到了逻辑回归，或者不带核函数的支持向量机。在这个两个地方，我把它们放在一起是有原因的。原因是：逻辑回归和不带核函数的支持向量机它们都是非常相似的算法，不管是逻辑回归还是不带核函数的<strong>SVM</strong>，通常都会做相似的事情，并给出相似的结果。但是根据你实现的情况，其中一个可能会比另一个更加有效。但是在其中一个算法应用的地方，逻辑回归或不带核函数的<strong>SVM</strong>另一个也很有可能很有效。但是随着<strong>SVM</strong>的复杂度增加，当你使用不同的内核函数来学习复杂的非线性函数时，这个体系，你知道的，当你有多达1万（10,000）的样本时，也可能是5万（50,000），你的特征变量的数量这是相当大的。那是一个非常常见的体系，也许在这个体系里，不带核函数的支持向量机就会表现得相当突出。你可以做比这困难得多需要逻辑回归的事情。</p><p>最后，神经网络使用于什么时候呢？ 对于所有的这些问题，对于所有的这些不同体系一个设计得很好的神经网络也很有可能会非常有效。有一个缺点是，或者说是有时可能不会使用神经网络的原因是：对于许多这样的问题，神经网络训练起来可能会特别慢，但是如果你有一个非常好的<strong>SVM</strong>实现包，它可能会运行得比较快比神经网络快很多，尽管我们在此之前没有展示，但是事实证明，<strong>SVM</strong>具有的优化问题，是一种凸优化问题。因此，好的<strong>SVM</strong>优化软件包总是会找到全局最小值，或者接近它的值。对于<strong>SVM</strong>你不需要担心局部最优。在实际应用中，局部最优不是神经网络所需要解决的一个重大问题，所以这是你在使用<strong>SVM</strong>的时候不需要太去担心的一个问题。根据你的问题，神经网络可能会比<strong>SVM</strong>慢，尤其是在这样一个体系中，至于这里给出的参考，看上去有些模糊，如果你在考虑一些问题，这些参考会有一些模糊，但是我仍然不能完全确定，我是该用这个算法还是改用那个算法，这个没有太大关系，当我遇到机器学习问题的时候，有时它确实不清楚这是否是最好的算法，但是就如在之前的视频中看到的算法确实很重要。但是通常更加重要的是：你有多少数据，你有多熟练是否擅长做误差分析和排除学习算法，指出如何设定新的特征变量和找出其他能决定你学习算法的变量等方面，通常这些方面会比你使用逻辑回归还是<strong>SVM</strong>这方面更加重要。但是，已经说过了，<strong>SVM</strong>仍然被广泛认为是一种最强大的学习算法，这是一个体系，包含了什么时候一个有效的方法去学习复杂的非线性函数。因此，实际上与逻辑回归、神经网络、<strong>SVM</strong>一起使用这些方法来提高学习算法，我认为你会很好地建立很有技术的状态。（编者注：当时<strong>GPU</strong>计算比较慢，神经网络还不流行。）</p><p>机器学习系统对于一个宽泛的应用领域来说，这是另一个在你军械库里非常强大的工具，你可以把它应用到很多地方，如硅谷、在工业、学术等领域建立许多高性能的机器学习系统。</p><h2 id="聚类-Clustering"><a href="#聚类-Clustering" class="headerlink" title="聚类(Clustering)"></a>聚类(Clustering)</h2><h3 id="无监督学习：简介"><a href="#无监督学习：简介" class="headerlink" title="无监督学习：简介"></a>无监督学习：简介</h3><p>参考视频: 13 - 1 - Unsupervised Learning_ Introduction (3 min).mkv</p><p>在这个视频中，我将开始介绍聚类算法。这将是一个激动人心的时刻，因为这是我们学习的第一个非监督学习算法。我们将要让计算机学习无标签数据，而不是此前的标签数据。</p><p>那么，什么是非监督学习呢？在课程的一开始，我曾简单的介绍过非监督学习，然而，我们还是有必要将其与监督学习做一下比较。</p><p>在一个典型的监督学习中，我们有一个有标签的训练集，我们的目标是找到能够区分正样本和负样本的决策边界，在这里的监督学习中，我们有一系列标签，我们需要据此拟合一个假设函数。与此不同的是，在非监督学习中，我们的数据没有附带任何标签，我们拿到的数据就是这样的：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6709f5ca3cd2240d4e95dcc3d3e808d5.png" alt="6709f5ca3cd2240d4e95dcc3d3e808d5"><br>在这里我们有一系列点，却没有标签。因此，我们的训练集可以写成只有$x^{(1)}$,$x^{(2)}$…..一直到$x^{(m)}$。我们没有任何标签$y$。因此，图上画的这些点没有标签信息。也就是说，在非监督学习中，我们需要将一系列无标签的训练数据，输入到一个算法中，然后我们告诉这个算法，快去为我们找找这个数据的内在结构给定数据。我们可能需要某种算法帮助我们寻找一种结构。图上的数据看起来可以分成两个分开的点集（称为簇），一个能够找到我圈出的这些点集的算法，就被称为聚类算法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6709f5ca3cd2240d4e95dcc3d3e808d5.png" alt="6709f5ca3cd2240d4e95dcc3d3e808d5"><br>这将是我们介绍的第一个非监督学习算法。当然，此后我们还将提到其他类型的非监督学习算法，它们可以为我们找到其他类型的结构或者其他的一些模式，而不只是簇。</p><p>我们将先介绍聚类算法。此后，我们将陆续介绍其他算法。那么聚类算法一般用来做什么呢？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ff180f091e9bad9ac185248721437526.png" alt="ff180f091e9bad9ac185248721437526"><br>在这门课程的早些时候，我曾经列举过一些应用：比如市场分割。也许你在数据库中存储了许多客户的信息，而你希望将他们分成不同的客户群，这样你可以对不同类型的客户分别销售产品或者分别提供更适合的服务。社交网络分析：事实上有许多研究人员正在研究这样一些内容，他们关注一群人，关注社交网络，例如<strong>Facebook</strong>，<strong>Google+</strong>，或者是其他的一些信息，比如说：你经常跟哪些人联系，而这些人又经常给哪些人发邮件，由此找到关系密切的人群。因此，这可能需要另一个聚类算法，你希望用它发现社交网络中关系密切的朋友。我有一个朋友正在研究这个问题，他希望使用聚类算法来更好的组织计算机集群，或者更好的管理数据中心。因为如果你知道数据中心中，那些计算机经常协作工作。那么，你可以重新分配资源，重新布局网络。由此优化数据中心，优化数据通信。</p><p>最后，我实际上还在研究如何利用聚类算法了解星系的形成。然后用这个知识，了解一些天文学上的细节问题。好的，这就是聚类算法。这将是我们介绍的第一个非监督学习算法。在下一个视频中，我们将开始介绍一个具体的聚类算法。</p><h3 id="K-均值算法"><a href="#K-均值算法" class="headerlink" title="K-均值算法"></a>K-均值算法</h3><p>参考视频: 13 - 2 - K-Means Algorithm (13 min).mkv</p><p><strong>K-均值</strong>是最普及的聚类算法，算法接受一个未标记的数据集，然后将数据聚类成不同的组。</p><p><strong>K-均值</strong>是一个迭代算法，假设我们想要将数据聚类成n个组，其方法为:</p><p>首先选择$K$个随机的点，称为<strong>聚类中心</strong>（<strong>cluster centroids</strong>）；</p><p>对于数据集中的每一个数据，按照距离$K$个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。</p><p>计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置。</p><p>重复步骤2-4直至中心点不再变化。</p><p>下面是一个聚类示例：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ff1db77ec2e83b592bbe1c4153586120.jpg" alt="ff1db77ec2e83b592bbe1c4153586120"><br>迭代 1 次</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/acdb3ac44f1fe61ff3b5a77d5a4895a1.jpg" alt="acdb3ac44f1fe61ff3b5a77d5a4895a1"><br>迭代 3 次</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fe6dd7acf1a1eddcd09da362ecdf976f.jpg" alt="fe6dd7acf1a1eddcd09da362ecdf976f"><br>迭代 10 次</p><p>用$μ^1$,$μ^2$,…,$μ^k$ 来表示聚类中心，用$c^{(1)}$,$c^{(2)}$,…,$c^{(m)}$来存储与第$i$个实例数据最近的聚类中心的索引，<strong>K-均值</strong>算法的伪代码如下：</p><pre><code>Repeat {

for i = 1 to m

c(i) := index (form 1 to K) of cluster centroid closest to x(i)

for k = 1 to K

μk := average (mean) of points assigned to cluster k

}</code></pre><p>算法分为两个步骤，第一个<strong>for</strong>循环是赋值步骤，即：对于每一个样例$i$，计算其应该属于的类。第二个<strong>for</strong>循环是聚类中心的移动，即：对于每一个类$K$，重新计算该类的质心。</p><p><strong>K-均值</strong>算法也可以很便利地用于将数据分为许多不同组，即使在没有非常明显区分的组群的情况下也可以。下图所示的数据集包含身高和体重两项特征构成的，利用<strong>K-均值</strong>算法将数据分为三类，用于帮助确定将要生产的T-恤衫的三种尺寸。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fed50a4e482cf3aae38afeb368141a97.png" alt="fed50a4e482cf3aae38afeb368141a97"></p><h3 id="优化目标-1"><a href="#优化目标-1" class="headerlink" title="优化目标"></a>优化目标</h3><p>参考视频: 13 - 3 - Optimization Objective (7 min).mkv</p><p>K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和，因此<br>K-均值的代价函数（又称<strong>畸变函数</strong> <strong>Distortion function</strong>）为：</p> $$J(c^{(1)},...,c^{(m)},μ_1,...,μ_K)=\dfrac {1}{m}\sum^{m}_{i=1}\left\| X^{\left( i\right) }-\mu_{c^{(i)} }\right\| ^{2}$$<p>其中${ {\mu }_{ {{c}^{(i)} }} }$代表与${ {x}^{(i)} }$最近的聚类中心点。<br>我们的的优化目标便是找出使得代价函数最小的 $c^{(1)}$,$c^{(2)}$,…,$c^{(m)}$和$μ^1$,$μ^2$,…,$μ^k$：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8605f0826623078a156d30a7782dfc3c.png" alt="8605f0826623078a156d30a7782dfc3c"></p><p>回顾刚才给出的:<br><strong>K-均值</strong>迭代算法，我们知道，第一个循环是用于减小$c^{(i)}$引起的代价，而第二个循环则是用于减小${ {\mu }_{i} }$引起的代价。迭代的过程一定会是每一次迭代都在减小代价函数，不然便是出现了错误。</p><h3 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h3><p>参考视频: 13 - 4 - Random Initialization (8 min).mkv</p><p>在运行K-均值算法的之前，我们首先要随机初始化所有的聚类中心点，下面介绍怎样做：</p><ol><li><p>我们应该选择$K&lt;m$，即聚类中心点的个数要小于所有训练集实例的数量</p></li><li><p>随机选择$K$个训练实例，然后令$K$个聚类中心分别与这$K$个训练实例相等</p></li></ol><p><strong>K-均值</strong>的一个问题在于，它有可能会停留在一个局部最小值处，而这取决于初始化的情况。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d4d2c3edbdd8915f4e9d254d2a47d9c7.png" alt="d4d2c3edbdd8915f4e9d254d2a47d9c7"><br>为了解决这个问题，我们通常需要多次运行<strong>K-均值</strong>算法，每一次都重新进行随机初始化，最后再比较多次运行<strong>K-均值</strong>的结果，选择代价函数最小的结果。这种方法在$K$较小的时候（2–10）还是可行的，但是如果$K$较大，这么做也可能不会有明显地改善。</p><h3 id="选择聚类数"><a href="#选择聚类数" class="headerlink" title="选择聚类数"></a>选择聚类数</h3><p>参考视频: 13 - 5 - Choosing the Number of Clusters (8 min).mkv</p><p>没有所谓最好的选择聚类数的方法，通常是需要根据不同的问题，人工进行选择的。选择的时候思考我们运用<strong>K-均值</strong>算法聚类的动机是什么，然后选择能最好服务于该目的标聚类数。</p><p>当人们在讨论，选择聚类数目的方法时，有一个可能会谈及的方法叫作“肘部法则”。关于“肘部法则”，我们所需要做的是改变$K$值，也就是聚类类别数目的总数。我们用一个聚类来运行<strong>K均值</strong>聚类方法。这就意味着，所有的数据都会分到一个聚类里，然后计算成本函数或者计算畸变函数$J$。$K$代表聚类数字。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f3ddc6d751cab7aba7a6f8f44794e975.png" alt="f3ddc6d751cab7aba7a6f8f44794e975"><br>我们可能会得到一条类似于这样的曲线。像一个人的肘部。这就是“肘部法则”所做的，让我们来看这样一个图，看起来就好像有一个很清楚的肘在那儿。好像人的手臂，如果你伸出你的胳膊，那么这就是你的肩关节、肘关节、手。这就是“肘部法则”。你会发现这种模式，它的畸变值会迅速下降，从1到2，从2到3之后，你会在3的时候达到一个肘点。在此之后，畸变值就下降的非常慢，看起来就像使用3个聚类来进行聚类是正确的，这是因为那个点是曲线的肘点，畸变值下降得很快，$K=3$之后就下降得很慢，那么我们就选$K=3$。当你应用“肘部法则”的时候，如果你得到了一个像上面这样的图，那么这将是一种用来选择聚类个数的合理方法。</p><p>例如，我们的 T-恤制造例子中，我们要将用户按照身材聚类，我们可以分成3个尺寸:$S,M,L$，也可以分成5个尺寸$XS,S,M,L,XL$，这样的选择是建立在回答“聚类后我们制造的T-恤是否能较好地适合我们的客户”这个问题的基础上作出的。</p><p><strong>聚类参考资料：</strong></p><p>1.相似度/距离计算方法总结</p><p>(1). 闵可夫斯基距离<strong>Minkowski</strong>/（其中欧式距离：$p=2$)</p> $dist(X,Y)={ {\left( { {\sum\limits_{i=1}^{n}{\left| { {x}_{i} }-{ {y}_{i} } \right|} }^{p} } \right)}^{\frac{1}{p} }}$<p>(2). 杰卡德相似系数(<strong>Jaccard</strong>)：</p> $J(A,B)=\frac{\left| A\cap B \right|}{\left|A\cup B \right|}$<p>(3). 余弦相似度(<strong>cosine similarity</strong>)：</p> $n$维向量$x$和$y$的夹角记做$\theta$，根据余弦定理，其余弦值为： $cos (\theta )=\frac{ {{x}^{T} }y}{\left|x \right|\cdot \left| y \right|}=\frac{\sum\limits_{i=1}^{n}{ {{x}_{i} }{ {y}_{i} }} }{\sqrt{\sum\limits_{i=1}^{n}{ {{x}_{i} }^{2} }}\sqrt{\sum\limits_{i=1}^{n}{ {{y}_{i} }^{2} }} }$<p>(4). Pearson皮尔逊相关系数：</p> ${ {\rho }_{XY} }=\frac{\operatorname{cov}(X,Y)}{ {{\sigma }_{X} }{ {\sigma }_{Y} }}=\frac{E[(X-{ {\mu }_{X} })(Y-{ {\mu }_{Y} })]}{ {{\sigma }_{X} }{ {\sigma }_{Y} }}=\frac{\sum\limits_{i=1}^{n}{(x-{ {\mu }_{X} })(y-{ {\mu }_{Y} })} }{\sqrt{\sum\limits_{i=1}^{n}{ {{(x-{ {\mu }_{X} })}^{2} }} }\sqrt{\sum\limits_{i=1}^{n}{ {{(y-{ {\mu }_{Y} })}^{2} }} }}$<p>Pearson相关系数即将$x$、$y$坐标向量各自平移到原点后的夹角余弦。</p><p>2.聚类的衡量指标</p><p>(1). 均一性：$p$</p><p>类似于精确率，一个簇中只包含一个类别的样本，则满足均一性。其实也可以认为就是正确率(每个 聚簇中正确分类的样本数占该聚簇总样本数的比例和)</p><p>(2). 完整性：$r$</p><p>类似于召回率，同类别样本被归类到相同簇中，则满足完整性;每个聚簇中正确分类的样本数占该<br>类型的总样本数比例的和</p><p>(3). <strong>V-measure</strong>:</p><p>均一性和完整性的加权平均</p><p>$V = \frac{(1+\beta^2)<em>pr}{\beta^2</em>p+r}$</p><p>(4). 轮廓系数</p><p>样本$i$的轮廓系数：$s(i)$</p><p>簇内不相似度:计算样本$i$到同簇其它样本的平均距离为$a(i)$，应尽可能小。</p><p>簇间不相似度:计算样本$i$到其它簇$C_j$的所有样本的平均距离$b_{ij}$，应尽可能大。</p><p>轮廓系数：$s(i)$值越接近1表示样本$i$聚类越合理，越接近-1，表示样本$i$应该分类到 另外的簇中，近似为0，表示样本$i$应该在边界上;所有样本的$s(i)$的均值被成为聚类结果的轮廓系数。</p> $s(i) = \frac{b(i)-a(i)}{max\{a(i),b(i)\} }$<p>(5). <strong>ARI</strong></p><p>数据集$S$共有$N$个元素， 两个聚类结果分别是：</p> $X=\{ {{X}_{1} },{ {X}_{2} },...,{ {X}_{r} }\},Y=\{ {{Y}_{1} },{ {Y}_{2} },...,{ {Y}_{s} }\}$ $X$和$Y$的元素个数为： $a=\{ {{a}_{1} },{ {a}_{2} },...,{ {a}_{r} }\},b=\{ {{b}_{1} },{ {b}_{2} },...,{ {b}_{s} }\}$<p><img src="/Ari11.png" alt="ri1"></p><p>记：${ {n}_{ij} }=\left| { {X}_{i} }\cap { {Y}_{i} } \right|$</p> $ARI=\frac{\sum\limits_{i,j}{C_{ {{n}_{ij} }}^{2} }-\left[ \left( \sum\limits_{i}{C_{ {{a}_{i} }}^{2} } \right)\cdot \left( \sum\limits_{i}{C_{ {{b}_{i} }}^{2} } \right) \right]/C_{n}^{2} }{\frac{1}{2}\left[ \left( \sum\limits_{i}{C_{ {{a}_{i} }}^{2} } \right)+\left( \sum\limits_{i}{C_{ {{b}_{i} }}^{2} } \right) \right]-\left[ \left( \sum\limits_{i}{C_{ {{a}_{i} }}^{2} } \right)\cdot \left( \sum\limits_{i}{C_{ {{b}_{i} }}^{2} } \right) \right]/C_{n}^{2} }$<h2 id="降维-Dimensionality-Reduction"><a href="#降维-Dimensionality-Reduction" class="headerlink" title="降维(Dimensionality Reduction)"></a>降维(Dimensionality Reduction)</h2><h3 id="动机一：数据压缩"><a href="#动机一：数据压缩" class="headerlink" title="动机一：数据压缩"></a>动机一：数据压缩</h3><p>参考视频: 14 - 1 - Motivation I_ Data Compression (10 min).mkv</p><p>这个视频，我想开始谈论第二种类型的无监督学习问题，称为降维。有几个不同的的原因使你可能想要做降维。一是数据压缩，后面我们会看了一些视频后，数据压缩不仅允许我们压缩数据，因而使用较少的计算机内存或磁盘空间，但它也让我们加快我们的学习算法。</p><p>但首先，让我们谈论降维是什么。作为一种生动的例子，我们收集的数据集，有许多，许多特征，我绘制两个在这里。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2373072a74d97a9f606981ffaf1dd53b.png" alt="2373072a74d97a9f606981ffaf1dd53b"><br>假设我们未知两个的特征：$x_1$:长度：用厘米表示；$x_2$：是用英寸表示同一物体的长度。</p><p>所以，这给了我们高度冗余表示，也许不是两个分开的特征$x_1$和$x_2$，这两个基本的长度度量，也许我们想要做的是减少数据到一维，只有一个数测量这个长度。这个例子似乎有点做作，这里厘米英寸的例子实际上不是那么不切实际的，两者并没有什么不同。</p><p>将数据从二维降至一维：<br>假使我们要采用两种不同的仪器来测量一些东西的尺寸，其中一个仪器测量结果的单位是英寸，另一个仪器测量的结果是厘米，我们希望将测量的结果作为我们机器学习的特征。现在的问题的是，两种仪器对同一个东西测量的结果不完全相等（由于误差、精度等），而将两者都作为特征有些重复，因而，我们希望将这个二维的数据降至一维。</p><p>从这件事情我看到的东西发生在工业上的事。如果你有几百个或成千上万的特征，它是它这往往容易失去你需要的特征。有时可能有几个不同的工程团队，也许一个工程队给你二百个特征，第二工程队给你另外三百个的特征，第三工程队给你五百个特征，一千多个特征都在一起，它实际上会变得非常困难，去跟踪你知道的那些特征，你从那些工程队得到的。其实不想有高度冗余的特征一样。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2c95b316a3c61cf076ef132d3d50b51c.png" alt="2c95b316a3c61cf076ef132d3d50b51c"><br>多年我一直在研究直升飞机自动驾驶。诸如此类。如果你想测量——如果你想做，你知道，做一个调查或做这些不同飞行员的测试——你可能有一个特征：$x_1$，这也许是他们的技能（直升机飞行员），也许$x_2$可能是飞行员的爱好。这是表示他们是否喜欢飞行，也许这两个特征将高度相关。你真正关心的可能是这条红线的方向，不同的特征，决定飞行员的能力。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8274f0c29314742e9b4f15071ea7624a.png" alt="8274f0c29314742e9b4f15071ea7624a"><br>将数据从三维降至二维：<br>这个例子中我们要将一个三维的特征向量降至一个二维的特征向量。过程是与上面类似的，我们将三维向量投射到一个二维的平面上，强迫使得所有的数据都在同一个平面上，降至二维的特征向量。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8274f0c29314742e9b4f15071ea7624a.png" alt="8274f0c29314742e9b4f15071ea7624a"><br>这样的处理过程可以被用于把任何维度的数据降到任何想要的维度，例如将1000维的特征降至100维。</p><p>正如我们所看到的，最后，这将使我们能够使我们的一些学习算法运行也较晚，但我们会在以后的视频提到它。</p><h3 id="动机二：数据可视化"><a href="#动机二：数据可视化" class="headerlink" title="动机二：数据可视化"></a>动机二：数据可视化</h3><p>参考视频: 14 - 2 - Motivation II_ Visualization (6 min).mkv</p><p>在许多及其学习问题中，如果我们能将数据可视化，我们便能寻找到一个更好的解决方案，降维可以帮助我们。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/789d90327121d3391735087b9276db2a.png" alt="789d90327121d3391735087b9276db2a"><br>假使我们有有关于许多不同国家的数据，每一个特征向量都有50个特征（如<strong>GDP</strong>，人均<strong>GDP</strong>，平均寿命等）。如果要将这个50维的数据可视化是不可能的。使用降维的方法将其降至2维，我们便可以将其可视化了。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/789d90327121d3391735087b9276db2a.png" alt="789d90327121d3391735087b9276db2a"><br>这样做的问题在于，降维的算法只负责减少维数，新产生的特征的意义就必须由我们自己去发现了。</p><h3 id="主成分分析问题"><a href="#主成分分析问题" class="headerlink" title="主成分分析问题"></a>主成分分析问题</h3><p>参考视频: 14 - 3 - Principal Component Analysis Problem Formulation (9 min). mkv</p><p>主成分分析(<strong>PCA</strong>)是最常见的降维算法。</p><p>在<strong>PCA</strong>中，我们要做的是找到一个方向向量（<strong>Vector direction</strong>），当我们把所有的数据都投射到该向量上时，我们希望投射平均均方误差能尽可能地小。方向向量是一个经过原点的向量，而投射误差是从特征向量向该方向向量作垂线的长度。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a93213474b35ce393320428996aeecd9.jpg" alt="a93213474b35ce393320428996aeecd9"><br>下面给出主成分分析问题的描述：</p><p>问题是要将$n$维数据降至$k$维，目标是找到向量$u^{(1)}$,$u^{(2)}$,…,$u^{(k)}$使得总的投射误差最小。主成分分析与线性回顾的比较：</p><p>主成分分析与线性回归是两种不同的算法。主成分分析最小化的是投射误差（<strong>Projected Error</strong>），而线性回归尝试的是最小化预测误差。线性回归的目的是预测结果，而主成分分析不作任何预测。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7e1389918ab9358d1432d20ed20f8142.png" alt="7e1389918ab9358d1432d20ed20f8142"><br>上图中，左边的是线性回归的误差（垂直于横轴投影），右边则是主要成分分析的误差（垂直于红线投影）。</p><p><strong>PCA</strong>将$n$个特征降维到$k$个，可以用来进行数据压缩，如果100维的向量最后可以用10维来表示，那么压缩率为90%。同样图像处理领域的<strong>KL变换</strong>使用<strong>PCA</strong>做图像压缩。但<strong>PCA</strong> 要保证降维后，还要保证数据的特性损失最小。</p><p><strong>PCA</strong>技术的一大好处是对数据进行降维的处理。我们可以对新求出的“主元”向量的重要性进行排序，根据需要取前面最重要的部分，将后面的维数省去，可以达到降维从而简化模型或是对数据进行压缩的效果。同时最大程度的保持了原有数据的信息。</p><p><strong>PCA</strong>技术的一个很大的优点是，它是完全无参数限制的。在<strong>PCA</strong>的计算过程中完全不需要人为的设定参数或是根据任何经验模型对计算进行干预，最后的结果只与数据相关，与用户是独立的。</p><p>但是，这一点同时也可以看作是缺点。如果用户对观测对象有一定的先验知识，掌握了数据的一些特征，却无法通过参数化等方法对处理过程进行干预，可能会得不到预期的效果，效率也不高。</p><h3 id="主成分分析算法"><a href="#主成分分析算法" class="headerlink" title="主成分分析算法"></a>主成分分析算法</h3><p>参考视频: 14 - 4 - Principal Component Analysis Algorithm (15 min).mkv</p><p><strong>PCA</strong> 减少$n$维到$k$维：</p><p>第一步是均值归一化。我们需要计算出所有特征的均值，然后令 $x_j= x_j-μ_j$。如果特征是在不同的数量级上，我们还需要将其除以标准差 $σ^2$。</p><p>第二步是计算<strong>协方差矩阵</strong>（<strong>covariance matrix</strong>）$Σ$：</p> $\sum=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}$<p>第三步是计算协方差矩阵$Σ$的<strong>特征向量</strong>（<strong>eigenvectors</strong>）:</p><p>在 <strong>Octave</strong> 里我们可以利用<strong>奇异值分解</strong>（<strong>singular value decomposition</strong>）来求解，<code>[U, S, V]= svd(sigma)</code>。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0918b38594709705723ed34bb74928ba.png" alt="0918b38594709705723ed34bb74928ba"></p> $$Sigma=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}$$<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/01e1c4a2f29a626b5980a27fc7d6a693.png" alt="01e1c4a2f29a626b5980a27fc7d6a693"><br>对于一个 $n×n$维度的矩阵，上式中的$U$是一个具有与数据之间最小投射误差的方向向量构成的矩阵。如果我们希望将数据从$n$维降至$k$维，我们只需要从$U$中选取前$k$个向量，获得一个$n×k$维度的矩阵，我们用$U_{reduce}$表示，然后通过如下计算获得要求的新特征向量$z^{(i)}$:<br>$$z^{(i)}=U^{T}_{reduce}*x^{(i)}$$</p><p>其中$x$是$n×1$维的，因此结果为$k×1$维度。注，我们不对方差特征进行处理。</p><h3 id="选择主成分的数量"><a href="#选择主成分的数量" class="headerlink" title="选择主成分的数量"></a>选择主成分的数量</h3><p>参考视频: 14 - 5 - Choosing The Number Of Principal Components (13 min).mkv</p><p>主要成分分析是减少投射的平均均方误差：</p><p>训练集的方差为：$\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }\right\| ^{2}$</p><p>我们希望在平均均方误差与训练集方差的比例尽可能小的情况下选择尽可能小的$k$值。</p><p>如果我们希望这个比例小于1%，就意味着原本数据的偏差有99%都保留下来了，如果我们选择保留95%的偏差，便能非常显著地降低模型中特征的维度了。</p><p>我们可以先令$k=1$，然后进行主要成分分析，获得$U_{reduce}$和$z$，然后计算比例是否小于1%。如果不是的话再令$k=2$，如此类推，直到找到可以使得比例小于1%的最小$k$ 值（原因是各个特征之间通常情况存在某种相关性）。</p><p>还有一些更好的方式来选择$k$，当我们在<strong>Octave</strong>中调用“<strong>svd</strong>”函数的时候，我们获得三个参数：<code>[U, S, V] = svd(sigma)</code>。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a4477d787f876ae4e72cb416a2cb0b8a.jpg" alt="a4477d787f876ae4e72cb416a2cb0b8a"><br>其中的$S$是一个$n×n$的矩阵，只有对角线上有值，而其它单元都是0，我们可以使用这个矩阵来计算平均均方误差与训练集方差的比例：</p> $$\dfrac {\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }-x^{\left( i\right) }_{approx}\right\| ^{2} }{\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{(i)}\right\| ^{2} }=1-\dfrac {\Sigma^{k}_{i=1}S_{ii} }{\Sigma^{m}_{i=1}S_{ii} }\leq 1\%$$<p>也就是：$$\frac {\Sigma^{k}_{i=1}s_{ii} }{\Sigma^{n}_{i=1}s_{ii} }\geq0.99$$</p><p>在压缩过数据后，我们可以采用如下方法来近似地获得原有的特征：$$x^{\left( i\right) }_{approx}=U_{reduce}z^{(i)}$$</p><h3 id="重建的压缩表示"><a href="#重建的压缩表示" class="headerlink" title="重建的压缩表示"></a>重建的压缩表示</h3><p>参考视频: 14 - 6 - Reconstruction from Compressed Representation (4 min).mkv</p><p>在以前的视频中，我谈论<strong>PCA</strong>作为压缩算法。在那里你可能需要把1000维的数据压缩100维特征，或具有三维数据压缩到一二维表示。所以，如果这是一个压缩算法，应该能回到这个压缩表示，回到你原有的高维数据的一种近似。</p><p>所以，给定的$z^{(i)}$，这可能100维，怎么回到你原来的表示$x^{(i)}$，这可能是1000维的数组？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0a4edcb9c0d0a3812a50b3e95ef3912a.png" alt="0a4edcb9c0d0a3812a50b3e95ef3912a"><br><strong>PCA</strong>算法，我们可能有一个这样的样本。如图中样本$x^{(1)}$,$x^{(2)}$。我们做的是，我们把这些样本投射到图中这个一维平面。然后现在我们需要只使用一个实数，比如$z^{(1)}$，指定这些点的位置后他们被投射到这一个三维曲面。给定一个点$z^{(1)}$，我们怎么能回去这个原始的二维空间呢？$x$为2维，$z$为1维，$z=U^{T}_{reduce}x$，相反的方程为：$x_{appox}=U_{reduce}\cdot z$,$x_{appox}\approx x$。如图：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/66544d8fa1c1639d80948006f7f4a8ff.png" alt="66544d8fa1c1639d80948006f7f4a8ff"><br>如你所知，这是一个漂亮的与原始数据相当相似。所以，这就是你从低维表示$z$回到未压缩的表示。我们得到的数据的一个之间你的原始数据 $x$，我们也把这个过程称为重建原始数据。</p><p>当我们认为试图重建从压缩表示 $x$ 的初始值。所以，给定未标记的数据集，您现在知道如何应用<strong>PCA</strong>，你的带高维特征$x$和映射到这的低维表示$z$。这个视频，希望你现在也知道如何采取这些低维表示$z$，映射到备份到一个近似你原有的高维数据。</p><p>现在你知道如何实施应用<strong>PCA</strong>，我们将要做的事是谈论一些技术在实际使用<strong>PCA</strong>很好，特别是，在接下来的视频中，我想谈一谈关于如何选择$k$。</p><h3 id="主成分分析法的应用建议"><a href="#主成分分析法的应用建议" class="headerlink" title="主成分分析法的应用建议"></a>主成分分析法的应用建议</h3><p>参考视频: 14 - 7 - Advice for Applying PCA (13 min).mkv</p><p>假使我们正在针对一张 100×100像素的图片进行某个计算机视觉的机器学习，即总共有10000 个特征。</p><ol><li><p>第一步是运用主要成分分析将数据压缩至1000个特征</p></li><li><p>然后对训练集运行学习算法</p></li><li><p>在预测时，采用之前学习而来的$U_{reduce}$将输入的特征$x$转换成特征向量$z$，然后再进行预测</p></li></ol><p>注：如果我们有交叉验证集合测试集，也采用对训练集学习而来的$U_{reduce}$。</p><p>错误的主要成分分析情况：一个常见错误使用主要成分分析的情况是，将其用于减少过拟合（减少了特征的数量）。这样做非常不好，不如尝试正则化处理。原因在于主要成分分析只是近似地丢弃掉一些特征，它并不考虑任何与结果变量有关的信息，因此可能会丢失非常重要的特征。然而当我们进行正则化处理时，会考虑到结果变量，不会丢掉重要的数据。</p><p>另一个常见的错误是，默认地将主要成分分析作为学习过程中的一部分，这虽然很多时候有效果，最好还是从所有原始特征开始，只在有必要的时候（算法运行太慢或者占用太多内存）才考虑采用主要成分分析。</p><h2 id="异常检测-Anomaly-Detection"><a href="#异常检测-Anomaly-Detection" class="headerlink" title="异常检测(Anomaly Detection)"></a>异常检测(Anomaly Detection)</h2><h3 id="问题的动机"><a href="#问题的动机" class="headerlink" title="问题的动机"></a>问题的动机</h3><p>参考文档: 15 - 1 - Problem Motivation (8 min).mkv</p><p>在接下来的一系列视频中，我将向大家介绍异常检测(<strong>Anomaly detection</strong>)问题。这是机器学习算法的一个常见应用。这种算法的一个有趣之处在于：它虽然主要用于非监督学习问题，但从某些角度看，它又类似于一些监督学习问题。</p><p>什么是异常检测呢？为了解释这个概念，让我举一个例子吧：</p><p>假想你是一个飞机引擎制造商，当你生产的飞机引擎从生产线上流出时，你需要进行<strong>QA</strong>(质量控制测试)，而作为这个测试的一部分，你测量了飞机引擎的一些特征变量，比如引擎运转时产生的热量，或者引擎的振动等等。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/93d6dfe7e5cb8a46923c178171889747.png" alt="93d6dfe7e5cb8a46923c178171889747"><br>这样一来，你就有了一个数据集，从$x^{(1)}$到$x^{(m)}$，如果你生产了$m$个引擎的话，你将这些数据绘制成图表，看起来就是这个样子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fe4472adbf6ddd9d9b51d698cc750b68.png" alt="fe4472adbf6ddd9d9b51d698cc750b68"><br>这里的每个点、每个叉，都是你的无标签数据。这样，异常检测问题可以定义如下：我们假设后来有一天，你有一个新的飞机引擎从生产线上流出，而你的新飞机引擎有特征变量$x_{test}$。所谓的异常检测问题就是：我们希望知道这个新的飞机引擎是否有某种异常，或者说，我们希望判断这个引擎是否需要进一步测试。因为，如果它看起来像一个正常的引擎，那么我们可以直接将它运送到客户那里，而不需要进一步的测试。</p><p>给定数据集 $x^{(1)},x^{(2)},..,x^{(m)}$，我们假使数据集是正常的，我们希望知道新的数据 $x_{test}$ 是不是异常的，即这个测试数据不属于该组数据的几率如何。我们所构建的模型应该能根据该测试数据的位置告诉我们其属于一组数据的可能性 $p(x)$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/65afdea865d50cba12d4f7674d599de5.png" alt="65afdea865d50cba12d4f7674d599de5"><br>上图中，在蓝色圈内的数据属于该组数据的可能性较高，而越是偏远的数据，其属于该组数据的可能性就越低。</p><p>这种方法称为密度估计，表达如下：</p><p>$$<br>if \quad p(x)<br>\begin{cases}<br>&lt; \varepsilon &amp; anomaly \</p><blockquote><p>=\varepsilon &amp; normal<br>\end{cases}<br>$$</p></blockquote><p>欺诈检测：</p> $x^{(i)} = {用户的第i个活动特征}$<p>模型$p(x)$ 为我们其属于一组数据的可能性，通过$p(x) &lt; \varepsilon$检测非正常用户。</p><p>异常检测主要用来识别欺骗。例如在线采集而来的有关用户的数据，一个特征向量中可能会包含如：用户多久登录一次，访问过的页面，在论坛发布的帖子数量，甚至是打字速度等。尝试根据这些特征构建一个模型，可以用这个模型来识别那些不符合该模式的用户。</p><p>再一个例子是检测一个数据中心，特征可能包含：内存使用情况，被访问的磁盘数量，<strong>CPU</strong>的负载，网络的通信量等。根据这些特征可以构建一个模型，用来判断某些计算机是不是有可能出错了。</p><h3 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h3><p>参考视频: 15 - 2 - Gaussian Distribution (10 min).mkv</p><p>在这个视频中，我将介绍高斯分布，也称为正态分布。回顾高斯分布的基本知识。</p><p>通常如果我们认为变量 $x$ 符合高斯分布 $x \sim N(\mu, \sigma^2)$则其概率密度函数为：</p> $p(x,\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$<p>我们可以利用已有的数据来预测总体中的$μ$和$σ^2$的计算方法如下：</p> $\mu=\frac{1}{m}\sum\limits_{i=1}^{m}x^{(i)}$ $\sigma^2=\frac{1}{m}\sum\limits_{i=1}^{m}(x^{(i)}-\mu)^2$<p>高斯分布样例：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fcb35433507a56631dde2b4e543743ee.png" alt="fcb35433507a56631dde2b4e543743ee"><br>注：机器学习中对于方差我们通常只除以$m$而非统计学中的$(m-1)$。这里顺便提一下，在实际使用中，到底是选择使用$1/m$还是$1/(m-1)$其实区别很小，只要你有一个还算大的训练集，在机器学习领域大部分人更习惯使用$1/m$这个版本的公式。这两个版本的公式在理论特性和数学特性上稍有不同，但是在实际使用中，他们的区别甚小，几乎可以忽略不计。</p><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>参考视频: 15 - 3 - Algorithm (12 min).mkv</p><p>在本节视频中，我将应用高斯分布开发异常检测算法。</p><p>异常检测算法：</p><p>对于给定的数据集 $x^{(1)},x^{(2)},...,x^{(m)}$，我们要针对每一个特征计算 $\mu$ 和 $\sigma^2$ 的估计值。</p> $\mu_j=\frac{1}{m}\sum\limits_{i=1}^{m}x_j^{(i)}$ $\sigma_j^2=\frac{1}{m}\sum\limits_{i=1}^m(x_j^{(i)}-\mu_j)^2$<p>一旦我们获得了平均值和方差的估计值，给定新的一个训练实例，根据模型计算 $p(x)$：</p> $p(x)=\prod\limits_{j=1}^np(x_j;\mu_j,\sigma_j^2)=\prod\limits_{j=1}^1\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$<p>当$p(x) &lt; \varepsilon$时，为异常。</p><p>下图是一个由两个特征的训练集，以及特征的分布情况：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ba47767a11ba39a23898b9f1a5a57cc5.png" alt="ba47767a11ba39a23898b9f1a5a57cc5"><br>下面的三维图表表示的是密度估计函数，$z$轴为根据两个特征的值所估计$p(x)$值：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/82b90f56570c05966da116c3afe6fc91.jpg" alt="82b90f56570c05966da116c3afe6fc91"><br>我们选择一个$\varepsilon$，将$p(x) = \varepsilon$作为我们的判定边界，当$p(x) > \varepsilon$时预测数据为正常数据，否则为异常。</p><p>在这段视频中，我们介绍了如何拟合$p(x)$，也就是 $x$的概率值，以开发出一种异常检测算法。同时，在这节课中，我们也给出了通过给出的数据集拟合参数，进行参数估计，得到参数 $\mu$ 和 $\sigma$，然后检测新的样本，确定新样本是否是异常。</p><p>在接下来的课程中，我们将深入研究这一算法，同时更深入地介绍，怎样让算法工作地更加有效。</p><h3 id="开发和评价一个异常检测系统"><a href="#开发和评价一个异常检测系统" class="headerlink" title="开发和评价一个异常检测系统"></a>开发和评价一个异常检测系统</h3><p>参考视频: 15 - 4 - Developing and Evaluating an Anomaly Detection System (13 min). mkv</p><p>异常检测算法是一个非监督学习算法，意味着我们无法根据结果变量 $ y$ 的值来告诉我们数据是否真的是异常的。我们需要另一种方法来帮助检验算法是否有效。当我们开发一个异常检测系统时，我们从带标记（异常或正常）的数据着手，我们从其中选择一部分正常数据用于构建训练集，然后用剩下的正常数据和异常数据混合的数据构成交叉检验集和测试集。</p><p>例如：我们有10000台正常引擎的数据，有20台异常引擎的数据。 我们这样分配数据：</p><p>6000台正常引擎的数据作为训练集</p><p>2000台正常引擎和10台异常引擎的数据作为交叉检验集</p><p>2000台正常引擎和10台异常引擎的数据作为测试集</p><p>具体的评价方法如下：</p><ol><li><p>根据测试集数据，我们估计特征的平均值和方差并构建$p(x)$函数</p></li><li><p>对交叉检验集，我们尝试使用不同的$\varepsilon$值作为阀值，并预测数据是否异常，根据$F1$值或者查准率与查全率的比例来选择 $\varepsilon$</p></li><li><p>选出 $\varepsilon$ 后，针对测试集进行预测，计算异常检验系统的$F1$值，或者查准率与查全率之比</p></li></ol><h3 id="异常检测与监督学习对比"><a href="#异常检测与监督学习对比" class="headerlink" title="异常检测与监督学习对比"></a>异常检测与监督学习对比</h3><p>参考视频: 15 - 5 - Anomaly Detection vs. Supervised Learning (8 min).mkv</p><p>之前我们构建的异常检测系统也使用了带标记的数据，与监督学习有些相似，下面的对比有助于选择采用监督学习还是异常检测：</p><p>两者比较：</p><table><thead><tr><th>异常检测</th><th>监督学习</th></tr></thead><tbody><tr><td>非常少量的正向类（异常数据 $y=1$）, 大量的负向类（$y=0$）</td><td>同时有大量的正向类和负向类</td></tr><tr><td>许多不同种类的异常，非常难。根据非常 少量的正向类数据来训练算法。</td><td>有足够多的正向类实例，足够用于训练 算法，未来遇到的正向类实例可能与训练集中的非常近似。</td></tr><tr><td>未来遇到的异常可能与已掌握的异常、非常的不同。</td><td></td></tr><tr><td>例如： 欺诈行为检测 生产（例如飞机引擎）检测数据中心的计算机运行状况</td><td>例如：邮件过滤器 天气预报 肿瘤分类</td></tr></tbody></table><p>希望这节课能让你明白一个学习问题的什么样的特征，能让你把这个问题当做是一个异常检测，或者是一个监督学习的问题。另外，对于很多技术公司可能会遇到的一些问题，通常来说，正样本的数量很少，甚至有时候是0，也就是说，出现了太多没见过的不同的异常类型，那么对于这些问题，通常应该使用的算法就是异常检测算法。</p><h3 id="选择特征"><a href="#选择特征" class="headerlink" title="选择特征"></a>选择特征</h3><p>参考视频: 15 - 6 - Choosing What Features to Use (12 min).mkv</p><p>对于异常检测算法，我们使用的特征是至关重要的，下面谈谈如何选择特征：</p><p>异常检测假设特征符合高斯分布，如果数据的分布不是高斯分布，异常检测算法也能够工作，但是最好还是将数据转换成高斯分布，例如使用对数函数：$x= log(x+c)$，其中 $c$ 为非负常数； 或者 $x=x^c$，$c$为 0-1 之间的一个分数，等方法。(编者注：在<strong>python</strong>中，通常用<code>np.log1p()</code>函数，$log1p$就是 $log(x+1)$，可以避免出现负数结果，反向函数就是<code>np.expm1()</code>)</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0990d6b7a5ab3c0036f42083fe2718c6.jpg" alt="0990d6b7a5ab3c0036f42083fe2718c6"><br>误差分析：</p><p>一个常见的问题是一些异常的数据可能也会有较高的$p(x)$值，因而被算法认为是正常的。这种情况下误差分析能够帮助我们，我们可以分析那些被算法错误预测为正常的数据，观察能否找出一些问题。我们可能能从问题中发现我们需要增加一些新的特征，增加这些新特征后获得的新算法能够帮助我们更好地进行异常检测。</p><p>异常检测误差分析：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f406bc738e5e032be79e52b6facfa48e.png" alt="f406bc738e5e032be79e52b6facfa48e"><br>我们通常可以通过将一些相关的特征进行组合，来获得一些新的更好的特征（异常数据的该特征值异常地大或小），例如，在检测数据中心的计算机状况的例子中，我们可以用<strong>CPU</strong>负载与网络通信量的比例作为一个新的特征，如果该值异常地大，便有可能意味着该服务器是陷入了一些问题中。</p><p>在这段视频中，我们介绍了如何选择特征，以及对特征进行一些小小的转换，让数据更像正态分布，然后再把数据输入异常检测算法。同时也介绍了建立特征时，进行的误差分析方法，来捕捉各种异常的可能。希望你通过这些方法，能够了解如何选择好的特征变量，从而帮助你的异常检测算法，捕捉到各种不同的异常情况。</p><h3 id="多元高斯分布（选修）"><a href="#多元高斯分布（选修）" class="headerlink" title="多元高斯分布（选修）"></a>多元高斯分布（选修）</h3><p>参考视频: 15 - 7 - Multivariate Gaussian Distribution (Optional) (14 min).mkv</p><p>假使我们有两个相关的特征，而且这两个特征的值域范围比较宽，这种情况下，一般的高斯分布模型可能不能很好地识别异常数据。其原因在于，一般的高斯分布模型尝试的是去同时抓住两个特征的偏差，因此创造出一个比较大的判定边界。</p><p>下图中是两个相关特征，洋红色的线（根据ε的不同其范围可大可小）是一般的高斯分布模型获得的判定边界，很明显绿色的<strong>X</strong>所代表的数据点很可能是异常值，但是其$p(x)$值却仍然在正常范围内。多元高斯分布将创建像图中蓝色曲线所示的判定边界。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/598db991a7c930c9021cec5f6ab9beb9.png" alt="598db991a7c930c9021cec5f6ab9beb9"><br>在一般的高斯分布模型中，我们计算 $p(x)$ 的方法是：<br>通过分别计算每个特征对应的几率然后将其累乘起来，在多元高斯分布模型中，我们将构建特征的协方差矩阵，用所有的特征一起来计算 $p(x)$。</p><p>我们首先计算所有特征的平均值，然后再计算协方差矩阵：</p> $p(x)=\prod_{j=1}^np(x_j;\mu,\sigma_j^2)=\prod_{j=1}^n\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$ $\mu=\frac{1}{m}\sum_{i=1}^mx^{(i)}$ $\Sigma = \frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T=\frac{1}{m}(X-\mu)^T(X-\mu)$<p>注:其中$\mu $ 是一个向量，其每一个单元都是原特征矩阵中一行数据的均值。最后我们计算多元高斯分布的$p\left( x \right)$:</p> $p(x)=\frac{1}{(2\pi)^{\frac{n}{2} }|\Sigma|^{\frac{1}{2} }}exp\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right)$<p>其中：</p> $|\Sigma|$是定矩阵，在 **Octave** 中用 `det(sigma)`计算 $\Sigma^{-1}$ 是逆矩阵，下面我们来看看协方差矩阵是如何影响模型的：<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/29df906704d254f18e92a63173dd51e7.jpg" alt="29df906704d254f18e92a63173dd51e7"><br>上图是5个不同的模型，从左往右依次分析：</p><ol><li><p>是一个一般的高斯分布模型</p></li><li><p>通过协方差矩阵，令特征1拥有较小的偏差，同时保持特征2的偏差</p></li><li><p>通过协方差矩阵，令特征2拥有较大的偏差，同时保持特征1的偏差</p></li><li><p>通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的正相关性</p></li><li><p>通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的负相关性</p></li></ol><p>多元高斯分布模型与原高斯分布模型的关系：</p><p>可以证明的是，原本的高斯分布模型是多元高斯分布模型的一个子集，即像上图中的第1、2、3，3个例子所示，如果协方差矩阵只在对角线的单位上有非零的值时，即为原本的高斯分布模型了。</p><p>原高斯分布模型和多元高斯分布模型的比较：</p><table><thead><tr><th>原高斯分布模型</th><th>多元高斯分布模型</th></tr></thead><tbody><tr><td>不能捕捉特征之间的相关性 但可以通过将特征进行组合的方法来解决</td><td>自动捕捉特征之间的相关性</td></tr><tr><td>计算代价低，能适应大规模的特征</td><td>计算代价较高 训练集较小时也同样适用</td></tr><tr><td></td><td>必须要有 $m>n$，不然的话协方差矩阵$\Sigma$不可逆的，通常需要 $m>10n$ 另外特征冗余也会导致协方差矩阵不可逆</td></tr></tbody></table><p>原高斯分布模型被广泛使用着，如果特征之间在某种程度上存在相互关联的情况，我们可以通过构造新新特征的方法来捕捉这些相关性。</p><p>如果训练集不是太大，并且没有太多的特征，我们可以使用多元高斯分布模型。</p><h3 id="使用多元高斯分布进行异常检测（可选）"><a href="#使用多元高斯分布进行异常检测（可选）" class="headerlink" title="使用多元高斯分布进行异常检测（可选）"></a>使用多元高斯分布进行异常检测（可选）</h3><p>参考视频: 15 - 8 - Anomaly Detection using the Multivariate Gaussian Distribution (Optional) (14 min).mkv</p><p>在我们谈到的最后一个视频，关于多元高斯分布，看到的一些建立的各种分布模型，当你改变参数，$\mu$ 和 $\Sigma$。在这段视频中，让我们用这些想法，并应用它们制定一个不同的异常检测算法。</p><p>要回顾一下多元高斯分布和多元正态分布：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3dbee365617e9264831400e4de247adc.png" alt="3dbee365617e9264831400e4de247adc"><br>分布有两个参数， $\mu$ 和 $\Sigma$。其中$\mu$这一个$n$维向量和 $\Sigma$ 的协方差矩阵，是一种$n\times n$的矩阵。而这里的公式$x$的概率，如按 $\mu$ 和参数化 $\Sigma$，和你的变量 $\mu$ 和 $\Sigma$，你可以得到一个范围的不同分布一样，你知道的，这些都是三个样本，那些我们在以前的视频看过了。</p><p>因此，让我们谈谈参数拟合或参数估计问题：</p><p>我有一组样本${ {{ x^{(1)},x^{(2)},...,x^{(m)} } } }$是一个$n$维向量，我想我的样本来自一个多元高斯分布。我如何尝试估计我的参数 $\mu$ 和 $\Sigma$ 以及标准公式？</p><p>估计他们是你设置 $\mu$ 是你的训练样本的平均值。</p> $\mu=\frac{1}{m}\sum_{i=1}^{m}x^{(i)}$<p>并设置$\Sigma$：</p> $\Sigma=\frac{1}{m}\sum_{i=1}^{m}(x^{(i)}-\mu)(x^{(i)}-\mu)^T$<p>这其实只是当我们使用<strong>PCA</strong>算法时候，有 $\Sigma$ 时写出来。所以你只需插入上述两个公式，这会给你你估计的参数 $\mu$ 和你估计的参数 $\Sigma$。所以，这里给出的数据集是你如何估计 $\mu$ 和 $\Sigma$。让我们以这种方法而只需将其插入到异常检测算法。那么，我们如何把所有这一切共同开发一个异常检测算法？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d1a228f2bec262f2206379ed844c7f4a.png" alt="d1a228f2bec262f2206379ed844c7f4a"><br>首先，我们把我们的训练集，和我们的拟合模型，我们计算$p(x)$，要知道，设定$\mu$和描述的一样$\Sigma$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/015cee3a224dde6da0181215cf91a23d.png" alt="015cee3a224dde6da0181215cf91a23d"><br>如图，该分布在中央最多，越到外面的圈的范围越小。</p><p>并在该点是出路这里的概率非常低。</p><p>原始模型与多元高斯模型的关系如图：</p><p>其中：协方差矩阵$\Sigma$为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7104dd2548f1251e4c423e059d1d2594.png" alt="7104dd2548f1251e4c423e059d1d2594"><br>原始模型和多元高斯分布比较如图：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f4585239738f2b5149608879fa166889.png" alt="f4585239738f2b5149608879fa166889"></p><h2 id="推荐系统-Recommender-Systems"><a href="#推荐系统-Recommender-Systems" class="headerlink" title="推荐系统(Recommender Systems)"></a>推荐系统(Recommender Systems)</h2><h3 id="问题形式化"><a href="#问题形式化" class="headerlink" title="问题形式化"></a>问题形式化</h3><p>参考视频: 16 - 1 - Problem Formulation (8 min).mkv</p><p>在接下来的视频中，我想讲一下推荐系统。我想讲推荐系统有两个原因：</p><p>第一、仅仅因为它是机器学习中的一个重要的应用。在过去几年，我偶尔访问硅谷不同的技术公司，我常和工作在这儿致力于机器学习应用的人们聊天，我常问他们，最重要的机器学习的应用是什么，或者，你最想改进的机器学习应用有哪些。我最常听到的答案是推荐系统。现在，在硅谷有很多团体试图建立很好的推荐系统。因此，如果你考虑网站像亚马逊，或网飞公司或易趣，或<strong>iTunes Genius</strong>，有很多的网站或系统试图推荐新产品给用户。如，亚马逊推荐新书给你，网飞公司试图推荐新电影给你，等等。这些推荐系统，根据浏览你过去买过什么书，或过去评价过什么电影来判断。这些系统会带来很大一部分收入，比如为亚马逊和像网飞这样的公司。因此，对推荐系统性能的改善，将对这些企业的有实质性和直接的影响。</p><p>推荐系统是个有趣的问题，在学术机器学习中因此，我们可以去参加一个学术机器学习会议，推荐系统问题实际上受到很少的关注，或者，至少在学术界它占了很小的份额。但是，如果你看正在发生的事情，许多有能力构建这些系统的科技企业，他们似乎在很多企业中占据很高的优先级。这是我为什么在这节课讨论它的原因之一。</p><p>我想讨论推荐系统地第二个原因是：这个班视频的最后几集我想讨论机器学习中的一些大思想，并和大家分享。这节课我们也看到了，对机器学习来说，特征是很重要的，你所选择的特征，将对你学习算法的性能有很大的影响。因此，在机器学习中有一种大思想，它针对一些问题，可能并不是所有的问题，而是一些问题，有算法可以为你自动学习一套好的特征。因此，不要试图手动设计，而手写代码这是目前为止我们常干的。有一些设置，你可以有一个算法，仅仅学习其使用的特征，推荐系统就是类型设置的一个例子。还有很多其它的，但是通过推荐系统，我们将领略一小部分特征学习的思想，至少，你将能够了解到这方面的一个例子，我认为，机器学习中的大思想也是这样。因此，让我们开始讨论推荐系统问题形式化。</p><p>我们从一个例子开始定义推荐系统的问题。</p><p>假使我们是一个电影供应商，我们有 5 部电影和 4 个用户，我们要求用户为电影打分。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c2822f2c28b343d7e6ade5bd40f3a1fc.png" alt="c2822f2c28b343d7e6ade5bd40f3a1fc"><br>前三部电影是爱情片，后两部则是动作片，我们可以看出<strong>Alice</strong>和<strong>Bob</strong>似乎更倾向与爱情片， 而 <strong>Carol</strong> 和 <strong>Dave</strong> 似乎更倾向与动作片。并且没有一个用户给所有的电影都打过分。我们希望构建一个算法来预测他们每个人可能会给他们没看过的电影打多少分，并以此作为推荐的依据。</p><p>下面引入一些标记：</p> $n_u$ 代表用户的数量 $n_m$ 代表电影的数量 $r(i, j)$ 如果用户j给电影 $i$ 评过分则 $r(i,j)=1$ $y^{(i, j)}$ 代表用户 $j$ 给电影$i$的评分 $m_j$代表用户 $j$ 评过分的电影的总数<h3 id="基于内容的推荐系统"><a href="#基于内容的推荐系统" class="headerlink" title="基于内容的推荐系统"></a>基于内容的推荐系统</h3><p>参考视频: 16 - 2 - Content Based Recommendations (15 min).mkv</p><p>在一个基于内容的推荐系统算法中，我们假设对于我们希望推荐的东西有一些数据，这些数据是有关这些东西的特征。</p><p>在我们的例子中，我们可以假设每部电影都有两个特征，如$x_1$代表电影的浪漫程度，$x_2$ 代表电影的动作程度。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/747c1fd6bff694c6034da1911aa3314b.png" alt="747c1fd6bff694c6034da1911aa3314b"><br>则每部电影都有一个特征向量，如$x^{(1)}$是第一部电影的特征向量为[0.9 0]。</p><p>下面我们要基于这些特征来构建一个推荐系统算法。<br>假设我们采用线性回归模型，我们可以针对每一个用户都训练一个线性回归模型，如${ {\theta }^{(1)} }$是第一个用户的模型的参数。<br>于是，我们有：</p> $\theta^{(j)}$用户 $j$ 的参数向量 $x^{(i)}$电影 $i$ 的特征向量<p>对于用户 $j$ 和电影 $i$，我们预测评分为：$(\theta^{(j)})^T x^{(i)}$</p><p>代价函数</p><p>针对用户 $j$，该线性回归模型的代价为预测误差的平方和，加上正则化项：<br>$$<br>\min_{\theta (j)}\frac{1}{2}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\left(\theta_{k}^{(j)}\right)^2<br>$$</p><p>其中 $i:r(i,j)$表示我们只计算那些用户 $j$ 评过分的电影。在一般的线性回归模型中，误差项和正则项应该都是乘以$1/2m$，在这里我们将$m$去掉。并且我们不对方差项$\theta_0$进行正则化处理。</p><p>上面的代价函数只是针对一个用户的，为了学习所有用户，我们将所有用户的代价函数求和：<br>$$<br>\min_{\theta^{(1)},…,\theta^{(n_u)} } \frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2<br>$$<br>如果我们要用梯度下降法来求解最优解，我们计算代价函数的偏导数后得到梯度下降的更新公式为：</p><p>$$<br>\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)} \quad (\text{for} , k = 0)<br>$$</p><p>$$<br>\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)}+\lambda\theta_k^{(j)}\right) \quad (\text{for} , k\neq 0)<br>$$</p><h3 id="协同过滤"><a href="#协同过滤" class="headerlink" title="协同过滤"></a>协同过滤</h3><p>参考视频: 16 - 3 - Collaborative Filtering (10 min).mkv</p><p>在之前的基于内容的推荐系统中，对于每一部电影，我们都掌握了可用的特征，使用这些特征训练出了每一个用户的参数。相反地，如果我们拥有用户的参数，我们可以学习得出电影的特征。</p><p>$$<br>\mathop{min}\limits_{x^{(1)},…,x^{(n_m)} }\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j{r(i,j)=1} }((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2<br>$$<br>但是如果我们既没有用户的参数，也没有电影的特征，这两种方法都不可行了。协同过滤算法可以同时学习这两者。</p><p>我们的优化目标便改为同时针对$x$和$\theta$进行。<br>$$<br>J(x^{(1)},…x^{(n_m)},\theta^{(1)},…,\theta^{(n_u)})=\frac{1}{2}\sum_{(i:j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2<br>$$</p><p>对代价函数求偏导数的结果如下：</p><p>$$<br>x_k^{(i)}:=x_k^{(i)}-\alpha\left(\sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\theta_k^{j}+\lambda x_k^{(i)}\right)<br>$$</p><p>$$<br>\theta_k^{(i)}:=\theta_k^{(i)}-\alpha\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}x_k^{(i)}+\lambda \theta_k^{(j)}\right)<br>$$</p><p>注：在协同过滤从算法中，我们通常不使用方差项，如果需要的话，算法会自动学得。<br>协同过滤算法使用步骤如下：</p><ol><li><p>初始 $x^{(1)},x^{(1)},...x^{(nm)},\ \theta^{(1)},\theta^{(2)},...,\theta^{(n_u)}$为一些随机小值</p></li><li><p>使用梯度下降算法最小化代价函数</p></li><li><p>在训练完算法后，我们预测$(\theta^{(j)})^Tx^{(i)}$为用户 $j$ 给电影 $i$ 的评分</p></li></ol><p>通过这个学习过程获得的特征矩阵包含了有关电影的重要数据，这些数据不总是人能读懂的，但是我们可以用这些数据作为给用户推荐电影的依据。</p><p>例如，如果一位用户正在观看电影 $x^{(i)}$，我们可以寻找另一部电影$x^{(j)}$，依据两部电影的特征向量之间的距离$\left\| { {x}^{(i)} }-{ {x}^{(j)} } \right\|$的大小。</p><h3 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h3><p>参考视频: 16 - 4 - Collaborative Filtering Algorithm (9 min).mkv</p><p>协同过滤优化目标：</p><p>给定$x^{(1)},...,x^{(n_m)}$，估计$\theta^{(1)},...,\theta^{(n_u)}$：<br>$$<br>\min_{\theta^{(1)},…,\theta^{(n_u)} }\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2<br>$$</p><p>给定$\theta^{(1)},...,\theta^{(n_u)}$，估计$x^{(1)},...,x^{(n_m)}$：</p><p>同时最小化$x^{(1)},...,x^{(n_m)}$和$\theta^{(1)},...,\theta^{(n_u)}$：<br>$$<br>J(x^{(1)},…,x^{(n_m)},\theta^{(1)},…,\theta^{(n_u)})=\frac{1}{2}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2<br>$$</p><p>$$<br>\min_{x^{(1)},…,x^{(n_m)} \\ \theta^{(1)},…,\theta^{(n_u)} }J(x^{(1)},…,x^{(n_m)},\theta^{(1)},…,\theta^{(n_u)})<br>$$</p><h3 id="向量化：低秩矩阵分解"><a href="#向量化：低秩矩阵分解" class="headerlink" title="向量化：低秩矩阵分解"></a>向量化：低秩矩阵分解</h3><p>参考视频: 16 - 5 - Vectorization_ Low Rank Matrix Factorization (8 min).mkv</p><p>在上几节视频中，我们谈到了协同过滤算法，本节视频中我将会讲到有关该算法的向量化实现，以及说说有关该算法你可以做的其他事情。</p><p>举例子：</p><ol><li><p>当给出一件产品时，你能否找到与之相关的其它产品。</p></li><li><p>一位用户最近看上一件产品，有没有其它相关的产品，你可以推荐给他。</p></li></ol><p>我将要做的是：实现一种选择的方法，写出协同过滤算法的预测情况。</p><p>我们有关于五部电影的数据集，我将要做的是，将这些用户的电影评分，进行分组并存到一个矩阵中。</p><p>我们有五部电影，以及四位用户，那么 这个矩阵 $Y$ 就是一个5行4列的矩阵，它将这些电影的用户评分数据都存在矩阵里：</p><table><thead><tr><th><strong>Movie</strong></th><th><strong>Alice (1)</strong></th><th><strong>Bob (2)</strong></th><th><strong>Carol (3)</strong></th><th><strong>Dave (4)</strong></th></tr></thead><tbody><tr><td>Love at last</td><td>5</td><td>5</td><td>0</td><td>0</td></tr><tr><td>Romance forever</td><td>5</td><td>?</td><td>?</td><td>0</td></tr><tr><td>Cute puppies of love</td><td>?</td><td>4</td><td>0</td><td>?</td></tr><tr><td>Nonstop car chases</td><td>0</td><td>0</td><td>5</td><td>4</td></tr><tr><td>Swords vs. karate</td><td>0</td><td>0</td><td>5</td><td>?</td></tr></tbody></table><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/42a92e07b32b593bb826f8f6bc4d9eb3.png" alt="42a92e07b32b593bb826f8f6bc4d9eb3"><br>推出评分：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c905a6f02e201a4767d869b3791e8aeb.png" alt="c905a6f02e201a4767d869b3791e8aeb"><br>找到相关影片：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0a8b49da1ab852f2996a02afcaca2322.png" alt="0a8b49da1ab852f2996a02afcaca2322"><br>现在既然你已经对特征参数向量进行了学习，那么我们就会有一个很方便的方法来度量两部电影之间的相似性。例如说：电影 $i$ 有一个特征向量$x^{(i)}$，你是否能找到一部不同的电影 $j$，保证两部电影的特征向量之间的距离$x^{(i)}$和$x^{(j)}$很小，那就能很有力地表明电影$i$和电影 $j$ 在某种程度上有相似，至少在某种意义上，某些人喜欢电影 $i$，或许更有可能也对电影 $j$ 感兴趣。总结一下，当用户在看某部电影 $i$ 的时候，如果你想找5部与电影非常相似的电影，为了能给用户推荐5部新电影，你需要做的是找出电影 $j$，在这些不同的电影中与我们要找的电影 $i$ 的距离最小，这样你就能给你的用户推荐几部不同的电影了。</p><p>通过这个方法，希望你能知道，如何进行一个向量化的计算来对所有的用户和所有的电影进行评分计算。同时希望你也能掌握，通过学习特征参数，来找到相关电影和产品的方法。</p><h3 id="推行工作上的细节：均值归一化"><a href="#推行工作上的细节：均值归一化" class="headerlink" title="推行工作上的细节：均值归一化"></a>推行工作上的细节：均值归一化</h3><p>参考视频: 16 - 6 - Implementational Detail_ Mean Normalization (9 min).mkv</p><p>让我们来看下面的用户评分数据：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54b1f7c3131aed24f9834d62a6835642.png" alt="54b1f7c3131aed24f9834d62a6835642"><br>如果我们新增一个用户 <strong>Eve</strong>，并且 <strong>Eve</strong> 没有为任何电影评分，那么我们以什么为依据为<strong>Eve</strong>推荐电影呢？</p><p>我们首先需要对结果 $Y $矩阵进行均值归一化处理，将每一个用户对某一部电影的评分减去所有用户对该电影评分的平均值：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9ec5cb55e14bd1462183e104f8e02b80.png" alt="9ec5cb55e14bd1462183e104f8e02b80"><br>然后我们利用这个新的 $Y$ 矩阵来训练算法。<br>如果我们要用新训练出的算法来预测评分，则需要将平均值重新加回去，预测$(\theta^{(j)})^T x^{(i)}+\mu_i$，对于<strong>Eve</strong>，我们的新模型会认为她给每部电影的评分都是该电影的平均分。</p><h2 id="大规模机器学习-Large-Scale-Machine-Learning"><a href="#大规模机器学习-Large-Scale-Machine-Learning" class="headerlink" title="大规模机器学习(Large Scale Machine Learning)"></a>大规模机器学习(Large Scale Machine Learning)</h2><h3 id="大型数据集的学习"><a href="#大型数据集的学习" class="headerlink" title="大型数据集的学习"></a>大型数据集的学习</h3><p>参考视频: 17 - 1 - Learning With Large Datasets (6 min).mkv</p><p>如果我们有一个低方差的模型，增加数据集的规模可以帮助你获得更好的结果。我们应该怎样应对一个有100万条记录的训练集？</p><p>以线性回归模型为例，每一次梯度下降迭代，我们都需要计算训练集的误差的平方和，如果我们的学习算法需要有20次迭代，这便已经是非常大的计算代价。</p><p>首先应该做的事是去检查一个这么大规模的训练集是否真的必要，也许我们只用1000个训练集也能获得较好的效果，我们可以绘制学习曲线来帮助判断。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bdf069136b4b661dd14158496d1d1419.png" alt="bdf069136b4b661dd14158496d1d1419"></p><h3 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h3><p>参考视频: 17 - 2 - Stochastic Gradient Descent (13 min).mkv</p><p>如果我们一定需要一个大规模的训练集，我们可以尝试使用随机梯度下降法来代替批量梯度下降法。</p><p>在随机梯度下降法中，我们定义代价函数为一个单一训练实例的代价：</p><p>​ $$cost\left( \theta, \left( {x}^{(i)} , {y}^{(i)} \right) \right) = \frac{1}{2}\left( {h}_{\theta}\left({x}^{(i)}\right)-{y}^{ {(i)} } \right)^{2}$$</p><p><strong>随机</strong>梯度下降算法为：首先对训练集随机“洗牌”，然后：<br>Repeat (usually anywhere between1-10){</p><p><strong>for</strong> $i = 1:m${</p><p>​ $\theta:={\theta}_{j}-\alpha\left( {h}_{\theta}\left({x}^{(i)}\right)-{y}^{(i)} \right){ {x}_{j} }^{(i)}$</p><p>​ (<strong>for</strong> $j=0:n$)</p><p>​ }<br>}</p><p>随机梯度下降算法在每一次计算之后便更新参数 ${ {\theta } }$ ，而不需要首先将所有的训练集求和，在梯度下降算法还没有完成一次迭代时，随机梯度下降算法便已经走出了很远。但是这样的算法存在的问题是，不是每一步都是朝着”正确”的方向迈出的。因此算法虽然会逐渐走向全局最小值的位置，但是可能无法站到那个最小值的那一点，而是在最小值点附近徘徊。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9710a69ba509a9dcbca351fccc6e7aae.jpg" alt="9710a69ba509a9dcbca351fccc6e7aae"></p><h3 id="小批量梯度下降"><a href="#小批量梯度下降" class="headerlink" title="小批量梯度下降"></a>小批量梯度下降</h3><p>参考视频: 17 - 3 - Mini-Batch Gradient Descent (6 min).mkv</p><p>小批量梯度下降算法是介于批量梯度下降算法和随机梯度下降算法之间的算法，每计算常数$b$次训练实例，便更新一次参数 ${ {\theta } }$ 。<br><strong>Repeat</strong> {</p><p><strong>for</strong> $i = 1:m${</p><p>​ $\theta:={\theta}_{j}-\alpha\frac{1}{b}\sum_\limits{k=i}^{i+b-1}\left( {h}_{\theta}\left({x}^{(k)}\right)-{y}^{(k)} \right){ {x}_{j} }^{(k)}$</p><p>​ (<strong>for</strong> $j=0:n$)</p><p>​ $ i +=10 $</p><p>​ }<br>}</p><p>通常我们会令 $b$ 在 2-100 之间。这样做的好处在于，我们可以用向量化的方式来循环 $b$个训练实例，如果我们用的线性代数函数库比较好，能够支持平行处理，那么算法的总体表现将不受影响（与随机梯度下降相同）。</p><h3 id="随机梯度下降收敛"><a href="#随机梯度下降收敛" class="headerlink" title="随机梯度下降收敛"></a>随机梯度下降收敛</h3><p>参考视频: 17 - 4 - Stochastic Gradient Descent Convergence (12 min). mkv</p><p>现在我们介绍随机梯度下降算法的调试，以及学习率 $α$ 的选取。</p><p>在批量梯度下降中，我们可以令代价函数$J$为迭代次数的函数，绘制图表，根据图表来判断梯度下降是否收敛。但是，在大规模的训练集的情况下，这是不现实的，因为计算代价太大了。</p><p>在随机梯度下降中，我们在每一次更新 ${ {\theta } }$ 之前都计算一次代价，然后每$x$次迭代后，求出这$x$次对训练实例计算代价的平均值，然后绘制这些平均值与$x$次迭代的次数之间的函数图表。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/76fb1df50bdf951f4b880fa66489e367.png" alt="76fb1df50bdf951f4b880fa66489e367"><br>当我们绘制这样的图表时，可能会得到一个颠簸不平但是不会明显减少的函数图像（如上面左下图中蓝线所示）。我们可以增加$α$来使得函数更加平缓，也许便能看出下降的趋势了（如上面左下图中红线所示）；或者可能函数图表仍然是颠簸不平且不下降的（如洋红色线所示），那么我们的模型本身可能存在一些错误。</p><p>如果我们得到的曲线如上面右下方所示，不断地上升，那么我们可能会需要选择一个较小的学习率$α$。</p><p>我们也可以令学习率随着迭代次数的增加而减小，例如令：</p><p>​ $$\alpha = \frac{const1}{iterationNumber + const2}$$</p><p>随着我们不断地靠近全局最小值，通过减小学习率，我们迫使算法收敛而非在最小值附近徘徊。<br>但是通常我们不需要这样做便能有非常好的效果了，对$α$进行调整所耗费的计算通常不值得</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f703f371dbb80d22fd5e4aec48aa9fd4.jpg" alt="f703f371dbb80d22fd5e4aec48aa9fd4"><br>总结下，这段视频中，我们介绍了一种方法，近似地监测出随机梯度下降算法在最优化代价函数中的表现，这种方法不需要定时地扫描整个训练集，来算出整个样本集的代价函数，而是只需要每次对最后1000个，或者多少个样本，求一下平均值。应用这种方法，你既可以保证随机梯度下降法正在正常运转和收敛，也可以用它来调整学习速率$α$的大小。</p><h3 id="在线学习"><a href="#在线学习" class="headerlink" title="在线学习"></a>在线学习</h3><p>参考视频: 17 - 5 - Online Learning (13 min).mkv</p><p>在这个视频中，讨论一种新的大规模的机器学习机制，叫做在线学习机制。在线学习机制让我们可以模型化问题。</p><p>今天，许多大型网站或者许多大型网络公司，使用不同版本的在线学习机制算法，从大批的涌入又离开网站的用户身上进行学习。特别要提及的是，如果你有一个由连续的用户流引发的连续的数据流，进入你的网站，你能做的是使用一个在线学习机制，从数据流中学习用户的偏好，然后使用这些信息来优化一些关于网站的决策。</p><p>假定你有一个提供运输服务的公司，用户们来向你询问把包裹从<strong>A</strong>地运到<strong>B</strong>地的服务，同时假定你有一个网站，让用户们可多次登陆，然后他们告诉你，他们想从哪里寄出包裹，以及包裹要寄到哪里去，也就是出发地与目的地，然后你的网站开出运输包裹的的服务价格。比如，我会收取&lt;!–￼780–&gt;20之类的，然后根据你开给用户的这个价格，用户有时会接受这个运输服务，那么这就是个正样本，有时他们会走掉，然后他们拒绝购买你的运输服务，所以，让我们假定我们想要一个学习算法来帮助我们，优化我们想给用户开出的价格。</p><p>一个算法来从中学习的时候来模型化问题在线学习算法指的是对数据流而非离线的静态数据集的学习。许多在线网站都有持续不断的用户流，对于每一个用户，网站希望能在不将数据存储到数据库中便顺利地进行算法学习。</p><p>假使我们正在经营一家物流公司，每当一个用户询问从地点A至地点B的快递费用时，我们给用户一个报价，该用户可能选择接受（$y=1$）或不接受（$y=0$）。</p><p>现在，我们希望构建一个模型，来预测用户接受报价使用我们的物流服务的可能性。因此报价<br>是我们的一个特征，其他特征为距离，起始地点，目标地点以及特定的用户数据。模型的输出是:$p(y=1)$。</p><p>在线学习的算法与随机梯度下降算法有些类似，我们对单一的实例进行学习，而非对一个提前定义的训练集进行循环。<br>Repeat forever (as long as the website is running) {<br>Get $\left(x,y\right)$ corresponding to the current user<br>​ $\theta:={\theta}_{j}-\alpha\left( {h}_{\theta}\left({x}\right)-{y} \right){ {x}_{j} }$<br>​ (<strong>for</strong> $j=0:n$)<br>}</p><p>一旦对一个数据的学习完成了，我们便可以丢弃该数据，不需要再存储它了。这种方式的好处在于，我们的算法可以很好的适应用户的倾向性，算法可以针对用户的当前行为不断地更新模型以适应该用户。</p><p>每次交互事件并不只产生一个数据集，例如，我们一次给用户提供3个物流选项，用户选择2项，我们实际上可以获得3个新的训练实例，因而我们的算法可以一次从3个实例中学习并更新模型。</p><p>这些问题中的任何一个都可以被归类到标准的，拥有一个固定的样本集的机器学习问题中。或许，你可以运行一个你自己的网站，尝试运行几天，然后保存一个数据集，一个固定的数据集，然后对其运行一个学习算法。但是这些是实际的问题，在这些问题里，你会看到大公司会获取如此多的数据，真的没有必要来保存一个固定的数据集，取而代之的是你可以使用一个在线学习算法来连续的学习，从这些用户不断产生的数据中来学习。这就是在线学习机制，然后就像我们所看到的，我们所使用的这个算法与随机梯度下降算法非常类似，唯一的区别的是，我们不会使用一个固定的数据集，我们会做的是获取一个用户样本，从那个样本中学习，然后丢弃那个样本并继续下去，而且如果你对某一种应用有一个连续的数据流，这样的算法可能会非常值得考虑。当然，在线学习的一个优点就是，如果你有一个变化的用户群，又或者你在尝试预测的事情，在缓慢变化，就像你的用户的品味在缓慢变化，这个在线学习算法，可以慢慢地调试你所学习到的假设，将其调节更新到最新的用户行为。</p><h3 id="映射化简和数据并行"><a href="#映射化简和数据并行" class="headerlink" title="映射化简和数据并行"></a>映射化简和数据并行</h3><p>参考视频: 17 - 6 - Map Reduce and Data Parallelism (14 min).mkv</p><p>映射化简和数据并行对于大规模机器学习问题而言是非常重要的概念。之前提到，如果我们用批量梯度下降算法来求解大规模数据集的最优解，我们需要对整个训练集进行循环，计算偏导数和代价，再求和，计算代价非常大。如果我们能够将我们的数据集分配给不多台计算机，让每一台计算机处理数据集的一个子集，然后我们将计所的结果汇总在求和。这样的方法叫做映射简化。</p><p>具体而言，如果任何学习算法能够表达为，对训练集的函数的求和，那么便能将这个任务分配给多台计算机（或者同一台计算机的不同<strong>CPU</strong> 核心），以达到加速处理的目的。</p><p>例如，我们有400个训练实例，我们可以将批量梯度下降的求和任务分配给4台计算机进行处理：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/919eabe903ef585ec7d08f2895551a1f.jpg" alt="919eabe903ef585ec7d08f2895551a1f"><br>很多高级的线性代数函数库已经能够利用多核<strong>CPU</strong>的多个核心来并行地处理矩阵运算，这也是算法的向量化实现如此重要的缘故（比调用循环快）。</p><h2 id="应用实例：图片文字识别-Application-Example-Photo-OCR"><a href="#应用实例：图片文字识别-Application-Example-Photo-OCR" class="headerlink" title="应用实例：图片文字识别(Application Example: Photo OCR)"></a>应用实例：图片文字识别(Application Example: Photo OCR)</h2><h3 id="问题描述和流程图"><a href="#问题描述和流程图" class="headerlink" title="问题描述和流程图"></a>问题描述和流程图</h3><p>参考视频: 18 - 1 - Problem Description and Pipeline (7 min).mkv</p><p>图像文字识别应用所作的事是，从一张给定的图片中识别文字。这比从一份扫描文档中识别文字要复杂的多。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/095e4712376c26ff7ffa260125760140.jpg" alt="095e4712376c26ff7ffa260125760140"><br>为了完成这样的工作，需要采取如下步骤：</p><ol><li><p>文字侦测（<strong>Text detection</strong>）——将图片上的文字与其他环境对象分离开来</p></li><li><p>字符切分（<strong>Character segmentation</strong>）——将文字分割成一个个单一的字符</p></li><li><p>字符分类（<strong>Character classification</strong>）——确定每一个字符是什么<br>可以用任务流程图来表达这个问题，每一项任务可以由一个单独的小队来负责解决：</p></li></ol><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/610fffb413d8d577882d6345c166a9fb.png" alt="610fffb413d8d577882d6345c166a9fb"></p><h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><p>参考视频: 18 - 2 - Sliding Windows (15 min).mkv</p><p>滑动窗口是一项用来从图像中抽取对象的技术。假使我们需要在一张图片中识别行人，首先要做的是用许多固定尺寸的图片来训练一个能够准确识别行人的模型。然后我们用之前训练识别行人的模型时所采用的图片尺寸在我们要进行行人识别的图片上进行剪裁，然后将剪裁得到的切片交给模型，让模型判断是否为行人，然后在图片上滑动剪裁区域重新进行剪裁，将新剪裁的切片也交给模型进行判断，如此循环直至将图片全部检测完。</p><p>一旦完成后，我们按比例放大剪裁的区域，再以新的尺寸对图片进行剪裁，将新剪裁的切片按比例缩小至模型所采纳的尺寸，交给模型进行判断，如此循环。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1e00d03719e20eeaf1f414f99d7f4109.jpg" alt="1e00d03719e20eeaf1f414f99d7f4109"><br>滑动窗口技术也被用于文字识别，首先训练模型能够区分字符与非字符，然后，运用滑动窗口技术识别字符，一旦完成了字符的识别，我们将识别得出的区域进行一些扩展，然后将重叠的区域进行合并。接着我们以宽高比作为过滤条件，过滤掉高度比宽度更大的区域（认为单词的长度通常比高度要大）。下图中绿色的区域是经过这些步骤后被认为是文字的区域，而红色的区域是被忽略的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bc48a4b0c7257591643eb50f2bf46db6.jpg" alt="bc48a4b0c7257591643eb50f2bf46db6"><br>以上便是文字侦测阶段。<br>下一步是训练一个模型来完成将文字分割成一个个字符的任务，需要的训练集由单个字符的图片和两个相连字符之间的图片来训练模型。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0a930f2083bbeb85837f018b74fd0a02.jpg" alt="0a930f2083bbeb85837f018b74fd0a02"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0bde4f379c8a46c2074336ecce1a955f.jpg" alt="0bde4f379c8a46c2074336ecce1a955f"><br>模型训练完后，我们仍然是使用滑动窗口技术来进行字符识别。</p><p>以上便是字符切分阶段。<br>最后一个阶段是字符分类阶段，利用神经网络、支持向量机或者逻辑回归算法训练一个分类器即可。</p><h3 id="获取大量数据和人工数据"><a href="#获取大量数据和人工数据" class="headerlink" title="获取大量数据和人工数据"></a>获取大量数据和人工数据</h3><p>参考视频: 18 - 3 - Getting Lots of Data and Artificial Data (16 min).mkv</p><p>如果我们的模型是低方差的，那么获得更多的数据用于训练模型，是能够有更好的效果的。问题在于，我们怎样获得数据，数据不总是可以直接获得的，我们有可能需要人工地创造一些数据。</p><p>以我们的文字识别应用为例，我们可以字体网站下载各种字体，然后利用这些不同的字体配上各种不同的随机背景图片创造出一些用于训练的实例，这让我们能够获得一个无限大的训练集。这是从零开始创造实例。</p><p>另一种方法是，利用已有的数据，然后对其进行修改，例如将已有的字符图片进行一些扭曲、旋转、模糊处理。只要我们认为实际数据有可能和经过这样处理后的数据类似，我们便可以用这样的方法来创造大量的数据。</p><p>有关获得更多数据的几种方法：</p><ol><li><p>人工数据合成</p></li><li><p>手动收集、标记数据</p></li><li><p>众包</p></li></ol><h3 id="上限分析：哪部分管道的接下去做"><a href="#上限分析：哪部分管道的接下去做" class="headerlink" title="上限分析：哪部分管道的接下去做"></a>上限分析：哪部分管道的接下去做</h3><p>参考视频: 18 - 4 - Ceiling Analysis_ What Part of the Pipeline to Work on Next<br>(14 min).mkv</p><p>在机器学习的应用中，我们通常需要通过几个步骤才能进行最终的预测，我们如何能够知道哪一部分最值得我们花时间和精力去改善呢？这个问题可以通过上限分析来回答。</p><p>回到我们的文字识别应用中，我们的流程图如下：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/55d41ee748680a62e755d6aa5b95b53c.png" alt="55d41ee748680a62e755d6aa5b95b53c"><br>流程图中每一部分的输出都是下一部分的输入，上限分析中，我们选取一部分，手工提供100%正确的输出结果，然后看应用的整体效果提升了多少。假使我们的例子中总体效果为72%的正确率。</p><p>如果我们令文字侦测部分输出的结果100%正确，发现系统的总体效果从72%提高到了89%。这意味着我们很可能会希望投入时间精力来提高我们的文字侦测部分。</p><p>接着我们手动选择数据，让字符切分输出的结果100%正确，发现系统的总体效果只提升了1%，这意味着，我们的字符切分部分可能已经足够好了。</p><p>最后我们手工选择数据，让字符分类输出的结果100%正确，系统的总体效果又提升了10%，这意味着我们可能也会应该投入更多的时间和精力来提高应用的总体表现。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f1ecee10884098f98032648da08f8937.jpg" alt="f1ecee10884098f98032648da08f8937"></p></article><div class="post-donate"><div id="donate_board" class="donate_bar center"><a id="btn_donate" class="btn_donate" href="javascript:;" title="打赏"></a> <span class="donate_txt">↑<br> 欢迎投食,求鼓励，求支持！</span><br></div><div id="donate_guide" class="donate_bar center hidden"> <img src="/images/alipay.png" alt="支付宝打赏"> <img src="/images/wechatpay.png" alt="微信打赏"></div><script type="text/javascript">document.getElementById("btn_donate").onclick=function(){$("#donate_board").addClass("hidden"),$("#donate_guide").removeClass("hidden")}</script></div><div class="nexmoe-post-copyright"><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i> <strong>本文作者：</strong>OneJane<br> <strong>本文链接：</strong><a href="https://onejane.github.io/2019/12/04/new_吴恩达机器学习笔记(6-10周)/" title="https://onejane.github.io/2019/12/04/new_吴恩达机器学习笔记(6-10周)/" target="_blank" rel="noopener">https://onejane.github.io/2019/12/04/new_吴恩达机器学习笔记(6-10周)/</a><br> <strong>版权声明：</strong>本文采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh" target="_blank">CC BY-NC-SA 3.0 CN</a> 协议进行许可</div><section class="nexmoe-comment"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.css"><div id="gitalk"></div><script src="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"e677e59382e1c7a468fd",clientSecret:"717d041bc4ab749f069314862232cfb6ec8adc15",id:decodeURI(window.location.pathname),repo:"onejane.github.io",owner:"onejane",admin:"onejane"});gitalk.render("gitalk")</script></section></div></div></div><script src="https://cdn.jsdelivr.net/npm/mdui@0.4.3/dist/js/mdui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/smoothscroll-for-websites@1.4.9/SmoothScroll.min.js"></script><script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.15.8/build/highlight.min.js"></script><script>hljs.initHighlightingOnLoad()</script><script src="/js/app.js?v=1578153607624"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@5.1.0/lazysizes.min.js"></script><div hidden><script type="text/javascript" src="https://js.users.51.la/20279757.js"></script></div></body><script src="https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js"></script></html>