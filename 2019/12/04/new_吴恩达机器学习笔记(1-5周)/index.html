<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><title>吴恩达机器学习笔记(1-5周) - OneJane</title><meta charset="UTF-8"><meta name="description" content="微服务,高可用,高并发,人工智能"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="msvalidate.01" content="396E9693347B4D18AAE96D9E75B9B686"><link rel="shortcut icon" href="/images/a.ico" type="image/png"><meta name="description" content="吴恩达机器学习笔记"><meta name="keywords" content="nlp"><meta property="og:type" content="article"><meta property="og:title" content="吴恩达机器学习笔记(1-5周)"><meta property="og:url" content="https://onejane.github.io/2019/12/04/new_吴恩达机器学习笔记(1-5周)/index.html"><meta property="og:site_name" content="OneJane"><meta property="og:description" content="吴恩达机器学习笔记"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423614245.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423705880.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423772270.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423900529.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423980984.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424111930.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424452903.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424505376.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424585514.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424646031.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424692858.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424716806.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424876911.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424969202.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424993676.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429352272.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429392028.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429400255.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429409440.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429686477.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429854299.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575430060807.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575430214648.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431053908.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431095812.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431123683.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431133404.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431168523.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431645491.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431758447.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431766568.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431781513.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431844502.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431851977.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431866164.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431954385.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432002700.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432364923.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432408169.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432413948.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432420036.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e2c2dcc31f19ac255566fa616799d496.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6dcdf4a7c0d56787648d4a1902034150.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8507899953ed2de68e6b2b83554f9ea.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/126b2a5c4b5bfb24e5c21cd080159530.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fec0936e2a78c0fe8c9e3ed107614a31.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8d63fe546c12a7e9eb658118d76288f7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a537df35ccc9ff83a3c7518362e2f729.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c11786828c587189891a9ef02f041ab7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4b67374499c0d38ed8670ba74ff892d0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/acedf91b6b39d551e62a89f2e0955628.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2cdc09b8bf67e546df7284ba74601c66.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dfcd1d37526824726d85a655f8951249.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ba8f0c3d2d8f017e0f7a611aa5be75d6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/693ebb444501838dd9b69520fff54be0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1cdbd87db83a4184098cd6d5ee3c6a87.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5d2b25d4078a276091b9c00812674fa9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/21985f8690965598d4a17e3a6e7fee94.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/846b48ec79c9fcee05b20767dcc89558.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0de6e7054e869a82060cefa9968cd56b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/048f3cac1c32e3dc56160849c4dd60b0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/10c06cc39058da2c5eef696d75e65a2c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08d11f870c5b30536f1965507fa7e7dc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/79b55d71cf434126f3d8457a3a615d18.png"><meta property="og:image" content="https://markdown.xiaoshujiang.com/img/spinner.gif"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0de527966203108b7efa1b6730bd966c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e4080d69119a0e408581c81a66e133c8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7e85f313f721f53f3ae74664210a7a25.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e49f56ceddd34dce986ae1dbdc399762.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e8207c74976c4443d1ea25ec2a3b8477.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a8c3b363f13820b4fc6463c7520ab58c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b39bf4e9212442464fe2f568dbe4fa0c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d1d551d0c540449d457e312a34434355.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f47bda45fd9beef6c600ebd48d163617.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e1c68a99a23d993674f08151e77dd44.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e07db429512d4b3b5d641c52e606159d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7f11aa788b1b75c5a534d030b3ebc624.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8ee5c7c05865e90f75feda99b9131319.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/38c956acb3bedf4362f40e6c5e8a692f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/646de38bffd4f7f6601167d0c0686970.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d456e7501d7aaa9fa2ef8a89e89fa7e1.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0c7c1d7726c09ffb45152cf153614003.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a36506049248948c82e598c8c254dc31.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9432bbcbfde53c7e0dcb1c7317b01c0c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e02eec3ca4688ff1cb9126c8eb13bfed.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fc04d42876c9d7d7bed51bade2077649.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ac9ad10f115d2d1cd15a0514c8ceeafa.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8c7f4f36183ef4b36bce427be2fce6f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/409a04487d1d7f039acfd61b3787f6aa.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d7221c981ecc7730465710a0d8b49b34.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/31bc524d1a19b4e9d8ea0974517a512e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0b9753a3e10bbdce0f26c3d44d61ae26.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4514b422525aaac1e99add67e44882ee.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575433328341.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2d32a23ab895a8e765caf90a7679817e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/38969cc85853190ff3eac4f06398bc1b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9eb4e496f34a801fd7ba5e85c4eec66b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/23594175efe66d5b9b1e687375a2dbda.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c765aeee9c53e0e77d01d1e73cabd9b4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a786b8ed82ddd182f4595de2173cc84b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f13993f4784d01e7da769b4ec2545cd7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/82a990a5832ae2618d768551b90470dc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/881986ec5af9d86b6b14b260fb3b3618.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/22a9a9536d4db17b6d64603fb54dce9e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c0e8b7a19ced9a1dd006ed87d6323c9b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/26a912d550af9fd43a7ae62e3b610e97.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/890f6ea8f857f22002f98c20d52b3bb8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fc956ae1291dc7d3b819e471d1962398.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1b37f81896a59145576ae996c9dd4d16.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/279cfbda6b4d9a2ced1332f086db4d9e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3fce4367c960bb6fbc492a3b8f9ddc5d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/247f96f4e7ab7a259ac9ef1eebe0b503.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3c857152ef3f0d6b374e4863289d1c60.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e01d6da07890e32d46d0616741a3fe64.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/885b5d19c33f545292ccc1b69976c789.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7fefb92d8680e4a15f947cd2ca24a9ac.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/125c07019cb39675085fe3b80b85fca5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/829e153c119919f80c058d1bc703a08b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/987fc9372da3b167fd16d7a19722405b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6ad266a30f955db5b905905670aabfc5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fa662ec6d5703d85c314f5e4792a7468.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20bc912bae44e66125f8bfcec6e720c7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/541b9f097a8e1357c2a75e4f64e53b54.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0a03d239f2f1d1af057d492bcce276f4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8d10103bf172a889090690a00037ffa1.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c84012101afc6836a3396893695d9669.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a77886a6eff0f20f9d909975bb69a7ab.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575441014185.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/29c12ee079c079c6408ee032870b2683.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d027a0612664ea460247c8637b25e306.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1073efb17b0d053b4f9218d4393246cc.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6590923ac94130a979a8ca1d911b68a3.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/58d098bbb415f2c3797a63bd870c3b8f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f71fb6102e1ceb616314499a027336dc.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/197d605aa74bee1556720ea248bab182.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f23eebddd70122ef05baa682f4d6bd0f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8b94e47b7630ac2b0bcb10d204513810.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54249cb51f0086fa6a805291bf2639f1.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ffa56adcc217800d71afdc3e0df88378.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/eb69baa91c2fc6e7dd8ebdf6c79a6a6f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/171031235527.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/171031235719.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0171031235044.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/394a1d763425c4ecf12f8f98a392067f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/743a769317d584a66509fc394b4e6095.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bd074e119a52163691cff93c3f42a1ee.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/68f56679a2113c7857ab9dd2afebcba8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54d7903564b4416305b26f6ff2e13c04.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/450a83c67732d254dbac2aeeb8ab910c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b72863ce7f85cd491e5b940924ef5a5f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/72f84165fbf1753cd516e65d5e91c0d3.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/be39b497588499d671942cc15026e4a2.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ea76cc5394cf298f2414f230bcded0bd.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/71d723ddb5863c943fcd4e6951114ee3.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2726da11c772fc58f0c85e40aaed14bd.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5316b24cd40908fb5cb1db5a055e4de5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3ac5e06e852ad3deef4cba782ebe425b.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7912ea75bc7982998870721cb1177226.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2b74c1eeff95db47f5ebd8aef1290f09.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/95c020b2227ca4b9a9bcbd40099d1766.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/697ae58b1370e81749f9feb333bdf842.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1ee5c76a62b35384491c603bb54c8c0c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3d93e8c1cd681c2b3599f05739e3f3cc.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7dabd366525c7c3124e844abce8c2dd6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c2233cd74605a9f8fe69fd59547d3853.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fbb4ffb48b64468c384647d45f7b86b5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8293711e1d23414d0a03f6878f5a2d91.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20171101224053.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/303ce7ad54d957fca9dbb6a992155111.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e17f58ce9a79525089a1c2e0b4c0ccc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/43f1cb8a2a7e9a18f928720adc1fac22.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6167ad04e696c400cb9e1b7dc1e58d8a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/10342b472803c339a9e3bc339188c5b8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/809187c1815e1ec67184699076de51f2.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6d652f125654d077480aadc578ae0164.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f75115da9090701516aa1ff0295436dd.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/aa27671f7a3a16545a28f356a2fb98c0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/57480b04956f1dc54ecfc64d68a6b357.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7527e61b1612dcf84dadbcf7a26a22fb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1fd3017dfa554642a5e1805d6d2b1fa6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4c44e69a12b48efdff2fe92a0a698768.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/432c906875baca78031bd337fe0c8682.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f3236b14640fa053e62c73177b3474ed.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/685180bf1774f7edd2b0856a8aae3498.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5e1a39d165f272b7f145c68ef78a3e13.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8f7c28297fc9ed297f42942018441850.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2ea8f5ce4c3df931ee49cf8d987ef25d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5514df14ebd508fd597e552fbadcf053.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5778e97c411b23487881a87cfca781bb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/63a0e4aef6d47ba7fa6e07088b61ae68.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/57aabbf26290e2082a00c5114ae1c5dc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1542307ad9033e39093e7f28d0c7146c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0ad78547859e6f794a7f18389d3d6128.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f9284204de41bffa4f7bc1dea567044e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ebd7e196e272737f497853ba60743c44.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5d04c4791eb12a74c843eb5acf601400.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bf65f3f3098025530a3c442eea562f8c.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/cea3f9a181d326681cd7d6ceaf4f2e46.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/56441d35d8bd4ecfd6d6f32b651c54a6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/41cdc4cd2bc49a1b75d57aaf748e0798.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dd4a022b5544d50f503c077b3a5a5251.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423614245.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423705880.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423772270.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423900529.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423980984.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424111930.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424452903.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424505376.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424585514.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424646031.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424692858.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424716806.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424876911.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424969202.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424993676.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429352272.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429392028.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429400255.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429409440.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429686477.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429854299.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575430060807.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575430214648.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431053908.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431095812.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431123683.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431133404.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431168523.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431645491.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431758447.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431766568.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431781513.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431844502.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431851977.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431866164.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431954385.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432002700.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432364923.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432408169.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432413948.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432420036.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e2c2dcc31f19ac255566fa616799d496.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6dcdf4a7c0d56787648d4a1902034150.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8507899953ed2de68e6b2b83554f9ea.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/126b2a5c4b5bfb24e5c21cd080159530.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fec0936e2a78c0fe8c9e3ed107614a31.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8d63fe546c12a7e9eb658118d76288f7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a537df35ccc9ff83a3c7518362e2f729.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c11786828c587189891a9ef02f041ab7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4b67374499c0d38ed8670ba74ff892d0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/acedf91b6b39d551e62a89f2e0955628.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2cdc09b8bf67e546df7284ba74601c66.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dfcd1d37526824726d85a655f8951249.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ba8f0c3d2d8f017e0f7a611aa5be75d6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/693ebb444501838dd9b69520fff54be0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1cdbd87db83a4184098cd6d5ee3c6a87.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5d2b25d4078a276091b9c00812674fa9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/21985f8690965598d4a17e3a6e7fee94.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/846b48ec79c9fcee05b20767dcc89558.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0de6e7054e869a82060cefa9968cd56b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/048f3cac1c32e3dc56160849c4dd60b0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/10c06cc39058da2c5eef696d75e65a2c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08d11f870c5b30536f1965507fa7e7dc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/79b55d71cf434126f3d8457a3a615d18.png"><meta property="og:image" content="https://markdown.xiaoshujiang.com/img/spinner.gif"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0de527966203108b7efa1b6730bd966c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e4080d69119a0e408581c81a66e133c8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7e85f313f721f53f3ae74664210a7a25.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e49f56ceddd34dce986ae1dbdc399762.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e8207c74976c4443d1ea25ec2a3b8477.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a8c3b363f13820b4fc6463c7520ab58c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b39bf4e9212442464fe2f568dbe4fa0c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d1d551d0c540449d457e312a34434355.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f47bda45fd9beef6c600ebd48d163617.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e1c68a99a23d993674f08151e77dd44.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e07db429512d4b3b5d641c52e606159d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7f11aa788b1b75c5a534d030b3ebc624.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8ee5c7c05865e90f75feda99b9131319.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/38c956acb3bedf4362f40e6c5e8a692f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/646de38bffd4f7f6601167d0c0686970.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d456e7501d7aaa9fa2ef8a89e89fa7e1.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0c7c1d7726c09ffb45152cf153614003.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a36506049248948c82e598c8c254dc31.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9432bbcbfde53c7e0dcb1c7317b01c0c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e02eec3ca4688ff1cb9126c8eb13bfed.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fc04d42876c9d7d7bed51bade2077649.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ac9ad10f115d2d1cd15a0514c8ceeafa.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8c7f4f36183ef4b36bce427be2fce6f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/409a04487d1d7f039acfd61b3787f6aa.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d7221c981ecc7730465710a0d8b49b34.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/31bc524d1a19b4e9d8ea0974517a512e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0b9753a3e10bbdce0f26c3d44d61ae26.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4514b422525aaac1e99add67e44882ee.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575433328341.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2d32a23ab895a8e765caf90a7679817e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/38969cc85853190ff3eac4f06398bc1b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9eb4e496f34a801fd7ba5e85c4eec66b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/23594175efe66d5b9b1e687375a2dbda.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c765aeee9c53e0e77d01d1e73cabd9b4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a786b8ed82ddd182f4595de2173cc84b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f13993f4784d01e7da769b4ec2545cd7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/82a990a5832ae2618d768551b90470dc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/881986ec5af9d86b6b14b260fb3b3618.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/22a9a9536d4db17b6d64603fb54dce9e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c0e8b7a19ced9a1dd006ed87d6323c9b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/26a912d550af9fd43a7ae62e3b610e97.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/890f6ea8f857f22002f98c20d52b3bb8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fc956ae1291dc7d3b819e471d1962398.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1b37f81896a59145576ae996c9dd4d16.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/279cfbda6b4d9a2ced1332f086db4d9e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3fce4367c960bb6fbc492a3b8f9ddc5d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/247f96f4e7ab7a259ac9ef1eebe0b503.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3c857152ef3f0d6b374e4863289d1c60.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e01d6da07890e32d46d0616741a3fe64.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/885b5d19c33f545292ccc1b69976c789.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7fefb92d8680e4a15f947cd2ca24a9ac.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/125c07019cb39675085fe3b80b85fca5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/829e153c119919f80c058d1bc703a08b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/987fc9372da3b167fd16d7a19722405b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6ad266a30f955db5b905905670aabfc5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fa662ec6d5703d85c314f5e4792a7468.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20bc912bae44e66125f8bfcec6e720c7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/541b9f097a8e1357c2a75e4f64e53b54.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0a03d239f2f1d1af057d492bcce276f4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8d10103bf172a889090690a00037ffa1.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c84012101afc6836a3396893695d9669.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a77886a6eff0f20f9d909975bb69a7ab.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575441014185.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/29c12ee079c079c6408ee032870b2683.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d027a0612664ea460247c8637b25e306.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1073efb17b0d053b4f9218d4393246cc.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6590923ac94130a979a8ca1d911b68a3.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/58d098bbb415f2c3797a63bd870c3b8f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f71fb6102e1ceb616314499a027336dc.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/197d605aa74bee1556720ea248bab182.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f23eebddd70122ef05baa682f4d6bd0f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8b94e47b7630ac2b0bcb10d204513810.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54249cb51f0086fa6a805291bf2639f1.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ffa56adcc217800d71afdc3e0df88378.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/eb69baa91c2fc6e7dd8ebdf6c79a6a6f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/171031235527.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/171031235719.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0171031235044.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/394a1d763425c4ecf12f8f98a392067f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/743a769317d584a66509fc394b4e6095.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bd074e119a52163691cff93c3f42a1ee.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/68f56679a2113c7857ab9dd2afebcba8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54d7903564b4416305b26f6ff2e13c04.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/450a83c67732d254dbac2aeeb8ab910c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b72863ce7f85cd491e5b940924ef5a5f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/72f84165fbf1753cd516e65d5e91c0d3.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/be39b497588499d671942cc15026e4a2.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ea76cc5394cf298f2414f230bcded0bd.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/71d723ddb5863c943fcd4e6951114ee3.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2726da11c772fc58f0c85e40aaed14bd.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5316b24cd40908fb5cb1db5a055e4de5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3ac5e06e852ad3deef4cba782ebe425b.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7912ea75bc7982998870721cb1177226.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2b74c1eeff95db47f5ebd8aef1290f09.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/95c020b2227ca4b9a9bcbd40099d1766.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/697ae58b1370e81749f9feb333bdf842.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1ee5c76a62b35384491c603bb54c8c0c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3d93e8c1cd681c2b3599f05739e3f3cc.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7dabd366525c7c3124e844abce8c2dd6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c2233cd74605a9f8fe69fd59547d3853.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fbb4ffb48b64468c384647d45f7b86b5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8293711e1d23414d0a03f6878f5a2d91.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20171101224053.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/303ce7ad54d957fca9dbb6a992155111.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e17f58ce9a79525089a1c2e0b4c0ccc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/43f1cb8a2a7e9a18f928720adc1fac22.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6167ad04e696c400cb9e1b7dc1e58d8a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/10342b472803c339a9e3bc339188c5b8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/809187c1815e1ec67184699076de51f2.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6d652f125654d077480aadc578ae0164.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f75115da9090701516aa1ff0295436dd.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/aa27671f7a3a16545a28f356a2fb98c0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/57480b04956f1dc54ecfc64d68a6b357.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7527e61b1612dcf84dadbcf7a26a22fb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1fd3017dfa554642a5e1805d6d2b1fa6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4c44e69a12b48efdff2fe92a0a698768.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/432c906875baca78031bd337fe0c8682.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f3236b14640fa053e62c73177b3474ed.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/685180bf1774f7edd2b0856a8aae3498.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5e1a39d165f272b7f145c68ef78a3e13.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8f7c28297fc9ed297f42942018441850.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2ea8f5ce4c3df931ee49cf8d987ef25d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5514df14ebd508fd597e552fbadcf053.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5778e97c411b23487881a87cfca781bb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/63a0e4aef6d47ba7fa6e07088b61ae68.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/57aabbf26290e2082a00c5114ae1c5dc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1542307ad9033e39093e7f28d0c7146c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0ad78547859e6f794a7f18389d3d6128.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f9284204de41bffa4f7bc1dea567044e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ebd7e196e272737f497853ba60743c44.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5d04c4791eb12a74c843eb5acf601400.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bf65f3f3098025530a3c442eea562f8c.jpg"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/cea3f9a181d326681cd7d6ceaf4f2e46.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/56441d35d8bd4ecfd6d6f32b651c54a6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/41cdc4cd2bc49a1b75d57aaf748e0798.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dd4a022b5544d50f503c077b3a5a5251.png"><meta property="og:updated_time" content="2019-12-05T03:53:46.753Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="吴恩达机器学习笔记(1-5周)"><meta name="twitter:description" content="吴恩达机器学习笔记"><meta name="twitter:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423614245.png"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdui@0.4.3/dist/css/mdui.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.15.8/styles/atom-one-dark.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1038733_0xvrvpg9c0r.css"><link rel="stylesheet" href="/css/style.css?v=1577592008052"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js"></script></head><body class="mdui-drawer-body-left"><div id="nexmoe-background"><div class="nexmoe-bg" style="background-image:url(https://www.github.com/OneJane/blog/raw/master/小书匠/1566388885395.png)"></div><div class="mdui-appbar mdui-shadow-0"><div class="mdui-toolbar"> <a mdui-drawer="{target: '#drawer', swipe: true}" title="menu" class="mdui-btn mdui-btn-icon"><i class="mdui-icon material-icons">menu</i></a><div class="mdui-toolbar-spacer"></div> <a href="/" title="OneJane" class="mdui-btn mdui-btn-icon"><img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388846021.png"></a></div></div></div><div id="nexmoe-header"><div class="nexmoe-drawer mdui-drawer" id="drawer"><div class="nexmoe-avatar mdui-ripple"> <a href="/" title="OneJane"><img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388846021.png" alt="OneJane"></a></div><div class="nexmoe-count"><div><span>文章</span>69</div><div><span>标签</span>83</div><div><span>分类</span>12</div></div><ul class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}"><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/" title="回到首页"><i class="mdui-list-item-icon nexmoefont icon-home"></i><div class="mdui-list-item-content"> 回到首页</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/about.html" title="关于博客"><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i><div class="mdui-list-item-content"> 关于博客</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/py.html" title="我的朋友"><i class="mdui-list-item-icon nexmoefont icon-unorderedlist"></i><div class="mdui-list-item-content"> 我的朋友</div></a></ul><aside id="nexmoe-sidebar"><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">社交按钮</h3><div class="nexmoe-widget nexmoe-social"><a class="mdui-ripple" href="https://github.com/OneJane" target="_blank" mdui-tooltip="{content: 'GitHub'}" style="color:#191717;background-color:rgba(25,23,23,.15)"><i class="nexmoefont icon-github"></i></a></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">文章分类</h3><div class="nexmoe-widget"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/人工智能/">人工智能</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/定时器/">定时器</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/持续集成/">持续集成</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/注册中心/">注册中心</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/测试/">测试</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/系统/">系统</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/自然语言处理/">自然语言处理</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目实战/">项目实战</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/高可用/">高可用</a><span class="category-list-count">4</span></li></ul></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">标签云</h3><div class="nexmoe-widget tagcloud"> <a href="/tags/Gensim/" style="font-size:10px">Gensim</a> <a href="/tags/Hanlp/" style="font-size:10px">Hanlp</a> <a href="/tags/NLTK/" style="font-size:10px">NLTK</a> <a href="/tags/OpenCV/" style="font-size:12.86px">OpenCV</a> <a href="/tags/Stanford-NLP/" style="font-size:10px">Stanford NLP</a> <a href="/tags/Tensorflow/" style="font-size:15.71px">Tensorflow</a> <a href="/tags/ant-design/" style="font-size:10px">ant design</a> <a href="/tags/ant-design-pro/" style="font-size:11.43px">ant design pro</a> <a href="/tags/auc/" style="font-size:10px">auc</a> <a href="/tags/bottle/" style="font-size:10px">bottle</a> <a href="/tags/chatterbot/" style="font-size:10px">chatterbot</a> <a href="/tags/cnn/" style="font-size:12.86px">cnn</a> <a href="/tags/crf/" style="font-size:12.86px">crf</a> <a href="/tags/doc2vec/" style="font-size:10px">doc2vec</a> <a href="/tags/docker/" style="font-size:17.14px">docker</a> <a href="/tags/dubbo/" style="font-size:11.43px">dubbo</a> <a href="/tags/elasticsearch/" style="font-size:10px">elasticsearch</a> <a href="/tags/elastisearch/" style="font-size:10px">elastisearch</a> <a href="/tags/email/" style="font-size:10px">email</a> <a href="/tags/es6/" style="font-size:10px">es6</a> <a href="/tags/feign/" style="font-size:10px">feign</a> <a href="/tags/flask/" style="font-size:11.43px">flask</a> <a href="/tags/folium/" style="font-size:10px">folium</a> <a href="/tags/freemarker/" style="font-size:10px">freemarker</a> <a href="/tags/function/" style="font-size:10px">function</a> <a href="/tags/gateway/" style="font-size:10px">gateway</a> <a href="/tags/gensim/" style="font-size:11.43px">gensim</a> <a href="/tags/gitlab/" style="font-size:11.43px">gitlab</a> <a href="/tags/gru/" style="font-size:11.43px">gru</a> <a href="/tags/hanlp/" style="font-size:11.43px">hanlp</a> <a href="/tags/haproxy/" style="font-size:10px">haproxy</a> <a href="/tags/hmm/" style="font-size:10px">hmm</a> <a href="/tags/jenkins/" style="font-size:11.43px">jenkins</a> <a href="/tags/jieba/" style="font-size:15.71px">jieba</a> <a href="/tags/jmeter/" style="font-size:10px">jmeter</a> <a href="/tags/keepalived/" style="font-size:10px">keepalived</a> <a href="/tags/lda/" style="font-size:11.43px">lda</a> <a href="/tags/linux/" style="font-size:10px">linux</a> <a href="/tags/lstm/" style="font-size:12.86px">lstm</a> <a href="/tags/maven/" style="font-size:11.43px">maven</a> <a href="/tags/multi-druid/" style="font-size:10px">multi druid</a> <a href="/tags/mybatis/" style="font-size:10px">mybatis</a> <a href="/tags/mybatisplus/" style="font-size:10px">mybatisplus</a> <a href="/tags/mysql/" style="font-size:10px">mysql</a> <a href="/tags/n-gram/" style="font-size:10px">n-gram</a> <a href="/tags/nacos/" style="font-size:11.43px">nacos</a> <a href="/tags/neo4j/" style="font-size:11.43px">neo4j</a> <a href="/tags/nexmoe/" style="font-size:10px">nexmoe</a> <a href="/tags/nlp/" style="font-size:20px">nlp</a> <a href="/tags/numpy/" style="font-size:10px">numpy</a> <a href="/tags/partition/" style="font-size:10px">partition</a> <a href="/tags/procedure/" style="font-size:10px">procedure</a> <a href="/tags/pxc/" style="font-size:10px">pxc</a> <a href="/tags/pyhanlp/" style="font-size:11.43px">pyhanlp</a> <a href="/tags/python/" style="font-size:10px">python</a> <a href="/tags/rabbitmq/" style="font-size:10px">rabbitmq</a> <a href="/tags/react/" style="font-size:11.43px">react</a> <a href="/tags/redis/" style="font-size:11.43px">redis</a> <a href="/tags/redis-cluster/" style="font-size:10px">redis-cluster</a> <a href="/tags/replication/" style="font-size:11.43px">replication</a> <a href="/tags/rnn/" style="font-size:10px">rnn</a> <a href="/tags/rocketmq/" style="font-size:11.43px">rocketmq</a> <a href="/tags/scrapy/" style="font-size:12.86px">scrapy</a> <a href="/tags/selenium/" style="font-size:12.86px">selenium</a> <a href="/tags/sentinel/" style="font-size:14.29px">sentinel</a> <a href="/tags/seq2seq/" style="font-size:10px">seq2seq</a> <a href="/tags/session/" style="font-size:10px">session</a> <a href="/tags/sklearn/" style="font-size:10px">sklearn</a> <a href="/tags/skywalking/" style="font-size:11.43px">skywalking</a> <a href="/tags/snownlp/" style="font-size:10px">snownlp</a> <a href="/tags/spring-cloud-alibaba/" style="font-size:18.57px">spring cloud alibaba</a> <a href="/tags/springboot/" style="font-size:14.29px">springboot</a> <a href="/tags/svm/" style="font-size:10px">svm</a> <a href="/tags/swagger/" style="font-size:10px">swagger</a> <a href="/tags/textrank/" style="font-size:10px">textrank</a> <a href="/tags/tf-idf/" style="font-size:12.86px">tf-idf</a> <a href="/tags/tk-mybatis/" style="font-size:10px">tk mybatis</a> <a href="/tags/umi/" style="font-size:10px">umi</a> <a href="/tags/validate/" style="font-size:10px">validate</a> <a href="/tags/word2vec/" style="font-size:10px">word2vec</a> <a href="/tags/wordcloud/" style="font-size:10px">wordcloud</a> <a href="/tags/xxl-job/" style="font-size:11.43px">xxl-job</a> <a href="/tags/zookeeper/" style="font-size:10px">zookeeper</a></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">文章归档</h3><div class="nexmoe-widget"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li></ul></div></div></aside><div class="nexmoe-copyright"> &copy; 2019 OneJane</div></div></div><div id="nexmoe-content"><div class="nexmoe-primary"><div class="nexmoe-post"><div class="nexmoe-post-cover"> <img src="https://www.github.com/OneJane/blog/raw/master/小书匠/82a490a419fe375d72125e422ed31adb_hd.jpg"><h1>吴恩达机器学习笔记(1-5周)</h1></div><div class="nexmoe-post-meta"><a><i class="nexmoefont icon-calendar-fill"></i> 2019年12月04日</a><a><i class="nexmoefont icon-areachart"></i> 98.1k 字</a><a><i class="nexmoefont icon-time-circle-fill"></i> 大概 424 分钟</a> <a class="nexmoefont icon-appstore-fill -link" href="/categories/人工智能/">人工智能</a> <a class="nexmoefont icon-tag-fill -link" href="/tags/nlp/">nlp</a></div><article><p><a href="https://onejane.github.io/">吴恩达机器学习笔记</a></p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><p>参考视频: 1 - 3 - Supervised Learning (12 min).mkv<br>我们用一个例子介绍什么是监督学习把正式的定义放在后面介绍。假如说你想预测房价。</p><p>前阵子，一个学生从波特兰俄勒冈州的研究所收集了一些房价的数据。你把这些数据画出来，看起来是这个样子：横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。那基于这组数据，假如你有一个朋友，他有一套750平方英尺房子，现在他希望把房子卖掉，他想知道这房子能卖多少钱。</p><p>那么关于这个问题，机器学习算法将会怎么帮助你呢？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423614245.png" alt="enter description here"></p><p>我们应用学习算法，可以在这组数据中画一条直线，或者换句话说，拟合一条直线，根据这条线我们可以推测出，这套房子可能卖$150,000，当然这不是唯一的算法。可能还有更好的，比如我们不用直线拟合这些数据，用二次方程去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近$200,000。稍后我们将讨论如何选择学习算法，如何决定用直线还是二次方程来拟合。两个方案中有一个能让你朋友的房子出售得更合理。这些都是学习算法里面很好的例子。以上就是<strong>监督学习</strong>的例子。</p><p>可以看出，监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成。在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。用术语来讲，这叫做<strong>回归问题</strong>。我们试着推测出一个连续值的结果，即房子的价格。</p><p>一般房子的价格会记到美分，所以房价实际上是一系列离散的值，但是我们通常又把房价看成实数，看成是标量，所以又把它看成一个连续的数值。</p><p><strong>回归这个词的意思是，我们在试着推测出这一系列连续值属性。</strong></p><p>我再举另外一个监督学习的例子。我和一些朋友之前研究过这个。假设说你想通过查看病历来推测乳腺癌良性与否，假如有人检测出乳腺肿瘤，恶性肿瘤有害并且十分危险，而良性的肿瘤危害就没那么大，所以人们显然会很在意这个问题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423705880.png" alt="enter description here"></p><p>让我们来看一组数据：这个数据集中，横轴表示肿瘤的大小，纵轴上，我标出1和0表示是或者不是恶性肿瘤。我们之前见过的肿瘤，如果是恶性则记为1，不是恶性，或者说良性记为0。</p><p>我有5个良性肿瘤样本，在1的位置有5个恶性肿瘤样本。现在我们有一个朋友很不幸检查出乳腺肿瘤。假设说她的肿瘤大概这么大，那么机器学习的问题就在于，你能否估算出肿瘤是恶性的或是良性的概率。用术语来讲，这是一个<strong>分类问题</strong>。</p><p><strong>分类指的是，我们试着推测出离散的输出值</strong>：0或1良性或恶性，而事实上在分类问题中，输出可能不止两个值。比如说可能有三种乳腺癌，所以你希望预测离散输出0、1、2、3。0 代表良性，1 表示第1类乳腺癌，2表示第2类癌症，3表示第3类，但这也是分类问题。</p><p>因为这几个离散的输出分别对应良性，第一类第二类或者第三类癌症，在分类问题中我们可以用另一种方式绘制这些数据点。</p><p>现在我用不同的符号来表示这些数据。既然我们把肿瘤的尺寸看做区分恶性或良性的特征，那么我可以这么画，我用不同的符号来表示良性和恶性肿瘤。或者说是负样本和正样本现在我们不全部画<strong>X</strong>，良性的肿瘤改成用 <strong>O</strong> 表示，恶性的继续用 <strong>X</strong> 表示。来预测肿瘤的恶性与否。</p><p>在其它一些机器学习问题中，可能会遇到不止一种特征。举个例子，我们不仅知道肿瘤的尺寸，还知道对应患者的年龄。在其他机器学习问题中，我们通常有更多的特征，我朋友研究这个问题时，通常采用这些特征，比如肿块密度，肿瘤细胞尺寸的一致性和形状的一致性等等，还有一些其他的特征。这就是我们即将学到最有趣的学习算法之一。</p><p>那种算法不仅能处理2种3种或5种特征，即使有无限多种特征都可以处理。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423772270.png" alt="enter description here"></p><p>上图中，我列举了总共5种不同的特征，坐标轴上的两种和右边的3种，但是在一些学习问题中，你希望不只用3种或5种特征。相反，你想用无限多种特征，好让你的算法可以利用大量的特征，或者说线索来做推测。那你怎么处理无限多个特征，甚至怎么存储这些特征都存在问题，你电脑的内存肯定不够用。<strong>我们以后会讲一个算法，叫支持向量机，里面有一个巧妙的数学技巧，能让计算机处理无限多个特征。</strong> 想象一下，我没有写下这两种和右边的三种特征，而是在一个无限长的列表里面，一直写一直写不停的写，写下无限多个特征，事实上，我们能用算法来处理它们。</p><p>现在来回顾一下，这节课我们介绍了<strong>监督学习。其基本思想是，我们数据集中的每个样本都有相应的“正确答案”。再根据这些样本作出预测，就像房子和肿瘤的例子中做的那样。我们还介绍了回归问题，即通过回归来推出一个连续的输出，之后我们介绍了分类问题，其目标是推出一组离散的结果。</strong></p><p>现在来个小测验：假设你经营着一家公司，你想开发学习算法来处理这两个问题：</p><ol><li><p>你有一大批同样的货物，想象一下，你有上千件一模一样的货物等待出售，这时你想预测接下来的三个月能卖多少件？</p></li><li><p>你有许多客户，这时你想写一个软件来检验每一个用户的账户。对于每一个账户，你要判断它们是否曾经被盗过？</p></li></ol><p>那这两个问题，它们属于分类问题、还是回归问题?</p><p>问题一是一个回归问题，因为你知道，如果我有数千件货物，我会把它看成一个实数，一个连续的值。因此卖出的物品数，也是一个连续的值。</p><p>问题二是一个分类问题，因为我会把预测的值，用 0 来表示账户未被盗，用 1 表示账户曾经被盗过。所以我们根据账号是否被盗过，把它们定为0 或 1，然后用算法推测一个账号是 0 还是 1，因为只有少数的离散值，所以我把它归为分类问题。</p><p>以上就是监督学习的内容。</p><h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>参考视频: 1 - 4 - Unsupervised Learning (14 min).mkv<br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423900529.png" alt="enter description here"></p><p>上个视频中，已经介绍了监督学习。回想当时的数据集，如图表所示，这个数据集中每条数据都已经标明是阴性或阳性，即是良性或恶性肿瘤。所以，对于监督学习里的每条数据，我们已经清楚地知道，训练集对应的正确答案，是良性或恶性了。</p><p>在无监督学习中，我们已知的数据。看上去有点不一样，不同于监督学习的数据的样子，即<strong>无监督学习中没有任何的标签或者是有相同的标签或者就是没标签</strong>。所以我们已知数据集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集。你能从数据中找到某种结构吗？针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做聚类算法。事实证明，它能被用在很多地方。</p><p>聚类应用的一个例子就是在谷歌新闻中。如果你以前从来没见过它，你可以到这个URL网址news.google.com去看看。谷歌新闻每天都在，收集非常多，非常多的网络的新闻内容。它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件，自动地把它们聚类到一起。所以，这些新闻事件全是同一主题的，所以显示到一起。</p><p>事实证明，聚类算法和无监督学习算法同样还用在很多其它的问题上。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423980984.png" alt="enter description here"></p><p>其中就有基因学的理解应用。一个<strong>DNA</strong>微观数据的例子。基本思想是输入一组不同个体，对其中的每个个体，你要分析出它们是否有一个特定的基因。技术上，你要分析多少特定基因已经表达。所以这些颜色，红，绿，灰等等颜色，这些颜色展示了相应的程度，即不同的个体是否有着一个特定的基因。你能做的就是运行一个聚类算法，把个体聚类到不同的类或不同类型的组（人）……</p><p>所以这个就是无监督学习，因为我们没有提前告知算法一些信息，比如，这是第一类的人，那些是第二类的人，还有第三类，等等。我们只是说，是的，这是有一堆数据。我不知道数据里面有什么。我不知道谁是什么类型。我甚至不知道人们有哪些不同的类型，这些类型又是什么。但你能自动地找到数据中的结构吗？就是说你要自动地聚类那些个体到各个类，我没法提前知道哪些是哪些。因为我们没有给算法正确答案来回应数据集中的数据，所以这就是无监督学习。</p><p>无监督学习或聚集有着大量的应用。它用于组织大型计算机集群。我有些朋友在大数据中心工作，那里有大型的计算机集群，他们想解决什么样的机器易于协同地工作，如果你能够让那些机器协同工作，你就能让你的数据中心工作得更高效。第二种应用就是社交网络的分析。所以已知你朋友的信息，比如你经常发<strong>email</strong>的，或是你<strong>Facebook</strong>的朋友、<strong>谷歌+</strong> 圈子的朋友，我们能否自动地给出朋友的分组呢？即每组里的人们彼此都熟识，认识组里的所有人？还有市场分割。许多公司有大型的数据库，存储消费者信息。所以，你能检索这些顾客数据集，自动地发现市场分类，并自动地把顾客划分到不同的细分市场中，你才能自动并更有效地销售或不同的细分市场一起进行销售。这也是无监督学习，因为我们拥有所有的顾客数据，但我们没有提前知道是什么的细分市场，以及分别有哪些我们数据集中的顾客。我们不知道谁是在一号细分市场，谁在二号市场，等等。那我们就必须让算法从数据中发现这一切。最后，无监督学习也可用于天文数据分析，这些聚类算法给出了令人惊讶、有趣、有用的理论，解释了星系是如何诞生的。这些都是聚类的例子，聚类只是无监督学习中的一种。</p><p>我现在告诉你们另一种。我先来介绍鸡尾酒宴问题。嗯，你参加过鸡尾酒宴吧？你可以想像下，有个宴会房间里满是人，全部坐着，都在聊天，这么多人同时在聊天，声音彼此重叠，因为每个人都在说话，同一时间都在说话，你几乎听不到你面前那人的声音。所以，可能在一个这样的鸡尾酒宴中的两个人，他俩同时都在说话，假设现在是在个有些小的鸡尾酒宴中。我们放两个麦克风在房间中，因为这些麦克风在两个地方，离说话人的距离不同每个麦克风记录下不同的声音，虽然是同样的两个说话人。听起来像是两份录音被叠加到一起，或是被归结到一起，产生了我们现在的这些录音。另外，这个算法还会区分出两个音频资源，这两个可以合成或合并成之前的录音，实际上，鸡尾酒算法的第一个输出结果是：</p><p>1，2，3，4，5，6，7，8，9，10,</p><p>所以，已经把英语的声音从录音中分离出来了。</p><p>第二个输出是这样：</p><p>1，2，3，4，5，6，7，8，9，10。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424111930.png" alt="enter description here"></p><p>看看这个无监督学习算法，实现这个得要多么的复杂，是吧？它似乎是这样，为了构建这个应用，完成这个音频处理似乎需要你去写大量的代码或链接到一堆的合成器<strong>JAVA</strong>库，处理音频的库，看上去绝对是个复杂的程序，去完成这个从音频中分离出音频。事实上，这个算法对应你刚才知道的那个问题的算法可以就用一行代码来完成。</p><p>就是这里展示的代码：<code>[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x&#39;);</code></p><p>研究人员花费了大量时间才最终实现这行代码。我不是说这个是简单的问题，但它证明了，当你使用正确的编程环境，许多学习算法是相当短的程序。所以，这也是为什么在本课中，我们打算使用<strong>Octave</strong>编程环境。<strong>Octave</strong>,是免费的开源软件，使用一个像<strong>Octave</strong>或<strong>Matlab</strong>的工具，许多学习算法变得只有几行代码就可实现。</p><p>后面，我会教你们一点关于如何使用<strong>Octave</strong>的知识，你就可以用<strong>Octave</strong>来实现一些算法了。或者，如果你有<strong>Matlab</strong>（盗版？），你也可以用<strong>Matlab</strong>。事实上，在硅谷里，对大量机器学习算法，我们第一步就是建原型，在<strong>Octave</strong>建软件原型，因为软件在<strong>Octave</strong>中可以令人难以置信地、快速地实现这些学习算法。这里的这些函数比如<strong>SVM</strong>（<strong>支持向量机</strong>）函数，<strong>奇异值分解</strong>，<strong>Octave</strong>里已经建好了。如果你试图完成这个工作，但借助<strong>C++</strong>或<strong>JAVA</strong>的话，你会需要很多很多行的代码，并链接复杂的<strong>C++</strong>或<strong>Java</strong>库。所以，你可以实现这些算法，借助<strong>C++</strong>或<strong>Java</strong>或<strong>Python</strong>，它只是用这些语言来实现会更加复杂。(编者注：这个是当时的情况，现在<strong>Python</strong>变主流了)</p><p>我已经见到，在我教机器学习将近十年后的现在，发现，学习可以更加高速，如果使用<strong>Octave</strong>作为编程环境，如果使用<strong>Octave</strong>作为学习工具，以及作为原型工具，它会让你对学习算法的学习和建原型快上许多。</p><p>事实上，许多人在大硅谷的公司里做的其实就是，使用一种工具像<strong>Octave</strong>来做第一步的学习算法的原型搭建，只有在你已经让它工作后，你才移植它到<strong>C++</strong> 或<strong>Java</strong>或别的语言。事实证明，这样做通常可以让你的算法运行得比直接用<strong>C++</strong> 实现更快，所以，我知道，作为一名指导者，我必须说“相信我”，但对你们中从未使用过<strong>Octave</strong>这种编程环境的人，我还是要告诉你们这一点一定要相信我，我想，对你们而言，我认为你们的时间，你们的开发时间是最有价值的资源。我已经见过很多人这样做了，我把你看作是机器学习研究员，或机器学习开发人员，想更加高产的话，你要学会使用这个原型工具，开始使用<strong>Octave</strong>。</p><p>我们介绍了<strong>无监督学习，它是学习策略，交给算法大量的数据，并让算法为我们从数据中找出某种结构。</strong></p><p>好的，希望你们还记得<strong>垃圾邮件问题</strong>。如果你有标记好的数据，区别好是垃圾还是非垃圾邮件，我们把这个当作<strong>监督学习问题</strong>。</p><p><strong>新闻事件分类</strong>的例子，就是那个谷歌新闻的例子，我们在本视频中有见到了，我们看到，可以用一个聚类算法来聚类这些文章到一起，所以是<strong>无监督学习</strong>。</p><p><strong>细分市场</strong>的例子，我在更早一点的时间讲过，你可以当作<strong>无监督学习</strong>问题，因为我只是拿到算法数据，再让算法去自动地发现细分市场。</p><p>最后一个例子，<strong>糖尿病</strong>，这个其实就像是我们的乳腺癌，上个视频里的。只是替换了好、坏肿瘤，良性、恶性肿瘤，我们改用糖尿病或没病。所以我们把这个当作<strong>监督学习</strong>，我们能够解决它，作为一个监督学习问题，就像我们在乳腺癌数据中做的一样。</p><h2 id="单变量线性回归-Linear-Regression-with-One-Variable"><a href="#单变量线性回归-Linear-Regression-with-One-Variable" class="headerlink" title="单变量线性回归(Linear Regression with One Variable)"></a>单变量线性回归(Linear Regression with One Variable)</h2><h3 id="模型表示"><a href="#模型表示" class="headerlink" title="模型表示"></a>模型表示</h3><p>参考视频: 2 - 1 - Model Representation (8 min).mkv</p><p>让我们通过一个例子来开始：这个例子是预测住房价格的，我们要使用一个数据集，数据集包含俄勒冈州波特兰市的住房价格。在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424452903.png" alt="enter description here"></p><p>它被称作监督学习是因为对于每个数据来说，我们给出了“正确的答案”，即告诉我们：根据我们的数据来说，房子实际的价格是多少，而且，更具体来说，这是一个回归问题。回归一词指的是，我们根据之前的数据预测出一个准确的输出值，对于这个例子就是价格，同时，还有另一种最常见的监督学习方式，叫做分类问题，当我们想要预测离散的输出值，例如，我们正在寻找癌症肿瘤，并想要确定肿瘤是良性的还是恶性的，这就是0/1离散输出的问题。更进一步来说，在监督学习中我们有一个数据集，这个数据集被称训练集。</p><p><strong>我将在整个课程中用小写的m来表示训练样本的数目。</strong></p><p>以之前的房屋交易问题为例，假使我们回归问题的训练集（<strong>Training Set</strong>）如下表所示：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424505376.png" alt="enter description here"></p><p>我们将要用来描述这个回归问题的标记如下:</p> $m$ 代表训练集中实例的数量 $x$ 代表特征/输入变量 $y$ 代表目标变量/输出变量 $\left( x,y \right)$ 代表训练集中的实例 $({ {x}^{(i)} },{ {y}^{(i)} })$ 代表第$i$ 个观察实例 $h$ 代表学习算法的解决方案或函数也称为假设（**hypothesis**）<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424585514.png" alt="enter description here"></p><p>这就是一个监督学习算法的工作方式，我们可以看到这里有我们的训练集里房屋价格<br>我们把它喂给我们的学习算法，学习算法的工作了，然后输出一个函数，通常表示为小写 $h$ 表示。$h$ 代表<strong>hypothesis</strong>(<strong>假设</strong>)，$h$表示一个函数，输入是房屋尺寸大小，就像你朋友想出售的房屋，因此 $h$ 根据输入的 $x$值来得出 $y$ 值，$y$ 值对应房子的价格 因此，$h$ 是一个从$x$ 到 $y$ 的函数映射。</p><p>我将选择最初的使用规则$h$代表<strong>hypothesis</strong>，因而，要解决房价预测问题，我们实际上是要将训练集“喂”给我们的学习算法，进而学习得到一个假设$h$，然后将我们要预测的房屋的尺寸作为输入变量输入给$h$，预测出该房屋的交易价格作为输出变量输出为结果。那么，对于我们的房价预测问题，我们该如何表达 $h$？</p><p>一种可能的表达方式为：$h_\theta \left( x \right)=\theta_{0} + \theta_{1}x$，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。</p><h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>参考视频: 2 - 2 - Cost Function (8 min).mkv<br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424646031.png" alt="enter description here"></p><p>在线性回归中我们有一个像这样的训练集，$m$代表了训练样本的数量，比如 $m = 47$。而我们的假设函数，也就是用来进行预测的函数，是这样的线性函数形式：$h_\theta \left( x \right)=\theta_{0}+\theta_{1}x$。</p><p>接下来我们会引入一些术语我们现在要做的便是为我们的模型选择合适的<strong>参数</strong>（<strong>parameters</strong>）$\theta_{0}$ 和 $\theta_{1}$，在房价问题这个例子中便是直线的斜率和在$y$ 轴上的截距。</p><p>我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是<strong>建模误差</strong>（<strong>modeling error</strong>）。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424692858.png" alt="enter description here"></p><p>我们的<strong>目标便是选择出可以使得建模误差的平方和能够最小的模型参数</strong>。 即使得代价函数 $J \left( \theta_0, \theta_1 \right) = \frac{1}{2m}\sum\limits_{i=1}^m \left( h_{\theta}(x^{(i)})-y^{(i)} \right)^{2}$最小。</p><p>我们绘制一个等高线图，三个坐标分别为$\theta_{0}$和$\theta_{1}$ 和$J(\theta_{0}, \theta_{1})$：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424716806.png" alt="enter description here"></p><p>则可以看出在三维空间中存在一个使得$J(\theta_{0}, \theta_{1})$最小的点。</p><p>代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。</p><p>在后续课程中，我们还会谈论其他的代价函数，但我们刚刚讲的选择是对于大多数线性回归问题非常合理的。</p><p>也许这个函数$J(\theta_{0}, \theta_{1})$有点抽象，可能你仍然不知道它的内涵，在接下来的几个视频里，我们要更进一步解释代价函数J的工作原理，并尝试更直观地解释它在计算什么，以及我们使用它的目的。</p><h3 id="代价函数的直观理解"><a href="#代价函数的直观理解" class="headerlink" title="代价函数的直观理解"></a>代价函数的直观理解</h3><p>参考视频: 2 - 3 - Cost Function - Intuition I (11 min).mkv<br>在上一个视频中，我们给了代价函数一个数学上的定义。在这个视频里，让我们通过一些例子来获取一些直观的感受，看看代价函数到底是在干什么。<br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424876911.png" alt="enter description here"></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424969202.png" alt="enter description here"></p><p>代价函数的样子，等高线图，则可以看出在三维空间中存在一个使得$J(\theta_{0}, \theta_{1})$最小的点。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424993676.png" alt="enter description here"></p><p>通过这些图形，我希望你能更好地理解这些代价函数$ J$所表达的值是什么样的，它们对应的假设是什么样的，以及什么样的假设对应的点，更接近于代价函数$J$的最小值。</p><p>当然，我们真正需要的是一种有效的算法，能够自动地找出这些使代价函数$J$取最小值的参数$\theta_{0}$和$\theta_{1}$来。</p><p>我们也不希望编个程序把这些点画出来，然后人工的方法来读出这些点的数值，这很明显不是一个好办法。我们会遇到更复杂、更高维度、更多参数的情况，而这些情况是很难画出图的，因此更无法将其可视化，因此我们真正需要的是编写程序来找出这些最小化代价函数的$\theta_{0}$和$\theta_{1}$的值，在下一节视频中，我们将介绍一种算法，能够自动地找出能使代价函数$J$最小化的参数$\theta_{0}$和$\theta_{1}$的值。</p><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>参考视频: 2 - 5 - Gradient Descent (11 min).mkv<br>梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数$J(\theta_{0}, \theta_{1})$ 的最小值。</p><p>梯度下降背后的思想是：开始时我们随机选择一个参数的组合$\left( {\theta_{0} },{\theta_{1} },......,{\theta_{n} } \right)$，计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到找到一个局部最小值（<strong>local minimum</strong>），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（<strong>global minimum</strong>），选择不同的初始参数组合，可能会找到不同的局部最小值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429352272.png" alt="enter description here"></p><p>想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。</p><p>批量梯度下降（<strong>batch gradient descent</strong>）算法的公式为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429392028.png" alt="enter description here"></p><p>其中$a$是学习率（<strong>learning rate</strong>），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在<strong>批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数</strong>。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429400255.png" alt="enter description here"></p><p>在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新${\theta_{0} }$和${\theta_{1} }$ ，当 $j=0$ 和$j=1$时，会产生更新，所以你将更新$J\left( {\theta_{0} } \right)$和$J\left( {\theta_{1} } \right)$。实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新${\theta_{0} }$和${\theta_{1} }$，我的意思是在这个等式中，我们要这样更新：</p> ${\theta_{0} }$:= ${\theta_{0} }$ ，并更新${\theta_{1} }$:= ${\theta_{1} }$。<p>实现方法是：你应该计算公式右边的部分，通过那一部分计算出${\theta_{0} }$和${\theta_{1} }$的值，然后同时更新${\theta_{0} }$和${\theta_{1} }$。</p><p>让我进一步阐述这个过程：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429409440.png" alt="enter description here"></p><p>在梯度下降算法中，这是正确实现同时更新的方法。我不打算解释为什么你需要同时更新，同时更新是梯度下降中的一种常用方法。我们之后会讲到，同步更新是更自然的实现方法。当人们谈到梯度下降时，他们的意思就是同步更新。</p><p>在接下来的视频中，我们要进入这个微分项的细节之中。我已经写了出来但没有真正定义，如果你已经修过微积分课程，如果你熟悉偏导数和导数，这其实就是这个微分项：</p> $\alpha \frac{\partial }{\partial { {\theta }_{0} }}J({ {\theta }_{0} },{ {\theta }_{1} })$，$\alpha \frac{\partial }{\partial { {\theta }_{1} }}J({ {\theta }_{0} },{ {\theta }_{1} })$。<p>如果你不熟悉微积分，不用担心，即使你之前没有看过微积分，或者没有接触过偏导数，在接下来的视频中，你会得到一切你需要知道，如何计算这个微分项的知识。</p><h3 id="梯度下降的直观理解"><a href="#梯度下降的直观理解" class="headerlink" title="梯度下降的直观理解"></a>梯度下降的直观理解</h3><p>参考视频: 2 - 6 - Gradient Descent Intuition (12 min).mkv<br>在之前的视频中，我们给出了一个数学上关于梯度下降的定义，本次视频我们更深入研究一下，更直观地感受一下这个算法是做什么的，以及梯度下降算法的更新过程有什么意义。梯度下降算法如下：</p> ${\theta_{j} }:={\theta_{j} }-\alpha \frac{\partial }{\partial {\theta_{j} }}J\left(\theta \right)$<p>描述：对$\theta $赋值，使得$J\left( \theta \right)$按梯度下降最快方向进行，一直迭代下去，最终得到局部最小值。其中$a$是学习率（<strong>learning rate</strong>），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429686477.png" alt="enter description here"></p><p>对于这个问题，求导的目的，基本上可以说取这个红点的切线，就是这样一条红色的直线，刚好与函数相切于这一点，让我们看看这条红色直线的斜率，就是这条刚好与函数曲线相切的这条直线，这条直线的斜率正好是这个三角形的高度除以这个水平长度，现在，这条线有一个正斜率，也就是说它有正导数，因此，我得到的新的${\theta_{1} }$，${\theta_{1} }$更新后等于${\theta_{1} }$减去一个正数乘以$a$。</p><p>这就是我梯度下降法的更新规则：${\theta_{j} }:={\theta_{j} }-\alpha \frac{\partial }{\partial {\theta_{j} }}J\left( \theta \right)$</p><p>让我们来看看如果$a$太小或$a$太大会出现什么情况：</p><p>如果$a$太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果$a$太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。</p><p>如果$a$太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果$a$太大，它会导致无法收敛，甚至发散。</p><p>现在，我还有一个问题，当我第一次学习这个地方时，我花了很长一段时间才理解这个问题，如果我们预先把${\theta_{1} }$放在一个局部的最低点，你认为下一步梯度下降法会怎样工作？</p><p>假设你将${\theta_{1} }$初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得${\theta_{1} }$不再改变，也就是新的${\theta_{1} }$等于原来的${\theta_{1} }$，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率$a$保持不变时，梯度下降也可以收敛到局部最低点。</p><p>我们来看一个例子，这是代价函数$J\left( \theta \right)$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429854299.png" alt="enter description here"></p><p>我想找到它的最小值，首先初始化我的梯度下降算法，在那个品红色的点初始化，如果我更新一步梯度下降，也许它会带我到这个点，因为这个点的导数是相当陡的。现在，在这个绿色的点，如果我再更新一步，你会发现我的导数，也即斜率，是没那么陡的。随着我接近最低点，我的导数越来越接近零，所以，梯度下降一步后，新的导数会变小一点点。然后我想再梯度下降一步，在这个绿点，我自然会用一个稍微跟刚才在那个品红点时比，再小一点的一步，到了新的红色点，更接近全局最低点了，因此这点的导数会比在绿点时更小。所以，我再进行一步梯度下降时，我的导数项是更小的，${\theta_{1} }$更新的幅度就会更小。所以随着梯度下降法的运行，你移动的幅度会自动变得越来越小，直到最终移动幅度非常小，你会发现，已经收敛到局部极小值。</p><p>回顾一下，在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小$a$。</p><p>这就是梯度下降算法，你可以用它来最小化任何代价函数$J$，不只是线性回归中的代价函数$J$。</p><p>在接下来的视频中，我们要用代价函数$J$，回到它的本质，线性回归中的代价函数。也就是我们前面得出的平方误差函数，结合梯度下降法，以及平方代价函数，我们会得出第一个机器学习算法，即线性回归算法。</p><h3 id="梯度下降的线性回归"><a href="#梯度下降的线性回归" class="headerlink" title="梯度下降的线性回归"></a>梯度下降的线性回归</h3><p>参考视频: 2 - 7 - GradientDescentForLinearRegression (6 min).mkv<br>在以前的视频中我们谈到关于梯度下降算法，梯度下降是很常用的算法，它不仅被用在线性回归上和线性回归模型、平方误差代价函数。在这段视频中，我们要将梯度下降和代价函数结合。我们将用到此算法，并将其应用于具体的拟合直线的线性回归算法里。</p><p>梯度下降算法和线性回归算法比较如图：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575430060807.png" alt="enter description here"></p><p>对我们之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数，即：</p> $h_\theta \left( x \right)=\theta_{0} + \theta_{1}x$ $\frac{\partial }{\partial { {\theta }_{j} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{\partial }{\partial { {\theta }_{j} }}\frac{1}{2m}{ {\sum\limits_{i=1}^{m}{\left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)} }^{2} }$ $j=0$ 时：$\frac{\partial }{\partial { {\theta }_{0} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{1}{m}{ {\sum\limits_{i=1}^{m}{\left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)} }}$ $j=1$ 时：$\frac{\partial }{\partial { {\theta }_{1} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)\cdot { {x}^{(i)} } \right)}$<p>则算法改写成：</p><p><strong>Repeat {</strong></p><p>​ ${\theta_{0} }:={\theta_{0} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{ \left({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)}$</p><p>​ ${\theta_{1} }:={\theta_{1} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)\cdot { {x}^{(i)} } \right)}$</p><p>​ <strong>}</strong></p><p>我们刚刚使用的算法，有时也称为批量梯度下降。实际上，在机器学习中，通常不太会给算法起名字，但这个名字”<strong>批量梯度下降</strong>”，指的是在梯度下降的每一步中，我们都用到了所有的训练样本，在梯度下降中，在计算微分求导项时，我们需要进行求和运算，所以，在每一个单独的梯度下降中，我们最终都要计算这样一个东西，这个项需要对所有$m$个训练样本求和。因此，批量梯度下降法这个名字说明了我们需要考虑所有这一”批”训练样本，而事实上，有时也有其他类型的梯度下降法，不是这种”批量”型的，不考虑整个的训练集，而是每次只关注训练集中的一些小的子集。在后面的课程中，我们也将介绍这些方法。</p><p>但就目前而言，应用刚刚学到的算法，你应该已经掌握了批量梯度算法，并且能把它应用到线性回归中了，这就是用于线性回归的梯度下降法。</p><p>如果你之前学过线性代数，有些同学之前可能已经学过高等线性代数，你应该知道有一种计算代价函数$J$最小值的数值解法，不需要梯度下降这种迭代算法。在后面的课程中，我们也会谈到这个方法，它可以在不需要多步梯度下降的情况下，也能解出代价函数$J$的最小值，这是另一种称为正规方程(<strong>normal equations</strong>)的方法。实际上在数据量较大的情况下，梯度下降法比正规方程要更适用一些。</p><p>现在我们已经掌握了梯度下降，我们可以在不同的环境中使用梯度下降法，我们还将在不同的机器学习问题中大量地使用它。所以，祝贺大家成功学会你的第一个机器学习算法。</p><p>在下一段视频中，告诉你泛化的梯度下降算法，这将使梯度下降更加强大。</p><h3 id="接下来的内容"><a href="#接下来的内容" class="headerlink" title="接下来的内容"></a>接下来的内容</h3><p>参考视频: 2 - 8 - What_’s Next (6 min).mkv<br>在接下来的一组视频中，我会对线性代数进行一个快速的复习回顾。如果你从来没有接触过向量和矩阵，那么这课件上所有的一切对你来说都是新知识，或者你之前对线性代数有所了解，但由于隔得久了，对其有所遗忘，那就请学习接下来的一组视频，我会快速地回顾你将用到的线性代数知识。</p><p>通过它们，你可以实现和使用更强大的线性回归模型。事实上，线性代数不仅仅在线性回归中应用广泛，它其中的矩阵和向量将有助于帮助我们实现之后更多的机器学习模型，并在计算上更有效率。正是因为这些矩阵和向量提供了一种有效的方式来组织大量的数据，特别是当我们处理巨大的训练集时，如果你不熟悉线性代数，如果你觉得线性代数看上去是一个复杂、可怕的概念，特别是对于之前从未接触过它的人，不必担心，事实上，为了实现机器学习算法，我们只需要一些非常非常基础的线性代数知识。通过接下来几个视频，你可以很快地学会所有你需要了解的线性代数知识。具体来说，为了帮助你判断是否有需要学习接下来的一组视频，我会讨论什么是矩阵和向量，谈谈如何加、减 、乘矩阵和向量，讨论逆矩阵和转置矩阵的概念。</p><p>如果你十分熟悉这些概念，那么你完全可以跳过这组关于线性代数的选修视频，但是如果你对这些概念仍有些许的不确定，不确定这些数字或这些矩阵的意思，那么请看一看下一组的视频，它会很快地教你一些你需要知道的线性代数的知识，便于之后编写机器学习算法和处理大量数据。</p><h2 id="线性代数回顾-Linear-Algebra-Review"><a href="#线性代数回顾-Linear-Algebra-Review" class="headerlink" title="线性代数回顾(Linear Algebra Review)"></a>线性代数回顾(Linear Algebra Review)</h2><h3 id="矩阵和向量"><a href="#矩阵和向量" class="headerlink" title="矩阵和向量"></a>矩阵和向量</h3><p>参考视频: 3 - 1 - Matrices and Vectors (9 min).mkv<br>如图：这个是4×2矩阵，即4行2列，如$m$为行，$n$为列，那么$m×n$即4×2</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575430214648.png" alt="enter description here"></p><p>矩阵的维数即行数×列数</p><p>矩阵元素（矩阵项）：$A=\left[ \begin{matrix} 1402 & 191 \\ 1371 & 821 \\ 949 & 1437 \\ 147 & 1448 \\\end{matrix} \right]$</p> $A_{ij}$指第$i$行，第$j$列的元素。<p>向量是一种特殊的矩阵，讲义中的向量一般都是列向量，如：</p> $y=\left[ \begin{matrix} {460} \\ {232} \\ {315} \\ {178} \\\end{matrix} \right]$<p>为四维列向量（4×1）。</p><p>如下图为1索引向量和0索引向量，左图为1索引向量，右图为0索引向量，一般我们用1索引向量。</p> $y=\left[ \begin{matrix} { {y}_{1} } \\ { {y}_{2} } \\ { {y}_{3} } \\ { {y}_{4} } \\\end{matrix} \right]$，$y=\left[ \begin{matrix} { {y}_{0} } \\ { {y}_{1} } \\ { {y}_{2} } \\ { {y}_{3} } \\\end{matrix} \right]$<h3 id="加法和标量乘法"><a href="#加法和标量乘法" class="headerlink" title="加法和标量乘法"></a>加法和标量乘法</h3><p>参考视频: 3 - 2 - Addition and Scalar Multiplication (7 min).mkv<br>矩阵的加法：行列数相等的可以加。</p><p>例：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431053908.png" alt="enter description here"></p><p>矩阵的乘法：每个元素都要乘</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431095812.png" alt="enter description here"></p><p>组合算法也类似。</p><h3 id="矩阵向量乘法"><a href="#矩阵向量乘法" class="headerlink" title="矩阵向量乘法"></a>矩阵向量乘法</h3><p>参考视频: 3 - 3 - Matrix Vector Multiplication (14 min).mkv</p><p>矩阵和向量的乘法如图：$m×n$的矩阵乘以$n×1$的向量，得到的是$m×1$的向量</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431123683.png" alt="enter description here"></p><p>算法举例：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431133404.png" alt="enter description here"></p><h3 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h3><p>参考视频: 3 - 4 - Matrix Matrix Multiplication (11 min).mkv<br>矩阵乘法：</p> $m×n$矩阵乘以$n×o$矩阵，变成$m×o$矩阵。<p>如果这样说不好理解的话就举一个例子来说明一下，比如说现在有两个矩阵$A$和$B$，那么它们的乘积就可以表示为图中所示的形式。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431168523.png" alt="enter description here"></p><h3 id="矩阵乘法的性质"><a href="#矩阵乘法的性质" class="headerlink" title="矩阵乘法的性质"></a>矩阵乘法的性质</h3><p>参考视频: 3 - 5 - Matrix Multiplication Properties (9 min).mkv<br>矩阵乘法的性质：</p><p>矩阵的乘法不满足交换律：$A×B≠B×A$</p><p>矩阵的乘法满足结合律。即：$A×(B×C)=(A×B)×C$</p><p>单位矩阵：在矩阵的乘法中，有一种矩阵起着特殊的作用，如同数的乘法中的1,我们称这种矩阵为单位矩阵．它是个方阵，一般用 $I$ 或者 $E$ 表示，本讲义都用 $I$ 代表单位矩阵，从左上角到右下角的对角线（称为主对角线）上的元素均为1以外全都为0。如：</p> $A{ {A}^{-1} }={ {A}^{-1} }A=I$<p>对于单位矩阵，有$AI=IA=A$</p><h3 id="逆、转置"><a href="#逆、转置" class="headerlink" title="逆、转置"></a>逆、转置</h3><p>参考视频: 3 - 6 - Inverse and Transpose (11 min).mkv<br>矩阵的逆：如矩阵$A$是一个$m×m$矩阵（方阵），如果有逆矩阵，则：$A{ {A}^{-1} }={ {A}^{-1} }A=I$</p><p>我们一般在<strong>OCTAVE</strong>或者<strong>MATLAB</strong>中进行计算矩阵的逆矩阵。</p><p>矩阵的转置：设$A$为$m×n$阶矩阵（即$m$行$n$列），第$i $行$j $列的元素是$a(i,j)$，即：$A=a(i,j)$</p><p>定义$A$的转置为这样一个$n×m$阶矩阵$B$，满足$B=a(j,i)$，即 $b (i,j)=a(j,i)$（$B$的第$i$行第$j$列元素是$A$的第$j$行第$i$列元素），记${ {A}^{T} }=B$。(有些书记为A’=B）</p><p>直观来看，将$A$的所有元素绕着一条从第1行第1列元素出发的右下方45度的射线作镜面反转，即得到$A$的转置。</p><p>例：</p> ${ {\left| \begin{matrix} a& b \\ c& d \\ e& f \\\end{matrix} \right|}^{T} }=\left|\begin{matrix} a& c & e \\ b& d & f \\\end{matrix} \right|$<p>矩阵的转置基本性质:</p> $ { {\left( A\pm B \right)}^{T} }={ {A}^{T} }\pm { {B}^{T} } $ ${ {\left( A\times B \right)}^{T} }={ {B}^{T} }\times { {A}^{T} }$ ${ {\left( { {A}^{T} } \right)}^{T} }=A $ ${ {\left( KA \right)}^{T} }=K{ {A}^{T} } $<p><strong>matlab</strong>中矩阵转置：直接打一撇，<code>x=y&#39;</code>。</p><h2 id="多变量线性回归-Linear-Regression-with-Multiple-Variables"><a href="#多变量线性回归-Linear-Regression-with-Multiple-Variables" class="headerlink" title="多变量线性回归(Linear Regression with Multiple Variables)"></a>多变量线性回归(Linear Regression with Multiple Variables)</h2><h3 id="多维特征"><a href="#多维特征" class="headerlink" title="多维特征"></a>多维特征</h3><p>参考视频: 4 - 1 - Multiple Features (8 min).mkv<br>目前为止，我们探讨了单变量/特征的回归模型，现在我们对房价模型增加更多的特征，例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为$\left( {x_{1} },{x_{2} },...,{x_{n} } \right)$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431645491.png" alt="enter description here"></p><p>增添更多特征后，我们引入一系列新的注释：</p> $n$ 代表特征的数量 ${x^{\left( i \right)} }$代表第 $i$ 个训练实例，是特征矩阵中的第$i$行，是一个**向量**（**vector**）。<p>比方说，上图的</p> ${x}^{(2)}\text{=}\begin{bmatrix} 1416\\\ 3\\\ 2\\\ 40 \end{bmatrix}$， ${x}_{j}^{\left( i \right)}$代表特征矩阵中第 $i$ 行的第 $j$ 个特征，也就是第 $i$ 个训练实例的第 $j$ 个特征。<p>如上图的$x_{2}^{\left( 2 \right)}=3,x_{3}^{\left( 2 \right)}=2$，</p><p>支持多变量的假设 $h$ 表示为：$h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$，</p><p>这个公式中有$n+1$个参数和$n$个变量，为了使得公式能够简化一些，引入$x_{0}=1$，则公式转化为：$h_{\theta} \left( x \right)={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$</p><p>此时模型中的参数是一个$n+1$维的向量，任何一个训练实例也都是$n+1$维的向量，特征矩阵$X$的维度是 $m*(n+1)$。 因此公式可以简化为：$h_{\theta} \left( x \right)={\theta^{T} }X$，其中上标$T$代表矩阵转置。</p><h3 id="多变量梯度下降"><a href="#多变量梯度下降" class="headerlink" title="多变量梯度下降"></a>多变量梯度下降</h3><p>参考视频: 4 - 2 - Gradient Descent for Multiple Variables (5 min).mkv<br>与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：$J\left( {\theta_{0} },{\theta_{1} }...{\theta_{n} } \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( h_{\theta} \left({x}^{\left( i \right)} \right)-{y}^{\left( i \right)} \right)}^{2} }}$ ，</p><p>其中：$h_{\theta}\left( x \right)=\theta^{T}X={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ ，</p><p>我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。<br>多变量线性回归的批量梯度下降算法为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431758447.png" alt="enter description here"></p><p>即：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431766568.png" alt="enter description here"></p><p>求导数后得到：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431781513.png" alt="enter description here"></p><p>当$n>=1$时，</p> ${ {\theta }_{0} }:={ {\theta }_{0} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{0}^{(i)}$ ${ {\theta }_{1} }:={ {\theta }_{1} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{1}^{(i)}$ ${ {\theta }_{2} }:={ {\theta }_{2} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{2}^{(i)}$<p>我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。</p><p>代码示例：</p><p>计算代价函数</p> $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( {h_{\theta} }\left( {x^{(i)} } \right)-{y^{(i)} } \right)}^{2} }}$<p>其中：${h_{\theta} }\left( x \right)={\theta^{T} }X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$</p><p><strong>Python</strong> 代码：</p><pre><code class="python">def computeCost(X, y, theta):
inner = np.power(((X * theta.T) - y), 2)
return np.sum(inner) / (2 * len(X))</code></pre><h3 id="梯度下降法实践1-特征缩放"><a href="#梯度下降法实践1-特征缩放" class="headerlink" title="梯度下降法实践1-特征缩放"></a>梯度下降法实践1-特征缩放</h3><p>参考视频: 4 - 3 - Gradient Descent in Practice I - Feature Scaling (9 min).mkv</p><p>在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。</p><p>以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431844502.png" alt="enter description here"></p><p>解决的方法是尝试<strong>将所有特征的尺度都尽量缩放到-1到1之间</strong>。如图：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431851977.png" alt="enter description here"></p><p>最简单的方法是令：${ {x}_{n} }=\frac{ {{x}_{n} }-{ {\mu}_{n} }}{ {{s}_{n} }}$，其中 ${\mu_{n} }$是平均值，${s_{n} }$是标准差。</p><h3 id="梯度下降法实践2-学习率"><a href="#梯度下降法实践2-学习率" class="headerlink" title="梯度下降法实践2-学习率"></a>梯度下降法实践2-学习率</h3><p>参考视频: 4 - 4 - Gradient Descent in Practice II - Learning Rate (9 min).mkv<br>梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431866164.png" alt="enter description here"></p><p>也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看上面这样的图表更好。</p><p>梯度下降算法的每次迭代受到学习率的影响，如果学习率$a$过小，则达到收敛所需的迭代次数会非常高；如果学习率$a$过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。</p><p>通常可以考虑尝试些学习率：</p> $\alpha=0.01，0.03，0.1，0.3，1，3，10$<h3 id="特征和多项式回归"><a href="#特征和多项式回归" class="headerlink" title="特征和多项式回归"></a>特征和多项式回归</h3><p>参考视频: 4 - 5 - Features and Polynomial Regression (8 min).mkv</p><p>如房价预测问题，</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431954385.png" alt="enter description here"></p> $h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }\times{frontage}+{\theta_{2} }\times{depth}$ ${x_{1} }=frontage$（临街宽度），${x_{2} }=depth$（纵向深度），$x=frontage*depth=area$（面积），则：${h_{\theta} }\left( x \right)={\theta_{0} }+{\theta_{1} }x$。<p>线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型：$h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}$<br>或者三次方模型： $h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}+{\theta_{3} }{x_{3}^3}$</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432002700.png" alt="enter description here"></p><p>通常我们需要先观察数据然后再决定准备尝试怎样的模型。 另外，我们可以令：</p> ${ {x}_{2} }=x_{2}^{2},{ {x}_{3} }=x_{3}^{3}$，从而将模型转化为线性回归模型。<p>根据函数图形特性，我们还可以使：</p> ${ {{h} }_{\theta} }(x)={ {\theta }_{0} }\text{+}{ {\theta }_{1} }(size)+{ {\theta}_{2} }{ {(size)}^{2} }$<p>或者:</p> ${ {{h} }_{\theta} }(x)={ {\theta }_{0} }\text{+}{ {\theta }_{1} }(size)+{ {\theta }_{2} }\sqrt{size}$<p>注：<strong>如果我们采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要</strong>。</p><h3 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h3><p>参考视频: 4 - 6 - Normal Equation (16 min).mkv<br>到目前为止，我们都在使用梯度下降算法，但是对于某些线性回归问题，正规方程方法是更好的解决方案。如：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432364923.png" alt="enter description here"></p><p>正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：$\frac{\partial}{\partial{\theta_{j} }}J\left( {\theta_{j} } \right)=0$ 。<br>假设我们的训练集特征矩阵为 $X$（包含了 ${ {x}_{0} }=1$）并且我们的训练集结果为向量 $y$，则利用正规方程解出向量 $\theta ={ {\left( {X^T}X \right)}^{-1} }{X^{T} }y$ 。<br>上标 <strong>T</strong> 代表矩阵转置，上标-1 代表矩阵的逆。设矩阵$A={X^{T} }X$，则：${ {\left( {X^T}X \right)}^{-1} }={A^{-1} }$<br>以下表示数据为例：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432408169.png" alt="enter description here"></p><p>即：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432413948.png" alt="enter description here"></p><p>运用正规方程方法求解参数：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432420036.png" alt="enter description here"></p><p>在 <strong>Octave</strong> 中，正规方程写作：</p><pre><code>pinv(X&#39;*X)*X&#39;*y</code></pre><p>注：对于那些不可逆的矩阵（通常是因为特征之间不独立，如同时包含英尺为单位的尺寸和米为单位的尺寸两个特征，也有可能是特征数量大于训练集的数量），正规方程方法是不能用的。</p><p>梯度下降与正规方程的比较：</p><table><thead><tr><th>梯度下降</th><th>正规方程</th></tr></thead><tbody><tr><td>需要选择学习率{% raw %}$\alpha${% endraw %}</td><td>不需要</td></tr><tr><td>需要多次迭代</td><td>一次运算得出</td></tr><tr><td>当特征数量{% raw %}$n${% endraw %}大时也能较好适用</td><td>需要计算{% raw %}${ {\left( { {X}^{T} }X \right)}^{-1} }${% endraw %} 如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为{% raw %}$O\left( { {n}^{3} } \right)${% endraw %}，通常来说当{% raw %}$n${% endraw %}小于10000 时还是可以接受的</td></tr><tr><td>适用于各种类型的模型</td><td>只适用于线性模型，不适合逻辑回归模型等其他模型</td></tr></tbody></table><p>总结一下，只要特征变量的数目并不大，标准方程是一个很好的计算参数{% raw %}$\theta ${% endraw %}的替代方法。具体地说，只要特征变量数量小于一万，我通常使用标准方程法，而不使用梯度下降法。</p><p>随着我们要讲的学习算法越来越复杂，例如，当我们讲到分类算法，像逻辑回归算法，我们会看到，实际上对于那些算法，并不能使用标准方程法。对于那些更复杂的学习算法，我们将不得不仍然使用梯度下降法。因此，梯度下降法是一个非常有用的算法，可以用在有大量特征变量的线性回归问题。或者我们以后在课程中，会讲到的一些其他的算法，因为标准方程法不适合或者不能用在它们上。但对于这个特定的线性回归模型，标准方程法是一个比梯度下降法更快的替代算法。所以，根据具体的问题，以及你的特征变量的数量，这两种算法都是值得学习的。</p><p>正规方程的<strong>python</strong>实现：</p><pre><code class="python">import numpy as np

def normalEqn(X, y):

theta = np.linalg.inv(X.T@X)@X.T@y #X.T@X等价于X.T.dot(X)

return theta</code></pre><h3 id="正规方程及不可逆性（可选）"><a href="#正规方程及不可逆性（可选）" class="headerlink" title="正规方程及不可逆性（可选）"></a>正规方程及不可逆性（可选）</h3><p>参考视频: 4 - 7 - Normal Equation Noninvertibility (Optional) (6 min).mkv<br>在这段视频中谈谈正规方程 ( <strong>normal equation</strong> )，以及它们的不可逆性。<br>由于这是一种较为深入的概念，并且总有人问我有关这方面的问题，因此，我想在这里来讨论它，由于概念较为深入，所以对这段可选材料大家放轻松吧，也许你可能会深入地探索下去，并且会觉得理解以后会非常有用。但即使你没有理解正规方程和线性回归的关系，也没有关系。</p><p>我们要讲的问题如下：$\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$</p><p>备注：本节最后我把推导过程写下。</p><p>有些同学曾经问过我，当计算 $\theta$=<code>inv(X&#39;X ) X&#39;y</code> ，那对于矩阵$X'X$的结果是不可逆的情况咋办呢?<br>如果你懂一点线性代数的知识，你或许会知道，有些矩阵可逆，而有些矩阵不可逆。我们称那些不可逆矩阵为奇异或退化矩阵。<br>问题的重点在于$X'X$的不可逆的问题很少发生，在<strong>Octave</strong>里，如果你用它来实现$\theta$的计算，你将会得到一个正常的解。在<strong>Octave</strong>里，有两个函数可以求解矩阵的逆，一个被称为<code>pinv()</code>，另一个是<code>inv()</code>，这两者之间的差异是些许计算过程上的，一个是所谓的伪逆，另一个被称为逆。使用<code>pinv()</code> 函数可以展现数学上的过程，这将计算出$\theta$的值，即便矩阵$X'X$是不可逆的。</p><p>在<code>pinv()</code> 和 <code>inv()</code> 之间，又有哪些具体区别呢 ?</p><p>其中<code>inv()</code> 引入了先进的数值计算的概念。例如，在预测住房价格时，如果${x_{1} }$是以英尺为尺寸规格计算的房子，${x_{2} }$是以平方米为尺寸规格计算的房子，同时，你也知道1米等于3.28英尺 ( 四舍五入到两位小数 )，这样，你的这两个特征值将始终满足约束：${x_{1} }={x_{2} }*{ {\left( 3.28 \right)}^{2} }$。<br>实际上，你可以用这样的一个线性方程，来展示那两个相关联的特征值，矩阵$X'X$将是不可逆的。</p><p>第二个原因是，在你想用大量的特征值，尝试实践你的学习算法的时候，可能会导致矩阵$X'X$的结果是不可逆的。<br>具体地说，在$m$小于或等于n的时候，例如，有$m$等于10个的训练样本也有$n$等于100的特征数量。要找到适合的$(n +1)$ 维参数矢量$\theta$，这将会变成一个101维的矢量，尝试从10个训练样本中找到满足101个参数的值，这工作可能会让你花上一阵子时间，但这并不总是一个好主意。因为，正如我们所看到你只有10个样本，以适应这100或101个参数，数据还是有些少。</p><p>稍后我们将看到，如何使用小数据样本以得到这100或101个参数，通常，我们会使用一种叫做正则化的线性代数方法，通过删除某些特征或者是使用某些技术，来解决当$m$比$n$小的时候的问题。即使你有一个相对较小的训练集，也可使用很多的特征来找到很多合适的参数。<br>总之当你发现的矩阵$X'X$的结果是奇异矩阵，或者找到的其它矩阵是不可逆的，我会建议你这么做。</p><p>首先，看特征值里是否有一些多余的特征，像这些${x_{1} }$和${x_{2} }$是线性相关的，互为线性函数。同时，当有一些多余的特征时，可以删除这两个重复特征里的其中一个，无须两个特征同时保留，将解决不可逆性的问题。因此，首先应该通过观察所有特征检查是否有多余的特征，如果有多余的就删除掉，直到他们不再是多余的为止，如果特征数量实在太多，我会删除些 用较少的特征来反映尽可能多内容，否则我会考虑使用正规化方法。<br>如果矩阵$X'X$是不可逆的，（通常来说，不会出现这种情况），如果在<strong>Octave</strong>里，可以用伪逆函数<code>pinv()</code> 来实现。这种使用不同的线性代数库的方法被称为伪逆。即使$X'X$的结果是不可逆的，但算法执行的流程是正确的。总之，出现不可逆矩阵的情况极少发生，所以在大多数实现线性回归中，出现不可逆的问题不应该过多的关注${X^{T} }X$是不可逆的。</p><p><strong>增加内容：</strong></p> $\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$ 的推导过程： $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( {h_{\theta} }\left( {x^{(i)} } \right)-{y^{(i)} } \right)}^{2} }}$<p>其中：${h_{\theta} }\left( x \right)={\theta^{T} }X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$</p><p>将向量表达形式转为矩阵表达形式，则有$J(\theta )=\frac{1}{2}{ {\left( X\theta -y\right)}^{2} }$ ，其中$X$为$m$行$n$列的矩阵（$m$为样本个数，$n$为特征个数），$\theta$为$n$行1列的矩阵，$y$为$m$行1列的矩阵，对$J(\theta )$进行如下变换</p> $J(\theta )=\frac{1}{2}{ {\left( X\theta -y\right)}^{T} }\left( X\theta -y \right)$<p>​ $=\frac{1}{2}\left( { {\theta }^{T} }{ {X}^{T} }-{ {y}^{T} } \right)\left(X\theta -y \right)$</p><p>​ $=\frac{1}{2}\left( { {\theta }^{T} }{ {X}^{T} }X\theta -{ {\theta}^{T} }{ {X}^{T} }y-{ {y}^{T} }X\theta -{ {y}^{T} }y \right)$</p><p>接下来对$J(\theta )$偏导，需要用到以下几个矩阵的求导法则:</p> $\frac{dAB}{dB}={ {A}^{T} }$ $\frac{d{ {X}^{T} }AX}{dX}=2AX$<p>所以有:</p> $\frac{\partial J\left( \theta \right)}{\partial \theta }=\frac{1}{2}\left(2{ {X}^{T} }X\theta -{ {X}^{T} }y -{}({ {y}^{T} }X )^{T}-0 \right)$ $=\frac{1}{2}\left(2{ {X}^{T} }X\theta -{ {X}^{T} }y -{ {X}^{T} }y -0 \right)$<p>​ $={ {X}^{T} }X\theta -{ {X}^{T} }y$</p><p>令$\frac{\partial J\left( \theta \right)}{\partial \theta }=0$,</p><p>则有$\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$</p><h2 id="Octave教程-Octave-Tutorial"><a href="#Octave教程-Octave-Tutorial" class="headerlink" title="Octave教程(Octave Tutorial)"></a>Octave教程(Octave Tutorial)</h2><h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><p>参考视频: 5 - 1 - Basic Operations (14 min).mkv</p><p>在这段视频中，我将教你一种编程语言：<strong>Octave</strong>语言。你能够用它来非常迅速地实现这门课中我们已经学过的，或者将要学的机器学习算法。</p><p>过去我一直尝试用不同的编程语言来教授机器学习，包括<strong>C++</strong>、<strong>Java</strong>、<strong>Python</strong>、<strong>Numpy</strong>和<strong>Octave</strong>。我发现当使用像<strong>Octave</strong>这样的高级语言时，学生能够更快更好地学习并掌握这些算法。事实上，在硅谷，我经常看到进行大规模的机器学习项目的人，通常使用的程序语言就是<strong>Octave</strong>。(编者注：这是当时的情况，现在主要是用<strong>Python</strong>)</p><p><strong>Octave</strong>是一种很好的原始语言(<strong>prototyping language</strong>)，使用<strong>Octave</strong>你能快速地实现你的算法，剩下的事情，你只需要进行大规模的资源配置，你只用再花时间用<strong>C++</strong>或<strong>Java</strong>这些语言把算法重新实现就行了。开发项目的时间是很宝贵的，机器学习的时间也是很宝贵的。所以，如果你能让你的学习算法在<strong>Octave</strong>上快速的实现，基本的想法实现以后，再用<strong>C++</strong>或者<strong>Java</strong>去改写，这样你就能节省出大量的时间。</p><p>据我所见，人们使用最多的用于机器学习的原始语言是<strong>Octave</strong>、<strong>MATLAB</strong>、<strong>Python</strong>、<strong>NumPy</strong> 和<strong>R</strong>。</p><p><strong>Octave</strong>很好，因为它是开源的。当然<strong>MATLAB</strong>也很好，但它不是每个人都买得起的。(貌似国内学生喜欢用收费的<strong>matlab</strong>，<strong>matlab</strong>功能要比<strong>Octave</strong>强大的多，网上有各种<strong>D</strong>版可以下载)。这次机器学习课的作业也是用<strong>matlab</strong>的。如果你能够使用<strong>matlab</strong>，你也可以在这门课里面使用。</p><p>如果你会<strong>Python</strong>、<strong>NumPy</strong>或者<strong>R</strong>语言，我也见过有人用 <strong>R</strong>的，据我所知，这些人不得不中途放弃了，因为这些语言在开发上比较慢，而且，因为这些语言如：<strong>Python</strong>、<strong>NumPy</strong>的语法相较于<strong>Octave</strong>来说，还是更麻烦一点。正因为这样，所以我强烈建议不要用<strong>NumPy</strong>或者<strong>R</strong>来完整这门课的作业，我建议在这门课中用<strong>Octave</strong>来写程序。</p><p>本视频将快速地介绍一系列的命令，目标是迅速地展示，通过这一系列<strong>Octave</strong>的命令，让你知道<strong>Octave</strong>能用来做什么。</p><p>启动<strong>Octave</strong>：</p><p>现在打开<strong>Octave</strong>，这是<strong>Octave</strong>命令行。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e2c2dcc31f19ac255566fa616799d496.png" alt="e2c2dcc31f19ac255566fa616799d496"></p><p>现在让我示范最基本的<strong>Octave</strong>代码：</p><p>输入5 + 6，然后得到11。</p><p>输入3 – 2、5×8、1/2、2^6等等，得到相应答案。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6dcdf4a7c0d56787648d4a1902034150.png" alt="6dcdf4a7c0d56787648d4a1902034150"></p><p>这些都是基本的数学运算。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8507899953ed2de68e6b2b83554f9ea.png" alt="f8507899953ed2de68e6b2b83554f9ea"><br>你也可以做逻辑运算，例如 1==2，计算结果为 <strong>false</strong> (<strong>假</strong>)，这里的百分号命令表示注释，1==2 计算结果为假，这里用0表示。</p><p>请注意，不等于符号的写法是这个波浪线加上等于符号 ( ~= )，而不是等于感叹号加等号( != )，这是和其他一些编程语言中不太一样的地方。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/126b2a5c4b5bfb24e5c21cd080159530.png" alt="126b2a5c4b5bfb24e5c21cd080159530"><br>让我们看看逻辑运算 1 &amp;&amp; 0，使用双&amp;符号表示逻辑与，1 &amp;&amp; 0判断为假，1和0的或运算 1 || 0，其计算结果为真。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fec0936e2a78c0fe8c9e3ed107614a31.png" alt="fec0936e2a78c0fe8c9e3ed107614a31"><br>还有异或运算 如<code>XOR ( 1, 0 )</code>，其返回值为1</p><p>从左向右写着 <strong>Octave 324.x</strong>版本，是默认的<strong>Octave</strong>提示，它显示了当前<strong>Octave</strong>的版本，以及相关的其它信息。</p><p>如果你不想看到那个提示，这里有一个隐藏的命令：</p><p>输入命令</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8d63fe546c12a7e9eb658118d76288f7.png" alt="8d63fe546c12a7e9eb658118d76288f7"><br>现在命令提示已经变得简化了。</p><p>接下来，我们将谈到<strong>Octave</strong>的变量。</p><p>现在写一个变量，对变量$A$赋值为3，并按下回车键，显示变量$A$等于3。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a537df35ccc9ff83a3c7518362e2f729.png" alt="a537df35ccc9ff83a3c7518362e2f729"><br>如果你想分配一个变量，但不希望在屏幕上显示结果，你可以在命令后加一个分号，可以抑制打印输出，敲入回车后，不打印任何东西。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c11786828c587189891a9ef02f041ab7.png" alt="c11786828c587189891a9ef02f041ab7"><br>其中这句命令不打印任何东西。</p><p>现在举一个字符串的例子：变量$b$等于”<strong>hi</strong>“。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4b67374499c0d38ed8670ba74ff892d0.png" alt="4b67374499c0d38ed8670ba74ff892d0"></p> $c$等于3大于等于1，所以，现在$c$变量的值是真。<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/acedf91b6b39d551e62a89f2e0955628.png" alt="acedf91b6b39d551e62a89f2e0955628"><br>如果你想打印出变量，或显示一个变量，你可以像下面这么做：</p><p>设置$a$等于圆周率$π$，如果我要打印该值，那么只需键入<code>a</code>像这样 就打印出来了。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2cdc09b8bf67e546df7284ba74601c66.png" alt="2cdc09b8bf67e546df7284ba74601c66"><br>对于更复杂的屏幕输出，也可以用<strong>DISP</strong>命令显示：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dfcd1d37526824726d85a655f8951249.png" alt="dfcd1d37526824726d85a655f8951249"><br>这是一种，旧风格的<strong>C语言</strong>语法，对于之前就学过<strong>C语言</strong>的同学来说，你可以使用这种基本的语法来将结果打印到屏幕。</p><p>例如 ^{T}命令的六个小数：0.6%f ,a，这应该打印$π$的6位小数形式。</p><p>也有一些控制输出长短格式的快捷命令：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ba8f0c3d2d8f017e0f7a611aa5be75d6.png" alt="ba8f0c3d2d8f017e0f7a611aa5be75d6"><br>下面，让我们来看看向量和矩阵：</p><p>比方说 建立一个矩阵$A$：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/693ebb444501838dd9b69520fff54be0.png" alt="693ebb444501838dd9b69520fff54be0"><br>对$A$矩阵进行赋值，考虑到这是一个三行两列的矩阵，你同样可以用向量。</p><p>建立向量$V$并赋值1 2 3，$V$是一个行向量，或者说是一个3 ( 列 )×1 ( 行 )的向量，或者说，一行三列的矩阵。</p><p>如果我想，分配一个列向量，我可以写“1;2;3”，现在便有了一个3 行 1 列的向量，同时这是一个列向量。</p><p>下面是一些更为有用的符号，如：</p><pre><code class="matlab">V=1：0.1：2</code></pre><p>这个该如何理解呢：这个集合{% raw %}$v${% endraw %}是一组值，从数值1开始，增量或说是步长为0.1，直到增加到2，按照这样的方法对向量{% raw %}$V${% endraw %}操作，可以得到一个行向量，这是一个1行11列的矩阵，其矩阵的元素是1<br>1.1 1.2 1.3，依此类推，直到数值2。</p><p>我也可以建立一个集合{% raw %}$v${% endraw %}并用命令“1:6”进行赋值，这样{% raw %}$V${% endraw %}就被赋值了1至6的六个整数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1cdbd87db83a4184098cd6d5ee3c6a87.png" alt="1cdbd87db83a4184098cd6d5ee3c6a87"><br>这里还有一些其他的方法来生成矩阵</p><p>例如“<code>ones(2, 3)</code>”，也可以用来生成矩阵：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5d2b25d4078a276091b9c00812674fa9.png" alt="5d2b25d4078a276091b9c00812674fa9"><br>元素都为2，两行三列的矩阵，就可以使用这个命令：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/21985f8690965598d4a17e3a6e7fee94.png" alt="21985f8690965598d4a17e3a6e7fee94"><br>你可以把这个方法当成一个生成矩阵的快速方法。</p> {% raw %}$w${% endraw %}为一个一行三列的零矩阵，一行三列的{% raw %}$A${% endraw %}矩阵里的元素全部是零：<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/846b48ec79c9fcee05b20767dcc89558.png" alt="846b48ec79c9fcee05b20767dcc89558"><br>还有很多的方式来生成矩阵。</p><p>如果我对{% raw %}$W${% endraw %}进行赋值，用<strong>Rand</strong>命令建立一个一行三列的矩阵，因为使用了<strong>Rand</strong>命令，则其一行三列的元素均为随机值，如“<code>rand(3,3)</code>”命令，这就生成了一个3×3的矩阵，并且其所有元素均为随机。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0de6e7054e869a82060cefa9968cd56b.png" alt="0de6e7054e869a82060cefa9968cd56b"><br>数值介于0和1之间，所以，正是因为这一点，我们可以得到数值均匀介于0和1之间的元素。</p><p>如果，你知道什么是高斯随机变量，或者，你知道什么是正态分布的随机变量，你可以设置集合{% raw %}$W${% endraw %}，使其等于一个一行三列的{% raw %}$N${% endraw %}矩阵，并且，来自三个值，一个平均值为0的高斯分布，方差或者等于1的标准偏差。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/048f3cac1c32e3dc56160849c4dd60b0.png" alt="048f3cac1c32e3dc56160849c4dd60b0"><br>还可以设置地更复杂：</p><p>并用<strong>hist</strong>命令绘制直方图。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/10c06cc39058da2c5eef696d75e65a2c.png" alt="10c06cc39058da2c5eef696d75e65a2c"><br>绘制单位矩阵：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08d11f870c5b30536f1965507fa7e7dc.png" alt="08d11f870c5b30536f1965507fa7e7dc"><br>如果对命令不清楚，建议用<strong>help</strong>命令：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/79b55d71cf434126f3d8457a3a615d18.png" alt="79b55d71cf434126f3d8457a3a615d18"><br>以上讲解的内容都是<strong>Octave</strong>的基本操作。希望你能通过上面的讲解，自己练习一些矩阵、乘、加等操作，将这些操作在<strong>Octave</strong>中熟练运用。</p><p>在接下来的视频中，将会涉及更多复杂的命令，并使用它们在<strong>Octave</strong>中对数据进行更多的操作。</p><h3 id="移动数据"><a href="#移动数据" class="headerlink" title="移动数据"></a>移动数据</h3><p>参考视频: 5 - 2 - Moving Data Around (16 min).mkv</p><p>在这段关于 <strong>Octave</strong>的辅导课视频中，我将开始介绍如何在 <strong>Octave</strong> 中移动数据。</p><p>如果你有一个机器学习问题，你怎样把数据加载到 <strong>Octave</strong> 中？</p><p>怎样把数据存入一个矩阵？</p><p>如何对矩阵进行相乘？</p><p>如何保存计算结果？</p><p>如何移动这些数据并用数据进行操作？</p><p>进入我的 <strong>Octave</strong> 窗口，</p><p>我键入{% raw %}$A${% endraw %}，得到我们之前构建的矩阵 {% raw %}$A${% endraw %}，也就是用这个命令生成的：</p><p><code>A = [1 2; 3 4; 5 6]</code></p><p>这是一个3行2列的矩阵，<strong>Octave</strong> 中的 <code>size()</code> 命令返回矩阵的尺寸。</p><p>所以 <code>size(A)</code> 命令返回3 2</p><p><img src="https://markdown.xiaoshujiang.com/img/spinner.gif" alt="0f1fe8638058e229f1fc6c5b9cd4520c" title="[[[1575432885877]]]"><br>实际上，<code>size()</code> 命令返回的是一个 1×2 的矩阵，我们可以用 {% raw %}$sz${% endraw %} 来存放。</p><p>设置 <code>sz = size(A)</code></p><p>因此 {% raw %}$sz${% endraw %} 就是一个1×2的矩阵，第一个元素是3，第二个元素是2。</p><p>所以如果键入 <code>size(sz)</code> 看看 {% raw %}$sz${% endraw %} 的尺寸，返回的是1 2，表示是一个1×2的矩阵，1 和 2分别表示矩阵{% raw %}$sz${% endraw %}的维度 。</p><p>你也可以键入 <code>size(A, 1)</code>，将返回3，这个命令会返回{% raw %}$A${% endraw %}矩阵的第一个元素，{% raw %}$A${% endraw %}矩阵的第一个维度的尺寸，也就是 {% raw %}$A${% endraw %} 矩阵的行数。</p><p>同样，命令 <code>size(A, 2)</code>，将返回2，也就是 {% raw %}$A${% endraw %} 矩阵的列数。</p><p>如果你有一个向量 {% raw %}$v${% endraw %}，假如 <code>v = [1 2 3 4]</code>，然后键入<code>length(v)</code>，这个命令将返回最大维度的大小，返回4。</p><p>你也可以键入<code>length(A)</code>，由于矩阵{% raw %}$A${% endraw %}是一个3×2的矩阵，因此最大的维度应该是3，因此该命令会返回3。</p><p>但通常我们还是对向量使用 {% raw %}$length${% endraw %} 命令，而不是对矩阵使用 <code>length</code> 命令，比如<br><code>length([1;2;3;4;5])</code>，返回5。</p><p>如何在系统中加载数据和寻找数据：</p><p>当我们打开 <strong>Octave</strong> 时，我们通常已经在一个默认路径中，这个路径是 <strong>Octave</strong>的安装位置，<code>pwd</code> 命令可以显示出<strong>Octave</strong> 当前所处路径。</p><p><code>cd</code>命令，意思是改变路径，我可以把路径改为<strong>C:\Users\ang\Desktop</strong>，这样当前目录就变为了桌面。</p><p>如果键入 <code>ls</code>，<strong>ls</strong> 来自于一个 <strong>Unix</strong> 或者 <strong>Linux</strong> 命令，<strong>ls</strong>命令将列出我桌面上的所有路径。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0de527966203108b7efa1b6730bd966c.png" alt="0de527966203108b7efa1b6730bd966c"><br>事实上，我的桌面上有两个文件：<strong>featuresX.dat</strong> 和<strong>priceY.dat</strong>，是两个我想解决的机器学习问题。</p><p><strong>featuresX</strong>文件如这个窗口所示，是一个含有两列数据的文件，其实就是我的房屋价格数据，数据集中有47行，第一个房子样本，面积是2104平方英尺，有3个卧室，第二套房子面积为1600，有3个卧室等等。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e4080d69119a0e408581c81a66e133c8.png" alt="e4080d69119a0e408581c81a66e133c8"><br><strong>priceY</strong>这个文件就是训练集中的价格数据，所以 <strong>featuresX</strong> 和<strong>priceY</strong>就是两个存放数据的文档，那么应该怎样把数据读入 <strong>Octave</strong> 呢？我们只需要键入<code>featuresX.dat</code>，这样我将加载了 <strong>featuresX</strong> 文件。同样地我可以加载<code>priceY.dat</code>。其实有好多种办法可以完成，如果你把命令写成字符串的形式<code>load(&#39;featureX.dat&#39;)</code>，也是可以的，这跟刚才的命令效果是相同的，只不过是把文件名写成了一个字符串的形式，现在文件名被存在一个字符串中。<strong>Octave</strong>中使用引号来表示字符串。</p><p>另外 <code>who</code> 命令，能显示出 在我的 <strong>Octave</strong>工作空间中的所有变量</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7e85f313f721f53f3ae74664210a7a25.png" alt="7e85f313f721f53f3ae74664210a7a25"><br>所以我可以键入<code>featuresX</code> 回车，来显示 <strong>featuresX</strong></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e49f56ceddd34dce986ae1dbdc399762.png" alt="e49f56ceddd34dce986ae1dbdc399762"><br>这些就是存在里面的数据。</p><p>还可以键入 <code>size(featuresX)</code>，得出的结果是 47 2，代表这是一个47×2的矩阵。</p><p>类似地，输入 <code>size(priceY)</code>，结果是 47<br>1，表示这是一个47维的向量，是一个列矩阵，存放的是训练集中的所有价格{% raw %}$Y${% endraw %} 的值。</p><p><code>who</code> 函数能让你看到当前工作空间中的所有变量，同样还有另一个 <code>whos</code>命令，能更详细地进行查看。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e8207c74976c4443d1ea25ec2a3b8477.png" alt="e8207c74976c4443d1ea25ec2a3b8477"><br>同样也列出我所有的变量，不仅如此，还列出了变量的维度。</p><p><strong>double</strong> 意思是双精度浮点型，这也就是说，这些数都是实数，是浮点数。</p><p>如果你想删除某个变量，你可以使用 <code>clear</code> 命令，我们键入 <code>clear featuresX</code>，然后再输入 <code>whos</code> 命令，你会发现 <strong>featuresX</strong> 消失了。</p><p>另外，我们怎么储存数据呢？</p><p>我们设变量 <code>V= priceY(1:10)</code></p><p>这表示的是将向量 {% raw %}$Y ${% endraw %}的前10个元素存入 {% raw %}$V${% endraw %}中。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a8c3b363f13820b4fc6463c7520ab58c.png" alt="a8c3b363f13820b4fc6463c7520ab58c"><br>假如我们想把它存入硬盘，那么用 <code>save hello.mat v</code> 命令，这个命令会将变量{% raw %}$V${% endraw %}存成一个叫 <strong>hello.mat</strong> 的文件，让我们回车，现在我的桌面上就出现了一个新文件，名为<strong>hello.mat</strong>。</p><p>由于我的电脑里同时安装了 <strong>MATLAB</strong>，所以这个图标上面有 <strong>MATLAB</strong>的标识，因为操作系统把文件识别为 <strong>MATLAB</strong>文件。如果在你的电脑上图标显示的不一样的话，也没有关系。</p><p>现在我们清除所有变量，直接键入<code>clear</code>，这样将删除工作空间中的所有变量，所以现在工作空间中啥都没了。</p><p>但如果我载入 <strong>hello.mat</strong> 文件，我又重新读取了变量 {% raw %}$v${% endraw %}，因为我之前把变量{% raw %}$v${% endraw %}存入了<strong>hello.mat</strong> 文件中，所以我们刚才用 <code>save</code>命令做了什么。这个命令把数据按照二进制形式储存，或者说是更压缩的二进制形式，因此，如果{% raw %}$v${% endraw %}是很大的数据，那么压缩幅度也更大，占用空间也更小。如果你想把数据存成一个人能看懂的形式，那么可以键入：</p><p><code>save hello.txt v -ascii</code></p><p>这样就会把数据存成一个文本文档，或者将数据的 <strong>ascii 码</strong>存成文本文档。</p><p>我键入了这个命令以后，我的桌面上就有了 <strong>hello.txt</strong>文件。如果打开它，我们可以发现这个文本文档存放着我们的数据。</p><p>这就是读取和储存数据的方法。</p><p>接下来我们再来讲讲操作数据的方法：</p><p>假如 {% raw %}$A${% endraw %} 还是那个矩阵</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b39bf4e9212442464fe2f568dbe4fa0c.png" alt="b39bf4e9212442464fe2f568dbe4fa0c"><br>跟刚才一样还是那个 3×2 的矩阵，现在我们加上索引值，比如键入 <code>A(3,2)</code></p><p>这将索引到{% raw %}$A${% endraw %} 矩阵的 (3,2) 元素。这就是我们通常书写矩阵的形式，写成 {% raw %}$A${% endraw %} 32，3和2分别表示矩阵的第三行和第二列对应的元素，因此也就对应 6。</p><p>我也可以键入<code>A(2,:)</code> 来返回第二行的所有元素，冒号表示该行或该列的所有元素。</p><p>类似地，如果我键入 <code>A(:,2)</code>，这将返回 {% raw %}$A${% endraw %} 矩阵第二列的所有元素，这将得到 2 4 6。</p><p>这表示返回{% raw %}$A${% endraw %} 矩阵的第二列的所有元素。</p><p>你也可以在运算中使用这些较为复杂的索引。</p><p>我再给你展示几个例子，可能你也不会经常使用，但我还是输入给你看 <code>A([1 3],:)</code>，这个命令意思是取 {% raw %}$A${% endraw %} 矩阵第一个索引值为1或3的元素，也就是说我取的是A矩阵的第一行和第三行的每一列，冒号表示的是取这两行的每一列元素，即：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d1d551d0c540449d457e312a34434355.png" alt="d1d551d0c540449d457e312a34434355"><br>可能这些比较复杂一点的索引操作你会经常用到。</p><p>我们还能做什么呢？依然是 {% raw %}$A${% endraw %} 矩阵，<code>A(:,2)</code> 命令返回第二列。</p><p>你也可以为它赋值，我可以取 {% raw %}$A${% endraw %} 矩阵的第二列，然后将它赋值为10 11 12，我实际上是取出了 {% raw %}$A${% endraw %} 的第二列，然后把一个列向量[10;11;12]赋给了它，因此现在 {% raw %}$A${% endraw %} 矩阵的第一列还是 1 3 5，第二列就被替换为 10 11 12。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f47bda45fd9beef6c600ebd48d163617.png" alt="f47bda45fd9beef6c600ebd48d163617"><br>接下来一个操作，让我们把 {% raw %}$A ${% endraw %}设为<code>A = [A, [100, 101,102]]</code>，这样做的结果是在原矩阵的右边附加了一个新的列矩阵，就是把 {% raw %}$A${% endraw %}矩阵设置为原来的 {% raw %}$A${% endraw %} 矩阵再在右边附上一个新添加的列矩阵。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e1c68a99a23d993674f08151e77dd44.png" alt="2e1c68a99a23d993674f08151e77dd44"><br>最后，还有一个小技巧，如果你就输入 <code>A(:)</code>，这是一个很特别的语法结构，意思是把 {% raw %}$A${% endraw %}中的所有元素放入一个单独的列向量，这样我们就得到了一个 9×1 的向量，这些元素都是{% raw %}$A${% endraw %} 中的元素排列起来的。</p><p>再来几个例子：</p><p>我还是把 A 重新设为 [1 2; 3 4; 5 6]，我再设一个 {% raw %}$B${% endraw %}为[11 12; 13 14; 15 16]，我可以新建一个矩阵 {% raw %}$C${% endraw %}，<code>C = [A B]</code>，这个意思就是把这两个矩阵直接连在一起，矩阵{% raw %}$A${% endraw %} 在左边，矩阵{% raw %}$B${% endraw %} 在右边，这样组成了 {% raw %}$C${% endraw %}矩阵，就是直接把{% raw %}$A${% endraw %}和 {% raw %}$B${% endraw %} 合起来。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e07db429512d4b3b5d641c52e606159d.png" alt="e07db429512d4b3b5d641c52e606159d"><br>我还可以设<code>C = [A; B]</code>，这里的分号表示把分号后面的东西放到下面。所以，<code>[A;B]</code>的作用依然还是把两个矩阵放在一起，只不过现在是上下排列，所以现在 {% raw %}$A${% endraw %} 在上面 {% raw %}$B${% endraw %}在下面，{% raw %}$C${% endraw %} 就是一个 6×2 矩阵。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7f11aa788b1b75c5a534d030b3ebc624.png" alt="7f11aa788b1b75c5a534d030b3ebc624"><br>简单地说，分号的意思就是换到下一行，所以 C 就包括上面的A，然后换行到下面，然后在下面放上一个 {% raw %}$B${% endraw %}。</p><p>另外顺便说一下，这个<code>[A B]</code>命令跟 <code>[A, B]</code> 是一样的，这两种写法的结果是相同的。</p><p>通过以上这些操作，希望你现在掌握了怎样构建矩阵，也希望我展示的这些命令能让你很快地学会怎样把矩阵放到一起，怎样取出矩阵，并且把它们放到一起，组成更大的矩阵。</p><p>通过几句简单的代码，<strong>Octave</strong>能够很方便地很快速地帮助我们组合复杂的矩阵以及对数据进行移动。这就是移动数据这一节课。</p><p>我认为对你来讲，最好的学习方法是，下课后复习一下我键入的这些代码好好地看一看，从课程的网上把代码的副本下载下来，重新好好看看这些副本，然后自己在<strong>Octave</strong> 中把这些命令重新输一遍，慢慢开始学会使用这些命令。</p><p>当然，没有必要把这些命令都记住，你也不可能记得住。你要做的就是，了解一下你可以用哪些命令，做哪些事。这样在你今后需要编写学习算法时，如果你要找到某个<strong>Octave</strong>中的命令，你可能回想起你之前在这里学到过，然后你就可以查找课程中提供的程序副本，这样就能很轻松地找到你想使用的命令了。</p><h3 id="计算数据"><a href="#计算数据" class="headerlink" title="计算数据"></a>计算数据</h3><p>参考视频: 5 - 3 - Computing on Data (13 min).mkv</p><p>现在，你已经学会了在<strong>Octave</strong>中如何加载或存储数据，如何把数据存入矩阵等等。在这段视频中，我将介绍如何对数据进行运算，稍后我们将使用这些运算操作来实现我们的学习算法。</p><p>这是我的 <strong>Octave</strong>窗口，我现在快速地初始化一些变量。比如设置{% raw %}$A${% endraw %}为一个3×2的矩阵，设置{% raw %}$B${% endraw %}为一个3 ×2矩阵，设置{% raw %}$C${% endraw %}为2 × 2矩阵。</p><p>我想算两个矩阵的乘积，比如说 {% raw %}$A × C${% endraw %}，我只需键入<code>A×C</code>，这是一个 3×2 矩阵乘以 2×2矩阵，得到这样一个3×2矩阵。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8ee5c7c05865e90f75feda99b9131319.png" alt="8ee5c7c05865e90f75feda99b9131319"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/38c956acb3bedf4362f40e6c5e8a692f.png" alt="38c956acb3bedf4362f40e6c5e8a692f"><br>你也可以对每一个元素，做运算 方法是做点乘运算<code>A.*B</code>，这么做Octave将矩阵 {% raw %}$A${% endraw %}中的每一个元素与矩阵 {% raw %}$B${% endraw %} 中的对应元素相乘:<code>A.*B</code></p><p>这里第一个元素1乘以11得到11，第二个元素2乘以12得到24，这就是两个矩阵的元素位运算。通常来说，在<strong>Octave</strong>中点号一般用来表示元素位运算。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/646de38bffd4f7f6601167d0c0686970.png" alt="646de38bffd4f7f6601167d0c0686970"><br>这里是一个矩阵{% raw %}$A${% endraw %}，这里我输入<code>A.^2</code>，这将对矩阵{% raw %}$A${% endraw %}中每一个元素平方。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d456e7501d7aaa9fa2ef8a89e89fa7e1.png" alt="d456e7501d7aaa9fa2ef8a89e89fa7e1"><br>我们设{% raw %}$V${% endraw %}为 [1; 2; 3] 是列向量，你也可以输入<code>1./V</code>，得到每一个元素的倒数，所以这样一来，就会分别算出 1/1 1/2 1/3。</p><p>矩阵也可以这样操作，<code>1./A</code> 得到{% raw %}$A${% endraw %}中每一个元素的倒数。</p><p>同样地，这里的点号还是表示对每一个元素进行操作。</p><p>我们还可以进行求对数运算，也就是对每个元素进行求对数运算。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0c7c1d7726c09ffb45152cf153614003.png" alt="0c7c1d7726c09ffb45152cf153614003"><br>还有自然数{% raw %}$e${% endraw %}的幂次运算，就是以{% raw %}$e${% endraw %}为底，以这些元素为幂的运算。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a36506049248948c82e598c8c254dc31.png" alt="a36506049248948c82e598c8c254dc31"><br>我还可以用 <strong>abs</strong>来对 {% raw %}$v${% endraw %} 的每一个元素求绝对值，当然这里 {% raw %}$v${% endraw %}都是正数。我们换成另一个这样对每个元素求绝对值，得到的结果就是这些非负的元素。还有{% raw %}$–v${% endraw %}，给出{% raw %}$v${% endraw %}中每个元素的相反数，这等价于 -1 乘以 {% raw %}$v${% endraw %}，一般就直接用 {% raw %}$-v${% endraw %}<br>就好了，其实就等于 $-1*v$。</p><p>还有一个技巧，比如说我们想对{% raw %}$v${% endraw %}中的每个元素都加1，那么我们可以这么做，首先构造一个3行1列的1向量，然后把这个1向量跟原来的向量相加，因此{% raw %}$v${% endraw %}向量从[1 2 3] 增至 [2 3 4]。我用了一个，<code>length(v)</code>命令，因此这样一来，<code>ones(length(v) ,1)</code> 就相当于<code>ones(3,1)</code>，然后我做的是<code>v +ones(3,1)</code>，也就是将 {% raw %}$v${% endraw %} 的各元素都加上这些1，这样就将{% raw %}$v${% endraw %} 的每个元素增加了1。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9432bbcbfde53c7e0dcb1c7317b01c0c.png" alt="9432bbcbfde53c7e0dcb1c7317b01c0c"><br>另一种更简单的方法是直接用 <code>v+1</code>，<code>v + 1</code> 也就等于把 {% raw %}$v${% endraw %} 中的每一个元素都加上1。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e02eec3ca4688ff1cb9126c8eb13bfed.png" alt="e02eec3ca4688ff1cb9126c8eb13bfed"><br>现在，让我们来谈谈更多的操作。</p><p>矩阵{% raw %}$A${% endraw %} 如果你想要求它的转置，那么方法是用A’,将得出 A 的转置矩阵。当然，如果我写<code>(A&#39;)&#39;</code>，也就是 {% raw %}$A${% endraw %} 转置两次，那么我又重新得到矩阵 {% raw %}$A${% endraw %}。</p><p>还有一些有用的函数，比如： <code>a=[1 15 2 0.5]</code>，这是一个1行4列矩阵，<code>val=max(a)</code>，这将返回{% raw %}$A${% endraw %}矩阵中的最大值15。</p><p>我还可以写 <code>[val, ind] =max(a)</code>，这将返回{% raw %}$A${% endraw %}矩阵中的最大值存入{% raw %}$val${% endraw %}，以及该值对应的索引，元素15对应的索引值为2,存入{% raw %}$ind${% endraw %}，所以 {% raw %}$ind =2${% endraw %}。</p><p>特别注意一下，如果你用命令 <code>max(A)</code>，{% raw %}$A${% endraw %}是一个矩阵的话，这样做就是对每一列求最大值。</p><p>我们还是用这个例子，这个 {% raw %}$a${% endraw %} 矩阵<code>a=[1 15 2 0.5]</code>，如果输入<code>a&amp;lt;3</code>，这将进行逐元素的运算，所以元素小于3的返回1，否则返回0。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fc04d42876c9d7d7bed51bade2077649.png" alt="fc04d42876c9d7d7bed51bade2077649"><br>因此，返回[1 1 0 1]。也就是说，对{% raw %}$a${% endraw %}矩阵的每一个元素与3进行比较，然后根据每一个元素与3的大小关系，返回1和0表示真与假。</p><p>如果我写 <code>find(a&amp;lt;3)</code>，这将告诉我{% raw %}$a${% endraw %} 中的哪些元素是小于3的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ac9ad10f115d2d1cd15a0514c8ceeafa.png" alt="ac9ad10f115d2d1cd15a0514c8ceeafa"><br>设<code>A = magic(3)</code>，<strong>magic 函数</strong>将返回一个矩阵，称为魔方阵或幻方 (<strong>magic squares</strong>)，它们具有以下这样的数学性质：它们所有的行和列和对角线加起来都等于相同的值。</p><p>当然据我所知，这在机器学习里基本用不上，但我可以用这个方法很方便地生成一个3行3列的矩阵，而这个魔方矩阵这神奇的方形屏幕。每一行、每一列、每一个对角线三个数字加起来都是等于同一个数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8c7f4f36183ef4b36bce427be2fce6f.png" alt="f8c7f4f36183ef4b36bce427be2fce6f"><br>在其他有用的机器学习应用中，这个矩阵其实没多大作用。</p><p>如果我输入 <code>[r,c] = find(A&gt;=7)</code>，这将找出所有{% raw %}$A${% endraw %}矩阵中大于等于7的元素，因此，{% raw %}$r${% endraw %} 和{% raw %}$c${% endraw %}分别表示行和列，这就表示，第一行第一列的元素大于等于7，第三行第二列的元素大于等于7，第二行第三列的元素大于等于7。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/409a04487d1d7f039acfd61b3787f6aa.png" alt="409a04487d1d7f039acfd61b3787f6aa"><br>顺便说一句，其实我从来都不去刻意记住这个 <strong>find 函数</strong>，到底是怎么用的，我只需要会用<strong>help函数</strong>就可以了，每当我在使用这个函数，忘记怎么用的时候，我就可以用 <strong>help函数</strong>，键入 <code>help find</code> 来找到帮助文档。</p><p>最后再讲两个内容，一个是求和函数，这是 {% raw %}$a${% endraw %} 矩阵：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d7221c981ecc7730465710a0d8b49b34.png" alt="d7221c981ecc7730465710a0d8b49b34"><br>键入 <code>sum(a)</code>，就把 a 中所有元素加起来了。</p><p>如果我想把它们都乘起来，键入 <code>prod(a)</code>，<strong>prod</strong> 意思是<strong>product(乘积)</strong>，它将返回这四个元素的乘积。</p><p><code>floor(a)</code> 是向下四舍五入，因此对于 {% raw %}$a${% endraw %} 中的元素0.5将被下舍入变成0。</p><p>还有 <code>ceil(a)</code>，表示向上四舍五入，所以0.5将上舍入变为最接近的整数，也就是1。</p><p>键入 <code>type(3)</code>，这通常得到一个3×3的矩阵，如果键入 <code>max(rand(3),rand(3))</code>，这样做的结果是返回两个3×3的随机矩阵，并且逐元素比较取最大值。</p><p>假如我输入<code>max(A,[],1)</code>，这样做会得到每一列的最大值。</p><p>所以第一列的最大值就是8，第二列是9，第三列的最大值是7，这里的1表示取A矩阵第一个维度的最大值。</p><p>相对地，如果我键入<code>max(A,[],2)</code>，这将得到每一行的最大值，所以，第一行的最大值是等于8，第二行最大值是7，第三行是9。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/31bc524d1a19b4e9d8ea0974517a512e.png" alt="31bc524d1a19b4e9d8ea0974517a512e"><br>所以你可以用这个方法来求得每一行或每一列的最值，另外，你要知道，默认情况下<code>max(A)</code>返回的是每一列的最大值，如果你想要找出整个矩阵A的最大值，你可以输入<code>max(max(A))</code>，或者你可以将{% raw %}$A${% endraw %} 矩阵转成一个向量，然后键入 <code>max(A(:))</code>，这样做就是把 {% raw %}$A${% endraw %} 当做一个向量，并返回 {% raw %}$A${% endraw %}向量中的最大值。</p><p>最后，让我们把 {% raw %}$A${% endraw %}设为一个9行9列的魔方阵，魔方阵具有的特性是每行每列和对角线的求和都是相等的。</p><p>这是一个9×9的魔方阵，我们来求一个 <code>sum(A,1)</code>，这样就得到每一列的总和，这也验证了一个9×9的魔方阵确实每一列加起来都相等，都为369。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0b9753a3e10bbdce0f26c3d44d61ae26.png" alt="0b9753a3e10bbdce0f26c3d44d61ae26"><br>现在我们来求每一行的和，键入<code>sum(A,2)</code>，这样就得到了{% raw %}$A${% endraw %} 中每一行的和加起来还是369。</p><p>现在我们来算{% raw %}$A ${% endraw %}的对角线元素的和。我们现在构造一个9×9 的单位矩阵，键入 <code>eye(9)</code>,</p><p>然后我们要用 {% raw %}$A${% endraw %}逐点乘以这个单位矩阵，除了对角线元素外，其他元素都会得到0。</p><p>键入<code>sum(sum(A.*eye(9))</code></p><p>这实际上是求得了，这个矩阵对角线元素的和确实是369。</p><p>你也可以求另一条对角线的和也是是369。</p><p><strong>flipup/flipud</strong> 表示向上/向下翻转。</p><p>同样地，如果你想求这个矩阵的逆矩阵，键入<code>pinv(A)</code>，通常称为伪逆矩阵，你就把它看成是矩阵 {% raw %}$A${% endraw %} 求逆，因此这就是 {% raw %}$A${% endraw %}矩阵的逆矩阵。</p><p>设 <code>temp = pinv(A)</code>，然后再用{% raw %}$temp${% endraw %} 乘以{% raw %}$A${% endraw %}，这实际上得到的就是单位矩阵，对角线为1，其他元素为0。</p><p>如何对矩阵中的数字进行各种操作，在运行完某个学习算法之后，通常一件最有用的事情是看看你的结果，或者说让你的结果可视化，在接下来的视频中，我会非常迅速地告诉你，如何很快地画图，如何只用一两行代码，你就可以快速地可视化你的数据，这样你就能更好地理解你使用的学习算法。</p><h3 id="绘图数据"><a href="#绘图数据" class="headerlink" title="绘图数据"></a>绘图数据</h3><p>参考视频: 5 - 4 - Plotting Data (10 min).mkv</p><p>当开发学习算法时，往往几个简单的图，可以让你更好地理解算法的内容，并且可以完整地检查下算法是否正常运行，是否达到了算法的目的。</p><p>例如在之前的视频中，我谈到了绘制成本函数{% raw %}$J(\theta)${% endraw %}，可以帮助确认梯度下降算法是否收敛。通常情况下，绘制数据或学习算法所有输出，也会启发你如何改进你的学习算法。幸运的是，<strong>Octave</strong>有非常简单的工具用来生成大量不同的图。当我用学习算法时，我发现绘制数据、绘制学习算法等，往往是我获得想法来改进算法的重要部分。在这段视频中，我想告诉你一些<strong>Octave</strong>的工具来绘制和可视化你的数据。</p><p>我们先来快速生成一些数据用来绘图。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4514b422525aaac1e99add67e44882ee.png" alt="4514b422525aaac1e99add67e44882ee"><br>如果我想绘制正弦函数，这是很容易的，我只需要输入<code>plot(t,y1)</code>，并回车，就出现了这个图：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575433328341.png" alt="enter description here"></p><p>横轴是{% raw %}$t${% endraw %}变量，纵轴是{% raw %}$y1${% endraw %}，也就是我们刚刚所输出的正弦函数。</p><p>让我们设置{% raw %}$y2${% endraw %}</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2d32a23ab895a8e765caf90a7679817e.png" alt="2d32a23ab895a8e765caf90a7679817e"><br><strong>Octave</strong>将会消除之前的正弦图，并且用这个余弦图来代替它，这里纵轴{% raw %}$cos(x)${% endraw %}从1开始，</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/38969cc85853190ff3eac4f06398bc1b.png" alt="38969cc85853190ff3eac4f06398bc1b"><br>如果我要同时表示正弦和余弦曲线。</p><p>我要做的就是，输入：<code>plot(t, y1)</code>，得到正弦函数，我使用函数<strong>hold on</strong>，<strong>hold on</strong>函数的功能是将新的图像绘制在旧的之上。</p><p>我现在绘制{% raw %}$y2${% endraw %}，输入：<code>plot(t, y2)</code>。</p><p>我要以不同的颜色绘制余弦函数，所以我在这里输入带引号的r绘制余弦函数，{% raw %}$r${% endraw %}表示所使用的颜色：<code>plot(t,y2,’r’)</code>，再加上命令<code>xlabel(&#39;time&#39;)</code>，<br>来标记X轴即水平轴，输入<code>ylabel(&#39;value&#39;)</code>，来标记垂直轴的值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9eb4e496f34a801fd7ba5e85c4eec66b.png" alt="9eb4e496f34a801fd7ba5e85c4eec66b"><br>同时我也可以来标记我的两条函数曲线，用这个命令 <code>legend(&#39;sin&#39;,&#39;cos&#39;)</code>将这个图例放在右上方，表示这两条曲线表示的内容。最后输入<code>title(&#39;myplot&#39;)</code>，在图像的顶部显示这幅图的标题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/23594175efe66d5b9b1e687375a2dbda.png" alt="23594175efe66d5b9b1e687375a2dbda"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c765aeee9c53e0e77d01d1e73cabd9b4.png" alt="c765aeee9c53e0e77d01d1e73cabd9b4"><br>如果你想保存这幅图像，你输入<code>print –dpng &#39;myplot.png&#39;</code>，<strong>png</strong>是一个图像文件格式，如果你这样做了，它可以让你保存为一个文件。</p><p><strong>Octave</strong>也可以保存为很多其他的格式，你可以键入<code>help plot</code>。</p><p>最后如果你想，删掉这个图像，用命令<strong>close</strong>会让这个图像关掉。</p><p><strong>Octave</strong>也可以让你为图像标号</p><p>你键入<code>figure(1); plot(t, y1);</code>将显示第一张图，绘制了变量{% raw %}$t${% endraw %} {% raw %}$y1${% endraw %}。</p><p>键入<code>figure(2); plot(t, y2);</code> 将显示第一张图，绘制了变量{% raw %}$t${% endraw %} {% raw %}$y2${% endraw %}。</p><p><strong>subplot</strong>命令，我们要使用<code>subplot(1,2,1)</code>，它将图像分为一个1*2的格子，也就是前两个参数，然后它使用第一个格子，也就是最后一个参数1的意思。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a786b8ed82ddd182f4595de2173cc84b.png" alt="a786b8ed82ddd182f4595de2173cc84b"><br>我现在使用第一个格子，如果键入<code>plot(t,y1)</code>，现在这个图显示在第一个格子。如果我键入<code>subplot(1,2,2)</code>，那么我就要使用第二个格子，键入<code>plot(t,y2)</code>；现在y2显示在右边，也就是第二个格子。</p><p>最后一个命令，你可以改变轴的刻度，比如改成[0.5 1 -1 1]，输入命令：<code>axis([0.5 1 -1 1])</code>也就是设置了右边图的{% raw %}$x${% endraw %}轴和{% raw %}$y${% endraw %}轴的范围。具体而言，它将右图中的横轴的范围调整至0.5到1，竖轴的范围为-1到1。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f13993f4784d01e7da769b4ec2545cd7.png" alt="f13993f4784d01e7da769b4ec2545cd7"><br>你不需要记住所有这些命令，如果你需要改变坐标轴，或者需要知道<strong>axis</strong>命令，你可以用<strong>Octave</strong>中用<strong>help</strong>命令了解细节。</p><p>最后，还有几个命令。</p><p><code>Clf</code>（清除一幅图像）。</p><p>让我们设置A等于一个5×5的<strong>magic</strong>方阵：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/82a990a5832ae2618d768551b90470dc.png" alt="82a990a5832ae2618d768551b90470dc"><br>我有时用一个巧妙的方法来可视化矩阵，也就是<code>imagesc(A</code>)命令，它将会绘制一个5*5的矩阵，一个5*5的彩色格图，不同的颜色对应A矩阵中的不同值。</p><p>我还可以使用函数<strong>colorbar</strong>，让我用一个更复杂的命令 <code>imagesc(A)，colorbar，colormap gray</code>。这实际上是在同一时间运行三个命令：运行<code>imagesc</code>，然后运行，<code>colorbar</code>，然后运行<code>colormap gray</code>。</p><p>它生成了一个颜色图像，一个灰度分布图，并在右边也加入一个颜色条。所以这个颜色条显示不同深浅的颜色所对应的值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/881986ec5af9d86b6b14b260fb3b3618.png" alt="881986ec5af9d86b6b14b260fb3b3618"><br>你可以看到在不同的方格，它对应于一个不同的灰度。</p><p>输入<code>imagesc(magic(15))，colorbar，colormap gray</code></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/22a9a9536d4db17b6d64603fb54dce9e.png" alt="22a9a9536d4db17b6d64603fb54dce9e"><br>这将会是一幅15*15的<strong>magic</strong>方阵值的图。</p><p>最后，总结一下这段视频。你看到我所做的是使用逗号连接函数调用。如果我键入{% raw %}$a=1${% endraw %},{% raw %}$b=2${% endraw %},{% raw %}$c=3${% endraw %}然后按<strong>Enter</strong>键，其实这是将这三个命令同时执行，或者是将三个命令一个接一个执行，它将输出所有这三个结果。</p><p>这很像{% raw %}$a=1${% endraw %}; {% raw %}$b=2${% endraw %};{% raw %}$c=3${% endraw %};如果我用分号来代替逗号，则没有输出出任何东西。</p><p>这里我们称之为逗号连接的命令或函数调用。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c0e8b7a19ced9a1dd006ed87d6323c9b.png" alt="c0e8b7a19ced9a1dd006ed87d6323c9b"><br>用逗号连接是另一种<strong>Octave</strong>中更便捷的方式，将多条命令例如<code>imagesc colorbar colormap</code>，将这多条命令写在同一行中。</p><p>现在你知道如何绘制<strong>Octave</strong>中不同的图像，在下面的视频中，我将告诉你怎样在Octave中，写控制语句，比如<strong>if while for</strong>语句，并且定义和使用函数。</p><h3 id="控制语句：for，while，if语句"><a href="#控制语句：for，while，if语句" class="headerlink" title="控制语句：for，while，if语句"></a>控制语句：for，while，if语句</h3><p>参考视频: 5 - 5 - Control Statements_ for, while, if statements (13 min).mkv</p><p>在这段视频中，我想告诉你怎样为你的 <strong>Octave</strong> 程序写控制语句。诸如：”<strong>for</strong>“ “<strong>while</strong>“ “<strong>if</strong>“ 这些语句，并且如何定义和使用方程。</p><p>我先告诉你如何使用 “<strong>for</strong>” 循环。</p><p>首先，我要将 {% raw %}$v${% endraw %} 值设为一个10行1列的零向量。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/26a912d550af9fd43a7ae62e3b610e97.png" alt="26a912d550af9fd43a7ae62e3b610e97"><br>接着我要写一个 “<strong>for</strong>“ 循环，让 {% raw %}$i${% endraw %} 等于 1 到 10，写出来就是 <code>i = 1:10</code>。我要设{% raw %}$ v(i)${% endraw %}的值等于 2 的 {% raw %}$i${% endraw %} 次方，循环最后写上“<strong>end</strong>”。</p><p>向量{% raw %}$v${% endraw %} 的值就是这样一个集合 2的一次方、2的二次方，依此类推。这就是我的 {% raw %}$i${% endraw %} 等于 1 到 10的语句结构，让 {% raw %}$i${% endraw %} 遍历 1 到 10的值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/890f6ea8f857f22002f98c20d52b3bb8.png" alt="890f6ea8f857f22002f98c20d52b3bb8"><br>另外，你还可以通过设置你的 indices (索引) 等于 1一直到10，来做到这一点。这时<strong>indices</strong> 就是一个从1到10的序列。</p><p>你也可以写 <code>i = indices</code>，这实际上和我直接把 i 写到 1 到 10 是一样。你可以写 <code>disp(i)</code>，也能得到一样的结果。所以 这就是一个 “<strong>for</strong>” 循环。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fc956ae1291dc7d3b819e471d1962398.png" alt="fc956ae1291dc7d3b819e471d1962398"><br>如果你对 “<strong>break</strong>” 和 “<strong>continue</strong>” 语句比较熟悉，<strong>Octave</strong>里也有 “<strong>break</strong>” 和 “<strong>continue</strong>”语句，你也可以在 <strong>Octave</strong>环境里使用那些循环语句。</p><p>但是首先让我告诉你一个 <strong>while</strong> 循环是如何工作的：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1b37f81896a59145576ae996c9dd4d16.png" alt="1b37f81896a59145576ae996c9dd4d16"><br>这是什么意思呢：我让 {% raw %}$i${% endraw %} 取值从 1 开始，然后我要让 {% raw %}$v(i)${% endraw %} 等于 100，再让 {% raw %}$i${% endraw %} 递增 1，直到{% raw %}$i${% endraw %} 大于 5停止。</p><p>现在来看一下结果，我现在已经取出了向量的前五个元素，把他们用100覆盖掉，这就是一个<strong>while</strong>循环的句法结构。</p><p>现在我们来分析另外一个例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/279cfbda6b4d9a2ced1332f086db4d9e.png" alt="279cfbda6b4d9a2ced1332f086db4d9e"><br>这里我将向你展示如何使用<strong>break</strong>语句。比方说 <code>v(i) = 999</code>，然后让 <code>i = i+1</code>，当 {% raw %}$i${% endraw %} 等于6的时候 <strong>break</strong> (停止循环)，结束 (<strong>end</strong>)。</p><p>当然这也是我们第一次使用一个 <strong>if</strong> 语句，所以我希望你们可以理解这个逻辑，让 {% raw %}$i${% endraw %} 等于1 然后开始下面的增量循环，<strong>while</strong>语句重复设置 {% raw %}$v(i)${% endraw %} 等于999，不断让{% raw %}$i${% endraw %}增加，然后当 {% raw %}$i${% endraw %} 达到6，做一个中止循环的命令，尽管有<strong>while</strong>循环，语句也就此中止。所以最后的结果是取出向量 {% raw %}$v${% endraw %} 的前5个元素，并且把它们设置为999。</p><p>所以，这就是<strong>if</strong> 语句和 <strong>while</strong> 语句的句法结构。并且要注意要有<strong>end</strong>，上面的例子里第一个 <strong>end</strong> 结束的是 <strong>if</strong><br>语句，第二个 <strong>end</strong> 结束的是 <strong>while</strong> 语句。</p><p>现在让我告诉你使用 <strong>if-else</strong> 语句：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3fce4367c960bb6fbc492a3b8f9ddc5d.png" alt="3fce4367c960bb6fbc492a3b8f9ddc5d"><br>最后，提醒一件事：如果你需要退出 <strong>Octave</strong>，你可以键入<code>exit</code>命令然后回车就会退出 <strong>Octave</strong>，或者命令<code>quit</code>也可以。</p><p>最后，让我们来说说函数 (<strong>functions</strong>)，如何定义和调用函数。</p><p>我在桌面上存了一个预先定义的文件名为 “<strong>squarethisnumber.m</strong>”，这就是在 <strong>Octave</strong> 环境下定义的函数。</p><p>让我们打开这个文件。请注意，我使用的是微软的写字板程序来打开这个文件，我只是想建议你，如果你也使用微软的<strong>Windows</strong>系统，那么可以使用写字板程序，而不是记事本来打开这些文件。如果你有别的什么文本编辑器也可以，记事本有时会把代码的间距弄得很乱。如果你只有记事本程序，那也能用。我建议你用写字板或者其他可以编辑函数的文本编辑器。</p><p>现在我们来说如何在 <strong>Octave</strong> 里定义函数：</p><p>这个文件只有三行：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/247f96f4e7ab7a259ac9ef1eebe0b503.png" alt="247f96f4e7ab7a259ac9ef1eebe0b503"><br>第一行写着 <code>function y = squareThisNumber(x)</code>，这就告诉 <strong>Octave</strong>，我想返回一个 y值，我想返回一个值，并且返回的这个值将被存放于变量 {% raw %}$y${% endraw %} 里。另外，它告诉了<strong>Octave</strong>这个函数有一个参数，就是参数 {% raw %}$x${% endraw %}，还有定义的函数体，也就是 {% raw %}$y${% endraw %} 等于 {% raw %}$x${% endraw %} 的平方。</p><p>还有一种更高级的功能，这只是对那些知道“<strong>search path</strong> (<strong>搜索路径</strong>)”这个术语的人使用的。所以如果你想要修改<br><strong>Octave</strong>的搜索路径，你可以把下面这部分作为一个进阶知识，或者选学材料，仅适用于那些熟悉编程语言中搜索路径概念的同学。</p><p>你可以使用<strong>addpath</strong> 命令添加路径，添加路径“<strong>C:\Users\ang\desktop</strong>”将该目录添加到<strong>Octav</strong>e的搜索路径，这样即使你跑到其他路径底下，<strong>Octave</strong>依然知道会在 <strong>Users\ang\desktop</strong>目录下寻找函数。这样，即使我现在在不同的目录下，它仍然知道在哪里可以找到“<strong>SquareThisNumber</strong>” 这个函数。</p><p>但是，如果你不熟悉搜索路径的概念，不用担心，只要确保在执行函数之前，先用 <code>cd</code>命令设置到你函数所在的目录下，实际上也是一样的效果。</p><p><strong>Octave</strong>还有一个其他许多编程语言都没有的概念，那就是它可以允许你定义一个函数，使得返回值是多个值或多个参数。这里就是一个例子，定义一个函数叫：</p><p>“<code>SquareAndCubeThisNumber(x)</code>” ({% raw %}$x${% endraw %}的平方以及{% raw %}$x${% endraw %}的立方)</p><p>这说的就是函数返回值是两个： {% raw %}$y1${% endraw %} 和 {% raw %}$y2${% endraw %}，接下来就是{% raw %}$y1${% endraw %}是被平方后的结果，{% raw %}$y2${% endraw %}是被立方后的结果，这就是说，函数会真的返回2个值。</p><p>有些同学可能会根据你使用的编程语言，比如你们可能熟悉的<strong>C</strong>或<strong>C++</strong>，通常情况下，认为作为函数返回值只能是一个值，但<strong>Octave</strong> 的语法结构就不一样，可以返回多个值。</p><p>如果我键入 <code>[a,b] = SquareAndCubeThisNumber(5)</code>，然后，{% raw %}$a${% endraw %}就等于25，{% raw %}$b${% endraw %} 就等于5的立方125。</p><p>所以说如果你需要定义一个函数并且返回多个值，这一点常常会带来很多方便。</p><p>最后，我来给大家演示一下一个更复杂一点的函数的例子。</p><p>比方说，我有一个数据集，像这样，数据点为[1,1], [2,2],[3,3]，我想做的事是定义一个 <strong>Octave</strong> 函数来计算代价函数 {% raw %}$J(\theta)${% endraw %}，就是计算不同 {% raw %}$\theta${% endraw %}值所对应的代价函数值{% raw %}$J${% endraw %}。</p><p>首先让我们把数据放到 <strong>Octave</strong> 里，我把我的矩阵设置为<code>X = [1 1; 1 2; 1 3];</code></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3c857152ef3f0d6b374e4863289d1c60.png" alt="3c857152ef3f0d6b374e4863289d1c60"><br>请仔细看一下这个函数的定义，确保你明白了定义中的每一步。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e01d6da07890e32d46d0616741a3fe64.png" alt="e01d6da07890e32d46d0616741a3fe64"><br>现在当我在 <strong>Octave</strong> 里运行时，我键入 <code>J = costFunctionJ (X, y, theta)</code>，它就计算出 {% raw %}$J${% endraw %}等于0，这是因为如果我的数据集{% raw %}$x${% endraw %} 为 [1;2;3]， {% raw %}$y${% endraw %} 也为 [1;2;3] 然后设置 {% raw %}$\theta_0${% endraw %} 等于0，{% raw %}$\theta_1${% endraw %}等于1，这给了我恰好45度的斜线，这条线是可以完美拟合我的数据集的。</p><p>而相反地，如果我设置{% raw %}$\theta${% endraw %} 等于[0;0]，那么这个假设就是0是所有的预测值，和刚才一样，设置{% raw %}$\theta_0${% endraw %} = 0，{% raw %}$\theta_1${% endraw %}也等于0，然后我计算的代价函数，结果是2.333。实际上，他就等于1的平方，也就是第一个样本的平方误差，加上2的平方，加上3的平方，然后除以{% raw %}$2m${% endraw %}，也就是训练样本数的两倍，这就是2.33。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/885b5d19c33f545292ccc1b69976c789.png" alt="885b5d19c33f545292ccc1b69976c789"><br>因此这也反过来验证了我们这里的函数，计算出了正确的代价函数。这些就是我们用简单的训练样本尝试的几次试验，这也可以作为我们对定义的代价函数{% raw %}$J${% endraw %}进行了完整性检查。确实是可以计算出正确的代价函数的。至少基于这里的 {% raw %}$x${% endraw %}和 {% raw %}$y${% endraw %}是成立的。也就是我们这几个简单的训练集，至少是成立的。</p><p>现在你知道如何在 <strong>Octave</strong> 环境下写出正确的控制语句，比如 <strong>for 循环</strong>、<strong>while 循环</strong>和 <strong>if语句</strong>，以及如何定义和使用函数。</p><p>在接下来的<strong>Octave</strong> 教程视频里，我会讲解一下向量化，这是一种可以使你的 <strong>Octave</strong>程序运行非常快的思想。</p><h3 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h3><p>参考视频: 5 - 6 - Vectorization (14 min).mkv</p><p>在这段视频中，我将介绍有关向量化的内容，无论你是用<strong>Octave</strong>，还是别的语言，比如<strong>MATLAB</strong>或者你正在用<strong>Python</strong>、<strong>NumPy</strong> 或 <strong>Java C C++</strong>，所有这些语言都具有各种线性代数库，这些库文件都是内置的，容易阅读和获取，他们通常写得很好，已经经过高度优化，通常是数值计算方面的博士或者专业人士开发的。</p><p>而当你实现机器学习算法时，如果你能好好利用这些线性代数库，或者数值线性代数库，并联合调用它们，而不是自己去做那些函数库可以做的事情。如果是这样的话，那么通常你会发现：首先，这样更有效，也就是说运行速度更快，并且更好地利用你的计算机里可能有的一些并行硬件系统等等；其次，这也意味着你可以用更少的代码来实现你需要的功能。因此，实现的方式更简单，代码出现问题的有可能性也就越小。</p><p>举个具体的例子：与其自己写代码做矩阵乘法。如果你只在<strong>Octave</strong>中输入{% raw %}$a${% endraw %}乘以{% raw %}$b${% endraw %}就是一个非常有效的两个矩阵相乘的程序。有很多例子可以说明，如果你用合适的向量化方法来实现，你就会有一个简单得多，也有效得多的代码。</p><p>让我们来看一些例子：这是一个常见的线性回归假设函数：{% raw %}${ {h}_{\theta } }(x)=\sum\limits_{j=0}^{n}{ {{\theta }_{j} }{ {x}_{j} }}${% endraw %}</p><p>如果你想要计算{% raw %}$h_\theta(x)${% endraw %} ，注意到右边是求和，那么你可以自己计算{% raw %}$j = 0${% endraw %} 到{% raw %}$ j = n${% endraw %} 的和。但换另一种方式来想想，把 {% raw %}$h_\theta(x)${% endraw %} 看作{% raw %}$\theta^Tx${% endraw %}，那么你就可以写成两个向量的内积，其中{% raw %}$\theta${% endraw %}就是{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}，如果你有两个特征量，如果 {% raw %}$n = 2${% endraw %}，并且如果你把 {% raw %}$x${% endraw %} 看作{% raw %}$x_0${% endraw %}、{% raw %}$x_1${% endraw %}、{% raw %}$x_2${% endraw %}，这两种思考角度，会给你两种不同的实现方式。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7fefb92d8680e4a15f947cd2ca24a9ac.png" alt="7fefb92d8680e4a15f947cd2ca24a9ac"><br>比如说，这是未向量化的代码实现方式：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/125c07019cb39675085fe3b80b85fca5.png" alt="125c07019cb39675085fe3b80b85fca5"><br>计算{% raw %}$h_\theta(x)${% endraw %}是未向量化的，我们可能首先要初始化变量 {% raw %}$prediction${% endraw %} 的值为0.0，而这个变量{% raw %}$prediction${% endraw %} 的最终结果就是{% raw %}$h_\theta(x)${% endraw %}，然后我要用一个 <strong>for</strong> 循环，{% raw %}$j${% endraw %} 取值 0 到{% raw %}$n+1${% endraw %}，变量{% raw %}$prediction${% endraw %} 每次就通过自身加上{% raw %}$ theta(j) ${% endraw %}乘以 {% raw %}$x(j)${% endraw %}更新值，这个就是算法的代码实现。</p><p>顺便我要提醒一下，这里的向量我用的下标是0，所以我有{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}，但因为<strong>MATLAB</strong>的下标从1开始，在 <strong>MATLAB</strong> 中{% raw %}$\theta_0${% endraw %}，我们可能会用 {% raw %}$theta(1)${% endraw %} 来表示，这第二个元素最后就会变成，{% raw %}$theta(2${% endraw %}) 而第三个元素，最终可能就用{% raw %}$theta(3)${% endraw %}表示，因为<strong>MATLAB</strong>中的下标从1开始，这就是为什么这里我的 <strong>for 循环</strong>，{% raw %}$j${% endraw %}取值从 1 直到{% raw %}$n+1${% endraw %}，而不是从 0 到 {% raw %}$n${% endraw %}。这是一个未向量化的代码实现方式，我们用一个 <strong>for 循环</strong>对 {% raw %}$n${% endraw %} 个元素进行加和。</p><p>作为比较，接下来是向量化的代码实现：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/829e153c119919f80c058d1bc703a08b.png" alt="829e153c119919f80c058d1bc703a08b"><br>你把x和{% raw %}$\theta${% endraw %}看做向量，而你只需要令变量{% raw %}$prediction${% endraw %}等于{% raw %}$theta${% endraw %}转置乘以{% raw %}$x${% endraw %}，你就可以这样计算。与其写所有这些for循环的代码，你只需要一行代码，这行代码就是利用 <strong>Octave</strong> 的高度优化的数值，线性代数算法来计算两个向量{% raw %}$\theta${% endraw %}以及{% raw %}$x${% endraw %}的内积，这样向量化的实现更简单，它运行起来也将更加高效。这就是 <strong>Octave</strong> 所做的而向量化的方法，在其他编程语言中同样可以实现。</p><p>让我们来看一个<strong>C++</strong> 的例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/987fc9372da3b167fd16d7a19722405b.png" alt="987fc9372da3b167fd16d7a19722405b"><br>与此相反，使用较好的<strong>C++</strong> 数值线性代数库，你可以写出像右边这样的代码，因此取决于你的数值线性代数库的内容。你只需要在<strong>C++</strong> 中将两个向量相乘，根据你所使用的数值和线性代数库的使用细节的不同，你最终使用的代码表达方式可能会有些许不同，但是通过一个库来做内积，你可以得到一段更简单、更有效的代码。</p><p>现在，让我们来看一个更为复杂的例子，这是线性回归算法梯度下降的更新规则：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6ad266a30f955db5b905905670aabfc5.png" alt="6ad266a30f955db5b905905670aabfc5"><br>我们用这条规则对{% raw %}$ j${% endraw %} 等于 0、1、2等等的所有值，更新对象{% raw %}$\theta_j${% endraw %}，我只是用{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}来写方程，假设我们有两个特征量，所以{% raw %}$n${% endraw %}等于2，这些都是我们需要对{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}进行更新，这些都应该是同步更新，我们用一个向量化的代码实现，这里是和之前相同的三个方程，只不过写得小一点而已。</p><p>你可以想象实现这三个方程的方式之一，就是用一个 <strong>for 循环</strong>，就是让 {% raw %}$j${% endraw %}等于0、等于1、等于2，来更新{% raw %}$\theta_j${% endraw %}。但让我们用向量化的方式来实现，看看我们是否能够有一个更简单的方法。基本上用三行代码或者一个<strong>for 循环</strong>，一次实现这三个方程。让我们来看看怎样能用这三步，并将它们压缩成一行向量化的代码来实现。做法如下：</p><p>我打算把{% raw %}$\theta${% endraw %}看做一个向量，然后我用{% raw %}$\theta${% endraw %}-{% raw %}$\alpha${% endraw %} 乘以某个别的向量{% raw %}$\delta${% endraw %} 来更新{% raw %}$\theta${% endraw %}。</p><p>这里的 {% raw %}$\delta${% endraw %} 等于</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fa662ec6d5703d85c314f5e4792a7468.png" alt="fa662ec6d5703d85c314f5e4792a7468"><br>让我解释一下是怎么回事：我要把{% raw %}$\theta${% endraw %}看作一个向量，有一个 {% raw %}$n+1${% endraw %} 维向量，{% raw %}$\alpha${% endraw %} 是一个实数，{% raw %}$\delta${% endraw %}在这里是一个向量。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20bc912bae44e66125f8bfcec6e720c7.png" alt="20bc912bae44e66125f8bfcec6e720c7"><br>所以这个减法运算是一个向量减法，因为 {% raw %}$\alpha${% endraw %} 乘以 δ是一个向量，所以{% raw %}$\theta${% endraw %}就是{% raw %}$\theta${% endraw %} - {% raw %}$\alpha \delta${% endraw %}得到的向量。</p><p>那么什么是向量 {% raw %}$\delta${% endraw %} 呢 ?</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/541b9f097a8e1357c2a75e4f64e53b54.png" alt="541b9f097a8e1357c2a75e4f64e53b54"></p> {% raw %}$X^{(i)}${% endraw %}是一个向量<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0a03d239f2f1d1af057d492bcce276f4.png" alt="0a03d239f2f1d1af057d492bcce276f4"><br>你就会得到这些不同的式子，然后作加和。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8d10103bf172a889090690a00037ffa1.png" alt="8d10103bf172a889090690a00037ffa1"><br>实际上，在以前的一个小测验，如果你要解这个方程，我们说过为了向量化这段代码，我们会令<code>u = 2v +5w</code>因此，我们说向量{% raw %}$u${% endraw %}等于2乘以向量{% raw %}$v${% endraw %}加上5乘以向量{% raw %}$w${% endraw %}。用这个例子说明，如何对不同的向量进行相加，这里的求和是同样的道理。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c84012101afc6836a3396893695d9669.png" alt="c84012101afc6836a3396893695d9669"><br>这就是为什么我们能够向量化地实现线性回归。</p><p>所以，我希望步骤是有逻辑的。请务必看视频，并且保证你确实能理解它。如果你实在不能理解它们数学上等价的原因，你就直接实现这个算法，也是能得到正确答案的。所以即使你没有完全理解为何是等价的，如果只是实现这种算法，你仍然能实现线性回归算法。如果你能弄清楚为什么这两个步骤是等价的，那我希望你可以对向量化有一个更好的理解，如果你在实现线性回归的时候，使用一个或两个以上的特征量。</p><p>有时我们使用几十或几百个特征量来计算线性归回，当你使用向量化地实现线性回归，通常运行速度就会比你以前用你的<strong>for循环</strong>快的多，也就是自己写代码更新{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}。</p><p>因此使用向量化实现方式，你应该是能够得到一个高效得多的线性回归算法。而当你向量化我们将在之后的课程里面学到的算法，这会是一个很好的技巧，无论是对于Octave 或者一些其他的语言 如C++、Java 来让你的代码运行得更高效。</p><h2 id="逻辑回归-Logistic-Regression"><a href="#逻辑回归-Logistic-Regression" class="headerlink" title="逻辑回归(Logistic Regression)"></a>逻辑回归(Logistic Regression)</h2><h3 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h3><p>参考文档: 6 - 1 - Classification (8 min).mkv</p><p>在这个以及接下来的几个视频中，开始介绍分类问题。</p><p>在分类问题中，你要预测的变量 {% raw %}$y${% endraw %} 是离散的值，我们将学习一种叫做逻辑回归 (<strong>Logistic Regression</strong>) 的算法，这是目前最流行使用最广泛的一种学习算法。</p><p>在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；之前我们也谈到了肿瘤分类问题的例子，区别一个肿瘤是恶性的还是良性的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a77886a6eff0f20f9d909975bb69a7ab.png" alt="a77886a6eff0f20f9d909975bb69a7ab"><br>我们从二元的分类问题开始讨论。</p><p>我们将因变量(<strong>dependent variable</strong>)可能属于的两个类分别称为负向类（<strong>negative class</strong>）和正向类（<strong>positive class</strong>），则因变量{% raw %}$y\in { 0,1 \\}${% endraw %} ，其中 0 表示负向类，1 表示正向类。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575441014185.png" alt="enter description here"></p><p>如果我们要用线性回归算法来解决一个分类问题，对于分类， {% raw %}$y${% endraw %} 取值为 0 或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于 1，或者远小于0，即使所有训练样本的标签 {% raw %}$y${% endraw %} 都等于 0 或 1。尽管我们知道标签应该取值0 或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到 1 之间。</p><p>顺便说一下，逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上是一种分类算法，它适用于标签 {% raw %}$y${% endraw %} 取值离散的情况，如：1 0 0 1。</p><p>在接下来的视频中，我们将开始学习逻辑回归算法的细节。</p><h3 id="假说表示"><a href="#假说表示" class="headerlink" title="假说表示"></a>假说表示</h3><p>参考视频: 6 - 2 - Hypothesis Representation (7 min).mkv</p><p>在这段视频中，我要给你展示假设函数的表达式，也就是说，在分类问题中，要用什么样的函数来表示我们的假设。此前我们说过，希望我们的分类器的输出值在0和1之间，因此，我们希望想出一个满足某个性质的假设函数，这个性质是它的预测值要在0和1之间。</p><p>回顾在一开始提到的乳腺癌分类问题，我们可以用线性回归的方法求出适合数据的一条直线：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/29c12ee079c079c6408ee032870b2683.jpg" alt="29c12ee079c079c6408ee032870b2683"><br>根据线性回归模型我们只能预测连续的值，然而对于分类问题，我们需要输出0或1，我们可以预测：</p><p>当{% raw %}${h_\theta}\left( x \right)>=0.5${% endraw %}时，预测 {% raw %}$y=1${% endraw %}。</p><p>当{% raw %}${h_\theta}\left( x \right)&lt;0.5${% endraw %}时，预测 {% raw %}$y=0${% endraw %} 。</p><p>对于上图所示的数据，这样的一个线性模型似乎能很好地完成分类任务。假使我们又观测到一个非常大尺寸的恶性肿瘤，将其作为实例加入到我们的训练集中来，这将使得我们获得一条新的直线。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d027a0612664ea460247c8637b25e306.jpg" alt="d027a0612664ea460247c8637b25e306"><br>这时，再使用0.5作为阀值来预测肿瘤是良性还是恶性便不合适了。可以看出，线性回归模型，因为其预测的值可以超越[0,1]的范围，并不适合解决这样的问题。</p><p>我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在0和1之间。<br>逻辑回归模型的假设是： {% raw %}$h_\theta \left( x \right)=g\left(\theta^{T}X \right)${% endraw %}<br>其中：</p> {% raw %}$X${% endraw %} 代表特征向量 {% raw %}$g${% endraw %} 代表逻辑函数（**logistic function**)是一个常用的逻辑函数为**S**形函数（**Sigmoid function**），公式为： {% raw %}$g\left( z \right)=\frac{1}{1+{ {e}^{-z} }}${% endraw %}。<p><strong>python</strong>代码实现：</p><pre><code class="python">import numpy as np

def sigmoid(z):

return 1 / (1 + np.exp(-z))</code></pre><p>该函数的图像为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1073efb17b0d053b4f9218d4393246cc.jpg" alt="1073efb17b0d053b4f9218d4393246cc"><br>合起来，我们得到逻辑回归模型的假设：</p><p>对模型的理解： $g\left( z \right)=\frac{1}{1+{ {e}^{-z} }}$。</p> $h_\theta \left( x \right)$的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性（**estimated probablity**）即$h_\theta \left( x \right)=P\left( y=1|x;\theta \right)$<p>例如，如果对于给定的$x$，通过已经确定的参数计算得出$h_\theta \left( x \right)=0.7$，则表示有70%的几率$y$为正向类，相应地$y$为负向类的几率为1-0.7=0.3。</p><h3 id="判定边界"><a href="#判定边界" class="headerlink" title="判定边界"></a>判定边界</h3><p>参考视频: 6 - 3 - Decision Boundary (15 min).mkv</p><p>现在讲下决策边界(<strong>decision boundary</strong>)的概念。这个概念能更好地帮助我们理解逻辑回归的假设函数在计算什么。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6590923ac94130a979a8ca1d911b68a3.png" alt="6590923ac94130a979a8ca1d911b68a3"><br>在逻辑回归中，我们预测：</p><p>当${h_\theta}\left( x \right)>=0.5$时，预测 $y=1$。</p><p>当${h_\theta}\left( x \right)&lt;0.5$时，预测 $y=0$ 。</p><p>根据上面绘制出的 <strong>S</strong> 形函数图像，我们知道当</p> $z=0$ 时 $g(z)=0.5$ $z>0$ 时 $g(z)>0.5$ $z&lt;0$ 时 $g(z)&lt;0.5$<p>又 $z={\theta^{T} }x$ ，即：</p> ${\theta^{T} }x>=0$ 时，预测 $y=1$ ${\theta^{T} }x&lt;0$ 时，预测 $y=0$<p>现在假设我们有一个模型：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/58d098bbb415f2c3797a63bd870c3b8f.png" alt="58d098bbb415f2c3797a63bd870c3b8f"><br>并且参数$\theta$ 是向量[-3 1 1]。 则当$-3+{x_1}+{x_2} \geq 0$，即${x_1}+{x_2} \geq 3$时，模型将预测 $y=1$。<br>我们可以绘制直线${x_1}+{x_2} = 3$，这条线便是我们模型的分界线，将预测为1的区域和预测为 0的区域分隔开。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f71fb6102e1ceb616314499a027336dc.jpg" alt="f71fb6102e1ceb616314499a027336dc"><br>假使我们的数据呈现这样的分布情况，怎样的模型才能适合呢？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/197d605aa74bee1556720ea248bab182.jpg" alt="197d605aa74bee1556720ea248bab182"><br>因为需要用曲线才能分隔 $y=0$ 的区域和 $y=1$ 的区域，我们需要二次方特征：${h_\theta}\left( x \right)=g\left( {\theta_0}+{\theta_1}{x_1}+{\theta_{2} }{x_{2} }+{\theta_{3} }x_{1}^{2}+{\theta_{4} }x_{2}^{2} \right)$是[-1 0 0 1 1]，则我们得到的判定边界恰好是圆点在原点且半径为1的圆形。</p><p>我们可以用非常复杂的模型来适应非常复杂形状的判定边界。</p><h3 id="代价函数-1"><a href="#代价函数-1" class="headerlink" title="代价函数"></a>代价函数</h3><p>参考视频: 6 - 4 - Cost Function (11 min).mkv</p><p>在这段视频中，我们要介绍如何拟合逻辑回归模型的参数$\theta$。具体来说，我要定义用来拟合参数的优化目标或者叫代价函数，这便是监督学习问题中的逻辑回归模型的拟合问题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f23eebddd70122ef05baa682f4d6bd0f.png" alt="f23eebddd70122ef05baa682f4d6bd0f"><br>对于线性回归模型，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将${h_\theta}\left( x \right)=\frac{1}{1+{e^{-\theta^{T}x} }}$带入到这样定义了的代价函数中时，我们得到的代价函数将是一个非凸函数（<strong>non-convexfunction</strong>）。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8b94e47b7630ac2b0bcb10d204513810.jpg" alt="8b94e47b7630ac2b0bcb10d204513810"><br>这意味着我们的代价函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。</p><p><strong>线性回归的代价函数</strong>为：$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{1}{2}{ {\left( {h_\theta}\left({x}^{\left( i \right)} \right)-{y}^{\left( i \right)} \right)}^{2} }}$ 。<br>我们<strong>重新定义逻辑回归的代价函数</strong>为：$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{ {Cost}\left( {h_\theta}\left( {x}^{\left( i \right)} \right),{y}^{\left( i \right)} \right)}$，其中</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54249cb51f0086fa6a805291bf2639f1.png" alt="54249cb51f0086fa6a805291bf2639f1"></p> ${h_\theta}\left( x \right)$与 $Cost\left( {h_\theta}\left( x \right),y \right)$之间的关系如下图所示：<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ffa56adcc217800d71afdc3e0df88378.jpg" alt="ffa56adcc217800d71afdc3e0df88378"><br>这样构建的$Cost\left( {h_\theta}\left( x \right),y \right)$函数的特点是：当实际的 $y=1$ 且${h_\theta}\left( x \right)$也为 1 时误差为 0，当 $y=1$ 但${h_\theta}\left( x \right)$不为1时误差随着${h_\theta}\left( x \right)$变小而变大；当实际的 $y=0$ 且${h_\theta}\left( x \right)$也为 0 时代价为 0，当$y=0$ 但${h_\theta}\left( x \right)$不为 0时误差随着 ${h_\theta}\left( x \right)$的变大而变大。<br>将构建的 $Cost\left( {h_\theta}\left( x \right),y \right)$简化如下：</p> $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$<p>带入代价函数得到：</p> $J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$<p>即：$J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$</p><p><strong>Python</strong>代码实现：</p><pre><code class="python">import numpy as np

def cost(theta, X, y):

theta = np.matrix(theta)
X = np.matrix(X)
y = np.matrix(y)
first = np.multiply(-y, np.log(sigmoid(X* theta.T)))
second = np.multiply((1 - y), np.log(1 - sigmoid(X* theta.T)))
return np.sum(first - second) / (len(X))</code></pre><p>在得到这样一个代价函数以后，我们便可以用<strong>梯度下降算法来求得能使代价函数最小的参数</strong>了。算法为：</p><p><strong>Repeat</strong> {</p> $\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j} J(\theta)$<p>(<strong>simultaneously update all</strong> )<br>}</p><p>求导后得到：</p><p><strong>Repeat</strong> {</p> $\theta_j := \theta_j - \alpha \frac{1}{m}\sum\limits_{i=1}^{m}{ {\left( {h_\theta}\left( \mathop{x}^{\left( i \right)} \right)-\mathop{y}^{\left( i \right)} \right)} }\mathop{x}_{j}^{(i)}$<p><strong>(simultaneously update all</strong> )<br>}</p><p>在这个视频中，我们定义了单训练样本的代价函数，凸性分析的内容是超出这门课的范围的，但是可以证明我们所选的代价值函数会给我们一个凸优化问题。代价函数$J(\theta)$会是一个凸函数，并且没有局部最优值。</p><p>推导过程：</p> $J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$<p>考虑：</p> ${h_\theta}\left( { {x}^{(i)} } \right)=\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }}$<p>则：</p> ${ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)$ $={ {y}^{(i)} }\log \left( \frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }} \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }} \right)$ $=-{ {y}^{(i)} }\log \left( 1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} } \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} } \right)$<p>所以：</p> $\frac{\partial }{\partial {\theta_{j} }}J\left( \theta \right)=\frac{\partial }{\partial {\theta_{j} }}[-\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( 1+{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} } \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1+{ {e}^{ {\theta^{T} }{ {x}^{(i)} }} } \right)]}]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\frac{-x_{j}^{(i)}{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} }}{1+{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} }}-\left( 1-{ {y}^{(i)} } \right)\frac{x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }} }]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{ {y}^{(i)} }\frac{x_j^{(i)} }{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}-\left( 1-{ {y}^{(i)} } \right)\frac{x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{ {{y}^{(i)} }x_j^{(i)}-x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }+{ {y}^{(i)} }x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{ {{y}^{(i)} }\left( 1\text{+}{ {e}^{ {\theta^T}{ {x}^{(i)} }} } \right)-{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{({ {y}^{(i)} }-\frac{ {{e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }})x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{({ {y}^{(i)} }-\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }})x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }-{h_\theta}\left( { {x}^{(i)} } \right)]x_j^{(i)} }$ $=\frac{1}{m}\sum\limits_{i=1}^{m}{[{h_\theta}\left( { {x}^{(i)} } \right)-{ {y}^{(i)} }]x_j^{(i)} }$<p>注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。</p><p>一些梯度下降算法之外的选择：<br>除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：<strong>共轭梯度</strong>（<strong>Conjugate Gradient</strong>），<strong>局部优化法</strong>(<strong>Broyden fletcher goldfarb shann,BFGS</strong>)和<strong>有限内存局部优化法</strong>(<strong>LBFGS</strong>) ，<strong>fminunc</strong>是 <strong>matlab</strong>和<strong>octave</strong> 中都带的一个最小值优化函数，使用时我们需要提供代价函数和每个参数的求导，下面是 <strong>octave</strong> 中使用 <strong>fminunc</strong> 函数的代码示例：</p><pre><code class="octave">function [jVal, gradient] = costFunction(theta)

jVal = [...code to compute J(theta)...];
gradient = [...code to compute derivative of J(theta)...];

end

options = optimset(&#39;GradObj&#39;, &#39;on&#39;, &#39;MaxIter&#39;, &#39;100&#39;);

initialTheta = zeros(2,1);

[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);</code></pre><p>在下一个视频中，我们会把单训练样本的代价函数的这些理念进一步发展，然后给出整个训练集的代价函数的定义，我们还会找到一种比我们目前用的更简单的写法，基于这些推导出的结果，我们将应用梯度下降法得到我们的逻辑回归算法。</p><h3 id="简化的成本函数和梯度下降"><a href="#简化的成本函数和梯度下降" class="headerlink" title="简化的成本函数和梯度下降"></a>简化的成本函数和梯度下降</h3><p>参考视频: 6 - 5 - Simplified Cost Function and Gradient Descent (10 min).mkv</p><p>在这段视频中，我们将会找出一种稍微简单一点的方法来写代价函数，来替换我们现在用的方法。同时我们还要弄清楚如何运用梯度下降法，来拟合出逻辑回归的参数。因此，听了这节课，你就应该知道如何实现一个完整的逻辑回归算法。</p><p>这就是逻辑回归的代价函数：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/eb69baa91c2fc6e7dd8ebdf6c79a6a6f.png" alt="eb69baa91c2fc6e7dd8ebdf6c79a6a6f"><br>这个式子可以合并成：</p> $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$<p>即，逻辑回归的代价函数：</p> $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$<p>根据这个代价函数，为了拟合出参数，该怎么做呢？我们要试图找尽量让$J\left( \theta \right)$ 取得最小值的参数$\theta $。</p> $\underset{\theta}{\min }J\left( \theta \right)$<p>所以我们想要尽量减小这一项，这将我们将得到某个参数$\theta $。<br>如果我们给出一个新的样本，假如某个特征 $x$，我们可以用拟合训练样本的参数$\theta $，来输出对假设的预测。<br>另外，我们假设的输出，实际上就是这个概率值：$p(y=1|x;\theta)$，就是关于 $x$以$\theta $为参数，$y=1$ 的概率，你可以认为我们的假设就是估计 $y=1$ 的概率，所以，接下来就是弄清楚如何最大限度地最小化代价函数$J\left( \theta \right)$，作为一个关于$\theta $的函数，这样我们才能为训练集拟合出参数$\theta $。</p><p>最小化代价函数的方法，是使用<strong>梯度下降法</strong>(<strong>gradient descent</strong>)。这是我们的代价函数：</p> $J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$<p>如果我们要最小化这个关于$\theta$的函数值，这就是我们通常用的梯度下降法的模板。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/171031235527.png" alt="171031235527"><br>我们要反复更新每个参数，用这个式子来更新，就是用它自己减去学习率 $\alpha$<br>乘以后面的微分项。求导后得到：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/171031235719.png" alt="171031235719"></p><p>如果你计算一下的话，你会得到这个等式：</p> ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){x_{j} }^{(i)} }$<p>我把它写在这里，将后面这个式子，在 $i=1$ 到 $m$ 上求和，其实就是预测误差乘以$x_j^{(i)}$ ，所以你把这个偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$放回到原来式子这里，我们就可以将梯度下降算法写作如下形式：</p> ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){x_{j} }^{(i)} }$<p>所以，如果你有 $n$ 个特征，也就是说：<img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0171031235044.png" alt="0171031235044">，参数向量$\theta $包括${\theta_{0} }$ ${\theta_{1} }$ ${\theta_{2} }$ 一直到${\theta_{n} }$，那么你就需要用这个式子：</p> ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){ {x}_{j} }^{(i)} }$来同时更新所有$\theta $的值。<p>现在，如果你把这个更新规则和我们之前用在线性回归上的进行比较的话，你会惊讶地发现，这个式子正是我们用来做线性回归梯度下降的。</p><p>那么，线性回归和逻辑回归是同一个算法吗？要回答这个问题，我们要观察逻辑回归看看发生了哪些变化。实际上，假设的定义发生了变化。</p><p>对于线性回归假设函数：</p> ${h_\theta}\left( x \right)={\theta^T}X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$<p>而现在逻辑函数假设函数：</p> ${h_\theta}\left( x \right)=\frac{1}{1+{ {e}^{-{\theta^T}X} }}$<p>因此，即使更新参数的规则看起来基本相同，但由于假设的定义发生了变化，所以逻辑函数的梯度下降，跟线性回归的梯度下降实际上是两个完全不同的东西。</p><p>在先前的视频中，当我们在谈论线性回归的梯度下降法时，我们谈到了如何监控梯度下降法以确保其收敛，我通常也把同样的方法用在逻辑回归中，来监测梯度下降，以确保它正常收敛。</p><p>当使用梯度下降法来实现逻辑回归时，我们有这些不同的参数$\theta $，就是${\theta_{0} }$ ${\theta_{1} }$ ${\theta_{2} }$ 一直到${\theta_{n} }$，我们需要用这个表达式来更新这些参数。我们还可以使用 <strong>for循环</strong>来更新这些参数值，用 <code>for i=1 to n</code>，或者 <code>for i=1 to n+1</code>。当然，不用 <strong>for循环</strong>也是可以的，理想情况下，我们更提倡使用向量化的实现，可以把所有这些 $n$个参数同时更新。</p><p>最后还有一点，我们之前在谈线性回归时讲到的特征缩放，我们看到了特征缩放是如何提高梯度下降的收敛速度的，这个特征缩放的方法，也适用于逻辑回归。如果你的特征范围差距很大的话，那么应用特征缩放的方法，同样也可以让逻辑回归中，梯度下降收敛更快。</p><p>就是这样，现在你知道如何实现逻辑回归，这是一种非常强大，甚至可能世界上使用最广泛的一种分类算法。</p><h3 id="高级优化"><a href="#高级优化" class="headerlink" title="高级优化"></a>高级优化</h3><p>参考视频: 6 - 6 - Advanced Optimization (14 min).mkv</p><p>在上一个视频中，我们讨论了用梯度下降的方法最小化逻辑回归中代价函数$J\left( \theta \right)$。在本次视频中，我会教你们一些高级优化算法和一些高级的优化概念，利用这些方法，我们就能够使通过梯度下降，进行逻辑回归的速度大大提高，而这也将使算法更加适合解决大型的机器学习问题，比如，我们有数目庞大的特征量。<br>现在我们换个角度来看什么是梯度下降，我们有个代价函数$J\left( \theta \right)$，而我们想要使其最小化，那么我们需要做的是编写代码，当输入参数 $\theta$ 时，它们会计算出两样东西：$J\left( \theta \right)$ 以及$J$ 等于 0、1直到 $n$ 时的偏导数项。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/394a1d763425c4ecf12f8f98a392067f.png" alt="394a1d763425c4ecf12f8f98a392067f"><br>假设我们已经完成了可以实现这两件事的代码，那么梯度下降所做的就是反复执行这些更新。<br>另一种考虑梯度下降的思路是：我们需要写出代码来计算$J\left( \theta \right)$ 和这些偏导数，然后把这些插入到梯度下降中，然后它就可以为我们最小化这个函数。<br>对于梯度下降来说，我认为从技术上讲，你实际并不需要编写代码来计算代价函数$J\left( \theta \right)$。你只需要编写代码来计算导数项，但是，如果你希望代码还要能够监控这些$J\left( \theta \right)$ 的收敛性，那么我们就需要自己编写代码来计算代价函数$J(\theta)$和偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$。所以，在写完能够计算这两者的代码之后，我们就可以使用梯度下降。<br>然而梯度下降并不是我们可以使用的唯一算法，还有其他一些算法，更高级、更复杂。如果我们能用这些方法来计算代价函数$J\left( \theta \right)$和偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$两个项的话，那么这些算法就是为我们优化代价函数的不同方法，<strong>共轭梯度法 BFGS</strong> (<strong>变尺度法</strong>) 和<strong>L-BFGS</strong> (<strong>限制变尺度法</strong>) 就是其中一些更高级的优化算法，它们需要有一种方法来计算 $J\left( \theta \right)$，以及需要一种方法计算导数项，然后使用比梯度下降更复杂的算法来最小化代价函数。这三种算法的具体细节超出了本门课程的范畴。实际上你最后通常会花费很多天，或几周时间研究这些算法，你可以专门学一门课来提高数值计算能力，不过让我来告诉你他们的一些特性：</p><p>这三种算法有许多优点：</p><p>一个是使用这其中任何一个算法，你通常不需要手动选择学习率 $\alpha$，所以对于这些算法的一种思路是，给出计算导数项和代价函数的方法，你可以认为算法有一个智能的内部循环，而且，事实上，他们确实有一个智能的内部循环，称为<strong>线性搜索</strong>(<strong>line search</strong>)算法，它可以自动尝试不同的学习速率 $\alpha$，并自动选择一个好的学习速率 $a$，因此它甚至可以为每次迭代选择不同的学习速率，那么你就不需要自己选择。这些算法实际上在做更复杂的事情，不仅仅是选择一个好的学习速率，所以它们往往最终比梯度下降收敛得快多了，不过关于它们到底做什么的详细讨论，已经超过了本门课程的范围。</p><p>实际上，我过去使用这些算法已经很长一段时间了，也许超过十年了，使用得相当频繁，而直到几年前我才真正搞清楚<strong>共轭梯度法 BFGS</strong> 和 <strong>L-BFGS</strong>的细节。</p><p>我们实际上完全有可能成功使用这些算法，并应用于许多不同的学习问题，而不需要真正理解这些算法的内环间在做什么，如果说这些算法有缺点的话，那么我想说主要缺点是它们比梯度下降法复杂多了，特别是你最好不要使用 <strong>L-BGFS</strong>、<strong>BFGS</strong>这些算法，除非你是数值计算方面的专家。实际上，我不会建议你们编写自己的代码来计算数据的平方根，或者计算逆矩阵，因为对于这些算法，我还是会建议你直接使用一个软件库，比如说，要求一个平方根，我们所能做的就是调用一些别人已经写好用来计算数字平方根的函数。幸运的是现在我们有<strong>Octave</strong> 和与它密切相关的 <strong>MATLAB</strong> 语言可以使用。</p><p><strong>Octave</strong> 有一个非常理想的库用于实现这些先进的优化算法，所以，如果你直接调用它自带的库，你就能得到不错的结果。我必须指出这些算法实现得好或不好是有区别的，因此，如果你正在你的机器学习程序中使用一种不同的语言，比如如果你正在使用<strong>C</strong>、<strong>C++</strong>、<strong>Java</strong>等等，你可能会想尝试一些不同的库，以确保你找到一个能很好实现这些算法的库。因为在<strong>L-BFGS</strong>或者等高线梯度的实现上，表现得好与不太好是有差别的，因此现在让我们来说明：如何使用这些算法：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/743a769317d584a66509fc394b4e6095.png" alt="743a769317d584a66509fc394b4e6095"><br>比方说，你有一个含两个参数的问题，这两个参数是${\theta_{0} }$和${\theta_{1} }$，因此，通过这个代价函数，你可以得到${\theta_{1} }$和 ${\theta_{2} }$的值，如果你将$J\left( \theta \right)$ 最小化的话，那么它的最小值将是${\theta_{1} }=5$ ，${\theta_{2} }=5$。代价函数$J\left( \theta \right)$的导数推出来就是这两个表达式：</p> $\frac{\partial }{\partial { {\theta }_{1} }}J(\theta)=2({ {\theta }_{1} }-5)$ $\frac{\partial }{\partial { {\theta }_{2} }}J(\theta)=2({ {\theta }_{2} }-5)$<p>如果我们不知道最小值，但你想要代价函数找到这个最小值，是用比如梯度下降这些算法，但最好是用比它更高级的算法，你要做的就是运行一个像这样的<strong>Octave</strong> 函数：</p><pre><code class="octave">function [jVal, gradient]=costFunction(theta)

jVal=(theta(1)-5)^2+(theta(2)-5)^2;

gradient=zeros(2,1);

gradient(1)=2*(theta(1)-5);

gradient(2)=2*(theta(2)-5);

end</code></pre><p>这样就计算出这个代价函数，函数返回的第二个值是梯度值，梯度值应该是一个2×1的向量，梯度向量的两个元素对应这里的两个偏导数项，运行这个<strong>costFunction</strong> 函数后，你就可以调用高级的优化函数，这个函数叫<br><strong>fminunc</strong>，它表示<strong>Octave</strong> 里无约束最小化函数。调用它的方式如下：</p><pre><code class="octave">options=optimset(&#39;GradObj&#39;,&#39;on&#39;,&#39;MaxIter&#39;,100);

initialTheta=zeros(2,1);

[optTheta, functionVal, exitFlag]=fminunc(@costFunction, initialTheta, options);</code></pre><p>你要设置几个<strong>options</strong>，这个 <strong>options</strong> 变量作为一个数据结构可以存储你想要的<strong>options</strong>，所以 <strong>GradObj</strong> 和<strong>On</strong>，这里设置梯度目标参数为打开(<strong>on</strong>)，这意味着你现在确实要给这个算法提供一个梯度，然后设置最大迭代次数，比方说100，我们给出一个$\theta$ 的猜测初始值，它是一个2×1的向量，那么这个命令就调用<strong>fminunc</strong>，这个@符号表示指向我们刚刚定义的<strong>costFunction</strong> 函数的指针。如果你调用它，它就会使用众多高级优化算法中的一个，当然你也可以把它当成梯度下降，只不过它能自动选择学习速率$\alpha$，你不需要自己来做。然后它会尝试使用这些高级的优化算法，就像加强版的梯度下降法，为你找到最佳的${\theta}$值。</p><p>让我告诉你它在 <strong>Octave</strong> 里什么样：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bd074e119a52163691cff93c3f42a1ee.png" alt="bd074e119a52163691cff93c3f42a1ee"><br>所以我写了这个关于<strong>theta</strong>的 <strong>costFunction</strong> 函数，它计算出代价函数 <strong>jval</strong>以及梯度<strong>gradient</strong>，<strong>gradient</strong> 有两个元素，是代价函数对于<strong>theta(1)</strong> 和 <strong>theta(2)</strong>这两个参数的偏导数。</p><p>我希望你们从这个幻灯片中学到的主要内容是：写一个函数，它能返回代价函数值、梯度值，因此要把这个应用到逻辑回归，或者甚至线性回归中，你也可以把这些优化算法用于线性回归，你需要做的就是输入合适的代码来计算这里的这些东西。</p><p>现在你已经知道如何使用这些高级的优化算法，有了这些算法，你就可以使用一个复杂的优化库，它让算法使用起来更模糊一点。因此也许稍微有点难调试，不过由于这些算法的运行速度通常远远超过梯度下降。</p><p>所以当我有一个很大的机器学习问题时，我会选择这些高级算法，而不是梯度下降。有了这些概念，你就应该能将逻辑回归和线性回归应用于更大的问题中，这就是高级优化的概念。</p><p>在下一个视频，我想要告诉你如何修改你已经知道的逻辑回归算法，然后使它在多类别分类问题中也能正常运行。</p><h3 id="多类别分类：一对多"><a href="#多类别分类：一对多" class="headerlink" title="多类别分类：一对多"></a>多类别分类：一对多</h3><p>参考视频: 6 - 7 - Multiclass Classification_ One-vs-all (6 min).mkv</p><p>在本节视频中，我们将谈到如何使用逻辑回归 (<strong>logistic regression</strong>)来解决多类别分类问题，具体来说，我想通过一个叫做”一对多” (<strong>one-vs-all</strong>) 的分类算法。</p><p>先看这样一些例子。</p><p>第一个例子：假如说你现在需要一个学习算法能自动地将邮件归类到不同的文件夹里，或者说可以自动地加上标签，那么，你也许需要一些不同的文件夹，或者不同的标签来完成这件事，来区分开来自工作的邮件、来自朋友的邮件、来自家人的邮件或者是有关兴趣爱好的邮件，那么，我们就有了这样一个分类问题：其类别有四个，分别用$y=1$、$y=2$、$y=3$、$y=4$ 来代表。</p><p>第二个例子是有关药物诊断的，如果一个病人因为鼻塞来到你的诊所，他可能并没有生病，用 $y=1$ 这个类别来代表；或者患了感冒，用 $y=2$ 来代表；或者得了流感用$y=3$来代表。</p><p>第三个例子：如果你正在做有关天气的机器学习分类问题，那么你可能想要区分哪些天是晴天、多云、雨天、或者下雪天，对上述所有的例子，$y$ 可以取一个很小的数值，一个相对”谨慎”的数值，比如1 到3、1到4或者其它数值，以上说的都是多类分类问题，顺便一提的是，对于下标是0 1 2 3，还是 1 2 3 4 都不重要，我更喜欢将分类从 1 开始标而不是0，其实怎样标注都不会影响最后的结果。</p><p>然而对于之前的一个，二元分类问题，我们的数据看起来可能是像这样：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/68f56679a2113c7857ab9dd2afebcba8.png" alt="68f56679a2113c7857ab9dd2afebcba8"><br>对于一个多类分类问题，我们的数据集或许看起来像这样：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54d7903564b4416305b26f6ff2e13c04.png" alt="54d7903564b4416305b26f6ff2e13c04"><br>我用3种不同的符号来代表3个类别，问题就是给出3个类型的数据集，我们如何得到一个学习算法来进行分类呢？</p><p>我们现在已经知道如何进行二元分类，可以使用逻辑回归，对于直线或许你也知道，可以将数据集一分为二为正类和负类。用一对多的分类思想，我们可以将其用在多类分类问题上。</p><p>下面将介绍如何进行一对多的分类工作，有时这个方法也被称为”一对余”方法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/450a83c67732d254dbac2aeeb8ab910c.png" alt="450a83c67732d254dbac2aeeb8ab910c"><br>现在我们有一个训练集，好比上图表示的有3个类别，我们用三角形表示 $y=1$，方框表示$y=2$，叉叉表示 $y=3$。我们下面要做的就是使用一个训练集，将其分成3个二元分类问题。</p><p>我们先从用三角形代表的类别1开始，实际上我们可以创建一个，新的”伪”训练集，类型2和类型3定为负类，类型1设定为正类，我们创建一个新的训练集，如下图所示的那样，我们要拟合出一个合适的分类器。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b72863ce7f85cd491e5b940924ef5a5f.png" alt="b72863ce7f85cd491e5b940924ef5a5f"><br>这里的三角形是正样本，而圆形代表负样本。可以这样想，设置三角形的值为1，圆形的值为0，下面我们来训练一个标准的逻辑回归分类器，这样我们就得到一个正边界。</p><p>为了能实现这样的转变，我们将多个类中的一个类标记为正向类（$y=1$），然后将其他所有类都标记为负向类，这个模型记作$h_\theta^{\left( 1 \right)}\left( x \right)$。接着，类似地第我们选择另一个类标记为正向类（$y=2$），再将其它类都标记为负向类，将这个模型记作 $h_\theta^{\left( 2 \right)}\left( x \right)$,依此类推。<br>最后我们得到一系列的模型简记为： $h_\theta^{\left( i \right)}\left( x \right)=p\left( y=i|x;\theta \right)$其中：$i=\left( 1,2,3....k \right)$</p><p>最后，在我们需要做预测时，我们将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。</p><p>总之，我们已经把要做的做完了，现在要做的就是训练这个逻辑回归分类器：$h_\theta^{\left( i \right)}\left( x \right)$， 其中 $i$ 对应每一个可能的 $y=i$，最后，为了做出预测，我们给出输入一个新的 $x$ 值，用这个做预测。我们要做的就是在我们三个分类器里面输入 $x$，然后我们选择一个让 $h_\theta^{\left( i \right)}\left( x \right)$ 最大的$ i$，即$\mathop{\max}\limits_i\,h_\theta^{\left( i \right)}\left( x \right)$。</p><p>你现在知道了基本的挑选分类器的方法，选择出哪一个分类器是可信度最高效果最好的，那么就可认为得到一个正确的分类，无论$i$值是多少，我们都有最高的概率值，我们预测$y$就是那个值。这就是多类别分类问题，以及一对多的方法，通过这个小方法，你现在也可以将逻辑回归分类器用在多类分类的问题上。</p><h2 id="正则化-Regularization"><a href="#正则化-Regularization" class="headerlink" title="正则化(Regularization)"></a>正则化(Regularization)</h2><h3 id="过拟合的问题"><a href="#过拟合的问题" class="headerlink" title="过拟合的问题"></a>过拟合的问题</h3><p>参考视频: 7 - 1 - The Problem of Overfitting (10 min).mkv</p><p>到现在为止，我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到过拟合(<strong>over-fitting</strong>)的问题，可能会导致它们效果很差。</p><p>在这段视频中，我将为你解释什么是过度拟合问题，并且在此之后接下来的几个视频中，我们将谈论一种称为正则化(<strong>regularization</strong>)的技术，它可以改善或者减少过度拟合问题。</p><p>如果我们有非常多的特征，我们通过学习得到的假设可能能够非常好地适应训练集（代价函数可能几乎为0），但是可能会不能推广到新的数据。</p><p>下图是一个回归问题的例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/72f84165fbf1753cd516e65d5e91c0d3.jpg" alt="72f84165fbf1753cd516e65d5e91c0d3"><br>第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：预测新数据。我们可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎最合适。</p><p>分类问题中也存在这样的问题：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/be39b497588499d671942cc15026e4a2.jpg" alt="be39b497588499d671942cc15026e4a2"><br>就以多项式理解，$x$ 的次数越高，拟合的越好，但相应的预测的能力就可能变差。</p><p>问题是，如果我们发现了过拟合问题，应该如何处理？</p><ol><li><p>丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如<strong>PCA</strong>）</p></li><li><p>正则化。 保留所有的特征，但是减少参数的大小（<strong>magnitude</strong>）。</p></li></ol><h3 id="代价函数-2"><a href="#代价函数-2" class="headerlink" title="代价函数"></a>代价函数</h3><p>参考视频: 7 - 2 - Cost Function (10 min).mkv</p><p>上面的回归问题中如果我们的模型是：</p> ${h_\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}+{\theta_{3} }{x_{3}^3}+{\theta_{4} }{x_{4}^4}$<p>我们可以从之前的事例中看出，正是那些高次项导致了过拟合的产生，所以如果我们能让这些高次项的系数接近于0的话，我们就能很好的拟合了。<br>所以我们要做的就是在一定程度上减小这些参数$\theta $ 的值，这就是正则化的基本方法。我们决定要减少${\theta_{3} }$和${\theta_{4} }$的大小，我们要做的便是修改代价函数，在其中${\theta_{3} }$和${\theta_{4} }$ 设置一点惩罚。这样做的话，我们在尝试最小化代价时也需要将这个惩罚纳入考虑中，并最终导致选择较小一些的${\theta_{3} }$和${\theta_{4} }$。<br>修改后的代价函数如下：$\underset{\theta }{\mathop{\min } }\,\frac{1}{2m}[\sum\limits_{i=1}^{m}{ {{\left( { {h}_{\theta } }\left( { {x}^{(i)} } \right)-{ {y}^{(i)} } \right)}^{2} }+1000\theta _{3}^{2}+10000\theta _{4}^{2}]}$</p><p>通过这样的代价函数选择出的${\theta_{3} }$和${\theta_{4} }$ 对预测结果的影响就比之前要小许多。假如我们有非常多的特征，我们并不知道其中哪些特征我们要惩罚，我们将对所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设：$J\left( \theta \right)=\frac{1}{2m}[\sum\limits_{i=1}^{m}{ {{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })}^{2} }+\lambda \sum\limits_{j=1}^{n}{\theta_{j}^{2} }]}$</p><p>其中$\lambda $又称为正则化参数（<strong>Regularization Parameter</strong>）。 注：根据惯例，我们不对${\theta_{0} }$ 进行惩罚。经过正则化处理的模型与原模型的可能对比如下图所示：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ea76cc5394cf298f2414f230bcded0bd.jpg" alt="ea76cc5394cf298f2414f230bcded0bd"><br>如果选择的正则化参数$\lambda$ 过大，则会把所有的参数都最小化了，导致模型变成 ${h_\theta}\left( x \right)={\theta_{0} }$，也就是上图中红色直线所示的情况，造成欠拟合。<br>那为什么增加的一项$\lambda =\sum\limits_{j=1}^{n}{\theta_j^{2} }$ 可以使$\theta $的值减小呢？<br>因为如果我们令 $\lambda$ 的值很大的话，为了使<strong>Cost Function</strong> 尽可能的小，所有的 $\theta $ 的值（不包括${\theta_{0} }$）都会在一定程度上减小。<br>但若$\lambda$ 的值太大了，那么$\theta $（不包括${\theta_{0} }$）都会趋近于0，这样我们所得到的只能是一条平行于$x$轴的直线。<br>所以对于正则化，我们要取一个合理的 $\lambda$ 的值，这样才能更好的应用正则化。<br>回顾一下代价函数，为了使用正则化，让我们把这些概念应用到到线性回归和逻辑回归中去，那么我们就可以让他们避免过度拟合了。</p><h3 id="正则化线性回归"><a href="#正则化线性回归" class="headerlink" title="正则化线性回归"></a>正则化线性回归</h3><p>参考视频: 7 - 3 - Regularized Linear Regression (11 min).mkv</p><p>对于线性回归的求解，我们之前推导了两种学习算法：一种基于梯度下降，一种基于正规方程。</p><p>正则化线性回归的代价函数为：</p> $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{[({ {({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })}^{2} }+\lambda \sum\limits_{j=1}^{n}{\theta _{j}^{2} })]}$<p>如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对$\theta_0$进行正则化，所以梯度下降算法将分两种情形：</p> $Repeat$ $until$ $convergence${<p>​ ${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{0}^{(i)} })$</p><p>​ ${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }+\frac{\lambda }{m}{\theta_j}]$</p><p>​ $for$ $j=1,2,...n$</p><p>​ }</p><p>对上面的算法中$ j=1,2,...,n$ 时的更新式子进行调整可得：</p> ${\theta_j}:={\theta_j}(1-a\frac{\lambda }{m})-a\frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }$<p>可以看出，正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令$\theta $值减少了一个额外的值。</p><p>我们同样也可以利用正规方程来求解正则化线性回归模型，方法如下所示：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/71d723ddb5863c943fcd4e6951114ee3.png" alt="71d723ddb5863c943fcd4e6951114ee3"><br>图中的矩阵尺寸为 $(n+1)*(n+1)$。</p><h3 id="正则化的逻辑回归模型"><a href="#正则化的逻辑回归模型" class="headerlink" title="正则化的逻辑回归模型"></a>正则化的逻辑回归模型</h3><p>参考视频: 7 - 4 - Regularized Logistic Regression (9 min).mkv</p><p>针对逻辑回归问题，我们在之前的课程已经学习过两种优化算法：我们首先学习了使用梯度下降法来优化代价函数$J\left( \theta \right)$，接下来学习了更高级的优化算法，这些高级优化算法需要你自己设计代价函数$J\left( \theta \right)$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2726da11c772fc58f0c85e40aaed14bd.png" alt="2726da11c772fc58f0c85e40aaed14bd"><br>自己计算导数同样对于逻辑回归，我们也给代价函数增加一个正则化的表达式，得到代价函数：</p> $J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}+\frac{\lambda }{2m}\sum\limits_{j=1}^{n}{\theta _{j}^{2} }$<p><strong>Python</strong>代码：</p><pre><code class="python">import numpy as np

def costReg(theta, X, y, learningRate):
theta = np.matrix(theta)
X = np.matrix(X)
y = np.matrix(y)
first = np.multiply(-y, np.log(sigmoid(X*theta.T)))
second = np.multiply((1 - y), np.log(1 - sigmoid(X*theta.T)))
reg = (learningRate / (2 * len(X))* np.sum(np.power(theta[:,1:theta.shape[1]],2))
return np.sum(first - second) / (len(X)) + reg</code></pre><p>要最小化该代价函数，通过求导，得出梯度下降算法为：</p> $Repeat$ $until$ $convergence${<p>​ ${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{0}^{(i)} })$</p><p>​ ${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }+\frac{\lambda }{m}{\theta_j}]$</p><p>​ $for$ $j=1,2,...n$</p><p>​ }</p><p>注：看上去同线性回归一样，但是知道 ${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$，所以与线性回归不同。<br><strong>Octave</strong> 中，我们依旧可以用 <code>fminuc</code> 函数来求解代价函数最小化的参数，值得注意的是参数${\theta_{0} }$的更新规则与其他情况不同。<br>注意：</p><ol><li><p>虽然正则化的逻辑回归中的梯度下降和正则化的线性回归中的表达式看起来一样，但由于两者的${h_\theta}\left( x \right)$不同所以还是有很大差别。</p></li><li>${\theta_{0} }$不参与其中的任何一个正则化。</li></ol><p>目前大家对机器学习算法可能还只是略懂，但是一旦你精通了线性回归、高级优化算法和正则化技术，坦率地说，你对机器学习的理解可能已经比许多工程师深入了。现在，你已经有了丰富的机器学习知识，目测比那些硅谷工程师还厉害，或者用机器学习算法来做产品。</p><p>接下来的课程中，我们将学习一个非常强大的非线性分类器，无论是线性回归问题，还是逻辑回归问题，都可以构造多项式来解决。你将逐渐发现还有更强大的非线性分类器，可以用来解决多项式回归问题。我们接下来将将学会，比现在解决问题的方法强大N倍的学习算法。</p><h2 id="神经网络：表述-Neural-Networks-Representation"><a href="#神经网络：表述-Neural-Networks-Representation" class="headerlink" title="神经网络：表述(Neural Networks: Representation)"></a>神经网络：表述(Neural Networks: Representation)</h2><h3 id="非线性假设"><a href="#非线性假设" class="headerlink" title="非线性假设"></a>非线性假设</h3><p>参考视频: 8 - 1 - Non-linear Hypotheses (10 min).mkv</p><p>我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。</p><p>下面是一个例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5316b24cd40908fb5cb1db5a055e4de5.png" alt="5316b24cd40908fb5cb1db5a055e4de5"><br>当我们使用$x_1$, $x_2$ 的多次项式进行预测时，我们可以应用的很好。<br>之前我们已经看到过，使用非线性的多项式项，能够帮助我们建立更好的分类模型。假设我们有非常多的特征，例如大于100个变量，我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合$(x_1x_2+x_1x_3+x_1x_4+...+x_2x_3+x_2x_4+...+x_{99}x_{100})$，我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。</p><p>假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车），我们怎样才能这么做呢？一种方法是我们利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。</p><p>假如我们只选用灰度图片，每个像素则只有一个值（而非 <strong>RGB</strong>值），我们可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3ac5e06e852ad3deef4cba782ebe425b.jpg" alt="3ac5e06e852ad3deef4cba782ebe425b"><br>假使我们采用的都是50x50像素的小图片，并且我们将所有的像素视为特征，则会有 2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约${ {2500}^{2} }/2$个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们需要神经网络。</p><h3 id="神经元和大脑"><a href="#神经元和大脑" class="headerlink" title="神经元和大脑"></a>神经元和大脑</h3><p>参考视频: 8 - 2 - Neurons and the Brain (8 min).mkv</p><p>神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。</p><p>在这门课中，我将向你们介绍神经网络。因为它能很好地解决不同的机器学习问题。而不只因为它们在逻辑上行得通，在这段视频中，我想告诉你们一些神经网络的背景知识，由此我们能知道可以用它们来做什么。不管是将其应用到现代的机器学习问题上，还是应用到那些你可能会感兴趣的问题中。也许，这一伟大的人工智能梦想在未来能制造出真正的智能机器。另外，我们还将讲解神经网络是怎么涉及这些问题的神经网络产生的原因是人们想尝试设计出模仿大脑的算法，从某种意义上说如果我们想要建立学习系统，那为什么不去模仿我们所认识的最神奇的学习机器——人类的大脑呢？</p><p>神经网络逐渐兴起于二十世纪八九十年代，应用得非常广泛。但由于各种原因，在90年代的后期应用减少了。但是最近，神经网络又东山再起了。其中一个原因是：神经网络是计算量有些偏大的算法。然而大概由于近些年计算机的运行速度变快，才足以真正运行起大规模的神经网络。正是由于这个原因和其他一些我们后面会讨论到的技术因素，如今的神经网络对于许多应用来说是最先进的技术。当你想模拟大脑时，是指想制造出与人类大脑作用效果相同的机器。大脑可以学会去以看而不是听的方式处理图像，学会处理我们的触觉。</p><p>我们能学习数学，学着做微积分，而且大脑能处理各种不同的令人惊奇的事情。似乎如果你想要模仿它，你得写很多不同的软件来模拟所有这些五花八门的奇妙的事情。不过能不能假设大脑做所有这些，不同事情的方法，不需要用上千个不同的程序去实现。相反的，大脑处理的方法，只需要一个单一的学习算法就可以了？尽管这只是一个假设，不过让我和你分享，一些这方面的证据。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7912ea75bc7982998870721cb1177226.jpg" alt="7912ea75bc7982998870721cb1177226"><br>大脑的这一部分这一小片红色区域是你的听觉皮层，你现在正在理解我的话，这靠的是耳朵。耳朵接收到声音信号，并把声音信号传递给你的听觉皮层，正因如此，你才能明白我的话。</p><p>神经系统科学家做了下面这个有趣的实验，把耳朵到听觉皮层的神经切断。在这种情况下，将其重新接到一个动物的大脑上，这样从眼睛到视神经的信号最终将传到听觉皮层。如果这样做了。那么结果表明听觉皮层将会学会“看”。这里的“看”代表了我们所知道的每层含义。所以，如果你对动物这样做，那么动物就可以完成视觉辨别任务，它们可以看图像，并根据图像做出适当的决定。它们正是通过脑组织中的这个部分完成的。下面再举另一个例子，这块红色的脑组织是你的躯体感觉皮层，这是你用来处理触觉的，如果你做一个和刚才类似的重接实验，那么躯体感觉皮层也能学会“看”。这个实验和其它一些类似的实验，被称为神经重接实验，从这个意义上说，如果人体有同一块脑组织可以处理光、声或触觉信号，那么也许存在一种学习算法，可以同时处理视觉、听觉和触觉，而不是需要运行上千个不同的程序，或者上千个不同的算法来做这些大脑所完成的成千上万的美好事情。也许我们需要做的就是找出一些近似的或实际的大脑学习算法，然后实现它大脑通过自学掌握如何处理这些不同类型的数据。在很大的程度上，可以猜想如果我们把几乎任何一种传感器接入到大脑的几乎任何一个部位的话，大脑就会学会处理它。</p><p>下面再举几个例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2b74c1eeff95db47f5ebd8aef1290f09.jpg" alt="2b74c1eeff95db47f5ebd8aef1290f09"><br>这张图是用舌头学会“看”的一个例子。它的原理是：这实际上是一个名为<strong>BrainPort</strong>的系统，它现在正在<strong>FDA</strong><br>(美国食品和药物管理局)的临床试验阶段，它能帮助失明人士看见事物。它的原理是，你在前额上带一个灰度摄像头，面朝前，它就能获取你面前事物的低分辨率的灰度图像。你连一根线到舌头上安装的电极阵列上，那么每个像素都被映射到你舌头的某个位置上，可能电压值高的点对应一个暗像素电压值低的点。对应于亮像素，即使依靠它现在的功能，使用这种系统就能让你我在几十分钟里就学会用我们的舌头“看”东西。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/95c020b2227ca4b9a9bcbd40099d1766.png" alt="95c020b2227ca4b9a9bcbd40099d1766"><br>这是第二个例子，关于人体回声定位或者说人体声纳。你有两种方法可以实现：你可以弹响指，或者咂舌头。不过现在有失明人士，确实在学校里接受这样的培训，并学会解读从环境反弹回来的声波模式—这就是声纳。如果你搜索<strong>YouTube</strong>之后，就会发现有些视频讲述了一个令人称奇的孩子，他因为癌症眼球惨遭移除，虽然失去了眼球，但是通过打响指，他可以四处走动而不撞到任何东西，他能滑滑板，他可以将篮球投入篮框中。注意这是一个没有眼球的孩子。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/697ae58b1370e81749f9feb333bdf842.png" alt="697ae58b1370e81749f9feb333bdf842"><br>第三个例子是触觉皮带，如果你把它戴在腰上，蜂鸣器会响，而且总是朝向北时发出嗡嗡声。它可以使人拥有方向感，用类似于鸟类感知方向的方式。</p><p>还有一些离奇的例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1ee5c76a62b35384491c603bb54c8c0c.png" alt="1ee5c76a62b35384491c603bb54c8c0c"><br>如果你在青蛙身上插入第三只眼，青蛙也能学会使用那只眼睛。因此，这将会非常令人惊奇。如果你能把几乎任何传感器接入到大脑中，大脑的学习算法就能找出学习数据的方法，并处理这些数据。从某种意义上来说，如果我们能找出大脑的学习算法，然后在计算机上执行大脑学习算法或与之相似的算法，也许这将是我们向人工智能迈进做出的最好的尝试。人工智能的梦想就是：有一天能制造出真正的智能机器。</p><p>神经网络可能为我们打开一扇进入遥远的人工智能梦的窗户，但我在这节课中讲授神经网络的原因，主要是对于现代机器学习应用。它是最有效的技术方法。因此在接下来的一些课程中，我们将开始深入到神经网络的技术细节。</p><h3 id="模型表示1"><a href="#模型表示1" class="headerlink" title="模型表示1"></a>模型表示1</h3><p>参考视频: 8 - 3 - Model Representation I (12 min).mkv</p><p>为了构建神经网络模型，我们需要首先思考大脑中的神经网络是怎样的？每一个神经元都可以被认为是一个处理单元/神经核（<strong>processing unit</strong>/<strong>Nucleus</strong>），它含有许多输入/树突（<strong>input</strong>/<strong>Dendrite</strong>），并且有一个输出/轴突（<strong>output</strong>/<strong>Axon</strong>）。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3d93e8c1cd681c2b3599f05739e3f3cc.jpg" alt="3d93e8c1cd681c2b3599f05739e3f3cc"><br>下面是一组神经元的示意图，神经元利用微弱的电流进行沟通。这些弱电流也称作动作电位，其实就是一些微弱的电流。所以如果神经元想要传递一个消息，它就会就通过它的轴突，发送一段微弱电流给其他神经元，这就是轴突。</p><p>这里是一条连接到输入神经，或者连接另一个神经元树突的神经，接下来这个神经元接收这条消息，做一些计算，它有可能会反过来将在轴突上的自己的消息传给其他神经元。这就是所有人类思考的模型：我们的神经元把自己的收到的消息进行计算，并向其他神经元传递消息。这也是我们的感觉和肌肉运转的原理。如果你想活动一块肌肉，就会触发一个神经元给你的肌肉发送脉冲，并引起你的肌肉收缩。如果一些感官：比如说眼睛想要给大脑传递一个消息，那么它就像这样发送电脉冲给大脑的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7dabd366525c7c3124e844abce8c2dd6.png" alt="7dabd366525c7c3124e844abce8c2dd6"><br>神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，<strong>activation unit</strong>）采纳一些特征作为输出，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，参数又可被成为权重（<strong>weight</strong>）。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c2233cd74605a9f8fe69fd59547d3853.jpg" alt="c2233cd74605a9f8fe69fd59547d3853"><br>我们设计出了类似于神经元的神经网络，效果如下：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fbb4ffb48b64468c384647d45f7b86b5.png" alt="fbb4ffb48b64468c384647d45f7b86b5"><br>其中$x_1$, $x_2$, $x_3$是输入单元（<strong>input units</strong>），我们将原始数据输入给它们。</p> $a_1$, $a_2$, $a_3$是中间单元，它们负责将数据进行处理，然后呈递到下一层。<p>最后是输出单元，它负责计算${h_\theta}\left( x \right)$。</p><p>神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个3层的神经网络，第一层成为输入层（<strong>Input Layer</strong>），最后一层称为输出层（<strong>Output Layer</strong>），中间一层成为隐藏层（<strong>Hidden Layers</strong>）。我们为每一层都增加一个偏差单位（<strong>bias unit</strong>）：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8293711e1d23414d0a03f6878f5a2d91.jpg" alt="8293711e1d23414d0a03f6878f5a2d91"><br>下面引入一些标记法来帮助描述模型：</p> $a_{i}^{\left( j \right)}$ 代表第$j$ 层的第 $i$ 个激活单元。${ {\theta }^{\left( j \right)} }$代表从第 $j$ 层映射到第$ j+1$ 层时的权重的矩阵，例如${ {\theta }^{\left( 1 \right)} }$代表从第一层映射到第二层的权重的矩阵。其尺寸为：以第 $j+1$层的激活单元数量为行数，以第 $j$ 层的激活单元数加一为列数的矩阵。例如：上图所示的神经网络中${ {\theta }^{\left( 1 \right)} }$的尺寸为 3*4。<p>对于上图所示的模型，激活单元和输出分别表达为：</p> $a_{1}^{(2)}=g(\Theta _{10}^{(1)}{ {x}_{0} }+\Theta _{11}^{(1)}{ {x}_{1} }+\Theta _{12}^{(1)}{ {x}_{2} }+\Theta _{13}^{(1)}{ {x}_{3} })$ $a_{2}^{(2)}=g(\Theta _{20}^{(1)}{ {x}_{0} }+\Theta _{21}^{(1)}{ {x}_{1} }+\Theta _{22}^{(1)}{ {x}_{2} }+\Theta _{23}^{(1)}{ {x}_{3} })$ $a_{3}^{(2)}=g(\Theta _{30}^{(1)}{ {x}_{0} }+\Theta _{31}^{(1)}{ {x}_{1} }+\Theta _{32}^{(1)}{ {x}_{2} }+\Theta _{33}^{(1)}{ {x}_{3} })$ ${ {h}_{\Theta } }(x)=g(\Theta _{10}^{(2)}a_{0}^{(2)}+\Theta _{11}^{(2)}a_{1}^{(2)}+\Theta _{12}^{(2)}a_{2}^{(2)}+\Theta _{13}^{(2)}a_{3}^{(2)})$<p>上面进行的讨论中只是将特征矩阵中的一行（一个训练实例）喂给了神经网络，我们需要将整个训练集都喂给我们的神经网络算法来学习模型。</p><p>我们可以知道：每一个$a$都是由上一层所有的$x$和每一个$x$所对应的决定的。</p><p>（我们把这样从左到右的算法称为前向传播算法( <strong>FORWARD PROPAGATION</strong> )）</p><p>把$x$, $\theta$, $a$ 分别用矩阵表示：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20171101224053.png" alt="20171101224053"><br>我们可以得到$\theta \cdot X=a$ 。</p><h3 id="模型表示2"><a href="#模型表示2" class="headerlink" title="模型表示2"></a>模型表示2</h3><p>参考视频: 8 - 4 - Model Representation II (12 min).mkv</p><p>( <strong>FORWARD PROPAGATION</strong> )<br>相对于使用循环来编码，利用向量化的方法会使得计算更为简便。以上面的神经网络为例，试着计算第二层的值：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/303ce7ad54d957fca9dbb6a992155111.png" alt="303ce7ad54d957fca9dbb6a992155111"></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e17f58ce9a79525089a1c2e0b4c0ccc.png" alt="2e17f58ce9a79525089a1c2e0b4c0ccc"><br>我们令 ${ {z}^{\left( 2 \right)} }={ {\theta }^{\left( 1 \right)} }x$，则 ${ {a}^{\left( 2 \right)} }=g({ {z}^{\left( 2 \right)} })$ ，计算后添加 $a_{0}^{\left( 2 \right)}=1$。 计算输出的值为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/43f1cb8a2a7e9a18f928720adc1fac22.png" alt="43f1cb8a2a7e9a18f928720adc1fac22"><br>我们令 ${ {z}^{\left( 3 \right)} }={ {\theta }^{\left( 2 \right)} }{ {a}^{\left( 2 \right)} }$，则 $h_\theta(x)={ {a}^{\left( 3 \right)} }=g({ {z}^{\left( 3 \right)} })$。<br>这只是针对训练集中一个训练实例所进行的计算。如果我们要对整个训练集进行计算，我们需要将训练集特征矩阵进行转置，使得同一个实例的特征都在同一列里。即：</p> ${ {z}^{\left( 2 \right)} }={ {\Theta }^{\left( 1 \right)} }\times { {X}^{T} } $ ${ {a}^{\left( 2 \right)} }=g({ {z}^{\left( 2 \right)} })$<p>为了更好了了解<strong>Neuron Networks</strong>的工作原理，我们先把左半部分遮住：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6167ad04e696c400cb9e1b7dc1e58d8a.png" alt="6167ad04e696c400cb9e1b7dc1e58d8a"><br>右半部分其实就是以$a_0, a_1, a_2, a_3$, 按照<strong>Logistic Regression</strong>的方式输出$h_\theta(x)$：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/10342b472803c339a9e3bc339188c5b8.png" alt="10342b472803c339a9e3bc339188c5b8"><br>其实神经网络就像是<strong>logistic regression</strong>，只不过我们把<strong>logistic regression</strong>中的输入向量$\left[ x_1\sim {x_3} \right]$ 变成了中间层的$\left[ a_1^{(2)}\sim a_3^{(2)} \right]$, 即: $h_\theta(x)=g\left( \Theta_0^{\left( 2 \right)}a_0^{\left( 2 \right)}+\Theta_1^{\left( 2 \right)}a_1^{\left( 2 \right)}+\Theta_{2}^{\left( 2 \right)}a_{2}^{\left( 2 \right)}+\Theta_{3}^{\left( 2 \right)}a_{3}^{\left( 2 \right)} \right)$<br>我们可以把$a_0, a_1, a_2, a_3$看成更为高级的特征值，也就是$x_0, x_1, x_2, x_3$的进化体，并且它们是由 $x$与$\theta$决定的，因为是梯度下降的，所以$a$是变化的，并且变得越来越厉害，所以这些更高级的特征值远比仅仅将 $x$次方厉害，也能更好的预测新数据。<br>这就是神经网络相比于逻辑回归和线性回归的优势。</p><h3 id="特征和直观理解1"><a href="#特征和直观理解1" class="headerlink" title="特征和直观理解1"></a>特征和直观理解1</h3><p>参考视频: 8 - 5 - Examples and Intuitions I (7 min).mkv</p><p>从本质上讲，神经网络能够通过学习得出其自身的一系列特征。在普通的逻辑回归中，我们被限制为使用数据中的原始特征$x_1,x_2,...,{ {x}_{n} }$，我们虽然可以使用一些二项式项来组合这些特征，但是我们仍然受到这些原始特征的限制。在神经网络中，原始特征只是输入层，在我们上面三层的神经网络例子中，第三层也就是输出层做出的预测利用的是第二层的特征，而非输入层中的原始特征，我们可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输出变量的新特征。</p><p>神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑与(<strong>AND</strong>)、逻辑或(<strong>OR</strong>)。</p><p>举例说明：逻辑与(<strong>AND</strong>)；下图中左半部分是神经网络的设计与<strong>output</strong>层表达式，右边上部分是<strong>sigmod</strong>函数，下半部分是真值表。</p><p>我们可以用这样的一个神经网络表示<strong>AND</strong> 函数：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/809187c1815e1ec67184699076de51f2.png" alt="809187c1815e1ec67184699076de51f2"><br>其中$\theta_0 = -30, \theta_1 = 20, \theta_2 = 20$<br>我们的输出函数$h_\theta(x)$即为：$h_\Theta(x)=g\left( -30+20x_1+20x_2 \right)$</p><p>我们知道$g(x)$的图像是：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6d652f125654d077480aadc578ae0164.png" alt="6d652f125654d077480aadc578ae0164"></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f75115da9090701516aa1ff0295436dd.png" alt="f75115da9090701516aa1ff0295436dd"><br>所以我们有：$h_\Theta(x) \approx \text{x}_1 \text{AND} \, \text{x}_2$</p><p>所以我们的：$h_\Theta(x) $</p><p>这就是<strong>AND</strong>函数。</p><p>接下来再介绍一个<strong>OR</strong>函数：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/aa27671f7a3a16545a28f356a2fb98c0.png" alt="aa27671f7a3a16545a28f356a2fb98c0"><br><strong>OR</strong>与<strong>AND</strong>整体一样，区别只在于的取值不同。</p><h3 id="样本和直观理解II"><a href="#样本和直观理解II" class="headerlink" title="样本和直观理解II"></a>样本和直观理解II</h3><p>参考视频: 8 - 6 - Examples and Intuitions II (10 min).mkv</p><p>二元逻辑运算符（<strong>BINARY LOGICAL OPERATORS</strong>）当输入特征为布尔值（0或1）时，我们可以用一个单一的激活层可以作为二元逻辑运算符，为了表示不同的运算符，我们只需要选择不同的权重即可。</p><p>下图的神经元（三个权重分别为-30，20，20）可以被视为作用同于逻辑与（<strong>AND</strong>）：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/57480b04956f1dc54ecfc64d68a6b357.png" alt="57480b04956f1dc54ecfc64d68a6b357"><br>下图的神经元（三个权重分别为-10，20，20）可以被视为作用等同于逻辑或（<strong>OR</strong>）：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7527e61b1612dcf84dadbcf7a26a22fb.png" alt="7527e61b1612dcf84dadbcf7a26a22fb"><br>下图的神经元（两个权重分别为 10，-20）可以被视为作用等同于逻辑非（<strong>NOT</strong>）：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1fd3017dfa554642a5e1805d6d2b1fa6.png" alt="1fd3017dfa554642a5e1805d6d2b1fa6"><br>我们可以利用神经元来组合成更为复杂的神经网络以实现更复杂的运算。例如我们要实现<strong>XNOR</strong> 功能（输入的两个值必须一样，均为1或均为0），即 $\text{XNOR}=( \text{x}_1\, \text{AND}\, \text{x}_2 )\, \text{OR} \left( \left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right) \right)$<br>首先构造一个能表达$\left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right)$部分的神经元：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4c44e69a12b48efdff2fe92a0a698768.png" alt="4c44e69a12b48efdff2fe92a0a698768"><br>然后将表示 <strong>AND</strong> 的神经元和表示$\left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right)$的神经元以及表示 OR 的神经元进行组合：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/432c906875baca78031bd337fe0c8682.png" alt="432c906875baca78031bd337fe0c8682"><br>我们就得到了一个能实现 $\text{XNOR}$ 运算符功能的神经网络。</p><p>按这种方法我们可以逐渐构造出越来越复杂的函数，也能得到更加厉害的特征值。</p><p>这就是神经网络的厉害之处。</p><h3 id="多类分类"><a href="#多类分类" class="headerlink" title="多类分类"></a>多类分类</h3><p>参考视频: 8 - 7 - Multiclass Classification (4 min).mkv</p><p>当我们有不止两种分类时（也就是$y=1,2,3….$），比如以下这种情况，该怎么办？如果我们要训练一个神经网络算法来识别路人、汽车、摩托车和卡车，在输出层我们应该有4个值。例如，第一个值为1或0用于预测是否是行人，第二个值用于判断是否为汽车。</p><p>输入向量$x$有三个维度，两个中间层，输出层4个神经元分别用来表示4类，也就是每一个数据在输出层都会出现${ {\left[ a\text{ }b\text{ }c\text{ }d \right]}^{T} }$，且$a,b,c,d$中仅有一个为1，表示当前类。下面是该神经网络的可能结构示例：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f3236b14640fa053e62c73177b3474ed.jpg" alt="f3236b14640fa053e62c73177b3474ed"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/685180bf1774f7edd2b0856a8aae3498.png" alt="685180bf1774f7edd2b0856a8aae3498"><br>神经网络算法的输出结果为四种可能情形之一：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5e1a39d165f272b7f145c68ef78a3e13.png" alt="5e1a39d165f272b7f145c68ef78a3e13"></p><h2 id="神经网络的学习-Neural-Networks-Learning"><a href="#神经网络的学习-Neural-Networks-Learning" class="headerlink" title="神经网络的学习(Neural Networks: Learning)"></a>神经网络的学习(Neural Networks: Learning)</h2><h3 id="代价函数-3"><a href="#代价函数-3" class="headerlink" title="代价函数"></a>代价函数</h3><p>参考视频: 9 - 1 - Cost Function (7 min).mkv</p><p>首先引入一些便于稍后讨论的新标记方法：</p><p>假设神经网络的训练样本有$m$个，每个包含一组输入$x$和一组输出信号$y$，$L$表示神经网络层数，$S_I$表示每层的<strong>neuron</strong>个数($S_l$表示输出层神经元个数)，$S_L$代表最后一层中处理单元的个数。</p><p>将神经网络的分类定义为两种情况：二类分类和多类分类，</p><p>二类分类：$S_L=0, y=0\, or\, 1$表示哪一类；</p> $K$类分类：$S_L=k, y_i = 1$表示分到第$i$类；$(k>2)$<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8f7c28297fc9ed297f42942018441850.jpg" alt="8f7c28297fc9ed297f42942018441850"><br>我们回顾逻辑回归问题中我们的代价函数为：</p> $ J\left(\theta \right)=-\frac{1}{m}\left[\sum_\limits{i=1}^{m}{y}^{(i)}\log{h_\theta({x}^{(i)})}+\left(1-{y}^{(i)}\right)log\left(1-h_\theta\left({x}^{(i)}\right)\right)\right]+\frac{\lambda}{2m}\sum_\limits{j=1}^{n}{\theta_j}^{2} $<p>在逻辑回归中，我们只有一个输出变量，又称标量（<strong>scalar</strong>），也只有一个因变量$y$，但是在神经网络中，我们可以有很多输出变量，我们的$h_\theta(x)$是一个维度为$K$的向量，并且我们训练集中的因变量也是同样维度的一个向量，因此我们的代价函数会比逻辑回归更加复杂一些，为：$\newcommand{\subk}[1]{ #1_k }$</p> $$h_\theta\left(x\right)\in \mathbb{R}^{K}$$ $${\left({h_\theta}\left(x\right)\right)}_{i}={i}^{th} \text{output}$$ $J(\Theta) = -\frac{1}{m} \left[ \sum\limits_{i=1}^{m} \sum\limits_{k=1}^{k} {y_k}^{(i)} \log \subk{(h_\Theta(x^{(i)}))} + \left( 1 - y_k^{(i)} \right) \log \left( 1- \subk{\left( h_\Theta \left( x^{(i)} \right) \right)} \right) \right] + \frac{\lambda}{2m} \sum\limits_{l=1}^{L-1} \sum\limits_{i=1}^{s_l} \sum\limits_{j=1}^{s_{l+1} } \left( \Theta_{ji}^{(l)} \right)^2$<p>这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出$K$个预测，基本上我们可以利用循环，对每一行特征都预测$K$个不同结果，然后在利用循环在$K$个预测中选择可能性最高的一个，将其与$y$中的实际数据进行比较。</p><p>正则化的那一项只是排除了每一层$\theta_0$后，每一层的$\theta$ 矩阵的和。最里层的循环$j$循环所有的行（由$s_{l+1}$ 层的激活单元数决定），循环$i$则循环所有的列，由该层（$s_l$层）的激活单元数所决定。即：$h_\theta(x)$与真实值之间的距离为每个样本-每个类输出的加和，对参数进行<strong>regularization</strong>的<strong>bias</strong>项处理所有参数的平方和。</p><h3 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h3><p>参考视频: 9 - 2 - Backpropagation Algorithm (12 min).mkv</p><p>之前我们在计算神经网络预测结果的时候我们采用了一种正向传播方法，我们从第一层开始正向一层一层进行计算，直到最后一层的$h_{\theta}\left(x\right)$。</p><p>现在，为了计算代价函数的偏导数$\frac{\partial}{\partial\Theta^{(l)}_{ij} }J\left(\Theta\right)$，我们需要采用一种反向传播算法，也就是首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。<br>以一个例子来说明反向传播算法。</p><p>假设我们的训练集只有一个样本$\left({x}^{(1)},{y}^{(1)}\right)$，我们的神经网络是一个四层的神经网络，其中$K=4，S_{L}=4，L=4$：</p><p>前向传播算法：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2ea8f5ce4c3df931ee49cf8d987ef25d.png" alt="2ea8f5ce4c3df931ee49cf8d987ef25d"><br>下面的公式推导过程见：&lt;<a href="https://blog.csdn.net/qq_29762941/article/details/80343185&gt;" target="_blank" rel="noopener">https://blog.csdn.net/qq_29762941/article/details/80343185&gt;</a></p><p>我们从最后一层的误差开始计算，误差是激活单元的预测（${a^{(4)} }$）与实际值（$y^k$）之间的误差，（$k=1:k$）。<br>我们用$\delta$来表示误差，则：$\delta^{(4)}=a^{(4)}-y$<br>我们利用这个误差值来计算前一层的误差：$\delta^{(3)}=\left({\Theta^{(3)} }\right)^{T}\delta^{(4)}\ast g'\left(z^{(3)}\right)$<br>其中 $g'(z^{(3)})$是 $S$ 形函数的导数，$g'(z^{(3)})=a^{(3)}\ast(1-a^{(3)})$。而$(θ^{(3)})^{T}\delta^{(4)}$则是权重导致的误差的和。下一步是继续计算第二层的误差：</p> $ \delta^{(2)}=(\Theta^{(2)})^{T}\delta^{(3)}\ast g'(z^{(2)})$<p>因为第一层是输入变量，不存在误差。我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设$λ=0$，即我们不做任何正则化处理时有：</p> $\frac{\partial}{\partial\Theta_{ij}^{(l)} }J(\Theta)=a_{j}^{(l)} \delta_{i}^{l+1}$<p>重要的是清楚地知道上面式子中上下标的含义：</p> $l$ 代表目前所计算的是第几层。 $j$ 代表目前计算层中的激活单元的下标，也将是下一层的第$j$个输入变量的下标。 $i$ 代表下一层中误差单元的下标，是受到权重矩阵中第$i$行影响的下一层中的误差单元的下标。<p>如果我们考虑正则化处理，并且我们的训练集是一个特征矩阵而非向量。在上面的特殊情况中，我们需要计算每一层的误差单元来计算代价函数的偏导数。在更为一般的情况中，我们同样需要计算每一层的误差单元，但是我们需要为整个训练集计算误差单元，此时的误差单元也是一个矩阵，我们用$\Delta^{(l)}_{ij}$来表示这个误差矩阵。第 $l$ 层的第 $i$ 个激活单元受到第 $j$ 个参数影响而导致的误差。</p><p>我们的算法表示为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5514df14ebd508fd597e552fbadcf053.jpg" alt="5514df14ebd508fd597e552fbadcf053"><br>即首先用正向传播方法计算出每一层的激活单元，利用训练集的结果与神经网络预测的结果求出最后一层的误差，然后利用该误差运用反向传播法计算出直至第二层的所有误差。</p><p>在求出了$\Delta_{ij}^{(l)}$之后，我们便可以计算代价函数的偏导数了，计算方法如下：</p> $ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)}$ ${if}\; j \neq 0$ $ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}$ ${if}\; j = 0$<p>在<strong>Octave</strong> 中，如果我们要使用 <code>fminuc</code>这样的优化算法来求解求出权重矩阵，我们需要将矩阵首先展开成为向量，在利用算法求出最优解后再重新转换回矩阵。</p><p>假设我们有三个权重矩阵，Theta1，Theta2 和 Theta3，尺寸分别为 10*11，10*11 和1*11，<br>下面的代码可以实现这样的转换：</p><pre><code>thetaVec = [Theta1(:) ; Theta2(:) ; Theta3(:)]

...optimization using functions like fminuc...

Theta1 = reshape(thetaVec(1:110, 10, 11);

Theta2 = reshape(thetaVec(111:220, 10, 11);

Theta1 = reshape(thetaVec(221:231, 1, 11);</code></pre><h3 id="反向传播算法的直观理解"><a href="#反向传播算法的直观理解" class="headerlink" title="反向传播算法的直观理解"></a>反向传播算法的直观理解</h3><p>参考视频: 9 - 3 - Backpropagation Intuition (13 min).mkv</p><p>在上一段视频中，我们介绍了反向传播算法，对很多人来说，当第一次看到这种算法时，第一印象通常是，这个算法需要那么多繁杂的步骤，简直是太复杂了，实在不知道这些步骤，到底应该如何合在一起使用。就好像一个黑箱，里面充满了复杂的步骤。如果你对反向传播算法也有这种感受的话，这其实是正常的，相比于线性回归算法和逻辑回归算法而言，从数学的角度上讲，反向传播算法似乎并不简洁，对于反向传播这种算法，其实我已经使用了很多年了，但即便如此，即使是现在，我也经常感觉自己对反向传播算法的理解并不是十分深入，对于反向传播算法究竟是如何执行的，并没有一个很直观的理解。做过编程练习的同学应该可以感受到这些练习或多或少能帮助你，将这些复杂的步骤梳理了一遍，巩固了反向传播算法具体是如何实现的，这样你才能自己掌握这种算法。</p><p>在这段视频中，我想更加深入地讨论一下反向传播算法的这些复杂的步骤，并且希望给你一个更加全面直观的感受，理解这些步骤究竟是在做什么，也希望通过这段视频，你能理解，它至少还是一个合理的算法。但可能你即使看了这段视频，你还是觉得反向传播依然很复杂，依然像一个黑箱，太多复杂的步骤，依然感到有点神奇，这也是没关系的。即使是我接触反向传播这么多年了，有时候仍然觉得这是一个难以理解的算法，但还是希望这段视频能有些许帮助，为了更好地理解反向传播算法，我们再来仔细研究一下前向传播的原理：</p><p>前向传播算法：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5778e97c411b23487881a87cfca781bb.png" alt="5778e97c411b23487881a87cfca781bb"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/63a0e4aef6d47ba7fa6e07088b61ae68.png" alt="63a0e4aef6d47ba7fa6e07088b61ae68"><br>反向传播算法做的是：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/57aabbf26290e2082a00c5114ae1c5dc.png" alt="57aabbf26290e2082a00c5114ae1c5dc"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1542307ad9033e39093e7f28d0c7146c.png" alt="1542307ad9033e39093e7f28d0c7146c"><br><strong>感悟</strong>：上图中的 $\delta^{(l)}_{j}="error" \ of cost \ for \ a^{(l)}_{j} \ (unit \ j \ in \ layer \ l)$ 理解如下：</p> $\delta^{(l)}_{j}$ 相当于是第 $l$ 层的第 $j$ 单元中得到的激活项的“误差”，即”正确“的 $a^{(l)}_{j}$ 与计算得到的 $a^{(l)}_{j}$ 的差。<p>而 $a^{(l)}_{j}=g(z^{(l)})$ ，（g为sigmoid函数）。我们可以想象 $\delta^{(l)}_{j}$ 为函数求导时迈出的那一丁点微分，所以更准确的说 $\delta^{(l)}_{j}=\frac{\partial}{\partial z^{(l)}_{j} }cost(i)$</p><h3 id="实现注意：展开参数"><a href="#实现注意：展开参数" class="headerlink" title="实现注意：展开参数"></a>实现注意：展开参数</h3><p>参考视频: 9 - 4 - Implementation Note_ Unrolling Parameters (8 min).mkv</p><p>在上一段视频中，我们谈到了怎样使用反向传播算法计算代价函数的导数。在这段视频中，我想快速地向你介绍一个细节的实现过程，怎样把你的参数从矩阵展开成向量，以便我们在高级最优化步骤中的使用需要。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0ad78547859e6f794a7f18389d3d6128.png" alt="0ad78547859e6f794a7f18389d3d6128"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f9284204de41bffa4f7bc1dea567044e.png" alt="f9284204de41bffa4f7bc1dea567044e"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ebd7e196e272737f497853ba60743c44.png" alt="ebd7e196e272737f497853ba60743c44"></p><h3 id="梯度检验"><a href="#梯度检验" class="headerlink" title="梯度检验"></a>梯度检验</h3><p>参考视频: 9 - 5 - Gradient Checking (12 min).mkv</p><p>当我们对一个较为复杂的模型（例如神经网络）使用梯度下降算法时，可能会存在一些不容易察觉的错误，意味着，虽然代价看上去在不断减小，但最终的结果可能并不是最优解。</p><p>为了避免这样的问题，我们采取一种叫做梯度的数值检验（<strong>Numerical Gradient Checking</strong>）方法。这种方法的思想是通过估计梯度值来检验我们计算的导数值是否真的是我们要求的。</p><p>对梯度的估计采用的方法是在代价函数上沿着切线的方向选择离两个非常近的点然后计算两个点的平均值用以估计梯度。即对于某个特定的 $\theta$，我们计算出在 $\theta$-$\varepsilon $ 处和 $\theta$+$\varepsilon $ 的代价值（$\varepsilon $是一个非常小的值，通常选取 0.001），然后求两个代价的平均，用以估计在 $\theta$ 处的代价值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5d04c4791eb12a74c843eb5acf601400.png" alt="5d04c4791eb12a74c843eb5acf601400"><br><strong>Octave</strong> 中代码如下：</p><p><code>gradApprox = (J(theta + eps) – J(theta - eps)) / (2*eps)</code></p><p>当$\theta$是一个向量时，我们则需要对偏导数进行检验。因为代价函数的偏导数检验只针对一个参数的改变进行检验，下面是一个只针对$\theta_1$进行检验的示例：</p> $$ \frac{\partial}{\partial\theta_1}=\frac{J\left(\theta_1+\varepsilon_1,\theta_2,\theta_3...\theta_n \right)-J \left( \theta_1-\varepsilon_1,\theta_2,\theta_3...\theta_n \right)}{2\varepsilon} $$<p>最后我们还需要对通过反向传播方法计算出的偏导数进行检验。</p><p>根据上面的算法，计算出的偏导数存储在矩阵 $D_{ij}^{(l)}$ 中。检验时，我们要将该矩阵展开成为向量，同时我们也将 $\theta$ 矩阵展开为向量，我们针对每一个 $\theta$ 都计算一个近似的梯度值，将这些值存储于一个近似梯度矩阵中，最终将得出的这个矩阵同 $D_{ij}^{(l)}$ 进行比较。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bf65f3f3098025530a3c442eea562f8c.jpg" alt="bf65f3f3098025530a3c442eea562f8c"></p><h3 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h3><p>参考视频: 9 - 6 - Random Initialization (7 min).mkv</p><p>任何优化算法都需要一些初始的参数。到目前为止我们都是初始所有参数为0，这样的初始方法对于逻辑回归来说是可行的，但是对于神经网络来说是不可行的。如果我们令所有的初始参数都为0，这将意味着我们第二层的所有激活单元都会有相同的值。同理，如果我们初始所有的参数都为一个非0的数，结果也是一样的。</p><p>我们通常初始参数为正负ε之间的随机值，假设我们要随机初始一个尺寸为10×11的参数矩阵，代码如下：</p><p><code>Theta1 = rand(10, 11) * (2*eps) – eps</code></p><h3 id="综合起来"><a href="#综合起来" class="headerlink" title="综合起来"></a>综合起来</h3><p>参考视频: 9 - 7 - Putting It Together (14 min).mkv</p><p>小结一下使用神经网络时的步骤：</p><p>网络结构：第一件要做的事是选择网络结构，即决定选择多少层以及决定每层分别有多少个单元。</p><p>第一层的单元数即我们训练集的特征数量。</p><p>最后一层的单元数是我们训练集的结果的类的数量。</p><p>如果隐藏层数大于1，确保每个隐藏层的单元个数相同，通常情况下隐藏层单元的个数越多越好。</p><p>我们真正要决定的是隐藏层的层数和每个中间层的单元数。</p><p>训练神经网络：</p><ol><li><p>参数的随机初始化</p></li><li><p>利用正向传播方法计算所有的$h_{\theta}(x)$</p></li><li><p>编写计算代价函数 $J$ 的代码</p></li><li><p>利用反向传播方法计算所有偏导数</p></li><li><p>利用数值检验方法检验这些偏导数</p></li><li><p>使用优化算法来最小化代价函数</p></li></ol><h3 id="自主驾驶"><a href="#自主驾驶" class="headerlink" title="自主驾驶"></a>自主驾驶</h3><p>参考视频: 9 - 8 - Autonomous Driving (7 min).mkv</p><p>在这段视频中，我想向你介绍一个具有历史意义的神经网络学习的重要例子。那就是使用神经网络来实现自动驾驶，也就是说使汽车通过学习来自己驾驶。接下来我将演示的这段视频是我从 Dean Pomerleau那里拿到的，他是我的同事，任职于美国东海岸的卡耐基梅隆大学。在这部分视频中，你就会明白可视化技术到底是什么？在看这段视频之前，我会告诉你可视化技术是什么。</p><p>在下面也就是左下方，就是汽车所看到的前方的路况图像。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/cea3f9a181d326681cd7d6ceaf4f2e46.png" alt="cea3f9a181d326681cd7d6ceaf4f2e46"><br>在图中你依稀能看出一条道路，朝左延伸了一点，又向右了一点，然后上面的这幅图，你可以看到一条水平的菜单栏显示的是驾驶操作人选择的方向。就是这里的这条白亮的区段显示的就是人类驾驶者选择的方向。比如：最左边的区段，对应的操作就是向左急转，而最右端则对应向右急转的操作。因此，稍微靠左的区段，也就是中心稍微向左一点的位置，则表示在这一点上人类驾驶者的操作是慢慢的向左拐。</p><p>这幅图的第二部分对应的就是学习算法选出的行驶方向。并且，类似的，这一条白亮的区段显示的就是神经网络在这里选择的行驶方向，是稍微的左转，并且实际上在神经网络开始学习之前，你会看到网络的输出是一条灰色的区段，就像这样的一条灰色区段覆盖着整个区域这些均称的灰色区域，显示出神经网络已经随机初始化了，并且初始化时，我们并不知道汽车如何行驶，或者说我们并不知道所选行驶方向。只有在学习算法运行了足够长的时间之后，才会有这条白色的区段出现在整条灰色区域之中。显示出一个具体的行驶方向这就表示神经网络算法，在这时候已经选出了一个明确的行驶方向，不像刚开始的时候，输出一段模糊的浅灰色区域，而是输出一条白亮的区段，表示已经选出了明确的行驶方向。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/56441d35d8bd4ecfd6d6f32b651c54a6.png" alt="56441d35d8bd4ecfd6d6f32b651c54a6"><br><strong>ALVINN</strong> (<strong>Autonomous Land Vehicle In a Neural Network</strong>)是一个基于神经网络的智能系统，通过观察人类的驾驶来学习驾驶，<strong>ALVINN</strong>能够控制<strong>NavLab</strong>，装在一辆改装版军用悍马，这辆悍马装载了传感器、计算机和驱动器用来进行自动驾驶的导航试验。实现<strong>ALVINN</strong>功能的第一步，是对它进行训练，也就是训练一个人驾驶汽车。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/41cdc4cd2bc49a1b75d57aaf748e0798.png" alt="41cdc4cd2bc49a1b75d57aaf748e0798"><br>然后让<strong>ALVINN</strong>观看，<strong>ALVINN</strong>每两秒将前方的路况图生成一张数字化图片，并且记录驾驶者的驾驶方向，得到的训练集图片被压缩为30x32像素，并且作为输入提供给<strong>ALVINN</strong>的三层神经网络，通过使用反向传播学习算法，<strong>ALVINN</strong>会训练得到一个与人类驾驶员操纵方向基本相近的结果。一开始，我们的网络选择出的方向是随机的，大约经过两分钟的训练后，我们的神经网络便能够准确地模拟人类驾驶者的驾驶方向，对其他道路类型，也重复进行这个训练过程，当网络被训练完成后，操作者就可按下运行按钮，车辆便开始行驶了。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dd4a022b5544d50f503c077b3a5a5251.png" alt="dd4a022b5544d50f503c077b3a5a5251"><br>每秒钟<strong>ALVINN</strong>生成12次数字化图片，并且将图像传送给神经网络进行训练，多个神经网络同时工作，每一个网络都生成一个行驶方向，以及一个预测自信度的参数，预测自信度最高的那个神经网络得到的行驶方向。比如这里，在这条单行道上训练出的网络将被最终用于控制车辆方向，车辆前方突然出现了一个交叉十字路口，当车辆到达这个十字路口时，我们单行道网络对应的自信度骤减，当它穿过这个十字路口时，前方的双车道将进入其视线，双车道网络的自信度便开始上升，当它的自信度上升时，双车道的网络，将被选择来控制行驶方向，车辆将被安全地引导进入双车道路。</p><h2 id="这就是基于神经网络的自动驾驶技术。当然，我们还有很多更加先进的试验来实现自动驾驶技术。在美国，欧洲等一些国家和地区，他们提供了一些比这个方法更加稳定的驾驶控制技术。但我认为，使用这样一个简单的基于反向传播的神经网络，训练出如此强大的自动驾驶汽车，的确是一次令人惊讶的成就。"><a href="#这就是基于神经网络的自动驾驶技术。当然，我们还有很多更加先进的试验来实现自动驾驶技术。在美国，欧洲等一些国家和地区，他们提供了一些比这个方法更加稳定的驾驶控制技术。但我认为，使用这样一个简单的基于反向传播的神经网络，训练出如此强大的自动驾驶汽车，的确是一次令人惊讶的成就。" class="headerlink" title="这就是基于神经网络的自动驾驶技术。当然，我们还有很多更加先进的试验来实现自动驾驶技术。在美国，欧洲等一些国家和地区，他们提供了一些比这个方法更加稳定的驾驶控制技术。但我认为，使用这样一个简单的基于反向传播的神经网络，训练出如此强大的自动驾驶汽车，的确是一次令人惊讶的成就。"></a>这就是基于神经网络的自动驾驶技术。当然，我们还有很多更加先进的试验来实现自动驾驶技术。在美国，欧洲等一些国家和地区，他们提供了一些比这个方法更加稳定的驾驶控制技术。但我认为，使用这样一个简单的基于反向传播的神经网络，训练出如此强大的自动驾驶汽车，的确是一次令人惊讶的成就。</h2><p>title: 吴恩达机器学习笔记(1-5周)<br>date: 2019-12-04 09:28:03<br>categories: 人工智能<br>tags:</p><ul><li>nlp<br>cover: <a href="https://www.github.com/OneJane/blog/raw/master/小书匠/82a490a419fe375d72125e422ed31adb_hd.jpg" target="_blank" rel="noopener">https://www.github.com/OneJane/blog/raw/master/小书匠/82a490a419fe375d72125e422ed31adb_hd.jpg</a></li></ul><hr><p><a href="https://onejane.github.io/">吴恩达机器学习笔记</a><br>&lt;!–more–&gt;</p><h2 id="引言-1"><a href="#引言-1" class="headerlink" title="引言"></a>引言</h2><h3 id="监督学习-1"><a href="#监督学习-1" class="headerlink" title="监督学习"></a>监督学习</h3><p>参考视频: 1 - 3 - Supervised Learning (12 min).mkv<br>我们用一个例子介绍什么是监督学习把正式的定义放在后面介绍。假如说你想预测房价。</p><p>前阵子，一个学生从波特兰俄勒冈州的研究所收集了一些房价的数据。你把这些数据画出来，看起来是这个样子：横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。那基于这组数据，假如你有一个朋友，他有一套750平方英尺房子，现在他希望把房子卖掉，他想知道这房子能卖多少钱。</p><p>那么关于这个问题，机器学习算法将会怎么帮助你呢？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423614245.png" alt="enter description here"></p><p>我们应用学习算法，可以在这组数据中画一条直线，或者换句话说，拟合一条直线，根据这条线我们可以推测出，这套房子可能卖$150,000，当然这不是唯一的算法。可能还有更好的，比如我们不用直线拟合这些数据，用二次方程去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近$200,000。稍后我们将讨论如何选择学习算法，如何决定用直线还是二次方程来拟合。两个方案中有一个能让你朋友的房子出售得更合理。这些都是学习算法里面很好的例子。以上就是<strong>监督学习</strong>的例子。</p><p>可以看出，监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成。在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。用术语来讲，这叫做<strong>回归问题</strong>。我们试着推测出一个连续值的结果，即房子的价格。</p><p>一般房子的价格会记到美分，所以房价实际上是一系列离散的值，但是我们通常又把房价看成实数，看成是标量，所以又把它看成一个连续的数值。</p><p><strong>回归这个词的意思是，我们在试着推测出这一系列连续值属性。</strong></p><p>我再举另外一个监督学习的例子。我和一些朋友之前研究过这个。假设说你想通过查看病历来推测乳腺癌良性与否，假如有人检测出乳腺肿瘤，恶性肿瘤有害并且十分危险，而良性的肿瘤危害就没那么大，所以人们显然会很在意这个问题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423705880.png" alt="enter description here"></p><p>让我们来看一组数据：这个数据集中，横轴表示肿瘤的大小，纵轴上，我标出1和0表示是或者不是恶性肿瘤。我们之前见过的肿瘤，如果是恶性则记为1，不是恶性，或者说良性记为0。</p><p>我有5个良性肿瘤样本，在1的位置有5个恶性肿瘤样本。现在我们有一个朋友很不幸检查出乳腺肿瘤。假设说她的肿瘤大概这么大，那么机器学习的问题就在于，你能否估算出肿瘤是恶性的或是良性的概率。用术语来讲，这是一个<strong>分类问题</strong>。</p><p><strong>分类指的是，我们试着推测出离散的输出值</strong>：0或1良性或恶性，而事实上在分类问题中，输出可能不止两个值。比如说可能有三种乳腺癌，所以你希望预测离散输出0、1、2、3。0 代表良性，1 表示第1类乳腺癌，2表示第2类癌症，3表示第3类，但这也是分类问题。</p><p>因为这几个离散的输出分别对应良性，第一类第二类或者第三类癌症，在分类问题中我们可以用另一种方式绘制这些数据点。</p><p>现在我用不同的符号来表示这些数据。既然我们把肿瘤的尺寸看做区分恶性或良性的特征，那么我可以这么画，我用不同的符号来表示良性和恶性肿瘤。或者说是负样本和正样本现在我们不全部画<strong>X</strong>，良性的肿瘤改成用 <strong>O</strong> 表示，恶性的继续用 <strong>X</strong> 表示。来预测肿瘤的恶性与否。</p><p>在其它一些机器学习问题中，可能会遇到不止一种特征。举个例子，我们不仅知道肿瘤的尺寸，还知道对应患者的年龄。在其他机器学习问题中，我们通常有更多的特征，我朋友研究这个问题时，通常采用这些特征，比如肿块密度，肿瘤细胞尺寸的一致性和形状的一致性等等，还有一些其他的特征。这就是我们即将学到最有趣的学习算法之一。</p><p>那种算法不仅能处理2种3种或5种特征，即使有无限多种特征都可以处理。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423772270.png" alt="enter description here"></p><p>上图中，我列举了总共5种不同的特征，坐标轴上的两种和右边的3种，但是在一些学习问题中，你希望不只用3种或5种特征。相反，你想用无限多种特征，好让你的算法可以利用大量的特征，或者说线索来做推测。那你怎么处理无限多个特征，甚至怎么存储这些特征都存在问题，你电脑的内存肯定不够用。<strong>我们以后会讲一个算法，叫支持向量机，里面有一个巧妙的数学技巧，能让计算机处理无限多个特征。</strong> 想象一下，我没有写下这两种和右边的三种特征，而是在一个无限长的列表里面，一直写一直写不停的写，写下无限多个特征，事实上，我们能用算法来处理它们。</p><p>现在来回顾一下，这节课我们介绍了<strong>监督学习。其基本思想是，我们数据集中的每个样本都有相应的“正确答案”。再根据这些样本作出预测，就像房子和肿瘤的例子中做的那样。我们还介绍了回归问题，即通过回归来推出一个连续的输出，之后我们介绍了分类问题，其目标是推出一组离散的结果。</strong></p><p>现在来个小测验：假设你经营着一家公司，你想开发学习算法来处理这两个问题：</p><ol><li><p>你有一大批同样的货物，想象一下，你有上千件一模一样的货物等待出售，这时你想预测接下来的三个月能卖多少件？</p></li><li><p>你有许多客户，这时你想写一个软件来检验每一个用户的账户。对于每一个账户，你要判断它们是否曾经被盗过？</p></li></ol><p>那这两个问题，它们属于分类问题、还是回归问题?</p><p>问题一是一个回归问题，因为你知道，如果我有数千件货物，我会把它看成一个实数，一个连续的值。因此卖出的物品数，也是一个连续的值。</p><p>问题二是一个分类问题，因为我会把预测的值，用 0 来表示账户未被盗，用 1 表示账户曾经被盗过。所以我们根据账号是否被盗过，把它们定为0 或 1，然后用算法推测一个账号是 0 还是 1，因为只有少数的离散值，所以我把它归为分类问题。</p><p>以上就是监督学习的内容。</p><h3 id="无监督学习-1"><a href="#无监督学习-1" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>参考视频: 1 - 4 - Unsupervised Learning (14 min).mkv<br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423900529.png" alt="enter description here"></p><p>上个视频中，已经介绍了监督学习。回想当时的数据集，如图表所示，这个数据集中每条数据都已经标明是阴性或阳性，即是良性或恶性肿瘤。所以，对于监督学习里的每条数据，我们已经清楚地知道，训练集对应的正确答案，是良性或恶性了。</p><p>在无监督学习中，我们已知的数据。看上去有点不一样，不同于监督学习的数据的样子，即<strong>无监督学习中没有任何的标签或者是有相同的标签或者就是没标签</strong>。所以我们已知数据集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集。你能从数据中找到某种结构吗？针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做聚类算法。事实证明，它能被用在很多地方。</p><p>聚类应用的一个例子就是在谷歌新闻中。如果你以前从来没见过它，你可以到这个URL网址news.google.com去看看。谷歌新闻每天都在，收集非常多，非常多的网络的新闻内容。它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件，自动地把它们聚类到一起。所以，这些新闻事件全是同一主题的，所以显示到一起。</p><p>事实证明，聚类算法和无监督学习算法同样还用在很多其它的问题上。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575423980984.png" alt="enter description here"></p><p>其中就有基因学的理解应用。一个<strong>DNA</strong>微观数据的例子。基本思想是输入一组不同个体，对其中的每个个体，你要分析出它们是否有一个特定的基因。技术上，你要分析多少特定基因已经表达。所以这些颜色，红，绿，灰等等颜色，这些颜色展示了相应的程度，即不同的个体是否有着一个特定的基因。你能做的就是运行一个聚类算法，把个体聚类到不同的类或不同类型的组（人）……</p><p>所以这个就是无监督学习，因为我们没有提前告知算法一些信息，比如，这是第一类的人，那些是第二类的人，还有第三类，等等。我们只是说，是的，这是有一堆数据。我不知道数据里面有什么。我不知道谁是什么类型。我甚至不知道人们有哪些不同的类型，这些类型又是什么。但你能自动地找到数据中的结构吗？就是说你要自动地聚类那些个体到各个类，我没法提前知道哪些是哪些。因为我们没有给算法正确答案来回应数据集中的数据，所以这就是无监督学习。</p><p>无监督学习或聚集有着大量的应用。它用于组织大型计算机集群。我有些朋友在大数据中心工作，那里有大型的计算机集群，他们想解决什么样的机器易于协同地工作，如果你能够让那些机器协同工作，你就能让你的数据中心工作得更高效。第二种应用就是社交网络的分析。所以已知你朋友的信息，比如你经常发<strong>email</strong>的，或是你<strong>Facebook</strong>的朋友、<strong>谷歌+</strong> 圈子的朋友，我们能否自动地给出朋友的分组呢？即每组里的人们彼此都熟识，认识组里的所有人？还有市场分割。许多公司有大型的数据库，存储消费者信息。所以，你能检索这些顾客数据集，自动地发现市场分类，并自动地把顾客划分到不同的细分市场中，你才能自动并更有效地销售或不同的细分市场一起进行销售。这也是无监督学习，因为我们拥有所有的顾客数据，但我们没有提前知道是什么的细分市场，以及分别有哪些我们数据集中的顾客。我们不知道谁是在一号细分市场，谁在二号市场，等等。那我们就必须让算法从数据中发现这一切。最后，无监督学习也可用于天文数据分析，这些聚类算法给出了令人惊讶、有趣、有用的理论，解释了星系是如何诞生的。这些都是聚类的例子，聚类只是无监督学习中的一种。</p><p>我现在告诉你们另一种。我先来介绍鸡尾酒宴问题。嗯，你参加过鸡尾酒宴吧？你可以想像下，有个宴会房间里满是人，全部坐着，都在聊天，这么多人同时在聊天，声音彼此重叠，因为每个人都在说话，同一时间都在说话，你几乎听不到你面前那人的声音。所以，可能在一个这样的鸡尾酒宴中的两个人，他俩同时都在说话，假设现在是在个有些小的鸡尾酒宴中。我们放两个麦克风在房间中，因为这些麦克风在两个地方，离说话人的距离不同每个麦克风记录下不同的声音，虽然是同样的两个说话人。听起来像是两份录音被叠加到一起，或是被归结到一起，产生了我们现在的这些录音。另外，这个算法还会区分出两个音频资源，这两个可以合成或合并成之前的录音，实际上，鸡尾酒算法的第一个输出结果是：</p><p>1，2，3，4，5，6，7，8，9，10,</p><p>所以，已经把英语的声音从录音中分离出来了。</p><p>第二个输出是这样：</p><p>1，2，3，4，5，6，7，8，9，10。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424111930.png" alt="enter description here"></p><p>看看这个无监督学习算法，实现这个得要多么的复杂，是吧？它似乎是这样，为了构建这个应用，完成这个音频处理似乎需要你去写大量的代码或链接到一堆的合成器<strong>JAVA</strong>库，处理音频的库，看上去绝对是个复杂的程序，去完成这个从音频中分离出音频。事实上，这个算法对应你刚才知道的那个问题的算法可以就用一行代码来完成。</p><p>就是这里展示的代码：<code>[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x&#39;);</code></p><p>研究人员花费了大量时间才最终实现这行代码。我不是说这个是简单的问题，但它证明了，当你使用正确的编程环境，许多学习算法是相当短的程序。所以，这也是为什么在本课中，我们打算使用<strong>Octave</strong>编程环境。<strong>Octave</strong>,是免费的开源软件，使用一个像<strong>Octave</strong>或<strong>Matlab</strong>的工具，许多学习算法变得只有几行代码就可实现。</p><p>后面，我会教你们一点关于如何使用<strong>Octave</strong>的知识，你就可以用<strong>Octave</strong>来实现一些算法了。或者，如果你有<strong>Matlab</strong>（盗版？），你也可以用<strong>Matlab</strong>。事实上，在硅谷里，对大量机器学习算法，我们第一步就是建原型，在<strong>Octave</strong>建软件原型，因为软件在<strong>Octave</strong>中可以令人难以置信地、快速地实现这些学习算法。这里的这些函数比如<strong>SVM</strong>（<strong>支持向量机</strong>）函数，<strong>奇异值分解</strong>，<strong>Octave</strong>里已经建好了。如果你试图完成这个工作，但借助<strong>C++</strong>或<strong>JAVA</strong>的话，你会需要很多很多行的代码，并链接复杂的<strong>C++</strong>或<strong>Java</strong>库。所以，你可以实现这些算法，借助<strong>C++</strong>或<strong>Java</strong>或<strong>Python</strong>，它只是用这些语言来实现会更加复杂。(编者注：这个是当时的情况，现在<strong>Python</strong>变主流了)</p><p>我已经见到，在我教机器学习将近十年后的现在，发现，学习可以更加高速，如果使用<strong>Octave</strong>作为编程环境，如果使用<strong>Octave</strong>作为学习工具，以及作为原型工具，它会让你对学习算法的学习和建原型快上许多。</p><p>事实上，许多人在大硅谷的公司里做的其实就是，使用一种工具像<strong>Octave</strong>来做第一步的学习算法的原型搭建，只有在你已经让它工作后，你才移植它到<strong>C++</strong> 或<strong>Java</strong>或别的语言。事实证明，这样做通常可以让你的算法运行得比直接用<strong>C++</strong> 实现更快，所以，我知道，作为一名指导者，我必须说“相信我”，但对你们中从未使用过<strong>Octave</strong>这种编程环境的人，我还是要告诉你们这一点一定要相信我，我想，对你们而言，我认为你们的时间，你们的开发时间是最有价值的资源。我已经见过很多人这样做了，我把你看作是机器学习研究员，或机器学习开发人员，想更加高产的话，你要学会使用这个原型工具，开始使用<strong>Octave</strong>。</p><p>我们介绍了<strong>无监督学习，它是学习策略，交给算法大量的数据，并让算法为我们从数据中找出某种结构。</strong></p><p>好的，希望你们还记得<strong>垃圾邮件问题</strong>。如果你有标记好的数据，区别好是垃圾还是非垃圾邮件，我们把这个当作<strong>监督学习问题</strong>。</p><p><strong>新闻事件分类</strong>的例子，就是那个谷歌新闻的例子，我们在本视频中有见到了，我们看到，可以用一个聚类算法来聚类这些文章到一起，所以是<strong>无监督学习</strong>。</p><p><strong>细分市场</strong>的例子，我在更早一点的时间讲过，你可以当作<strong>无监督学习</strong>问题，因为我只是拿到算法数据，再让算法去自动地发现细分市场。</p><p>最后一个例子，<strong>糖尿病</strong>，这个其实就像是我们的乳腺癌，上个视频里的。只是替换了好、坏肿瘤，良性、恶性肿瘤，我们改用糖尿病或没病。所以我们把这个当作<strong>监督学习</strong>，我们能够解决它，作为一个监督学习问题，就像我们在乳腺癌数据中做的一样。</p><h2 id="单变量线性回归-Linear-Regression-with-One-Variable-1"><a href="#单变量线性回归-Linear-Regression-with-One-Variable-1" class="headerlink" title="单变量线性回归(Linear Regression with One Variable)"></a>单变量线性回归(Linear Regression with One Variable)</h2><h3 id="模型表示-1"><a href="#模型表示-1" class="headerlink" title="模型表示"></a>模型表示</h3><p>参考视频: 2 - 1 - Model Representation (8 min).mkv</p><p>让我们通过一个例子来开始：这个例子是预测住房价格的，我们要使用一个数据集，数据集包含俄勒冈州波特兰市的住房价格。在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424452903.png" alt="enter description here"></p><p>它被称作监督学习是因为对于每个数据来说，我们给出了“正确的答案”，即告诉我们：根据我们的数据来说，房子实际的价格是多少，而且，更具体来说，这是一个回归问题。回归一词指的是，我们根据之前的数据预测出一个准确的输出值，对于这个例子就是价格，同时，还有另一种最常见的监督学习方式，叫做分类问题，当我们想要预测离散的输出值，例如，我们正在寻找癌症肿瘤，并想要确定肿瘤是良性的还是恶性的，这就是0/1离散输出的问题。更进一步来说，在监督学习中我们有一个数据集，这个数据集被称训练集。</p><p><strong>我将在整个课程中用小写的m来表示训练样本的数目。</strong></p><p>以之前的房屋交易问题为例，假使我们回归问题的训练集（<strong>Training Set</strong>）如下表所示：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424505376.png" alt="enter description here"></p><p>我们将要用来描述这个回归问题的标记如下:</p> $m$ 代表训练集中实例的数量 $x$ 代表特征/输入变量 $y$ 代表目标变量/输出变量 $\left( x,y \right)$ 代表训练集中的实例 $({ {x}^{(i)} },{ {y}^{(i)} })$ 代表第$i$ 个观察实例 $h$ 代表学习算法的解决方案或函数也称为假设（**hypothesis**）<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424585514.png" alt="enter description here"></p><p>这就是一个监督学习算法的工作方式，我们可以看到这里有我们的训练集里房屋价格<br>我们把它喂给我们的学习算法，学习算法的工作了，然后输出一个函数，通常表示为小写 $h$ 表示。$h$ 代表<strong>hypothesis</strong>(<strong>假设</strong>)，$h$表示一个函数，输入是房屋尺寸大小，就像你朋友想出售的房屋，因此 $h$ 根据输入的 $x$值来得出 $y$ 值，$y$ 值对应房子的价格 因此，$h$ 是一个从$x$ 到 $y$ 的函数映射。</p><p>我将选择最初的使用规则$h$代表<strong>hypothesis</strong>，因而，要解决房价预测问题，我们实际上是要将训练集“喂”给我们的学习算法，进而学习得到一个假设$h$，然后将我们要预测的房屋的尺寸作为输入变量输入给$h$，预测出该房屋的交易价格作为输出变量输出为结果。那么，对于我们的房价预测问题，我们该如何表达 $h$？</p><p>一种可能的表达方式为：$h_\theta \left( x \right)=\theta_{0} + \theta_{1}x$，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。</p><h3 id="代价函数-4"><a href="#代价函数-4" class="headerlink" title="代价函数"></a>代价函数</h3><p>参考视频: 2 - 2 - Cost Function (8 min).mkv<br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424646031.png" alt="enter description here"></p><p>在线性回归中我们有一个像这样的训练集，$m$代表了训练样本的数量，比如 $m = 47$。而我们的假设函数，也就是用来进行预测的函数，是这样的线性函数形式：$h_\theta \left( x \right)=\theta_{0}+\theta_{1}x$。</p><p>接下来我们会引入一些术语我们现在要做的便是为我们的模型选择合适的<strong>参数</strong>（<strong>parameters</strong>）$\theta_{0}$ 和 $\theta_{1}$，在房价问题这个例子中便是直线的斜率和在$y$ 轴上的截距。</p><p>我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是<strong>建模误差</strong>（<strong>modeling error</strong>）。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424692858.png" alt="enter description here"></p><p>我们的<strong>目标便是选择出可以使得建模误差的平方和能够最小的模型参数</strong>。 即使得代价函数 $J \left( \theta_0, \theta_1 \right) = \frac{1}{2m}\sum\limits_{i=1}^m \left( h_{\theta}(x^{(i)})-y^{(i)} \right)^{2}$最小。</p><p>我们绘制一个等高线图，三个坐标分别为$\theta_{0}$和$\theta_{1}$ 和$J(\theta_{0}, \theta_{1})$：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424716806.png" alt="enter description here"></p><p>则可以看出在三维空间中存在一个使得$J(\theta_{0}, \theta_{1})$最小的点。</p><p>代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。</p><p>在后续课程中，我们还会谈论其他的代价函数，但我们刚刚讲的选择是对于大多数线性回归问题非常合理的。</p><p>也许这个函数$J(\theta_{0}, \theta_{1})$有点抽象，可能你仍然不知道它的内涵，在接下来的几个视频里，我们要更进一步解释代价函数J的工作原理，并尝试更直观地解释它在计算什么，以及我们使用它的目的。</p><h3 id="代价函数的直观理解-1"><a href="#代价函数的直观理解-1" class="headerlink" title="代价函数的直观理解"></a>代价函数的直观理解</h3><p>参考视频: 2 - 3 - Cost Function - Intuition I (11 min).mkv<br>在上一个视频中，我们给了代价函数一个数学上的定义。在这个视频里，让我们通过一些例子来获取一些直观的感受，看看代价函数到底是在干什么。<br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424876911.png" alt="enter description here"></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424969202.png" alt="enter description here"></p><p>代价函数的样子，等高线图，则可以看出在三维空间中存在一个使得$J(\theta_{0}, \theta_{1})$最小的点。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575424993676.png" alt="enter description here"></p><p>通过这些图形，我希望你能更好地理解这些代价函数$ J$所表达的值是什么样的，它们对应的假设是什么样的，以及什么样的假设对应的点，更接近于代价函数$J$的最小值。</p><p>当然，我们真正需要的是一种有效的算法，能够自动地找出这些使代价函数$J$取最小值的参数$\theta_{0}$和$\theta_{1}$来。</p><p>我们也不希望编个程序把这些点画出来，然后人工的方法来读出这些点的数值，这很明显不是一个好办法。我们会遇到更复杂、更高维度、更多参数的情况，而这些情况是很难画出图的，因此更无法将其可视化，因此我们真正需要的是编写程序来找出这些最小化代价函数的$\theta_{0}$和$\theta_{1}$的值，在下一节视频中，我们将介绍一种算法，能够自动地找出能使代价函数$J$最小化的参数$\theta_{0}$和$\theta_{1}$的值。</p><h3 id="梯度下降-1"><a href="#梯度下降-1" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>参考视频: 2 - 5 - Gradient Descent (11 min).mkv<br>梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数$J(\theta_{0}, \theta_{1})$ 的最小值。</p><p>梯度下降背后的思想是：开始时我们随机选择一个参数的组合$\left( {\theta_{0} },{\theta_{1} },......,{\theta_{n} } \right)$，计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到找到一个局部最小值（<strong>local minimum</strong>），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（<strong>global minimum</strong>），选择不同的初始参数组合，可能会找到不同的局部最小值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429352272.png" alt="enter description here"></p><p>想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。</p><p>批量梯度下降（<strong>batch gradient descent</strong>）算法的公式为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429392028.png" alt="enter description here"></p><p>其中$a$是学习率（<strong>learning rate</strong>），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在<strong>批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数</strong>。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429400255.png" alt="enter description here"></p><p>在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新${\theta_{0} }$和${\theta_{1} }$ ，当 $j=0$ 和$j=1$时，会产生更新，所以你将更新$J\left( {\theta_{0} } \right)$和$J\left( {\theta_{1} } \right)$。实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新${\theta_{0} }$和${\theta_{1} }$，我的意思是在这个等式中，我们要这样更新：</p> ${\theta_{0} }$:= ${\theta_{0} }$ ，并更新${\theta_{1} }$:= ${\theta_{1} }$。<p>实现方法是：你应该计算公式右边的部分，通过那一部分计算出${\theta_{0} }$和${\theta_{1} }$的值，然后同时更新${\theta_{0} }$和${\theta_{1} }$。</p><p>让我进一步阐述这个过程：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429409440.png" alt="enter description here"></p><p>在梯度下降算法中，这是正确实现同时更新的方法。我不打算解释为什么你需要同时更新，同时更新是梯度下降中的一种常用方法。我们之后会讲到，同步更新是更自然的实现方法。当人们谈到梯度下降时，他们的意思就是同步更新。</p><p>在接下来的视频中，我们要进入这个微分项的细节之中。我已经写了出来但没有真正定义，如果你已经修过微积分课程，如果你熟悉偏导数和导数，这其实就是这个微分项：</p> $\alpha \frac{\partial }{\partial { {\theta }_{0} }}J({ {\theta }_{0} },{ {\theta }_{1} })$，$\alpha \frac{\partial }{\partial { {\theta }_{1} }}J({ {\theta }_{0} },{ {\theta }_{1} })$。<p>如果你不熟悉微积分，不用担心，即使你之前没有看过微积分，或者没有接触过偏导数，在接下来的视频中，你会得到一切你需要知道，如何计算这个微分项的知识。</p><h3 id="梯度下降的直观理解-1"><a href="#梯度下降的直观理解-1" class="headerlink" title="梯度下降的直观理解"></a>梯度下降的直观理解</h3><p>参考视频: 2 - 6 - Gradient Descent Intuition (12 min).mkv<br>在之前的视频中，我们给出了一个数学上关于梯度下降的定义，本次视频我们更深入研究一下，更直观地感受一下这个算法是做什么的，以及梯度下降算法的更新过程有什么意义。梯度下降算法如下：</p> ${\theta_{j} }:={\theta_{j} }-\alpha \frac{\partial }{\partial {\theta_{j} }}J\left(\theta \right)$<p>描述：对$\theta $赋值，使得$J\left( \theta \right)$按梯度下降最快方向进行，一直迭代下去，最终得到局部最小值。其中$a$是学习率（<strong>learning rate</strong>），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429686477.png" alt="enter description here"></p><p>对于这个问题，求导的目的，基本上可以说取这个红点的切线，就是这样一条红色的直线，刚好与函数相切于这一点，让我们看看这条红色直线的斜率，就是这条刚好与函数曲线相切的这条直线，这条直线的斜率正好是这个三角形的高度除以这个水平长度，现在，这条线有一个正斜率，也就是说它有正导数，因此，我得到的新的${\theta_{1} }$，${\theta_{1} }$更新后等于${\theta_{1} }$减去一个正数乘以$a$。</p><p>这就是我梯度下降法的更新规则：${\theta_{j} }:={\theta_{j} }-\alpha \frac{\partial }{\partial {\theta_{j} }}J\left( \theta \right)$</p><p>让我们来看看如果$a$太小或$a$太大会出现什么情况：</p><p>如果$a$太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果$a$太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。</p><p>如果$a$太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果$a$太大，它会导致无法收敛，甚至发散。</p><p>现在，我还有一个问题，当我第一次学习这个地方时，我花了很长一段时间才理解这个问题，如果我们预先把${\theta_{1} }$放在一个局部的最低点，你认为下一步梯度下降法会怎样工作？</p><p>假设你将${\theta_{1} }$初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得${\theta_{1} }$不再改变，也就是新的${\theta_{1} }$等于原来的${\theta_{1} }$，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率$a$保持不变时，梯度下降也可以收敛到局部最低点。</p><p>我们来看一个例子，这是代价函数$J\left( \theta \right)$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575429854299.png" alt="enter description here"></p><p>我想找到它的最小值，首先初始化我的梯度下降算法，在那个品红色的点初始化，如果我更新一步梯度下降，也许它会带我到这个点，因为这个点的导数是相当陡的。现在，在这个绿色的点，如果我再更新一步，你会发现我的导数，也即斜率，是没那么陡的。随着我接近最低点，我的导数越来越接近零，所以，梯度下降一步后，新的导数会变小一点点。然后我想再梯度下降一步，在这个绿点，我自然会用一个稍微跟刚才在那个品红点时比，再小一点的一步，到了新的红色点，更接近全局最低点了，因此这点的导数会比在绿点时更小。所以，我再进行一步梯度下降时，我的导数项是更小的，${\theta_{1} }$更新的幅度就会更小。所以随着梯度下降法的运行，你移动的幅度会自动变得越来越小，直到最终移动幅度非常小，你会发现，已经收敛到局部极小值。</p><p>回顾一下，在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小$a$。</p><p>这就是梯度下降算法，你可以用它来最小化任何代价函数$J$，不只是线性回归中的代价函数$J$。</p><p>在接下来的视频中，我们要用代价函数$J$，回到它的本质，线性回归中的代价函数。也就是我们前面得出的平方误差函数，结合梯度下降法，以及平方代价函数，我们会得出第一个机器学习算法，即线性回归算法。</p><h3 id="梯度下降的线性回归-1"><a href="#梯度下降的线性回归-1" class="headerlink" title="梯度下降的线性回归"></a>梯度下降的线性回归</h3><p>参考视频: 2 - 7 - GradientDescentForLinearRegression (6 min).mkv<br>在以前的视频中我们谈到关于梯度下降算法，梯度下降是很常用的算法，它不仅被用在线性回归上和线性回归模型、平方误差代价函数。在这段视频中，我们要将梯度下降和代价函数结合。我们将用到此算法，并将其应用于具体的拟合直线的线性回归算法里。</p><p>梯度下降算法和线性回归算法比较如图：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575430060807.png" alt="enter description here"></p><p>对我们之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数，即：</p> $h_\theta \left( x \right)=\theta_{0} + \theta_{1}x$ $\frac{\partial }{\partial { {\theta }_{j} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{\partial }{\partial { {\theta }_{j} }}\frac{1}{2m}{ {\sum\limits_{i=1}^{m}{\left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)} }^{2} }$ $j=0$ 时：$\frac{\partial }{\partial { {\theta }_{0} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{1}{m}{ {\sum\limits_{i=1}^{m}{\left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)} }}$ $j=1$ 时：$\frac{\partial }{\partial { {\theta }_{1} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)\cdot { {x}^{(i)} } \right)}$<p>则算法改写成：</p><p><strong>Repeat {</strong></p><p>​ ${\theta_{0} }:={\theta_{0} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{ \left({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)}$</p><p>​ ${\theta_{1} }:={\theta_{1} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)\cdot { {x}^{(i)} } \right)}$</p><p>​ <strong>}</strong></p><p>我们刚刚使用的算法，有时也称为批量梯度下降。实际上，在机器学习中，通常不太会给算法起名字，但这个名字”<strong>批量梯度下降</strong>”，指的是在梯度下降的每一步中，我们都用到了所有的训练样本，在梯度下降中，在计算微分求导项时，我们需要进行求和运算，所以，在每一个单独的梯度下降中，我们最终都要计算这样一个东西，这个项需要对所有$m$个训练样本求和。因此，批量梯度下降法这个名字说明了我们需要考虑所有这一”批”训练样本，而事实上，有时也有其他类型的梯度下降法，不是这种”批量”型的，不考虑整个的训练集，而是每次只关注训练集中的一些小的子集。在后面的课程中，我们也将介绍这些方法。</p><p>但就目前而言，应用刚刚学到的算法，你应该已经掌握了批量梯度算法，并且能把它应用到线性回归中了，这就是用于线性回归的梯度下降法。</p><p>如果你之前学过线性代数，有些同学之前可能已经学过高等线性代数，你应该知道有一种计算代价函数$J$最小值的数值解法，不需要梯度下降这种迭代算法。在后面的课程中，我们也会谈到这个方法，它可以在不需要多步梯度下降的情况下，也能解出代价函数$J$的最小值，这是另一种称为正规方程(<strong>normal equations</strong>)的方法。实际上在数据量较大的情况下，梯度下降法比正规方程要更适用一些。</p><p>现在我们已经掌握了梯度下降，我们可以在不同的环境中使用梯度下降法，我们还将在不同的机器学习问题中大量地使用它。所以，祝贺大家成功学会你的第一个机器学习算法。</p><p>在下一段视频中，告诉你泛化的梯度下降算法，这将使梯度下降更加强大。</p><h3 id="接下来的内容-1"><a href="#接下来的内容-1" class="headerlink" title="接下来的内容"></a>接下来的内容</h3><p>参考视频: 2 - 8 - What_’s Next (6 min).mkv<br>在接下来的一组视频中，我会对线性代数进行一个快速的复习回顾。如果你从来没有接触过向量和矩阵，那么这课件上所有的一切对你来说都是新知识，或者你之前对线性代数有所了解，但由于隔得久了，对其有所遗忘，那就请学习接下来的一组视频，我会快速地回顾你将用到的线性代数知识。</p><p>通过它们，你可以实现和使用更强大的线性回归模型。事实上，线性代数不仅仅在线性回归中应用广泛，它其中的矩阵和向量将有助于帮助我们实现之后更多的机器学习模型，并在计算上更有效率。正是因为这些矩阵和向量提供了一种有效的方式来组织大量的数据，特别是当我们处理巨大的训练集时，如果你不熟悉线性代数，如果你觉得线性代数看上去是一个复杂、可怕的概念，特别是对于之前从未接触过它的人，不必担心，事实上，为了实现机器学习算法，我们只需要一些非常非常基础的线性代数知识。通过接下来几个视频，你可以很快地学会所有你需要了解的线性代数知识。具体来说，为了帮助你判断是否有需要学习接下来的一组视频，我会讨论什么是矩阵和向量，谈谈如何加、减 、乘矩阵和向量，讨论逆矩阵和转置矩阵的概念。</p><p>如果你十分熟悉这些概念，那么你完全可以跳过这组关于线性代数的选修视频，但是如果你对这些概念仍有些许的不确定，不确定这些数字或这些矩阵的意思，那么请看一看下一组的视频，它会很快地教你一些你需要知道的线性代数的知识，便于之后编写机器学习算法和处理大量数据。</p><h2 id="线性代数回顾-Linear-Algebra-Review-1"><a href="#线性代数回顾-Linear-Algebra-Review-1" class="headerlink" title="线性代数回顾(Linear Algebra Review)"></a>线性代数回顾(Linear Algebra Review)</h2><h3 id="矩阵和向量-1"><a href="#矩阵和向量-1" class="headerlink" title="矩阵和向量"></a>矩阵和向量</h3><p>参考视频: 3 - 1 - Matrices and Vectors (9 min).mkv<br>如图：这个是4×2矩阵，即4行2列，如$m$为行，$n$为列，那么$m×n$即4×2</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575430214648.png" alt="enter description here"></p><p>矩阵的维数即行数×列数</p><p>矩阵元素（矩阵项）：$A=\left[ \begin{matrix} 1402 & 191 \\ 1371 & 821 \\ 949 & 1437 \\ 147 & 1448 \\\end{matrix} \right]$</p> $A_{ij}$指第$i$行，第$j$列的元素。<p>向量是一种特殊的矩阵，讲义中的向量一般都是列向量，如：</p> $y=\left[ \begin{matrix} {460} \\ {232} \\ {315} \\ {178} \\\end{matrix} \right]$<p>为四维列向量（4×1）。</p><p>如下图为1索引向量和0索引向量，左图为1索引向量，右图为0索引向量，一般我们用1索引向量。</p> $y=\left[ \begin{matrix} { {y}_{1} } \\ { {y}_{2} } \\ { {y}_{3} } \\ { {y}_{4} } \\\end{matrix} \right]$，$y=\left[ \begin{matrix} { {y}_{0} } \\ { {y}_{1} } \\ { {y}_{2} } \\ { {y}_{3} } \\\end{matrix} \right]$<h3 id="加法和标量乘法-1"><a href="#加法和标量乘法-1" class="headerlink" title="加法和标量乘法"></a>加法和标量乘法</h3><p>参考视频: 3 - 2 - Addition and Scalar Multiplication (7 min).mkv<br>矩阵的加法：行列数相等的可以加。</p><p>例：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431053908.png" alt="enter description here"></p><p>矩阵的乘法：每个元素都要乘</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431095812.png" alt="enter description here"></p><p>组合算法也类似。</p><h3 id="矩阵向量乘法-1"><a href="#矩阵向量乘法-1" class="headerlink" title="矩阵向量乘法"></a>矩阵向量乘法</h3><p>参考视频: 3 - 3 - Matrix Vector Multiplication (14 min).mkv</p><p>矩阵和向量的乘法如图：$m×n$的矩阵乘以$n×1$的向量，得到的是$m×1$的向量</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431123683.png" alt="enter description here"></p><p>算法举例：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431133404.png" alt="enter description here"></p><h3 id="矩阵乘法-1"><a href="#矩阵乘法-1" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h3><p>参考视频: 3 - 4 - Matrix Matrix Multiplication (11 min).mkv<br>矩阵乘法：</p> $m×n$矩阵乘以$n×o$矩阵，变成$m×o$矩阵。<p>如果这样说不好理解的话就举一个例子来说明一下，比如说现在有两个矩阵$A$和$B$，那么它们的乘积就可以表示为图中所示的形式。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431168523.png" alt="enter description here"></p><h3 id="矩阵乘法的性质-1"><a href="#矩阵乘法的性质-1" class="headerlink" title="矩阵乘法的性质"></a>矩阵乘法的性质</h3><p>参考视频: 3 - 5 - Matrix Multiplication Properties (9 min).mkv<br>矩阵乘法的性质：</p><p>矩阵的乘法不满足交换律：$A×B≠B×A$</p><p>矩阵的乘法满足结合律。即：$A×(B×C)=(A×B)×C$</p><p>单位矩阵：在矩阵的乘法中，有一种矩阵起着特殊的作用，如同数的乘法中的1,我们称这种矩阵为单位矩阵．它是个方阵，一般用 $I$ 或者 $E$ 表示，本讲义都用 $I$ 代表单位矩阵，从左上角到右下角的对角线（称为主对角线）上的元素均为1以外全都为0。如：</p> $A{ {A}^{-1} }={ {A}^{-1} }A=I$<p>对于单位矩阵，有$AI=IA=A$</p><h3 id="逆、转置-1"><a href="#逆、转置-1" class="headerlink" title="逆、转置"></a>逆、转置</h3><p>参考视频: 3 - 6 - Inverse and Transpose (11 min).mkv<br>矩阵的逆：如矩阵$A$是一个$m×m$矩阵（方阵），如果有逆矩阵，则：$A{ {A}^{-1} }={ {A}^{-1} }A=I$</p><p>我们一般在<strong>OCTAVE</strong>或者<strong>MATLAB</strong>中进行计算矩阵的逆矩阵。</p><p>矩阵的转置：设$A$为$m×n$阶矩阵（即$m$行$n$列），第$i $行$j $列的元素是$a(i,j)$，即：$A=a(i,j)$</p><p>定义$A$的转置为这样一个$n×m$阶矩阵$B$，满足$B=a(j,i)$，即 $b (i,j)=a(j,i)$（$B$的第$i$行第$j$列元素是$A$的第$j$行第$i$列元素），记${ {A}^{T} }=B$。(有些书记为A’=B）</p><p>直观来看，将$A$的所有元素绕着一条从第1行第1列元素出发的右下方45度的射线作镜面反转，即得到$A$的转置。</p><p>例：</p> ${ {\left| \begin{matrix} a& b \\ c& d \\ e& f \\\end{matrix} \right|}^{T} }=\left|\begin{matrix} a& c & e \\ b& d & f \\\end{matrix} \right|$<p>矩阵的转置基本性质:</p> $ { {\left( A\pm B \right)}^{T} }={ {A}^{T} }\pm { {B}^{T} } $ ${ {\left( A\times B \right)}^{T} }={ {B}^{T} }\times { {A}^{T} }$ ${ {\left( { {A}^{T} } \right)}^{T} }=A $ ${ {\left( KA \right)}^{T} }=K{ {A}^{T} } $<p><strong>matlab</strong>中矩阵转置：直接打一撇，<code>x=y&#39;</code>。</p><h2 id="多变量线性回归-Linear-Regression-with-Multiple-Variables-1"><a href="#多变量线性回归-Linear-Regression-with-Multiple-Variables-1" class="headerlink" title="多变量线性回归(Linear Regression with Multiple Variables)"></a>多变量线性回归(Linear Regression with Multiple Variables)</h2><h3 id="多维特征-1"><a href="#多维特征-1" class="headerlink" title="多维特征"></a>多维特征</h3><p>参考视频: 4 - 1 - Multiple Features (8 min).mkv<br>目前为止，我们探讨了单变量/特征的回归模型，现在我们对房价模型增加更多的特征，例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为$\left( {x_{1} },{x_{2} },...,{x_{n} } \right)$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431645491.png" alt="enter description here"></p><p>增添更多特征后，我们引入一系列新的注释：</p> $n$ 代表特征的数量 ${x^{\left( i \right)} }$代表第 $i$ 个训练实例，是特征矩阵中的第$i$行，是一个**向量**（**vector**）。<p>比方说，上图的</p> ${x}^{(2)}\text{=}\begin{bmatrix} 1416\\\ 3\\\ 2\\\ 40 \end{bmatrix}$， ${x}_{j}^{\left( i \right)}$代表特征矩阵中第 $i$ 行的第 $j$ 个特征，也就是第 $i$ 个训练实例的第 $j$ 个特征。<p>如上图的$x_{2}^{\left( 2 \right)}=3,x_{3}^{\left( 2 \right)}=2$，</p><p>支持多变量的假设 $h$ 表示为：$h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$，</p><p>这个公式中有$n+1$个参数和$n$个变量，为了使得公式能够简化一些，引入$x_{0}=1$，则公式转化为：$h_{\theta} \left( x \right)={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$</p><p>此时模型中的参数是一个$n+1$维的向量，任何一个训练实例也都是$n+1$维的向量，特征矩阵$X$的维度是 $m*(n+1)$。 因此公式可以简化为：$h_{\theta} \left( x \right)={\theta^{T} }X$，其中上标$T$代表矩阵转置。</p><h3 id="多变量梯度下降-1"><a href="#多变量梯度下降-1" class="headerlink" title="多变量梯度下降"></a>多变量梯度下降</h3><p>参考视频: 4 - 2 - Gradient Descent for Multiple Variables (5 min).mkv<br>与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：$J\left( {\theta_{0} },{\theta_{1} }...{\theta_{n} } \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( h_{\theta} \left({x}^{\left( i \right)} \right)-{y}^{\left( i \right)} \right)}^{2} }}$ ，</p><p>其中：$h_{\theta}\left( x \right)=\theta^{T}X={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ ，</p><p>我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。<br>多变量线性回归的批量梯度下降算法为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431758447.png" alt="enter description here"></p><p>即：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431766568.png" alt="enter description here"></p><p>求导数后得到：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431781513.png" alt="enter description here"></p><p>当$n>=1$时，</p> ${ {\theta }_{0} }:={ {\theta }_{0} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{0}^{(i)}$ ${ {\theta }_{1} }:={ {\theta }_{1} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{1}^{(i)}$ ${ {\theta }_{2} }:={ {\theta }_{2} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{2}^{(i)}$<p>我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。</p><p>代码示例：</p><p>计算代价函数</p> $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( {h_{\theta} }\left( {x^{(i)} } \right)-{y^{(i)} } \right)}^{2} }}$<p>其中：${h_{\theta} }\left( x \right)={\theta^{T} }X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$</p><p><strong>Python</strong> 代码：</p><pre><code class="python">def computeCost(X, y, theta):
inner = np.power(((X * theta.T) - y), 2)
return np.sum(inner) / (2 * len(X))</code></pre><h3 id="梯度下降法实践1-特征缩放-1"><a href="#梯度下降法实践1-特征缩放-1" class="headerlink" title="梯度下降法实践1-特征缩放"></a>梯度下降法实践1-特征缩放</h3><p>参考视频: 4 - 3 - Gradient Descent in Practice I - Feature Scaling (9 min).mkv</p><p>在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。</p><p>以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431844502.png" alt="enter description here"></p><p>解决的方法是尝试<strong>将所有特征的尺度都尽量缩放到-1到1之间</strong>。如图：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431851977.png" alt="enter description here"></p><p>最简单的方法是令：${ {x}_{n} }=\frac{ {{x}_{n} }-{ {\mu}_{n} }}{ {{s}_{n} }}$，其中 ${\mu_{n} }$是平均值，${s_{n} }$是标准差。</p><h3 id="梯度下降法实践2-学习率-1"><a href="#梯度下降法实践2-学习率-1" class="headerlink" title="梯度下降法实践2-学习率"></a>梯度下降法实践2-学习率</h3><p>参考视频: 4 - 4 - Gradient Descent in Practice II - Learning Rate (9 min).mkv<br>梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431866164.png" alt="enter description here"></p><p>也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看上面这样的图表更好。</p><p>梯度下降算法的每次迭代受到学习率的影响，如果学习率$a$过小，则达到收敛所需的迭代次数会非常高；如果学习率$a$过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。</p><p>通常可以考虑尝试些学习率：</p> $\alpha=0.01，0.03，0.1，0.3，1，3，10$<h3 id="特征和多项式回归-1"><a href="#特征和多项式回归-1" class="headerlink" title="特征和多项式回归"></a>特征和多项式回归</h3><p>参考视频: 4 - 5 - Features and Polynomial Regression (8 min).mkv</p><p>如房价预测问题，</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575431954385.png" alt="enter description here"></p> $h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }\times{frontage}+{\theta_{2} }\times{depth}$ ${x_{1} }=frontage$（临街宽度），${x_{2} }=depth$（纵向深度），$x=frontage*depth=area$（面积），则：${h_{\theta} }\left( x \right)={\theta_{0} }+{\theta_{1} }x$。<p>线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型：$h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}$<br>或者三次方模型： $h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}+{\theta_{3} }{x_{3}^3}$</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432002700.png" alt="enter description here"></p><p>通常我们需要先观察数据然后再决定准备尝试怎样的模型。 另外，我们可以令：</p> ${ {x}_{2} }=x_{2}^{2},{ {x}_{3} }=x_{3}^{3}$，从而将模型转化为线性回归模型。<p>根据函数图形特性，我们还可以使：</p> ${ {{h} }_{\theta} }(x)={ {\theta }_{0} }\text{+}{ {\theta }_{1} }(size)+{ {\theta}_{2} }{ {(size)}^{2} }$<p>或者:</p> ${ {{h} }_{\theta} }(x)={ {\theta }_{0} }\text{+}{ {\theta }_{1} }(size)+{ {\theta }_{2} }\sqrt{size}$<p>注：<strong>如果我们采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要</strong>。</p><h3 id="正规方程-1"><a href="#正规方程-1" class="headerlink" title="正规方程"></a>正规方程</h3><p>参考视频: 4 - 6 - Normal Equation (16 min).mkv<br>到目前为止，我们都在使用梯度下降算法，但是对于某些线性回归问题，正规方程方法是更好的解决方案。如：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432364923.png" alt="enter description here"></p><p>正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：$\frac{\partial}{\partial{\theta_{j} }}J\left( {\theta_{j} } \right)=0$ 。<br>假设我们的训练集特征矩阵为 $X$（包含了 ${ {x}_{0} }=1$）并且我们的训练集结果为向量 $y$，则利用正规方程解出向量 $\theta ={ {\left( {X^T}X \right)}^{-1} }{X^{T} }y$ 。<br>上标 <strong>T</strong> 代表矩阵转置，上标-1 代表矩阵的逆。设矩阵$A={X^{T} }X$，则：${ {\left( {X^T}X \right)}^{-1} }={A^{-1} }$<br>以下表示数据为例：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432408169.png" alt="enter description here"></p><p>即：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432413948.png" alt="enter description here"></p><p>运用正规方程方法求解参数：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575432420036.png" alt="enter description here"></p><p>在 <strong>Octave</strong> 中，正规方程写作：</p><pre><code>pinv(X&#39;*X)*X&#39;*y</code></pre><p>注：对于那些不可逆的矩阵（通常是因为特征之间不独立，如同时包含英尺为单位的尺寸和米为单位的尺寸两个特征，也有可能是特征数量大于训练集的数量），正规方程方法是不能用的。</p><p>梯度下降与正规方程的比较：</p><table><thead><tr><th>梯度下降</th><th>正规方程</th></tr></thead><tbody><tr><td>需要选择学习率{% raw %}$\alpha${% endraw %}</td><td>不需要</td></tr><tr><td>需要多次迭代</td><td>一次运算得出</td></tr><tr><td>当特征数量{% raw %}$n${% endraw %}大时也能较好适用</td><td>需要计算{% raw %}${ {\left( { {X}^{T} }X \right)}^{-1} }${% endraw %} 如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为{% raw %}$O\left( { {n}^{3} } \right)${% endraw %}，通常来说当{% raw %}$n${% endraw %}小于10000 时还是可以接受的</td></tr><tr><td>适用于各种类型的模型</td><td>只适用于线性模型，不适合逻辑回归模型等其他模型</td></tr></tbody></table><p>总结一下，只要特征变量的数目并不大，标准方程是一个很好的计算参数{% raw %}$\theta ${% endraw %}的替代方法。具体地说，只要特征变量数量小于一万，我通常使用标准方程法，而不使用梯度下降法。</p><p>随着我们要讲的学习算法越来越复杂，例如，当我们讲到分类算法，像逻辑回归算法，我们会看到，实际上对于那些算法，并不能使用标准方程法。对于那些更复杂的学习算法，我们将不得不仍然使用梯度下降法。因此，梯度下降法是一个非常有用的算法，可以用在有大量特征变量的线性回归问题。或者我们以后在课程中，会讲到的一些其他的算法，因为标准方程法不适合或者不能用在它们上。但对于这个特定的线性回归模型，标准方程法是一个比梯度下降法更快的替代算法。所以，根据具体的问题，以及你的特征变量的数量，这两种算法都是值得学习的。</p><p>正规方程的<strong>python</strong>实现：</p><pre><code class="python">import numpy as np

def normalEqn(X, y):

theta = np.linalg.inv(X.T@X)@X.T@y #X.T@X等价于X.T.dot(X)

return theta</code></pre><h3 id="正规方程及不可逆性（可选）-1"><a href="#正规方程及不可逆性（可选）-1" class="headerlink" title="正规方程及不可逆性（可选）"></a>正规方程及不可逆性（可选）</h3><p>参考视频: 4 - 7 - Normal Equation Noninvertibility (Optional) (6 min).mkv<br>在这段视频中谈谈正规方程 ( <strong>normal equation</strong> )，以及它们的不可逆性。<br>由于这是一种较为深入的概念，并且总有人问我有关这方面的问题，因此，我想在这里来讨论它，由于概念较为深入，所以对这段可选材料大家放轻松吧，也许你可能会深入地探索下去，并且会觉得理解以后会非常有用。但即使你没有理解正规方程和线性回归的关系，也没有关系。</p><p>我们要讲的问题如下：$\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$</p><p>备注：本节最后我把推导过程写下。</p><p>有些同学曾经问过我，当计算 $\theta$=<code>inv(X&#39;X ) X&#39;y</code> ，那对于矩阵$X'X$的结果是不可逆的情况咋办呢?<br>如果你懂一点线性代数的知识，你或许会知道，有些矩阵可逆，而有些矩阵不可逆。我们称那些不可逆矩阵为奇异或退化矩阵。<br>问题的重点在于$X'X$的不可逆的问题很少发生，在<strong>Octave</strong>里，如果你用它来实现$\theta$的计算，你将会得到一个正常的解。在<strong>Octave</strong>里，有两个函数可以求解矩阵的逆，一个被称为<code>pinv()</code>，另一个是<code>inv()</code>，这两者之间的差异是些许计算过程上的，一个是所谓的伪逆，另一个被称为逆。使用<code>pinv()</code> 函数可以展现数学上的过程，这将计算出$\theta$的值，即便矩阵$X'X$是不可逆的。</p><p>在<code>pinv()</code> 和 <code>inv()</code> 之间，又有哪些具体区别呢 ?</p><p>其中<code>inv()</code> 引入了先进的数值计算的概念。例如，在预测住房价格时，如果${x_{1} }$是以英尺为尺寸规格计算的房子，${x_{2} }$是以平方米为尺寸规格计算的房子，同时，你也知道1米等于3.28英尺 ( 四舍五入到两位小数 )，这样，你的这两个特征值将始终满足约束：${x_{1} }={x_{2} }*{ {\left( 3.28 \right)}^{2} }$。<br>实际上，你可以用这样的一个线性方程，来展示那两个相关联的特征值，矩阵$X'X$将是不可逆的。</p><p>第二个原因是，在你想用大量的特征值，尝试实践你的学习算法的时候，可能会导致矩阵$X'X$的结果是不可逆的。<br>具体地说，在$m$小于或等于n的时候，例如，有$m$等于10个的训练样本也有$n$等于100的特征数量。要找到适合的$(n +1)$ 维参数矢量$\theta$，这将会变成一个101维的矢量，尝试从10个训练样本中找到满足101个参数的值，这工作可能会让你花上一阵子时间，但这并不总是一个好主意。因为，正如我们所看到你只有10个样本，以适应这100或101个参数，数据还是有些少。</p><p>稍后我们将看到，如何使用小数据样本以得到这100或101个参数，通常，我们会使用一种叫做正则化的线性代数方法，通过删除某些特征或者是使用某些技术，来解决当$m$比$n$小的时候的问题。即使你有一个相对较小的训练集，也可使用很多的特征来找到很多合适的参数。<br>总之当你发现的矩阵$X'X$的结果是奇异矩阵，或者找到的其它矩阵是不可逆的，我会建议你这么做。</p><p>首先，看特征值里是否有一些多余的特征，像这些${x_{1} }$和${x_{2} }$是线性相关的，互为线性函数。同时，当有一些多余的特征时，可以删除这两个重复特征里的其中一个，无须两个特征同时保留，将解决不可逆性的问题。因此，首先应该通过观察所有特征检查是否有多余的特征，如果有多余的就删除掉，直到他们不再是多余的为止，如果特征数量实在太多，我会删除些 用较少的特征来反映尽可能多内容，否则我会考虑使用正规化方法。<br>如果矩阵$X'X$是不可逆的，（通常来说，不会出现这种情况），如果在<strong>Octave</strong>里，可以用伪逆函数<code>pinv()</code> 来实现。这种使用不同的线性代数库的方法被称为伪逆。即使$X'X$的结果是不可逆的，但算法执行的流程是正确的。总之，出现不可逆矩阵的情况极少发生，所以在大多数实现线性回归中，出现不可逆的问题不应该过多的关注${X^{T} }X$是不可逆的。</p><p><strong>增加内容：</strong></p> $\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$ 的推导过程： $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( {h_{\theta} }\left( {x^{(i)} } \right)-{y^{(i)} } \right)}^{2} }}$<p>其中：${h_{\theta} }\left( x \right)={\theta^{T} }X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$</p><p>将向量表达形式转为矩阵表达形式，则有$J(\theta )=\frac{1}{2}{ {\left( X\theta -y\right)}^{2} }$ ，其中$X$为$m$行$n$列的矩阵（$m$为样本个数，$n$为特征个数），$\theta$为$n$行1列的矩阵，$y$为$m$行1列的矩阵，对$J(\theta )$进行如下变换</p> $J(\theta )=\frac{1}{2}{ {\left( X\theta -y\right)}^{T} }\left( X\theta -y \right)$<p>​ $=\frac{1}{2}\left( { {\theta }^{T} }{ {X}^{T} }-{ {y}^{T} } \right)\left(X\theta -y \right)$</p><p>​ $=\frac{1}{2}\left( { {\theta }^{T} }{ {X}^{T} }X\theta -{ {\theta}^{T} }{ {X}^{T} }y-{ {y}^{T} }X\theta -{ {y}^{T} }y \right)$</p><p>接下来对$J(\theta )$偏导，需要用到以下几个矩阵的求导法则:</p> $\frac{dAB}{dB}={ {A}^{T} }$ $\frac{d{ {X}^{T} }AX}{dX}=2AX$<p>所以有:</p> $\frac{\partial J\left( \theta \right)}{\partial \theta }=\frac{1}{2}\left(2{ {X}^{T} }X\theta -{ {X}^{T} }y -{}({ {y}^{T} }X )^{T}-0 \right)$ $=\frac{1}{2}\left(2{ {X}^{T} }X\theta -{ {X}^{T} }y -{ {X}^{T} }y -0 \right)$<p>​ $={ {X}^{T} }X\theta -{ {X}^{T} }y$</p><p>令$\frac{\partial J\left( \theta \right)}{\partial \theta }=0$,</p><p>则有$\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$</p><h2 id="Octave教程-Octave-Tutorial-1"><a href="#Octave教程-Octave-Tutorial-1" class="headerlink" title="Octave教程(Octave Tutorial)"></a>Octave教程(Octave Tutorial)</h2><h3 id="基本操作-1"><a href="#基本操作-1" class="headerlink" title="基本操作"></a>基本操作</h3><p>参考视频: 5 - 1 - Basic Operations (14 min).mkv</p><p>在这段视频中，我将教你一种编程语言：<strong>Octave</strong>语言。你能够用它来非常迅速地实现这门课中我们已经学过的，或者将要学的机器学习算法。</p><p>过去我一直尝试用不同的编程语言来教授机器学习，包括<strong>C++</strong>、<strong>Java</strong>、<strong>Python</strong>、<strong>Numpy</strong>和<strong>Octave</strong>。我发现当使用像<strong>Octave</strong>这样的高级语言时，学生能够更快更好地学习并掌握这些算法。事实上，在硅谷，我经常看到进行大规模的机器学习项目的人，通常使用的程序语言就是<strong>Octave</strong>。(编者注：这是当时的情况，现在主要是用<strong>Python</strong>)</p><p><strong>Octave</strong>是一种很好的原始语言(<strong>prototyping language</strong>)，使用<strong>Octave</strong>你能快速地实现你的算法，剩下的事情，你只需要进行大规模的资源配置，你只用再花时间用<strong>C++</strong>或<strong>Java</strong>这些语言把算法重新实现就行了。开发项目的时间是很宝贵的，机器学习的时间也是很宝贵的。所以，如果你能让你的学习算法在<strong>Octave</strong>上快速的实现，基本的想法实现以后，再用<strong>C++</strong>或者<strong>Java</strong>去改写，这样你就能节省出大量的时间。</p><p>据我所见，人们使用最多的用于机器学习的原始语言是<strong>Octave</strong>、<strong>MATLAB</strong>、<strong>Python</strong>、<strong>NumPy</strong> 和<strong>R</strong>。</p><p><strong>Octave</strong>很好，因为它是开源的。当然<strong>MATLAB</strong>也很好，但它不是每个人都买得起的。(貌似国内学生喜欢用收费的<strong>matlab</strong>，<strong>matlab</strong>功能要比<strong>Octave</strong>强大的多，网上有各种<strong>D</strong>版可以下载)。这次机器学习课的作业也是用<strong>matlab</strong>的。如果你能够使用<strong>matlab</strong>，你也可以在这门课里面使用。</p><p>如果你会<strong>Python</strong>、<strong>NumPy</strong>或者<strong>R</strong>语言，我也见过有人用 <strong>R</strong>的，据我所知，这些人不得不中途放弃了，因为这些语言在开发上比较慢，而且，因为这些语言如：<strong>Python</strong>、<strong>NumPy</strong>的语法相较于<strong>Octave</strong>来说，还是更麻烦一点。正因为这样，所以我强烈建议不要用<strong>NumPy</strong>或者<strong>R</strong>来完整这门课的作业，我建议在这门课中用<strong>Octave</strong>来写程序。</p><p>本视频将快速地介绍一系列的命令，目标是迅速地展示，通过这一系列<strong>Octave</strong>的命令，让你知道<strong>Octave</strong>能用来做什么。</p><p>启动<strong>Octave</strong>：</p><p>现在打开<strong>Octave</strong>，这是<strong>Octave</strong>命令行。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e2c2dcc31f19ac255566fa616799d496.png" alt="e2c2dcc31f19ac255566fa616799d496"></p><p>现在让我示范最基本的<strong>Octave</strong>代码：</p><p>输入5 + 6，然后得到11。</p><p>输入3 – 2、5×8、1/2、2^6等等，得到相应答案。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6dcdf4a7c0d56787648d4a1902034150.png" alt="6dcdf4a7c0d56787648d4a1902034150"></p><p>这些都是基本的数学运算。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8507899953ed2de68e6b2b83554f9ea.png" alt="f8507899953ed2de68e6b2b83554f9ea"><br>你也可以做逻辑运算，例如 1==2，计算结果为 <strong>false</strong> (<strong>假</strong>)，这里的百分号命令表示注释，1==2 计算结果为假，这里用0表示。</p><p>请注意，不等于符号的写法是这个波浪线加上等于符号 ( ~= )，而不是等于感叹号加等号( != )，这是和其他一些编程语言中不太一样的地方。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/126b2a5c4b5bfb24e5c21cd080159530.png" alt="126b2a5c4b5bfb24e5c21cd080159530"><br>让我们看看逻辑运算 1 &amp;&amp; 0，使用双&amp;符号表示逻辑与，1 &amp;&amp; 0判断为假，1和0的或运算 1 || 0，其计算结果为真。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fec0936e2a78c0fe8c9e3ed107614a31.png" alt="fec0936e2a78c0fe8c9e3ed107614a31"><br>还有异或运算 如<code>XOR ( 1, 0 )</code>，其返回值为1</p><p>从左向右写着 <strong>Octave 324.x</strong>版本，是默认的<strong>Octave</strong>提示，它显示了当前<strong>Octave</strong>的版本，以及相关的其它信息。</p><p>如果你不想看到那个提示，这里有一个隐藏的命令：</p><p>输入命令</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8d63fe546c12a7e9eb658118d76288f7.png" alt="8d63fe546c12a7e9eb658118d76288f7"><br>现在命令提示已经变得简化了。</p><p>接下来，我们将谈到<strong>Octave</strong>的变量。</p><p>现在写一个变量，对变量$A$赋值为3，并按下回车键，显示变量$A$等于3。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a537df35ccc9ff83a3c7518362e2f729.png" alt="a537df35ccc9ff83a3c7518362e2f729"><br>如果你想分配一个变量，但不希望在屏幕上显示结果，你可以在命令后加一个分号，可以抑制打印输出，敲入回车后，不打印任何东西。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c11786828c587189891a9ef02f041ab7.png" alt="c11786828c587189891a9ef02f041ab7"><br>其中这句命令不打印任何东西。</p><p>现在举一个字符串的例子：变量$b$等于”<strong>hi</strong>“。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4b67374499c0d38ed8670ba74ff892d0.png" alt="4b67374499c0d38ed8670ba74ff892d0"></p> $c$等于3大于等于1，所以，现在$c$变量的值是真。<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/acedf91b6b39d551e62a89f2e0955628.png" alt="acedf91b6b39d551e62a89f2e0955628"><br>如果你想打印出变量，或显示一个变量，你可以像下面这么做：</p><p>设置$a$等于圆周率$π$，如果我要打印该值，那么只需键入<code>a</code>像这样 就打印出来了。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2cdc09b8bf67e546df7284ba74601c66.png" alt="2cdc09b8bf67e546df7284ba74601c66"><br>对于更复杂的屏幕输出，也可以用<strong>DISP</strong>命令显示：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dfcd1d37526824726d85a655f8951249.png" alt="dfcd1d37526824726d85a655f8951249"><br>这是一种，旧风格的<strong>C语言</strong>语法，对于之前就学过<strong>C语言</strong>的同学来说，你可以使用这种基本的语法来将结果打印到屏幕。</p><p>例如 ^{T}命令的六个小数：0.6%f ,a，这应该打印$π$的6位小数形式。</p><p>也有一些控制输出长短格式的快捷命令：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ba8f0c3d2d8f017e0f7a611aa5be75d6.png" alt="ba8f0c3d2d8f017e0f7a611aa5be75d6"><br>下面，让我们来看看向量和矩阵：</p><p>比方说 建立一个矩阵$A$：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/693ebb444501838dd9b69520fff54be0.png" alt="693ebb444501838dd9b69520fff54be0"><br>对$A$矩阵进行赋值，考虑到这是一个三行两列的矩阵，你同样可以用向量。</p><p>建立向量$V$并赋值1 2 3，$V$是一个行向量，或者说是一个3 ( 列 )×1 ( 行 )的向量，或者说，一行三列的矩阵。</p><p>如果我想，分配一个列向量，我可以写“1;2;3”，现在便有了一个3 行 1 列的向量，同时这是一个列向量。</p><p>下面是一些更为有用的符号，如：</p><pre><code class="matlab">V=1：0.1：2</code></pre><p>这个该如何理解呢：这个集合{% raw %}$v${% endraw %}是一组值，从数值1开始，增量或说是步长为0.1，直到增加到2，按照这样的方法对向量{% raw %}$V${% endraw %}操作，可以得到一个行向量，这是一个1行11列的矩阵，其矩阵的元素是1<br>1.1 1.2 1.3，依此类推，直到数值2。</p><p>我也可以建立一个集合{% raw %}$v${% endraw %}并用命令“1:6”进行赋值，这样{% raw %}$V${% endraw %}就被赋值了1至6的六个整数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1cdbd87db83a4184098cd6d5ee3c6a87.png" alt="1cdbd87db83a4184098cd6d5ee3c6a87"><br>这里还有一些其他的方法来生成矩阵</p><p>例如“<code>ones(2, 3)</code>”，也可以用来生成矩阵：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5d2b25d4078a276091b9c00812674fa9.png" alt="5d2b25d4078a276091b9c00812674fa9"><br>元素都为2，两行三列的矩阵，就可以使用这个命令：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/21985f8690965598d4a17e3a6e7fee94.png" alt="21985f8690965598d4a17e3a6e7fee94"><br>你可以把这个方法当成一个生成矩阵的快速方法。</p> {% raw %}$w${% endraw %}为一个一行三列的零矩阵，一行三列的{% raw %}$A${% endraw %}矩阵里的元素全部是零：<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/846b48ec79c9fcee05b20767dcc89558.png" alt="846b48ec79c9fcee05b20767dcc89558"><br>还有很多的方式来生成矩阵。</p><p>如果我对{% raw %}$W${% endraw %}进行赋值，用<strong>Rand</strong>命令建立一个一行三列的矩阵，因为使用了<strong>Rand</strong>命令，则其一行三列的元素均为随机值，如“<code>rand(3,3)</code>”命令，这就生成了一个3×3的矩阵，并且其所有元素均为随机。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0de6e7054e869a82060cefa9968cd56b.png" alt="0de6e7054e869a82060cefa9968cd56b"><br>数值介于0和1之间，所以，正是因为这一点，我们可以得到数值均匀介于0和1之间的元素。</p><p>如果，你知道什么是高斯随机变量，或者，你知道什么是正态分布的随机变量，你可以设置集合{% raw %}$W${% endraw %}，使其等于一个一行三列的{% raw %}$N${% endraw %}矩阵，并且，来自三个值，一个平均值为0的高斯分布，方差或者等于1的标准偏差。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/048f3cac1c32e3dc56160849c4dd60b0.png" alt="048f3cac1c32e3dc56160849c4dd60b0"><br>还可以设置地更复杂：</p><p>并用<strong>hist</strong>命令绘制直方图。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/10c06cc39058da2c5eef696d75e65a2c.png" alt="10c06cc39058da2c5eef696d75e65a2c"><br>绘制单位矩阵：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08d11f870c5b30536f1965507fa7e7dc.png" alt="08d11f870c5b30536f1965507fa7e7dc"><br>如果对命令不清楚，建议用<strong>help</strong>命令：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/79b55d71cf434126f3d8457a3a615d18.png" alt="79b55d71cf434126f3d8457a3a615d18"><br>以上讲解的内容都是<strong>Octave</strong>的基本操作。希望你能通过上面的讲解，自己练习一些矩阵、乘、加等操作，将这些操作在<strong>Octave</strong>中熟练运用。</p><p>在接下来的视频中，将会涉及更多复杂的命令，并使用它们在<strong>Octave</strong>中对数据进行更多的操作。</p><h3 id="移动数据-1"><a href="#移动数据-1" class="headerlink" title="移动数据"></a>移动数据</h3><p>参考视频: 5 - 2 - Moving Data Around (16 min).mkv</p><p>在这段关于 <strong>Octave</strong>的辅导课视频中，我将开始介绍如何在 <strong>Octave</strong> 中移动数据。</p><p>如果你有一个机器学习问题，你怎样把数据加载到 <strong>Octave</strong> 中？</p><p>怎样把数据存入一个矩阵？</p><p>如何对矩阵进行相乘？</p><p>如何保存计算结果？</p><p>如何移动这些数据并用数据进行操作？</p><p>进入我的 <strong>Octave</strong> 窗口，</p><p>我键入{% raw %}$A${% endraw %}，得到我们之前构建的矩阵 {% raw %}$A${% endraw %}，也就是用这个命令生成的：</p><p><code>A = [1 2; 3 4; 5 6]</code></p><p>这是一个3行2列的矩阵，<strong>Octave</strong> 中的 <code>size()</code> 命令返回矩阵的尺寸。</p><p>所以 <code>size(A)</code> 命令返回3 2</p><p><img src="https://markdown.xiaoshujiang.com/img/spinner.gif" alt="0f1fe8638058e229f1fc6c5b9cd4520c" title="[[[1575432885877]]]"><br>实际上，<code>size()</code> 命令返回的是一个 1×2 的矩阵，我们可以用 {% raw %}$sz${% endraw %} 来存放。</p><p>设置 <code>sz = size(A)</code></p><p>因此 {% raw %}$sz${% endraw %} 就是一个1×2的矩阵，第一个元素是3，第二个元素是2。</p><p>所以如果键入 <code>size(sz)</code> 看看 {% raw %}$sz${% endraw %} 的尺寸，返回的是1 2，表示是一个1×2的矩阵，1 和 2分别表示矩阵{% raw %}$sz${% endraw %}的维度 。</p><p>你也可以键入 <code>size(A, 1)</code>，将返回3，这个命令会返回{% raw %}$A${% endraw %}矩阵的第一个元素，{% raw %}$A${% endraw %}矩阵的第一个维度的尺寸，也就是 {% raw %}$A${% endraw %} 矩阵的行数。</p><p>同样，命令 <code>size(A, 2)</code>，将返回2，也就是 {% raw %}$A${% endraw %} 矩阵的列数。</p><p>如果你有一个向量 {% raw %}$v${% endraw %}，假如 <code>v = [1 2 3 4]</code>，然后键入<code>length(v)</code>，这个命令将返回最大维度的大小，返回4。</p><p>你也可以键入<code>length(A)</code>，由于矩阵{% raw %}$A${% endraw %}是一个3×2的矩阵，因此最大的维度应该是3，因此该命令会返回3。</p><p>但通常我们还是对向量使用 {% raw %}$length${% endraw %} 命令，而不是对矩阵使用 <code>length</code> 命令，比如<br><code>length([1;2;3;4;5])</code>，返回5。</p><p>如何在系统中加载数据和寻找数据：</p><p>当我们打开 <strong>Octave</strong> 时，我们通常已经在一个默认路径中，这个路径是 <strong>Octave</strong>的安装位置，<code>pwd</code> 命令可以显示出<strong>Octave</strong> 当前所处路径。</p><p><code>cd</code>命令，意思是改变路径，我可以把路径改为<strong>C:\Users\ang\Desktop</strong>，这样当前目录就变为了桌面。</p><p>如果键入 <code>ls</code>，<strong>ls</strong> 来自于一个 <strong>Unix</strong> 或者 <strong>Linux</strong> 命令，<strong>ls</strong>命令将列出我桌面上的所有路径。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0de527966203108b7efa1b6730bd966c.png" alt="0de527966203108b7efa1b6730bd966c"><br>事实上，我的桌面上有两个文件：<strong>featuresX.dat</strong> 和<strong>priceY.dat</strong>，是两个我想解决的机器学习问题。</p><p><strong>featuresX</strong>文件如这个窗口所示，是一个含有两列数据的文件，其实就是我的房屋价格数据，数据集中有47行，第一个房子样本，面积是2104平方英尺，有3个卧室，第二套房子面积为1600，有3个卧室等等。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e4080d69119a0e408581c81a66e133c8.png" alt="e4080d69119a0e408581c81a66e133c8"><br><strong>priceY</strong>这个文件就是训练集中的价格数据，所以 <strong>featuresX</strong> 和<strong>priceY</strong>就是两个存放数据的文档，那么应该怎样把数据读入 <strong>Octave</strong> 呢？我们只需要键入<code>featuresX.dat</code>，这样我将加载了 <strong>featuresX</strong> 文件。同样地我可以加载<code>priceY.dat</code>。其实有好多种办法可以完成，如果你把命令写成字符串的形式<code>load(&#39;featureX.dat&#39;)</code>，也是可以的，这跟刚才的命令效果是相同的，只不过是把文件名写成了一个字符串的形式，现在文件名被存在一个字符串中。<strong>Octave</strong>中使用引号来表示字符串。</p><p>另外 <code>who</code> 命令，能显示出 在我的 <strong>Octave</strong>工作空间中的所有变量</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7e85f313f721f53f3ae74664210a7a25.png" alt="7e85f313f721f53f3ae74664210a7a25"><br>所以我可以键入<code>featuresX</code> 回车，来显示 <strong>featuresX</strong></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e49f56ceddd34dce986ae1dbdc399762.png" alt="e49f56ceddd34dce986ae1dbdc399762"><br>这些就是存在里面的数据。</p><p>还可以键入 <code>size(featuresX)</code>，得出的结果是 47 2，代表这是一个47×2的矩阵。</p><p>类似地，输入 <code>size(priceY)</code>，结果是 47<br>1，表示这是一个47维的向量，是一个列矩阵，存放的是训练集中的所有价格{% raw %}$Y${% endraw %} 的值。</p><p><code>who</code> 函数能让你看到当前工作空间中的所有变量，同样还有另一个 <code>whos</code>命令，能更详细地进行查看。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e8207c74976c4443d1ea25ec2a3b8477.png" alt="e8207c74976c4443d1ea25ec2a3b8477"><br>同样也列出我所有的变量，不仅如此，还列出了变量的维度。</p><p><strong>double</strong> 意思是双精度浮点型，这也就是说，这些数都是实数，是浮点数。</p><p>如果你想删除某个变量，你可以使用 <code>clear</code> 命令，我们键入 <code>clear featuresX</code>，然后再输入 <code>whos</code> 命令，你会发现 <strong>featuresX</strong> 消失了。</p><p>另外，我们怎么储存数据呢？</p><p>我们设变量 <code>V= priceY(1:10)</code></p><p>这表示的是将向量 {% raw %}$Y ${% endraw %}的前10个元素存入 {% raw %}$V${% endraw %}中。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a8c3b363f13820b4fc6463c7520ab58c.png" alt="a8c3b363f13820b4fc6463c7520ab58c"><br>假如我们想把它存入硬盘，那么用 <code>save hello.mat v</code> 命令，这个命令会将变量{% raw %}$V${% endraw %}存成一个叫 <strong>hello.mat</strong> 的文件，让我们回车，现在我的桌面上就出现了一个新文件，名为<strong>hello.mat</strong>。</p><p>由于我的电脑里同时安装了 <strong>MATLAB</strong>，所以这个图标上面有 <strong>MATLAB</strong>的标识，因为操作系统把文件识别为 <strong>MATLAB</strong>文件。如果在你的电脑上图标显示的不一样的话，也没有关系。</p><p>现在我们清除所有变量，直接键入<code>clear</code>，这样将删除工作空间中的所有变量，所以现在工作空间中啥都没了。</p><p>但如果我载入 <strong>hello.mat</strong> 文件，我又重新读取了变量 {% raw %}$v${% endraw %}，因为我之前把变量{% raw %}$v${% endraw %}存入了<strong>hello.mat</strong> 文件中，所以我们刚才用 <code>save</code>命令做了什么。这个命令把数据按照二进制形式储存，或者说是更压缩的二进制形式，因此，如果{% raw %}$v${% endraw %}是很大的数据，那么压缩幅度也更大，占用空间也更小。如果你想把数据存成一个人能看懂的形式，那么可以键入：</p><p><code>save hello.txt v -ascii</code></p><p>这样就会把数据存成一个文本文档，或者将数据的 <strong>ascii 码</strong>存成文本文档。</p><p>我键入了这个命令以后，我的桌面上就有了 <strong>hello.txt</strong>文件。如果打开它，我们可以发现这个文本文档存放着我们的数据。</p><p>这就是读取和储存数据的方法。</p><p>接下来我们再来讲讲操作数据的方法：</p><p>假如 {% raw %}$A${% endraw %} 还是那个矩阵</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b39bf4e9212442464fe2f568dbe4fa0c.png" alt="b39bf4e9212442464fe2f568dbe4fa0c"><br>跟刚才一样还是那个 3×2 的矩阵，现在我们加上索引值，比如键入 <code>A(3,2)</code></p><p>这将索引到{% raw %}$A${% endraw %} 矩阵的 (3,2) 元素。这就是我们通常书写矩阵的形式，写成 {% raw %}$A${% endraw %} 32，3和2分别表示矩阵的第三行和第二列对应的元素，因此也就对应 6。</p><p>我也可以键入<code>A(2,:)</code> 来返回第二行的所有元素，冒号表示该行或该列的所有元素。</p><p>类似地，如果我键入 <code>A(:,2)</code>，这将返回 {% raw %}$A${% endraw %} 矩阵第二列的所有元素，这将得到 2 4 6。</p><p>这表示返回{% raw %}$A${% endraw %} 矩阵的第二列的所有元素。</p><p>你也可以在运算中使用这些较为复杂的索引。</p><p>我再给你展示几个例子，可能你也不会经常使用，但我还是输入给你看 <code>A([1 3],:)</code>，这个命令意思是取 {% raw %}$A${% endraw %} 矩阵第一个索引值为1或3的元素，也就是说我取的是A矩阵的第一行和第三行的每一列，冒号表示的是取这两行的每一列元素，即：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d1d551d0c540449d457e312a34434355.png" alt="d1d551d0c540449d457e312a34434355"><br>可能这些比较复杂一点的索引操作你会经常用到。</p><p>我们还能做什么呢？依然是 {% raw %}$A${% endraw %} 矩阵，<code>A(:,2)</code> 命令返回第二列。</p><p>你也可以为它赋值，我可以取 {% raw %}$A${% endraw %} 矩阵的第二列，然后将它赋值为10 11 12，我实际上是取出了 {% raw %}$A${% endraw %} 的第二列，然后把一个列向量[10;11;12]赋给了它，因此现在 {% raw %}$A${% endraw %} 矩阵的第一列还是 1 3 5，第二列就被替换为 10 11 12。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f47bda45fd9beef6c600ebd48d163617.png" alt="f47bda45fd9beef6c600ebd48d163617"><br>接下来一个操作，让我们把 {% raw %}$A ${% endraw %}设为<code>A = [A, [100, 101,102]]</code>，这样做的结果是在原矩阵的右边附加了一个新的列矩阵，就是把 {% raw %}$A${% endraw %}矩阵设置为原来的 {% raw %}$A${% endraw %} 矩阵再在右边附上一个新添加的列矩阵。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e1c68a99a23d993674f08151e77dd44.png" alt="2e1c68a99a23d993674f08151e77dd44"><br>最后，还有一个小技巧，如果你就输入 <code>A(:)</code>，这是一个很特别的语法结构，意思是把 {% raw %}$A${% endraw %}中的所有元素放入一个单独的列向量，这样我们就得到了一个 9×1 的向量，这些元素都是{% raw %}$A${% endraw %} 中的元素排列起来的。</p><p>再来几个例子：</p><p>我还是把 A 重新设为 [1 2; 3 4; 5 6]，我再设一个 {% raw %}$B${% endraw %}为[11 12; 13 14; 15 16]，我可以新建一个矩阵 {% raw %}$C${% endraw %}，<code>C = [A B]</code>，这个意思就是把这两个矩阵直接连在一起，矩阵{% raw %}$A${% endraw %} 在左边，矩阵{% raw %}$B${% endraw %} 在右边，这样组成了 {% raw %}$C${% endraw %}矩阵，就是直接把{% raw %}$A${% endraw %}和 {% raw %}$B${% endraw %} 合起来。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e07db429512d4b3b5d641c52e606159d.png" alt="e07db429512d4b3b5d641c52e606159d"><br>我还可以设<code>C = [A; B]</code>，这里的分号表示把分号后面的东西放到下面。所以，<code>[A;B]</code>的作用依然还是把两个矩阵放在一起，只不过现在是上下排列，所以现在 {% raw %}$A${% endraw %} 在上面 {% raw %}$B${% endraw %}在下面，{% raw %}$C${% endraw %} 就是一个 6×2 矩阵。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7f11aa788b1b75c5a534d030b3ebc624.png" alt="7f11aa788b1b75c5a534d030b3ebc624"><br>简单地说，分号的意思就是换到下一行，所以 C 就包括上面的A，然后换行到下面，然后在下面放上一个 {% raw %}$B${% endraw %}。</p><p>另外顺便说一下，这个<code>[A B]</code>命令跟 <code>[A, B]</code> 是一样的，这两种写法的结果是相同的。</p><p>通过以上这些操作，希望你现在掌握了怎样构建矩阵，也希望我展示的这些命令能让你很快地学会怎样把矩阵放到一起，怎样取出矩阵，并且把它们放到一起，组成更大的矩阵。</p><p>通过几句简单的代码，<strong>Octave</strong>能够很方便地很快速地帮助我们组合复杂的矩阵以及对数据进行移动。这就是移动数据这一节课。</p><p>我认为对你来讲，最好的学习方法是，下课后复习一下我键入的这些代码好好地看一看，从课程的网上把代码的副本下载下来，重新好好看看这些副本，然后自己在<strong>Octave</strong> 中把这些命令重新输一遍，慢慢开始学会使用这些命令。</p><p>当然，没有必要把这些命令都记住，你也不可能记得住。你要做的就是，了解一下你可以用哪些命令，做哪些事。这样在你今后需要编写学习算法时，如果你要找到某个<strong>Octave</strong>中的命令，你可能回想起你之前在这里学到过，然后你就可以查找课程中提供的程序副本，这样就能很轻松地找到你想使用的命令了。</p><h3 id="计算数据-1"><a href="#计算数据-1" class="headerlink" title="计算数据"></a>计算数据</h3><p>参考视频: 5 - 3 - Computing on Data (13 min).mkv</p><p>现在，你已经学会了在<strong>Octave</strong>中如何加载或存储数据，如何把数据存入矩阵等等。在这段视频中，我将介绍如何对数据进行运算，稍后我们将使用这些运算操作来实现我们的学习算法。</p><p>这是我的 <strong>Octave</strong>窗口，我现在快速地初始化一些变量。比如设置{% raw %}$A${% endraw %}为一个3×2的矩阵，设置{% raw %}$B${% endraw %}为一个3 ×2矩阵，设置{% raw %}$C${% endraw %}为2 × 2矩阵。</p><p>我想算两个矩阵的乘积，比如说 {% raw %}$A × C${% endraw %}，我只需键入<code>A×C</code>，这是一个 3×2 矩阵乘以 2×2矩阵，得到这样一个3×2矩阵。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8ee5c7c05865e90f75feda99b9131319.png" alt="8ee5c7c05865e90f75feda99b9131319"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/38c956acb3bedf4362f40e6c5e8a692f.png" alt="38c956acb3bedf4362f40e6c5e8a692f"><br>你也可以对每一个元素，做运算 方法是做点乘运算<code>A.*B</code>，这么做Octave将矩阵 {% raw %}$A${% endraw %}中的每一个元素与矩阵 {% raw %}$B${% endraw %} 中的对应元素相乘:<code>A.*B</code></p><p>这里第一个元素1乘以11得到11，第二个元素2乘以12得到24，这就是两个矩阵的元素位运算。通常来说，在<strong>Octave</strong>中点号一般用来表示元素位运算。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/646de38bffd4f7f6601167d0c0686970.png" alt="646de38bffd4f7f6601167d0c0686970"><br>这里是一个矩阵{% raw %}$A${% endraw %}，这里我输入<code>A.^2</code>，这将对矩阵{% raw %}$A${% endraw %}中每一个元素平方。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d456e7501d7aaa9fa2ef8a89e89fa7e1.png" alt="d456e7501d7aaa9fa2ef8a89e89fa7e1"><br>我们设{% raw %}$V${% endraw %}为 [1; 2; 3] 是列向量，你也可以输入<code>1./V</code>，得到每一个元素的倒数，所以这样一来，就会分别算出 1/1 1/2 1/3。</p><p>矩阵也可以这样操作，<code>1./A</code> 得到{% raw %}$A${% endraw %}中每一个元素的倒数。</p><p>同样地，这里的点号还是表示对每一个元素进行操作。</p><p>我们还可以进行求对数运算，也就是对每个元素进行求对数运算。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0c7c1d7726c09ffb45152cf153614003.png" alt="0c7c1d7726c09ffb45152cf153614003"><br>还有自然数{% raw %}$e${% endraw %}的幂次运算，就是以{% raw %}$e${% endraw %}为底，以这些元素为幂的运算。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a36506049248948c82e598c8c254dc31.png" alt="a36506049248948c82e598c8c254dc31"><br>我还可以用 <strong>abs</strong>来对 {% raw %}$v${% endraw %} 的每一个元素求绝对值，当然这里 {% raw %}$v${% endraw %}都是正数。我们换成另一个这样对每个元素求绝对值，得到的结果就是这些非负的元素。还有{% raw %}$–v${% endraw %}，给出{% raw %}$v${% endraw %}中每个元素的相反数，这等价于 -1 乘以 {% raw %}$v${% endraw %}，一般就直接用 {% raw %}$-v${% endraw %}<br>就好了，其实就等于 $-1*v$。</p><p>还有一个技巧，比如说我们想对{% raw %}$v${% endraw %}中的每个元素都加1，那么我们可以这么做，首先构造一个3行1列的1向量，然后把这个1向量跟原来的向量相加，因此{% raw %}$v${% endraw %}向量从[1 2 3] 增至 [2 3 4]。我用了一个，<code>length(v)</code>命令，因此这样一来，<code>ones(length(v) ,1)</code> 就相当于<code>ones(3,1)</code>，然后我做的是<code>v +ones(3,1)</code>，也就是将 {% raw %}$v${% endraw %} 的各元素都加上这些1，这样就将{% raw %}$v${% endraw %} 的每个元素增加了1。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9432bbcbfde53c7e0dcb1c7317b01c0c.png" alt="9432bbcbfde53c7e0dcb1c7317b01c0c"><br>另一种更简单的方法是直接用 <code>v+1</code>，<code>v + 1</code> 也就等于把 {% raw %}$v${% endraw %} 中的每一个元素都加上1。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e02eec3ca4688ff1cb9126c8eb13bfed.png" alt="e02eec3ca4688ff1cb9126c8eb13bfed"><br>现在，让我们来谈谈更多的操作。</p><p>矩阵{% raw %}$A${% endraw %} 如果你想要求它的转置，那么方法是用A’,将得出 A 的转置矩阵。当然，如果我写<code>(A&#39;)&#39;</code>，也就是 {% raw %}$A${% endraw %} 转置两次，那么我又重新得到矩阵 {% raw %}$A${% endraw %}。</p><p>还有一些有用的函数，比如： <code>a=[1 15 2 0.5]</code>，这是一个1行4列矩阵，<code>val=max(a)</code>，这将返回{% raw %}$A${% endraw %}矩阵中的最大值15。</p><p>我还可以写 <code>[val, ind] =max(a)</code>，这将返回{% raw %}$A${% endraw %}矩阵中的最大值存入{% raw %}$val${% endraw %}，以及该值对应的索引，元素15对应的索引值为2,存入{% raw %}$ind${% endraw %}，所以 {% raw %}$ind =2${% endraw %}。</p><p>特别注意一下，如果你用命令 <code>max(A)</code>，{% raw %}$A${% endraw %}是一个矩阵的话，这样做就是对每一列求最大值。</p><p>我们还是用这个例子，这个 {% raw %}$a${% endraw %} 矩阵<code>a=[1 15 2 0.5]</code>，如果输入<code>a&amp;lt;3</code>，这将进行逐元素的运算，所以元素小于3的返回1，否则返回0。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fc04d42876c9d7d7bed51bade2077649.png" alt="fc04d42876c9d7d7bed51bade2077649"><br>因此，返回[1 1 0 1]。也就是说，对{% raw %}$a${% endraw %}矩阵的每一个元素与3进行比较，然后根据每一个元素与3的大小关系，返回1和0表示真与假。</p><p>如果我写 <code>find(a&amp;lt;3)</code>，这将告诉我{% raw %}$a${% endraw %} 中的哪些元素是小于3的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ac9ad10f115d2d1cd15a0514c8ceeafa.png" alt="ac9ad10f115d2d1cd15a0514c8ceeafa"><br>设<code>A = magic(3)</code>，<strong>magic 函数</strong>将返回一个矩阵，称为魔方阵或幻方 (<strong>magic squares</strong>)，它们具有以下这样的数学性质：它们所有的行和列和对角线加起来都等于相同的值。</p><p>当然据我所知，这在机器学习里基本用不上，但我可以用这个方法很方便地生成一个3行3列的矩阵，而这个魔方矩阵这神奇的方形屏幕。每一行、每一列、每一个对角线三个数字加起来都是等于同一个数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8c7f4f36183ef4b36bce427be2fce6f.png" alt="f8c7f4f36183ef4b36bce427be2fce6f"><br>在其他有用的机器学习应用中，这个矩阵其实没多大作用。</p><p>如果我输入 <code>[r,c] = find(A&gt;=7)</code>，这将找出所有{% raw %}$A${% endraw %}矩阵中大于等于7的元素，因此，{% raw %}$r${% endraw %} 和{% raw %}$c${% endraw %}分别表示行和列，这就表示，第一行第一列的元素大于等于7，第三行第二列的元素大于等于7，第二行第三列的元素大于等于7。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/409a04487d1d7f039acfd61b3787f6aa.png" alt="409a04487d1d7f039acfd61b3787f6aa"><br>顺便说一句，其实我从来都不去刻意记住这个 <strong>find 函数</strong>，到底是怎么用的，我只需要会用<strong>help函数</strong>就可以了，每当我在使用这个函数，忘记怎么用的时候，我就可以用 <strong>help函数</strong>，键入 <code>help find</code> 来找到帮助文档。</p><p>最后再讲两个内容，一个是求和函数，这是 {% raw %}$a${% endraw %} 矩阵：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d7221c981ecc7730465710a0d8b49b34.png" alt="d7221c981ecc7730465710a0d8b49b34"><br>键入 <code>sum(a)</code>，就把 a 中所有元素加起来了。</p><p>如果我想把它们都乘起来，键入 <code>prod(a)</code>，<strong>prod</strong> 意思是<strong>product(乘积)</strong>，它将返回这四个元素的乘积。</p><p><code>floor(a)</code> 是向下四舍五入，因此对于 {% raw %}$a${% endraw %} 中的元素0.5将被下舍入变成0。</p><p>还有 <code>ceil(a)</code>，表示向上四舍五入，所以0.5将上舍入变为最接近的整数，也就是1。</p><p>键入 <code>type(3)</code>，这通常得到一个3×3的矩阵，如果键入 <code>max(rand(3),rand(3))</code>，这样做的结果是返回两个3×3的随机矩阵，并且逐元素比较取最大值。</p><p>假如我输入<code>max(A,[],1)</code>，这样做会得到每一列的最大值。</p><p>所以第一列的最大值就是8，第二列是9，第三列的最大值是7，这里的1表示取A矩阵第一个维度的最大值。</p><p>相对地，如果我键入<code>max(A,[],2)</code>，这将得到每一行的最大值，所以，第一行的最大值是等于8，第二行最大值是7，第三行是9。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/31bc524d1a19b4e9d8ea0974517a512e.png" alt="31bc524d1a19b4e9d8ea0974517a512e"><br>所以你可以用这个方法来求得每一行或每一列的最值，另外，你要知道，默认情况下<code>max(A)</code>返回的是每一列的最大值，如果你想要找出整个矩阵A的最大值，你可以输入<code>max(max(A))</code>，或者你可以将{% raw %}$A${% endraw %} 矩阵转成一个向量，然后键入 <code>max(A(:))</code>，这样做就是把 {% raw %}$A${% endraw %} 当做一个向量，并返回 {% raw %}$A${% endraw %}向量中的最大值。</p><p>最后，让我们把 {% raw %}$A${% endraw %}设为一个9行9列的魔方阵，魔方阵具有的特性是每行每列和对角线的求和都是相等的。</p><p>这是一个9×9的魔方阵，我们来求一个 <code>sum(A,1)</code>，这样就得到每一列的总和，这也验证了一个9×9的魔方阵确实每一列加起来都相等，都为369。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0b9753a3e10bbdce0f26c3d44d61ae26.png" alt="0b9753a3e10bbdce0f26c3d44d61ae26"><br>现在我们来求每一行的和，键入<code>sum(A,2)</code>，这样就得到了{% raw %}$A${% endraw %} 中每一行的和加起来还是369。</p><p>现在我们来算{% raw %}$A ${% endraw %}的对角线元素的和。我们现在构造一个9×9 的单位矩阵，键入 <code>eye(9)</code>,</p><p>然后我们要用 {% raw %}$A${% endraw %}逐点乘以这个单位矩阵，除了对角线元素外，其他元素都会得到0。</p><p>键入<code>sum(sum(A.*eye(9))</code></p><p>这实际上是求得了，这个矩阵对角线元素的和确实是369。</p><p>你也可以求另一条对角线的和也是是369。</p><p><strong>flipup/flipud</strong> 表示向上/向下翻转。</p><p>同样地，如果你想求这个矩阵的逆矩阵，键入<code>pinv(A)</code>，通常称为伪逆矩阵，你就把它看成是矩阵 {% raw %}$A${% endraw %} 求逆，因此这就是 {% raw %}$A${% endraw %}矩阵的逆矩阵。</p><p>设 <code>temp = pinv(A)</code>，然后再用{% raw %}$temp${% endraw %} 乘以{% raw %}$A${% endraw %}，这实际上得到的就是单位矩阵，对角线为1，其他元素为0。</p><p>如何对矩阵中的数字进行各种操作，在运行完某个学习算法之后，通常一件最有用的事情是看看你的结果，或者说让你的结果可视化，在接下来的视频中，我会非常迅速地告诉你，如何很快地画图，如何只用一两行代码，你就可以快速地可视化你的数据，这样你就能更好地理解你使用的学习算法。</p><h3 id="绘图数据-1"><a href="#绘图数据-1" class="headerlink" title="绘图数据"></a>绘图数据</h3><p>参考视频: 5 - 4 - Plotting Data (10 min).mkv</p><p>当开发学习算法时，往往几个简单的图，可以让你更好地理解算法的内容，并且可以完整地检查下算法是否正常运行，是否达到了算法的目的。</p><p>例如在之前的视频中，我谈到了绘制成本函数{% raw %}$J(\theta)${% endraw %}，可以帮助确认梯度下降算法是否收敛。通常情况下，绘制数据或学习算法所有输出，也会启发你如何改进你的学习算法。幸运的是，<strong>Octave</strong>有非常简单的工具用来生成大量不同的图。当我用学习算法时，我发现绘制数据、绘制学习算法等，往往是我获得想法来改进算法的重要部分。在这段视频中，我想告诉你一些<strong>Octave</strong>的工具来绘制和可视化你的数据。</p><p>我们先来快速生成一些数据用来绘图。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4514b422525aaac1e99add67e44882ee.png" alt="4514b422525aaac1e99add67e44882ee"><br>如果我想绘制正弦函数，这是很容易的，我只需要输入<code>plot(t,y1)</code>，并回车，就出现了这个图：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575433328341.png" alt="enter description here"></p><p>横轴是{% raw %}$t${% endraw %}变量，纵轴是{% raw %}$y1${% endraw %}，也就是我们刚刚所输出的正弦函数。</p><p>让我们设置{% raw %}$y2${% endraw %}</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2d32a23ab895a8e765caf90a7679817e.png" alt="2d32a23ab895a8e765caf90a7679817e"><br><strong>Octave</strong>将会消除之前的正弦图，并且用这个余弦图来代替它，这里纵轴{% raw %}$cos(x)${% endraw %}从1开始，</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/38969cc85853190ff3eac4f06398bc1b.png" alt="38969cc85853190ff3eac4f06398bc1b"><br>如果我要同时表示正弦和余弦曲线。</p><p>我要做的就是，输入：<code>plot(t, y1)</code>，得到正弦函数，我使用函数<strong>hold on</strong>，<strong>hold on</strong>函数的功能是将新的图像绘制在旧的之上。</p><p>我现在绘制{% raw %}$y2${% endraw %}，输入：<code>plot(t, y2)</code>。</p><p>我要以不同的颜色绘制余弦函数，所以我在这里输入带引号的r绘制余弦函数，{% raw %}$r${% endraw %}表示所使用的颜色：<code>plot(t,y2,’r’)</code>，再加上命令<code>xlabel(&#39;time&#39;)</code>，<br>来标记X轴即水平轴，输入<code>ylabel(&#39;value&#39;)</code>，来标记垂直轴的值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9eb4e496f34a801fd7ba5e85c4eec66b.png" alt="9eb4e496f34a801fd7ba5e85c4eec66b"><br>同时我也可以来标记我的两条函数曲线，用这个命令 <code>legend(&#39;sin&#39;,&#39;cos&#39;)</code>将这个图例放在右上方，表示这两条曲线表示的内容。最后输入<code>title(&#39;myplot&#39;)</code>，在图像的顶部显示这幅图的标题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/23594175efe66d5b9b1e687375a2dbda.png" alt="23594175efe66d5b9b1e687375a2dbda"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c765aeee9c53e0e77d01d1e73cabd9b4.png" alt="c765aeee9c53e0e77d01d1e73cabd9b4"><br>如果你想保存这幅图像，你输入<code>print –dpng &#39;myplot.png&#39;</code>，<strong>png</strong>是一个图像文件格式，如果你这样做了，它可以让你保存为一个文件。</p><p><strong>Octave</strong>也可以保存为很多其他的格式，你可以键入<code>help plot</code>。</p><p>最后如果你想，删掉这个图像，用命令<strong>close</strong>会让这个图像关掉。</p><p><strong>Octave</strong>也可以让你为图像标号</p><p>你键入<code>figure(1); plot(t, y1);</code>将显示第一张图，绘制了变量{% raw %}$t${% endraw %} {% raw %}$y1${% endraw %}。</p><p>键入<code>figure(2); plot(t, y2);</code> 将显示第一张图，绘制了变量{% raw %}$t${% endraw %} {% raw %}$y2${% endraw %}。</p><p><strong>subplot</strong>命令，我们要使用<code>subplot(1,2,1)</code>，它将图像分为一个1*2的格子，也就是前两个参数，然后它使用第一个格子，也就是最后一个参数1的意思。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a786b8ed82ddd182f4595de2173cc84b.png" alt="a786b8ed82ddd182f4595de2173cc84b"><br>我现在使用第一个格子，如果键入<code>plot(t,y1)</code>，现在这个图显示在第一个格子。如果我键入<code>subplot(1,2,2)</code>，那么我就要使用第二个格子，键入<code>plot(t,y2)</code>；现在y2显示在右边，也就是第二个格子。</p><p>最后一个命令，你可以改变轴的刻度，比如改成[0.5 1 -1 1]，输入命令：<code>axis([0.5 1 -1 1])</code>也就是设置了右边图的{% raw %}$x${% endraw %}轴和{% raw %}$y${% endraw %}轴的范围。具体而言，它将右图中的横轴的范围调整至0.5到1，竖轴的范围为-1到1。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f13993f4784d01e7da769b4ec2545cd7.png" alt="f13993f4784d01e7da769b4ec2545cd7"><br>你不需要记住所有这些命令，如果你需要改变坐标轴，或者需要知道<strong>axis</strong>命令，你可以用<strong>Octave</strong>中用<strong>help</strong>命令了解细节。</p><p>最后，还有几个命令。</p><p><code>Clf</code>（清除一幅图像）。</p><p>让我们设置A等于一个5×5的<strong>magic</strong>方阵：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/82a990a5832ae2618d768551b90470dc.png" alt="82a990a5832ae2618d768551b90470dc"><br>我有时用一个巧妙的方法来可视化矩阵，也就是<code>imagesc(A</code>)命令，它将会绘制一个5*5的矩阵，一个5*5的彩色格图，不同的颜色对应A矩阵中的不同值。</p><p>我还可以使用函数<strong>colorbar</strong>，让我用一个更复杂的命令 <code>imagesc(A)，colorbar，colormap gray</code>。这实际上是在同一时间运行三个命令：运行<code>imagesc</code>，然后运行，<code>colorbar</code>，然后运行<code>colormap gray</code>。</p><p>它生成了一个颜色图像，一个灰度分布图，并在右边也加入一个颜色条。所以这个颜色条显示不同深浅的颜色所对应的值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/881986ec5af9d86b6b14b260fb3b3618.png" alt="881986ec5af9d86b6b14b260fb3b3618"><br>你可以看到在不同的方格，它对应于一个不同的灰度。</p><p>输入<code>imagesc(magic(15))，colorbar，colormap gray</code></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/22a9a9536d4db17b6d64603fb54dce9e.png" alt="22a9a9536d4db17b6d64603fb54dce9e"><br>这将会是一幅15*15的<strong>magic</strong>方阵值的图。</p><p>最后，总结一下这段视频。你看到我所做的是使用逗号连接函数调用。如果我键入{% raw %}$a=1${% endraw %},{% raw %}$b=2${% endraw %},{% raw %}$c=3${% endraw %}然后按<strong>Enter</strong>键，其实这是将这三个命令同时执行，或者是将三个命令一个接一个执行，它将输出所有这三个结果。</p><p>这很像{% raw %}$a=1${% endraw %}; {% raw %}$b=2${% endraw %};{% raw %}$c=3${% endraw %};如果我用分号来代替逗号，则没有输出出任何东西。</p><p>这里我们称之为逗号连接的命令或函数调用。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c0e8b7a19ced9a1dd006ed87d6323c9b.png" alt="c0e8b7a19ced9a1dd006ed87d6323c9b"><br>用逗号连接是另一种<strong>Octave</strong>中更便捷的方式，将多条命令例如<code>imagesc colorbar colormap</code>，将这多条命令写在同一行中。</p><p>现在你知道如何绘制<strong>Octave</strong>中不同的图像，在下面的视频中，我将告诉你怎样在Octave中，写控制语句，比如<strong>if while for</strong>语句，并且定义和使用函数。</p><h3 id="控制语句：for，while，if语句-1"><a href="#控制语句：for，while，if语句-1" class="headerlink" title="控制语句：for，while，if语句"></a>控制语句：for，while，if语句</h3><p>参考视频: 5 - 5 - Control Statements_ for, while, if statements (13 min).mkv</p><p>在这段视频中，我想告诉你怎样为你的 <strong>Octave</strong> 程序写控制语句。诸如：”<strong>for</strong>“ “<strong>while</strong>“ “<strong>if</strong>“ 这些语句，并且如何定义和使用方程。</p><p>我先告诉你如何使用 “<strong>for</strong>” 循环。</p><p>首先，我要将 {% raw %}$v${% endraw %} 值设为一个10行1列的零向量。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/26a912d550af9fd43a7ae62e3b610e97.png" alt="26a912d550af9fd43a7ae62e3b610e97"><br>接着我要写一个 “<strong>for</strong>“ 循环，让 {% raw %}$i${% endraw %} 等于 1 到 10，写出来就是 <code>i = 1:10</code>。我要设{% raw %}$ v(i)${% endraw %}的值等于 2 的 {% raw %}$i${% endraw %} 次方，循环最后写上“<strong>end</strong>”。</p><p>向量{% raw %}$v${% endraw %} 的值就是这样一个集合 2的一次方、2的二次方，依此类推。这就是我的 {% raw %}$i${% endraw %} 等于 1 到 10的语句结构，让 {% raw %}$i${% endraw %} 遍历 1 到 10的值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/890f6ea8f857f22002f98c20d52b3bb8.png" alt="890f6ea8f857f22002f98c20d52b3bb8"><br>另外，你还可以通过设置你的 indices (索引) 等于 1一直到10，来做到这一点。这时<strong>indices</strong> 就是一个从1到10的序列。</p><p>你也可以写 <code>i = indices</code>，这实际上和我直接把 i 写到 1 到 10 是一样。你可以写 <code>disp(i)</code>，也能得到一样的结果。所以 这就是一个 “<strong>for</strong>” 循环。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fc956ae1291dc7d3b819e471d1962398.png" alt="fc956ae1291dc7d3b819e471d1962398"><br>如果你对 “<strong>break</strong>” 和 “<strong>continue</strong>” 语句比较熟悉，<strong>Octave</strong>里也有 “<strong>break</strong>” 和 “<strong>continue</strong>”语句，你也可以在 <strong>Octave</strong>环境里使用那些循环语句。</p><p>但是首先让我告诉你一个 <strong>while</strong> 循环是如何工作的：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1b37f81896a59145576ae996c9dd4d16.png" alt="1b37f81896a59145576ae996c9dd4d16"><br>这是什么意思呢：我让 {% raw %}$i${% endraw %} 取值从 1 开始，然后我要让 {% raw %}$v(i)${% endraw %} 等于 100，再让 {% raw %}$i${% endraw %} 递增 1，直到{% raw %}$i${% endraw %} 大于 5停止。</p><p>现在来看一下结果，我现在已经取出了向量的前五个元素，把他们用100覆盖掉，这就是一个<strong>while</strong>循环的句法结构。</p><p>现在我们来分析另外一个例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/279cfbda6b4d9a2ced1332f086db4d9e.png" alt="279cfbda6b4d9a2ced1332f086db4d9e"><br>这里我将向你展示如何使用<strong>break</strong>语句。比方说 <code>v(i) = 999</code>，然后让 <code>i = i+1</code>，当 {% raw %}$i${% endraw %} 等于6的时候 <strong>break</strong> (停止循环)，结束 (<strong>end</strong>)。</p><p>当然这也是我们第一次使用一个 <strong>if</strong> 语句，所以我希望你们可以理解这个逻辑，让 {% raw %}$i${% endraw %} 等于1 然后开始下面的增量循环，<strong>while</strong>语句重复设置 {% raw %}$v(i)${% endraw %} 等于999，不断让{% raw %}$i${% endraw %}增加，然后当 {% raw %}$i${% endraw %} 达到6，做一个中止循环的命令，尽管有<strong>while</strong>循环，语句也就此中止。所以最后的结果是取出向量 {% raw %}$v${% endraw %} 的前5个元素，并且把它们设置为999。</p><p>所以，这就是<strong>if</strong> 语句和 <strong>while</strong> 语句的句法结构。并且要注意要有<strong>end</strong>，上面的例子里第一个 <strong>end</strong> 结束的是 <strong>if</strong><br>语句，第二个 <strong>end</strong> 结束的是 <strong>while</strong> 语句。</p><p>现在让我告诉你使用 <strong>if-else</strong> 语句：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3fce4367c960bb6fbc492a3b8f9ddc5d.png" alt="3fce4367c960bb6fbc492a3b8f9ddc5d"><br>最后，提醒一件事：如果你需要退出 <strong>Octave</strong>，你可以键入<code>exit</code>命令然后回车就会退出 <strong>Octave</strong>，或者命令<code>quit</code>也可以。</p><p>最后，让我们来说说函数 (<strong>functions</strong>)，如何定义和调用函数。</p><p>我在桌面上存了一个预先定义的文件名为 “<strong>squarethisnumber.m</strong>”，这就是在 <strong>Octave</strong> 环境下定义的函数。</p><p>让我们打开这个文件。请注意，我使用的是微软的写字板程序来打开这个文件，我只是想建议你，如果你也使用微软的<strong>Windows</strong>系统，那么可以使用写字板程序，而不是记事本来打开这些文件。如果你有别的什么文本编辑器也可以，记事本有时会把代码的间距弄得很乱。如果你只有记事本程序，那也能用。我建议你用写字板或者其他可以编辑函数的文本编辑器。</p><p>现在我们来说如何在 <strong>Octave</strong> 里定义函数：</p><p>这个文件只有三行：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/247f96f4e7ab7a259ac9ef1eebe0b503.png" alt="247f96f4e7ab7a259ac9ef1eebe0b503"><br>第一行写着 <code>function y = squareThisNumber(x)</code>，这就告诉 <strong>Octave</strong>，我想返回一个 y值，我想返回一个值，并且返回的这个值将被存放于变量 {% raw %}$y${% endraw %} 里。另外，它告诉了<strong>Octave</strong>这个函数有一个参数，就是参数 {% raw %}$x${% endraw %}，还有定义的函数体，也就是 {% raw %}$y${% endraw %} 等于 {% raw %}$x${% endraw %} 的平方。</p><p>还有一种更高级的功能，这只是对那些知道“<strong>search path</strong> (<strong>搜索路径</strong>)”这个术语的人使用的。所以如果你想要修改<br><strong>Octave</strong>的搜索路径，你可以把下面这部分作为一个进阶知识，或者选学材料，仅适用于那些熟悉编程语言中搜索路径概念的同学。</p><p>你可以使用<strong>addpath</strong> 命令添加路径，添加路径“<strong>C:\Users\ang\desktop</strong>”将该目录添加到<strong>Octav</strong>e的搜索路径，这样即使你跑到其他路径底下，<strong>Octave</strong>依然知道会在 <strong>Users\ang\desktop</strong>目录下寻找函数。这样，即使我现在在不同的目录下，它仍然知道在哪里可以找到“<strong>SquareThisNumber</strong>” 这个函数。</p><p>但是，如果你不熟悉搜索路径的概念，不用担心，只要确保在执行函数之前，先用 <code>cd</code>命令设置到你函数所在的目录下，实际上也是一样的效果。</p><p><strong>Octave</strong>还有一个其他许多编程语言都没有的概念，那就是它可以允许你定义一个函数，使得返回值是多个值或多个参数。这里就是一个例子，定义一个函数叫：</p><p>“<code>SquareAndCubeThisNumber(x)</code>” ({% raw %}$x${% endraw %}的平方以及{% raw %}$x${% endraw %}的立方)</p><p>这说的就是函数返回值是两个： {% raw %}$y1${% endraw %} 和 {% raw %}$y2${% endraw %}，接下来就是{% raw %}$y1${% endraw %}是被平方后的结果，{% raw %}$y2${% endraw %}是被立方后的结果，这就是说，函数会真的返回2个值。</p><p>有些同学可能会根据你使用的编程语言，比如你们可能熟悉的<strong>C</strong>或<strong>C++</strong>，通常情况下，认为作为函数返回值只能是一个值，但<strong>Octave</strong> 的语法结构就不一样，可以返回多个值。</p><p>如果我键入 <code>[a,b] = SquareAndCubeThisNumber(5)</code>，然后，{% raw %}$a${% endraw %}就等于25，{% raw %}$b${% endraw %} 就等于5的立方125。</p><p>所以说如果你需要定义一个函数并且返回多个值，这一点常常会带来很多方便。</p><p>最后，我来给大家演示一下一个更复杂一点的函数的例子。</p><p>比方说，我有一个数据集，像这样，数据点为[1,1], [2,2],[3,3]，我想做的事是定义一个 <strong>Octave</strong> 函数来计算代价函数 {% raw %}$J(\theta)${% endraw %}，就是计算不同 {% raw %}$\theta${% endraw %}值所对应的代价函数值{% raw %}$J${% endraw %}。</p><p>首先让我们把数据放到 <strong>Octave</strong> 里，我把我的矩阵设置为<code>X = [1 1; 1 2; 1 3];</code></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3c857152ef3f0d6b374e4863289d1c60.png" alt="3c857152ef3f0d6b374e4863289d1c60"><br>请仔细看一下这个函数的定义，确保你明白了定义中的每一步。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e01d6da07890e32d46d0616741a3fe64.png" alt="e01d6da07890e32d46d0616741a3fe64"><br>现在当我在 <strong>Octave</strong> 里运行时，我键入 <code>J = costFunctionJ (X, y, theta)</code>，它就计算出 {% raw %}$J${% endraw %}等于0，这是因为如果我的数据集{% raw %}$x${% endraw %} 为 [1;2;3]， {% raw %}$y${% endraw %} 也为 [1;2;3] 然后设置 {% raw %}$\theta_0${% endraw %} 等于0，{% raw %}$\theta_1${% endraw %}等于1，这给了我恰好45度的斜线，这条线是可以完美拟合我的数据集的。</p><p>而相反地，如果我设置{% raw %}$\theta${% endraw %} 等于[0;0]，那么这个假设就是0是所有的预测值，和刚才一样，设置{% raw %}$\theta_0${% endraw %} = 0，{% raw %}$\theta_1${% endraw %}也等于0，然后我计算的代价函数，结果是2.333。实际上，他就等于1的平方，也就是第一个样本的平方误差，加上2的平方，加上3的平方，然后除以{% raw %}$2m${% endraw %}，也就是训练样本数的两倍，这就是2.33。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/885b5d19c33f545292ccc1b69976c789.png" alt="885b5d19c33f545292ccc1b69976c789"><br>因此这也反过来验证了我们这里的函数，计算出了正确的代价函数。这些就是我们用简单的训练样本尝试的几次试验，这也可以作为我们对定义的代价函数{% raw %}$J${% endraw %}进行了完整性检查。确实是可以计算出正确的代价函数的。至少基于这里的 {% raw %}$x${% endraw %}和 {% raw %}$y${% endraw %}是成立的。也就是我们这几个简单的训练集，至少是成立的。</p><p>现在你知道如何在 <strong>Octave</strong> 环境下写出正确的控制语句，比如 <strong>for 循环</strong>、<strong>while 循环</strong>和 <strong>if语句</strong>，以及如何定义和使用函数。</p><p>在接下来的<strong>Octave</strong> 教程视频里，我会讲解一下向量化，这是一种可以使你的 <strong>Octave</strong>程序运行非常快的思想。</p><h3 id="向量化-1"><a href="#向量化-1" class="headerlink" title="向量化"></a>向量化</h3><p>参考视频: 5 - 6 - Vectorization (14 min).mkv</p><p>在这段视频中，我将介绍有关向量化的内容，无论你是用<strong>Octave</strong>，还是别的语言，比如<strong>MATLAB</strong>或者你正在用<strong>Python</strong>、<strong>NumPy</strong> 或 <strong>Java C C++</strong>，所有这些语言都具有各种线性代数库，这些库文件都是内置的，容易阅读和获取，他们通常写得很好，已经经过高度优化，通常是数值计算方面的博士或者专业人士开发的。</p><p>而当你实现机器学习算法时，如果你能好好利用这些线性代数库，或者数值线性代数库，并联合调用它们，而不是自己去做那些函数库可以做的事情。如果是这样的话，那么通常你会发现：首先，这样更有效，也就是说运行速度更快，并且更好地利用你的计算机里可能有的一些并行硬件系统等等；其次，这也意味着你可以用更少的代码来实现你需要的功能。因此，实现的方式更简单，代码出现问题的有可能性也就越小。</p><p>举个具体的例子：与其自己写代码做矩阵乘法。如果你只在<strong>Octave</strong>中输入{% raw %}$a${% endraw %}乘以{% raw %}$b${% endraw %}就是一个非常有效的两个矩阵相乘的程序。有很多例子可以说明，如果你用合适的向量化方法来实现，你就会有一个简单得多，也有效得多的代码。</p><p>让我们来看一些例子：这是一个常见的线性回归假设函数：{% raw %}${ {h}_{\theta } }(x)=\sum\limits_{j=0}^{n}{ {{\theta }_{j} }{ {x}_{j} }}${% endraw %}</p><p>如果你想要计算{% raw %}$h_\theta(x)${% endraw %} ，注意到右边是求和，那么你可以自己计算{% raw %}$j = 0${% endraw %} 到{% raw %}$ j = n${% endraw %} 的和。但换另一种方式来想想，把 {% raw %}$h_\theta(x)${% endraw %} 看作{% raw %}$\theta^Tx${% endraw %}，那么你就可以写成两个向量的内积，其中{% raw %}$\theta${% endraw %}就是{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}，如果你有两个特征量，如果 {% raw %}$n = 2${% endraw %}，并且如果你把 {% raw %}$x${% endraw %} 看作{% raw %}$x_0${% endraw %}、{% raw %}$x_1${% endraw %}、{% raw %}$x_2${% endraw %}，这两种思考角度，会给你两种不同的实现方式。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7fefb92d8680e4a15f947cd2ca24a9ac.png" alt="7fefb92d8680e4a15f947cd2ca24a9ac"><br>比如说，这是未向量化的代码实现方式：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/125c07019cb39675085fe3b80b85fca5.png" alt="125c07019cb39675085fe3b80b85fca5"><br>计算{% raw %}$h_\theta(x)${% endraw %}是未向量化的，我们可能首先要初始化变量 {% raw %}$prediction${% endraw %} 的值为0.0，而这个变量{% raw %}$prediction${% endraw %} 的最终结果就是{% raw %}$h_\theta(x)${% endraw %}，然后我要用一个 <strong>for</strong> 循环，{% raw %}$j${% endraw %} 取值 0 到{% raw %}$n+1${% endraw %}，变量{% raw %}$prediction${% endraw %} 每次就通过自身加上{% raw %}$ theta(j) ${% endraw %}乘以 {% raw %}$x(j)${% endraw %}更新值，这个就是算法的代码实现。</p><p>顺便我要提醒一下，这里的向量我用的下标是0，所以我有{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}，但因为<strong>MATLAB</strong>的下标从1开始，在 <strong>MATLAB</strong> 中{% raw %}$\theta_0${% endraw %}，我们可能会用 {% raw %}$theta(1)${% endraw %} 来表示，这第二个元素最后就会变成，{% raw %}$theta(2${% endraw %}) 而第三个元素，最终可能就用{% raw %}$theta(3)${% endraw %}表示，因为<strong>MATLAB</strong>中的下标从1开始，这就是为什么这里我的 <strong>for 循环</strong>，{% raw %}$j${% endraw %}取值从 1 直到{% raw %}$n+1${% endraw %}，而不是从 0 到 {% raw %}$n${% endraw %}。这是一个未向量化的代码实现方式，我们用一个 <strong>for 循环</strong>对 {% raw %}$n${% endraw %} 个元素进行加和。</p><p>作为比较，接下来是向量化的代码实现：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/829e153c119919f80c058d1bc703a08b.png" alt="829e153c119919f80c058d1bc703a08b"><br>你把x和{% raw %}$\theta${% endraw %}看做向量，而你只需要令变量{% raw %}$prediction${% endraw %}等于{% raw %}$theta${% endraw %}转置乘以{% raw %}$x${% endraw %}，你就可以这样计算。与其写所有这些for循环的代码，你只需要一行代码，这行代码就是利用 <strong>Octave</strong> 的高度优化的数值，线性代数算法来计算两个向量{% raw %}$\theta${% endraw %}以及{% raw %}$x${% endraw %}的内积，这样向量化的实现更简单，它运行起来也将更加高效。这就是 <strong>Octave</strong> 所做的而向量化的方法，在其他编程语言中同样可以实现。</p><p>让我们来看一个<strong>C++</strong> 的例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/987fc9372da3b167fd16d7a19722405b.png" alt="987fc9372da3b167fd16d7a19722405b"><br>与此相反，使用较好的<strong>C++</strong> 数值线性代数库，你可以写出像右边这样的代码，因此取决于你的数值线性代数库的内容。你只需要在<strong>C++</strong> 中将两个向量相乘，根据你所使用的数值和线性代数库的使用细节的不同，你最终使用的代码表达方式可能会有些许不同，但是通过一个库来做内积，你可以得到一段更简单、更有效的代码。</p><p>现在，让我们来看一个更为复杂的例子，这是线性回归算法梯度下降的更新规则：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6ad266a30f955db5b905905670aabfc5.png" alt="6ad266a30f955db5b905905670aabfc5"><br>我们用这条规则对{% raw %}$ j${% endraw %} 等于 0、1、2等等的所有值，更新对象{% raw %}$\theta_j${% endraw %}，我只是用{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}来写方程，假设我们有两个特征量，所以{% raw %}$n${% endraw %}等于2，这些都是我们需要对{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}进行更新，这些都应该是同步更新，我们用一个向量化的代码实现，这里是和之前相同的三个方程，只不过写得小一点而已。</p><p>你可以想象实现这三个方程的方式之一，就是用一个 <strong>for 循环</strong>，就是让 {% raw %}$j${% endraw %}等于0、等于1、等于2，来更新{% raw %}$\theta_j${% endraw %}。但让我们用向量化的方式来实现，看看我们是否能够有一个更简单的方法。基本上用三行代码或者一个<strong>for 循环</strong>，一次实现这三个方程。让我们来看看怎样能用这三步，并将它们压缩成一行向量化的代码来实现。做法如下：</p><p>我打算把{% raw %}$\theta${% endraw %}看做一个向量，然后我用{% raw %}$\theta${% endraw %}-{% raw %}$\alpha${% endraw %} 乘以某个别的向量{% raw %}$\delta${% endraw %} 来更新{% raw %}$\theta${% endraw %}。</p><p>这里的 {% raw %}$\delta${% endraw %} 等于</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fa662ec6d5703d85c314f5e4792a7468.png" alt="fa662ec6d5703d85c314f5e4792a7468"><br>让我解释一下是怎么回事：我要把{% raw %}$\theta${% endraw %}看作一个向量，有一个 {% raw %}$n+1${% endraw %} 维向量，{% raw %}$\alpha${% endraw %} 是一个实数，{% raw %}$\delta${% endraw %}在这里是一个向量。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20bc912bae44e66125f8bfcec6e720c7.png" alt="20bc912bae44e66125f8bfcec6e720c7"><br>所以这个减法运算是一个向量减法，因为 {% raw %}$\alpha${% endraw %} 乘以 δ是一个向量，所以{% raw %}$\theta${% endraw %}就是{% raw %}$\theta${% endraw %} - {% raw %}$\alpha \delta${% endraw %}得到的向量。</p><p>那么什么是向量 {% raw %}$\delta${% endraw %} 呢 ?</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/541b9f097a8e1357c2a75e4f64e53b54.png" alt="541b9f097a8e1357c2a75e4f64e53b54"></p> {% raw %}$X^{(i)}${% endraw %}是一个向量<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0a03d239f2f1d1af057d492bcce276f4.png" alt="0a03d239f2f1d1af057d492bcce276f4"><br>你就会得到这些不同的式子，然后作加和。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8d10103bf172a889090690a00037ffa1.png" alt="8d10103bf172a889090690a00037ffa1"><br>实际上，在以前的一个小测验，如果你要解这个方程，我们说过为了向量化这段代码，我们会令<code>u = 2v +5w</code>因此，我们说向量{% raw %}$u${% endraw %}等于2乘以向量{% raw %}$v${% endraw %}加上5乘以向量{% raw %}$w${% endraw %}。用这个例子说明，如何对不同的向量进行相加，这里的求和是同样的道理。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c84012101afc6836a3396893695d9669.png" alt="c84012101afc6836a3396893695d9669"><br>这就是为什么我们能够向量化地实现线性回归。</p><p>所以，我希望步骤是有逻辑的。请务必看视频，并且保证你确实能理解它。如果你实在不能理解它们数学上等价的原因，你就直接实现这个算法，也是能得到正确答案的。所以即使你没有完全理解为何是等价的，如果只是实现这种算法，你仍然能实现线性回归算法。如果你能弄清楚为什么这两个步骤是等价的，那我希望你可以对向量化有一个更好的理解，如果你在实现线性回归的时候，使用一个或两个以上的特征量。</p><p>有时我们使用几十或几百个特征量来计算线性归回，当你使用向量化地实现线性回归，通常运行速度就会比你以前用你的<strong>for循环</strong>快的多，也就是自己写代码更新{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}。</p><p>因此使用向量化实现方式，你应该是能够得到一个高效得多的线性回归算法。而当你向量化我们将在之后的课程里面学到的算法，这会是一个很好的技巧，无论是对于Octave 或者一些其他的语言 如C++、Java 来让你的代码运行得更高效。</p><h2 id="逻辑回归-Logistic-Regression-1"><a href="#逻辑回归-Logistic-Regression-1" class="headerlink" title="逻辑回归(Logistic Regression)"></a>逻辑回归(Logistic Regression)</h2><h3 id="分类问题-1"><a href="#分类问题-1" class="headerlink" title="分类问题"></a>分类问题</h3><p>参考文档: 6 - 1 - Classification (8 min).mkv</p><p>在这个以及接下来的几个视频中，开始介绍分类问题。</p><p>在分类问题中，你要预测的变量 {% raw %}$y${% endraw %} 是离散的值，我们将学习一种叫做逻辑回归 (<strong>Logistic Regression</strong>) 的算法，这是目前最流行使用最广泛的一种学习算法。</p><p>在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；之前我们也谈到了肿瘤分类问题的例子，区别一个肿瘤是恶性的还是良性的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a77886a6eff0f20f9d909975bb69a7ab.png" alt="a77886a6eff0f20f9d909975bb69a7ab"><br>我们从二元的分类问题开始讨论。</p><p>我们将因变量(<strong>dependent variable</strong>)可能属于的两个类分别称为负向类（<strong>negative class</strong>）和正向类（<strong>positive class</strong>），则因变量{% raw %}$y\in { 0,1 \\}${% endraw %} ，其中 0 表示负向类，1 表示正向类。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1575441014185.png" alt="enter description here"></p><p>如果我们要用线性回归算法来解决一个分类问题，对于分类， {% raw %}$y${% endraw %} 取值为 0 或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于 1，或者远小于0，即使所有训练样本的标签 {% raw %}$y${% endraw %} 都等于 0 或 1。尽管我们知道标签应该取值0 或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到 1 之间。</p><p>顺便说一下，逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上是一种分类算法，它适用于标签 {% raw %}$y${% endraw %} 取值离散的情况，如：1 0 0 1。</p><p>在接下来的视频中，我们将开始学习逻辑回归算法的细节。</p><h3 id="假说表示-1"><a href="#假说表示-1" class="headerlink" title="假说表示"></a>假说表示</h3><p>参考视频: 6 - 2 - Hypothesis Representation (7 min).mkv</p><p>在这段视频中，我要给你展示假设函数的表达式，也就是说，在分类问题中，要用什么样的函数来表示我们的假设。此前我们说过，希望我们的分类器的输出值在0和1之间，因此，我们希望想出一个满足某个性质的假设函数，这个性质是它的预测值要在0和1之间。</p><p>回顾在一开始提到的乳腺癌分类问题，我们可以用线性回归的方法求出适合数据的一条直线：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/29c12ee079c079c6408ee032870b2683.jpg" alt="29c12ee079c079c6408ee032870b2683"><br>根据线性回归模型我们只能预测连续的值，然而对于分类问题，我们需要输出0或1，我们可以预测：</p><p>当{% raw %}${h_\theta}\left( x \right)>=0.5${% endraw %}时，预测 {% raw %}$y=1${% endraw %}。</p><p>当{% raw %}${h_\theta}\left( x \right)&lt;0.5${% endraw %}时，预测 {% raw %}$y=0${% endraw %} 。</p><p>对于上图所示的数据，这样的一个线性模型似乎能很好地完成分类任务。假使我们又观测到一个非常大尺寸的恶性肿瘤，将其作为实例加入到我们的训练集中来，这将使得我们获得一条新的直线。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d027a0612664ea460247c8637b25e306.jpg" alt="d027a0612664ea460247c8637b25e306"><br>这时，再使用0.5作为阀值来预测肿瘤是良性还是恶性便不合适了。可以看出，线性回归模型，因为其预测的值可以超越[0,1]的范围，并不适合解决这样的问题。</p><p>我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在0和1之间。<br>逻辑回归模型的假设是： {% raw %}$h_\theta \left( x \right)=g\left(\theta^{T}X \right)${% endraw %}<br>其中：</p> {% raw %}$X${% endraw %} 代表特征向量 {% raw %}$g${% endraw %} 代表逻辑函数（**logistic function**)是一个常用的逻辑函数为**S**形函数（**Sigmoid function**），公式为： {% raw %}$g\left( z \right)=\frac{1}{1+{ {e}^{-z} }}${% endraw %}。<p><strong>python</strong>代码实现：</p><pre><code class="python">import numpy as np

def sigmoid(z):

return 1 / (1 + np.exp(-z))</code></pre><p>该函数的图像为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1073efb17b0d053b4f9218d4393246cc.jpg" alt="1073efb17b0d053b4f9218d4393246cc"><br>合起来，我们得到逻辑回归模型的假设：</p><p>对模型的理解： $g\left( z \right)=\frac{1}{1+{ {e}^{-z} }}$。</p> $h_\theta \left( x \right)$的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性（**estimated probablity**）即$h_\theta \left( x \right)=P\left( y=1|x;\theta \right)$<p>例如，如果对于给定的$x$，通过已经确定的参数计算得出$h_\theta \left( x \right)=0.7$，则表示有70%的几率$y$为正向类，相应地$y$为负向类的几率为1-0.7=0.3。</p><h3 id="判定边界-1"><a href="#判定边界-1" class="headerlink" title="判定边界"></a>判定边界</h3><p>参考视频: 6 - 3 - Decision Boundary (15 min).mkv</p><p>现在讲下决策边界(<strong>decision boundary</strong>)的概念。这个概念能更好地帮助我们理解逻辑回归的假设函数在计算什么。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6590923ac94130a979a8ca1d911b68a3.png" alt="6590923ac94130a979a8ca1d911b68a3"><br>在逻辑回归中，我们预测：</p><p>当${h_\theta}\left( x \right)>=0.5$时，预测 $y=1$。</p><p>当${h_\theta}\left( x \right)&lt;0.5$时，预测 $y=0$ 。</p><p>根据上面绘制出的 <strong>S</strong> 形函数图像，我们知道当</p> $z=0$ 时 $g(z)=0.5$ $z>0$ 时 $g(z)>0.5$ $z&lt;0$ 时 $g(z)&lt;0.5$<p>又 $z={\theta^{T} }x$ ，即：</p> ${\theta^{T} }x>=0$ 时，预测 $y=1$ ${\theta^{T} }x&lt;0$ 时，预测 $y=0$<p>现在假设我们有一个模型：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/58d098bbb415f2c3797a63bd870c3b8f.png" alt="58d098bbb415f2c3797a63bd870c3b8f"><br>并且参数$\theta$ 是向量[-3 1 1]。 则当$-3+{x_1}+{x_2} \geq 0$，即${x_1}+{x_2} \geq 3$时，模型将预测 $y=1$。<br>我们可以绘制直线${x_1}+{x_2} = 3$，这条线便是我们模型的分界线，将预测为1的区域和预测为 0的区域分隔开。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f71fb6102e1ceb616314499a027336dc.jpg" alt="f71fb6102e1ceb616314499a027336dc"><br>假使我们的数据呈现这样的分布情况，怎样的模型才能适合呢？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/197d605aa74bee1556720ea248bab182.jpg" alt="197d605aa74bee1556720ea248bab182"><br>因为需要用曲线才能分隔 $y=0$ 的区域和 $y=1$ 的区域，我们需要二次方特征：${h_\theta}\left( x \right)=g\left( {\theta_0}+{\theta_1}{x_1}+{\theta_{2} }{x_{2} }+{\theta_{3} }x_{1}^{2}+{\theta_{4} }x_{2}^{2} \right)$是[-1 0 0 1 1]，则我们得到的判定边界恰好是圆点在原点且半径为1的圆形。</p><p>我们可以用非常复杂的模型来适应非常复杂形状的判定边界。</p><h3 id="代价函数-5"><a href="#代价函数-5" class="headerlink" title="代价函数"></a>代价函数</h3><p>参考视频: 6 - 4 - Cost Function (11 min).mkv</p><p>在这段视频中，我们要介绍如何拟合逻辑回归模型的参数$\theta$。具体来说，我要定义用来拟合参数的优化目标或者叫代价函数，这便是监督学习问题中的逻辑回归模型的拟合问题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f23eebddd70122ef05baa682f4d6bd0f.png" alt="f23eebddd70122ef05baa682f4d6bd0f"><br>对于线性回归模型，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将${h_\theta}\left( x \right)=\frac{1}{1+{e^{-\theta^{T}x} }}$带入到这样定义了的代价函数中时，我们得到的代价函数将是一个非凸函数（<strong>non-convexfunction</strong>）。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8b94e47b7630ac2b0bcb10d204513810.jpg" alt="8b94e47b7630ac2b0bcb10d204513810"><br>这意味着我们的代价函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。</p><p><strong>线性回归的代价函数</strong>为：$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{1}{2}{ {\left( {h_\theta}\left({x}^{\left( i \right)} \right)-{y}^{\left( i \right)} \right)}^{2} }}$ 。<br>我们<strong>重新定义逻辑回归的代价函数</strong>为：$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{ {Cost}\left( {h_\theta}\left( {x}^{\left( i \right)} \right),{y}^{\left( i \right)} \right)}$，其中</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54249cb51f0086fa6a805291bf2639f1.png" alt="54249cb51f0086fa6a805291bf2639f1"></p> ${h_\theta}\left( x \right)$与 $Cost\left( {h_\theta}\left( x \right),y \right)$之间的关系如下图所示：<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ffa56adcc217800d71afdc3e0df88378.jpg" alt="ffa56adcc217800d71afdc3e0df88378"><br>这样构建的$Cost\left( {h_\theta}\left( x \right),y \right)$函数的特点是：当实际的 $y=1$ 且${h_\theta}\left( x \right)$也为 1 时误差为 0，当 $y=1$ 但${h_\theta}\left( x \right)$不为1时误差随着${h_\theta}\left( x \right)$变小而变大；当实际的 $y=0$ 且${h_\theta}\left( x \right)$也为 0 时代价为 0，当$y=0$ 但${h_\theta}\left( x \right)$不为 0时误差随着 ${h_\theta}\left( x \right)$的变大而变大。<br>将构建的 $Cost\left( {h_\theta}\left( x \right),y \right)$简化如下：</p> $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$<p>带入代价函数得到：</p> $J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$<p>即：$J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$</p><p><strong>Python</strong>代码实现：</p><pre><code class="python">import numpy as np

def cost(theta, X, y):

theta = np.matrix(theta)
X = np.matrix(X)
y = np.matrix(y)
first = np.multiply(-y, np.log(sigmoid(X* theta.T)))
second = np.multiply((1 - y), np.log(1 - sigmoid(X* theta.T)))
return np.sum(first - second) / (len(X))</code></pre><p>在得到这样一个代价函数以后，我们便可以用<strong>梯度下降算法来求得能使代价函数最小的参数</strong>了。算法为：</p><p><strong>Repeat</strong> {</p> $\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j} J(\theta)$<p>(<strong>simultaneously update all</strong> )<br>}</p><p>求导后得到：</p><p><strong>Repeat</strong> {</p> $\theta_j := \theta_j - \alpha \frac{1}{m}\sum\limits_{i=1}^{m}{ {\left( {h_\theta}\left( \mathop{x}^{\left( i \right)} \right)-\mathop{y}^{\left( i \right)} \right)} }\mathop{x}_{j}^{(i)}$<p><strong>(simultaneously update all</strong> )<br>}</p><p>在这个视频中，我们定义了单训练样本的代价函数，凸性分析的内容是超出这门课的范围的，但是可以证明我们所选的代价值函数会给我们一个凸优化问题。代价函数$J(\theta)$会是一个凸函数，并且没有局部最优值。</p><p>推导过程：</p> $J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$<p>考虑：</p> ${h_\theta}\left( { {x}^{(i)} } \right)=\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }}$<p>则：</p> ${ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)$ $={ {y}^{(i)} }\log \left( \frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }} \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }} \right)$ $=-{ {y}^{(i)} }\log \left( 1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} } \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} } \right)$<p>所以：</p> $\frac{\partial }{\partial {\theta_{j} }}J\left( \theta \right)=\frac{\partial }{\partial {\theta_{j} }}[-\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( 1+{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} } \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1+{ {e}^{ {\theta^{T} }{ {x}^{(i)} }} } \right)]}]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\frac{-x_{j}^{(i)}{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} }}{1+{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} }}-\left( 1-{ {y}^{(i)} } \right)\frac{x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }} }]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{ {y}^{(i)} }\frac{x_j^{(i)} }{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}-\left( 1-{ {y}^{(i)} } \right)\frac{x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{ {{y}^{(i)} }x_j^{(i)}-x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }+{ {y}^{(i)} }x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{ {{y}^{(i)} }\left( 1\text{+}{ {e}^{ {\theta^T}{ {x}^{(i)} }} } \right)-{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{({ {y}^{(i)} }-\frac{ {{e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }})x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{({ {y}^{(i)} }-\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }})x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }-{h_\theta}\left( { {x}^{(i)} } \right)]x_j^{(i)} }$ $=\frac{1}{m}\sum\limits_{i=1}^{m}{[{h_\theta}\left( { {x}^{(i)} } \right)-{ {y}^{(i)} }]x_j^{(i)} }$<p>注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。</p><p>一些梯度下降算法之外的选择：<br>除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：<strong>共轭梯度</strong>（<strong>Conjugate Gradient</strong>），<strong>局部优化法</strong>(<strong>Broyden fletcher goldfarb shann,BFGS</strong>)和<strong>有限内存局部优化法</strong>(<strong>LBFGS</strong>) ，<strong>fminunc</strong>是 <strong>matlab</strong>和<strong>octave</strong> 中都带的一个最小值优化函数，使用时我们需要提供代价函数和每个参数的求导，下面是 <strong>octave</strong> 中使用 <strong>fminunc</strong> 函数的代码示例：</p><pre><code class="octave">function [jVal, gradient] = costFunction(theta)

jVal = [...code to compute J(theta)...];
gradient = [...code to compute derivative of J(theta)...];

end

options = optimset(&#39;GradObj&#39;, &#39;on&#39;, &#39;MaxIter&#39;, &#39;100&#39;);

initialTheta = zeros(2,1);

[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);</code></pre><p>在下一个视频中，我们会把单训练样本的代价函数的这些理念进一步发展，然后给出整个训练集的代价函数的定义，我们还会找到一种比我们目前用的更简单的写法，基于这些推导出的结果，我们将应用梯度下降法得到我们的逻辑回归算法。</p><h3 id="简化的成本函数和梯度下降-1"><a href="#简化的成本函数和梯度下降-1" class="headerlink" title="简化的成本函数和梯度下降"></a>简化的成本函数和梯度下降</h3><p>参考视频: 6 - 5 - Simplified Cost Function and Gradient Descent (10 min).mkv</p><p>在这段视频中，我们将会找出一种稍微简单一点的方法来写代价函数，来替换我们现在用的方法。同时我们还要弄清楚如何运用梯度下降法，来拟合出逻辑回归的参数。因此，听了这节课，你就应该知道如何实现一个完整的逻辑回归算法。</p><p>这就是逻辑回归的代价函数：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/eb69baa91c2fc6e7dd8ebdf6c79a6a6f.png" alt="eb69baa91c2fc6e7dd8ebdf6c79a6a6f"><br>这个式子可以合并成：</p> $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$<p>即，逻辑回归的代价函数：</p> $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$<p>根据这个代价函数，为了拟合出参数，该怎么做呢？我们要试图找尽量让$J\left( \theta \right)$ 取得最小值的参数$\theta $。</p> $\underset{\theta}{\min }J\left( \theta \right)$<p>所以我们想要尽量减小这一项，这将我们将得到某个参数$\theta $。<br>如果我们给出一个新的样本，假如某个特征 $x$，我们可以用拟合训练样本的参数$\theta $，来输出对假设的预测。<br>另外，我们假设的输出，实际上就是这个概率值：$p(y=1|x;\theta)$，就是关于 $x$以$\theta $为参数，$y=1$ 的概率，你可以认为我们的假设就是估计 $y=1$ 的概率，所以，接下来就是弄清楚如何最大限度地最小化代价函数$J\left( \theta \right)$，作为一个关于$\theta $的函数，这样我们才能为训练集拟合出参数$\theta $。</p><p>最小化代价函数的方法，是使用<strong>梯度下降法</strong>(<strong>gradient descent</strong>)。这是我们的代价函数：</p> $J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$<p>如果我们要最小化这个关于$\theta$的函数值，这就是我们通常用的梯度下降法的模板。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/171031235527.png" alt="171031235527"><br>我们要反复更新每个参数，用这个式子来更新，就是用它自己减去学习率 $\alpha$<br>乘以后面的微分项。求导后得到：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/171031235719.png" alt="171031235719"></p><p>如果你计算一下的话，你会得到这个等式：</p> ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){x_{j} }^{(i)} }$<p>我把它写在这里，将后面这个式子，在 $i=1$ 到 $m$ 上求和，其实就是预测误差乘以$x_j^{(i)}$ ，所以你把这个偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$放回到原来式子这里，我们就可以将梯度下降算法写作如下形式：</p> ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){x_{j} }^{(i)} }$<p>所以，如果你有 $n$ 个特征，也就是说：<img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0171031235044.png" alt="0171031235044">，参数向量$\theta $包括${\theta_{0} }$ ${\theta_{1} }$ ${\theta_{2} }$ 一直到${\theta_{n} }$，那么你就需要用这个式子：</p> ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){ {x}_{j} }^{(i)} }$来同时更新所有$\theta $的值。<p>现在，如果你把这个更新规则和我们之前用在线性回归上的进行比较的话，你会惊讶地发现，这个式子正是我们用来做线性回归梯度下降的。</p><p>那么，线性回归和逻辑回归是同一个算法吗？要回答这个问题，我们要观察逻辑回归看看发生了哪些变化。实际上，假设的定义发生了变化。</p><p>对于线性回归假设函数：</p> ${h_\theta}\left( x \right)={\theta^T}X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$<p>而现在逻辑函数假设函数：</p> ${h_\theta}\left( x \right)=\frac{1}{1+{ {e}^{-{\theta^T}X} }}$<p>因此，即使更新参数的规则看起来基本相同，但由于假设的定义发生了变化，所以逻辑函数的梯度下降，跟线性回归的梯度下降实际上是两个完全不同的东西。</p><p>在先前的视频中，当我们在谈论线性回归的梯度下降法时，我们谈到了如何监控梯度下降法以确保其收敛，我通常也把同样的方法用在逻辑回归中，来监测梯度下降，以确保它正常收敛。</p><p>当使用梯度下降法来实现逻辑回归时，我们有这些不同的参数$\theta $，就是${\theta_{0} }$ ${\theta_{1} }$ ${\theta_{2} }$ 一直到${\theta_{n} }$，我们需要用这个表达式来更新这些参数。我们还可以使用 <strong>for循环</strong>来更新这些参数值，用 <code>for i=1 to n</code>，或者 <code>for i=1 to n+1</code>。当然，不用 <strong>for循环</strong>也是可以的，理想情况下，我们更提倡使用向量化的实现，可以把所有这些 $n$个参数同时更新。</p><p>最后还有一点，我们之前在谈线性回归时讲到的特征缩放，我们看到了特征缩放是如何提高梯度下降的收敛速度的，这个特征缩放的方法，也适用于逻辑回归。如果你的特征范围差距很大的话，那么应用特征缩放的方法，同样也可以让逻辑回归中，梯度下降收敛更快。</p><p>就是这样，现在你知道如何实现逻辑回归，这是一种非常强大，甚至可能世界上使用最广泛的一种分类算法。</p><h3 id="高级优化-1"><a href="#高级优化-1" class="headerlink" title="高级优化"></a>高级优化</h3><p>参考视频: 6 - 6 - Advanced Optimization (14 min).mkv</p><p>在上一个视频中，我们讨论了用梯度下降的方法最小化逻辑回归中代价函数$J\left( \theta \right)$。在本次视频中，我会教你们一些高级优化算法和一些高级的优化概念，利用这些方法，我们就能够使通过梯度下降，进行逻辑回归的速度大大提高，而这也将使算法更加适合解决大型的机器学习问题，比如，我们有数目庞大的特征量。<br>现在我们换个角度来看什么是梯度下降，我们有个代价函数$J\left( \theta \right)$，而我们想要使其最小化，那么我们需要做的是编写代码，当输入参数 $\theta$ 时，它们会计算出两样东西：$J\left( \theta \right)$ 以及$J$ 等于 0、1直到 $n$ 时的偏导数项。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/394a1d763425c4ecf12f8f98a392067f.png" alt="394a1d763425c4ecf12f8f98a392067f"><br>假设我们已经完成了可以实现这两件事的代码，那么梯度下降所做的就是反复执行这些更新。<br>另一种考虑梯度下降的思路是：我们需要写出代码来计算$J\left( \theta \right)$ 和这些偏导数，然后把这些插入到梯度下降中，然后它就可以为我们最小化这个函数。<br>对于梯度下降来说，我认为从技术上讲，你实际并不需要编写代码来计算代价函数$J\left( \theta \right)$。你只需要编写代码来计算导数项，但是，如果你希望代码还要能够监控这些$J\left( \theta \right)$ 的收敛性，那么我们就需要自己编写代码来计算代价函数$J(\theta)$和偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$。所以，在写完能够计算这两者的代码之后，我们就可以使用梯度下降。<br>然而梯度下降并不是我们可以使用的唯一算法，还有其他一些算法，更高级、更复杂。如果我们能用这些方法来计算代价函数$J\left( \theta \right)$和偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$两个项的话，那么这些算法就是为我们优化代价函数的不同方法，<strong>共轭梯度法 BFGS</strong> (<strong>变尺度法</strong>) 和<strong>L-BFGS</strong> (<strong>限制变尺度法</strong>) 就是其中一些更高级的优化算法，它们需要有一种方法来计算 $J\left( \theta \right)$，以及需要一种方法计算导数项，然后使用比梯度下降更复杂的算法来最小化代价函数。这三种算法的具体细节超出了本门课程的范畴。实际上你最后通常会花费很多天，或几周时间研究这些算法，你可以专门学一门课来提高数值计算能力，不过让我来告诉你他们的一些特性：</p><p>这三种算法有许多优点：</p><p>一个是使用这其中任何一个算法，你通常不需要手动选择学习率 $\alpha$，所以对于这些算法的一种思路是，给出计算导数项和代价函数的方法，你可以认为算法有一个智能的内部循环，而且，事实上，他们确实有一个智能的内部循环，称为<strong>线性搜索</strong>(<strong>line search</strong>)算法，它可以自动尝试不同的学习速率 $\alpha$，并自动选择一个好的学习速率 $a$，因此它甚至可以为每次迭代选择不同的学习速率，那么你就不需要自己选择。这些算法实际上在做更复杂的事情，不仅仅是选择一个好的学习速率，所以它们往往最终比梯度下降收敛得快多了，不过关于它们到底做什么的详细讨论，已经超过了本门课程的范围。</p><p>实际上，我过去使用这些算法已经很长一段时间了，也许超过十年了，使用得相当频繁，而直到几年前我才真正搞清楚<strong>共轭梯度法 BFGS</strong> 和 <strong>L-BFGS</strong>的细节。</p><p>我们实际上完全有可能成功使用这些算法，并应用于许多不同的学习问题，而不需要真正理解这些算法的内环间在做什么，如果说这些算法有缺点的话，那么我想说主要缺点是它们比梯度下降法复杂多了，特别是你最好不要使用 <strong>L-BGFS</strong>、<strong>BFGS</strong>这些算法，除非你是数值计算方面的专家。实际上，我不会建议你们编写自己的代码来计算数据的平方根，或者计算逆矩阵，因为对于这些算法，我还是会建议你直接使用一个软件库，比如说，要求一个平方根，我们所能做的就是调用一些别人已经写好用来计算数字平方根的函数。幸运的是现在我们有<strong>Octave</strong> 和与它密切相关的 <strong>MATLAB</strong> 语言可以使用。</p><p><strong>Octave</strong> 有一个非常理想的库用于实现这些先进的优化算法，所以，如果你直接调用它自带的库，你就能得到不错的结果。我必须指出这些算法实现得好或不好是有区别的，因此，如果你正在你的机器学习程序中使用一种不同的语言，比如如果你正在使用<strong>C</strong>、<strong>C++</strong>、<strong>Java</strong>等等，你可能会想尝试一些不同的库，以确保你找到一个能很好实现这些算法的库。因为在<strong>L-BFGS</strong>或者等高线梯度的实现上，表现得好与不太好是有差别的，因此现在让我们来说明：如何使用这些算法：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/743a769317d584a66509fc394b4e6095.png" alt="743a769317d584a66509fc394b4e6095"><br>比方说，你有一个含两个参数的问题，这两个参数是${\theta_{0} }$和${\theta_{1} }$，因此，通过这个代价函数，你可以得到${\theta_{1} }$和 ${\theta_{2} }$的值，如果你将$J\left( \theta \right)$ 最小化的话，那么它的最小值将是${\theta_{1} }=5$ ，${\theta_{2} }=5$。代价函数$J\left( \theta \right)$的导数推出来就是这两个表达式：</p> $\frac{\partial }{\partial { {\theta }_{1} }}J(\theta)=2({ {\theta }_{1} }-5)$ $\frac{\partial }{\partial { {\theta }_{2} }}J(\theta)=2({ {\theta }_{2} }-5)$<p>如果我们不知道最小值，但你想要代价函数找到这个最小值，是用比如梯度下降这些算法，但最好是用比它更高级的算法，你要做的就是运行一个像这样的<strong>Octave</strong> 函数：</p><pre><code class="octave">function [jVal, gradient]=costFunction(theta)

jVal=(theta(1)-5)^2+(theta(2)-5)^2;

gradient=zeros(2,1);

gradient(1)=2*(theta(1)-5);

gradient(2)=2*(theta(2)-5);

end</code></pre><p>这样就计算出这个代价函数，函数返回的第二个值是梯度值，梯度值应该是一个2×1的向量，梯度向量的两个元素对应这里的两个偏导数项，运行这个<strong>costFunction</strong> 函数后，你就可以调用高级的优化函数，这个函数叫<br><strong>fminunc</strong>，它表示<strong>Octave</strong> 里无约束最小化函数。调用它的方式如下：</p><pre><code class="octave">options=optimset(&#39;GradObj&#39;,&#39;on&#39;,&#39;MaxIter&#39;,100);

initialTheta=zeros(2,1);

[optTheta, functionVal, exitFlag]=fminunc(@costFunction, initialTheta, options);</code></pre><p>你要设置几个<strong>options</strong>，这个 <strong>options</strong> 变量作为一个数据结构可以存储你想要的<strong>options</strong>，所以 <strong>GradObj</strong> 和<strong>On</strong>，这里设置梯度目标参数为打开(<strong>on</strong>)，这意味着你现在确实要给这个算法提供一个梯度，然后设置最大迭代次数，比方说100，我们给出一个$\theta$ 的猜测初始值，它是一个2×1的向量，那么这个命令就调用<strong>fminunc</strong>，这个@符号表示指向我们刚刚定义的<strong>costFunction</strong> 函数的指针。如果你调用它，它就会使用众多高级优化算法中的一个，当然你也可以把它当成梯度下降，只不过它能自动选择学习速率$\alpha$，你不需要自己来做。然后它会尝试使用这些高级的优化算法，就像加强版的梯度下降法，为你找到最佳的${\theta}$值。</p><p>让我告诉你它在 <strong>Octave</strong> 里什么样：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bd074e119a52163691cff93c3f42a1ee.png" alt="bd074e119a52163691cff93c3f42a1ee"><br>所以我写了这个关于<strong>theta</strong>的 <strong>costFunction</strong> 函数，它计算出代价函数 <strong>jval</strong>以及梯度<strong>gradient</strong>，<strong>gradient</strong> 有两个元素，是代价函数对于<strong>theta(1)</strong> 和 <strong>theta(2)</strong>这两个参数的偏导数。</p><p>我希望你们从这个幻灯片中学到的主要内容是：写一个函数，它能返回代价函数值、梯度值，因此要把这个应用到逻辑回归，或者甚至线性回归中，你也可以把这些优化算法用于线性回归，你需要做的就是输入合适的代码来计算这里的这些东西。</p><p>现在你已经知道如何使用这些高级的优化算法，有了这些算法，你就可以使用一个复杂的优化库，它让算法使用起来更模糊一点。因此也许稍微有点难调试，不过由于这些算法的运行速度通常远远超过梯度下降。</p><p>所以当我有一个很大的机器学习问题时，我会选择这些高级算法，而不是梯度下降。有了这些概念，你就应该能将逻辑回归和线性回归应用于更大的问题中，这就是高级优化的概念。</p><p>在下一个视频，我想要告诉你如何修改你已经知道的逻辑回归算法，然后使它在多类别分类问题中也能正常运行。</p><h3 id="多类别分类：一对多-1"><a href="#多类别分类：一对多-1" class="headerlink" title="多类别分类：一对多"></a>多类别分类：一对多</h3><p>参考视频: 6 - 7 - Multiclass Classification_ One-vs-all (6 min).mkv</p><p>在本节视频中，我们将谈到如何使用逻辑回归 (<strong>logistic regression</strong>)来解决多类别分类问题，具体来说，我想通过一个叫做”一对多” (<strong>one-vs-all</strong>) 的分类算法。</p><p>先看这样一些例子。</p><p>第一个例子：假如说你现在需要一个学习算法能自动地将邮件归类到不同的文件夹里，或者说可以自动地加上标签，那么，你也许需要一些不同的文件夹，或者不同的标签来完成这件事，来区分开来自工作的邮件、来自朋友的邮件、来自家人的邮件或者是有关兴趣爱好的邮件，那么，我们就有了这样一个分类问题：其类别有四个，分别用$y=1$、$y=2$、$y=3$、$y=4$ 来代表。</p><p>第二个例子是有关药物诊断的，如果一个病人因为鼻塞来到你的诊所，他可能并没有生病，用 $y=1$ 这个类别来代表；或者患了感冒，用 $y=2$ 来代表；或者得了流感用$y=3$来代表。</p><p>第三个例子：如果你正在做有关天气的机器学习分类问题，那么你可能想要区分哪些天是晴天、多云、雨天、或者下雪天，对上述所有的例子，$y$ 可以取一个很小的数值，一个相对”谨慎”的数值，比如1 到3、1到4或者其它数值，以上说的都是多类分类问题，顺便一提的是，对于下标是0 1 2 3，还是 1 2 3 4 都不重要，我更喜欢将分类从 1 开始标而不是0，其实怎样标注都不会影响最后的结果。</p><p>然而对于之前的一个，二元分类问题，我们的数据看起来可能是像这样：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/68f56679a2113c7857ab9dd2afebcba8.png" alt="68f56679a2113c7857ab9dd2afebcba8"><br>对于一个多类分类问题，我们的数据集或许看起来像这样：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54d7903564b4416305b26f6ff2e13c04.png" alt="54d7903564b4416305b26f6ff2e13c04"><br>我用3种不同的符号来代表3个类别，问题就是给出3个类型的数据集，我们如何得到一个学习算法来进行分类呢？</p><p>我们现在已经知道如何进行二元分类，可以使用逻辑回归，对于直线或许你也知道，可以将数据集一分为二为正类和负类。用一对多的分类思想，我们可以将其用在多类分类问题上。</p><p>下面将介绍如何进行一对多的分类工作，有时这个方法也被称为”一对余”方法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/450a83c67732d254dbac2aeeb8ab910c.png" alt="450a83c67732d254dbac2aeeb8ab910c"><br>现在我们有一个训练集，好比上图表示的有3个类别，我们用三角形表示 $y=1$，方框表示$y=2$，叉叉表示 $y=3$。我们下面要做的就是使用一个训练集，将其分成3个二元分类问题。</p><p>我们先从用三角形代表的类别1开始，实际上我们可以创建一个，新的”伪”训练集，类型2和类型3定为负类，类型1设定为正类，我们创建一个新的训练集，如下图所示的那样，我们要拟合出一个合适的分类器。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b72863ce7f85cd491e5b940924ef5a5f.png" alt="b72863ce7f85cd491e5b940924ef5a5f"><br>这里的三角形是正样本，而圆形代表负样本。可以这样想，设置三角形的值为1，圆形的值为0，下面我们来训练一个标准的逻辑回归分类器，这样我们就得到一个正边界。</p><p>为了能实现这样的转变，我们将多个类中的一个类标记为正向类（$y=1$），然后将其他所有类都标记为负向类，这个模型记作$h_\theta^{\left( 1 \right)}\left( x \right)$。接着，类似地第我们选择另一个类标记为正向类（$y=2$），再将其它类都标记为负向类，将这个模型记作 $h_\theta^{\left( 2 \right)}\left( x \right)$,依此类推。<br>最后我们得到一系列的模型简记为： $h_\theta^{\left( i \right)}\left( x \right)=p\left( y=i|x;\theta \right)$其中：$i=\left( 1,2,3....k \right)$</p><p>最后，在我们需要做预测时，我们将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。</p><p>总之，我们已经把要做的做完了，现在要做的就是训练这个逻辑回归分类器：$h_\theta^{\left( i \right)}\left( x \right)$， 其中 $i$ 对应每一个可能的 $y=i$，最后，为了做出预测，我们给出输入一个新的 $x$ 值，用这个做预测。我们要做的就是在我们三个分类器里面输入 $x$，然后我们选择一个让 $h_\theta^{\left( i \right)}\left( x \right)$ 最大的$ i$，即$\mathop{\max}\limits_i\,h_\theta^{\left( i \right)}\left( x \right)$。</p><p>你现在知道了基本的挑选分类器的方法，选择出哪一个分类器是可信度最高效果最好的，那么就可认为得到一个正确的分类，无论$i$值是多少，我们都有最高的概率值，我们预测$y$就是那个值。这就是多类别分类问题，以及一对多的方法，通过这个小方法，你现在也可以将逻辑回归分类器用在多类分类的问题上。</p><h2 id="正则化-Regularization-1"><a href="#正则化-Regularization-1" class="headerlink" title="正则化(Regularization)"></a>正则化(Regularization)</h2><h3 id="过拟合的问题-1"><a href="#过拟合的问题-1" class="headerlink" title="过拟合的问题"></a>过拟合的问题</h3><p>参考视频: 7 - 1 - The Problem of Overfitting (10 min).mkv</p><p>到现在为止，我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到过拟合(<strong>over-fitting</strong>)的问题，可能会导致它们效果很差。</p><p>在这段视频中，我将为你解释什么是过度拟合问题，并且在此之后接下来的几个视频中，我们将谈论一种称为正则化(<strong>regularization</strong>)的技术，它可以改善或者减少过度拟合问题。</p><p>如果我们有非常多的特征，我们通过学习得到的假设可能能够非常好地适应训练集（代价函数可能几乎为0），但是可能会不能推广到新的数据。</p><p>下图是一个回归问题的例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/72f84165fbf1753cd516e65d5e91c0d3.jpg" alt="72f84165fbf1753cd516e65d5e91c0d3"><br>第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：预测新数据。我们可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎最合适。</p><p>分类问题中也存在这样的问题：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/be39b497588499d671942cc15026e4a2.jpg" alt="be39b497588499d671942cc15026e4a2"><br>就以多项式理解，$x$ 的次数越高，拟合的越好，但相应的预测的能力就可能变差。</p><p>问题是，如果我们发现了过拟合问题，应该如何处理？</p><ol><li><p>丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如<strong>PCA</strong>）</p></li><li><p>正则化。 保留所有的特征，但是减少参数的大小（<strong>magnitude</strong>）。</p></li></ol><h3 id="代价函数-6"><a href="#代价函数-6" class="headerlink" title="代价函数"></a>代价函数</h3><p>参考视频: 7 - 2 - Cost Function (10 min).mkv</p><p>上面的回归问题中如果我们的模型是：</p> ${h_\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}+{\theta_{3} }{x_{3}^3}+{\theta_{4} }{x_{4}^4}$<p>我们可以从之前的事例中看出，正是那些高次项导致了过拟合的产生，所以如果我们能让这些高次项的系数接近于0的话，我们就能很好的拟合了。<br>所以我们要做的就是在一定程度上减小这些参数$\theta $ 的值，这就是正则化的基本方法。我们决定要减少${\theta_{3} }$和${\theta_{4} }$的大小，我们要做的便是修改代价函数，在其中${\theta_{3} }$和${\theta_{4} }$ 设置一点惩罚。这样做的话，我们在尝试最小化代价时也需要将这个惩罚纳入考虑中，并最终导致选择较小一些的${\theta_{3} }$和${\theta_{4} }$。<br>修改后的代价函数如下：$\underset{\theta }{\mathop{\min } }\,\frac{1}{2m}[\sum\limits_{i=1}^{m}{ {{\left( { {h}_{\theta } }\left( { {x}^{(i)} } \right)-{ {y}^{(i)} } \right)}^{2} }+1000\theta _{3}^{2}+10000\theta _{4}^{2}]}$</p><p>通过这样的代价函数选择出的${\theta_{3} }$和${\theta_{4} }$ 对预测结果的影响就比之前要小许多。假如我们有非常多的特征，我们并不知道其中哪些特征我们要惩罚，我们将对所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设：$J\left( \theta \right)=\frac{1}{2m}[\sum\limits_{i=1}^{m}{ {{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })}^{2} }+\lambda \sum\limits_{j=1}^{n}{\theta_{j}^{2} }]}$</p><p>其中$\lambda $又称为正则化参数（<strong>Regularization Parameter</strong>）。 注：根据惯例，我们不对${\theta_{0} }$ 进行惩罚。经过正则化处理的模型与原模型的可能对比如下图所示：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ea76cc5394cf298f2414f230bcded0bd.jpg" alt="ea76cc5394cf298f2414f230bcded0bd"><br>如果选择的正则化参数$\lambda$ 过大，则会把所有的参数都最小化了，导致模型变成 ${h_\theta}\left( x \right)={\theta_{0} }$，也就是上图中红色直线所示的情况，造成欠拟合。<br>那为什么增加的一项$\lambda =\sum\limits_{j=1}^{n}{\theta_j^{2} }$ 可以使$\theta $的值减小呢？<br>因为如果我们令 $\lambda$ 的值很大的话，为了使<strong>Cost Function</strong> 尽可能的小，所有的 $\theta $ 的值（不包括${\theta_{0} }$）都会在一定程度上减小。<br>但若$\lambda$ 的值太大了，那么$\theta $（不包括${\theta_{0} }$）都会趋近于0，这样我们所得到的只能是一条平行于$x$轴的直线。<br>所以对于正则化，我们要取一个合理的 $\lambda$ 的值，这样才能更好的应用正则化。<br>回顾一下代价函数，为了使用正则化，让我们把这些概念应用到到线性回归和逻辑回归中去，那么我们就可以让他们避免过度拟合了。</p><h3 id="正则化线性回归-1"><a href="#正则化线性回归-1" class="headerlink" title="正则化线性回归"></a>正则化线性回归</h3><p>参考视频: 7 - 3 - Regularized Linear Regression (11 min).mkv</p><p>对于线性回归的求解，我们之前推导了两种学习算法：一种基于梯度下降，一种基于正规方程。</p><p>正则化线性回归的代价函数为：</p> $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{[({ {({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })}^{2} }+\lambda \sum\limits_{j=1}^{n}{\theta _{j}^{2} })]}$<p>如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对$\theta_0$进行正则化，所以梯度下降算法将分两种情形：</p> $Repeat$ $until$ $convergence${<p>​ ${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{0}^{(i)} })$</p><p>​ ${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }+\frac{\lambda }{m}{\theta_j}]$</p><p>​ $for$ $j=1,2,...n$</p><p>​ }</p><p>对上面的算法中$ j=1,2,...,n$ 时的更新式子进行调整可得：</p> ${\theta_j}:={\theta_j}(1-a\frac{\lambda }{m})-a\frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }$<p>可以看出，正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令$\theta $值减少了一个额外的值。</p><p>我们同样也可以利用正规方程来求解正则化线性回归模型，方法如下所示：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/71d723ddb5863c943fcd4e6951114ee3.png" alt="71d723ddb5863c943fcd4e6951114ee3"><br>图中的矩阵尺寸为 $(n+1)*(n+1)$。</p><h3 id="正则化的逻辑回归模型-1"><a href="#正则化的逻辑回归模型-1" class="headerlink" title="正则化的逻辑回归模型"></a>正则化的逻辑回归模型</h3><p>参考视频: 7 - 4 - Regularized Logistic Regression (9 min).mkv</p><p>针对逻辑回归问题，我们在之前的课程已经学习过两种优化算法：我们首先学习了使用梯度下降法来优化代价函数$J\left( \theta \right)$，接下来学习了更高级的优化算法，这些高级优化算法需要你自己设计代价函数$J\left( \theta \right)$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2726da11c772fc58f0c85e40aaed14bd.png" alt="2726da11c772fc58f0c85e40aaed14bd"><br>自己计算导数同样对于逻辑回归，我们也给代价函数增加一个正则化的表达式，得到代价函数：</p> $J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}+\frac{\lambda }{2m}\sum\limits_{j=1}^{n}{\theta _{j}^{2} }$<p><strong>Python</strong>代码：</p><pre><code class="python">import numpy as np

def costReg(theta, X, y, learningRate):
theta = np.matrix(theta)
X = np.matrix(X)
y = np.matrix(y)
first = np.multiply(-y, np.log(sigmoid(X*theta.T)))
second = np.multiply((1 - y), np.log(1 - sigmoid(X*theta.T)))
reg = (learningRate / (2 * len(X))* np.sum(np.power(theta[:,1:theta.shape[1]],2))
return np.sum(first - second) / (len(X)) + reg</code></pre><p>要最小化该代价函数，通过求导，得出梯度下降算法为：</p> $Repeat$ $until$ $convergence${<p>​ ${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{0}^{(i)} })$</p><p>​ ${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }+\frac{\lambda }{m}{\theta_j}]$</p><p>​ $for$ $j=1,2,...n$</p><p>​ }</p><p>注：看上去同线性回归一样，但是知道 ${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$，所以与线性回归不同。<br><strong>Octave</strong> 中，我们依旧可以用 <code>fminuc</code> 函数来求解代价函数最小化的参数，值得注意的是参数${\theta_{0} }$的更新规则与其他情况不同。<br>注意：</p><ol><li><p>虽然正则化的逻辑回归中的梯度下降和正则化的线性回归中的表达式看起来一样，但由于两者的${h_\theta}\left( x \right)$不同所以还是有很大差别。</p></li><li>${\theta_{0} }$不参与其中的任何一个正则化。</li></ol><p>目前大家对机器学习算法可能还只是略懂，但是一旦你精通了线性回归、高级优化算法和正则化技术，坦率地说，你对机器学习的理解可能已经比许多工程师深入了。现在，你已经有了丰富的机器学习知识，目测比那些硅谷工程师还厉害，或者用机器学习算法来做产品。</p><p>接下来的课程中，我们将学习一个非常强大的非线性分类器，无论是线性回归问题，还是逻辑回归问题，都可以构造多项式来解决。你将逐渐发现还有更强大的非线性分类器，可以用来解决多项式回归问题。我们接下来将将学会，比现在解决问题的方法强大N倍的学习算法。</p><h2 id="神经网络：表述-Neural-Networks-Representation-1"><a href="#神经网络：表述-Neural-Networks-Representation-1" class="headerlink" title="神经网络：表述(Neural Networks: Representation)"></a>神经网络：表述(Neural Networks: Representation)</h2><h3 id="非线性假设-1"><a href="#非线性假设-1" class="headerlink" title="非线性假设"></a>非线性假设</h3><p>参考视频: 8 - 1 - Non-linear Hypotheses (10 min).mkv</p><p>我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。</p><p>下面是一个例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5316b24cd40908fb5cb1db5a055e4de5.png" alt="5316b24cd40908fb5cb1db5a055e4de5"><br>当我们使用$x_1$, $x_2$ 的多次项式进行预测时，我们可以应用的很好。<br>之前我们已经看到过，使用非线性的多项式项，能够帮助我们建立更好的分类模型。假设我们有非常多的特征，例如大于100个变量，我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合$(x_1x_2+x_1x_3+x_1x_4+...+x_2x_3+x_2x_4+...+x_{99}x_{100})$，我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。</p><p>假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车），我们怎样才能这么做呢？一种方法是我们利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。</p><p>假如我们只选用灰度图片，每个像素则只有一个值（而非 <strong>RGB</strong>值），我们可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3ac5e06e852ad3deef4cba782ebe425b.jpg" alt="3ac5e06e852ad3deef4cba782ebe425b"><br>假使我们采用的都是50x50像素的小图片，并且我们将所有的像素视为特征，则会有 2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约${ {2500}^{2} }/2$个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们需要神经网络。</p><h3 id="神经元和大脑-1"><a href="#神经元和大脑-1" class="headerlink" title="神经元和大脑"></a>神经元和大脑</h3><p>参考视频: 8 - 2 - Neurons and the Brain (8 min).mkv</p><p>神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。</p><p>在这门课中，我将向你们介绍神经网络。因为它能很好地解决不同的机器学习问题。而不只因为它们在逻辑上行得通，在这段视频中，我想告诉你们一些神经网络的背景知识，由此我们能知道可以用它们来做什么。不管是将其应用到现代的机器学习问题上，还是应用到那些你可能会感兴趣的问题中。也许，这一伟大的人工智能梦想在未来能制造出真正的智能机器。另外，我们还将讲解神经网络是怎么涉及这些问题的神经网络产生的原因是人们想尝试设计出模仿大脑的算法，从某种意义上说如果我们想要建立学习系统，那为什么不去模仿我们所认识的最神奇的学习机器——人类的大脑呢？</p><p>神经网络逐渐兴起于二十世纪八九十年代，应用得非常广泛。但由于各种原因，在90年代的后期应用减少了。但是最近，神经网络又东山再起了。其中一个原因是：神经网络是计算量有些偏大的算法。然而大概由于近些年计算机的运行速度变快，才足以真正运行起大规模的神经网络。正是由于这个原因和其他一些我们后面会讨论到的技术因素，如今的神经网络对于许多应用来说是最先进的技术。当你想模拟大脑时，是指想制造出与人类大脑作用效果相同的机器。大脑可以学会去以看而不是听的方式处理图像，学会处理我们的触觉。</p><p>我们能学习数学，学着做微积分，而且大脑能处理各种不同的令人惊奇的事情。似乎如果你想要模仿它，你得写很多不同的软件来模拟所有这些五花八门的奇妙的事情。不过能不能假设大脑做所有这些，不同事情的方法，不需要用上千个不同的程序去实现。相反的，大脑处理的方法，只需要一个单一的学习算法就可以了？尽管这只是一个假设，不过让我和你分享，一些这方面的证据。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7912ea75bc7982998870721cb1177226.jpg" alt="7912ea75bc7982998870721cb1177226"><br>大脑的这一部分这一小片红色区域是你的听觉皮层，你现在正在理解我的话，这靠的是耳朵。耳朵接收到声音信号，并把声音信号传递给你的听觉皮层，正因如此，你才能明白我的话。</p><p>神经系统科学家做了下面这个有趣的实验，把耳朵到听觉皮层的神经切断。在这种情况下，将其重新接到一个动物的大脑上，这样从眼睛到视神经的信号最终将传到听觉皮层。如果这样做了。那么结果表明听觉皮层将会学会“看”。这里的“看”代表了我们所知道的每层含义。所以，如果你对动物这样做，那么动物就可以完成视觉辨别任务，它们可以看图像，并根据图像做出适当的决定。它们正是通过脑组织中的这个部分完成的。下面再举另一个例子，这块红色的脑组织是你的躯体感觉皮层，这是你用来处理触觉的，如果你做一个和刚才类似的重接实验，那么躯体感觉皮层也能学会“看”。这个实验和其它一些类似的实验，被称为神经重接实验，从这个意义上说，如果人体有同一块脑组织可以处理光、声或触觉信号，那么也许存在一种学习算法，可以同时处理视觉、听觉和触觉，而不是需要运行上千个不同的程序，或者上千个不同的算法来做这些大脑所完成的成千上万的美好事情。也许我们需要做的就是找出一些近似的或实际的大脑学习算法，然后实现它大脑通过自学掌握如何处理这些不同类型的数据。在很大的程度上，可以猜想如果我们把几乎任何一种传感器接入到大脑的几乎任何一个部位的话，大脑就会学会处理它。</p><p>下面再举几个例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2b74c1eeff95db47f5ebd8aef1290f09.jpg" alt="2b74c1eeff95db47f5ebd8aef1290f09"><br>这张图是用舌头学会“看”的一个例子。它的原理是：这实际上是一个名为<strong>BrainPort</strong>的系统，它现在正在<strong>FDA</strong><br>(美国食品和药物管理局)的临床试验阶段，它能帮助失明人士看见事物。它的原理是，你在前额上带一个灰度摄像头，面朝前，它就能获取你面前事物的低分辨率的灰度图像。你连一根线到舌头上安装的电极阵列上，那么每个像素都被映射到你舌头的某个位置上，可能电压值高的点对应一个暗像素电压值低的点。对应于亮像素，即使依靠它现在的功能，使用这种系统就能让你我在几十分钟里就学会用我们的舌头“看”东西。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/95c020b2227ca4b9a9bcbd40099d1766.png" alt="95c020b2227ca4b9a9bcbd40099d1766"><br>这是第二个例子，关于人体回声定位或者说人体声纳。你有两种方法可以实现：你可以弹响指，或者咂舌头。不过现在有失明人士，确实在学校里接受这样的培训，并学会解读从环境反弹回来的声波模式—这就是声纳。如果你搜索<strong>YouTube</strong>之后，就会发现有些视频讲述了一个令人称奇的孩子，他因为癌症眼球惨遭移除，虽然失去了眼球，但是通过打响指，他可以四处走动而不撞到任何东西，他能滑滑板，他可以将篮球投入篮框中。注意这是一个没有眼球的孩子。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/697ae58b1370e81749f9feb333bdf842.png" alt="697ae58b1370e81749f9feb333bdf842"><br>第三个例子是触觉皮带，如果你把它戴在腰上，蜂鸣器会响，而且总是朝向北时发出嗡嗡声。它可以使人拥有方向感，用类似于鸟类感知方向的方式。</p><p>还有一些离奇的例子：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1ee5c76a62b35384491c603bb54c8c0c.png" alt="1ee5c76a62b35384491c603bb54c8c0c"><br>如果你在青蛙身上插入第三只眼，青蛙也能学会使用那只眼睛。因此，这将会非常令人惊奇。如果你能把几乎任何传感器接入到大脑中，大脑的学习算法就能找出学习数据的方法，并处理这些数据。从某种意义上来说，如果我们能找出大脑的学习算法，然后在计算机上执行大脑学习算法或与之相似的算法，也许这将是我们向人工智能迈进做出的最好的尝试。人工智能的梦想就是：有一天能制造出真正的智能机器。</p><p>神经网络可能为我们打开一扇进入遥远的人工智能梦的窗户，但我在这节课中讲授神经网络的原因，主要是对于现代机器学习应用。它是最有效的技术方法。因此在接下来的一些课程中，我们将开始深入到神经网络的技术细节。</p><h3 id="模型表示1-1"><a href="#模型表示1-1" class="headerlink" title="模型表示1"></a>模型表示1</h3><p>参考视频: 8 - 3 - Model Representation I (12 min).mkv</p><p>为了构建神经网络模型，我们需要首先思考大脑中的神经网络是怎样的？每一个神经元都可以被认为是一个处理单元/神经核（<strong>processing unit</strong>/<strong>Nucleus</strong>），它含有许多输入/树突（<strong>input</strong>/<strong>Dendrite</strong>），并且有一个输出/轴突（<strong>output</strong>/<strong>Axon</strong>）。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3d93e8c1cd681c2b3599f05739e3f3cc.jpg" alt="3d93e8c1cd681c2b3599f05739e3f3cc"><br>下面是一组神经元的示意图，神经元利用微弱的电流进行沟通。这些弱电流也称作动作电位，其实就是一些微弱的电流。所以如果神经元想要传递一个消息，它就会就通过它的轴突，发送一段微弱电流给其他神经元，这就是轴突。</p><p>这里是一条连接到输入神经，或者连接另一个神经元树突的神经，接下来这个神经元接收这条消息，做一些计算，它有可能会反过来将在轴突上的自己的消息传给其他神经元。这就是所有人类思考的模型：我们的神经元把自己的收到的消息进行计算，并向其他神经元传递消息。这也是我们的感觉和肌肉运转的原理。如果你想活动一块肌肉，就会触发一个神经元给你的肌肉发送脉冲，并引起你的肌肉收缩。如果一些感官：比如说眼睛想要给大脑传递一个消息，那么它就像这样发送电脉冲给大脑的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7dabd366525c7c3124e844abce8c2dd6.png" alt="7dabd366525c7c3124e844abce8c2dd6"><br>神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，<strong>activation unit</strong>）采纳一些特征作为输出，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，参数又可被成为权重（<strong>weight</strong>）。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c2233cd74605a9f8fe69fd59547d3853.jpg" alt="c2233cd74605a9f8fe69fd59547d3853"><br>我们设计出了类似于神经元的神经网络，效果如下：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fbb4ffb48b64468c384647d45f7b86b5.png" alt="fbb4ffb48b64468c384647d45f7b86b5"><br>其中$x_1$, $x_2$, $x_3$是输入单元（<strong>input units</strong>），我们将原始数据输入给它们。</p> $a_1$, $a_2$, $a_3$是中间单元，它们负责将数据进行处理，然后呈递到下一层。<p>最后是输出单元，它负责计算${h_\theta}\left( x \right)$。</p><p>神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个3层的神经网络，第一层成为输入层（<strong>Input Layer</strong>），最后一层称为输出层（<strong>Output Layer</strong>），中间一层成为隐藏层（<strong>Hidden Layers</strong>）。我们为每一层都增加一个偏差单位（<strong>bias unit</strong>）：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8293711e1d23414d0a03f6878f5a2d91.jpg" alt="8293711e1d23414d0a03f6878f5a2d91"><br>下面引入一些标记法来帮助描述模型：</p> $a_{i}^{\left( j \right)}$ 代表第$j$ 层的第 $i$ 个激活单元。${ {\theta }^{\left( j \right)} }$代表从第 $j$ 层映射到第$ j+1$ 层时的权重的矩阵，例如${ {\theta }^{\left( 1 \right)} }$代表从第一层映射到第二层的权重的矩阵。其尺寸为：以第 $j+1$层的激活单元数量为行数，以第 $j$ 层的激活单元数加一为列数的矩阵。例如：上图所示的神经网络中${ {\theta }^{\left( 1 \right)} }$的尺寸为 3*4。<p>对于上图所示的模型，激活单元和输出分别表达为：</p> $a_{1}^{(2)}=g(\Theta _{10}^{(1)}{ {x}_{0} }+\Theta _{11}^{(1)}{ {x}_{1} }+\Theta _{12}^{(1)}{ {x}_{2} }+\Theta _{13}^{(1)}{ {x}_{3} })$ $a_{2}^{(2)}=g(\Theta _{20}^{(1)}{ {x}_{0} }+\Theta _{21}^{(1)}{ {x}_{1} }+\Theta _{22}^{(1)}{ {x}_{2} }+\Theta _{23}^{(1)}{ {x}_{3} })$ $a_{3}^{(2)}=g(\Theta _{30}^{(1)}{ {x}_{0} }+\Theta _{31}^{(1)}{ {x}_{1} }+\Theta _{32}^{(1)}{ {x}_{2} }+\Theta _{33}^{(1)}{ {x}_{3} })$ ${ {h}_{\Theta } }(x)=g(\Theta _{10}^{(2)}a_{0}^{(2)}+\Theta _{11}^{(2)}a_{1}^{(2)}+\Theta _{12}^{(2)}a_{2}^{(2)}+\Theta _{13}^{(2)}a_{3}^{(2)})$<p>上面进行的讨论中只是将特征矩阵中的一行（一个训练实例）喂给了神经网络，我们需要将整个训练集都喂给我们的神经网络算法来学习模型。</p><p>我们可以知道：每一个$a$都是由上一层所有的$x$和每一个$x$所对应的决定的。</p><p>（我们把这样从左到右的算法称为前向传播算法( <strong>FORWARD PROPAGATION</strong> )）</p><p>把$x$, $\theta$, $a$ 分别用矩阵表示：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20171101224053.png" alt="20171101224053"><br>我们可以得到$\theta \cdot X=a$ 。</p><h3 id="模型表示2-1"><a href="#模型表示2-1" class="headerlink" title="模型表示2"></a>模型表示2</h3><p>参考视频: 8 - 4 - Model Representation II (12 min).mkv</p><p>( <strong>FORWARD PROPAGATION</strong> )<br>相对于使用循环来编码，利用向量化的方法会使得计算更为简便。以上面的神经网络为例，试着计算第二层的值：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/303ce7ad54d957fca9dbb6a992155111.png" alt="303ce7ad54d957fca9dbb6a992155111"></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e17f58ce9a79525089a1c2e0b4c0ccc.png" alt="2e17f58ce9a79525089a1c2e0b4c0ccc"><br>我们令 ${ {z}^{\left( 2 \right)} }={ {\theta }^{\left( 1 \right)} }x$，则 ${ {a}^{\left( 2 \right)} }=g({ {z}^{\left( 2 \right)} })$ ，计算后添加 $a_{0}^{\left( 2 \right)}=1$。 计算输出的值为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/43f1cb8a2a7e9a18f928720adc1fac22.png" alt="43f1cb8a2a7e9a18f928720adc1fac22"><br>我们令 ${ {z}^{\left( 3 \right)} }={ {\theta }^{\left( 2 \right)} }{ {a}^{\left( 2 \right)} }$，则 $h_\theta(x)={ {a}^{\left( 3 \right)} }=g({ {z}^{\left( 3 \right)} })$。<br>这只是针对训练集中一个训练实例所进行的计算。如果我们要对整个训练集进行计算，我们需要将训练集特征矩阵进行转置，使得同一个实例的特征都在同一列里。即：</p> ${ {z}^{\left( 2 \right)} }={ {\Theta }^{\left( 1 \right)} }\times { {X}^{T} } $ ${ {a}^{\left( 2 \right)} }=g({ {z}^{\left( 2 \right)} })$<p>为了更好了了解<strong>Neuron Networks</strong>的工作原理，我们先把左半部分遮住：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6167ad04e696c400cb9e1b7dc1e58d8a.png" alt="6167ad04e696c400cb9e1b7dc1e58d8a"><br>右半部分其实就是以$a_0, a_1, a_2, a_3$, 按照<strong>Logistic Regression</strong>的方式输出$h_\theta(x)$：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/10342b472803c339a9e3bc339188c5b8.png" alt="10342b472803c339a9e3bc339188c5b8"><br>其实神经网络就像是<strong>logistic regression</strong>，只不过我们把<strong>logistic regression</strong>中的输入向量$\left[ x_1\sim {x_3} \right]$ 变成了中间层的$\left[ a_1^{(2)}\sim a_3^{(2)} \right]$, 即: $h_\theta(x)=g\left( \Theta_0^{\left( 2 \right)}a_0^{\left( 2 \right)}+\Theta_1^{\left( 2 \right)}a_1^{\left( 2 \right)}+\Theta_{2}^{\left( 2 \right)}a_{2}^{\left( 2 \right)}+\Theta_{3}^{\left( 2 \right)}a_{3}^{\left( 2 \right)} \right)$<br>我们可以把$a_0, a_1, a_2, a_3$看成更为高级的特征值，也就是$x_0, x_1, x_2, x_3$的进化体，并且它们是由 $x$与$\theta$决定的，因为是梯度下降的，所以$a$是变化的，并且变得越来越厉害，所以这些更高级的特征值远比仅仅将 $x$次方厉害，也能更好的预测新数据。<br>这就是神经网络相比于逻辑回归和线性回归的优势。</p><h3 id="特征和直观理解1-1"><a href="#特征和直观理解1-1" class="headerlink" title="特征和直观理解1"></a>特征和直观理解1</h3><p>参考视频: 8 - 5 - Examples and Intuitions I (7 min).mkv</p><p>从本质上讲，神经网络能够通过学习得出其自身的一系列特征。在普通的逻辑回归中，我们被限制为使用数据中的原始特征$x_1,x_2,...,{ {x}_{n} }$，我们虽然可以使用一些二项式项来组合这些特征，但是我们仍然受到这些原始特征的限制。在神经网络中，原始特征只是输入层，在我们上面三层的神经网络例子中，第三层也就是输出层做出的预测利用的是第二层的特征，而非输入层中的原始特征，我们可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输出变量的新特征。</p><p>神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑与(<strong>AND</strong>)、逻辑或(<strong>OR</strong>)。</p><p>举例说明：逻辑与(<strong>AND</strong>)；下图中左半部分是神经网络的设计与<strong>output</strong>层表达式，右边上部分是<strong>sigmod</strong>函数，下半部分是真值表。</p><p>我们可以用这样的一个神经网络表示<strong>AND</strong> 函数：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/809187c1815e1ec67184699076de51f2.png" alt="809187c1815e1ec67184699076de51f2"><br>其中$\theta_0 = -30, \theta_1 = 20, \theta_2 = 20$<br>我们的输出函数$h_\theta(x)$即为：$h_\Theta(x)=g\left( -30+20x_1+20x_2 \right)$</p><p>我们知道$g(x)$的图像是：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6d652f125654d077480aadc578ae0164.png" alt="6d652f125654d077480aadc578ae0164"></p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f75115da9090701516aa1ff0295436dd.png" alt="f75115da9090701516aa1ff0295436dd"><br>所以我们有：$h_\Theta(x) \approx \text{x}_1 \text{AND} \, \text{x}_2$</p><p>所以我们的：$h_\Theta(x) $</p><p>这就是<strong>AND</strong>函数。</p><p>接下来再介绍一个<strong>OR</strong>函数：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/aa27671f7a3a16545a28f356a2fb98c0.png" alt="aa27671f7a3a16545a28f356a2fb98c0"><br><strong>OR</strong>与<strong>AND</strong>整体一样，区别只在于的取值不同。</p><h3 id="样本和直观理解II-1"><a href="#样本和直观理解II-1" class="headerlink" title="样本和直观理解II"></a>样本和直观理解II</h3><p>参考视频: 8 - 6 - Examples and Intuitions II (10 min).mkv</p><p>二元逻辑运算符（<strong>BINARY LOGICAL OPERATORS</strong>）当输入特征为布尔值（0或1）时，我们可以用一个单一的激活层可以作为二元逻辑运算符，为了表示不同的运算符，我们只需要选择不同的权重即可。</p><p>下图的神经元（三个权重分别为-30，20，20）可以被视为作用同于逻辑与（<strong>AND</strong>）：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/57480b04956f1dc54ecfc64d68a6b357.png" alt="57480b04956f1dc54ecfc64d68a6b357"><br>下图的神经元（三个权重分别为-10，20，20）可以被视为作用等同于逻辑或（<strong>OR</strong>）：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7527e61b1612dcf84dadbcf7a26a22fb.png" alt="7527e61b1612dcf84dadbcf7a26a22fb"><br>下图的神经元（两个权重分别为 10，-20）可以被视为作用等同于逻辑非（<strong>NOT</strong>）：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1fd3017dfa554642a5e1805d6d2b1fa6.png" alt="1fd3017dfa554642a5e1805d6d2b1fa6"><br>我们可以利用神经元来组合成更为复杂的神经网络以实现更复杂的运算。例如我们要实现<strong>XNOR</strong> 功能（输入的两个值必须一样，均为1或均为0），即 $\text{XNOR}=( \text{x}_1\, \text{AND}\, \text{x}_2 )\, \text{OR} \left( \left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right) \right)$<br>首先构造一个能表达$\left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right)$部分的神经元：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4c44e69a12b48efdff2fe92a0a698768.png" alt="4c44e69a12b48efdff2fe92a0a698768"><br>然后将表示 <strong>AND</strong> 的神经元和表示$\left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right)$的神经元以及表示 OR 的神经元进行组合：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/432c906875baca78031bd337fe0c8682.png" alt="432c906875baca78031bd337fe0c8682"><br>我们就得到了一个能实现 $\text{XNOR}$ 运算符功能的神经网络。</p><p>按这种方法我们可以逐渐构造出越来越复杂的函数，也能得到更加厉害的特征值。</p><p>这就是神经网络的厉害之处。</p><h3 id="多类分类-1"><a href="#多类分类-1" class="headerlink" title="多类分类"></a>多类分类</h3><p>参考视频: 8 - 7 - Multiclass Classification (4 min).mkv</p><p>当我们有不止两种分类时（也就是$y=1,2,3….$），比如以下这种情况，该怎么办？如果我们要训练一个神经网络算法来识别路人、汽车、摩托车和卡车，在输出层我们应该有4个值。例如，第一个值为1或0用于预测是否是行人，第二个值用于判断是否为汽车。</p><p>输入向量$x$有三个维度，两个中间层，输出层4个神经元分别用来表示4类，也就是每一个数据在输出层都会出现${ {\left[ a\text{ }b\text{ }c\text{ }d \right]}^{T} }$，且$a,b,c,d$中仅有一个为1，表示当前类。下面是该神经网络的可能结构示例：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f3236b14640fa053e62c73177b3474ed.jpg" alt="f3236b14640fa053e62c73177b3474ed"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/685180bf1774f7edd2b0856a8aae3498.png" alt="685180bf1774f7edd2b0856a8aae3498"><br>神经网络算法的输出结果为四种可能情形之一：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5e1a39d165f272b7f145c68ef78a3e13.png" alt="5e1a39d165f272b7f145c68ef78a3e13"></p><h2 id="神经网络的学习-Neural-Networks-Learning-1"><a href="#神经网络的学习-Neural-Networks-Learning-1" class="headerlink" title="神经网络的学习(Neural Networks: Learning)"></a>神经网络的学习(Neural Networks: Learning)</h2><h3 id="代价函数-7"><a href="#代价函数-7" class="headerlink" title="代价函数"></a>代价函数</h3><p>参考视频: 9 - 1 - Cost Function (7 min).mkv</p><p>首先引入一些便于稍后讨论的新标记方法：</p><p>假设神经网络的训练样本有$m$个，每个包含一组输入$x$和一组输出信号$y$，$L$表示神经网络层数，$S_I$表示每层的<strong>neuron</strong>个数($S_l$表示输出层神经元个数)，$S_L$代表最后一层中处理单元的个数。</p><p>将神经网络的分类定义为两种情况：二类分类和多类分类，</p><p>二类分类：$S_L=0, y=0\, or\, 1$表示哪一类；</p> $K$类分类：$S_L=k, y_i = 1$表示分到第$i$类；$(k>2)$<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8f7c28297fc9ed297f42942018441850.jpg" alt="8f7c28297fc9ed297f42942018441850"><br>我们回顾逻辑回归问题中我们的代价函数为：</p> $ J\left(\theta \right)=-\frac{1}{m}\left[\sum_\limits{i=1}^{m}{y}^{(i)}\log{h_\theta({x}^{(i)})}+\left(1-{y}^{(i)}\right)log\left(1-h_\theta\left({x}^{(i)}\right)\right)\right]+\frac{\lambda}{2m}\sum_\limits{j=1}^{n}{\theta_j}^{2} $<p>在逻辑回归中，我们只有一个输出变量，又称标量（<strong>scalar</strong>），也只有一个因变量$y$，但是在神经网络中，我们可以有很多输出变量，我们的$h_\theta(x)$是一个维度为$K$的向量，并且我们训练集中的因变量也是同样维度的一个向量，因此我们的代价函数会比逻辑回归更加复杂一些，为：$\newcommand{\subk}[1]{ #1_k }$</p> $$h_\theta\left(x\right)\in \mathbb{R}^{K}$$ $${\left({h_\theta}\left(x\right)\right)}_{i}={i}^{th} \text{output}$$ $J(\Theta) = -\frac{1}{m} \left[ \sum\limits_{i=1}^{m} \sum\limits_{k=1}^{k} {y_k}^{(i)} \log \subk{(h_\Theta(x^{(i)}))} + \left( 1 - y_k^{(i)} \right) \log \left( 1- \subk{\left( h_\Theta \left( x^{(i)} \right) \right)} \right) \right] + \frac{\lambda}{2m} \sum\limits_{l=1}^{L-1} \sum\limits_{i=1}^{s_l} \sum\limits_{j=1}^{s_{l+1} } \left( \Theta_{ji}^{(l)} \right)^2$<p>这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出$K$个预测，基本上我们可以利用循环，对每一行特征都预测$K$个不同结果，然后在利用循环在$K$个预测中选择可能性最高的一个，将其与$y$中的实际数据进行比较。</p><p>正则化的那一项只是排除了每一层$\theta_0$后，每一层的$\theta$ 矩阵的和。最里层的循环$j$循环所有的行（由$s_{l+1}$ 层的激活单元数决定），循环$i$则循环所有的列，由该层（$s_l$层）的激活单元数所决定。即：$h_\theta(x)$与真实值之间的距离为每个样本-每个类输出的加和，对参数进行<strong>regularization</strong>的<strong>bias</strong>项处理所有参数的平方和。</p><h3 id="反向传播算法-1"><a href="#反向传播算法-1" class="headerlink" title="反向传播算法"></a>反向传播算法</h3><p>参考视频: 9 - 2 - Backpropagation Algorithm (12 min).mkv</p><p>之前我们在计算神经网络预测结果的时候我们采用了一种正向传播方法，我们从第一层开始正向一层一层进行计算，直到最后一层的$h_{\theta}\left(x\right)$。</p><p>现在，为了计算代价函数的偏导数$\frac{\partial}{\partial\Theta^{(l)}_{ij} }J\left(\Theta\right)$，我们需要采用一种反向传播算法，也就是首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。<br>以一个例子来说明反向传播算法。</p><p>假设我们的训练集只有一个样本$\left({x}^{(1)},{y}^{(1)}\right)$，我们的神经网络是一个四层的神经网络，其中$K=4，S_{L}=4，L=4$：</p><p>前向传播算法：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2ea8f5ce4c3df931ee49cf8d987ef25d.png" alt="2ea8f5ce4c3df931ee49cf8d987ef25d"><br>下面的公式推导过程见：&lt;<a href="https://blog.csdn.net/qq_29762941/article/details/80343185&gt;" target="_blank" rel="noopener">https://blog.csdn.net/qq_29762941/article/details/80343185&gt;</a></p><p>我们从最后一层的误差开始计算，误差是激活单元的预测（${a^{(4)} }$）与实际值（$y^k$）之间的误差，（$k=1:k$）。<br>我们用$\delta$来表示误差，则：$\delta^{(4)}=a^{(4)}-y$<br>我们利用这个误差值来计算前一层的误差：$\delta^{(3)}=\left({\Theta^{(3)} }\right)^{T}\delta^{(4)}\ast g'\left(z^{(3)}\right)$<br>其中 $g'(z^{(3)})$是 $S$ 形函数的导数，$g'(z^{(3)})=a^{(3)}\ast(1-a^{(3)})$。而$(θ^{(3)})^{T}\delta^{(4)}$则是权重导致的误差的和。下一步是继续计算第二层的误差：</p> $ \delta^{(2)}=(\Theta^{(2)})^{T}\delta^{(3)}\ast g'(z^{(2)})$<p>因为第一层是输入变量，不存在误差。我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设$λ=0$，即我们不做任何正则化处理时有：</p> $\frac{\partial}{\partial\Theta_{ij}^{(l)} }J(\Theta)=a_{j}^{(l)} \delta_{i}^{l+1}$<p>重要的是清楚地知道上面式子中上下标的含义：</p> $l$ 代表目前所计算的是第几层。 $j$ 代表目前计算层中的激活单元的下标，也将是下一层的第$j$个输入变量的下标。 $i$ 代表下一层中误差单元的下标，是受到权重矩阵中第$i$行影响的下一层中的误差单元的下标。<p>如果我们考虑正则化处理，并且我们的训练集是一个特征矩阵而非向量。在上面的特殊情况中，我们需要计算每一层的误差单元来计算代价函数的偏导数。在更为一般的情况中，我们同样需要计算每一层的误差单元，但是我们需要为整个训练集计算误差单元，此时的误差单元也是一个矩阵，我们用$\Delta^{(l)}_{ij}$来表示这个误差矩阵。第 $l$ 层的第 $i$ 个激活单元受到第 $j$ 个参数影响而导致的误差。</p><p>我们的算法表示为：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5514df14ebd508fd597e552fbadcf053.jpg" alt="5514df14ebd508fd597e552fbadcf053"><br>即首先用正向传播方法计算出每一层的激活单元，利用训练集的结果与神经网络预测的结果求出最后一层的误差，然后利用该误差运用反向传播法计算出直至第二层的所有误差。</p><p>在求出了$\Delta_{ij}^{(l)}$之后，我们便可以计算代价函数的偏导数了，计算方法如下：</p> $ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)}$ ${if}\; j \neq 0$ $ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}$ ${if}\; j = 0$<p>在<strong>Octave</strong> 中，如果我们要使用 <code>fminuc</code>这样的优化算法来求解求出权重矩阵，我们需要将矩阵首先展开成为向量，在利用算法求出最优解后再重新转换回矩阵。</p><p>假设我们有三个权重矩阵，Theta1，Theta2 和 Theta3，尺寸分别为 10*11，10*11 和1*11，<br>下面的代码可以实现这样的转换：</p><pre><code>thetaVec = [Theta1(:) ; Theta2(:) ; Theta3(:)]

...optimization using functions like fminuc...

Theta1 = reshape(thetaVec(1:110, 10, 11);

Theta2 = reshape(thetaVec(111:220, 10, 11);

Theta1 = reshape(thetaVec(221:231, 1, 11);</code></pre><h3 id="反向传播算法的直观理解-1"><a href="#反向传播算法的直观理解-1" class="headerlink" title="反向传播算法的直观理解"></a>反向传播算法的直观理解</h3><p>参考视频: 9 - 3 - Backpropagation Intuition (13 min).mkv</p><p>在上一段视频中，我们介绍了反向传播算法，对很多人来说，当第一次看到这种算法时，第一印象通常是，这个算法需要那么多繁杂的步骤，简直是太复杂了，实在不知道这些步骤，到底应该如何合在一起使用。就好像一个黑箱，里面充满了复杂的步骤。如果你对反向传播算法也有这种感受的话，这其实是正常的，相比于线性回归算法和逻辑回归算法而言，从数学的角度上讲，反向传播算法似乎并不简洁，对于反向传播这种算法，其实我已经使用了很多年了，但即便如此，即使是现在，我也经常感觉自己对反向传播算法的理解并不是十分深入，对于反向传播算法究竟是如何执行的，并没有一个很直观的理解。做过编程练习的同学应该可以感受到这些练习或多或少能帮助你，将这些复杂的步骤梳理了一遍，巩固了反向传播算法具体是如何实现的，这样你才能自己掌握这种算法。</p><p>在这段视频中，我想更加深入地讨论一下反向传播算法的这些复杂的步骤，并且希望给你一个更加全面直观的感受，理解这些步骤究竟是在做什么，也希望通过这段视频，你能理解，它至少还是一个合理的算法。但可能你即使看了这段视频，你还是觉得反向传播依然很复杂，依然像一个黑箱，太多复杂的步骤，依然感到有点神奇，这也是没关系的。即使是我接触反向传播这么多年了，有时候仍然觉得这是一个难以理解的算法，但还是希望这段视频能有些许帮助，为了更好地理解反向传播算法，我们再来仔细研究一下前向传播的原理：</p><p>前向传播算法：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5778e97c411b23487881a87cfca781bb.png" alt="5778e97c411b23487881a87cfca781bb"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/63a0e4aef6d47ba7fa6e07088b61ae68.png" alt="63a0e4aef6d47ba7fa6e07088b61ae68"><br>反向传播算法做的是：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/57aabbf26290e2082a00c5114ae1c5dc.png" alt="57aabbf26290e2082a00c5114ae1c5dc"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1542307ad9033e39093e7f28d0c7146c.png" alt="1542307ad9033e39093e7f28d0c7146c"><br><strong>感悟</strong>：上图中的 $\delta^{(l)}_{j}="error" \ of cost \ for \ a^{(l)}_{j} \ (unit \ j \ in \ layer \ l)$ 理解如下：</p> $\delta^{(l)}_{j}$ 相当于是第 $l$ 层的第 $j$ 单元中得到的激活项的“误差”，即”正确“的 $a^{(l)}_{j}$ 与计算得到的 $a^{(l)}_{j}$ 的差。<p>而 $a^{(l)}_{j}=g(z^{(l)})$ ，（g为sigmoid函数）。我们可以想象 $\delta^{(l)}_{j}$ 为函数求导时迈出的那一丁点微分，所以更准确的说 $\delta^{(l)}_{j}=\frac{\partial}{\partial z^{(l)}_{j} }cost(i)$</p><h3 id="实现注意：展开参数-1"><a href="#实现注意：展开参数-1" class="headerlink" title="实现注意：展开参数"></a>实现注意：展开参数</h3><p>参考视频: 9 - 4 - Implementation Note_ Unrolling Parameters (8 min).mkv</p><p>在上一段视频中，我们谈到了怎样使用反向传播算法计算代价函数的导数。在这段视频中，我想快速地向你介绍一个细节的实现过程，怎样把你的参数从矩阵展开成向量，以便我们在高级最优化步骤中的使用需要。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0ad78547859e6f794a7f18389d3d6128.png" alt="0ad78547859e6f794a7f18389d3d6128"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f9284204de41bffa4f7bc1dea567044e.png" alt="f9284204de41bffa4f7bc1dea567044e"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ebd7e196e272737f497853ba60743c44.png" alt="ebd7e196e272737f497853ba60743c44"></p><h3 id="梯度检验-1"><a href="#梯度检验-1" class="headerlink" title="梯度检验"></a>梯度检验</h3><p>参考视频: 9 - 5 - Gradient Checking (12 min).mkv</p><p>当我们对一个较为复杂的模型（例如神经网络）使用梯度下降算法时，可能会存在一些不容易察觉的错误，意味着，虽然代价看上去在不断减小，但最终的结果可能并不是最优解。</p><p>为了避免这样的问题，我们采取一种叫做梯度的数值检验（<strong>Numerical Gradient Checking</strong>）方法。这种方法的思想是通过估计梯度值来检验我们计算的导数值是否真的是我们要求的。</p><p>对梯度的估计采用的方法是在代价函数上沿着切线的方向选择离两个非常近的点然后计算两个点的平均值用以估计梯度。即对于某个特定的 $\theta$，我们计算出在 $\theta$-$\varepsilon $ 处和 $\theta$+$\varepsilon $ 的代价值（$\varepsilon $是一个非常小的值，通常选取 0.001），然后求两个代价的平均，用以估计在 $\theta$ 处的代价值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5d04c4791eb12a74c843eb5acf601400.png" alt="5d04c4791eb12a74c843eb5acf601400"><br><strong>Octave</strong> 中代码如下：</p><p><code>gradApprox = (J(theta + eps) – J(theta - eps)) / (2*eps)</code></p><p>当$\theta$是一个向量时，我们则需要对偏导数进行检验。因为代价函数的偏导数检验只针对一个参数的改变进行检验，下面是一个只针对$\theta_1$进行检验的示例：</p> $$ \frac{\partial}{\partial\theta_1}=\frac{J\left(\theta_1+\varepsilon_1,\theta_2,\theta_3...\theta_n \right)-J \left( \theta_1-\varepsilon_1,\theta_2,\theta_3...\theta_n \right)}{2\varepsilon} $$<p>最后我们还需要对通过反向传播方法计算出的偏导数进行检验。</p><p>根据上面的算法，计算出的偏导数存储在矩阵 $D_{ij}^{(l)}$ 中。检验时，我们要将该矩阵展开成为向量，同时我们也将 $\theta$ 矩阵展开为向量，我们针对每一个 $\theta$ 都计算一个近似的梯度值，将这些值存储于一个近似梯度矩阵中，最终将得出的这个矩阵同 $D_{ij}^{(l)}$ 进行比较。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bf65f3f3098025530a3c442eea562f8c.jpg" alt="bf65f3f3098025530a3c442eea562f8c"></p><h3 id="随机初始化-1"><a href="#随机初始化-1" class="headerlink" title="随机初始化"></a>随机初始化</h3><p>参考视频: 9 - 6 - Random Initialization (7 min).mkv</p><p>任何优化算法都需要一些初始的参数。到目前为止我们都是初始所有参数为0，这样的初始方法对于逻辑回归来说是可行的，但是对于神经网络来说是不可行的。如果我们令所有的初始参数都为0，这将意味着我们第二层的所有激活单元都会有相同的值。同理，如果我们初始所有的参数都为一个非0的数，结果也是一样的。</p><p>我们通常初始参数为正负ε之间的随机值，假设我们要随机初始一个尺寸为10×11的参数矩阵，代码如下：</p><p><code>Theta1 = rand(10, 11) * (2*eps) – eps</code></p><h3 id="综合起来-1"><a href="#综合起来-1" class="headerlink" title="综合起来"></a>综合起来</h3><p>参考视频: 9 - 7 - Putting It Together (14 min).mkv</p><p>小结一下使用神经网络时的步骤：</p><p>网络结构：第一件要做的事是选择网络结构，即决定选择多少层以及决定每层分别有多少个单元。</p><p>第一层的单元数即我们训练集的特征数量。</p><p>最后一层的单元数是我们训练集的结果的类的数量。</p><p>如果隐藏层数大于1，确保每个隐藏层的单元个数相同，通常情况下隐藏层单元的个数越多越好。</p><p>我们真正要决定的是隐藏层的层数和每个中间层的单元数。</p><p>训练神经网络：</p><ol><li><p>参数的随机初始化</p></li><li><p>利用正向传播方法计算所有的$h_{\theta}(x)$</p></li><li><p>编写计算代价函数 $J$ 的代码</p></li><li><p>利用反向传播方法计算所有偏导数</p></li><li><p>利用数值检验方法检验这些偏导数</p></li><li><p>使用优化算法来最小化代价函数</p></li></ol><h3 id="自主驾驶-1"><a href="#自主驾驶-1" class="headerlink" title="自主驾驶"></a>自主驾驶</h3><p>参考视频: 9 - 8 - Autonomous Driving (7 min).mkv</p><p>在这段视频中，我想向你介绍一个具有历史意义的神经网络学习的重要例子。那就是使用神经网络来实现自动驾驶，也就是说使汽车通过学习来自己驾驶。接下来我将演示的这段视频是我从 Dean Pomerleau那里拿到的，他是我的同事，任职于美国东海岸的卡耐基梅隆大学。在这部分视频中，你就会明白可视化技术到底是什么？在看这段视频之前，我会告诉你可视化技术是什么。</p><p>在下面也就是左下方，就是汽车所看到的前方的路况图像。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/cea3f9a181d326681cd7d6ceaf4f2e46.png" alt="cea3f9a181d326681cd7d6ceaf4f2e46"><br>在图中你依稀能看出一条道路，朝左延伸了一点，又向右了一点，然后上面的这幅图，你可以看到一条水平的菜单栏显示的是驾驶操作人选择的方向。就是这里的这条白亮的区段显示的就是人类驾驶者选择的方向。比如：最左边的区段，对应的操作就是向左急转，而最右端则对应向右急转的操作。因此，稍微靠左的区段，也就是中心稍微向左一点的位置，则表示在这一点上人类驾驶者的操作是慢慢的向左拐。</p><p>这幅图的第二部分对应的就是学习算法选出的行驶方向。并且，类似的，这一条白亮的区段显示的就是神经网络在这里选择的行驶方向，是稍微的左转，并且实际上在神经网络开始学习之前，你会看到网络的输出是一条灰色的区段，就像这样的一条灰色区段覆盖着整个区域这些均称的灰色区域，显示出神经网络已经随机初始化了，并且初始化时，我们并不知道汽车如何行驶，或者说我们并不知道所选行驶方向。只有在学习算法运行了足够长的时间之后，才会有这条白色的区段出现在整条灰色区域之中。显示出一个具体的行驶方向这就表示神经网络算法，在这时候已经选出了一个明确的行驶方向，不像刚开始的时候，输出一段模糊的浅灰色区域，而是输出一条白亮的区段，表示已经选出了明确的行驶方向。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/56441d35d8bd4ecfd6d6f32b651c54a6.png" alt="56441d35d8bd4ecfd6d6f32b651c54a6"><br><strong>ALVINN</strong> (<strong>Autonomous Land Vehicle In a Neural Network</strong>)是一个基于神经网络的智能系统，通过观察人类的驾驶来学习驾驶，<strong>ALVINN</strong>能够控制<strong>NavLab</strong>，装在一辆改装版军用悍马，这辆悍马装载了传感器、计算机和驱动器用来进行自动驾驶的导航试验。实现<strong>ALVINN</strong>功能的第一步，是对它进行训练，也就是训练一个人驾驶汽车。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/41cdc4cd2bc49a1b75d57aaf748e0798.png" alt="41cdc4cd2bc49a1b75d57aaf748e0798"><br>然后让<strong>ALVINN</strong>观看，<strong>ALVINN</strong>每两秒将前方的路况图生成一张数字化图片，并且记录驾驶者的驾驶方向，得到的训练集图片被压缩为30x32像素，并且作为输入提供给<strong>ALVINN</strong>的三层神经网络，通过使用反向传播学习算法，<strong>ALVINN</strong>会训练得到一个与人类驾驶员操纵方向基本相近的结果。一开始，我们的网络选择出的方向是随机的，大约经过两分钟的训练后，我们的神经网络便能够准确地模拟人类驾驶者的驾驶方向，对其他道路类型，也重复进行这个训练过程，当网络被训练完成后，操作者就可按下运行按钮，车辆便开始行驶了。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dd4a022b5544d50f503c077b3a5a5251.png" alt="dd4a022b5544d50f503c077b3a5a5251"><br>每秒钟<strong>ALVINN</strong>生成12次数字化图片，并且将图像传送给神经网络进行训练，多个神经网络同时工作，每一个网络都生成一个行驶方向，以及一个预测自信度的参数，预测自信度最高的那个神经网络得到的行驶方向。比如这里，在这条单行道上训练出的网络将被最终用于控制车辆方向，车辆前方突然出现了一个交叉十字路口，当车辆到达这个十字路口时，我们单行道网络对应的自信度骤减，当它穿过这个十字路口时，前方的双车道将进入其视线，双车道网络的自信度便开始上升，当它的自信度上升时，双车道的网络，将被选择来控制行驶方向，车辆将被安全地引导进入双车道路。</p><p>这就是基于神经网络的自动驾驶技术。当然，我们还有很多更加先进的试验来实现自动驾驶技术。在美国，欧洲等一些国家和地区，他们提供了一些比这个方法更加稳定的驾驶控制技术。但我认为，使用这样一个简单的基于反向传播的神经网络，训练出如此强大的自动驾驶汽车，的确是一次令人惊讶的成就。</p></article><div class="post-donate"><div id="donate_board" class="donate_bar center"><a id="btn_donate" class="btn_donate" href="javascript:;" title="打赏"></a> <span class="donate_txt">↑<br> 欢迎投食,求鼓励，求支持！</span><br></div><div id="donate_guide" class="donate_bar center hidden"> <img src="/images/alipay.png" alt="支付宝打赏"> <img src="/images/wechatpay.png" alt="微信打赏"></div><script type="text/javascript">document.getElementById("btn_donate").onclick=function(){$("#donate_board").addClass("hidden"),$("#donate_guide").removeClass("hidden")}</script></div><div class="nexmoe-post-copyright"><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i> <strong>本文作者：</strong>OneJane<br> <strong>本文链接：</strong><a href="https://onejane.github.io/2019/12/04/new_吴恩达机器学习笔记(1-5周)/" title="https://onejane.github.io/2019/12/04/new_吴恩达机器学习笔记(1-5周)/" target="_blank" rel="noopener">https://onejane.github.io/2019/12/04/new_吴恩达机器学习笔记(1-5周)/</a><br> <strong>版权声明：</strong>本文采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh" target="_blank">CC BY-NC-SA 3.0 CN</a> 协议进行许可</div><section class="nexmoe-comment"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.css"><div id="gitalk"></div><script src="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"e677e59382e1c7a468fd",clientSecret:"717d041bc4ab749f069314862232cfb6ec8adc15",id:decodeURI(window.location.pathname),repo:"onejane.github.io",owner:"onejane",admin:"onejane"});gitalk.render("gitalk")</script></section></div></div></div><script src="https://cdn.jsdelivr.net/npm/mdui@0.4.3/dist/js/mdui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/smoothscroll-for-websites@1.4.9/SmoothScroll.min.js"></script><script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.15.8/build/highlight.min.js"></script><script>hljs.initHighlightingOnLoad()</script><script src="/js/app.js?v=1577592008069"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@5.1.0/lazysizes.min.js"></script><div hidden><script type="text/javascript" src="https://js.users.51.la/20279757.js"></script></div></body><script src="https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js"></script></html>