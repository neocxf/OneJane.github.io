<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><title>吴恩达深度学习笔记(第二课时) - OneJane</title><meta charset="UTF-8"><meta name="description" content="微服务,高可用,高并发,人工智能"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="msvalidate.01" content="396E9693347B4D18AAE96D9E75B9B686"><link rel="shortcut icon" href="/images/a.ico" type="image/png"><meta name="description" content="吴恩达深度学习笔记"><meta name="keywords" content="nlp"><meta property="og:type" content="article"><meta property="og:title" content="吴恩达深度学习笔记(第二课时)"><meta property="og:url" content="https://onejane.github.io/2019/12/05/new_吴恩达深度学习笔记(第二课时)/index.html"><meta property="og:site_name" content="OneJane"><meta property="og:description" content="吴恩达深度学习笔记"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_1.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_2.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/97596da07232f85d566710ee7dd2f8ad.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/072653e2e9402d2857bfcb7b9f783a5c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ebbfb8514ff5a983f41e938d5870b79d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1224fb0922d5673c380e6dad9ded0b6b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/459ffc8998b35b259bc3bab4fd4fb44c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/658fc77a1ea588d5768dcd1a9a90761a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/02556a7f525c0ec016483644755c2231.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e0ec4205933b7c2a9eaed9fbaa8d4afc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/05ac08b96177b5d0aaae7b7bfea64f3a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2efd9728b5f07f914903dde309167a5d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c61d149beecddb96f0f93944320cf639.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fcdc2a7afbaaa07ca08b078bb4d37e8d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8fdbf9ed01b8634573125e0fb2ca860.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e9451f36e8baa41b74c95d9a09b0f028.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6e86aa7d9b21b1a49bf4a084c7503527.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/67dc5997a956314e238e6fc362f9883d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6bf7e092ddf93104ea64a5ddecbb7c6d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fa185e95684bbe6c0e9100164aff2ee5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/84c4e19130a91a09120087dd704bbaa4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5190dbc5a98db7a248499f54a04257cc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e88bd6f30a8ff8014d6d7dbe6d0488a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a8336b2cfeed4128a23f20fab843d226.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5663bd9360df02b7e5a04c01d4e1bbc7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dffec3cca0e523e22646704e5e76c39a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b6856a371ed552fd6b9ada2068ab4c2c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dafb163da5b9c3ece677a7ebce05b680.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f752bc74e0978320a72bcb15d1777cf8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/cba0f1c7a480139acb04e762e4fe57f8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/15d5607b8ac1c1fbaa023cb6060633f2.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1a6c47e64293cde6a0facb3872701db2.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d5ee6f2b60ff7601d50967f4365d0ecb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2aafa244c3f184cc271b26d1d95d70c9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f35d94efc03123e4a5de6496c1b896c0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/884d5768243f4badc77356f843cb8c0c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/63fa65e2609fe7a6909544247855d1a5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fcdff0820223fb8a5756ad0bf99991fe.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8248be8e83121535b73969a4599fbb08.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/307675386a412e57cf60be3381f02a64.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b84cc50eb967cd177007e21e93960b5c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/97e37bf0d2893f890561cda932ba8c42.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e45f9a948989b365650ddf16f62b097e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9fa7196adeeaf88eb386fda2e9fa9909.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/70b248490e496fed9b8d1d616e4d8303.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c75fe55c6bc17b60b00f5360aab180f4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6ba17ffcb3ff22a4a0ec857e66946086.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/272d902720be9993454c6d9a5f0bec49.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/de49d4e160f29544055819c5ab1dd9c0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_16.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9b9f963a73e3ef9fcac008b179b6cf74.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5fcb1441866d6d3eff1164ed4ea38cfe.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/13987e28fa537a110c6b123fc4455f7c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_17.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e2ccf4a2bb9156f876321ce07b006ca.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dd9a0f8209e53fdab8030b98d39e11eb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/69d92a8de8f62ab602d2bc022591d3c9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9d0db64a9c9b050466a039c935f36f93.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/51ca931387ed9fb80313263113c56e8e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f5fd5df8235145c54aece1a5bf7b31f6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_19.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5e49434607f22caf087f7730177931bf.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bc4eccfb6c9dbef6cc81636d5ce60390.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4d0c183882a140ecd205f1618243d7f8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fc03196f0b6d1c9f56fa39d0d462cfa4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ff87a8ea1377053128cdbf5129f0203f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/db9472c81a2cf6bb704dc398ea1cf017.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e4114d7dc1c6242bd96cdadb457b8959.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3decc82bf6f48903ee1fedbdb7e2c0f6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/91cde35a0fc9c11a98f16ad2797f20a7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b24ad9ce9fdc4a32be4d98915d8f6ffb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/35a2e86581eab4665634593870fe5180.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1b2617461ed10089bc61ad273c84594f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/94fb79f5694c802a5261298e54157e14.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f56f0cdc90730068109a6e20fcd41724.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bed27b1d469acaf24dc1a7c1a7cdc086.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f223102bc7d144b66ad9b2ffa4a85f00.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/07fd11e7b28ef0ab7d3b6d23b19a8fdc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_24.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ef8c62ba3c82cb37e6ed4783e7717a8d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/31ee4f6d35c7b509b65f6714574a08f6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/112c45cf393d896833ffce29e14fe8bc.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/609ea5be2140af929985951f2aab542c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/98fd6e4c5eec8866bbf722c489cd6177.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/539405047b6986e05f2a3eb06dd7027d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0818dc0f8b7b8c1703d0c596f6027728.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0818dc0f8b7b8c1703d0c596f6027728.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b5c07d7dec7e54bed73cdcd43e79452d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2181fbdc47d4d28840c3da00295548ea.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6ffa1351889a85cb5247fc7c43555959.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f5fce700d57a539bebebdc0e5195c5fb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bb2398f985f57c5d422df3c71437e5ea.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0f9d1f236d2a4847e9d0c6eb4c5400dd.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/66128cd2cc8d698c2a1fa351f2a22fb9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d49c52a460376e00c8e5b40baed2cf23.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/625746a61a4573b7f8594a3c071044c5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4324e926e3ba304e339cda820f61fc28.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c8d108c5e38cfa4defe77cb517a8c7c2.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a3b26bbce9cd3d0decba5aa8b26af035.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/81710bf53763e939fdac8bd8736960e6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/369ae78c3b63e5b537cc0e30f60eb471.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6f5438fde578ef4285059d85976d52ed.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9ab7565d5a3e13a9a525ec6d2f119a79.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a3f97d59db202127014297ceccf1aacb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/469d894aae98925841134e9766557fc7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a0bbcc060cac02d8d3f0b1403484f017.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/880dbafaccbd93a4ab0a92a9b8607956.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9cef2303cf6d7893020647bfde69b22c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7820d206a4afa0a694333e74ad74233b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/358269d36d06e3c70da3e87d8dc523e4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/53d041ed225ba1d37f239b6498bd134e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/26a3c3022a7f7ae7ba0cd27fc74cbcf6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f602c9d517a7f6c01fe18171dade17e6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54322ca2d7b5aed9739fd079fb3b2b6d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f378695f4b475da6546b6ab239d27a3d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/cc2d415b8ccda9fdaba12c575d4d3c4b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/be943a4d64800e989a375e7972fefbfe.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a3af0fb5e49e16c108e72d015ef0fdb6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/89d51f9b5882cf226111b2c0eda2f3e3.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/01dcc876f49fece3c6ad5f5a158020f6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/553ee26f6efd82d9996dec5f77e3f12e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d43cf7898bd88adff4aaac607c1bd5a1.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/720d168e6679fd689fb87c6c5bcb27fa.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9ca9bfc160d53b23ea0d1164e6accffe.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e9858303cd62eacc21759b16a121ff58.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/463d0a973dda9b0c8c04f46100b5e0ad.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c1b5ed3bb9f4ef32fe47056a017e51bf.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/095feaa609b0029d6abc5c74ef7b3b35.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7c4141aeec2ef4afc6aa534a486a34c8.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7e0edfb697e8262dc39a040a987c62bd.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e1b6dc57b8b73ecf5ff400852c4f7086.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a662f8be4a3a009b68c30a3e6e0683a3.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1f7df04b804836fbcadcd258c0b55f74.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a8c3dfdc238762a9f0edf26e6037ee09.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ea0d64953a3a7b41ef2997c8fee2f930.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c5e480c51363d55e8d5e43df1eee679b.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/011e9625870797d6c0695658b92f606e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/51d79b3734ccf1abdb0b9795a80d8bb7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/607bd30801c87ed74bb95c49f218f632.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7b73f4de29ea13d9aba5f49e393d4674.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/75bfa084ea64d99b1d01a393a7c988a6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7dbcb658f5054473480982c89e480c3f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/961655e4384e6f148bbe23f9eb46e2b0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c3b248ac8ca2cf646d5b705270e01e78.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3b45624120e77aea2fcd117cbfdc9bdb.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/651422f74439fd7e648e364d26d21485.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08307acea7c8db95c1479c611189dbfa.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fe47f46414d0c26183e85c7b2e4f2f0a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a54d5ea6cd623f741f75e62195f072ca.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2c4e6d3419beb66ed0163331443c6b40.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e3b1803ab468a94a4cae13e89217704.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bb7feac2d0698b8721bfedbc67cc6289.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3858f51032e483e215ebbd136dc07431.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/439e7b041ac3d948e5852e8307dd09dd.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1cbcd20a708281e777d2d0c50e355038.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a361c621a9a0a1a99b03eef8716c5799.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5cd1e3dd73e69cbf0b2cbc80fddfa4d9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7eed1a2ef94832c54d1765731a57b2b5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20949eb2c30cb22ab87eef411f01375d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/734eeb203b02cca8a978ba61b4803bb5.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e10ea98faa1ce9fe86ec8bf9f4fef71e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3d494a1d3fb25f7fd67f1bdbf8d8e464.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6216dd90d3483f05f08bd8dc86fc7df6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c4d0391006609385bc309af394c514f9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2d314293ae9aaa67285299267857632f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/02ae6d8845f468b753c1c4244c312b43.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/55047d3da405778b6272e6722cd28ac6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0204b45c1adae38694b26de9b7af2edd.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/27dc60faf8c8e4d8360b4c8091b85355.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/06fa55207f5d245e70db73a7e5e89a68.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/61cee05b5822c9bc97bfdfd88861dfd6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/79d8bc44c225879e9bc89e352b62502a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3711c11e52433b6417227e78b998e849.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08ab0b778ede091a860048d609048167.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/797be77383bc6b34ddd2ea9e49688cf6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b84c6784df7184b0baed8e96453646ac.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/125efc4b05bcba7b0e50d78614d58d1f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2f19f3438704a51d217ede3abb4eef3d.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08f134faa74ebd283a5f5f19be43efab.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8cd4b32c6febb45c71a1c91394cb1d1a.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/32efeb52697bd9543900bbd38a732e3c.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8a80801c51e13947d7f2cafb4a8fe69.png"><meta property="og:image" content="https://markdown.xiaoshujiang.com/img/spinner.gif"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0feb6ee8af40238fc1374131bc517e35.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fd1f67f2e97e814079607f190111f65f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9e64b0cb330797ece66c0a56958bfcca.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6699883f2e531063e4437cc63c5a2a83.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e36d502aa68bf9e1a118f5d13e24b134.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e65ba7b81d0b02d021c33bf0094f4059.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/97ab8f2af0788776bdd486c5f4f40354.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08e51a30d97c877410fed7f7dbe1203f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c791fc935e680ef37ef036723f0f2510.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fec90de0e70081185c234c215a23d307.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1dc4bf21b6e38cbe9bdfb729ed969c99.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7207527be03bc1daec77afb6c29b8533.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6b825763afc787168a19597da2a38d58.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/01a404ae594bdc5871aec07e9fd478d1.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b433ed42cdde6c732820c57eebfb85f7.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/36802969e1acc8b96bb19506d391efe4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2d590b27f3f80bbd31d8af257e3be606.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ed6ccb8dc9e65953f383a3bb774e8f53.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d9907b5fd482e355e9c6a4e6b3bdf5f9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c357c15e4133152bd8bb262789e71765.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e342eb0e5cc8031f43fd375084b1f473.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1d5eca1724fe08158fb9b53a73691a74.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/acb3843cd1085b0742f39677289890a0.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2a06f1bc26d2eff88246233ba60fc999.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/66541b3ff40c4c43897a062395420cfa.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f89f49038463b9f30eb09b10f7c0c438.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/43a90dbd043662008d46f168def244b6.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/05ab9534065d6359969bcc947e90bad4.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c93322e2d42219cd37fb579170abada9.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0c3521b9de148f6df29b7bfccf3e6686.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/52e7654f07e90eb39a99679692bd6514.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/10589b1fbdea44354e14a071a2244466.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3642c894eee19fce479efa42b027b56f.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b276862d4e931b4b94a7a8d216e2812e.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/421ad00776a97e6cd4fd926e35a5a419.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c7c804ba2a909bb914efbfd76eb57784.png"><meta property="og:updated_time" content="2019-12-05T06:57:29.416Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="吴恩达深度学习笔记(第二课时)"><meta name="twitter:description" content="吴恩达深度学习笔记"><meta name="twitter:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_1.png"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdui@0.4.3/dist/css/mdui.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.15.8/styles/atom-one-dark.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1038733_0xvrvpg9c0r.css"><link rel="stylesheet" href="/css/style.css?v=1575538185586"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js"></script></head><body class="mdui-drawer-body-left"><div id="nexmoe-background"><div class="nexmoe-bg" style="background-image:url(https://www.github.com/OneJane/blog/raw/master/小书匠/1566388885395.png)"></div><div class="mdui-appbar mdui-shadow-0"><div class="mdui-toolbar"> <a mdui-drawer="{target: '#drawer', swipe: true}" title="menu" class="mdui-btn mdui-btn-icon"><i class="mdui-icon material-icons">menu</i></a><div class="mdui-toolbar-spacer"></div> <a href="/" title="OneJane" class="mdui-btn mdui-btn-icon"><img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388846021.png"></a></div></div></div><div id="nexmoe-header"><div class="nexmoe-drawer mdui-drawer" id="drawer"><div class="nexmoe-avatar mdui-ripple"> <a href="/" title="OneJane"><img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388846021.png" alt="OneJane"></a></div><div class="nexmoe-count"><div><span>文章</span>69</div><div><span>标签</span>83</div><div><span>分类</span>12</div></div><ul class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}"><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/" title="回到首页"><i class="mdui-list-item-icon nexmoefont icon-home"></i><div class="mdui-list-item-content"> 回到首页</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/about.html" title="关于博客"><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i><div class="mdui-list-item-content"> 关于博客</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/py.html" title="我的朋友"><i class="mdui-list-item-icon nexmoefont icon-unorderedlist"></i><div class="mdui-list-item-content"> 我的朋友</div></a></ul><aside id="nexmoe-sidebar"><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">社交按钮</h3><div class="nexmoe-widget nexmoe-social"><a class="mdui-ripple" href="https://www.zhihu.com/people/codewj/activities" target="_blank" mdui-tooltip="{content: 'zhihu'}" style="color:#e76a8d;background-color:rgba(231,106,141,.15)"><i class="nexmoefont icon-zhihu"></i></a><a class="mdui-ripple" href="https://github.com/OneJane" target="_blank" mdui-tooltip="{content: 'GitHub'}" style="color:#191717;background-color:rgba(25,23,23,.15)"><i class="nexmoefont icon-github"></i></a></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">文章分类</h3><div class="nexmoe-widget"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/人工智能/">人工智能</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/定时器/">定时器</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/持续集成/">持续集成</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/注册中心/">注册中心</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/测试/">测试</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/系统/">系统</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/自然语言处理/">自然语言处理</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目实战/">项目实战</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/高可用/">高可用</a><span class="category-list-count">4</span></li></ul></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">标签云</h3><div class="nexmoe-widget tagcloud"> <a href="/tags/Gensim/" style="font-size:10px">Gensim</a> <a href="/tags/Hanlp/" style="font-size:10px">Hanlp</a> <a href="/tags/NLTK/" style="font-size:10px">NLTK</a> <a href="/tags/OpenCV/" style="font-size:12.86px">OpenCV</a> <a href="/tags/Stanford-NLP/" style="font-size:10px">Stanford NLP</a> <a href="/tags/Tensorflow/" style="font-size:15.71px">Tensorflow</a> <a href="/tags/ant-design/" style="font-size:10px">ant design</a> <a href="/tags/ant-design-pro/" style="font-size:11.43px">ant design pro</a> <a href="/tags/auc/" style="font-size:10px">auc</a> <a href="/tags/bottle/" style="font-size:10px">bottle</a> <a href="/tags/chatterbot/" style="font-size:10px">chatterbot</a> <a href="/tags/cnn/" style="font-size:12.86px">cnn</a> <a href="/tags/crf/" style="font-size:12.86px">crf</a> <a href="/tags/doc2vec/" style="font-size:10px">doc2vec</a> <a href="/tags/docker/" style="font-size:17.14px">docker</a> <a href="/tags/dubbo/" style="font-size:11.43px">dubbo</a> <a href="/tags/elasticsearch/" style="font-size:10px">elasticsearch</a> <a href="/tags/elastisearch/" style="font-size:10px">elastisearch</a> <a href="/tags/email/" style="font-size:10px">email</a> <a href="/tags/es6/" style="font-size:10px">es6</a> <a href="/tags/feign/" style="font-size:10px">feign</a> <a href="/tags/flask/" style="font-size:11.43px">flask</a> <a href="/tags/folium/" style="font-size:10px">folium</a> <a href="/tags/freemarker/" style="font-size:10px">freemarker</a> <a href="/tags/function/" style="font-size:10px">function</a> <a href="/tags/gateway/" style="font-size:10px">gateway</a> <a href="/tags/gensim/" style="font-size:11.43px">gensim</a> <a href="/tags/gitlab/" style="font-size:11.43px">gitlab</a> <a href="/tags/gru/" style="font-size:11.43px">gru</a> <a href="/tags/hanlp/" style="font-size:11.43px">hanlp</a> <a href="/tags/haproxy/" style="font-size:10px">haproxy</a> <a href="/tags/hmm/" style="font-size:10px">hmm</a> <a href="/tags/jenkins/" style="font-size:11.43px">jenkins</a> <a href="/tags/jieba/" style="font-size:15.71px">jieba</a> <a href="/tags/jmeter/" style="font-size:10px">jmeter</a> <a href="/tags/keepalived/" style="font-size:10px">keepalived</a> <a href="/tags/lda/" style="font-size:11.43px">lda</a> <a href="/tags/linux/" style="font-size:10px">linux</a> <a href="/tags/lstm/" style="font-size:12.86px">lstm</a> <a href="/tags/maven/" style="font-size:11.43px">maven</a> <a href="/tags/multi-druid/" style="font-size:10px">multi druid</a> <a href="/tags/mybatis/" style="font-size:10px">mybatis</a> <a href="/tags/mybatisplus/" style="font-size:10px">mybatisplus</a> <a href="/tags/mysql/" style="font-size:10px">mysql</a> <a href="/tags/n-gram/" style="font-size:10px">n-gram</a> <a href="/tags/nacos/" style="font-size:11.43px">nacos</a> <a href="/tags/neo4j/" style="font-size:11.43px">neo4j</a> <a href="/tags/nexmoe/" style="font-size:10px">nexmoe</a> <a href="/tags/nlp/" style="font-size:20px">nlp</a> <a href="/tags/numpy/" style="font-size:10px">numpy</a> <a href="/tags/partition/" style="font-size:10px">partition</a> <a href="/tags/procedure/" style="font-size:10px">procedure</a> <a href="/tags/pxc/" style="font-size:10px">pxc</a> <a href="/tags/pyhanlp/" style="font-size:11.43px">pyhanlp</a> <a href="/tags/python/" style="font-size:10px">python</a> <a href="/tags/rabbitmq/" style="font-size:10px">rabbitmq</a> <a href="/tags/react/" style="font-size:11.43px">react</a> <a href="/tags/redis/" style="font-size:11.43px">redis</a> <a href="/tags/redis-cluster/" style="font-size:10px">redis-cluster</a> <a href="/tags/replication/" style="font-size:11.43px">replication</a> <a href="/tags/rnn/" style="font-size:10px">rnn</a> <a href="/tags/rocketmq/" style="font-size:11.43px">rocketmq</a> <a href="/tags/scrapy/" style="font-size:12.86px">scrapy</a> <a href="/tags/selenium/" style="font-size:12.86px">selenium</a> <a href="/tags/sentinel/" style="font-size:14.29px">sentinel</a> <a href="/tags/seq2seq/" style="font-size:10px">seq2seq</a> <a href="/tags/session/" style="font-size:10px">session</a> <a href="/tags/sklearn/" style="font-size:10px">sklearn</a> <a href="/tags/skywalking/" style="font-size:11.43px">skywalking</a> <a href="/tags/snownlp/" style="font-size:10px">snownlp</a> <a href="/tags/spring-cloud-alibaba/" style="font-size:18.57px">spring cloud alibaba</a> <a href="/tags/springboot/" style="font-size:14.29px">springboot</a> <a href="/tags/svm/" style="font-size:10px">svm</a> <a href="/tags/swagger/" style="font-size:10px">swagger</a> <a href="/tags/textrank/" style="font-size:10px">textrank</a> <a href="/tags/tf-idf/" style="font-size:12.86px">tf-idf</a> <a href="/tags/tk-mybatis/" style="font-size:10px">tk mybatis</a> <a href="/tags/umi/" style="font-size:10px">umi</a> <a href="/tags/validate/" style="font-size:10px">validate</a> <a href="/tags/word2vec/" style="font-size:10px">word2vec</a> <a href="/tags/wordcloud/" style="font-size:10px">wordcloud</a> <a href="/tags/xxl-job/" style="font-size:11.43px">xxl-job</a> <a href="/tags/zookeeper/" style="font-size:10px">zookeeper</a></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">文章归档</h3><div class="nexmoe-widget"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li></ul></div></div></aside><div class="nexmoe-copyright"> &copy; 2019 OneJane</div></div></div><div id="nexmoe-content"><div class="nexmoe-primary"><div class="nexmoe-post"><div class="nexmoe-post-cover"> <img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388570600.png"><h1>吴恩达深度学习笔记(第二课时)</h1></div><div class="nexmoe-post-meta"><a><i class="nexmoefont icon-calendar-fill"></i> 2019年12月05日</a><a><i class="nexmoefont icon-areachart"></i> 58.1k 字</a><a><i class="nexmoefont icon-time-circle-fill"></i> 大概 245 分钟</a> <a class="nexmoefont icon-appstore-fill -link" href="/categories/人工智能/">人工智能</a> <a class="nexmoefont icon-tag-fill -link" href="/tags/nlp/">nlp</a></div><article><p><a href="https://onejane.github.io/">吴恩达深度学习笔记</a></p><a id="more"></a><h1 id="改善深层神经网络：超参数调试、正则化以及优化-Improving-Deep-Neural-Networks-Hyperparameter-tuning-Regularization-and-Optimization"><a href="#改善深层神经网络：超参数调试、正则化以及优化-Improving-Deep-Neural-Networks-Hyperparameter-tuning-Regularization-and-Optimization" class="headerlink" title="改善深层神经网络：超参数调试、正则化以及优化(Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)"></a>改善深层神经网络：超参数调试、正则化以及优化(Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)</h1><h2 id="第一周：深度学习的实践层面-Practical-aspects-of-Deep-Learning"><a href="#第一周：深度学习的实践层面-Practical-aspects-of-Deep-Learning" class="headerlink" title="第一周：深度学习的实践层面(Practical aspects of Deep Learning)"></a>第一周：深度学习的实践层面(Practical aspects of Deep Learning)</h2><h3 id="1-1-训练，验证，测试集（Train-Dev-Test-sets）"><a href="#1-1-训练，验证，测试集（Train-Dev-Test-sets）" class="headerlink" title="1.1 训练，验证，测试集（Train / Dev / Test sets）"></a>1.1 训练，验证，测试集（Train / Dev / Test sets）</h3><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_1.png" alt="L2_week1_1"><br>大家可能已经了解了，那么本周，我们将继续学习如何有效运作神经网络，内容涉及超参数调优，如何构建数据，以及如何确保优化算法快速运行，从而使学习算法在合理时间内完成自我学习。</p><p>第一周，我们首先说说神经网络机器学习中的问题，然后是随机神经网络，还会学习一些确保神经网络正确运行的技巧，带着这些问题，我们开始今天的课程。</p><p>在配置训练、验证和测试数据集的过程中做出正确决策会在很大程度上帮助大家创建高效的神经网络。训练神经网络时，我们需要做出很多决策，例如：</p><ol><li><p>神经网络分多少层</p></li><li><p>每层含有多少个隐藏单元</p></li><li><p>学习速率是多少</p></li><li><p>各层采用哪些激活函数</p></li></ol><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_2.png" alt="L2_week1_2"><br>创建新应用的过程中，我们不可能从一开始就准确预测出这些信息和其他超级参数。实际上，应用型机器学习是一个高度迭代的过程，通常在项目启动时，我们会先有一个初步想法，比如构建一个含有特定层数，隐藏单元数量或数据集个数等等的神经网络，然后编码，并尝试运行这些代码，通过运行和测试得到该神经网络或这些配置信息的运行结果，你可能会根据输出结果重新完善自己的想法，改变策略，或者为了找到更好的神经网络不断迭代更新自己的方案。</p><p>现如今，深度学习已经在自然语言处理，计算机视觉，语音识别以及结构化数据应用等众多领域取得巨大成功。结构化数据无所不包，从广告到网络搜索。其中网络搜索不仅包括网络搜索引擎，还包括购物网站，从所有根据搜索栏词条传输结果的网站。再到计算机安全，物流，比如判断司机去哪接送货，范围之广，不胜枚举。</p><p>我发现，可能有自然语言处理方面的人才想踏足计算机视觉领域，或者经验丰富的语音识别专家想投身广告行业，又或者，有的人想从电脑安全领域跳到物流行业，在我看来，从一个领域或者应用领域得来的直觉经验，通常无法转移到其他应用领域，最佳决策取决于你所拥有的数据量，计算机配置中输入特征的数量，用<strong>GPU</strong>训练还是<strong>CPU</strong>，<strong>GPU</strong>和<strong>CPU</strong>的具体配置以及其他诸多因素。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/97596da07232f85d566710ee7dd2f8ad.png" alt="97596da07232f85d566710ee7dd2f8ad"><br>目前为止，我觉得，对于很多应用系统，即使是经验丰富的深度学习行家也不太可能一开始就预设出最匹配的超级参数，所以说，应用深度学习是一个典型的迭代过程，需要多次循环往复，才能为应用程序找到一个称心的神经网络，因此循环该过程的效率是决定项目进展速度的一个关键因素，而创建高质量的训练数据集，验证集和测试集也有助于提高循环效率。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/072653e2e9402d2857bfcb7b9f783a5c.png" alt="072653e2e9402d2857bfcb7b9f783a5c"><br>假设这是训练数据，我用一个长方形表示，我们通常会将这些数据划分成几部分，一部分作为训练集，一部分作为简单交叉验证集，有时也称之为验证集，方便起见，我就叫它验证集（<strong>dev set</strong>），其实都是同一个概念，最后一部分则作为测试集。</p><p>接下来，我们开始对训练集执行算法，通过验证集或简单交叉验证集选择最好的模型，经过充分验证，我们选定了最终模型，然后就可以在测试集上进行评估了，为了无偏评估算法的运行状况。</p><p>在机器学习发展的小数据量时代，常见做法是将所有数据三七分，就是人们常说的70%训练集，30%测试集。如果明确设置了验证集，也可以按照60%训练集，20%验证集和20%测试集来划分。这是前几年机器学习领域普遍认可的最好的实践方法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ebbfb8514ff5a983f41e938d5870b79d.png" alt="ebbfb8514ff5a983f41e938d5870b79d"><br>如果只有100条，1000条或者1万条数据，那么上述比例划分是非常合理的。</p><p>但是在大数据时代，我们现在的数据量可能是百万级别，那么验证集和测试集占数据总量的比例会趋向于变得更小。因为验证集的目的就是验证不同的算法，检验哪种算法更有效，因此，验证集只要足够大到能评估不同的算法，比如2个甚至10个不同算法，并迅速判断出哪种算法更有效。我们可能不需要拿出20%的数据作为验证集。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1224fb0922d5673c380e6dad9ded0b6b.png" alt="1224fb0922d5673c380e6dad9ded0b6b"><br>比如我们有100万条数据，那么取1万条数据便足以进行评估，找出其中表现最好的1-2种算法。同样地，根据最终选择的分类器，测试集的主要目的是正确评估分类器的性能，所以，如果拥有百万数据，我们只需要1000条数据，便足以评估单个分类器，并且准确评估该分类器的性能。假设我们有100万条数据，其中1万条作为验证集，1万条作为测试集，100万里取1万，比例是1%，即：训练集占98%，验证集和测试集各占1%。对于数据量过百万的应用，训练集可以占到99.5%，验证和测试集各占0.25%，或者验证集占0.4%，测试集占0.1%。</p><p>总结一下，在机器学习中，我们通常将样本分成训练集，验证集和测试集三部分，数据集规模相对较小，适用传统的划分比例，数据集规模较大的，验证集和测试集要小于数据总量的20%或10%。后面我会给出如何划分验证集和测试集的具体指导。</p><p>现代深度学习的另一个趋势是越来越多的人在训练和测试集分布不匹配的情况下进行训练，假设你要构建一个用户可以上传大量图片的应用程序，目的是找出并呈现所有猫咪图片，可能你的用户都是爱猫人士，训练集可能是从网上下载的猫咪图片，而验证集和测试集是用户在这个应用上上传的猫的图片，就是说，训练集可能是从网络上抓下来的图片。而验证集和测试集是用户上传的图片。结果许多网页上的猫咪图片分辨率很高，很专业，后期制作精良，而用户上传的照片可能是用手机随意拍摄的，像素低，比较模糊，这两类数据有所不同，针对这种情况，根据经验，我建议大家要确保验证集和测试集的数据来自同一分布，关于这个问题我也会多讲一些。因为你们要用验证集来评估不同的模型，尽可能地优化性能。如果验证集和测试集来自同一个分布就会很好。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/459ffc8998b35b259bc3bab4fd4fb44c.png" alt="459ffc8998b35b259bc3bab4fd4fb44c"><br>但由于深度学习算法需要大量的训练数据，为了获取更大规模的训练数据集，我们可以采用当前流行的各种创意策略，例如，网页抓取，代价就是训练集数据与验证集和测试集数据有可能不是来自同一分布。但只要遵循这个经验法则，你就会发现机器学习算法会变得更快。我会在后面的课程中更加详细地解释这条经验法则。</p><p>最后一点，就算没有测试集也不要紧，测试集的目的是对最终所选定的神经网络系统做出无偏估计，如果不需要无偏估计，也可以不设置测试集。所以如果只有验证集，没有测试集，我们要做的就是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估。当然，如果你不需要无偏估计，那就再好不过了。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/658fc77a1ea588d5768dcd1a9a90761a.png" alt="658fc77a1ea588d5768dcd1a9a90761a"><br>在机器学习中，如果只有一个训练集和一个验证集，而没有独立的测试集，遇到这种情况，训练集还被人们称为训练集，而验证集则被称为测试集，不过在实际应用中，人们只是把测试集当成简单交叉验证集使用，并没有完全实现该术语的功能，因为他们把验证集数据过度拟合到了测试集中。如果某团队跟你说他们只设置了一个训练集和一个测试集，我会很谨慎，心想他们是不是真的有训练验证集，因为他们把验证集数据过度拟合到了测试集中，让这些团队改变叫法，改称其为“训练验证集”，而不是“训练测试集”，可能不太容易。即便我认为“训练验证集“在专业用词上更准确。实际上，如果你不需要无偏评估算法性能，那么这样是可以的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/02556a7f525c0ec016483644755c2231.png" alt="02556a7f525c0ec016483644755c2231"><br>所以说，搭建训练验证集和测试集能够加速神经网络的集成，也可以更有效地衡量算法地偏差和方差，从而帮助我们更高效地选择合适方法来优化算法。</p><h3 id="1-2-偏差，方差（Bias-Variance）"><a href="#1-2-偏差，方差（Bias-Variance）" class="headerlink" title="1.2 偏差，方差（Bias /Variance）"></a>1.2 偏差，方差（Bias /Variance）</h3><p>我注意到，几乎所有机器学习从业人员都期望深刻理解偏差和方差，这两个概念易学难精，即使你自己认为已经理解了偏差和方差的基本概念，却总有一些意想不到的新东西出现。关于深度学习的误差问题，另一个趋势是对偏差和方差的权衡研究甚浅，你可能听说过这两个概念，但深度学习的误差很少权衡二者，我们总是分别考虑偏差和方差，却很少谈及偏差和方差的权衡问题，下面我们来一探究竟。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e0ec4205933b7c2a9eaed9fbaa8d4afc.png" alt="e0ec4205933b7c2a9eaed9fbaa8d4afc"><br>假设这就是数据集，如果给这个数据集拟合一条直线，可能得到一个逻辑回归拟合，但它并不能很好地拟合该数据，这是高偏差（<strong>high bias</strong>）的情况，我们称为“欠拟合”（<strong>underfitting</strong>）。</p><p>相反的如果我们拟合一个非常复杂的分类器，比如深度神经网络或含有隐藏单元的神经网络，可能就非常适用于这个数据集，但是这看起来也不是一种很好的拟合方式分类器方差较高（<strong>high variance</strong>），数据过度拟合（<strong>overfitting</strong>）。</p><p>在两者之间，可能还有一些像图中这样的，复杂程度适中，数据拟合适度的分类器，这个数据拟合看起来更加合理，我们称之为“适度拟合”（<strong>just right</strong>）是介于过度拟合和欠拟合中间的一类。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/05ac08b96177b5d0aaae7b7bfea64f3a.png" alt="05ac08b96177b5d0aaae7b7bfea64f3a"><br>在这样一个只有$x_1$和$x_2$两个特征的二维数据集中，我们可以绘制数据，将偏差和方差可视化。在多维空间数据中，绘制数据和可视化分割边界无法实现，但我们可以通过几个指标，来研究偏差和方差。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2efd9728b5f07f914903dde309167a5d.png" alt="2efd9728b5f07f914903dde309167a5d"><br>我们沿用猫咪图片分类这个例子，左边一张是猫咪图片，右边一张不是。理解偏差和方差的两个关键数据是训练集误差（<strong>Train set error</strong>）和验证集误差（<strong>Dev set error</strong>），为了方便论证，假设我们可以辨别图片中的小猫，我们用肉眼识别几乎是不会出错的。</p><p>假定训练集误差是1%，为了方便论证，假定验证集误差是11%，可以看出训练集设置得非常好，而验证集设置相对较差，我们可能过度拟合了训练集，在某种程度上，验证集并没有充分利用交叉验证集的作用，像这种情况，我们称之为“高方差”。</p><p>通过查看训练集误差和验证集误差，我们便可以诊断算法是否具有高方差。也就是说衡量训练集和验证集误差就可以得出不同结论。</p><p>假设训练集误差是15%，我们把训练集误差写在首行，验证集误差是16%，假设该案例中人的错误率几乎为0%，人们浏览这些图片，分辨出是不是猫。算法并没有在训练集中得到很好训练，如果训练数据的拟合度不高，就是数据欠拟合，就可以说这种算法偏差比较高。相反，它对于验证集产生的结果却是合理的，验证集中的错误率只比训练集的多了1%，所以这种算法偏差高，因为它甚至不能拟合训练集，这与上一张幻灯片最左边的图片相似。</p><p>再举一个例子，训练集误差是15%，偏差相当高，但是，验证集的评估结果更糟糕，错误率达到30%，在这种情况下，我会认为这种算法偏差高，因为它在训练集上结果不理想，而且方差也很高，这是方差偏差都很糟糕的情况。</p><p>再看最后一个例子，训练集误差是0.5%，验证集误差是1%，用户看到这样的结果会很开心，猫咪分类器只有1%的错误率，偏差和方差都很低。</p><p>有一点我先在这个简单提一下，具体的留在后面课程里讲，这些分析都是基于假设预测的，假设人眼辨别的错误率接近0%，一般来说，最优误差也被称为贝叶斯误差，所以，最优误差接近0%，我就不在这里细讲了，如果最优误差或贝叶斯误差非常高，比如15%。我们再看看这个分类器（训练误差15%，验证误差16%），15%的错误率对训练集来说也是非常合理的，偏差不高，方差也非常低。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c61d149beecddb96f0f93944320cf639.png" alt="c61d149beecddb96f0f93944320cf639"><br>当所有分类器都不适用时，如何分析偏差和方差呢？比如，图片很模糊，即使是人眼，或者没有系统可以准确无误地识别图片，在这种情况下，最优误差会更高，那么分析过程就要做些改变了，我们暂时先不讨论这些细微差别，重点是通过查看训练集误差，我们可以判断数据拟合情况，至少对于训练数据是这样，可以判断是否有偏差问题，然后查看错误率有多高。当完成训练集训练，开始使用验证集验证时，我们可以判断方差是否过高，从训练集到验证集的这个过程中，我们可以判断方差是否过高。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fcdc2a7afbaaa07ca08b078bb4d37e8d.png" alt="fcdc2a7afbaaa07ca08b078bb4d37e8d"><br>以上分析的前提都是假设基本误差很小，训练集和验证集数据来自相同分布，如果没有这些假设作为前提，分析过程更加复杂，我们将会在稍后课程里讨论。</p><p>上一张幻灯片，我们讲了高偏差和高方差的情况，大家应该对优质分类器有了一定的认识，偏差和方差都高是什么样子呢？这种情况对于两个衡量标准来说都是非常糟糕的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8fdbf9ed01b8634573125e0fb2ca860.png" alt="f8fdbf9ed01b8634573125e0fb2ca860"><br>我们之前讲过，这样的分类器，会产生高偏差，因为它的数据拟合度低，像这种接近线性的分类器，数据拟合度低。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e9451f36e8baa41b74c95d9a09b0f028.png" alt="e9451f36e8baa41b74c95d9a09b0f028"><br>但是如果我们稍微改变一下分类器，我用紫色笔画出，它会过度拟合部分数据，用紫色线画出的分类器具有高偏差和高方差，偏差高是因为它几乎是一条线性分类器，并未拟合数据。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6e86aa7d9b21b1a49bf4a084c7503527.png" alt="6e86aa7d9b21b1a49bf4a084c7503527"><br>这种二次曲线能够很好地拟合数据。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/67dc5997a956314e238e6fc362f9883d.png" alt="67dc5997a956314e238e6fc362f9883d"><br>这条曲线中间部分灵活性非常高，却过度拟合了这两个样本，这类分类器偏差很高，因为它几乎是线性的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6bf7e092ddf93104ea64a5ddecbb7c6d.png" alt="6bf7e092ddf93104ea64a5ddecbb7c6d"><br>而采用曲线函数或二次元函数会产生高方差，因为它曲线灵活性太高以致拟合了这两个错误样本和中间这些活跃数据。</p><p>这看起来有些不自然，从两个维度上看都不太自然，但对于高维数据，有些数据区域偏差高，有些数据区域方差高，所以在高维数据中采用这种分类器看起来就不会那么牵强了。</p><p>总结一下，我们讲了如何通过分析在训练集上训练算法产生的误差和验证集上验证算法产生的误差来诊断算法是否存在高偏差和高方差，是否两个值都高，或者两个值都不高，根据算法偏差和方差的具体情况决定接下来你要做的工作，下节课，我会根据算法偏差和方差的高低情况讲解一些机器学习的基本方法，帮助大家更系统地优化算法，我们下节课见。</p><h3 id="1-3-机器学习基础（Basic-Recipe-for-Machine-Learning）"><a href="#1-3-机器学习基础（Basic-Recipe-for-Machine-Learning）" class="headerlink" title="1.3 机器学习基础（Basic Recipe for Machine Learning）"></a>1.3 机器学习基础（Basic Recipe for Machine Learning）</h3><p>上节课我们讲的是如何通过训练误差和验证集误差判断算法偏差或方差是否偏高，帮助我们更加系统地在机器学习中运用这些方法来优化算法性能。</p><p>下图就是我在训练神经网络用到的基本方法：（尝试这些方法，可能有用，可能没用）</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_8.png" alt="L2_week1_8"><br>这是我在训练神经网络时用到地基本方法，初始模型训练完成后，我首先要知道算法的偏差高不高，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至无法拟合训练集，那么你要做的就是选择一个新的网络，比如含有更多隐藏层或者隐藏单元的网络，或者花费更多时间来训练网络，或者尝试更先进的优化算法，后面我们会讲到这部分内容。你也可以尝试其他方法，可能有用，也可能没用。</p><p>一会儿我们会看到许多不同的神经网络架构，或许你能找到一个更合适解决此问题的新的网络架构，加上括号，因为其中一条就是你必须去尝试，可能有用，也可能没用，不过采用规模更大的网络通常都会有所帮助，延长训练时间不一定有用，但也没什么坏处。训练学习算法时，我会不断尝试这些方法，直到解决掉偏差问题，这是最低标准，反复尝试，直到可以拟合数据为止，至少能够拟合训练集。</p><p>如果网络足够大，通常可以很好的拟合训练集，只要你能扩大网络规模，如果图片很模糊，算法可能无法拟合该图片，但如果有人可以分辨出图片，如果你觉得基本误差不是很高，那么训练一个更大的网络，你就应该可以……至少可以很好地拟合训练集，至少可以拟合或者过拟合训练集。一旦偏差降低到可以接受的数值，检查一下方差有没有问题，为了评估方差，我们要查看验证集性能，我们能从一个性能理想的训练集推断出验证集的性能是否也理想，如果方差高，最好的解决办法就是采用更多数据，如果你能做到，会有一定的帮助，但有时候，我们无法获得更多数据，我们也可以尝试通过正则化来减少过拟合，这个我们下节课会讲。有时候我们不得不反复尝试，但是，如果能找到更合适的神经网络框架，有时它可能会一箭双雕，同时减少方差和偏差。如何实现呢？想系统地说出做法很难，总之就是不断重复尝试，直到找到一个低偏差，低方差的框架，这时你就成功了。</p><p>有两点需要大家注意：</p><p>第一点，高偏差和高方差是两种不同的情况，我们后续要尝试的方法也可能完全不同，我通常会用训练验证集来诊断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方法。举个例子，如果算法存在高偏差问题，准备更多训练数据其实也没什么用处，至少这不是更有效的方法，所以大家要清楚存在的问题是偏差还是方差，还是两者都有问题，明确这一点有助于我们选择出最有效的方法。</p><p>第二点，在机器学习的初期阶段，关于所谓的偏差方差权衡的讨论屡见不鲜，原因是我们能尝试的方法有很多。可以增加偏差，减少方差，也可以减少偏差，增加方差，但是在深度学习的早期阶段，我们没有太多工具可以做到只减少偏差或方差却不影响到另一方。但在当前的深度学习和大数据时代，只要持续训练一个更大的网络，只要准备了更多数据，那么也并非只有这两种情况，我们假定是这样，那么，只要正则适度，通常构建一个更大的网络便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。这两步实际要做的工作是：训练网络，选择网络或者准备更多数据，现在我们有工具可以做到在减少偏差或方差的同时，不对另一方产生过多不良影响。我觉得这就是深度学习对监督式学习大有裨益的一个重要原因，也是我们不用太过关注如何平衡偏差和方差的一个重要原因，但有时我们有很多选择，减少偏差或方差而不增加另一方。最终，我们会得到一个非常规范化的网络。从下节课开始，我们将讲解正则化，训练一个更大的网络几乎没有任何负面影响，而训练一个大型神经网络的主要代价也只是计算时间，前提是网络是比较规范化的。</p><p>今天我们讲了如何通过组织机器学习来诊断偏差和方差的基本方法，然后选择解决问题的正确操作，希望大家有所了解和认识。我在课上不止一次提到了正则化，它是一种非常实用的减少方差的方法，正则化时会出现偏差方差权衡问题，偏差可能略有增加，如果网络足够大，增幅通常不会太高，我们下节课再细讲，以便大家更好理解如何实现神经网络的正则化。</p><h3 id="1-4-正则化（Regularization）"><a href="#1-4-正则化（Regularization）" class="headerlink" title="1.4 正则化（Regularization）"></a>1.4 正则化（Regularization）</h3><p>深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。</p><p>如果你怀疑神经网络过度拟合了数据，即存在高方差问题，那么最先想到的方法可能是正则化，另一个解决高方差的方法就是准备更多数据，这也是非常可靠的办法，但你可能无法时时准备足够多的训练数据，或者，获取更多数据的成本很高，但正则化有助于避免过度拟合，或者减少网络误差，下面我们就来讲讲正则化的作用原理。</p><p>我们用逻辑回归来实现这些设想，求成本函数$J$的最小值，它是我们定义的成本函数，参数包含一些训练数据和不同数据中个体预测的损失，$w$和$b$是逻辑回归的两个参数，$w$是一个多维度参数矢量，$b$是一个实数。在逻辑回归函数中加入正则化，只需添加参数λ，也就是正则化参数，一会儿再详细讲。</p> $\frac{\lambda}{2m}$乘以$w$范数的平方，其中$\left\| w \right\|_2^2$是$w$的欧几里德范数的平方，等于$w_{j}$（$j$ 值从1到$n_{x}$）平方的和，也可表示为$w^{T}w$，也就是向量参数$w$ 的欧几里德范数（2范数）的平方，此方法称为$L2$正则化，因为这里用了欧几里德范数，被称为向量参数$w$的$L2$范数。<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fa185e95684bbe6c0e9100164aff2ee5.png" alt="fa185e95684bbe6c0e9100164aff2ee5"><br>为什么只正则化参数$w$？为什么不再加上参数 $b$ 呢？你可以这么做，只是我习惯省略不写，因为$w$通常是一个高维参数矢量，已经可以表达高偏差问题，$w$可能包含有很多参数，我们不可能拟合所有参数，而$b$只是单个数字，所以$w$几乎涵盖所有参数，而不是$b$，如果加了参数$b$，其实也没太大影响，因为$b$只是众多参数中的一个，所以我通常省略不计，如果你想加上这个参数，完全没问题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/84c4e19130a91a09120087dd704bbaa4.png" alt="84c4e19130a91a09120087dd704bbaa4"></p> $L2$正则化是最常见的正则化类型，你们可能听说过$L1$正则化，$L1$正则化，加的不是$L2$范数，而是正则项$\frac{\lambda}{m}$乘以$\sum_{j= 1}^{n_{x} }{|w|}$，$\sum_{j =1}^{n_{x} }{|w|}$也被称为参数$w$向量的$L1$范数，无论分母是$m$还是$2m$，它都是一个比例常量。<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5190dbc5a98db7a248499f54a04257cc.png" alt="5190dbc5a98db7a248499f54a04257cc"><br>如果用的是$L1$正则化，$w$最终会是稀疏的，也就是说$w$向量中有很多0，有人说这样有利于压缩模型，因为集合中参数均为0，存储模型所占用的内存更少。实际上，虽然$L1$正则化使模型变得稀疏，却没有降低太多存储内存，所以我认为这并不是$L1$正则化的目的，至少不是为了压缩模型，人们在训练网络时，越来越倾向于使用$L2$正则化。</p><p>我们来看最后一个细节，$\lambda$是正则化参数，我们通常使用验证集或交叉验证集来配置这个参数，尝试各种各样的数据，寻找最好的参数，我们要考虑训练集之间的权衡，把参数设置为较小值，这样可以避免过拟合，所以λ是另外一个需要调整的超级参数，顺便说一下，为了方便写代码，在<strong>Python</strong>编程语言中，$\lambda$是一个保留字段，编写代码时，我们删掉$a$，写成$lambd$，以免与<strong>Python</strong>中的保留字段冲突，这就是在逻辑回归函数中实现$L2$正则化的过程，如何在神经网络中实现$L2$正则化呢？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e88bd6f30a8ff8014d6d7dbe6d0488a.png" alt="2e88bd6f30a8ff8014d6d7dbe6d0488a"><br>神经网络含有一个成本函数，该函数包含$W^{[1]}$，$b^{[1]}$到$W^{[l]}$，$b^{[l]}$所有参数，字母$L$是神经网络所含的层数，因此成本函数等于$m$个训练样本损失函数的总和乘以$\frac{1}{m}$，正则项为$\frac{\lambda }{2m}{ {\sum\nolimits_{1}^{L}{| { {W}^{[l]} }|} }^{2} }$，我们称${||W^{\left[l\right]}||}^{2}$为范数平方，这个矩阵范数${||W^{\left[l\right]}||}^{2}$（即平方范数），被定义为矩阵中所有元素的平方求和，</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a8336b2cfeed4128a23f20fab843d226.png" alt="a8336b2cfeed4128a23f20fab843d226"><br>我们看下求和公式的具体参数，第一个求和符号其值$i$从1到$n^{[l - 1]}$，第二个其$J$值从1到$n^{[l]}$，因为$W$是一个$n^{[l]}\times n^{[l-1]}$的多维矩阵，$n^{[l]}$表示$l$ 层单元的数量，$n^{[l-1]}$表示第$l-1$层隐藏单元的数量。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5663bd9360df02b7e5a04c01d4e1bbc7.png" alt="5663bd9360df02b7e5a04c01d4e1bbc7"><br>该矩阵范数被称作“弗罗贝尼乌斯范数”，用下标$F$标注”，鉴于线性代数中一些神秘晦涩的原因，我们不称之为“矩阵$L2$范数”，而称它为“弗罗贝尼乌斯范数”，矩阵$L2$范数听起来更自然，但鉴于一些大家无须知道的特殊原因，按照惯例，我们称之为“弗罗贝尼乌斯范数”，它表示一个矩阵中所有元素的平方和。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dffec3cca0e523e22646704e5e76c39a.png" alt="dffec3cca0e523e22646704e5e76c39a"><br>该如何使用该范数实现梯度下降呢？</p><p>用<strong>backprop</strong>计算出$dW$的值，<strong>backprop</strong>会给出$J$对$W$的偏导数，实际上是$ W^{[l]}$，把$W^{[l]}$替换为$W^{[l]}$减去学习率乘以$dW$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b6856a371ed552fd6b9ada2068ab4c2c.png" alt="b6856a371ed552fd6b9ada2068ab4c2c"><br>这就是之前我们额外增加的正则化项，既然已经增加了这个正则项，现在我们要做的就是给$dW$加上这一项$\frac {\lambda}{m}W^{[l]}$，然后计算这个更新项，使用新定义的$dW^{[l]}$，它的定义含有相关参数代价函数导数和，以及最后添加的额外正则项，这也是$L2$正则化有时被称为“权重衰减”的原因。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dafb163da5b9c3ece677a7ebce05b680.png" alt="dafb163da5b9c3ece677a7ebce05b680"><br>我们用$ dW^{[l]}$的定义替换此处的$dW^{[l]}$，可以看到，$W^{[l]}$的定义被更新为$W^{[l]}$减去学习率$\alpha$ 乘以<strong>backprop</strong> 再加上$\frac{\lambda}{m}W^{[l]}$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f752bc74e0978320a72bcb15d1777cf8.png" alt="f752bc74e0978320a72bcb15d1777cf8"><br>该正则项说明，不论$W^{[l]}$是什么，我们都试图让它变得更小，实际上，相当于我们给矩阵W乘以$(1 - \alpha\frac{\lambda}{m})$倍的权重，矩阵$W$减去$\alpha\frac{\lambda}{m}$倍的它，也就是用这个系数$(1-\alpha\frac{\lambda}{m})$乘以矩阵$W$，该系数小于1，因此$L2$范数正则化也被称为“权重衰减”，因为它就像一般的梯度下降，$W$被更新为少了$\alpha$乘以<strong>backprop</strong>输出的最初梯度值，同时$W$也乘以了这个系数，这个系数小于1，因此$L2$正则化也被称为“权重衰减”。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/cba0f1c7a480139acb04e762e4fe57f8.png" alt="cba0f1c7a480139acb04e762e4fe57f8"><br>我不打算这么叫它，之所以叫它“权重衰减”是因为这两项相等，权重指标乘以了一个小于1的系数。</p><p>以上就是在神经网络中应用$L2$正则化的过程，有人会问我，为什么正则化可以预防过拟合，我们放在下节课讲，同时直观感受一下正则化是如何预防过拟合的。</p><h3 id="1-5-为什么正则化有利于预防过拟合呢？（Why-regularization-reduces-overfitting-）"><a href="#1-5-为什么正则化有利于预防过拟合呢？（Why-regularization-reduces-overfitting-）" class="headerlink" title="1.5 为什么正则化有利于预防过拟合呢？（Why regularization reduces overfitting?）"></a>1.5 为什么正则化有利于预防过拟合呢？（Why regularization reduces overfitting?）</h3><p>为什么正则化有利于预防过拟合呢？为什么它可以减少方差问题？我们通过两个例子来直观体会一下。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/15d5607b8ac1c1fbaa023cb6060633f2.png" alt="15d5607b8ac1c1fbaa023cb6060633f2"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1a6c47e64293cde6a0facb3872701db2.png" alt="1a6c47e64293cde6a0facb3872701db2"><br>左图是高偏差，右图是高方差，中间是<strong>Just Right</strong>，这几张图我们在前面课程中看到过。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d5ee6f2b60ff7601d50967f4365d0ecb.png" alt="d5ee6f2b60ff7601d50967f4365d0ecb"><br>现在我们来看下这个庞大的深度拟合神经网络。我知道这张图不够大，深度也不够，但你可以想象这是一个过拟合的神经网络。这是我们的代价函数$J$，含有参数$W$，$b$。我们添加正则项，它可以避免数据权值矩阵过大，这就是弗罗贝尼乌斯范数，为什么压缩$L2$范数，或者弗罗贝尼乌斯范数或者参数可以减少过拟合？</p><p>直观上理解就是如果正则化$\lambda$设置得足够大，权重矩阵$W$被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。</p><p>但是$\lambda$会存在一个中间值，于是会有一个接近“<strong>Just Right</strong>”的中间状态。</p><p>直观理解就是$\lambda$增加到足够大，$W$会接近于0，实际上是不会发生这种情况的，我们尝试消除或至少减少许多隐藏单元的影响，最终这个网络会变得更简单，这个神经网络越来越接近逻辑回归，我们直觉上认为大量隐藏单元被完全消除了，其实不然，实际上是该神经网络的所有隐藏单元依然存在，但是它们的影响变得更小了。神经网络变得更简单了，貌似这样更不容易发生过拟合，因此我不确定这个直觉经验是否有用，不过在编程中执行正则化时，你实际看到一些方差减少的结果。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2aafa244c3f184cc271b26d1d95d70c9.png" alt="2aafa244c3f184cc271b26d1d95d70c9"><br>我们再来直观感受一下，正则化为什么可以预防过拟合，假设我们用的是这样的双曲线激活函数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f35d94efc03123e4a5de6496c1b896c0.png" alt="f35d94efc03123e4a5de6496c1b896c0"><br>用$g(z)$表示$tanh(z)$，我们发现如果 <em>z</em> 非常小，比如 <em>z</em> 只涉及很小范围的参数（图中原点附近的红色区域），这里我们利用了双曲正切函数的线性状态，只要$z$可以扩展为这样的更大值或者更小值，激活函数开始变得非线性。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/884d5768243f4badc77356f843cb8c0c.png" alt="884d5768243f4badc77356f843cb8c0c"><br>现在你应该摒弃这个直觉，如果正则化参数λ很大，激活函数的参数会相对较小，因为代价函数中的参数变大了，如果$W$很小，</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/63fa65e2609fe7a6909544247855d1a5.png" alt="63fa65e2609fe7a6909544247855d1a5"><br>如果$W$很小，相对来说，$z$也会很小。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fcdff0820223fb8a5756ad0bf99991fe.png" alt="fcdff0820223fb8a5756ad0bf99991fe"><br>特别是，如果$z$的值最终在这个范围内，都是相对较小的值，$g(z)$大致呈线性，每层几乎都是线性的，和线性回归函数一样。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8248be8e83121535b73969a4599fbb08.png" alt="8248be8e83121535b73969a4599fbb08"><br>第一节课我们讲过，如果每层都是线性的，那么整个网络就是一个线性网络，即使是一个非常深的深层网络，因具有线性激活函数的特征，最终我们只能计算线性函数，因此，它不适用于非常复杂的决策，以及过度拟合数据集的非线性决策边界，如同我们在幻灯片中看到的过度拟合高方差的情况。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/307675386a412e57cf60be3381f02a64.png" alt="307675386a412e57cf60be3381f02a64"><br>总结一下，如果正则化参数变得很大，参数$W$很小，$z$也会相对变小，此时忽略$b$的影响，$z$会相对变小，实际上，$z$的取值范围很小，这个激活函数，也就是曲线函数$tanh$会相对呈线性，整个神经网络会计算离线性函数近的值，这个线性函数非常简单，并不是一个极复杂的高度非线性函数，不会发生过拟合。</p><p>大家在编程作业里实现正则化的时候，会亲眼看到这些结果，总结正则化之前，我给大家一个执行方面的小建议，在增加正则化项时，应用之前定义的代价函数$J$，我们做过修改，增加了一项，目的是预防权重过大。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b84cc50eb967cd177007e21e93960b5c.png" alt="b84cc50eb967cd177007e21e93960b5c"><br>如果你使用的是梯度下降函数，在调试梯度下降时，其中一步就是把代价函数$J$设计成这样一个函数，在调试梯度下降时，它代表梯度下降的调幅数量。可以看到，代价函数对于梯度下降的每个调幅都单调递减。如果你实施的是正则化函数，请牢记，$J$已经有一个全新的定义。如果你用的是原函数$J$，也就是这第一个项正则化项，你可能看不到单调递减现象，为了调试梯度下降，请务必使用新定义的$J$函数，它包含第二个正则化项，否则函数$J$可能不会在所有调幅范围内都单调递减。</p><p>这就是$L2$正则化，它是我在训练深度学习模型时最常用的一种方法。在深度学习中，还有一种方法也用到了正则化，就是<strong>dropout</strong>正则化，我们下节课再讲。</p><h3 id="1-6-dropout-正则化（Dropout-Regularization）"><a href="#1-6-dropout-正则化（Dropout-Regularization）" class="headerlink" title="1.6 dropout 正则化（Dropout Regularization）"></a>1.6 dropout 正则化（Dropout Regularization）</h3><p>除了$L2$正则化，还有一个非常实用的正则化方法——“<strong>Dropout</strong>（随机失活）”，我们来看看它的工作原理。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/97e37bf0d2893f890561cda932ba8c42.png" alt="97e37bf0d2893f890561cda932ba8c42"><br>假设你在训练上图这样的神经网络，它存在过拟合，这就是<strong>dropout</strong>所要处理的，我们复制这个神经网络，<strong>dropout</strong>会遍历网络的每一层，并设置消除神经网络中节点的概率。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用<strong>backprop</strong>方法进行训练。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e45f9a948989b365650ddf16f62b097e.png" alt="e45f9a948989b365650ddf16f62b097e"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9fa7196adeeaf88eb386fda2e9fa9909.png" alt="9fa7196adeeaf88eb386fda2e9fa9909"><br>这是网络节点精简后的一个样本，对于其它样本，我们照旧以抛硬币的方式设置概率，保留一类节点集合，删除其它类型的节点集合。对于每个训练样本，我们都将采用一个精简后神经网络来训练它，这种方法似乎有点怪，单纯遍历节点，编码也是随机的，可它真的有效。不过可想而知，我们针对每个训练样本训练规模小得多的网络，最后你可能会认识到为什么要正则化网络，因为我们在训练规模小得多的网络。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/70b248490e496fed9b8d1d616e4d8303.png" alt="70b248490e496fed9b8d1d616e4d8303"><br>如何实施<strong>dropout</strong>呢？方法有几种，接下来我要讲的是最常用的方法，即<strong>inverted dropout</strong>（反向随机失活），出于完整性考虑，我们用一个三层（$l=3$）网络来举例说明。编码中会有很多涉及到3的地方。我只举例说明如何在某一层中实施<strong>dropout</strong>。</p><p>首先要定义向量$d$，$d^{[3]}$表示网络第三层的<strong>dropout</strong>向量：</p><p><code>d3 = np.random.rand(a3.shape[0],a3.shape[1])</code></p><p>然后看它是否小于某数，我们称之为<strong>keep-prob</strong>，<strong>keep-prob</strong>是一个具体数字，上个示例中它是0.5，而本例中它是0.8，它表示保留某个隐藏单元的概率，此处<strong>keep-prob</strong>等于0.8，它意味着消除任意一个隐藏单元的概率是0.2，它的作用就是生成随机矩阵，如果对$a^{[3]}$进行因子分解，效果也是一样的。$d^{[3]}$是一个矩阵，每个样本和每个隐藏单元，其中$d^{[3]}$中的对应值为1的概率都是0.8，对应为0的概率是0.2，随机数字小于0.8。它等于1的概率是0.8，等于0的概率是0.2。</p><p>接下来要做的就是从第三层中获取激活函数，这里我们叫它$a^{[3]}$，$a^{[3]}$含有要计算的激活函数，$a^{[3]}$等于上面的$a^{[3]}$乘以$d^{[3]}$，<code>a3 =np.multiply(a3,d3)</code>，这里是元素相乘，也可写为$a3*=d3$，它的作用就是让$d^{[3]}$中所有等于0的元素（输出），而各个元素等于0的概率只有20%，乘法运算最终把$d^{\left\lbrack3 \right]}$中相应元素输出，即让$d^{[3]}$中0元素与$a^{[3]}$中相对元素归零。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c75fe55c6bc17b60b00f5360aab180f4.png" alt="c75fe55c6bc17b60b00f5360aab180f4"><br>如果用<strong>python</strong>实现该算法的话，$d^{[3]}$则是一个布尔型数组，值为<strong>true</strong>和<strong>false</strong>，而不是1和0，乘法运算依然有效，<strong>python</strong>会把<strong>true</strong>和<strong>false</strong>翻译为1和0，大家可以用<strong>python</strong>尝试一下。</p><p>最后，我们向外扩展$a^{[3]}$，用它除以0.8，或者除以<strong>keep-prob</strong>参数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6ba17ffcb3ff22a4a0ec857e66946086.png" alt="6ba17ffcb3ff22a4a0ec857e66946086"><br>下面我解释一下为什么要这么做，为方便起见，我们假设第三隐藏层上有50个单元或50个神经元，在一维上$a^{[3]}$是50，我们通过因子分解将它拆分成$50×m$维的，保留和删除它们的概率分别为80%和20%，这意味着最后被删除或归零的单元平均有10（50×20%=10）个，现在我们看下$z^{\lbrack4]}$，$z^{[4]} = w^{[4]} a^{[3]} + b^{[4]}$，我们的预期是，$a^{[3]}$减少20%，也就是说$a^{[3]}$中有20%的元素被归零，为了不影响$z^{\lbrack4]}$的期望值，我们需要用$w^{[4]} a^{[3]}/0.8$，它将会修正或弥补我们所需的那20%，$a^{[3]}$的期望值不会变，划线部分就是所谓的<strong>dropout</strong>方法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/272d902720be9993454c6d9a5f0bec49.png" alt="272d902720be9993454c6d9a5f0bec49"><br>它的功能是，不论<strong>keep-prop</strong>的值是多少0.8，0.9甚至是1，如果<strong>keep-prop</strong>设置为1，那么就不存在<strong>dropout</strong>，因为它会保留所有节点。反向随机失活（<strong>inverted dropout</strong>）方法通过除以<strong>keep-prob</strong>，确保$a^{[3]}$的期望值不变。</p><p>事实证明，在测试阶段，当我们评估一个神经网络时，也就是用绿线框标注的反向随机失活方法，使测试阶段变得更容易，因为它的数据扩展问题变少，我们将在下节课讨论。</p><p>据我了解，目前实施<strong>dropout</strong>最常用的方法就是<strong>Inverted dropout</strong>，建议大家动手实践一下。<strong>Dropout</strong>早期的迭代版本都没有除以<strong>keep-prob</strong>，所以在测试阶段，平均值会变得越来越复杂，不过那些版本已经不再使用了。</p><p>现在你使用的是$d$向量，你会发现，不同的训练样本，清除不同的隐藏单元也不同。实际上，如果你通过相同训练集多次传递数据，每次训练数据的梯度不同，则随机对不同隐藏单元归零，有时却并非如此。比如，需要将相同隐藏单元归零，第一次迭代梯度下降时，把一些隐藏单元归零，第二次迭代梯度下降时，也就是第二次遍历训练集时，对不同类型的隐藏层单元归零。向量$d$或$d^{[3]}$用来决定第三层中哪些单元归零，无论用<strong>foreprop</strong>还是<strong>backprop</strong>，这里我们只介绍了<strong>foreprob</strong>。</p><p>如何在测试阶段训练算法，在测试阶段，我们已经给出了$x$，或是想预测的变量，用的是标准计数法。我用$a^{\lbrack0]}$，第0层的激活函数标注为测试样本$x$，我们在测试阶段不使用<strong>dropout</strong>函数，尤其是像下列情况：</p> $z^{[1]} = w^{[1]} a^{[0]} + b^{[1]}$ $a^{[1]} = g^{[1]}(z^{[1]})$ $z^{[2]} = \ w^{[2]} a^{[1]} + b^{[2]}$ $a^{[2]} = \ldots$<p>以此类推直到最后一层，预测值为$\hat{y}$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/de49d4e160f29544055819c5ab1dd9c0.png" alt="de49d4e160f29544055819c5ab1dd9c0"><br>显然在测试阶段，我们并未使用<strong>dropout</strong>，自然也就不用抛硬币来决定失活概率，以及要消除哪些隐藏单元了，因为在测试阶段进行预测时，我们不期望输出结果是随机的，如果测试阶段应用<strong>dropout</strong>函数，预测会受到干扰。理论上，你只需要多次运行预测处理过程，每一次，不同的隐藏单元会被随机归零，预测处理遍历它们，但计算效率低，得出的结果也几乎相同，与这个不同程序产生的结果极为相似。</p><p><strong>Inverted dropout</strong>函数在除以<strong>keep-prob</strong>时可以记住上一步的操作，目的是确保即使在测试阶段不执行<strong>dropout</strong>来调整数值范围，激活函数的预期结果也不会发生变化，所以没必要在测试阶段额外添加尺度参数，这与训练阶段不同。</p> $l=keep-prob$<p>这就是<strong>dropout</strong>，大家可以通过本周的编程练习来执行这个函数，亲身实践一下。</p><p>为什么<strong>dropout</strong>会起作用呢？下节课我们将更加直观地了解<strong>dropout</strong>的具体功能。</p><h3 id="1-7-理解-dropout（Understanding-Dropout）"><a href="#1-7-理解-dropout（Understanding-Dropout）" class="headerlink" title="1.7 理解 dropout（Understanding Dropout）"></a>1.7 理解 dropout（Understanding Dropout）</h3><p><strong>Dropout</strong>可以随机删除网络中的神经单元，他为什么可以通过正则化发挥如此大的作用呢？</p><p>直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，<strong>dropout</strong>将产生收缩权重的平方范数的效果，和之前讲的$L2$正则化类似；实施<strong>dropout</strong>的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；$L2$对不同权重的衰减是不同的，它取决于激活函数倍增的大小。</p><p>总结一下，<strong>dropout</strong>的功能类似于$L2$正则化，与$L2$正则化不同的是应用方式不同会带来一点点小变化，甚至更适用于不同的输入范围。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_16.png" alt="L2_week1_16"><br>第二个直观认识是，我们从单个神经元入手，如图，这个单元的工作就是输入并生成一些有意义的输出。通过<strong>dropout</strong>，该单元的输入几乎被消除，有时这两个单元会被删除，有时会删除其它单元，就是说，我用紫色圈起来的这个单元，它不能依靠任何特征，因为特征都有可能被随机清除，或者说该单元的输入也都可能被随机清除。我不愿意把所有赌注都放在一个节点上，不愿意给任何一个输入加上太多权重，因为它可能会被删除，因此该单元将通过这种方式积极地传播开，并为单元的四个输入增加一点权重，通过传播所有权重，<strong>dropout</strong>将产生收缩权重的平方范数的效果，和我们之前讲过的$L2$正则化类似，实施<strong>dropout</strong>的结果是它会压缩权重，并完成一些预防过拟合的外层正则化。</p><p>事实证明，<strong>dropout</strong>被正式地作为一种正则化的替代形式，$L2$对不同权重的衰减是不同的，它取决于倍增的激活函数的大小。</p><p>总结一下，<strong>dropout</strong>的功能类似于$L2$正则化，与$L2$正则化不同的是，被应用的方式不同，<strong>dropout</strong>也会有所不同，甚至更适用于不同的输入范围。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9b9f963a73e3ef9fcac008b179b6cf74.png" alt="9b9f963a73e3ef9fcac008b179b6cf74"><br>实施<strong>dropout</strong>的另一个细节是，这是一个拥有三个输入特征的网络，其中一个要选择的参数是<strong>keep-prob</strong>，它代表每一层上保留单元的概率。所以不同层的<strong>keep-prob</strong>也可以变化。第一层，矩阵$W^{[1]}$是7×3，第二个权重矩阵$W^{[2]}$是7×7，第三个权重矩阵$W^{[3]}$是3×7，以此类推，$W^{[2]}$是最大的权重矩阵，因为$W^{[2]}$拥有最大参数集，即7×7，为了预防矩阵的过拟合，对于这一层，我认为这是第二层，它的<strong>keep-prob</strong>值应该相对较低，假设是0.5。对于其它层，过拟合的程度可能没那么严重，它们的<strong>keep-prob</strong>值可能高一些，可能是0.7，这里是0.7。如果在某一层，我们不必担心其过拟合的问题，那么<strong>keep-prob</strong>可以为1，为了表达清除，我用紫色线笔把它们圈出来，每层<strong>keep-prob</strong>的值可能不同。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5fcb1441866d6d3eff1164ed4ea38cfe.png" alt="5fcb1441866d6d3eff1164ed4ea38cfe"><br>注意<strong>keep-prob</strong>的值是1，意味着保留所有单元，并且不在这一层使用<strong>dropout</strong>，对于有可能出现过拟合，且含有诸多参数的层，我们可以把<strong>keep-prob</strong>设置成比较小的值，以便应用更强大的<strong>dropout</strong>，有点像在处理$L2$正则化的正则化参数$\lambda$，我们尝试对某些层施行更多正则化，从技术上讲，我们也可以对输入层应用<strong>dropout</strong>，我们有机会删除一个或多个输入特征，虽然现实中我们通常不这么做，<strong>keep-prob</strong>的值为1，是非常常用的输入值，也可以用更大的值，或许是0.9。但是消除一半的输入特征是不太可能的，如果我们遵守这个准则，<strong>keep-prob</strong>会接近于1，即使你对输入层应用<strong>dropout</strong>。</p><p>总结一下，如果你担心某些层比其它层更容易发生过拟合，可以把某些层的<strong>keep-prob</strong>值设置得比其它层更低，缺点是为了使用交叉验证，你要搜索更多的超级参数，另一种方案是在一些层上应用<strong>dropout</strong>，而有些层不用<strong>dropout</strong>，应用<strong>dropout</strong>的层只含有一个超级参数，就是<strong>keep-prob</strong>。</p><p>结束前分享两个实施过程中的技巧，实施<strong>dropout</strong>，在计算机视觉领域有很多成功的第一次。计算视觉中的输入量非常大，输入太多像素，以至于没有足够的数据，所以<strong>dropout</strong>在计算机视觉中应用得比较频繁，有些计算机视觉研究人员非常喜欢用它，几乎成了默认的选择，但要牢记一点，<strong>dropout</strong>是一种正则化方法，它有助于预防过拟合，因此除非算法过拟合，不然我是不会使用<strong>dropout</strong>的，所以它在其它领域应用得比较少，主要存在于计算机视觉领域，因为我们通常没有足够的数据，所以一直存在过拟合，这就是有些计算机视觉研究人员如此钟情于<strong>dropout</strong>函数的原因。直观上我认为不能概括其它学科。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/13987e28fa537a110c6b123fc4455f7c.png" alt="13987e28fa537a110c6b123fc4455f7c"><br><strong>dropout</strong>一大缺点就是代价函数$J$不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。定义明确的代价函数$J$每次迭代后都会下降，因为我们所优化的代价函数$J$实际上并没有明确定义，或者说在某种程度上很难计算，所以我们失去了调试工具来绘制这样的图片。我通常会关闭<strong>dropout</strong>函数，将<strong>keep-prob</strong>的值设为1，运行代码，确保J函数单调递减。然后打开<strong>dropout</strong>函数，希望在<strong>dropout</strong>过程中，代码并未引入<strong>bug</strong>。我觉得你也可以尝试其它方法，虽然我们并没有关于这些方法性能的数据统计，但你可以把它们与<strong>dropout</strong>方法一起使用。</p><h3 id="1-8-其他正则化方法（Other-regularization-methods）"><a href="#1-8-其他正则化方法（Other-regularization-methods）" class="headerlink" title="1.8 其他正则化方法（Other regularization methods）"></a>1.8 其他正则化方法（Other regularization methods）</h3><p>除了$L2$正则化和随机失活（<strong>dropout</strong>）正则化，还有几种方法可以减少神经网络中的过拟合:</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_17.png" alt="L2_week1_17"><br>一.数据扩增</p><p>假设你正在拟合猫咪图片分类器，如果你想通过扩增训练数据来解决过拟合，但扩增数据代价高，而且有时候我们无法扩增数据，但我们可以通过添加这类图片来增加训练集。例如，水平翻转图片，并把它添加到训练集。所以现在训练集中有原图，还有翻转后的这张图片，所以通过水平翻转图片，训练集则可以增大一倍，因为训练集有冗余，这虽然不如我们额外收集一组新图片那么好，但这样做节省了获取更多猫咪图片的花费。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e2ccf4a2bb9156f876321ce07b006ca.png" alt="2e2ccf4a2bb9156f876321ce07b006ca"><br>除了水平翻转图片，你也可以随意裁剪图片，这张图是把原图旋转并随意放大后裁剪的，仍能辨别出图片中的猫咪。</p><p>通过随意翻转和裁剪图片，我们可以增大数据集，额外生成假训练数据。和全新的，独立的猫咪图片数据相比，这些额外的假的数据无法包含像全新数据那么多的信息，但我们这么做基本没有花费，代价几乎为零，除了一些对抗性代价。以这种方式扩增算法数据，进而正则化数据集，减少过拟合比较廉价。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/dd9a0f8209e53fdab8030b98d39e11eb.png" alt="dd9a0f8209e53fdab8030b98d39e11eb"><br>像这样人工合成数据的话，我们要通过算法验证，图片中的猫经过水平翻转之后依然是猫。大家注意，我并没有垂直翻转，因为我们不想上下颠倒图片，也可以随机选取放大后的部分图片，猫可能还在上面。</p><p>对于光学字符识别，我们还可以通过添加数字，随意旋转或扭曲数字来扩增数据，把这些数字添加到训练集，它们仍然是数字。为了方便说明，我对字符做了强变形处理，所以数字4看起来是波形的，其实不用对数字4做这么夸张的扭曲，只要轻微的变形就好，我做成这样是为了让大家看的更清楚。实际操作的时候，我们通常对字符做更轻微的变形处理。因为这几个4看起来有点扭曲。所以，数据扩增可作为正则化方法使用，实际功能上也与正则化相似。</p><p>二.<strong>early stopping</strong></p><p>还有另外一种常用的方法叫作<strong>early stopping</strong>，运行梯度下降时，我们可以绘制训练误差，或只绘制代价函数$J$的优化过程，在训练集上用0-1记录分类误差次数。呈单调下降趋势，如图。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/69d92a8de8f62ab602d2bc022591d3c9.png" alt="69d92a8de8f62ab602d2bc022591d3c9"><br>因为在训练过程中，我们希望训练误差，代价函数$J$都在下降，通过<strong>early stopping</strong>，我们不但可以绘制上面这些内容，还可以绘制验证集误差，它可以是验证集上的分类误差，或验证集上的代价函数，逻辑损失和对数损失等，你会发现，验证集误差通常会先呈下降趋势，然后在某个节点处开始上升，<strong>early stopping</strong>的作用是，你会说，神经网络已经在这个迭代过程中表现得很好了，我们在此停止训练吧，得到验证集误差，它是怎么发挥作用的？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9d0db64a9c9b050466a039c935f36f93.png" alt="9d0db64a9c9b050466a039c935f36f93"><br>当你还未在神经网络上运行太多迭代过程的时候，参数$w$接近0，因为随机初始化$w$值时，它的值可能都是较小的随机值，所以在你长期训练神经网络之前$w$依然很小，在迭代过程和训练过程中$w$的值会变得越来越大，比如在这儿，神经网络中参数$w$的值已经非常大了，所以<strong>early stopping</strong>要做就是在中间点停止迭代过程，我们得到一个$w$值中等大小的弗罗贝尼乌斯范数，与$L2$正则化相似，选择参数w范数较小的神经网络，但愿你的神经网络过度拟合不严重。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/51ca931387ed9fb80313263113c56e8e.png" alt="51ca931387ed9fb80313263113c56e8e"><br>术语<strong>early stopping</strong>代表提早停止训练神经网络，训练神经网络时，我有时会用到<strong>early stopping</strong>，但是它也有一个缺点，我们来了解一下。</p><p>我认为机器学习过程包括几个步骤，其中一步是选择一个算法来优化代价函数$J$，我们有很多种工具来解决这个问题，如梯度下降，后面我会介绍其它算法，例如<strong>Momentum</strong>，<strong>RMSprop</strong>和<strong>Adam</strong>等等，但是优化代价函数$J$之后，我也不想发生过拟合，也有一些工具可以解决该问题，比如正则化，扩增数据等等。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f5fd5df8235145c54aece1a5bf7b31f6.png" alt="f5fd5df8235145c54aece1a5bf7b31f6"><br>在机器学习中，超级参数激增，选出可行的算法也变得越来越复杂。我发现，如果我们用一组工具优化代价函数$J$，机器学习就会变得更简单，在重点优化代价函数$J$时，你只需要留意$w$和$b$，$J(w,b)$的值越小越好，你只需要想办法减小这个值，其它的不用关注。然后，预防过拟合还有其他任务，换句话说就是减少方差，这一步我们用另外一套工具来实现，这个原理有时被称为“正交化”。思路就是在一个时间做一个任务，后面课上我会具体介绍正交化，如果你还不了解这个概念，不用担心。</p><p>但对我来说<strong>early stopping</strong>的主要缺点就是你不能独立地处理这两个问题，因为提早停止梯度下降，也就是停止了优化代价函数$J$，因为现在你不再尝试降低代价函数$J$，所以代价函数$J$的值可能不够小，同时你又希望不出现过拟合，你没有采取不同的方式来解决这两个问题，而是用一种方法同时解决两个问题，这样做的结果是我要考虑的东西变得更复杂。</p><p>如果不用<strong>early stopping</strong>，另一种方法就是$L2$正则化，训练神经网络的时间就可能很长。我发现，这导致超级参数搜索空间更容易分解，也更容易搜索，但是缺点在于，你必须尝试很多正则化参数$\lambda$的值，这也导致搜索大量$\lambda$值的计算代价太高。</p><p><strong>Early stopping</strong>的优点是，只运行一次梯度下降，你可以找出$w$的较小值，中间值和较大值，而无需尝试$L2$正则化超级参数$\lambda$的很多值。</p><p>如果你还不能完全理解这个概念，没关系，下节课我们会详细讲解正交化，这样会更好理解。</p><p>虽然$L2$正则化有缺点，可还是有很多人愿意用它。吴恩达老师个人更倾向于使用$L2$正则化，尝试许多不同的$\lambda$值，假设你可以负担大量计算的代价。而使用<strong>early stopping</strong>也能得到相似结果，还不用尝试这么多$\lambda$值。</p><p>这节课我们讲了如何使用数据扩增，以及如何使用<strong>early stopping</strong>降低神经网络中的方差或预防过拟合。</p><h3 id="1-9-归一化输入（Normalizing-inputs）"><a href="#1-9-归一化输入（Normalizing-inputs）" class="headerlink" title="1.9 归一化输入（Normalizing inputs）"></a>1.9 归一化输入（Normalizing inputs）</h3><p>训练神经网络，其中一个加速训练的方法就是归一化输入。假设一个训练集有两个特征，输入特征为2维，归一化需要两个步骤：</p><ol><li><p>零均值</p></li><li><p>归一化方差；</p></li></ol><p>我们希望无论是训练集和测试集都是通过相同的$μ$和$σ^2$定义的数据转换，这两个是由训练集得出来的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_19.png" alt="L2_week1_19"><br>第一步是零均值化，$\mu = \frac{1}{m}\sum_{i =1}^{m}x^{(i)}$，它是一个向量，$x$等于每个训练数据 $x$减去$\mu$，意思是移动训练集，直到它完成零均值化。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5e49434607f22caf087f7730177931bf.png" alt="5e49434607f22caf087f7730177931bf"><br>第二步是归一化方差，注意特征$x_{1}$的方差比特征$x_{2}$的方差要大得多，我们要做的是给$\sigma$赋值，$\sigma^{2}= \frac{1}{m}\sum_{i =1}^{m}{({x^{(i)})}^{2} }$，这是节点$y$ 的平方，$\sigma^{2}$是一个向量，它的每个特征都有方差，注意，我们已经完成零值均化，$({x^{(i)})}^{2}$元素$y^{2}$就是方差，我们把所有数据除以向量$\sigma^{2}$，最后变成上图形式。</p> $x_{1}$和$x_{2}$的方差都等于1。提示一下，如果你用它来调整训练数据，那么用相同的 $μ$ 和 $\sigma^{2}$来归一化测试集。尤其是，你不希望训练集和测试集的归一化有所不同，不论$μ$的值是什么，也不论$\sigma^{2}$的值是什么，这两个公式中都会用到它们。所以你要用同样的方法调整测试集，而不是在训练集和测试集上分别预估$μ$ 和 $\sigma^{2}$。因为我们希望不论是训练数据还是测试数据，都是通过相同μ和$\sigma^{2}$定义的相同数据转换，其中$μ$和$\sigma^{2}$是由训练集数据计算得来的。<p>我们为什么要这么做呢？为什么我们想要归一化输入特征，回想一下右上角所定义的代价函数。</p> $J(w,b)=\frac{1}{m}\sum\limits_{i=1}^{m}{L({ {{\hat{y} }}^{(i)} },{ {y}^{(i)} })}$<p>如果你使用非归一化的输入特征，代价函数会像这样：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bc4eccfb6c9dbef6cc81636d5ce60390.png" alt="bc4eccfb6c9dbef6cc81636d5ce60390"><br>这是一个非常细长狭窄的代价函数，你要找的最小值应该在这里。但如果特征值在不同范围，假如$x_{1}$取值范围从1到1000，特征$x_{2}$的取值范围从0到1，结果是参数$w_{1}$和$w_{2}$值的范围或比率将会非常不同，这些数据轴应该是$w_{1}$和$w_{2}$，但直观理解，我标记为$w$和$b$，代价函数就有点像狭长的碗一样，如果你能画出该函数的部分轮廓，它会是这样一个狭长的函数。</p><p>然而如果你归一化特征，代价函数平均起来看更对称，如果你在上图这样的代价函数上运行梯度下降法，你必须使用一个非常小的学习率。因为如果是在这个位置，梯度下降法可能需要多次迭代过程，直到最后找到最小值。但如果函数是一个更圆的球形轮廓，那么不论从哪个位置开始，梯度下降法都能够更直接地找到最小值，你可以在梯度下降法中使用较大步长，而不需要像在左图中那样反复执行。</p><p>当然，实际上$w$是一个高维向量，因此用二维绘制$w$并不能正确地传达并直观理解，但总地直观理解是代价函数会更圆一些，而且更容易优化，前提是特征都在相似范围内，而不是从1到1000，0到1的范围，而是在-1到1范围内或相似偏差，这使得代价函数$J$优化起来更简单快速。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4d0c183882a140ecd205f1618243d7f8.png" alt="4d0c183882a140ecd205f1618243d7f8"><br>实际上如果假设特征$x_{1}$范围在0-1之间，$x_{2}$的范围在-1到1之间，$x_{3}$范围在1-2之间，它们是相似范围，所以会表现得很好。</p><p>当它们在非常不同的取值范围内，如其中一个从1到1000，另一个从0到1，这对优化算法非常不利。但是仅将它们设置为均化零值，假设方差为1，就像上一张幻灯片里设定的那样，确保所有特征都在相似范围内，通常可以帮助学习算法运行得更快。</p><p>所以如果输入特征处于不同范围内，可能有些特征值从0到1，有些从1到1000，那么归一化特征值就非常重要了。如果特征值处于相似范围内，那么归一化就不是很重要了。执行这类归一化并不会产生什么危害，我通常会做归一化处理，虽然我不确定它能否提高训练或算法速度。</p><p>这就是归一化特征输入，下节课我们将继续讨论提升神经网络训练速度的方法。</p><h3 id="1-10-梯度消失-梯度爆炸（Vanishing-Exploding-gradients）"><a href="#1-10-梯度消失-梯度爆炸（Vanishing-Exploding-gradients）" class="headerlink" title="1.10 梯度消失/梯度爆炸（Vanishing / Exploding gradients）"></a>1.10 梯度消失/梯度爆炸（Vanishing / Exploding gradients）</h3><p>训练神经网络，尤其是深度神经所面临的一个问题就是梯度消失或梯度爆炸，也就是你训练神经网络的时候，导数或坡度有时会变得非常大，或者非常小，甚至于以指数方式变小，这加大了训练的难度。</p><p>这节课，你将会了解梯度消失或梯度爆炸的真正含义，以及如何更明智地选择随机初始化权重，从而避免这个问题。<br>假设你正在训练这样一个极深的神经网络，为了节约幻灯片上的空间，我画的神经网络每层只有两个隐藏单元，但它可能含有更多，但这个神经网络会有参数$W^{[1]}$，$W^{[2]}$，$W^{[3]}$等等，直到$W^{[l]}$，为了简单起见，假设我们使用激活函数$g(z)=z$，也就是线性激活函数，我们忽略$b$，假设$b^{[l]}$=0，如果那样的话，输出$ y=W^{[l]}W^{[L -1]}W^{[L - 2]}\ldots W^{[3]}W^{[2]}W^{[1]}x$，如果你想考验我的数学水平，$W^{[1]} x = z^{[1]}$，因为$b=0$，所以我想$z^{[1]} =W^{[1]} x$，$a^{[1]} = g(z^{[1]})$，因为我们使用了一个线性激活函数，它等于$z^{[1]}$，所以第一项$W^{[1]} x = a^{[1]}$，通过推理，你会得出$W^{[2]}W^{[1]}x =a^{[2]}$，因为$a^{[2]} = g(z^{[2]})$，还等于$g(W^{[2]}a^{[1]})$，可以用$W^{[1]}x$替换$a^{[1]}$，所以这一项就等于$a^{[2]}$，这个就是$a^{[3]}$($W^{[3]}W^{[2]}W^{[1]}x$)。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fc03196f0b6d1c9f56fa39d0d462cfa4.png" alt="fc03196f0b6d1c9f56fa39d0d462cfa4"><br>所有这些矩阵数据传递的协议将给出$\hat y$而不是$y$的值。</p><p>假设每个权重矩阵$W^{[l]} = \begin{bmatrix} 1.5 & 0 \\0 & 1.5 \\\end{bmatrix}$，从技术上来讲，最后一项有不同维度，可能它就是余下的权重矩阵，$y= W^{[1]}\begin{bmatrix} 1.5 & 0 \\ 0 & 1.5 \\\end{bmatrix}^{(L -1)}x$，因为我们假设所有矩阵都等于它，它是1.5倍的单位矩阵，最后的计算结果就是$\hat{y}$，$\hat{y}$也就是等于${1.5}^{(L-1)}x$。如果对于一个深度神经网络来说$L$值较大，那么$\hat{y}$的值也会非常大，实际上它呈指数级增长的，它增长的比率是${1.5}^{L}$，因此对于一个深度神经网络，$y$的值将爆炸式增长。</p><p>相反的，如果权重是0.5，$W^{[l]} = \begin{bmatrix} 0.5& 0 \\ 0 & 0.5 \\ \end{bmatrix}$，它比1小，这项也就变成了${0.5}^{L}$，矩阵$y= W^{[1]}\begin{bmatrix} 0.5 & 0 \\ 0 & 0.5 \\\end{bmatrix}^{(L - 1)}x$，再次忽略$W^{[L]}$，因此每个矩阵都小于1，假设$x_{1}$和$x_{2}$都是1，激活函数将变成$\frac{1}{2}$，$\frac{1}{2}$，$\frac{1}{4}$，$\frac{1}{4}$，$\frac{1}{8}$，$\frac{1}{8}$等，直到最后一项变成$\frac{1}{2^{L} }$，所以作为自定义函数，激活函数的值将以指数级下降，它是与网络层数数量$L$相关的函数，在深度网络中，激活函数以指数级递减。</p><p>我希望你得到的直观理解是，权重$W$只比1略大一点，或者说只是比单位矩阵大一点，深度神经网络的激活函数将爆炸式增长，如果$W$比1略小一点，可能是$\begin{bmatrix}0.9 & 0 \\ 0 & 0.9 \\ \end{bmatrix}$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ff87a8ea1377053128cdbf5129f0203f.png" alt="ff87a8ea1377053128cdbf5129f0203f"><br>在深度神经网络中，激活函数将以指数级递减，虽然我只是讨论了激活函数以与$L$相关的指数级数增长或下降，它也适用于与层数$L$相关的导数或梯度函数，也是呈指数级增长或呈指数递减。</p><p>对于当前的神经网络，假设$L=150$，最近<strong>Microsoft</strong>对152层神经网络的研究取得了很大进展，在这样一个深度神经网络中，如果激活函数或梯度函数以与$L$相关的指数增长或递减，它们的值将会变得极大或极小，从而导致训练难度上升，尤其是梯度指数小于$L$时，梯度下降算法的步长会非常非常小，梯度下降算法将花费很长时间来学习。</p><p>总结一下，我们讲了深度神经网络是如何产生梯度消失或爆炸问题的，实际上，在很长一段时间内，它曾是训练深度神经网络的阻力，虽然有一个不能彻底解决此问题的解决方案，但是已在如何选择初始化权重问题上提供了很多帮助。</p><h3 id="1-11-神经网络的权重初始化（Weight-Initialization-for-Deep-NetworksVanishing-Exploding-gradients）"><a href="#1-11-神经网络的权重初始化（Weight-Initialization-for-Deep-NetworksVanishing-Exploding-gradients）" class="headerlink" title="1.11 神经网络的权重初始化（Weight Initialization for Deep NetworksVanishing / Exploding gradients）"></a>1.11 神经网络的权重初始化（Weight Initialization for Deep NetworksVanishing / Exploding gradients）</h3><p>上节课，我们学习了深度神经网络如何产生梯度消失和梯度爆炸问题，最终针对该问题，我们想出了一个不完整的解决方案，虽然不能彻底解决问题，却很有用，有助于我们为神经网络更谨慎地选择随机初始化参数，为了更好地理解它，我们先举一个神经单元初始化地例子，然后再演变到整个深度网络。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/db9472c81a2cf6bb704dc398ea1cf017.png" alt="db9472c81a2cf6bb704dc398ea1cf017"><br>我们来看看只有一个神经元的情况，然后才是深度网络。</p><p>单个神经元可能有4个输入特征，从$x_{1}$到$x_{4}$，经过$a=g(z)$处理，最终得到$\hat{y}$，稍后讲深度网络时，这些输入表示为$a^{[l]}$，暂时我们用$x$表示。</p> $z = w_{1}x_{1} + w_{2}x_{2} + \ldots +w_{n}x_{n}$，$b=0$，暂时忽略$b$，为了预防$z$值过大或过小，你可以看到$n$越大，你希望$w_{i}$越小，因为$z$是$w_{i}x_{i}$的和，如果你把很多此类项相加，希望每项值更小，最合理的方法就是设置$w_{i}=\frac{1}{n}$，$n$表示神经元的输入特征数量，实际上，你要做的就是设置某层权重矩阵$w^{[l]} = np.random.randn( \text{shape})*\text{np.}\text{sqrt}(\frac{1}{n^{[l-1]} })$，$n^{[l - 1]}$就是我喂给第$l$层神经单元的数量（即第$l-1$层神经元数量）。<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e4114d7dc1c6242bd96cdadb457b8959.png" alt="e4114d7dc1c6242bd96cdadb457b8959"><br>结果，如果你是用的是<strong>Relu</strong>激活函数，而不是$\frac{1}{n}$，方差设置为$\frac{2}{n}$，效果会更好。你常常发现，初始化时，尤其是使用<strong>Relu</strong>激活函数时，$g^{[l]}(z) =Relu(z)$,它取决于你对随机变量的熟悉程度，这是高斯随机变量，然后乘以它的平方根，也就是引用这个方差$\frac{2}{n}$。这里，我用的是$n^{[l - 1]}$，因为本例中，逻辑回归的特征是不变的。但一般情况下$l$层上的每个神经元都有$n^{[l - 1]}$个输入。如果激活函数的输入特征被零均值和标准方差化，方差是1，$z$也会调整到相似范围，这就没解决问题（梯度消失和爆炸问题）。但它确实降低了梯度消失和爆炸问题，因为它给权重矩阵$w$设置了合理值，你也知道，它不能比1大很多，也不能比1小很多，所以梯度没有爆炸或消失过快。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3decc82bf6f48903ee1fedbdb7e2c0f6.png" alt="3decc82bf6f48903ee1fedbdb7e2c0f6"><br>我提到了其它变体函数，刚刚提到的函数是<strong>Relu</strong>激活函数，一篇由<strong>Herd</strong>等人撰写的论文曾介绍过。对于几个其它变体函数，如<strong>tanh</strong>激活函数，有篇论文提到，常量1比常量2的效率更高，对于<strong>tanh</strong>函数来说，它是$\sqrt{\frac{1}{n^{[l-1]} }}$，这里平方根的作用与这个公式作用相同($\text{np.}\text{sqrt}(\frac{1}{n^{[l-1]} })$)，它适用于<strong>tanh</strong>激活函数，被称为<strong>Xavier</strong>初始化。<strong>Yoshua Bengio</strong>和他的同事还提出另一种方法，你可能在一些论文中看到过，它们使用的是公式$\sqrt{\frac{2}{n^{[l-1]} + n^{\left[l\right]} }}$。其它理论已对此证明，但如果你想用<strong>Relu</strong>激活函数，也就是最常用的激活函数，我会用这个公式$\text{np.}\text{sqrt}(\frac{2}{n^{[l-1]} })$，如果使用<strong>tanh</strong>函数，可以用公式$\sqrt{\frac{1}{n^{[l-1]} }}$，有些作者也会使用这个函数。</p><p>实际上，我认为所有这些公式只是给你一个起点，它们给出初始化权重矩阵的方差的默认值，如果你想添加方差，方差参数则是另一个你需要调整的超级参数，可以给公式$\text{np.}\text{sqrt}(\frac{2}{n^{[l-1]} })$添加一个乘数参数，调优作为超级参数激增一份子的乘子参数。有时调优该超级参数效果一般，这并不是我想调优的首要超级参数，但我发现调优过程中产生的问题，虽然调优该参数能起到一定作用，但考虑到相比调优，其它超级参数的重要性，我通常把它的优先级放得比较低。</p><p>希望你现在对梯度消失或爆炸问题以及如何为权重初始化合理值已经有了一个直观认识，希望你设置的权重矩阵既不会增长过快，也不会太快下降到0，从而训练出一个权重或梯度不会增长或消失过快的深度网络。我们在训练深度网络时，这也是一个加快训练速度的技巧。</p><h3 id="1-12-梯度的数值逼近（Numerical-approximation-of-gradients）"><a href="#1-12-梯度的数值逼近（Numerical-approximation-of-gradients）" class="headerlink" title="1.12 梯度的数值逼近（Numerical approximation of gradients）"></a>1.12 梯度的数值逼近（Numerical approximation of gradients）</h3><p>在实施<strong>backprop</strong>时，有一个测试叫做梯度检验，它的作用是确保<strong>backprop</strong>正确实施。因为有时候，你虽然写下了这些方程式，却不能100%确定，执行<strong>backprop</strong>的所有细节都是正确的。为了逐渐实现梯度检验，我们首先说说如何计算梯度的数值逼近，下节课，我们将讨论如何在<strong>backprop</strong>中执行梯度检验，以确保<strong>backprop</strong>正确实施。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/91cde35a0fc9c11a98f16ad2797f20a7.png" alt="91cde35a0fc9c11a98f16ad2797f20a7"><br>我们先画出函数$f$，标记为$f\left( \theta \right)$，$f\left( \theta \right)=\theta^{3}$，先看一下$\theta$的值，假设$\theta=1$，不增大$\theta$的值，而是在$\theta$ 右侧，设置一个$\theta +\varepsilon$，在$\theta$左侧，设置$\theta -\varepsilon$。因此$\theta=1$，$\theta +\varepsilon =1.01,\theta -\varepsilon =0.99$,，跟以前一样，$\varepsilon$的值为0.01，看下这个小三角形，计算高和宽的比值，就是更准确的梯度预估，选择$f$函数在$\theta -\varepsilon$上的这个点，用这个较大三角形的高比上宽，技术上的原因我就不详细解释了，较大三角形的高宽比值更接近于$\theta$的导数，把右上角的三角形下移，好像有了两个三角形，右上角有一个，左下角有一个，我们通过这个绿色大三角形同时考虑了这两个小三角形。所以我们得到的不是一个单边公差而是一个双边公差。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b24ad9ce9fdc4a32be4d98915d8f6ffb.png" alt="b24ad9ce9fdc4a32be4d98915d8f6ffb"><br>我们写一下数据算式，图中绿色三角形上边的点的值是$f( \theta +\varepsilon )$，下边的点是$f( \theta-\varepsilon)$，这个三角形的高度是$f( \theta +\varepsilon)-f(\theta -\varepsilon)$，这两个宽度都是ε，所以三角形的宽度是$2\varepsilon$，高宽比值为$\frac{f(\theta + \varepsilon ) - (\theta -\varepsilon)}{2\varepsilon}$，它的期望值接近$g( \theta)$，$f( \theta)=\theta^{3}$传入参数值，$\frac {f\left( \theta + \varepsilon \right) - f(\theta -\varepsilon)}{2\varepsilon} = \frac{ {(1.01)}^{3} - {(0.99)}^{3} }{2 \times0.01}$，大家可以暂停视频，用计算器算算结果，结果应该是3.0001，而前面一张幻灯片上面是，当$\theta =1$时，$g( \theta)=3\theta^{2} =3$，所以这两个$g(\theta)$值非常接近，逼近误差为0.0001，前一张幻灯片，我们只考虑了单边公差，即从$\theta $到$\theta +\varepsilon$之间的误差，$g( \theta)$的值为3.0301，逼近误差是0.03，不是0.0001，所以使用双边误差的方法更逼近导数，其结果接近于3，现在我们更加确信，$g( \theta)$可能是$f$导数的正确实现，在梯度检验和反向传播中使用该方法时，最终，它与运行两次单边公差的速度一样，实际上，我认为这种方法还是非常值得使用的，因为它的结果更准确。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/35a2e86581eab4665634593870fe5180.png" alt="35a2e86581eab4665634593870fe5180"><br>这是一些你可能比较熟悉的微积分的理论，如果你不太明白我讲的这些理论也没关系，导数的官方定义是针对值很小的$\varepsilon$，导数的官方定义是$f^{'}\theta) = \operatorname{}\frac{f( \theta + \varepsilon) -f(\theta -\varepsilon)}{2\varepsilon}$，如果你上过微积分课，应该学过无穷尽的定义，我就不在这里讲了。</p><p>对于一个非零的$\varepsilon$，它的逼近误差可以写成$O(\varepsilon^{2})$，ε值非常小，如果$\varepsilon=0.01$，$\varepsilon^{2}=0.0001$，大写符号$O$的含义是指逼近误差其实是一些常量乘以$\varepsilon^{2}$，但它的确是很准确的逼近误差，所以大写$O$的常量有时是1。然而，如果我们用另外一个公式逼近误差就是$O(\varepsilon)$，当$\varepsilon$小于1时，实际上$\varepsilon$比$\varepsilon^{2}$大很多，所以这个公式近似值远没有左边公式的准确，所以在执行梯度检验时，我们使用双边误差，即$\frac{f\left(\theta + \varepsilon \right) - f(\theta -\varepsilon)}{2\varepsilon}$，而不使用单边公差，因为它不够准确。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1b2617461ed10089bc61ad273c84594f.png" alt="1b2617461ed10089bc61ad273c84594f"><br>如果你不理解上面两条结论，所有公式都在这儿，不用担心，如果你对微积分和数值逼近有所了解，这些信息已经足够多了，重点是要记住，双边误差公式的结果更准确，下节课我们做梯度检验时就会用到这个方法。</p><p>今天我们讲了如何使用双边误差来判断别人给你的函数$g( \theta)$，是否正确实现了函数$f$的偏导，现在我们可以使用这个方法来检验反向传播是否得以正确实施，如果不正确，它可能有bug需要你来解决。</p><h3 id="1-13-梯度检验（Gradient-checking）"><a href="#1-13-梯度检验（Gradient-checking）" class="headerlink" title="1.13 梯度检验（Gradient checking）"></a>1.13 梯度检验（Gradient checking）</h3><p>梯度检验帮我们节省了很多时间，也多次帮我发现<strong>backprop</strong>实施过程中的bug，接下来，我们看看如何利用它来调试或检验<strong>backprop</strong>的实施是否正确。</p><p>假设你的网络中含有下列参数，$W^{[1]}$和$b^{[1]}$……$W^{[l]}$和$b^{[l]}$，为了执行梯度检验，首先要做的就是，把所有参数转换成一个巨大的向量数据，你要做的就是把矩阵$W$转换成一个向量，把所有$W$矩阵转换成向量之后，做连接运算，得到一个巨型向量$\theta$，该向量表示为参数$\theta$，代价函数$J$是所有$W$和$b$的函数，现在你得到了一个$\theta$的代价函数$J$（即$J(\theta)$）。接着，你得到与$W$和$b$顺序相同的数据，你同样可以把$dW^{[1]}$和${db}^{[1]}$……${dW}^{[l]}$和${db}^{[l]}$转换成一个新的向量，用它们来初始化大向量$d\theta$，它与$\theta$具有相同维度。</p><p>同样的，把$dW^{[1]}$转换成矩阵，$db^{[1]}$已经是一个向量了，直到把${dW}^{[l]}$转换成矩阵，这样所有的$dW$都已经是矩阵，注意$dW^{[1]}$与$W^{[1]}$具有相同维度，$db^{[1]}$与$b^{[1]}$具有相同维度。经过相同的转换和连接运算操作之后，你可以把所有导数转换成一个大向量$d\theta$，它与$\theta$具有相同维度，现在的问题是$d\theta$和代价函数$J$的梯度或坡度有什么关系？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/94fb79f5694c802a5261298e54157e14.png" alt="94fb79f5694c802a5261298e54157e14"><br>这就是实施梯度检验的过程，英语里通常简称为“<strong>grad check</strong>”，首先，我们要清楚$J$是超参数$\theta$的一个函数，你也可以将J函数展开为$J(\theta_{1},\theta_{2},\theta_{3},\ldots\ldots)$，不论超级参数向量$\theta$的维度是多少，为了实施梯度检验，你要做的就是循环执行，从而对每个$i$也就是对每个$\theta$组成元素计算$d\theta_{\text{approx} }[i]$的值，我使用双边误差，也就是</p> $d\theta_{\text{approx} }\left[i \right] = \frac{J\left( \theta_{1},\theta_{2},\ldots\theta_{i} + \varepsilon,\ldots \right) - J\left( \theta_{1},\theta_{2},\ldots\theta_{i} - \varepsilon,\ldots \right)}{2\varepsilon}$<p>只对$\theta_{i}$增加$\varepsilon$，其它项保持不变，因为我们使用的是双边误差，对另一边做同样的操作，只不过是减去$\varepsilon$，$\theta$其它项全都保持不变。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f56f0cdc90730068109a6e20fcd41724.png" alt="f56f0cdc90730068109a6e20fcd41724"><br>从上节课中我们了解到这个值（$d\theta_{\text{approx} }\left[i \right]$）应该逼近$d\theta\left[i \right]$=$\frac{\partial J}{\partial\theta_{i} }$，$d\theta\left[i \right]$是代价函数的偏导数，然后你需要对i的每个值都执行这个运算，最后得到两个向量，得到$d\theta$的逼近值$d\theta_{\text{approx} }$，它与$d\theta$具有相同维度，它们两个与$\theta$具有相同维度，你要做的就是验证这些向量是否彼此接近。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bed27b1d469acaf24dc1a7c1a7cdc086.png" alt="bed27b1d469acaf24dc1a7c1a7cdc086"><br>具体来说，如何定义两个向量是否真的接近彼此？我一般做下列运算，计算这两个向量的距离，$d\theta_{\text{approx} }\left[i \right] - d\theta[i]$的欧几里得范数，注意这里（${||d\theta_{\text{approx} } -d\theta||}_{2}$）没有平方，它是误差平方之和，然后求平方根，得到欧式距离，然后用向量长度归一化，使用向量长度的欧几里得范数。分母只是用于预防这些向量太小或太大，分母使得这个方程式变成比率，我们实际执行这个方程式，$\varepsilon$可能为$10^{-7}$，使用这个取值范围内的$\varepsilon$，如果你发现计算方程式得到的值为$10^{-7}$或更小，这就很好，这就意味着导数逼近很有可能是正确的，它的值非常小。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f223102bc7d144b66ad9b2ffa4a85f00.png" alt="f223102bc7d144b66ad9b2ffa4a85f00"><br>如果它的值在$10^{-5}$范围内，我就要小心了，也许这个值没问题，但我会再次检查这个向量的所有项，确保没有一项误差过大，可能这里有<strong>bug</strong>。</p><p>如果左边这个方程式结果是$10^{-3}$，我就会担心是否存在<strong>bug</strong>，计算结果应该比$10^{- 3}$小很多，如果比$10^{-3}$大很多，我就会很担心，担心是否存在<strong>bug</strong>。这时应该仔细检查所有$\theta$项，看是否有一个具体的$i$值，使得$d\theta_{\text{approx} }\left[i \right]$与$ d\theta[i]$大不相同，并用它来追踪一些求导计算是否正确，经过一些调试，最终结果会是这种非常小的值（$10^{-7}$），那么，你的实施可能是正确的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/07fd11e7b28ef0ab7d3b6d23b19a8fdc.png" alt="07fd11e7b28ef0ab7d3b6d23b19a8fdc"><br>在实施神经网络时，我经常需要执行<strong>foreprop</strong>和<strong>backprop</strong>，然后我可能发现这个梯度检验有一个相对较大的值，我会怀疑存在<strong>bug</strong>，然后开始调试，调试，调试，调试一段时间后，我得到一个很小的梯度检验值，现在我可以很自信的说，神经网络实施是正确的。</p><p>现在你已经了解了梯度检验的工作原理，它帮助我在神经网络实施中发现了很多<strong>bug</strong>，希望它对你也有所帮助。</p><h3 id="1-14-梯度检验应用的注意事项（Gradient-Checking-Implementation-Notes）"><a href="#1-14-梯度检验应用的注意事项（Gradient-Checking-Implementation-Notes）" class="headerlink" title="1.14 梯度检验应用的注意事项（Gradient Checking Implementation Notes）"></a>1.14 梯度检验应用的注意事项（Gradient Checking Implementation Notes）</h3><p>这节课，分享一些关于如何在神经网络实施梯度检验的实用技巧和注意事项。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/L2_week1_24.png" alt="L2_week1_24"><br>首先，不要在训练中使用梯度检验，它只用于调试。我的意思是，计算所有$i$值的$d\theta_{\text{approx} }\left[i\right]$是一个非常漫长的计算过程，为了实施梯度下降，你必须使用$W$和$b$ <strong>backprop</strong>来计算$d\theta$，并使用<strong>backprop</strong>来计算导数，只要调试的时候，你才会计算它，来确认数值是否接近$d\theta$。完成后，你会关闭梯度检验，梯度检验的每一个迭代过程都不执行它，因为它太慢了。</p><p>第二点，如果算法的梯度检验失败，要检查所有项，检查每一项，并试着找出<strong>bug</strong>，也就是说，如果$d\theta_{\text{approx} }\left[i\right]$与dθ[i]的值相差很大，我们要做的就是查找不同的i值，看看是哪个导致$d\theta_{\text{approx} }\left[i\right]$与$d\theta\left[i\right]$的值相差这么多。举个例子，如果你发现，相对某些层或某层的$\theta$或$d\theta$的值相差很大，但是$\text{dw}^{[l]}$的各项非常接近，注意$\theta$的各项与$b$和$w$的各项都是一一对应的，这时，你可能会发现，在计算参数$b$的导数$db$的过程中存在<strong>bug</strong>。反过来也是一样，如果你发现它们的值相差很大，$d\theta_{\text{approx} }\left[i\right]$的值与$d\theta\left[i\right]$的值相差很大，你会发现所有这些项目都来自于$dw$或某层的$dw$，可能帮你定位bug的位置，虽然未必能够帮你准确定位bug的位置，但它可以帮助你估测需要在哪些地方追踪<strong>bug</strong>。</p><p>第三点，在实施梯度检验时，如果使用正则化，请注意正则项。如果代价函数$J(\theta) = \frac{1}{m}\sum_{}^{}{L(\hat y^{(i)},y^{(i)})} + \frac{\lambda}{2m}\sum_{}^{}{||W^{[l]}||}^{2}$，这就是代价函数$J$的定义，$d\theta$等于与$\theta$相关的$J$函数的梯度，包括这个正则项，记住一定要包括这个正则项。</p><p>第四点，梯度检验不能与<strong>dropout</strong>同时使用，因为每次迭代过程中，<strong>dropout</strong>会随机消除隐藏层单元的不同子集，难以计算<strong>dropout</strong>在梯度下降上的代价函数$J$。因此<strong>dropout</strong>可作为优化代价函数$J$的一种方法，但是代价函数J被定义为对所有指数极大的节点子集求和。而在任何迭代过程中，这些节点都有可能被消除，所以很难计算代价函数$J$。你只是对成本函数做抽样，用<strong>dropout</strong>，每次随机消除不同的子集，所以很难用梯度检验来双重检验<strong>dropout</strong>的计算，所以我一般不同时使用梯度检验和<strong>dropout</strong>。如果你想这样做，可以把<strong>dropout</strong>中的<strong>keepprob</strong>设置为1.0，然后打开<strong>dropout</strong>，并寄希望于<strong>dropout</strong>的实施是正确的，你还可以做点别的，比如修改节点丢失模式确定梯度检验是正确的。实际上，我一般不这么做，我建议关闭<strong>dropout</strong>，用梯度检验进行双重检查，在没有<strong>dropout</strong>的情况下，你的算法至少是正确的，然后打开<strong>dropout</strong>。</p><p>最后一点，也是比较微妙的一点，现实中几乎不会出现这种情况。当$w$和$b$接近0时，梯度下降的实施是正确的，在随机初始化过程中……，但是在运行梯度下降时，$w$和$b$变得更大。可能只有在$w$和$b$接近0时，<strong>backprop</strong>的实施才是正确的。但是当$W$和$b$变大时，它会变得越来越不准确。你需要做一件事，我不经常这么做，就是在随机初始化过程中，运行梯度检验，然后再训练网络，$w$和$b$会有一段时间远离0，如果随机初始化值比较小，反复训练网络之后，再重新运行梯度检验。</p><p>这就是梯度检验，恭喜大家，这是本周最后一课了。回顾这一周，我们讲了如何配置训练集，验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差以及高偏差和高方差并存的问题，如何在神经网络中应用不同形式的正则化，如$L2$正则化和<strong>dropout</strong>，还有加快神经网络训练速度的技巧，最后是梯度检验。这一周我们学习了很多内容，你可以在本周编程作业中多多练习这些概念。祝你好运，期待下周再见。</p><h2 id="优化算法-Optimization-algorithms"><a href="#优化算法-Optimization-algorithms" class="headerlink" title="优化算法 (Optimization algorithms)"></a>优化算法 (Optimization algorithms)</h2><h3 id="2-1-Mini-batch-梯度下降（Mini-batch-gradient-descent）"><a href="#2-1-Mini-batch-梯度下降（Mini-batch-gradient-descent）" class="headerlink" title="2.1 Mini-batch 梯度下降（Mini-batch gradient descent）"></a>2.1 Mini-batch 梯度下降（Mini-batch gradient descent）</h3><p>本周将学习优化算法，这能让你的神经网络运行得更快。机器学习的应用是一个高度依赖经验的过程，伴随着大量迭代的过程，你需要训练诸多模型，才能找到合适的那一个，所以，优化算法能够帮助你快速训练模型。</p><p>其中一个难点在于，深度学习没有在大数据领域发挥最大的效果，我们可以利用一个巨大的数据集来训练神经网络，而在巨大的数据集基础上进行训练速度很慢。因此，你会发现，使用快速的优化算法，使用好用的优化算法能够大大提高你和团队的效率，那么，我们首先来谈谈<strong>mini-batch</strong>梯度下降法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ef8c62ba3c82cb37e6ed4783e7717a8d.png" alt="ef8c62ba3c82cb37e6ed4783e7717a8d"><br>你之前学过，向量化能够让你有效地对所有$m$个样本进行计算，允许你处理整个训练集，而无需某个明确的公式。所以我们要把训练样本放大巨大的矩阵$X$当中去，$X= \lbrack x^{(1)}\ x^{(2)}\ x^{(3)}\ldots\ldots x^{(m)}\rbrack$，$Y$也是如此，$Y= \lbrack y^{(1)}\ y^{(2)}\ y^{(3)}\ldots \ldots y^{(m)}\rbrack$，所以$X$的维数是$(n_{x},m)$，$Y$的维数是$(1,m)$，向量化能够让你相对较快地处理所有$m$个样本。如果$m$很大的话，处理速度仍然缓慢。比如说，如果$m$是500万或5000万或者更大的一个数，在对整个训练集执行梯度下降法时，你要做的是，你必须处理整个训练集，然后才能进行一步梯度下降法，然后你需要再重新处理500万个训练样本，才能进行下一步梯度下降法。所以如果你在处理完整个500万个样本的训练集之前，先让梯度下降法处理一部分，你的算法速度会更快，准确地说，这是你可以做的一些事情。</p><p>你可以把训练集分割为小一点的子集训练，这些子集被取名为<strong>mini-batch</strong>，假设每一个子集中只有1000个样本，那么把其中的$x^{(1)}$到$x^{(1000)}$取出来，将其称为第一个子训练集，也叫做<strong>mini-batch</strong>，然后你再取出接下来的1000个样本，从$x^{(1001)}$到$x^{(2000)}$，然后再取1000个样本，以此类推。</p><p>接下来我要说一个新的符号，把$x^{(1)}$到$x^{(1000)}$称为$X^{\{1\} }$，$x^{(1001)}$到$x^{(2000)}$称为$X^{\{2\} }$，如果你的训练样本一共有500万个，每个<strong>mini-batch</strong>都有1000个样本，也就是说，你有5000个<strong>mini-batch</strong>，因为5000乘以1000就是5000万。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/31ee4f6d35c7b509b65f6714574a08f6.png" alt="31ee4f6d35c7b509b65f6714574a08f6"><br>你共有5000个<strong>mini-batch</strong>，所以最后得到是$X^{\left\{ 5000 \right\} }$</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/112c45cf393d896833ffce29e14fe8bc.png" alt="112c45cf393d896833ffce29e14fe8bc"><br>对$Y$也要进行相同处理，你也要相应地拆分$Y$的训练集，所以这是$Y^{\{1\} }$，然后从$y^{(1001)}$到$y^{(2000)}$，这个叫$Y^{\{2\} }$，一直到$Y^{\{ 5000\} }$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/609ea5be2140af929985951f2aab542c.png" alt="609ea5be2140af929985951f2aab542c"><br><strong>mini-batch</strong>的数量$t$组成了$X^{\{ t\} }$和$Y^{\{t\} }$，这就是1000个训练样本，包含相应的输入输出对。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/98fd6e4c5eec8866bbf722c489cd6177.png" alt="98fd6e4c5eec8866bbf722c489cd6177"><br>在继续课程之前，先确定一下我的符号，之前我们使用了上角小括号$(i)$表示训练集里的值，所以$x^{(i)}$是第$i$个训练样本。我们用了上角中括号$[l]$来表示神经网络的层数，$z^{\lbrack l\rbrack}$表示神经网络中第$l$层的$z$值，我们现在引入了大括号${t}$来代表不同的<strong>mini-batch</strong>，所以我们有$X^{\{ t\} }$和$Y^{\{ t\} }$，检查一下自己是否理解无误。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/539405047b6986e05f2a3eb06dd7027d.png" alt="539405047b6986e05f2a3eb06dd7027d"></p> $X^{\{ t\} }$和$Y^{\{ t\} }$的维数：如果$X^{\{1\} }$是一个有1000个样本的训练集，或者说是1000个样本的$x$值，所以维数应该是$(n_{x},1000)$，$X^{\{2\} }$的维数应该是$(n_{x},1000)$，以此类推。因此所有的子集维数都是$(n_{x},1000)$，而这些（$Y^{\{ t\} }$）的维数都是$(1,1000)$。<p>解释一下这个算法的名称，<strong>batch</strong>梯度下降法指的是我们之前讲过的梯度下降法算法，就是同时处理整个训练集，这个名字就是来源于能够同时看到整个<strong>batch</strong>训练集的样本被处理，这个名字不怎么样，但就是这样叫它。</p><p>相比之下，<strong>mini-batch</strong>梯度下降法，指的是我们在下一张幻灯片中会讲到的算法，你每次同时处理的单个的<strong>mini-batch</strong> $X^{\{t\} }$和$Y^{\{ t\} }$，而不是同时处理全部的$X$和$Y$训练集。</p><p>那么究竟<strong>mini-batch</strong>梯度下降法的原理是什么？在训练集上运行<strong>mini-batch</strong>梯度下降法，你运行<code>for t=1……5000</code>，因为我们有5000个各有1000个样本的组，在<strong>for</strong>循环里你要做得基本就是对$X^{\{t\} }$和$Y^{\{t\} }$执行一步梯度下降法。假设你有一个拥有1000个样本的训练集，而且假设你已经很熟悉一次性处理完的方法，你要用向量化去几乎同时处理1000个样本。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0818dc0f8b7b8c1703d0c596f6027728.png" alt="0818dc0f8b7b8c1703d0c596f6027728"><br>首先对输入也就是$X^{\{ t\} }$，执行前向传播，然后执行$z^{\lbrack 1\rbrack} =W^{\lbrack 1\rbrack}X + b^{\lbrack 1\rbrack}$，之前我们这里只有，但是现在你正在处理整个训练集，你在处理第一个<strong>mini-batch</strong>，在处理<strong>mini-batch</strong>时它变成了$X^{\{ t\} }$，即$z^{\lbrack 1\rbrack} = W^{\lbrack 1\rbrack}X^{\{ t\} } + b^{\lbrack1\rbrack}$，然后执行$A^{[1]k} =g^{[1]}(Z^{[1]})$，之所以用大写的$Z$是因为这是一个向量内涵，以此类推，直到$A^{\lbrack L\rbrack} = g^{\left\lbrack L \right\rbrack}(Z^{\lbrack L\rbrack})$，这就是你的预测值。注意这里你需要用到一个向量化的执行命令，这个向量化的执行命令，一次性处理1000个而不是500万个样本。接下来你要计算损失成本函数$J$，因为子集规模是1000，$J= \frac{1}{1000}\sum_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})}$，说明一下，这（$L(\hat y^{(i)},y^{(i)})$）指的是来自于<strong>mini-batch</strong>$X^{\{ t\} }$和$Y^{\{t\} }$中的样本。</p><p>如果你用到了正则化，你也可以使用正则化的术语，$J =\frac{1}{1000}\sum_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})} +\frac{\lambda}{2 1000}\sum_{l}^{}{||w^{[l]}||}_{F}^{2}$，因为这是一个<strong>mini-batch</strong>的损失，所以我将$J$损失记为上角标$t$，放在大括号里（$J^{\{t\} } = \frac{1}{1000}\sum_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})} +\frac{\lambda}{2 1000}\sum_{l}^{}{||w^{[l]}||}_{F}^{2}$）。</p><p>你也会注意到，我们做的一切似曾相识，其实跟之前我们执行梯度下降法如出一辙，除了你现在的对象不是$X$，$Y$，而是$X^{\{t\} }$和$Y^{\{ t\} }$。接下来，你执行反向传播来计算$J^{\{t\} }$的梯度，你只是使用$X^{\{ t\} }$和$Y^{\{t\} }$，然后你更新加权值，$W$实际上是$W^{\lbrack l\rbrack}$，更新为$W^{[l]}:= W^{[l]} - adW^{[l]}$，对$b$做相同处理，$b^{[l]}:= b^{[l]} - adb^{[l]}$。这是使用<strong>mini-batch</strong>梯度下降法训练样本的一步，我写下的代码也可被称为进行“一代”（<strong>1 epoch</strong>）的训练。一代这个词意味着只是一次遍历了训练集。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0818dc0f8b7b8c1703d0c596f6027728.png" alt="0818dc0f8b7b8c1703d0c596f6027728"><br>使用<strong>batch</strong>梯度下降法，一次遍历训练集只能让你做一个梯度下降，使用<strong>mini-batch</strong>梯度下降法，一次遍历训练集，能让你做5000个梯度下降。当然正常来说你想要多次遍历训练集，还需要为另一个<strong>while</strong>循环设置另一个<strong>for</strong>循环。所以你可以一直处理遍历训练集，直到最后你能收敛到一个合适的精度。</p><p>如果你有一个丢失的训练集，<strong>mini-batch</strong>梯度下降法比<strong>batch</strong>梯度下降法运行地更快，所以几乎每个研习深度学习的人在训练巨大的数据集时都会用到，下一个视频中，我们将进一步深度讨论<strong>mini-batch</strong>梯度下降法，你也会因此更好地理解它的作用和原理。</p><h3 id="2-2-理解mini-batch梯度下降法（Understanding-mini-batch-gradient-descent）"><a href="#2-2-理解mini-batch梯度下降法（Understanding-mini-batch-gradient-descent）" class="headerlink" title="2.2 理解mini-batch梯度下降法（Understanding mini-batch gradient descent）"></a>2.2 理解mini-batch梯度下降法（Understanding mini-batch gradient descent）</h3><p>在上周视频中，你知道了如何利用<strong>mini-batch</strong>梯度下降法来开始处理训练集和开始梯度下降，即使你只处理了部分训练集，即使你是第一次处理，本视频中，我们将进一步学习如何执行梯度下降法，更好地理解其作用和原理。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b5c07d7dec7e54bed73cdcd43e79452d.png" alt="b5c07d7dec7e54bed73cdcd43e79452d"><br>使用<strong>batch</strong>梯度下降法时，每次迭代你都需要历遍整个训练集，可以预期每次迭代成本都会下降，所以如果成本函数$J$是迭代次数的一个函数，它应该会随着每次迭代而减少，如果$J$在某次迭代中增加了，那肯定出了问题，也许你的学习率太大。</p><p>使用<strong>mini-batch</strong>梯度下降法，如果你作出成本函数在整个过程中的图，则并不是每次迭代都是下降的，特别是在每次迭代中，你要处理的是$X^{\{t\} }$和$Y^{\{ t\} }$，如果要作出成本函数$J^{\{ t\} }$的图，而$J^{\{t\} }$只和$X^{\{ t\} }$，$Y^{\{t\} }$有关，也就是每次迭代下你都在训练不同的样本集或者说训练不同的<strong>mini-batch</strong>，如果你要作出成本函数$J$的图，你很可能会看到这样的结果，走向朝下，但有更多的噪声，所以如果你作出$J^{\{t\} }$的图，因为在训练<strong>mini-batch</strong>梯度下降法时，会经过多代，你可能会看到这样的曲线。没有每次迭代都下降是不要紧的，但走势应该向下，噪声产生的原因在于也许$X^{\{1\} }$和$Y^{\{1\} }$是比较容易计算的<strong>mini-batch</strong>，因此成本会低一些。不过也许出于偶然，$X^{\{2\} }$和$Y^{\{2\} }$是比较难运算的<strong>mini-batch</strong>，或许你需要一些残缺的样本，这样一来，成本会更高一些，所以才会出现这些摆动，因为你是在运行<strong>mini-batch</strong>梯度下降法作出成本函数图。</p><p>你需要决定的变量之一是<strong>mini-batch</strong>的大小，$m$就是训练集的大小，极端情况下，如果<strong>mini-batch</strong>的大小等于$m$，其实就是<strong>batch</strong>梯度下降法，在这种极端情况下，你就有了<strong>mini-batch</strong> $X^{\{1\} }$和$Y^{\{1\} }$，并且该<strong>mini-batch</strong>等于整个训练集，所以把<strong>mini-batch</strong>大小设为$m$可以得到<strong>batch</strong>梯度下降法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2181fbdc47d4d28840c3da00295548ea.png" alt="2181fbdc47d4d28840c3da00295548ea"><br>另一个极端情况，假设<strong>mini-batch</strong>大小为1，就有了新的算法，叫做随机梯度下降法，每个样本都是独立的<strong>mini-batch</strong>，当你看第一个<strong>mini-batch</strong>，也就是$X^{\{1\} }$和$Y^{\{1\} }$，如果<strong>mini-batch</strong>大小为1，它就是你的第一个训练样本，这就是你的第一个训练样本。接着再看第二个<strong>mini-batch</strong>，也就是第二个训练样本，采取梯度下降步骤，然后是第三个训练样本，以此类推，一次只处理一个。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6ffa1351889a85cb5247fc7c43555959.png" alt="6ffa1351889a85cb5247fc7c43555959"><br>看在两种极端下成本函数的优化情况，如果这是你想要最小化的成本函数的轮廓，最小值在那里，<strong>batch</strong>梯度下降法从某处开始，相对噪声低些，幅度也大一些，你可以继续找最小值。</p><p>相反，在随机梯度下降法中，从某一点开始，我们重新选取一个起始点，每次迭代，你只对一个样本进行梯度下降，大部分时候你向着全局最小值靠近，有时候你会远离最小值，因为那个样本恰好给你指的方向不对，因此随机梯度下降法是有很多噪声的，平均来看，它最终会靠近最小值，不过有时候也会方向错误，因为随机梯度下降法永远不会收敛，而是会一直在最小值附近波动，但它并不会在达到最小值并停留在此。</p><p>实际上你选择的<strong>mini-batch</strong>大小在二者之间，大小在1和$m$之间，而1太小了，$m$太大了，原因在于如果使用<strong>batch</strong>梯度下降法，<strong>mini-batch</strong>的大小为$m$，每个迭代需要处理大量训练样本，该算法的主要弊端在于特别是在训练样本数量巨大的时候，单次迭代耗时太长。如果训练样本不大，<strong>batch</strong>梯度下降法运行地很好。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f5fce700d57a539bebebdc0e5195c5fb.png" alt="f5fce700d57a539bebebdc0e5195c5fb"><br>相反，如果使用随机梯度下降法，如果你只要处理一个样本，那这个方法很好，这样做没有问题，通过减小学习率，噪声会被改善或有所减小，但随机梯度下降法的一大缺点是，你会失去所有向量化带给你的加速，因为一次性只处理了一个训练样本，这样效率过于低下，所以实践中最好选择不大不小的<strong>mini-batch</strong>尺寸，实际上学习率达到最快。你会发现两个好处，一方面，你得到了大量向量化，上个视频中我们用过的例子中，如果<strong>mini-batch</strong>大小为1000个样本，你就可以对1000个样本向量化，比你一次性处理多个样本快得多。另一方面，你不需要等待整个训练集被处理完就可以开始进行后续工作，再用一下上个视频的数字，每次训练集允许我们采取5000个梯度下降步骤，所以实际上一些位于中间的<strong>mini-batch</strong>大小效果最好。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bb2398f985f57c5d422df3c71437e5ea.png" alt="bb2398f985f57c5d422df3c71437e5ea"><br>用<strong>mini-batch</strong>梯度下降法，我们从这里开始，一次迭代这样做，两次，三次，四次，它不会总朝向最小值靠近，但它比随机梯度下降要更持续地靠近最小值的方向，它也不一定在很小的范围内收敛或者波动，如果出现这个问题，可以慢慢减少学习率，我们在下个视频会讲到学习率衰减，也就是如何减小学习率。</p><p>如果<strong>mini-batch</strong>大小既不是1也不是$m$，应该取中间值，那应该怎么选择呢？其实是有指导原则的。</p><p>首先，如果训练集较小，直接使用<strong>batch</strong>梯度下降法，样本集较小就没必要使用<strong>mini-batch</strong>梯度下降法，你可以快速处理整个训练集，所以使用<strong>batch</strong>梯度下降法也很好，这里的少是说小于2000个样本，这样比较适合使用<strong>batch</strong>梯度下降法。不然，样本数目较大的话，一般的<strong>mini-batch</strong>大小为64到512，考虑到电脑内存设置和使用的方式，如果<strong>mini-batch</strong>大小是2的$n$次方，代码会运行地快一些，64就是2的6次方，以此类推，128是2的7次方，256是2的8次方，512是2的9次方。所以我经常把<strong>mini-batch</strong>大小设成2的次方。在上一个视频里，我的<strong>mini-batch</strong>大小设为了1000，建议你可以试一下1024，也就是2的10次方。也有<strong>mini-batch</strong>的大小为1024，不过比较少见，64到512的<strong>mini-batch</strong>比较常见。</p><p>最后需要注意的是在你的<strong>mini-batch</strong>中，要确保$X^{\{ t\} }$和$Y^{\{t\} }$要符合<strong>CPU</strong>/<strong>GPU</strong>内存，取决于你的应用方向以及训练集的大小。如果你处理的<strong>mini-batch</strong>和<strong>CPU</strong>/<strong>GPU</strong>内存不相符，不管你用什么方法处理数据，你会注意到算法的表现急转直下变得惨不忍睹，所以我希望你对一般人们使用的<strong>mini-batch</strong>大小有一个直观了解。事实上<strong>mini-batch</strong>大小是另一个重要的变量，你需要做一个快速尝试，才能找到能够最有效地减少成本函数的那个，我一般会尝试几个不同的值，几个不同的2次方，然后看能否找到一个让梯度下降优化算法最高效的大小。希望这些能够指导你如何开始找到这一数值。</p><p>你学会了如何执行<strong>mini-batch</strong>梯度下降，令算法运行得更快，特别是在训练样本数目较大的情况下。不过还有个更高效的算法，比梯度下降法和<strong>mini-batch</strong>梯度下降法都要高效的多，我们在接下来的视频中将为大家一一讲解。</p><h3 id="2-3-指数加权平均数（Exponentially-weighted-averages）"><a href="#2-3-指数加权平均数（Exponentially-weighted-averages）" class="headerlink" title="2.3 指数加权平均数（Exponentially weighted averages）"></a>2.3 指数加权平均数（Exponentially weighted averages）</h3><p>我想向你展示几个优化算法，它们比梯度下降法快，要理解这些算法，你需要用到指数加权平均，在统计中也叫做指数加权移动平均，我们首先讲这个，然后再来讲更复杂的优化算法。<br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0f9d1f236d2a4847e9d0c6eb4c5400dd.png" alt="0f9d1f236d2a4847e9d0c6eb4c5400dd"><br>虽然现在我生活在美国，实际上我生于英国伦敦。比如我这儿有去年伦敦的每日温度，所以1月1号，温度是40华氏度，相当于4摄氏度。我知道世界上大部分地区使用摄氏度，但是美国使用华氏度。在1月2号是9摄氏度等等。在年中的时候，一年365天，年中就是说，大概180天的样子，也就是5月末，温度是60华氏度，也就是15摄氏度等等。夏季温度转暖，然后冬季降温。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/66128cd2cc8d698c2a1fa351f2a22fb9.png" alt="66128cd2cc8d698c2a1fa351f2a22fb9"><br>你用数据作图，可以得到以下结果，起始日在1月份，这里是夏季初，这里是年末，相当于12月末。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d49c52a460376e00c8e5b40baed2cf23.png" alt="d49c52a460376e00c8e5b40baed2cf23"><br>这里是1月1号，年中接近夏季的时候，随后就是年末的数据，看起来有些杂乱，如果要计算趋势的话，也就是温度的局部平均值，或者说移动平均值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/625746a61a4573b7f8594a3c071044c5.png" alt="625746a61a4573b7f8594a3c071044c5"><br>你要做的是，首先使$v_{0} =0$，每天，需要使用0.9的加权数之前的数值加上当日温度的0.1倍，即$v_{1} =0.9v_{0} + 0.1\theta_{1}$，所以这里是第一天的温度值。</p><p>第二天，又可以获得一个加权平均数，0.9乘以之前的值加上当日的温度0.1倍，即$v_{2}= 0.9v_{1} + 0.1\theta_{2}$，以此类推。</p><p>第二天值加上第三日数据的0.1，如此往下。大体公式就是某天的$v$等于前一天$v$值的0.9加上当日温度的0.1。</p><p>如此计算，然后用红线作图的话，便得到这样的结果。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4324e926e3ba304e339cda820f61fc28.png" alt="4324e926e3ba304e339cda820f61fc28"><br>你得到了移动平均值，每日温度的指数加权平均值。</p><p>看一下上一张幻灯片里的公式，$v_{t} = 0.9v_{t - 1} +0.1\theta_{t}$，我们把0.9这个常数变成$\beta$，将之前的0.1变成$(1 - \beta)$，即$v_{t} = \beta v_{t - 1} + (1 - \beta)\theta_{t}$</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c8d108c5e38cfa4defe77cb517a8c7c2.png" alt="c8d108c5e38cfa4defe77cb517a8c7c2"><br>由于以后我们要考虑的原因，在计算时可视$v_{t}$大概是$\frac{1}{(1 -\beta)}$的每日温度，如果$\beta$是0.9，你会想，这是十天的平均值，也就是红线部分。</p><p>我们来试试别的，将$\beta$设置为接近1的一个值，比如0.98，计算$\frac{1}{(1 - 0.98)} =50$，这就是粗略平均了一下，过去50天的温度，这时作图可以得到绿线。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a3b26bbce9cd3d0decba5aa8b26af035.png" alt="a3b26bbce9cd3d0decba5aa8b26af035"><br>这个高值$\beta$要注意几点，你得到的曲线要平坦一些，原因在于你多平均了几天的温度，所以这个曲线，波动更小，更加平坦，缺点是曲线进一步右移，因为现在平均的温度值更多，要平均更多的值，指数加权平均公式在温度变化时，适应地更缓慢一些，所以会出现一定延迟，因为当$\beta=0.98$，相当于给前一天的值加了太多权重，只有0.02的权重给了当日的值，所以温度变化时，温度上下起伏，当$\beta$ 较大时，指数加权平均值适应地更缓慢一些。</p><p>我们可以再换一个值试一试，如果$\beta$是另一个极端值，比如说0.5，根据右边的公式（$\frac{1}{(1-\beta)}$），这是平均了两天的温度。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/81710bf53763e939fdac8bd8736960e6.png" alt="81710bf53763e939fdac8bd8736960e6"><br>作图运行后得到黄线。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/369ae78c3b63e5b537cc0e30f60eb471.png" alt="369ae78c3b63e5b537cc0e30f60eb471"><br>由于仅平均了两天的温度，平均的数据太少，所以得到的曲线有更多的噪声，有可能出现异常值，但是这个曲线能够更快适应温度变化。</p><p>所以指数加权平均数经常被使用，再说一次，它在统计学中被称为指数加权移动平均值，我们就简称为指数加权平均数。通过调整这个参数（$\beta$），或者说后面的算法学习，你会发现这是一个很重要的参数，可以取得稍微不同的效果，往往中间有某个值效果最好，$\beta$为中间值时得到的红色曲线，比起绿线和黄线更好地平均了温度。</p><p>现在你知道计算指数加权平均数的基本原理，下一个视频中，我们再聊聊它的本质作用。</p><h3 id="2-4-理解指数加权平均数（Understanding-exponentially-weighted-averages）"><a href="#2-4-理解指数加权平均数（Understanding-exponentially-weighted-averages）" class="headerlink" title="2.4 理解指数加权平均数（Understanding exponentially weighted averages）"></a>2.4 理解指数加权平均数（Understanding exponentially weighted averages）</h3><p>上个视频中，我们讲到了指数加权平均数，这是几个优化算法中的关键一环，而这几个优化算法能帮助你训练神经网络。本视频中，我希望进一步探讨算法的本质作用。</p><p>回忆一下这个计算指数加权平均数的关键方程。</p> ${ {v}_{t} }=\beta { {v}_{t-1} }+(1-\beta ){ {\theta }_{t} }$ $\beta=0.9$的时候，得到的结果是红线，如果它更接近于1，比如0.98，结果就是绿线，如果$\beta$小一点，如果是0.5，结果就是黄线。<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6f5438fde578ef4285059d85976d52ed.png" alt="6f5438fde578ef4285059d85976d52ed"><br>我们进一步地分析，来理解如何计算出每日温度的平均值。</p><p>同样的公式，${ {v}_{t} }=\beta { {v}_{t-1} }+(1-\beta ){ {\theta }_{t} }$</p><p>使$\beta=0.9$，写下相应的几个公式，所以在执行的时候，$t$从0到1到2到3，$t$的值在不断增加，为了更好地分析，我写的时候使得$t$的值不断减小，然后继续往下写。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9ab7565d5a3e13a9a525ec6d2f119a79.png" alt="9ab7565d5a3e13a9a525ec6d2f119a79"><br>首先看第一个公式，理解$v_{100}$是什么？我们调换一下这两项（$0.9v_{99}0.1\theta_{100}$），$v_{100}= 0.1\theta_{100} + 0.9v_{99}$。</p><p>那么$v_{99}$是什么？我们就代入这个公式（$v_{99} = 0.1\theta_{99} +0.9v_{98}$），所以：</p> $v_{100} = 0.1\theta_{100} + 0.9(0.1\theta_{99} + 0.9v_{98})$。<p>那么$v_{98}$是什么？你可以用这个公式计算（$v_{98} = 0.1\theta_{98} +0.9v_{97}$），把公式代进去，所以：</p> $v_{100} = 0.1\theta_{100} + 0.9(0.1\theta_{99} + 0.9(0.1\theta_{98} +0.9v_{97}))$。<p>以此类推，如果你把这些括号都展开，</p> $v_{100} = 0.1\theta_{100} + 0.1 \times 0.9 \theta_{99} + 0.1 \times {(0.9)}^{2}\theta_{98} + 0.1 \times {(0.9)}^{3}\theta_{97} + 0.1 \times {(0.9)}^{4}\theta_{96} + \ldots$<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a3f97d59db202127014297ceccf1aacb.png" alt="a3f97d59db202127014297ceccf1aacb"><br>所以这是一个加和并平均，100号数据，也就是当日温度。我们分析$v_{100}$的组成，也就是在一年第100天计算的数据，但是这个是总和，包括100号数据，99号数据，97号数据等等。画图的一个办法是，假设我们有一些日期的温度，所以这是数据，这是$t$，所以100号数据有个数值，99号数据有个数值，98号数据等等，$t$为100，99，98等等，这就是数日的温度数值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/469d894aae98925841134e9766557fc7.png" alt="469d894aae98925841134e9766557fc7"><br>然后我们构建一个指数衰减函数，从0.1开始，到$0.1 \times 0.9$，到$0.1 \times {(0.9)}^{2}$，以此类推，所以就有了这个指数衰减函数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a0bbcc060cac02d8d3f0b1403484f017.png" alt="a0bbcc060cac02d8d3f0b1403484f017"><br>计算$v_{100}$是通过，把两个函数对应的元素，然后求和，用这个数值100号数据值乘以0.1，99号数据值乘以0.1乘以${(0.9)}^{2}$，这是第二项，以此类推，所以选取的是每日温度，将其与指数衰减函数相乘，然后求和，就得到了$v_{100}$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/880dbafaccbd93a4ab0a92a9b8607956.png" alt="880dbafaccbd93a4ab0a92a9b8607956"><br>结果是，稍后我们详细讲解，不过所有的这些系数（$0.10.1 \times 0.90.1 \times {(0.9)}^{2}0.1 \times {(0.9)}^{3}\ldots$），相加起来为1或者逼近1，我们称之为偏差修正，下个视频会涉及。</p><p>最后也许你会问，到底需要平均多少天的温度。实际上${(0.9)}^{10}$大约为0.35，这大约是$\frac{1}{e}$，e是自然算法的基础之一。大体上说，如果有$1-\varepsilon$，在这个例子中，$\varepsilon=0.1$，所以$1-\varepsilon=0.9$，${(1-\varepsilon)}^{(\frac{1}{\varepsilon})}$约等于$\frac{1}{e}$，大约是0.34，0.35，换句话说，10天后，曲线的高度下降到$\frac{1}{3}$，相当于在峰值的$\frac{1}{e}$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9cef2303cf6d7893020647bfde69b22c.png" alt="9cef2303cf6d7893020647bfde69b22c"><br>又因此当$\beta=0.9$的时候，我们说仿佛你在计算一个指数加权平均数，只关注了过去10天的温度，因为10天后，权重下降到不到当日权重的三分之一。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7820d206a4afa0a694333e74ad74233b.png" alt="7820d206a4afa0a694333e74ad74233b"><br>相反，如果，那么0.98需要多少次方才能达到这么小的数值？${(0.98)}^{50}$大约等于$\frac{1}{e}$，所以前50天这个数值比$\frac{1}{e}$大，数值会快速衰减，所以本质上这是一个下降幅度很大的函数，你可以看作平均了50天的温度。因为在例子中，要代入等式的左边，$\varepsilon=0.02$，所以$\frac{1}{\varepsilon}$为50，我们由此得到公式，我们平均了大约$\frac{1}{(1-\beta)}$天的温度，这里$\varepsilon$代替了$1-\beta$，也就是说根据一些常数，你能大概知道能够平均多少日的温度，不过这只是思考的大致方向，并不是正式的数学证明。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/358269d36d06e3c70da3e87d8dc523e4.png" alt="358269d36d06e3c70da3e87d8dc523e4"><br>最后讲讲如何在实际中执行，还记得吗？我们一开始将$v_{0}$设置为0，然后计算第一天$v_{1}$，然后$v_{2}$，以此类推。</p><p>现在解释一下算法，可以将$v_{0}$，$v_{1}$，$v_{2}$等等写成明确的变量，不过在实际中执行的话，你要做的是，一开始将$v$初始化为0，然后在第一天使$v:= \beta v + (1 - \beta)\theta_{1}$，然后第二天，更新$v$值，$v: = \beta v + (1 -\beta)\theta_{2}$，以此类推，有些人会把$v$加下标，来表示$v$是用来计算数据的指数加权平均数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/53d041ed225ba1d37f239b6498bd134e.png" alt="53d041ed225ba1d37f239b6498bd134e"><br>再说一次，但是换个说法，$v_{\theta} =0$，然后每一天，拿到第$t$天的数据，把$v$更新为$v: = \beta v_{\theta} + (1 -\beta)\theta_{t}$。</p><p>指数加权平均数公式的好处之一在于，它占用极少内存，电脑内存中只占用一行数字而已，然后把最新数据代入公式，不断覆盖就可以了，正因为这个原因，其效率，它基本上只占用一行代码，计算指数加权平均数也只占用单行数字的存储和内存，当然它并不是最好的，也不是最精准的计算平均数的方法。如果你要计算移动窗，你直接算出过去10天的总和，过去50天的总和，除以10和50就好，如此往往会得到更好的估测。但缺点是，如果保存所有最近的温度数据，和过去10天的总和，必须占用更多的内存，执行更加复杂，计算成本也更加高昂。</p><p>所以在接下来的视频中，我们会计算多个变量的平均值，从计算和内存效率来说，这是一个有效的方法，所以在机器学习中会经常使用，更不用说只要一行代码，这也是一个优势。</p><p>现在你学会了计算指数加权平均数，你还需要知道一个专业概念，叫做偏差修正，下一个视频我们会讲到它，接着你就可以用它构建更好的优化算法，而不是简单直接的梯度下降法。</p><h3 id="2-5-指数加权平均的偏差修正（Bias-correction-in-exponentially-weighted-averages）"><a href="#2-5-指数加权平均的偏差修正（Bias-correction-in-exponentially-weighted-averages）" class="headerlink" title="2.5 指数加权平均的偏差修正（Bias correction in exponentially weighted averages）"></a>2.5 指数加权平均的偏差修正（Bias correction in exponentially weighted averages）</h3><p>你学过了如何计算指数加权平均数，有一个技术名词叫做偏差修正，可以让平均数运算更加准确，来看看它是怎么运行的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/26a3c3022a7f7ae7ba0cd27fc74cbcf6.png" alt="26a3c3022a7f7ae7ba0cd27fc74cbcf6"></p> ${ {v}_{t} }=\beta { {v}_{t-1} }+(1-\beta ){ {\theta }_{t} }$<p>在上一个视频中，这个（红色）曲线对应$\beta$的值为0.9，这个（绿色）曲线对应的$\beta$=0.98，如果你执行写在这里的公式，在$\beta$等于0.98的时候，得到的并不是绿色曲线，而是紫色曲线，你可以注意到紫色曲线的起点较低，我们来看看怎么处理。</p><p>计算移动平均数的时候，初始化$v_{0} = 0$，$v_{1} = 0.98v_{0} +0.02\theta_{1}$，但是$v_{0} =0$，所以这部分没有了（$0.98v_{0}$），所以$v_{1} =0.02\theta_{1}$，所以如果一天温度是40华氏度，那么$v_{1} = 0.02\theta_{1} =0.02 \times 40 = 8$，因此得到的值会小很多，所以第一天温度的估测不准。</p> $v_{2} = 0.98v_{1} + 0.02\theta_{2}$，如果代入$v_{1}$，然后相乘，所以$v_{2}= 0.98 \times 0.02\theta_{1} + 0.02\theta_{2} = 0.0196\theta_{1} +0.02\theta_{2}$，假设$\theta_{1}$和$\theta_{2}$都是正数，计算后$v_{2}$要远小于$\theta_{1}$和$\theta_{2}$，所以$v_{2}$不能很好估测出这一年前两天的温度。<p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f602c9d517a7f6c01fe18171dade17e6.png" alt="f602c9d517a7f6c01fe18171dade17e6"><br>有个办法可以修改这一估测，让估测变得更好，更准确，特别是在估测初期，也就是不用$v_{t}$，而是用$\frac{v_{t} }{1- \beta^{t} }$，t就是现在的天数。举个具体例子，当$t=2$时，$1 - \beta^{t} = 1 - {0.98}^{2} = 0.0396$，因此对第二天温度的估测变成了$\frac{v_{2} }{0.0396} =\frac{0.0196\theta_{1} + 0.02\theta_{2} }{0.0396}$，也就是$\theta_{1}$和$\theta_{2}$的加权平均数，并去除了偏差。你会发现随着$t$增加，$\beta^{t}$接近于0，所以当$t$很大的时候，偏差修正几乎没有作用，因此当$t$较大的时候，紫线基本和绿线重合了。不过在开始学习阶段，你才开始预测热身练习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。</p><p>在机器学习中，在计算指数加权平均数的大部分时候，大家不在乎执行偏差修正，因为大部分人宁愿熬过初始时期，拿到具有偏差的估测，然后继续计算下去。如果你关心初始时期的偏差，在刚开始计算指数加权移动平均数的时候，偏差修正能帮助你在早期获取更好的估测。</p><p>所以你学会了计算指数加权移动平均数，我们接着用它来构建更好的优化算法吧！</p><h3 id="2-6-动量梯度下降法（Gradient-descent-with-Momentum）"><a href="#2-6-动量梯度下降法（Gradient-descent-with-Momentum）" class="headerlink" title="2.6 动量梯度下降法（Gradient descent with Momentum）"></a>2.6 动量梯度下降法（Gradient descent with Momentum）</h3><p>还有一种算法叫做<strong>Momentum</strong>，或者叫做动量梯度下降法，运行速度几乎总是快于标准的梯度下降算法，简而言之，基本的想法就是计算梯度的指数加权平均数，并利用该梯度更新你的权重，在本视频中，我们呢要一起拆解单句描述，看看你到底如何计算。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/54322ca2d7b5aed9739fd079fb3b2b6d.png" alt="54322ca2d7b5aed9739fd079fb3b2b6d"><br>例如，如果你要优化成本函数，函数形状如图，红点代表最小值的位置，假设你从这里（蓝色点）开始梯度下降法，如果进行梯度下降法的一次迭代，无论是<strong>batch</strong>或<strong>mini-batch</strong>下降法，也许会指向这里，现在在椭圆的另一边，计算下一步梯度下降，结果或许如此，然后再计算一步，再一步，计算下去，你会发现梯度下降法要很多计算步骤对吧？</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f378695f4b475da6546b6ab239d27a3d.png" alt="f378695f4b475da6546b6ab239d27a3d"><br>慢慢摆动到最小值，这种上下波动减慢了梯度下降法的速度，你就无法使用更大的学习率，如果你要用较大的学习率（紫色箭头），结果可能会偏离函数的范围，为了避免摆动过大，你要用一个较小的学习率。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/cc2d415b8ccda9fdaba12c575d4d3c4b.png" alt="cc2d415b8ccda9fdaba12c575d4d3c4b"><br>另一个看待问题的角度是，在纵轴上，你希望学习慢一点，因为你不想要这些摆动，但是在横轴上，你希望加快学习，你希望快速从左向右移，移向最小值，移向红点。所以使用动量梯度下降法，你需要做的是，在每次迭代中，确切来说在第$t$次迭代的过程中，你会计算微分$dW$，$db$，我会省略上标$[l]$，你用现有的<strong>mini-batch</strong>计算$dW$，$db$。如果你用<strong>batch</strong>梯度下降法，现在的<strong>mini-batch</strong>就是全部的<strong>batch</strong>，对于<strong>batch</strong>梯度下降法的效果是一样的。如果现有的<strong>mini-batch</strong>就是整个训练集，效果也不错，你要做的是计算$v_{ {dW} }= \beta v_{ {dW} } + \left( 1 - \beta \right)dW$，这跟我们之前的计算相似，也就是$v = \beta v + \left( 1 - \beta \right)\theta_{t}$，$dW$的移动平均数，接着同样地计算$v_{db}$，$v_{db} = \beta v_{ {db} } + ( 1 - \beta){db}$，然后重新赋值权重，$W:= W -av_{ {dW} }$，同样$b:= b - a v_{db}$，这样就可以减缓梯度下降的幅度。</p><p>例如，在上几个导数中，你会发现这些纵轴上的摆动平均值接近于零，所以在纵轴方向，你希望放慢一点，平均过程中，正负数相互抵消，所以平均值接近于零。但在横轴方向，所有的微分都指向横轴方向，因此横轴方向的平均值仍然较大，因此用算法几次迭代后，你发现动量梯度下降法，最终纵轴方向的摆动变小了，横轴方向运动更快，因此你的算法走了一条更加直接的路径，在抵达最小值的路上减少了摆动。</p><p>动量梯度下降法的一个本质，这对有些人而不是所有人有效，就是如果你要最小化碗状函数，这是碗的形状，我画的不太好。</p><p>它们能够最小化碗状函数，这些微分项，想象它们为你从山上往下滚的一个球，提供了加速度，<strong>Momentum</strong>项相当于速度。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/be943a4d64800e989a375e7972fefbfe.png" alt="be943a4d64800e989a375e7972fefbfe"><br>想象你有一个碗，你拿一个球，微分项给了这个球一个加速度，此时球正向山下滚，球因为加速度越滚越快，而因为$\beta$ 稍小于1，表现出一些摩擦力，所以球不会无限加速下去，所以不像梯度下降法，每一步都独立于之前的步骤，你的球可以向下滚，获得动量，可以从碗向下加速获得动量。我发现这个球从碗滚下的比喻，物理能力强的人接受得比较好，但不是所有人都能接受，如果球从碗中滚下这个比喻，你理解不了，别担心。</p><p>最后我们来看具体如何计算，算法在此。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a3af0fb5e49e16c108e72d015ef0fdb6.png" alt="a3af0fb5e49e16c108e72d015ef0fdb6"><br>所以你有两个超参数，学习率$a$以及参数$\beta$，$\beta$控制着指数加权平均数。$\beta$最常用的值是0.9，我们之前平均了过去十天的温度，所以现在平均了前十次迭代的梯度。实际上$\beta$为0.9时，效果不错，你可以尝试不同的值，可以做一些超参数的研究，不过0.9是很棒的鲁棒数。那么关于偏差修正，所以你要拿$v_{dW}$和$v_{db}$除以$1-\beta^{t}$，实际上人们不这么做，因为10次迭代之后，因为你的移动平均已经过了初始阶段。实际中，在使用梯度下降法或动量梯度下降法时，人们不会受到偏差修正的困扰。当然$v_{ {dW} }$初始值是0，要注意到这是和$dW$拥有相同维数的零矩阵，也就是跟$W$拥有相同的维数，$v_{db}$的初始值也是向量零，所以和$db$拥有相同的维数，也就是和$b$是同一维数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/89d51f9b5882cf226111b2c0eda2f3e3.png" alt="89d51f9b5882cf226111b2c0eda2f3e3"><br>最后要说一点，如果你查阅了动量梯度下降法相关资料，你经常会看到一个被删除了的专业词汇，$1-\beta$被删除了，最后得到的是$v_{dW}= \beta v_{ {dW} } +dW$。用紫色版本的结果就是，所以$v_{ {dW} }$缩小了$1-\beta$倍，相当于乘以$\frac{1}{1- \beta}$，所以你要用梯度下降最新值的话，$a$要根据$\frac{1}{1 -\beta}$相应变化。实际上，二者效果都不错，只会影响到学习率$a$的最佳值。我觉得这个公式用起来没有那么自然，因为有一个影响，如果你最后要调整超参数$\beta$，就会影响到$v_{ {dW} }$和$v_{db}$，你也许还要修改学习率$a$，所以我更喜欢左边的公式，而不是删去了$1-\beta$的这个公式，所以我更倾向于使用左边的公式，也就是有$1-\beta$的这个公式，但是两个公式都将$\beta$设置为0.9，是超参数的常见选择，只是在这两个公式中，学习率$a$的调整会有所不同。</p><p>所以这就是动量梯度下降法，这个算法肯定要好于没有<strong>Momentum</strong>的梯度下降算法，我们还可以做别的事情来加快学习算法，我们将在接下来的视频中探讨这些问题。</p><h3 id="2-7-RMSprop"><a href="#2-7-RMSprop" class="headerlink" title="2.7 RMSprop"></a>2.7 RMSprop</h3><p>你们知道了动量（<strong>Momentum</strong>）可以加快梯度下降，还有一个叫做<strong>RMSprop</strong>的算法，全称是<strong>root mean square prop</strong>算法，它也可以加速梯度下降，我们来看看它是如何运作的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/01dcc876f49fece3c6ad5f5a158020f6.png" alt="01dcc876f49fece3c6ad5f5a158020f6"><br>回忆一下我们之前的例子，如果你执行梯度下降，虽然横轴方向正在推进，但纵轴方向会有大幅度摆动，为了分析这个例子，假设纵轴代表参数$b$，横轴代表参数$W$，可能有$W_{1}$，$W_{2}$或者其它重要的参数，为了便于理解，被称为$b$和$W$。</p><p>所以，你想减缓$b$方向的学习，即纵轴方向，同时加快，至少不是减缓横轴方向的学习，<strong>RMSprop</strong>算法可以实现这一点。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/553ee26f6efd82d9996dec5f77e3f12e.png" alt="553ee26f6efd82d9996dec5f77e3f12e"><br>在第$t$次迭代中，该算法会照常计算当下<strong>mini-batch</strong>的微分$dW$，$db$，所以我会保留这个指数加权平均数，我们用到新符号$S_{dW}$，而不是$v_{dW}$，因此$S_{dW}= \beta S_{dW} + (1 -\beta) {dW}^{2}$，澄清一下，这个平方的操作是针对这一整个符号的，这样做能够保留微分平方的加权平均数，同样$S_{db}= \beta S_{db} + (1 - \beta){db}^{2}$，再说一次，平方是针对整个符号的操作。</p><p>接着<strong>RMSprop</strong>会这样更新参数值，$W:= W -a\frac{dW}{\sqrt{S_{dW} }}$，$b:=b -\alpha\frac{db}{\sqrt{S_{db} }}$，我们来理解一下其原理。记得在横轴方向或者在例子中的$W$方向，我们希望学习速度快，而在垂直方向，也就是例子中的$b$方向，我们希望减缓纵轴上的摆动，所以有了$S_{dW}$和$S_{db}$，我们希望$S_{dW}$会相对较小，所以我们要除以一个较小的数，而希望$S_{db}$又较大，所以这里我们要除以较大的数字，这样就可以减缓纵轴上的变化。你看这些微分，垂直方向的要比水平方向的大得多，所以斜率在$b$方向特别大，所以这些微分中，$db$较大，$dW$较小，因为函数的倾斜程度，在纵轴上，也就是b方向上要大于在横轴上，也就是$W$方向上。$db$的平方较大，所以$S_{db}$也会较大，而相比之下，$dW$会小一些，亦或$dW$平方会小一些，因此$S_{dW}$会小一些，结果就是纵轴上的更新要被一个较大的数相除，就能消除摆动，而水平方向的更新则被较小的数相除。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d43cf7898bd88adff4aaac607c1bd5a1.png" alt="d43cf7898bd88adff4aaac607c1bd5a1"><br><strong>RMSprop</strong>的影响就是你的更新最后会变成这样（绿色线），纵轴方向上摆动较小，而横轴方向继续推进。还有个影响就是，你可以用一个更大学习率$a$，然后加快学习，而无须在纵轴上垂直方向偏离。</p><p>要说明一点，我一直把纵轴和横轴方向分别称为$b$和$W$，只是为了方便展示而已。实际中，你会处于参数的高维度空间，所以需要消除摆动的垂直维度，你需要消除摆动，实际上是参数$W_1$，$W_2$等的合集，水平维度可能$W_3$，$W_4$等等，因此把$W$和$b$分开只是方便说明。实际中$dW$是一个高维度的参数向量，$db$也是一个高维度参数向量，但是你的直觉是，在你要消除摆动的维度中，最终你要计算一个更大的和值，这个平方和微分的加权平均值，所以你最后去掉了那些有摆动的方向。所以这就是<strong>RMSprop</strong>，全称是均方根，因为你将微分进行平方，然后最后使用平方根。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/720d168e6679fd689fb87c6c5bcb27fa.png" alt="720d168e6679fd689fb87c6c5bcb27fa"><br>最后再就这个算法说一些细节的东西，然后我们再继续。下一个视频中，我们会将<strong>RMSprop</strong>和<strong>Momentum</strong>结合起来，我们在<strong>Momentum</strong>中采用超参数$\beta$，为了避免混淆，我们现在不用$\beta$，而采用超参数$\beta_{2}$以保证在<strong>Momentum</strong>和<strong>RMSprop</strong>中采用同一超参数。要确保你的算法不会除以0，如果$S_{dW}$的平方根趋近于0怎么办？得到的答案就非常大，为了确保数值稳定，在实际操练的时候，你要在分母上加上一个很小很小的$\varepsilon$，$\varepsilon$是多少没关系，$10^{-8}$是个不错的选择，这只是保证数值能稳定一些，无论什么原因，你都不会除以一个很小很小的数。所以<strong>RMSprop</strong>跟<strong>Momentum</strong>有很相似的一点，可以消除梯度下降中的摆动，包括<strong>mini-batch</strong>梯度下降，并允许你使用一个更大的学习率$a$，从而加快你的算法学习速度。</p><p>所以你学会了如何运用<strong>RMSprop</strong>，这是给学习算法加速的另一方法。关于<strong>RMSprop</strong>的一个有趣的事是，它首次提出并不是在学术研究论文中，而是在多年前<strong>Jeff Hinton</strong>在<strong>Coursera</strong>的课程上。我想<strong>Coursera</strong>并不是故意打算成为一个传播新兴的学术研究的平台，但是却达到了意想不到的效果。就是从<strong>Coursera</strong>课程开始，<strong>RMSprop</strong>开始被人们广为熟知，并且发展迅猛。</p><p>我们讲过了<strong>Momentum</strong>，我们讲了<strong>RMSprop</strong>，如果二者结合起来，你会得到一个更好的优化算法，在下个视频中我们再好好讲一讲为什么。</p><h3 id="2-8-Adam-优化算法-Adam-optimization-algorithm"><a href="#2-8-Adam-优化算法-Adam-optimization-algorithm" class="headerlink" title="2.8 Adam 优化算法(Adam optimization algorithm)"></a>2.8 Adam 优化算法(Adam optimization algorithm)</h3><p>在深度学习的历史上，包括许多知名研究者在内，提出了优化算法，并很好地解决了一些问题，但随后这些优化算法被指出并不能一般化，并不适用于多种神经网络，时间久了，深度学习圈子里的人开始多少有些质疑全新的优化算法，很多人都觉得动量（<strong>Momentum</strong>）梯度下降法很好用，很难再想出更好的优化算法。所以<strong>RMSprop</strong>以及<strong>Adam</strong>优化算法（<strong>Adam</strong>优化算法也是本视频的内容），就是少有的经受住人们考验的两种算法，已被证明适用于不同的深度学习结构，这个算法我会毫不犹豫地推荐给你，因为很多人都试过，并且用它很好地解决了许多问题。</p><p><strong>Adam</strong>优化算法基本上就是将<strong>Momentum</strong>和<strong>RMSprop</strong>结合在一起，那么来看看如何使用<strong>Adam</strong>算法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9ca9bfc160d53b23ea0d1164e6accffe.png" alt="9ca9bfc160d53b23ea0d1164e6accffe"><br>使用<strong>Adam</strong>算法，首先你要初始化，$v_{dW} = 0$，$S_{dW} =0$，$v_{db} = 0$，$S_{db} =0$，在第$t$次迭代中，你要计算微分，用当前的<strong>mini-batch</strong>计算$dW$，$db$，一般你会用<strong>mini-batch</strong>梯度下降法。接下来计算<strong>Momentum</strong>指数加权平均数，所以$v_{dW}= \beta_{1}v_{dW} + ( 1 - \beta_{1})dW$（使用$\beta_{1}$，这样就不会跟超参数$\beta_{2}$混淆，因为后面<strong>RMSprop</strong>要用到$\beta_{2}$），使用<strong>Momentum</strong>时我们肯定会用这个公式，但现在不叫它$\beta$，而叫它$\beta_{1}$。同样$v_{db}= \beta_{1}v_{db} + ( 1 -\beta_{1} ){db}$。</p><p>接着你用<strong>RMSprop</strong>进行更新，即用不同的超参数$\beta_{2}$，$S_{dW}=\beta_{2}S_{dW} + ( 1 - \beta_{2}){(dW)}^{2}$，再说一次，这里是对整个微分$dW$进行平方处理，$S_{db} =\beta_{2}S_{db} + \left( 1 - \beta_{2} \right){(db)}^{2}$。</p><p>相当于<strong>Momentum</strong>更新了超参数$\beta_{1}$，<strong>RMSprop</strong>更新了超参数$\beta_{2}$。一般使用<strong>Adam</strong>算法的时候，要计算偏差修正，$v_{dW}^{\text{corrected} }$，修正也就是在偏差修正之后，</p> $v_{dW}^{\text{corrected} }= \frac{v_{dW} }{1 - \beta_{1}^{t} }$，<p>同样$v_{db}^{\text{corrected} } =\frac{v_{db} }{1 -\beta_{1}^{t} }$，</p> $S$也使用偏差修正，也就是$S_{dW}^{\text{corrected} } =\frac{S_{dW} }{1 - \beta_{2}^{t} }$，$S_{db}^{\text{corrected} } =\frac{S_{db} }{1 - \beta_{2}^{t} }$。<p>最后更新权重，所以$W$更新后是$W:= W - \frac{a v_{dW}^{\text{corrected} }}{\sqrt{S_{dW}^{\text{corrected} }} +\varepsilon}$（如果你只是用<strong>Momentum</strong>，使用$v_{dW}$或者修正后的$v_{dW}$，但现在我们加入了<strong>RMSprop</strong>的部分，所以我们要除以修正后$S_{dW}$的平方根加上$\varepsilon$）。</p><p>根据类似的公式更新$b$值，$b:=b - \frac{\alpha v_{\text{db} }^{\text{corrected} }}{\sqrt{S_{\text{db} }^{\text{corrected} }} +\varepsilon}$。</p><p>所以<strong>Adam</strong>算法结合了<strong>Momentum</strong>和<strong>RMSprop</strong>梯度下降法，并且是一种极其常用的学习算法，被证明能有效适用于不同神经网络，适用于广泛的结构。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e9858303cd62eacc21759b16a121ff58.png" alt="e9858303cd62eacc21759b16a121ff58"><br>本算法中有很多超参数，超参数学习率$a$很重要，也经常需要调试，你可以尝试一系列值，然后看哪个有效。$\beta_{1}$常用的缺省值为0.9，这是dW的移动平均数，也就是$dW$的加权平均数，这是<strong>Momentum</strong>涉及的项。至于超参数$\beta_{2}$，<strong>Adam</strong>论文作者，也就是<strong>Adam</strong>算法的发明者，推荐使用0.999，这是在计算${(dW)}^{2}$以及${(db)}^{2}$的移动加权平均值，关于$\varepsilon$的选择其实没那么重要，<strong>Adam</strong>论文的作者建议$\varepsilon$为$10^{-8}$，但你并不需要设置它，因为它并不会影响算法表现。但是在使用<strong>Adam</strong>的时候，人们往往使用缺省值即可，$\beta_{1}$，$\beta_{2}$和$\varepsilon$都是如此，我觉得没人会去调整$\varepsilon$，然后尝试不同的$a$值，看看哪个效果最好。你也可以调整$\beta_{1}$和$\beta_{2}$，但我认识的业内人士很少这么干。</p><p>为什么这个算法叫做<strong>Adam</strong>？<strong>Adam</strong>代表的是<strong>Adaptive Moment Estimation</strong>，$\beta_{1}$用于计算这个微分（$dW$），叫做第一矩，$\beta_{2}$用来计算平方数的指数加权平均数（${(dW)}^{2}$），叫做第二矩，所以<strong>Adam</strong>的名字由此而来，但是大家都简称<strong>Adam</strong>权威算法。</p><p>顺便提一下，我有一个老朋友兼合作伙伴叫做<strong>Adam Coates</strong>。据我所知，他跟<strong>Adam</strong>算法没有任何关系，不过我觉得他偶尔会用到这个算法，不过有时有人会问我这个问题，我想你可能也有相同的疑惑。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/463d0a973dda9b0c8c04f46100b5e0ad.png" alt="463d0a973dda9b0c8c04f46100b5e0ad"><br>这就是关于<strong>Adam</strong>优化算法的全部内容，有了它，你可以更加快速地训练神经网络，在结束本周课程之前，我们还要讲一下超参数调整，以及更好地理解神经网络的优化问题有哪些。下个视频中，我们将讲讲学习率衰减。</p><h3 id="2-9-学习率衰减-Learning-rate-decay"><a href="#2-9-学习率衰减-Learning-rate-decay" class="headerlink" title="2.9 学习率衰减(Learning rate decay)"></a>2.9 学习率衰减(Learning rate decay)</h3><p>加快学习算法的一个办法就是随时间慢慢减少学习率，我们将之称为学习率衰减，我们来看看如何做到，首先通过一个例子看看，为什么要计算学习率衰减。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c1b5ed3bb9f4ef32fe47056a017e51bf.png" alt="c1b5ed3bb9f4ef32fe47056a017e51bf"><br>假设你要使用<strong>mini-batch</strong>梯度下降法，<strong>mini-batch</strong>数量不大，大概64或者128个样本，在迭代过程中会有噪音（蓝色线），下降朝向这里的最小值，但是不会精确地收敛，所以你的算法最后在附近摆动，并不会真正收敛，因为你用的$a$是固定值，不同的<strong>mini-batch</strong>中有噪音。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/095feaa609b0029d6abc5c74ef7b3b35.png" alt="095feaa609b0029d6abc5c74ef7b3b35"><br>但要慢慢减少学习率$a$的话，在初期的时候，$a$学习率还较大，你的学习还是相对较快，但随着$a$变小，你的步伐也会变慢变小，所以最后你的曲线（绿色线）会在最小值附近的一小块区域里摆动，而不是在训练过程中，大幅度在最小值附近摆动。</p><p>所以慢慢减少$a$的本质在于，在学习初期，你能承受较大的步伐，但当开始收敛的时候，小一些的学习率能让你步伐小一些。</p><p>你可以这样做到学习率衰减，记得一代要遍历一次数据，如果你有以下这样的训练集，</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7c4141aeec2ef4afc6aa534a486a34c8.png" alt="7c4141aeec2ef4afc6aa534a486a34c8"><br>你应该拆分成不同的<strong>mini-batch</strong>，第一次遍历训练集叫做第一代。第二次就是第二代，依此类推，你可以将$a$学习率设为$a= \frac{1}{1 + decayrate * \text{epoch}\text{-num} }a_{0}$（<strong>decay-rate</strong>称为衰减率，<strong>epoch-num</strong>为代数，$\alpha_{0}$为初始学习率），注意这个衰减率是另一个你需要调整的超参数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7e0edfb697e8262dc39a040a987c62bd.png" alt="7e0edfb697e8262dc39a040a987c62bd"><br>这里有一个具体例子，如果你计算了几代，也就是遍历了几次，如果$a_{0}$为0.2，衰减率<strong>decay-rate</strong>为1，那么在第一代中，$a = \frac{1}{1 + 1}a_{0} = 0.1$，这是在代入这个公式计算（$a= \frac{1}{1 + decayrate * \text{epoch}\text{-num} }a_{0}$），此时衰减率是1而代数是1。在第二代学习率为0.67，第三代变成0.5，第四代为0.4等等，你可以自己多计算几个数据。要理解，作为代数函数，根据上述公式，你的学习率呈递减趋势。如果你想用学习率衰减，要做的是要去尝试不同的值，包括超参数$a_{0}$，以及超参数衰退率，找到合适的值，除了这个学习率衰减的公式，人们还会用其它的公式。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e1b6dc57b8b73ecf5ff400852c4f7086.png" alt="e1b6dc57b8b73ecf5ff400852c4f7086"><br>比如，这个叫做指数衰减，其中$a$相当于一个小于1的值，如$a ={0.95}^{\text{epoch-num} } a_{0}$，所以你的学习率呈指数下降。</p><p>人们用到的其它公式有$a =\frac{k}{\sqrt{\text{epoch-num} }}a_{0}$或者$a =\frac{k}{\sqrt{t} }a_{0}$（$t$为<strong>mini-batch</strong>的数字）。</p><p>有时人们也会用一个离散下降的学习率，也就是某个步骤有某个学习率，一会之后，学习率减少了一半，一会儿减少一半，一会儿又一半，这就是离散下降（<strong>discrete stair cease</strong>）的意思。</p><p>到现在，我们讲了一些公式，看学习率$a$究竟如何随时间变化。人们有时候还会做一件事，手动衰减。如果你一次只训练一个模型，如果你要花上数小时或数天来训练，有些人的确会这么做，看看自己的模型训练，耗上数日，然后他们觉得，学习速率变慢了，我把$a$调小一点。手动控制$a$当然有用，时复一时，日复一日地手动调整$a$，只有模型数量小的时候有用，但有时候人们也会这么做。</p><p>所以现在你有了多个选择来控制学习率$a$。你可能会想，好多超参数，究竟我应该做哪一个选择，我觉得，现在担心为时过早。下一周，我们会讲到，如何系统选择超参数。对我而言，学习率衰减并不是我尝试的要点，设定一个固定的$a$，然后好好调整，会有很大的影响，学习率衰减的确大有裨益，有时候可以加快训练，但它并不是我会率先尝试的内容，但下周我们将涉及超参数调整，你能学到更多系统的办法来管理所有的超参数，以及如何高效搜索超参数。</p><p>这就是学习率衰减，最后我还要讲讲神经网络中的局部最优以及鞍点，所以能更好理解在训练神经网络过程中，你的算法正在解决的优化问题，下个视频我们就好好聊聊这些问题。</p><h3 id="2-10-局部最优的问题-The-problem-of-local-optima"><a href="#2-10-局部最优的问题-The-problem-of-local-optima" class="headerlink" title="2.10 局部最优的问题(The problem of local optima)"></a>2.10 局部最优的问题(The problem of local optima)</h3><p>在深度学习研究早期，人们总是担心优化算法会困在极差的局部最优，不过随着深度学习理论不断发展，我们对局部最优的理解也发生了改变。我向你展示一下现在我们怎么看待局部最优以及深度学习中的优化问题。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a662f8be4a3a009b68c30a3e6e0683a3.png" alt="a662f8be4a3a009b68c30a3e6e0683a3"><br>这是曾经人们在想到局部最优时脑海里会出现的图，也许你想优化一些参数，我们把它们称之为$W_{1}$和$W_{2}$，平面的高度就是损失函数。在图中似乎各处都分布着局部最优。梯度下降法或者某个算法可能困在一个局部最优中，而不会抵达全局最优。如果你要作图计算一个数字，比如说这两个维度，就容易出现有多个不同局部最优的图，而这些低维的图曾经影响了我们的理解，但是这些理解并不正确。事实上，如果你要创建一个神经网络，通常梯度为零的点并不是这个图中的局部最优点，实际上成本函数的零梯度点，通常是鞍点。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1f7df04b804836fbcadcd258c0b55f74.png" alt="1f7df04b804836fbcadcd258c0b55f74"><br>也就是在这个点，这里是$W_{1}$和$W_{2}$，高度即成本函数$J$的值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a8c3dfdc238762a9f0edf26e6037ee09.png" alt><br>但是一个具有高维度空间的函数，如果梯度为0，那么在每个方向，它可能是凸函数，也可能是凹函数。如果你在2万维空间中，那么想要得到局部最优，所有的2万个方向都需要是这样，但发生的机率也许很小，也许是$2^{-20000}$，你更有可能遇到有些方向的曲线会这样向上弯曲，另一些方向曲线向下弯，而不是所有的都向上弯曲，因此在高维度空间，你更可能碰到鞍点。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ea0d64953a3a7b41ef2997c8fee2f930.png" alt="ea0d64953a3a7b41ef2997c8fee2f930"><br>就像下面的这种：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c5e480c51363d55e8d5e43df1eee679b.png" alt="c5e480c51363d55e8d5e43df1eee679b"><br>而不会碰到局部最优。至于为什么会把一个曲面叫做鞍点，你想象一下，就像是放在马背上的马鞍一样，如果这是马，这是马的头，这就是马的眼睛，画得不好请多包涵，然后你就是骑马的人，要坐在马鞍上，因此这里的这个点，导数为0的点，这个点叫做鞍点。我想那确实是你坐在马鞍上的那个点，而这里导数为0。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/011e9625870797d6c0695658b92f606e.png" alt="011e9625870797d6c0695658b92f606e"><br>所以我们从深度学习历史中学到的一课就是，我们对低维度空间的大部分直觉，比如你可以画出上面的图，并不能应用到高维度空间中。适用于其它算法，因为如果你有2万个参数，那么$J$函数有2万个维度向量，你更可能遇到鞍点，而不是局部最优点。</p><p>如果局部最优不是问题，那么问题是什么？结果是平稳段会减缓学习，平稳段是一块区域，其中导数长时间接近于0，如果你在此处，梯度会从曲面从从上向下下降，因为梯度等于或接近0，曲面很平坦，你得花上很长时间慢慢抵达平稳段的这个点，因为左边或右边的随机扰动，我换个笔墨颜色，大家看得清楚一些，然后你的算法能够走出平稳段（红色笔）。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/51d79b3734ccf1abdb0b9795a80d8bb7.png" alt="51d79b3734ccf1abdb0b9795a80d8bb7"><br>我们可以沿着这段长坡走，直到这里，然后走出平稳段。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/607bd30801c87ed74bb95c49f218f632.png" alt="607bd30801c87ed74bb95c49f218f632"><br>所以此次视频的要点是，首先，你不太可能困在极差的局部最优中，条件是你在训练较大的神经网络，存在大量参数，并且成本函数$J$被定义在较高的维度空间。</p><p>第二点，平稳段是一个问题，这样使得学习十分缓慢，这也是像<strong>Momentum</strong>或是<strong>RMSprop</strong>，<strong>Adam</strong>这样的算法，能够加速学习算法的地方。在这些情况下，更成熟的优化算法，如<strong>Adam</strong>算法，能够加快速度，让你尽早往下走出平稳段。</p><p>因为你的网络要解决优化问题，说实话，要面临如此之高的维度空间，我觉得没有人有那么好的直觉，知道这些空间长什么样，而且我们对它们的理解还在不断发展，不过我希望这一点能够让你更好地理解优化算法所面临的问题。</p><h2 id="超参数调试、Batch正则化和程序框架（Hyperparameter-tuning）"><a href="#超参数调试、Batch正则化和程序框架（Hyperparameter-tuning）" class="headerlink" title="超参数调试、Batch正则化和程序框架（Hyperparameter tuning）"></a>超参数调试、Batch正则化和程序框架（Hyperparameter tuning）</h2><h3 id="3-1-调试处理（Tuning-process）"><a href="#3-1-调试处理（Tuning-process）" class="headerlink" title="3.1 调试处理（Tuning process）"></a>3.1 调试处理（Tuning process）</h3><p>大家好，欢迎回来，目前为止，你已经了解到，神经网络的改变会涉及到许多不同超参数的设置。现在，对于超参数而言，你要如何找到一套好的设定呢？在此视频中，我想和你分享一些指导原则，一些关于如何系统地组织超参调试过程的技巧，希望这些能够让你更有效的聚焦到合适的超参设定中。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7b73f4de29ea13d9aba5f49e393d4674.png" alt="7b73f4de29ea13d9aba5f49e393d4674"><br>关于训练深度最难的事情之一是你要处理的参数的数量，从学习速率$a$到<strong>Momentum</strong>（动量梯度下降法）的参数$\beta$。如果使用<strong>Momentum</strong>或<strong>Adam</strong>优化算法的参数，$\beta_{1}$，${\beta}_{2}$和$\varepsilon$，也许你还得选择层数，也许你还得选择不同层中隐藏单元的数量，也许你还想使用学习率衰减。所以，你使用的不是单一的学习率$a$。接着，当然你可能还需要选择<strong>mini-batch</strong>的大小。</p><p>结果证实一些超参数比其它的更为重要，我认为，最为广泛的学习应用是$a$，学习速率是需要调试的最重要的超参数。</p><p>除了$a$，还有一些参数需要调试，例如<strong>Momentum</strong>参数$\beta$，0.9就是个很好的默认值。我还会调试<strong>mini-batch</strong>的大小，以确保最优算法运行有效。我还会经常调试隐藏单元，我用橙色圈住的这些，这三个是我觉得其次比较重要的，相对于$a$而言。重要性排第三位的是其他因素，层数有时会产生很大的影响，学习率衰减也是如此。当应用<strong>Adam</strong>算法时，事实上，我从不调试$\beta_{1}$，${\beta}_{2}$和$\varepsilon$，我总是选定其分别为0.9，0.999和$10^{-8}$，如果你想的话也可以调试它们。</p><p>但希望你粗略了解到哪些超参数较为重要，$a$无疑是最重要的，接下来是我用橙色圈住的那些，然后是我用紫色圈住的那些，但这不是严格且快速的标准，我认为，其它深度学习的研究者可能会很不同意我的观点或有着不同的直觉。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/75bfa084ea64d99b1d01a393a7c988a6.png" alt="75bfa084ea64d99b1d01a393a7c988a6"><br>现在，如果你尝试调整一些超参数，该如何选择调试值呢？在早一代的机器学习算法中，如果你有两个超参数，这里我会称之为超参1，超参2，常见的做法是在网格中取样点，像这样，然后系统的研究这些数值。这里我放置的是5×5的网格，实践证明，网格可以是5×5，也可多可少，但对于这个例子，你可以尝试这所有的25个点，然后选择哪个参数效果最好。当参数的数量相对较少时，这个方法很实用。</p><p>在深度学习领域，我们常做的，我推荐你采用下面的做法，随机选择点，所以你可以选择同等数量的点，对吗？25个点，接着，用这些随机取的点试验超参数的效果。之所以这么做是因为，对于你要解决的问题而言，你很难提前知道哪个超参数最重要，正如你之前看到的，一些超参数的确要比其它的更重要。</p><p>举个例子，假设超参数1是$a$（学习速率），取一个极端的例子，假设超参数2是<strong>Adam</strong>算法中，分母中的$\varepsilon$。在这种情况下，$a$的取值很重要，而$\varepsilon$取值则无关紧要。如果你在网格中取点，接着，你试验了$a$的5个取值，那你会发现，无论$\varepsilon$取何值，结果基本上都是一样的。所以，你知道共有25种模型，但进行试验的$a$值只有5个，我认为这是很重要的。</p><p>对比而言，如果你随机取值，你会试验25个独立的$a$，似乎你更有可能发现效果做好的那个。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7dbcb658f5054473480982c89e480c3f.png" alt="7dbcb658f5054473480982c89e480c3f"><br>我已经解释了两个参数的情况，实践中，你搜索的超参数可能不止两个。假如，你有三个超参数，这时你搜索的不是一个方格，而是一个立方体，超参数3代表第三维，接着，在三维立方体中取值，你会试验大量的更多的值，三个超参数中每个都是。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/961655e4384e6f148bbe23f9eb46e2b0.png" alt="961655e4384e6f148bbe23f9eb46e2b0"><br>实践中，你搜索的可能不止三个超参数有时很难预知，哪个是最重要的超参数，对于你的具体应用而言，随机取值而不是网格取值表明，你探究了更多重要超参数的潜在值，无论结果是什么。</p><p>当你给超参数取值时，另一个惯例是采用由粗糙到精细的策略。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c3b248ac8ca2cf646d5b705270e01e78.png" alt="c3b248ac8ca2cf646d5b705270e01e78"><br>比如在二维的那个例子中，你进行了取值，也许你会发现效果最好的某个点，也许这个点周围的其他一些点效果也很好，那在接下来要做的是放大这块小区域（小蓝色方框内），然后在其中更密集得取值或随机取值，聚集更多的资源，在这个蓝色的方格中搜索，如果你怀疑这些超参数在这个区域的最优结果，那在整个的方格中进行粗略搜索后，你会知道接下来应该聚焦到更小的方格中。在更小的方格中，你可以更密集得取点。所以这种从粗到细的搜索也经常使用。</p><p>通过试验超参数的不同取值，你可以选择对训练集目标而言的最优值，或对于开发集而言的最优值，或在超参搜索过程中你最想优化的东西。</p><p>我希望，这能给你提供一种方法去系统地组织超参数搜索过程。另一个关键点是随机取值和精确搜索，考虑使用由粗糙到精细的搜索过程。但超参数的搜索内容还不止这些，在下一个视频中，我会继续讲解关于如何选择超参数取值的合理范围。</p><h3 id="3-2-为超参数选择合适的范围（Using-an-appropriate-scale-to-pick-hyperparameters）"><a href="#3-2-为超参数选择合适的范围（Using-an-appropriate-scale-to-pick-hyperparameters）" class="headerlink" title="3.2 为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）"></a>3.2 为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）</h3><p>在上一个视频中，你已经看到了在超参数范围中，随机取值可以提升你的搜索效率。但随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数，这很重要。在这个视频中，我会教你怎么做。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3b45624120e77aea2fcd117cbfdc9bdb.png" alt="3b45624120e77aea2fcd117cbfdc9bdb"><br>假设你要选取隐藏单元的数量$n^{[l]}$，假设，你选取的取值范围是从50到100中某点，这种情况下，看到这条从50-100的数轴，你可以随机在其取点，这是一个搜索特定超参数的很直观的方式。或者，如果你要选取神经网络的层数，我们称之为字母$L$，你也许会选择层数为2到4中的某个值，接着顺着2，3，4随机均匀取样才比较合理，你还可以应用网格搜索，你会觉得2，3，4，这三个数值是合理的，这是在几个在你考虑范围内随机均匀取值的例子，这些取值还蛮合理的，但对某些超参数而言不适用。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/651422f74439fd7e648e364d26d21485.png" alt="651422f74439fd7e648e364d26d21485"><br>看看这个例子，假设你在搜索超参数$a$（学习速率），假设你怀疑其值最小是0.0001或最大是1。如果你画一条从0.0001到1的数轴，沿其随机均匀取值，那90%的数值将会落在0.1到1之间，结果就是，在0.1到1之间，应用了90%的资源，而在0.0001到0.1之间，只有10%的搜索资源，这看上去不太对。</p><p>反而，用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，分别依次取0.0001，0.001，0.01，0.1，1，在对数轴上均匀随机取点，这样，在0.0001到0.001之间，就会有更多的搜索资源可用，还有在0.001到0.01之间等等。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08307acea7c8db95c1479c611189dbfa.png" alt="08307acea7c8db95c1479c611189dbfa"><br>所以在<strong>Python</strong>中，你可以这样做，使<code>r=-4*np.random.rand()</code>，然后$a$随机取值，$ a =10^{r}$，所以，第一行可以得出$r \in [ 4,0]$，那么$a \in[10^{-4},10^{0}]$，所以最左边的数字是$10^{-4}$，最右边是$10^{0}$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fe47f46414d0c26183e85c7b2e4f2f0a.png" alt="fe47f46414d0c26183e85c7b2e4f2f0a"><br>更常见的情况是，如果你在$10^{a}$和$10^{b}$之间取值，在此例中，这是$10^{a}$（0.0001），你可以通过$\operatorname{}{0.0001}$算出$a$的值，即-4，在右边的值是$10^{b}$，你可以算出$b$的值$\operatorname{}1$，即0。你要做的就是在$[a,b]$区间随机均匀地给$r$取值，这个例子中$r \in \lbrack - 4,0\rbrack$，然后你可以设置$a$的值，基于随机取样的超参数$a =10^{r}$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a54d5ea6cd623f741f75e62195f072ca.png" alt="a54d5ea6cd623f741f75e62195f072ca"><br>所以总结一下，在对数坐标下取值，取最小值的对数就得到$a$的值，取最大值的对数就得到$b$值，所以现在你在对数轴上的$10^{a}$到$10^{b}$区间取值，在$a$，$b$间随意均匀的选取$r$值，将超参数设置为$10^{r}$，这就是在对数轴上取值的过程。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2c4e6d3419beb66ed0163331443c6b40.png" alt="2c4e6d3419beb66ed0163331443c6b40"><br>最后，另一个棘手的例子是给$\beta$ 取值，用于计算指数的加权平均值。假设你认为$\beta$是0.9到0.999之间的某个值，也许这就是你想搜索的范围。记住这一点，当计算指数的加权平均值时，取0.9就像在10个值中计算平均值，有点类似于计算10天的温度平均值，而取0.999就是在1000个值中取平均。</p><p>所以和上张幻灯片上的内容类似，如果你想在0.9到0.999区间搜索，那就不能用线性轴取值，对吧？不要随机均匀在此区间取值，所以考虑这个问题最好的方法就是，我们要探究的是$1-\beta$，此值在0.1到0.001区间内，所以我们会给$1-\beta$取值，大概是从0.1到0.001，应用之前幻灯片中介绍的方法，这是$10^{-1}$，这是$10^{-3}$，值得注意的是，在之前的幻灯片里，我们把最小值写在左边，最大值写在右边，但在这里，我们颠倒了大小。这里，左边的是最大值，右边的是最小值。所以你要做的就是在$[-3,-1]$里随机均匀的给r取值。你设定了$1- \beta = 10^{r}$，所以$\beta = 1-10^{r}$，然后这就变成了在特定的选择范围内超参数随机取值。希望用这种方式得到想要的结果，你在0.9到0.99区间探究的资源，和在0.99到0.999区间探究的一样多。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2e3b1803ab468a94a4cae13e89217704.png" alt="2e3b1803ab468a94a4cae13e89217704"><br>所以，如果你想研究更多正式的数学证明，关于为什么我们要这样做，为什么用线性轴取值不是个好办法，这是因为当$\beta$ 接近1时，所得结果的灵敏度会变化，即使$\beta$有微小的变化。所以$\beta$ 在0.9到0.9005之间取值，无关紧要，你的结果几乎不会变化。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/bb7feac2d0698b8721bfedbc67cc6289.png" alt="bb7feac2d0698b8721bfedbc67cc6289"><br>但$\beta$值如果在0.999到0.9995之间，这会对你的算法产生巨大影响，对吧？在这两种情况下，是根据大概10个值取平均。但这里，它是指数的加权平均值，基于1000个值，现在是2000个值，因为这个公式$\frac{1}{1- \beta}$，当$\beta$接近1时，$\beta$就会对细微的变化变得很敏感。所以整个取值过程中，你需要更加密集地取值，在$\beta$ 接近1的区间内，或者说，当$1-\beta$ 接近于0时，这样，你就可以更加有效的分布取样点，更有效率的探究可能的结果。</p><p>希望能帮助你选择合适的标尺，来给超参数取值。如果你没有在超参数选择中作出正确的标尺决定，别担心，即使你在均匀的标尺上取值，如果数值总量较多的话，你也会得到还不错的结果，尤其是应用从粗到细的搜索方法，在之后的迭代中，你还是会聚焦到有用的超参数取值范围上。</p><p>希望这会对你的超参数搜索有帮助，下一个视频中，我们将会分享一些关于如何组建搜索过程的思考，希望它能使你的工作更高效。</p><h3 id="3-3-超参数调试的实践：Pandas-VS-Caviar（Hyperparameters-tuning-in-practice-Pandas-vs-Caviar）"><a href="#3-3-超参数调试的实践：Pandas-VS-Caviar（Hyperparameters-tuning-in-practice-Pandas-vs-Caviar）" class="headerlink" title="3.3 超参数调试的实践：Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）"></a>3.3 超参数调试的实践：Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）</h3><p>到现在为止，你已经听了许多关于如何搜索最优超参数的内容，在结束我们关于超参数搜索的讨论之前，我想最后和你分享一些建议和技巧，关于如何组织你的超参数搜索过程。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3858f51032e483e215ebbd136dc07431.png" alt="3858f51032e483e215ebbd136dc07431"><br>如今的深度学习已经应用到许多不同的领域，某个应用领域的超参数设定，有可能通用于另一领域，不同的应用领域出现相互交融。比如，我曾经看到过计算机视觉领域中涌现的巧妙方法，比如说<strong>Confonets</strong>或<strong>ResNets</strong>，这我们会在后续课程中讲到。它还成功应用于语音识别，我还看到过最初起源于语音识别的想法成功应用于<strong>NLP</strong>等等。</p><p>深度学习领域中，发展很好的一点是，不同应用领域的人们会阅读越来越多其它研究领域的文章，跨领域去寻找灵感。</p><p>就超参数的设定而言，我见到过有些直觉想法变得很缺乏新意，所以，即使你只研究一个问题，比如说逻辑学，你也许已经找到一组很好的参数设置，并继续发展算法，或许在几个月的过程中，观察到你的数据会逐渐改变，或也许只是在你的数据中心更新了服务器，正因为有了这些变化，你原来的超参数的设定不再好用，所以我建议，或许只是重新测试或评估你的超参数，至少每隔几个月一次，以确保你对数值依然很满意。</p><p>最后，关于如何搜索超参数的问题，我见过大概两种重要的思想流派或人们通常采用的两种重要但不同的方式。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/439e7b041ac3d948e5852e8307dd09dd.png" alt="439e7b041ac3d948e5852e8307dd09dd"><br>一种是你照看一个模型，通常是有庞大的数据组，但没有许多计算资源或足够的<strong>CPU</strong>和<strong>GPU</strong>的前提下，基本而言，你只可以一次负担起试验一个模型或一小批模型，在这种情况下，即使当它在试验时，你也可以逐渐改良。比如，第0天，你将随机参数初始化，然后开始试验，然后你逐渐观察自己的学习曲线，也许是损失函数J，或者数据设置误差或其它的东西，在第1天内逐渐减少，那这一天末的时候，你可能会说，看，它学习得真不错。我试着增加一点学习速率，看看它会怎样，也许结果证明它做得更好，那是你第二天的表现。两天后，你会说，它依旧做得不错，也许我现在可以填充下<strong>Momentum</strong>或减少变量。然后进入第三天，每天，你都会观察它，不断调整你的参数。也许有一天，你会发现你的学习率太大了，所以你可能又回归之前的模型，像这样，但你可以说是在每天花时间照看此模型，即使是它在许多天或许多星期的试验过程中。所以这是一个人们照料一个模型的方法，观察它的表现，耐心地调试学习率，但那通常是因为你没有足够的计算能力，不能在同一时间试验大量模型时才采取的办法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1cbcd20a708281e777d2d0c50e355038.png" alt="1cbcd20a708281e777d2d0c50e355038"><br>另一种方法则是同时试验多种模型，你设置了一些超参数，尽管让它自己运行，或者是一天甚至多天，然后你会获得像这样的学习曲线，这可以是损失函数J或实验误差或损失或数据误差的损失，但都是你曲线轨迹的度量。同时你可以开始一个有着不同超参数设定的不同模型，所以，你的第二个模型会生成一个不同的学习曲线，也许是像这样的一条（紫色曲线），我会说这条看起来更好些。与此同时，你可以试验第三种模型，其可能产生一条像这样的学习曲线（红色曲线），还有另一条（绿色曲线），也许这条有所偏离，像这样，等等。或者你可以同时平行试验许多不同的模型，橙色的线就是不同的模型。用这种方式你可以试验许多不同的参数设定，然后只是最后快速选择工作效果最好的那个。在这个例子中，也许这条看起来是最好的（下方绿色曲线）。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/a361c621a9a0a1a99b03eef8716c5799.png" alt="a361c621a9a0a1a99b03eef8716c5799"><br>打个比方，我把左边的方法称为熊猫方式。当熊猫有了孩子，他们的孩子非常少，一次通常只有一个，然后他们花费很多精力抚养熊猫宝宝以确保其能成活，所以，这的确是一种照料，一种模型类似于一只熊猫宝宝。对比而言，右边的方式更像鱼类的行为，我称之为鱼子酱方式。在交配季节，有些鱼类会产下一亿颗卵，但鱼类繁殖的方式是，它们会产生很多卵，但不对其中任何一个多加照料，只是希望其中一个，或其中一群，能够表现出色。我猜，这就是哺乳动物繁衍和鱼类，很多爬虫类动物繁衍的区别。我将称之为熊猫方式与鱼子酱方式，因为这很有趣，更容易记住。</p><p>所以这两种方式的选择，是由你拥有的计算资源决定的，如果你拥有足够的计算机去平行试验许多模型，那绝对采用鱼子酱方式，尝试许多不同的超参数，看效果怎么样。但在一些应用领域，比如在线广告设置和计算机视觉应用领域，那里的数据太多了，你需要试验大量的模型，所以同时试验大量的模型是很困难的，它的确是依赖于应用的过程。但我看到那些应用熊猫方式多一些的组织，那里，你会像对婴儿一样照看一个模型，调试参数，试着让它工作运转。尽管，当然，甚至是在熊猫方式中，试验一个模型，观察它工作与否，也许第二或第三个星期后，也许我应该建立一个不同的模型（绿色曲线），像熊猫那样照料它，我猜，这样一生中可以培育几个孩子，即使它们一次只有一个孩子或孩子的数量很少。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5cd1e3dd73e69cbf0b2cbc80fddfa4d9.png" alt="5cd1e3dd73e69cbf0b2cbc80fddfa4d9"><br>所以希望你能学会如何进行超参数的搜索过程，现在，还有另一种技巧，能使你的神经网络变得更加坚实，它并不是对所有的神经网络都适用，但当适用时，它可以使超参数搜索变得容易许多并加速试验过程，我们在下个视频中再讲解这个技巧。</p><h3 id="3-4-归一化网络的激活函数（Normalizing-activations-in-a-network）"><a href="#3-4-归一化网络的激活函数（Normalizing-activations-in-a-network）" class="headerlink" title="3.4 归一化网络的激活函数（Normalizing activations in a network）"></a>3.4 归一化网络的激活函数（Normalizing activations in a network）</h3><p>在深度学习兴起后，最重要的一个思想是它的一种算法，叫做<strong>Batch</strong>归一化，由<strong>Sergey loffe</strong>和<strong>Christian Szegedy</strong>两位研究者创造。<strong>Batch</strong>归一化会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会是你的训练更加容易，甚至是深层网络。让我们来看看<strong>Batch</strong>归一化是怎么起作用的吧。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7eed1a2ef94832c54d1765731a57b2b5.png" alt="7eed1a2ef94832c54d1765731a57b2b5"><br>当训练一个模型，比如<strong>logistic</strong>回归时，你也许会记得，归一化输入特征可以加快学习过程。你计算了平均值，从训练集中减去平均值，计算了方差，接着根据方差归一化你的数据集，在之前的视频中我们看到，这是如何把学习问题的轮廓，从很长的东西，变成更圆的东西，更易于算法优化。所以这是有效的，对<strong>logistic</strong>回归和神经网络的归一化输入特征值而言。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/20949eb2c30cb22ab87eef411f01375d.png" alt="20949eb2c30cb22ab87eef411f01375d"><br>那么更深的模型呢？你不仅输入了特征值$x$，而且这层有激活值$a^{[1]}$，这层有激活值$a^{[2]}$等等。如果你想训练这些参数，比如$w^{[3]}$，$b^{[3]}$，那归一化$a^{[2]}$的平均值和方差岂不是很好？以便使$w^{[3]}$，$b^{[3]}$的训练更有效率。在<strong>logistic</strong>回归的例子中，我们看到了如何归一化$x_{1}$，$x_{2}$，$x_{3}$，会帮助你更有效的训练$w$和$b$。</p><p>所以问题来了，对任何一个隐藏层而言，我们能否归一化$a$值，在此例中，比如说$a^{[2]}$的值，但可以是任何隐藏层的，以更快的速度训练$w^{[3]}$，$b^{[3]}$，因为$a^{[2]}$是下一层的输入值，所以就会影响$w^{[3]}$，$b^{[3]}$的训练。简单来说，这就是<strong>Batch</strong>归一化的作用。尽管严格来说，我们真正归一化的不是$a^{[2]}$，而是$z^{[2]}$，深度学习文献中有一些争论，关于在激活函数之前是否应该将值$z^{[2]}$归一化，或是否应该在应用激活函数$a^{[2]}$后再规范值。实践中，经常做的是归一化$z^{[2]}$，所以这就是我介绍的版本，我推荐其为默认选择，那下面就是<strong>Batch</strong>归一化的使用方法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/734eeb203b02cca8a978ba61b4803bb5.png" alt="734eeb203b02cca8a978ba61b4803bb5"><br>在神经网络中，已知一些中间值，假设你有一些隐藏单元值，从$z^{(1)}$到$z^{(m)}$，这些来源于隐藏层，所以这样写会更准确，即$z^{[l](i)}$为隐藏层，$i$从1到$m$，但这样书写，我要省略$l$及方括号，以便简化这一行的符号。所以已知这些值，如下，你要计算平均值，强调一下，所有这些都是针对$l$层，但我省略$l$及方括号，然后用正如你常用的那个公式计算方差，接着，你会取每个$z^{(i)}$值，使其规范化，方法如下，减去均值再除以标准偏差，为了使数值稳定，通常将$\varepsilon$作为分母，以防$σ=0$的情况。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e10ea98faa1ce9fe86ec8bf9f4fef71e.png" alt="e10ea98faa1ce9fe86ec8bf9f4fef71e"><br>所以现在我们已把这些$z$值标准化，化为含平均值0和标准单位方差，所以$z$的每一个分量都含有平均值0和方差1，但我们不想让隐藏单元总是含有平均值0和方差1，也许隐藏单元有了不同的分布会有意义，所以我们所要做的就是计算，我们称之为${\tilde{z} }^{(i)}$，${\tilde{z} }^{(i)}= \gamma z_{\text{norm} }^{(i)} +\beta$，这里$\gamma$和$\beta$是你模型的学习参数，所以我们使用梯度下降或一些其它类似梯度下降的算法，比如<strong>Momentum</strong>或者<strong>Nesterov</strong>，<strong>Adam</strong>，你会更新$\gamma$和$\beta$，正如更新神经网络的权重一样。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3d494a1d3fb25f7fd67f1bdbf8d8e464.png" alt="3d494a1d3fb25f7fd67f1bdbf8d8e464"><br>请注意$\gamma$和$\beta$的作用是，你可以随意设置${\tilde{z} }^{(i)}$的平均值，事实上，如果$\gamma= \sqrt{\sigma^{2} +\varepsilon}$，如果$\gamma$等于这个分母项（$z_{\text{norm} }^{(i)} = \frac{z^{(i)} -\mu}{\sqrt{\sigma^{2} +\varepsilon} }$中的分母），$\beta$等于$\mu$，这里的这个值是$z_{\text{norm} }^{(i)}= \frac{z^{(i)} - \mu}{\sqrt{\sigma^{2} + \varepsilon} }$中的$\mu$，那么$\gamma z_{\text{norm} }^{(i)} +\beta$的作用在于，它会精确转化这个方程，如果这些成立（$\gamma =\sqrt{\sigma^{2} + \varepsilon},\beta =\mu$），那么${\tilde{z} }^{(i)} = z^{(i)}$。</p><p>通过对$\gamma$和$\beta$合理设定，规范化过程，即这四个等式，从根本来说，只是计算恒等函数，通过赋予$\gamma$和$\beta$其它值，可以使你构造含其它平均值和方差的隐藏单元值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6216dd90d3483f05f08bd8dc86fc7df6.png" alt="6216dd90d3483f05f08bd8dc86fc7df6"><br>所以，在网络匹配这个单元的方式，之前可能是用$z^{(1)}$，$z^{(2)}$等等，现在则会用${\tilde{z} }^{(i)}$取代$z^{(i)}$，方便神经网络中的后续计算。如果你想放回$[l]$，以清楚的表明它位于哪层，你可以把它放这。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c4d0391006609385bc309af394c514f9.png" alt="c4d0391006609385bc309af394c514f9"><br>所以我希望你学到的是，归一化输入特征$X$是怎样有助于神经网络中的学习，<strong>Batch</strong>归一化的作用是它适用的归一化过程，不只是输入层，甚至同样适用于神经网络中的深度隐藏层。你应用<strong>Batch</strong>归一化了一些隐藏单元值中的平均值和方差，不过训练输入和这些隐藏单元值的一个区别是，你也许不想隐藏单元值必须是平均值0和方差1。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2d314293ae9aaa67285299267857632f.png" alt="2d314293ae9aaa67285299267857632f"><br>比如，如果你有<strong>sigmoid</strong>激活函数，你不想让你的值总是全部集中在这里，你想使它们有更大的方差，或不是0的平均值，以便更好的利用非线性的<strong>sigmoid</strong>函数，而不是使所有的值都集中于这个线性版本中，这就是为什么有了$\gamma$和$\beta$两个参数后，你可以确保所有的$z^{(i)}$值可以是你想赋予的任意值，或者它的作用是保证隐藏的单元已使均值和方差标准化。那里，均值和方差由两参数控制，即$\gamma$和$\beta$，学习算法可以设置为任何值，所以它真正的作用是，使隐藏单元值的均值和方差标准化，即$z^{(i)}$有固定的均值和方差，均值和方差可以是0和1，也可以是其它值，它是由$\gamma$和$\beta$两参数控制的。</p><p>我希望你能学会怎样使用<strong>Batch</strong>归一化，至少就神经网络的单一层而言，在下一个视频中，我会教你如何将<strong>Batch</strong>归一化与神经网络甚至是深度神经网络相匹配。对于神经网络许多不同层而言，又该如何使它适用，之后，我会告诉你，<strong>Batch</strong>归一化有助于训练神经网络的原因。所以如果觉得<strong>Batch</strong>归一化起作用的原因还显得有点神秘，那跟着我走，在接下来的两个视频中，我们会弄清楚。</p><h3 id="3-5-将-Batch-Norm-拟合进神经网络（Fitting-Batch-Norm-into-a-neural-network）"><a href="#3-5-将-Batch-Norm-拟合进神经网络（Fitting-Batch-Norm-into-a-neural-network）" class="headerlink" title="3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）"></a>3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）</h3><p>你已经看到那些等式，它可以在单一隐藏层进行<strong>Batch</strong>归一化，接下来，让我们看看它是怎样在深度网络训练中拟合的吧。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/02ae6d8845f468b753c1c4244c312b43.png" alt="02ae6d8845f468b753c1c4244c312b43"><br>假设你有一个这样的神经网络，我之前说过，你可以认为每个单元负责计算两件事。第一，它先计算z，然后应用其到激活函数中再计算a，所以我可以认为，每个圆圈代表着两步的计算过程。同样的，对于下一层而言，那就是$z_{1}^{[2]}$和$a_{1}^{[2]}$等。所以如果你没有应用<strong>Batch</strong>归一化，你会把输入$X$拟合到第一隐藏层，然后首先计算$z^{[1]}$，这是由$w^{[1]}$和$b^{[1]}$两个参数控制的。接着，通常而言，你会把$z^{[1]}$拟合到激活函数以计算$a^{[1]}$。但<strong>Batch</strong>归一化的做法是将$z^{[1]}$值进行<strong>Batch</strong>归一化，简称<strong>BN</strong>，此过程将由${\beta}^{[1]}$和$\gamma^{[1]}$两参数控制，这一操作会给你一个新的规范化的$z^{[1]}$值（${\tilde{z} }^{[1]}$），然后将其输入激活函数中得到$a^{[1]}$，即$a^{[1]} = g^{[1]}({\tilde{z} }^{[ l]})$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/55047d3da405778b6272e6722cd28ac6.png" alt="55047d3da405778b6272e6722cd28ac6"><br>现在，你已在第一层进行了计算，此时<strong>Batch</strong>归一化发生在z的计算和$a$之间，接下来，你需要应用$a^{[1]}$值来计算$z^{[2]}$，此过程是由$w^{[2]}$和$b^{[2]}$控制的。与你在第一层所做的类似，你会将$z^{[2]}$进行<strong>Batch</strong>归一化，现在我们简称<strong>BN</strong>，这是由下一层的<strong>Batch</strong>归一化参数所管制的，即${\beta}^{[2]}$和$\gamma^{[2]}$，现在你得到${\tilde{z} }^{[2]}$，再通过激活函数计算出$a^{[2]}$等等。</p><p>所以需要强调的是<strong>Batch</strong>归一化是发生在计算$z$和$a$之间的。直觉就是，与其应用没有归一化的$z$值，不如用归一过的$\tilde{z}$，这是第一层（${\tilde{z} }^{[1]}$）。第二层同理，与其应用没有规范过的$z^{[2]}$值，不如用经过方差和均值归一后的${\tilde{z} }^{[2]}$。所以，你网络的参数就会是$w^{[1]}$，$b^{[1]}$，$w^{[2]}$和$b^{[2]}$等等，我们将要去掉这些参数。但现在，想象参数$w^{[1]}$，$b^{[1]}$到$w^{[l]}$，$b^{[l]}$，我们将另一些参数加入到此新网络中${\beta}^{[1]}$，${\beta}^{[2]}$，$\gamma^{[1]}$，$\gamma^{[2]}$等等。对于应用<strong>Batch</strong>归一化的每一层而言。需要澄清的是，请注意，这里的这些$\beta$（${\beta}^{[1]}$，${\beta}^{[2]}$等等）和超参数$\beta$没有任何关系，下一张幻灯片中会解释原因，后者是用于<strong>Momentum</strong>或计算各个指数的加权平均值。<strong>Adam</strong>论文的作者，在论文里用$\beta$代表超参数。<strong>Batch</strong>归一化论文的作者，则使用$\beta$代表此参数（${\beta}^{[1]}$，${\beta}^{[2]}$等等），但这是两个完全不同的$\beta$。我在两种情况下都决定使用$\beta$，以便你阅读那些原创的论文，但<strong>Batch</strong>归一化学习参数${\beta}^{[1]}$，${\beta}^{\left\lbrack2 \right\rbrack}$等等和用于<strong>Momentum</strong>、<strong>Adam</strong>、<strong>RMSprop</strong>算法中的$\beta$不同。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0204b45c1adae38694b26de9b7af2edd.png" alt="0204b45c1adae38694b26de9b7af2edd"><br>所以现在，这是你算法的新参数，接下来你可以使用想用的任何一种优化算法，比如使用梯度下降法来执行它。</p><p>举个例子，对于给定层，你会计算$d{\beta}^{[l]}$，接着更新参数$\beta$为${\beta}^{[l]} = {\beta}^{[l]} - \alpha d{\beta}^{[l]}$。你也可以使用<strong>Adam</strong>或<strong>RMSprop</strong>或<strong>Momentum</strong>，以更新参数$\beta$和$\gamma$，并不是只应用梯度下降法。</p><p>即使在之前的视频中，我已经解释过<strong>Batch</strong>归一化是怎么操作的，计算均值和方差，减去均值，再除以方差，如果它们使用的是深度学习编程框架，通常你不必自己把<strong>Batch</strong>归一化步骤应用于<strong>Batch</strong>归一化层。因此，探究框架，可写成一行代码，比如说，在<strong>TensorFlow</strong>框架中，你可以用这个函数（<code>tf.nn.batch_normalization</code>）来实现<strong>Batch</strong>归一化，我们稍后讲解，但实践中，你不必自己操作所有这些具体的细节，但知道它是如何作用的，你可以更好的理解代码的作用。但在深度学习框架中，<strong>Batch</strong>归一化的过程，经常是类似一行代码的东西。</p><p>所以，到目前为止，我们已经讲了<strong>Batch</strong>归一化，就像你在整个训练站点上训练一样，或就像你正在使用<strong>Batch</strong>梯度下降法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/27dc60faf8c8e4d8360b4c8091b85355.png" alt="27dc60faf8c8e4d8360b4c8091b85355"><br>实践中，<strong>Batch</strong>归一化通常和训练集的<strong>mini-batch</strong>一起使用。你应用<strong>Batch</strong>归一化的方式就是，你用第一个<strong>mini-batch</strong>($X^{\{1\} }$)，然后计算$z^{[1]}$，这和上张幻灯片上我们所做的一样，应用参数$w^{[1]}$和$b^{[1]}$，使用这个<strong>mini-batch</strong>($X^{\{1\} }$)。接着，继续第二个<strong>mini-batch</strong>($X^{\{2\} }$)，接着<strong>Batch</strong>归一化会减去均值，除以标准差，由${\beta}^{[1]}$和$\gamma^{[1]}$重新缩放，这样就得到了${\tilde{z} }^{[1]}$，而所有的这些都是在第一个<strong>mini-batch</strong>的基础上，你再应用激活函数得到$a^{[1]}$。然后用$w^{[2]}$和$b^{[2]}$计算$z^{[2]}$，等等，所以你做的这一切都是为了在第一个<strong>mini-batch</strong>($X^{\{1\} }$)上进行一步梯度下降法。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/06fa55207f5d245e70db73a7e5e89a68.png" alt="06fa55207f5d245e70db73a7e5e89a68"><br>类似的工作，你会在第二个<strong>mini-batch</strong>（$X^{\left\{2 \right\} }$）上计算$z^{[1]}$，然后用<strong>Batch</strong>归一化来计算${\tilde{z} }^{[1]}$，所以<strong>Batch</strong>归一化的此步中，你用第二个<strong>mini-batch</strong>（$X^{\left\{2 \right\} }$）中的数据使${\tilde{z} }^{[1]}$归一化，这里的<strong>Batch</strong>归一化步骤也是如此，让我们来看看在第二个<strong>mini-batch</strong>（$X^{\left\{2 \right\} }$）中的例子，在<strong>mini-batch</strong>上计算$z^{[1]}$的均值和方差，重新缩放的$\beta$和$\gamma$得到$z^{[1]}$，等等。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/61cee05b5822c9bc97bfdfd88861dfd6.png" alt="61cee05b5822c9bc97bfdfd88861dfd6"><br>然后在第三个<strong>mini-batch</strong>（$X^{\left\{ 3 \right\} }$）上同样这样做，继续训练。</p><p>现在，我想澄清此参数的一个细节。先前我说过每层的参数是$w^{[l]}$和$b^{[l]}$，还有${\beta}^{[l]}$和$\gamma^{[l]}$，请注意计算$z$的方式如下，$z^{[l]} =w^{[l]}a^{\left\lbrack l - 1 \right\rbrack} +b^{[l]}$，但<strong>Batch</strong>归一化做的是，它要看这个<strong>mini-batch</strong>，先将$z^{[l]}$归一化，结果为均值0和标准方差，再由$\beta$和$$\gamma$$重缩放，但这意味着，无论$b^{[l]}$的值是多少，都是要被减去的，因为在<strong>Batch</strong>归一化的过程中，你要计算$z^{[l]}$的均值，再减去平均值，在此例中的<strong>mini-batch</strong>中增加任何常数，数值都不会改变，因为加上的任何常数都将会被均值减去所抵消。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/79d8bc44c225879e9bc89e352b62502a.png" alt="79d8bc44c225879e9bc89e352b62502a"><br>所以，如果你在使用<strong>Batch</strong>归一化，其实你可以消除这个参数（$b^{[l]}$），或者你也可以，暂时把它设置为0，那么，参数变成$z^{[l]} = w^{[l]}a^{\left\lbrack l - 1 \right\rbrack}$，然后你计算归一化的$z^{[l]}$，${\tilde{z} }^{[l]} = \gamma^{[l]}z^{[l]} + {\beta}^{[l]}$，你最后会用参数${\beta}^{[l]}$，以便决定${\tilde{z} }^{[l]}$的取值，这就是原因。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3711c11e52433b6417227e78b998e849.png" alt="3711c11e52433b6417227e78b998e849"><br>所以总结一下，因为<strong>Batch</strong>归一化超过了此层$z^{[l]}$的均值，$b^{[l]}$这个参数没有意义，所以，你必须去掉它，由${\beta}^{[l]}$代替，这是个控制参数，会影响转移或偏置条件。</p><p>最后，请记住$z^{[l]}$的维数，因为在这个例子中，维数会是$(n^{[l]},1)$，$b^{[l]}$的尺寸为$(n^{[l]},1)$，如果是l层隐藏单元的数量，那${\beta}^{[l]}$和$\gamma^{[l]}$的维度也是$(n^{[l]},1)$，因为这是你隐藏层的数量，你有$n^{[l]}$隐藏单元，所以${\beta}^{[l]}$和$\gamma^{[l]}$用来将每个隐藏层的均值和方差缩放为网络想要的值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08ab0b778ede091a860048d609048167.png" alt="08ab0b778ede091a860048d609048167"><br>让我们总结一下关于如何用<strong>Batch</strong>归一化来应用梯度下降法，假设你在使用<strong>mini-batch</strong>梯度下降法，你运行$t=1$到<strong>batch</strong>数量的<strong>for</strong>循环，你会在<strong>mini-batch</strong> $X^{\left\{ t\right\} }$上应用正向<strong>prop</strong>，每个隐藏层都应用正向<strong>prop</strong>，用<strong>Batch</strong>归一化代替$z^{[l]}$为${\tilde{z} }^{[l]}$。接下来，它确保在这个<strong>mini-batch</strong>中，$z$值有归一化的均值和方差，归一化均值和方差后是${\tilde{z} }^{[l]}$，然后，你用反向<strong>prop</strong>计算$dw^{[l]}$和$db^{[l]}$，及所有l层所有的参数，$d{\beta}^{[l]}$和$d\gamma^{[l]}$。尽管严格来说，因为你要去掉$b$，这部分其实已经去掉了。最后，你更新这些参数：$w^{[l]} = w^{[l]} -\text{αd}w^{[l]}$，和以前一样，${\beta}^{[l]} = {\beta}^{[l]} - {αd}{\beta}^{[l]}$，对于$\gamma$也是如此$\gamma^{[l]} = \gamma^{[l]} -{αd}\gamma^{[l]}$。</p><p>如果你已将梯度计算如下，你就可以使用梯度下降法了，这就是我写到这里的，但也适用于有<strong>Momentum</strong>、<strong>RMSprop</strong>、<strong>Adam</strong>的梯度下降法。与其使用梯度下降法更新<strong>mini-batch</strong>，你可以使用这些其它算法来更新，我们在之前几个星期中的视频中讨论过的，也可以应用其它的一些优化算法来更新由<strong>Batch</strong>归一化添加到算法中的$\beta$ 和$\gamma$ 参数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/797be77383bc6b34ddd2ea9e49688cf6.png" alt="797be77383bc6b34ddd2ea9e49688cf6"><br>我希望，你能学会如何从头开始应用<strong>Batch</strong>归一化，如果你想的话。如果你使用深度学习编程框架之一，我们之后会谈。，希望，你可以直接调用别人的编程框架，这会使<strong>Batch</strong>归一化的使用变得很容易。</p><p>现在，以防<strong>Batch</strong>归一化仍然看起来有些神秘，尤其是你还不清楚为什么其能如此显著的加速训练，我们进入下一个视频，详细讨论<strong>Batch</strong>归一化为何效果如此显著，它到底在做什么。</p><h3 id="3-6-Batch-Norm-为什么奏效？（Why-does-Batch-Norm-work-）"><a href="#3-6-Batch-Norm-为什么奏效？（Why-does-Batch-Norm-work-）" class="headerlink" title="3.6 Batch Norm 为什么奏效？（Why does Batch Norm work?）"></a>3.6 Batch Norm 为什么奏效？（Why does Batch Norm work?）</h3><p>为什么<strong>Batch</strong>归一化会起作用呢？</p><p>一个原因是，你已经看到如何归一化输入特征值$x$，使其均值为0，方差1，它又是怎样加速学习的，有一些从0到1而不是从1到1000的特征值，通过归一化所有的输入特征值$x$，以获得类似范围的值，可以加速学习。所以<strong>Batch</strong>归一化起的作用的原因，直观的一点就是，它在做类似的工作，但不仅仅对于这里的输入值，还有隐藏单元的值，这只是<strong>Batch</strong>归一化作用的冰山一角，还有些深层的原理，它会有助于你对<strong>Batch</strong>归一化的作用有更深的理解，让我们一起来看看吧。</p><p><strong>Batch</strong>归一化有效的第二个原因是，它可以使权重比你的网络更滞后或更深层，比如，第10层的权重更能经受得住变化，相比于神经网络中前层的权重，比如第1层，为了解释我的意思，让我们来看看这个最生动形象的例子。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b84c6784df7184b0baed8e96453646ac.png" alt="b84c6784df7184b0baed8e96453646ac"><br>这是一个网络的训练，也许是个浅层网络，比如<strong>logistic</strong>回归或是一个神经网络，也许是个浅层网络，像这个回归函数。或一个深层网络，建立在我们著名的猫脸识别检测上，但假设你已经在所有黑猫的图像上训练了数据集，如果现在你要把此网络应用于有色猫，这种情况下，正面的例子不只是左边的黑猫，还有右边其它颜色的猫，那么你的<strong>cosfa</strong>可能适用的不会很好。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/125efc4b05bcba7b0e50d78614d58d1f.png" alt="125efc4b05bcba7b0e50d78614d58d1f"><br>如果图像中，你的训练集是这个样子的，你的正面例子在这儿，反面例子在那儿（左图），但你试图把它们都统一于一个数据集，也许正面例子在这，反面例子在那儿（右图）。你也许无法期待，在左边训练得很好的模块，同样在右边也运行得很好，即使存在运行都很好的同一个函数，但你不会希望你的学习算法去发现绿色的决策边界，如果只看左边数据的话。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2f19f3438704a51d217ede3abb4eef3d.png" alt="2f19f3438704a51d217ede3abb4eef3d"><br>所以使你数据改变分布的这个想法，有个有点怪的名字“<strong>Covariate shift</strong>”，想法是这样的，如果你已经学习了$x$到$y$ 的映射，如果$x$ 的分布改变了，那么你可能需要重新训练你的学习算法。这种做法同样适用于，如果真实函数由$x$ 到$y$ 映射保持不变，正如此例中，因为真实函数是此图片是否是一只猫，训练你的函数的需要变得更加迫切，如果真实函数也改变，情况就更糟了。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08f134faa74ebd283a5f5f19be43efab.png" alt="08f134faa74ebd283a5f5f19be43efab"><br>“<strong>Covariate shift</strong>”的问题怎么应用于神经网络呢？试想一个像这样的深度网络，让我们从这层（第三层）来看看学习过程。此网络已经学习了参数$w^{[3]}$和$b^{[3]}$，从第三隐藏层的角度来看，它从前层中取得一些值，接着它需要做些什么，使希望输出值$\hat y$接近真实值$y$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/8cd4b32c6febb45c71a1c91394cb1d1a.png" alt="8cd4b32c6febb45c71a1c91394cb1d1a"><br>让我先遮住左边的部分，从第三隐藏层的角度来看，它得到一些值，称为$a_{1}^{[2]}$，$a_{2}^{[2]}$，$a_{3}^{[2]}$，$a_{4}^{[2]}$，但这些值也可以是特征值$x_{1}$，$x_{2}$，$x_{3}$，$x_{4}$，第三层隐藏层的工作是找到一种方式，使这些值映射到$\hat y$，你可以想象做一些截断，所以这些参数$w^{[3]}$和$b^{[3]}$或$w^{[4]}$和$b^{[4]}$或$w^{[5]}$和$b^{[5]}$，也许是学习这些参数，所以网络做的不错，从左边我用黑色笔写的映射到输出值$\hat y$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/32efeb52697bd9543900bbd38a732e3c.png" alt="32efeb52697bd9543900bbd38a732e3c"><br>现在我们把网络的左边揭开，这个网络还有参数$w^{[2]}$，$b^{[2]}$和$w^{[1]}$，$b^{[1]}$，如果这些参数改变，这些$a^{[2]}$的值也会改变。所以从第三层隐藏层的角度来看，这些隐藏单元的值在不断地改变，所以它就有了“<strong>Covariate shift</strong>”的问题，上张幻灯片中我们讲过的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f8a80801c51e13947d7f2cafb4a8fe69.png" alt="f8a80801c51e13947d7f2cafb4a8fe69"><br><strong>Batch</strong>归一化做的，是它减少了这些隐藏值分布变化的数量。如果是绘制这些隐藏的单元值的分布，也许这是重整值$z$，这其实是$z_{1}^{[2]}$，$z_{2}^{[2]}$，我要绘制两个值而不是四个值，以便我们设想为<strong>2D</strong>，<strong>Batch</strong>归一化讲的是$z_{1}^{[2]}$，$z_{2}^{[2]}$的值可以改变，它们的确会改变，当神经网络在之前层中更新参数，<strong>Batch</strong>归一化可以确保无论其怎样变化$z_{1}^{[2]}$，$z_{2}^{[2]}$的均值和方差保持不变，所以即使$z_{1}^{[2]}$，$z_{2}^{[2]}$的值改变，至少他们的均值和方差也会是均值0，方差1，或不一定必须是均值0，方差1，而是由${\beta}^{[2]}$和$\gamma^{[2]}$决定的值。如果神经网络选择的话，可强制其为均值0，方差1，或其他任何均值和方差。但它做的是，它限制了在前层的参数更新，会影响数值分布的程度，第三层看到的这种情况，因此得到学习。</p><p><strong>Batch</strong>归一化减少了输入值改变的问题，它的确使这些值变得更稳定，神经网络的之后层就会有更坚实的基础。即使使输入分布改变了一些，它会改变得更少。它做的是当前层保持学习，当改变时，迫使后层适应的程度减小了，你可以这样想，它减弱了前层参数的作用与后层参数的作用之间的联系，它使得网络每层都可以自己学习，稍稍独立于其它层，这有助于加速整个网络的学习。</p><p><img src="https://markdown.xiaoshujiang.com/img/spinner.gif" alt="db19ef11d7b654cc020a5f943806ac38" title="[[[1575528745268]]]"><br>所以，希望这能带给你更好的直觉，重点是<strong>Batch</strong>归一化的意思是，尤其从神经网络后层之一的角度而言，前层不会左右移动的那么多，因为它们被同样的均值和方差所限制，所以，这会使得后层的学习工作变得更容易些。</p><p><strong>Batch</strong>归一化还有一个作用，它有轻微的正则化效果，<strong>Batch</strong>归一化中非直观的一件事是，每个<strong>mini-batch</strong>，我会说<strong>mini-batch</strong>$X^{\{ t \} }$的值为$z^{\lbrack t\rbrack}$，$z^{[l]}$，在<strong>mini-batch</strong>计算中，由均值和方差缩放的，因为在<strong>mini-batch</strong>上计算的均值和方差，而不是在整个数据集上，均值和方差有一些小的噪声，因为它只在你的<strong>mini-batch</strong>上计算，比如64或128或256或更大的训练例子。因为均值和方差有一点小噪音，因为它只是由一小部分数据估计得出的。缩放过程从$z^{[l]}$到${\tilde{z} }^{[l]}$，过程也有一些噪音，因为它是用有些噪音的均值和方差计算得出的。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0feb6ee8af40238fc1374131bc517e35.png" alt="0feb6ee8af40238fc1374131bc517e35"><br>所以和<strong>dropout</strong>相似，它往每个隐藏层的激活值上增加了噪音，<strong>dropout</strong>有增加噪音的方式，它使一个隐藏的单元，以一定的概率乘以0，以一定的概率乘以1，所以你的<strong>dropout</strong>含几重噪音，因为它乘以0或1。</p><p>对比而言，<strong>Batch</strong>归一化含几重噪音，因为标准偏差的缩放和减去均值带来的额外噪音。这里的均值和标准差的估计值也是有噪音的，所以类似于<strong>dropout</strong>，<strong>Batch</strong>归一化有轻微的正则化效果，因为给隐藏单元添加了噪音，这迫使后部单元不过分依赖任何一个隐藏单元，类似于<strong>dropout</strong>，它给隐藏层增加了噪音，因此有轻微的正则化效果。因为添加的噪音很微小，所以并不是巨大的正则化效果，你可以将<strong>Batch</strong>归一化和<strong>dropout</strong>一起使用，如果你想得到<strong>dropout</strong>更强大的正则化效果。</p><p>也许另一个轻微非直观的效果是，如果你应用了较大的<strong>mini-batch</strong>，对，比如说，你用了512而不是64，通过应用较大的<strong>min-batch</strong>，你减少了噪音，因此减少了正则化效果，这是<strong>dropout</strong>的一个奇怪的性质，就是应用较大的<strong>mini-batch</strong>可以减少正则化效果。</p><p>说到这儿，我会把<strong>Batch</strong>归一化当成一种正则化，这确实不是其目的，但有时它会对你的算法有额外的期望效应或非期望效应。但是不要把<strong>Batch</strong>归一化当作正则化，把它当作将你归一化隐藏单元激活值并加速学习的方式，我认为正则化几乎是一个意想不到的副作用。</p><p>所以希望这能让你更理解<strong>Batch</strong>归一化的工作，在我们结束<strong>Batch</strong>归一化的讨论之前，我想确保你还知道一个细节。<strong>Batch</strong>归一化一次只能处理一个<strong>mini-batch</strong>数据，它在<strong>mini-batch</strong>上计算均值和方差。所以测试时，你试图做出预测，试着评估神经网络，你也许没有<strong>mini-batch</strong>的例子，你也许一次只能进行一个简单的例子，所以测试时，你需要做一些不同的东西以确保你的预测有意义。</p><p>在下一个也就是最后一个<strong>Batch</strong>归一化视频中，让我们详细谈谈你需要注意的一些细节，来让你的神经网络应用<strong>Batch</strong>归一化来做出预测。</p><h3 id="3-7-测试时的-Batch-Norm（Batch-Norm-at-test-time）"><a href="#3-7-测试时的-Batch-Norm（Batch-Norm-at-test-time）" class="headerlink" title="3.7 测试时的 Batch Norm（Batch Norm at test time）"></a>3.7 测试时的 Batch Norm（Batch Norm at test time）</h3><p><strong>Batch</strong>归一化将你的数据以<strong>mini-batch</strong>的形式逐一处理，但在测试时，你可能需要对每个样本逐一处理，我们来看一下怎样调整你的网络来做到这一点。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fd1f67f2e97e814079607f190111f65f.png" alt="fd1f67f2e97e814079607f190111f65f"><br>回想一下，在训练时，这些就是用来执行<strong>Batch</strong>归一化的等式。在一个<strong>mini-batch</strong>中，你将<strong>mini-batch</strong>的$z^{(i)}$值求和，计算均值，所以这里你只把一个<strong>mini-batch</strong>中的样本都加起来，我用m来表示这个<strong>mini-batch</strong>中的样本数量，而不是整个训练集。然后计算方差，再算$z_{\text{norm} }^{(i)}$，即用均值和标准差来调整，加上$\varepsilon$是为了数值稳定性。$\tilde{z}$是用$\gamma$和$\beta$再次调整$z_{\text{norm} }$得到的。</p><p>请注意用于调节计算的$\mu$和$\sigma^{2}$是在整个<strong>mini-batch</strong>上进行计算，但是在测试时，你可能不能将一个<strong>mini-batch</strong>中的6428或2056个样本同时处理，因此你需要用其它方式来得到$\mu$和$\sigma^{2}$，而且如果你只有一个样本，一个样本的均值和方差没有意义。那么实际上，为了将你的神经网络运用于测试，就需要单独估算$\mu$和$\sigma^{2}$，在典型的<strong>Batch</strong>归一化运用中，你需要用一个指数加权平均来估算，这个平均数涵盖了所有<strong>mini-batch</strong>，接下来我会具体解释。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/9e64b0cb330797ece66c0a56958bfcca.png" alt="9e64b0cb330797ece66c0a56958bfcca"><br>我们选择$l$层，假设我们有<strong>mini-batch</strong>，$X^{[1]}$，$X^{[2]}$，$X^{[3]}$……以及对应的$y$值等等，那么在为$l$层训练$X^{\{ 1\} }$时，你就得到了$\mu^{[l]}$，我还是把它写做第一个<strong>mini-batch</strong>和这一层的$\mu$吧，（$\mu^{[l]} \rightarrow \mu^{\left\{1 \right\}[l]}$）。当你训练第二个<strong>mini-batch</strong>，在这一层和这个<strong>mini-batch</strong>中，你就会得到第二个$\mu$（$\mu^{\{2\}[l]}$）值。然后在这一隐藏层的第三个<strong>mini-batch</strong>，你得到了第三个$\mu$（$\mu^{\left\{3 \right\}[l]}$）值。正如我们之前用的指数加权平均来计算$\theta_{1}$，$\theta_{2}$，$\theta_{3}$的均值，当时是试着计算当前气温的指数加权平均，你会这样来追踪你看到的这个均值向量的最新平均值，于是这个指数加权平均就成了你对这一隐藏层的$z$均值的估值。同样的，你可以用指数加权平均来追踪你在这一层的第一个<strong>mini-batch</strong>中所见的$\sigma^{2}$的值，以及第二个<strong>mini-batch</strong>中所见的$\sigma^{2}$的值等等。因此在用不同的<strong>mini-batch</strong>训练神经网络的同时，能够得到你所查看的每一层的$\mu$和$\sigma^{2}$的平均数的实时数值。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6699883f2e531063e4437cc63c5a2a83.png" alt="6699883f2e531063e4437cc63c5a2a83"><br>最后在测试时，对应这个等式（$z_{\text{norm} }^{(i)} = \frac{z^{(i)} -\mu}{\sqrt{\sigma^{2} +\varepsilon} }$），你只需要用你的$z$值来计算$z_{\text{norm} }^{(i)}$，用$\mu$和$\sigma^{2}$的指数加权平均，用你手头的最新数值来做调整，然后你可以用左边我们刚算出来的$z_{\text{norm} }$和你在神经网络训练过程中得到的$\beta$和$\gamma$参数来计算你那个测试样本的$\tilde{z}$值。</p><p>总结一下就是，在训练时，$\mu$和$\sigma^{2}$是在整个<strong>mini-batch</strong>上计算出来的包含了像是64或28或其它一定数量的样本，但在测试时，你可能需要逐一处理样本，方法是根据你的训练集估算$\mu$和$\sigma^{2}$，估算的方式有很多种，理论上你可以在最终的网络中运行整个训练集来得到$\mu$和$\sigma^{2}$，但在实际操作中，我们通常运用指数加权平均来追踪在训练过程中你看到的$\mu$和$\sigma^{2}$的值。还可以用指数加权平均，有时也叫做流动平均来粗略估算$\mu$和$\sigma^{2}$，然后在测试中使用$\mu$和$\sigma^{2}$的值来进行你所需要的隐藏单元$z$值的调整。在实践中，不管你用什么方式估算$\mu$和$\sigma^{2}$，这套过程都是比较稳健的，因此我不太会担心你具体的操作方式，而且如果你使用的是某种深度学习框架，通常会有默认的估算$\mu$和$\sigma^{2}$的方式，应该一样会起到比较好的效果。但在实践中，任何合理的估算你的隐藏单元$z$值的均值和方差的方式，在测试中应该都会有效。</p><p><strong>Batch</strong>归一化就讲到这里，使用<strong>Batch</strong>归一化，你能够训练更深的网络，让你的学习算法运行速度更快，在结束这周的课程之前，我还想和你们分享一些关于深度学习框架的想法，让我们在下一段视频中一起讨论这个话题。</p><h3 id="3-8-Softmax-回归（Softmax-regression）"><a href="#3-8-Softmax-回归（Softmax-regression）" class="headerlink" title="3.8 Softmax 回归（Softmax regression）"></a>3.8 Softmax 回归（Softmax regression）</h3><p>到目前为止，我们讲到过的分类的例子都使用了二分分类，这种分类只有两种可能的标记0或1，这是一只猫或者不是一只猫，如果我们有多种可能的类型的话呢？有一种<strong>logistic</strong>回归的一般形式，叫做<strong>Softmax</strong>回归，能让你在试图识别某一分类时做出预测，或者说是多种分类中的一个，不只是识别两个分类，我们来一起看一下。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e36d502aa68bf9e1a118f5d13e24b134.png" alt="e36d502aa68bf9e1a118f5d13e24b134"><br>假设你不单需要识别猫，而是想识别猫，狗和小鸡，我把猫加做类1，狗为类2，小鸡是类3，如果不属于以上任何一类，就分到“其它”或者说“以上均不符合”这一类，我把它叫做类0。这里显示的图片及其对应的分类就是一个例子，这幅图片上是一只小鸡，所以是类3，猫是类1，狗是类2，我猜这是一只考拉，所以以上均不符合，那就是类0，下一个类3，以此类推。我们将会用符号表示，我会用大写的$C$来表示你的输入会被分入的类别总个数，在这个例子中，我们有4种可能的类别，包括“其它”或“以上均不符合”这一类。当有4个分类时，指示类别的数字，就是从0到$C-1$，换句话说就是0、1、2、3。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e65ba7b81d0b02d021c33bf0094f4059.png" alt><br>在这个例子中，我们将建立一个神经网络，其输出层有4个，或者说$C$个输出单元，因此$n$，即输出层也就是$L$层的单元数量，等于4，或者一般而言等于$C$。我们想要输出层单元的数字告诉我们这4种类型中每个的概率有多大，所以这里的第一个节点(最后输出的第1个方格+圆圈)输出的应该是或者说我们希望它输出“其它”类的概率。在输入$X$的情况下，这个(最后输出的第2个方格+圆圈)会输出猫的概率。在输入$X$的情况下，这个会输出狗的概率(最后输出的第3个方格+圆圈)。在输入$X$的情况下，输出小鸡的概率（最后输出的第4个方格+圆圈），我把小鸡缩写为<strong>bc</strong>（<strong>baby chick</strong>）。因此这里的$\hat y$将是一个$4×1$维向量，因为它必须输出四个数字，给你这四种概率，因为它们加起来应该等于1，输出中的四个数字加起来应该等于1。</p><p>让你的网络做到这一点的标准模型要用到<strong>Softmax</strong>层，以及输出层来生成输出，让我把式子写下来，然后回过头来，就会对<strong>Softmax</strong>的作用有一点感觉了。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/97ab8f2af0788776bdd486c5f4f40354.png" alt="97ab8f2af0788776bdd486c5f4f40354"><br>在神经网络的最后一层，你将会像往常一样计算各层的线性部分，$z^{[l]}$这是最后一层的$z$变量，记住这是大写$L$层，和往常一样，计算方法是$z^{[l]} = W^{[l]}a^{[L-1]} + b^{[l]}$，算出了$z$之后，你需要应用<strong>Softmax</strong>激活函数，这个激活函数对于<strong>Softmax</strong>层而言有些不同，它的作用是这样的。首先，我们要计算一个临时变量，我们把它叫做t，它等于$e^{z^{[l]} }$，这适用于每个元素，而这里的$z^{[l]}$，在我们的例子中，$z^{[l]}$是4×1的，四维向量$t=e^{z^{[l]} }$，这是对所有元素求幂，$t$也是一个4×1维向量，然后输出的$a^{[l]}$，基本上就是向量$t$，但是会归一化，使和为1。因此$a^{[l]} = \frac{e^{z^{[l]} }}{\sum_{j =1}^{4}t_{i} }$，换句话说，$a^{[l]}$也是一个4×1维向量，而这个四维向量的第$i$个元素，我把它写下来，$a_{i}^{[l]} = \frac{t_{i} }{\sum_{j =1}^{4}t_{i} }$，以防这里的计算不够清晰易懂，我们马上会举个例子来详细解释。</p><p>我们来看一个例子，详细解释，假设你算出了$z^{[l]}$，$z^{[l]}$是一个四维向量，假设为$z^{[l]} = \begin{bmatrix} 5 \\ 2 \\ - 1 \\ 3 \\ \end{bmatrix}$，我们要做的就是用这个元素取幂方法来计算$t$，所以$t =\begin{bmatrix} e^{5} \\ e^{2} \\ e^{- 1} \\ e^{3} \\ \end{bmatrix}$，如果你按一下计算器就会得到以下值$t = \begin{bmatrix} 148.4 \\ 7.4 \\ 0.4 \\ 20.1 \\ \end{bmatrix}$，我们从向量$t$得到向量$a^{[l]}$就只需要将这些项目归一化，使总和为1。如果你把$t$的元素都加起来，把这四个数字加起来，得到176.3，最终$a^{[l]} = \frac{t} {176.3}$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/08e51a30d97c877410fed7f7dbe1203f.png" alt="08e51a30d97c877410fed7f7dbe1203f"><br>例如这里的第一个节点，它会输出$\frac{e^{5} }{176.3} =0.842$，这样说来，对于这张图片，如果这是你得到的$z$值($\begin{bmatrix} 5 \\ 2 \\ - 1 \\ 3 \\ \end{bmatrix}$)，它是类0的概率就是84.2%。下一个节点输出$\frac{e^{2} }{176.3} =0.042$，也就是4.2%的几率。下一个是$\frac{e^{- 1} }{176.3} =0.002$。最后一个是$\frac{e^{3} }{176.3} =0.114$，也就是11.4%的概率属于类3，也就是小鸡组，对吧？这就是它属于类0，类1，类2，类3的可能性。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c791fc935e680ef37ef036723f0f2510.png" alt="c791fc935e680ef37ef036723f0f2510"><br>神经网络的输出$a^{[l]}$，也就是$\hat y$，是一个4×1维向量，这个4×1向量的元素就是我们算出来的这四个数字($\begin{bmatrix} 0.842 \\ 0.042 \\ 0.002 \\ 0.114 \\ \end{bmatrix}$)，所以这种算法通过向量$z^{[l]}$计算出总和为1的四个概率。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/fec90de0e70081185c234c215a23d307.png" alt="fec90de0e70081185c234c215a23d307"><br>如果我们总结一下从$z^{[l]}$到$a^{[l]}$的计算步骤，整个计算过程，从计算幂到得出临时变量$t$，再归一化，我们可以将此概括为一个<strong>Softmax</strong>激活函数。设$a^{[l]} = g^{[l]}(z^{[l]})$，这一激活函数的与众不同之处在于，这个激活函数$g$ 需要输入一个4×1维向量，然后输出一个4×1维向量。之前，我们的激活函数都是接受单行数值输入，例如<strong>Sigmoid</strong>和<strong>ReLu</strong>激活函数，输入一个实数，输出一个实数。<strong>Softmax</strong>激活函数的特殊之处在于，因为需要将所有可能的输出归一化，就需要输入一个向量，最后输出一个向量。</p><p>那么<strong>Softmax</strong>分类器还可以代表其它的什么东西么？我来举几个例子，你有两个输入$x_{1}$，$x_{2}$，它们直接输入到<strong>Softmax</strong>层，它有三四个或者更多的输出节点，输出$\hat y$，我将向你展示一个没有隐藏层的神经网络，它所做的就是计算$z^{[1]} = W^{[1]}x + b^{[1]}$，而输出的出$a^{[l]}$，或者说$\hat y$，$a^{[l]} = y = g(z^{[1]})$，就是$z^{[1]}$的<strong>Softmax</strong>激活函数，这个没有隐藏层的神经网络应该能让你对<strong>Softmax</strong>函数能够代表的东西有所了解。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1dc4bf21b6e38cbe9bdfb729ed969c99.png" alt="1dc4bf21b6e38cbe9bdfb729ed969c99"><br>这个例子中（左边图），原始输入只有$x_{1}$和$x_{2}$，一个$C=3$个输出分类的<strong>Softmax</strong>层能够代表这种类型的决策边界，请注意这是几条线性决策边界，但这使得它能够将数据分到3个类别中，在这张图表中，我们所做的是选择这张图中显示的训练集，用数据的3种输出标签来训练<strong>Softmax</strong>分类器，图中的颜色显示了<strong>Softmax</strong>分类器的输出的阈值，输入的着色是基于三种输出中概率最高的那种。因此我们可以看到这是<strong>logistic</strong>回归的一般形式，有类似线性的决策边界，但有超过两个分类，分类不只有0和1，而是可以是0，1或2。</p><p>这是（中间图）另一个<strong>Softmax</strong>分类器可以代表的决策边界的例子，用有三个分类的数据集来训练，这里（右边图）还有一个。对吧，但是直觉告诉我们，任何两个分类之间的决策边界都是线性的，这就是为什么你看到，比如这里黄色和红色分类之间的决策边界是线性边界，紫色和红色之间的也是线性边界，紫色和黄色之间的也是线性决策边界，但它能用这些不同的线性函数来把空间分成三类。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7207527be03bc1daec77afb6c29b8533.png" alt="7207527be03bc1daec77afb6c29b8533"><br>我们来看一下更多分类的例子，这个例子中（左边图）$C=4$，因此这个绿色分类和<strong>Softmax</strong>仍旧可以代表多种分类之间的这些类型的线性决策边界。另一个例子（中间图）是$C=5$类，最后一个例子（右边图）是$C=6$，这显示了<strong>Softmax</strong>分类器在没有隐藏层的情况下能够做到的事情，当然更深的神经网络会有$x$，然后是一些隐藏单元，以及更多隐藏单元等等，你就可以学习更复杂的非线性决策边界，来区分多种不同分类。</p><p>我希望你了解了神经网络中的<strong>Softmax</strong>层或者<strong>Softmax</strong>激活函数有什么作用，下一个视频中，我们来看一下你该怎样训练一个使用<strong>Softmax</strong>层的神经网络。</p><h3 id="3-9-训练一个-Softmax-分类器（Training-a-Softmax-classifier）"><a href="#3-9-训练一个-Softmax-分类器（Training-a-Softmax-classifier）" class="headerlink" title="3.9 训练一个 Softmax 分类器（Training a Softmax classifier）"></a>3.9 训练一个 Softmax 分类器（Training a Softmax classifier）</h3><p>上一个视频中我们学习了<strong>Softmax</strong>层和<strong>Softmax</strong>激活函数，在这个视频中，你将更深入地了解<strong>Softmax</strong>分类，并学习如何训练一个使用了<strong>Softmax</strong>层的模型。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6b825763afc787168a19597da2a38d58.png" alt="6b825763afc787168a19597da2a38d58"><br>回忆一下我们之前举的的例子，输出层计算出的$z^{[l]}$如下，$z^{[l]} = \begin{bmatrix} 5 \\ 2 \\ - 1 \\ 3 \\ \end{bmatrix}$我们有四个分类$C=4$，$z^{[l]}$可以是4×1维向量，我们计算了临时变量$t$，$t = \begin{bmatrix} e^{5} \\ e^{2} \\ e^{- 1} \\ e^{3} \\ \end{bmatrix}$，对元素进行幂运算，最后，如果你的输出层的激活函数$g^{[L]}()$是<strong>Softmax</strong>激活函数，那么输出就会是这样的：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/01a404ae594bdc5871aec07e9fd478d1.png" alt="01a404ae594bdc5871aec07e9fd478d1"><br>简单来说就是用临时变量$t$将它归一化，使总和为1，于是这就变成了$a^{[L]}$，你注意到向量$z$中，最大的元素是5，而最大的概率也就是第一种概率。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b433ed42cdde6c732820c57eebfb85f7.png" alt="b433ed42cdde6c732820c57eebfb85f7"><br><strong>Softmax</strong>这个名称的来源是与所谓<strong>hardmax</strong>对比，<strong>hardmax</strong>会把向量$z$变成这个向量$\begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \\ \end{bmatrix}$，<strong>hardmax</strong>函数会观察$z$的元素，然后在$z$中最大元素的位置放上1，其它位置放上0，所这是一个<strong>hard max</strong>，也就是最大的元素的输出为1，其它的输出都为0。与之相反，<strong>Softmax</strong>所做的从$z$到这些概率的映射更为温和，我不知道这是不是一个好名字，但至少这就是<strong>softmax</strong>这一名称背后所包含的想法，与<strong>hardmax</strong>正好相反。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/36802969e1acc8b96bb19506d391efe4.png" alt="36802969e1acc8b96bb19506d391efe4"><br>有一点我没有细讲，但之前已经提到过的，就是<strong>Softmax</strong>回归或<strong>Softmax</strong>激活函数将<strong>logistic</strong>激活函数推广到$C$类，而不仅仅是两类，结果就是如果$C=2$，那么$C=2$的<strong>Softmax</strong>实际上变回了<strong>logistic</strong>回归，我不会在这个视频中给出证明，但是大致的证明思路是这样的，如果$C=2$，并且你应用了<strong>Softmax</strong>，那么输出层$a^{[L]}$将会输出两个数字，如果$C=2$的话，也许输出0.842和0.158，对吧？这两个数字加起来要等于1，因为它们的和必须为1，其实它们是冗余的，也许你不需要计算两个，而只需要计算其中一个，结果就是你最终计算那个数字的方式又回到了<strong>logistic</strong>回归计算单个输出的方式。这算不上是一个证明，但我们可以从中得出结论，<strong>Softmax</strong>回归将<strong>logistic</strong>回归推广到了两种分类以上。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2d590b27f3f80bbd31d8af257e3be606.png" alt="2d590b27f3f80bbd31d8af257e3be606"><br>接下来我们来看怎样训练带有<strong>Softmax</strong>输出层的神经网络，具体而言，我们先定义训练神经网络使会用到的损失函数。举个例子，我们来看看训练集中某个样本的目标输出，真实标签是$\begin{bmatrix} 0 \\ 1 \\ 0 \\ 0 \\ \end{bmatrix}$，用上一个视频中讲到过的例子，这表示这是一张猫的图片，因为它属于类1，现在我们假设你的神经网络输出的是$\hat y$，$\hat y$是一个包括总和为1的概率的向量，$y = \begin{bmatrix} 0.3 \\ 0.2 \\ 0.1 \\ 0.4 \\ \end{bmatrix}$，你可以看到总和为1，这就是$a^{[l]}$，$a^{[l]} = y = \begin{bmatrix} 0.3 \\ 0.2 \\ 0.1 \\ 0.4 \\ \end{bmatrix}$。对于这个样本神经网络的表现不佳，这实际上是一只猫，但却只分配到20%是猫的概率，所以在本例中表现不佳。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/ed6ccb8dc9e65953f383a3bb774e8f53.png" alt="ed6ccb8dc9e65953f383a3bb774e8f53"><br>那么你想用什么损失函数来训练这个神经网络？在<strong>Softmax</strong>分类中，我们一般用到的损失函数是$L(\hat y,y ) = - \sum_{j = 1}^{4}{y_{j}log\hat y_{j} }$，我们来看上面的单个样本来更好地理解整个过程。注意在这个样本中$y_{1} =y_{3} = y_{4} = 0$，因为这些都是0，只有$y_{2} =1$，如果你看这个求和，所有含有值为0的$y_{j}$的项都等于0，最后只剩下$-y_{2}t{log}\hat y_{2}$，因为当你按照下标$j$全部加起来，所有的项都为0，除了$j=2$时，又因为$y_{2}=1$，所以它就等于$- \ log\hat y_{2}$。</p> $L\left( \hat y,y \right) = - \sum_{j = 1}^{4}{y_{j}\log \hat y_{j} } = - y_{2}{\ log} \hat y_{2} = - {\ log} \hat y_{2}$<p>这就意味着，如果你的学习算法试图将它变小，因为梯度下降法是用来减少训练集的损失的，要使它变小的唯一方式就是使$-{\log}\hat y_{2}$变小，要想做到这一点，就需要使$\hat y_{2}$尽可能大，因为这些是概率，所以不可能比1大，但这的确也讲得通，因为在这个例子中$x$是猫的图片，你就需要这项输出的概率尽可能地大（$y= \begin{bmatrix} 0.3 \\ 0.2 \\ 0.1 \\ 0.4 \\ \end{bmatrix}$中第二个元素）。</p><p>概括来讲，损失函数所做的就是它找到你的训练集中的真实类别，然后试图使该类别相应的概率尽可能地高，如果你熟悉统计学中最大似然估计，这其实就是最大似然估计的一种形式。但如果你不知道那是什么意思，也不用担心，用我们刚刚讲过的算法思维也足够了。</p><p>这是单个训练样本的损失，整个训练集的损失$J$又如何呢？也就是设定参数的代价之类的，还有各种形式的偏差的代价，它的定义你大致也能猜到，就是整个训练集损失的总和，把你的训练算法对所有训练样本的预测都加起来，</p> $J( w^{[1]},b^{[1]},\ldots\ldots) = \frac{1}{m}\sum_{i = 1}^{m}{L( \hat y^{(i)},y^{(i)})}$<p>因此你要做的就是用梯度下降法，使这里的损失最小化。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/d9907b5fd482e355e9c6a4e6b3bdf5f9.png" alt="d9907b5fd482e355e9c6a4e6b3bdf5f9"><br>最后还有一个实现细节，注意因为$C=4$，$y$是一个4×1向量，$y$也是一个4×1向量，如果你实现向量化，矩阵大写$Y$就是$\lbrack y^{(1)}\text{}y^{(2)}\ldots\ldots\ y^{\left( m \right)}\rbrack$，例如如果上面这个样本是你的第一个训练样本，那么矩阵$Y =\begin{bmatrix} 0 & 0 & 1 & \ldots \\ 1 & 0 & 0 & \ldots \\ 0 & 1 & 0 & \ldots \\ 0 & 0 & 0 & \ldots \\ \end{bmatrix}$，那么这个矩阵$Y$最终就是一个$4×m$维矩阵。类似的，$\hat{Y} = \lbrack{\hat{y} }^{(1)}{\hat{y} }^{(2)} \ldots \ldots\ {\hat{y} }^{(m)}\rbrack$，这个其实就是${\hat{y} }^{(1)}$（$a^{[l](1)} = y^{(1)} = \begin{bmatrix} 0.3 \\ 0.2 \\ 0.1 \\ 0.4 \\ \end{bmatrix}$），或是第一个训练样本的输出，那么$\hat{Y} = \begin{bmatrix} 0.3 & \ldots \\ 0.2 & \ldots \\ 0.1 & \ldots \\ 0.4 & \ldots \\ \end{bmatrix}$，$\hat{Y}$本身也是一个$4×m$维矩阵。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c357c15e4133152bd8bb262789e71765.png" alt="c357c15e4133152bd8bb262789e71765"><br>最后我们来看一下，在有<strong>Softmax</strong>输出层时如何实现梯度下降法，这个输出层会计算$z^{[l]}$，它是$C×1$维的，在这个例子中是4×1，然后你用<strong>Softmax</strong>激活函数来得到$a^{[l]}$或者说$y$，然后又能由此计算出损失。我们已经讲了如何实现神经网络前向传播的步骤，来得到这些输出，并计算损失，那么反向传播步骤或者梯度下降法又如何呢？其实初始化反向传播所需要的关键步骤或者说关键方程是这个表达式$dz^{[l]} = \hat{y} -y$，你可以用$\hat{y}$这个4×1向量减去$y$这个4×1向量，你可以看到这些都会是4×1向量，当你有4个分类时，在一般情况下就是$C×1$，这符合我们对$dz$的一般定义，这是对$z^{[l]}$损失函数的偏导数（$dz^{[l]} = \frac{\partial J}{\partial z^{[l]} }$），如果你精通微积分就可以自己推导，或者说如果你精通微积分，可以试着自己推导，但如果你需要从零开始使用这个公式，它也一样有用。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/e342eb0e5cc8031f43fd375084b1f473.png" alt="e342eb0e5cc8031f43fd375084b1f473"><br>有了这个，你就可以计算$dz^{[l]}$，然后开始反向传播的过程，计算整个神经网络中所需要的所有导数。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1d5eca1724fe08158fb9b53a73691a74.png" alt="1d5eca1724fe08158fb9b53a73691a74"><br>但在这周的初级练习中，我们将开始使用一种深度学习编程框架，对于这些编程框架，通常你只需要专注于把前向传播做对，只要你将它指明为编程框架，前向传播，它自己会弄明白怎样反向传播，会帮你实现反向传播，所以这个表达式值得牢记（$dz^{[l]} = \hat{y} -y$），如果你需要从头开始，实现<strong>Softmax</strong>回归或者<strong>Softmax</strong>分类，但其实在这周的初级练习中你不会用到它，因为编程框架会帮你搞定导数计算。</p><p><strong>Softmax</strong>分类就讲到这里，有了它，你就可以运用学习算法将输入分成不止两类，而是$C$个不同类别。接下来我想向你展示一些深度学习编程框架，可以让你在实现深度学习算法时更加高效，让我们在下一个视频中一起讨论。</p><h3 id="3-10-深度学习框架（Deep-Learning-frameworks）"><a href="#3-10-深度学习框架（Deep-Learning-frameworks）" class="headerlink" title="3.10 深度学习框架（Deep Learning frameworks）"></a>3.10 深度学习框架（Deep Learning frameworks）</h3><p>你已经差不多从零开始学习了使用<strong>Python</strong>和<strong>NumPy</strong>实现深度学习算法，很高兴你这样做了，因为我希望你理解这些深度学习算法实际上在做什么。但你会发现，除非应用更复杂的模型，例如卷积神经网络，或者循环神经网络，或者当你开始应用很大的模型，否则它就越来越不实用了，至少对大多数人而言，从零开始全部靠自己实现并不现实。</p><p>幸运的是，现在有很多好的深度学习软件框架，可以帮助你实现这些模型。类比一下，我猜你知道如何做矩阵乘法，你还应该知道如何编程实现两个矩阵相乘，但是当你在建很大的应用时，你很可能不想用自己的矩阵乘法函数，而是想要访问一个数值线性代数库，它会更高效，但如果你明白两个矩阵相乘是怎么回事还是挺有用的。我认为现在深度学习已经很成熟了，利用一些深度学习框架会更加实用，会使你的工作更加有效，那就让我们来看下有哪些框架。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/acb3843cd1085b0742f39677289890a0.png" alt="acb3843cd1085b0742f39677289890a0"><br>现在有许多深度学习框架，能让实现神经网络变得更简单，我们来讲主要的几个。每个框架都针对某一用户或开发群体的，我觉得这里的每一个框架都是某类应用的可靠选择，有很多人写文章比较这些深度学习框架，以及这些深度学习框架发展得有多好，而且因为这些框架往往不断进化，每个月都在进步，如果你想看看关于这些框架的优劣之处的讨论，我留给你自己去网上搜索，但我认为很多框架都在很快进步，越来越好，因此我就不做强烈推荐了，而是与你分享推荐一下选择框架的标准。</p><p>一个重要的标准就是便于编程，这既包括神经网络的开发和迭代，还包括为产品进行配置，为了成千上百万，甚至上亿用户的实际使用，取决于你想要做什么。</p><p>第二个重要的标准是运行速度，特别是训练大数据集时，一些框架能让你更高效地运行和训练神经网络。</p><p>还有一个标准人们不常提到，但我觉得很重要，那就是这个框架是否真的开放，要是一个框架真的开放，它不仅需要开源，而且需要良好的管理。不幸的是，在软件行业中，一些公司有开源软件的历史，但是公司保持着对软件的全权控制，当几年时间过去，人们开始使用他们的软件时，一些公司开始逐渐关闭曾经开放的资源，或将功能转移到他们专营的云服务中。因此我会注意的一件事就是你能否相信这个框架能长时间保持开源，而不是在一家公司的控制之下，它未来有可能出于某种原因选择停止开源，即便现在这个软件是以开源的形式发布的。但至少在短期内，取决于你对语言的偏好，看你更喜欢<strong>Python</strong>，<strong>Java</strong>还是<strong>C++</strong>或者其它什么，也取决于你在开发的应用，是计算机视觉，还是自然语言处理或者线上广告，等等，我认为这里的多个框架都是很好的选择。</p><p>程序框架就讲到这里，通过提供比数值线性代数库更高程度的抽象化，这里的每一个程序框架都能让你在开发深度机器学习应用时更加高效。</p><h3 id="3-11-TensorFlow"><a href="#3-11-TensorFlow" class="headerlink" title="3.11 TensorFlow"></a>3.11 TensorFlow</h3><p>欢迎来到这周的最后一个视频，有很多很棒的深度学习编程框架，其中一个是<strong>TensorFlow</strong>，我很期待帮助你开始学习使用<strong>TensorFlow</strong>，我想在这个视频中向你展示<strong>TensorFlow</strong>程序的基本结构，然后让你自己练习，学习更多细节，并运用到本周的编程练习中，这周的编程练习需要花些时间来做，所以请务必留出一些空余时间。</p><p>先提一个启发性的问题，假设你有一个损失函数$J$需要最小化，在本例中，我将使用这个高度简化的损失函数，$Jw= w^{2}-10w+25$，这就是损失函数，也许你已经注意到该函数其实就是${(w -5)}^{2}$，如果你把这个二次方式子展开就得到了上面的表达式，所以使它最小的$w$值是5，但假设我们不知道这点，你只有这个函数，我们来看一下怎样用<strong>TensorFlow</strong>将其最小化，因为一个非常类似的程序结构可以用来训练神经网络。其中可以有一些复杂的损失函数$J(w,b)$取决于你的神经网络的所有参数，然后类似的，你就能用<strong>TensorFlow</strong>自动找到使损失函数最小的$w$和$b$的值。但让我们先从左边这个更简单的例子入手。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2a06f1bc26d2eff88246233ba60fc999.png" alt="2a06f1bc26d2eff88246233ba60fc999"><br>我在我的<strong>Jupyter notebook</strong>中运行<strong>Python</strong>，</p><pre><code>import numpy as np
import tensorflow as tf
#导入TensorFlow

w = tf.Variable(0,dtype = tf.float32)
#接下来，让我们定义参数w，在TensorFlow中，你要用tf.Variable()来定义参数

#然后我们定义损失函数：

cost = tf.add(tf.add(w**2,tf.multiply(- 10.,w)),25)
#然后我们定义损失函数J
然后我们再写：

train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)
#(让我们用0.01的学习率，目标是最小化损失)。

#最后下面的几行是惯用表达式:

init = tf.global_variables_initializer()

session = tf.Session()#这样就开启了一个TensorFlow session。

session.run(init)#来初始化全局变量。

#然后让TensorFlow评估一个变量，我们要用到:

session.run(w)

#上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以#上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以session.run(w)评估了w，让我：：

print(session.run(w))
</code></pre><p>所以如果我们运行这个，它评估$w$等于0，因为我们什么都还没运行。</p><pre><code>#现在让我们输入：

$session.run(train)，它所做的就是运行一步梯度下降法。
#接下来在运行了一步梯度下降法后，让我们评估一下w的值，再print：

print(session.run(w))
#在一步梯度下降法之后，w现在是0.1。</code></pre><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/66541b3ff40c4c43897a062395420cfa.png" alt="66541b3ff40c4c43897a062395420cfa"><br>现在我们运行梯度下降1000次迭代：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/f89f49038463b9f30eb09b10f7c0c438.png" alt="f89f49038463b9f30eb09b10f7c0c438"><br>这是运行了梯度下降的1000次迭代，最后$w$变成了4.99999，记不记得我们说${(w -5)}^{2}$最小化，因此$w$的最优值是5，这个结果已经很接近了。</p><p>希望这个让你对<strong>TensorFlow</strong>程序的大致结构有了了解，当你做编程练习，使用更多<strong>TensorFlow</strong>代码时，我这里用到的一些函数你会熟悉起来，这里有个地方要注意，$w$是我们想要优化的参数，因此将它称为变量，注意我们需要做的就是定义一个损失函数，使用这些<code>add</code>和<code>multiply</code>之类的函数。<strong>TensorFlow</strong>知道如何对<code>add</code>和<code>mutiply</code>，还有其它函数求导，这就是为什么你只需基本实现前向传播，它能弄明白如何做反向传播和梯度计算，因为它已经内置在<code>add</code>，<code>multiply</code>和平方函数中。</p><p>对了，要是觉得这种写法不好看的话，<strong>TensorFlow</strong>其实还重载了一般的加减运算等等，因此你也可以把$cost$写成更好看的形式，把之前的<code>cost</code>标成注释，重新运行，得到了同样的结果。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/43a90dbd043662008d46f168def244b6.png" alt="43a90dbd043662008d46f168def244b6"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/05ab9534065d6359969bcc947e90bad4.png" alt="05ab9534065d6359969bcc947e90bad4"><br>一旦$w$被称为<strong>TensorFlow</strong>变量，平方，乘法和加减运算都重载了，因此你不必使用上面这种不好看的句法。</p><p><strong>TensorFlow</strong>还有一个特点，我想告诉你，那就是这个例子将$w$的一个固定函数最小化了。如果你想要最小化的函数是训练集函数又如何呢？不管你有什么训练数据$x$，当你训练神经网络时，训练数据$x$会改变，那么如何把训练数据加入<strong>TensorFlow</strong>程序呢？</p><p>我会定义$x$，把它想做扮演训练数据的角色，事实上训练数据有$x$和$y$，但这个例子中只有$x$，把$x$定义为：</p><p><code>x = tf.placeholder(tf.float32,[3,1])</code>，让它成为$[3,1]$数组，我要做的就是，因为$cost$这个二次方程的三项前有固定的系数，它是$w^{2}+10w + 25$，我们可以把这些数字1，-10和25变成数据，我要做的就是把$cost$替换成：</p><p><code>cost = x[0][0]*w**2 +x[1][0]*w + x[2][0]</code>，现在$x$变成了控制这个二次函数系数的数据，这个<strong>placeholder</strong>函数告诉<strong>TensorFlow</strong>，你稍后会为$x$提供数值。</p><p>让我们再定义一个数组，<code>coefficient = np.array([[1.],[-10.],[25.]])</code>，这就是我们要接入$x$的数据。最后我们需要用某种方式把这个系数数组接入变量$x$，做到这一点的句法是，在训练这一步中，要提供给$x$的数值，我在这里设置：</p><p><code>feed_dict = {x:coefficients}</code></p><p>好了，希望没有语法错误，我们重新运行它，希望得到和之前一样的结果。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c93322e2d42219cd37fb579170abada9.png" alt="c93322e2d42219cd37fb579170abada9"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/0c3521b9de148f6df29b7bfccf3e6686.png" alt="0c3521b9de148f6df29b7bfccf3e6686"><br>现在如果你想改变这个二次函数的系数，假设你把：</p><p><code>coefficient = np.array([[1.],[-10.],[25.]])</code></p><p>改为：<code>coefficient = np.array([[1.],[-20.],[100.]])</code></p><p>现在这个函数就变成了${(w -10)}^{2}$，如果我重新运行，希望我得到的使${(w -10)}^{2}$最小化的$w$值为10，让我们看一下，很好，在梯度下降1000次迭代之后，我们得到接近10的$w$。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/52e7654f07e90eb39a99679692bd6514.png" alt="52e7654f07e90eb39a99679692bd6514"><br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/10589b1fbdea44354e14a071a2244466.png" alt="10589b1fbdea44354e14a071a2244466"><br>在你做编程练习时，见到更多的是，<strong>TensorFlow</strong>中的<strong>placeholder</strong>是一个你之后会赋值的变量，这种方式便于把训练数据加入损失方程，把数据加入损失方程用的是这个句法，当你运行训练迭代，用<code>feed_dict</code>来让<code>x=coefficients</code>。如果你在做<strong>mini-batch</strong>梯度下降，在每次迭代时，你需要插入不同的<strong>mini-batch</strong>，那么每次迭代，你就用<code>feed_dict</code>来喂入训练集的不同子集，把不同的<strong>mini-batch</strong>喂入损失函数需要数据的地方。</p><p>希望这让你了解了<strong>TensorFlow</strong>能做什么，让它如此强大的是，你只需说明如何计算损失函数，它就能求导，而且用一两行代码就能运用梯度优化器，<strong>Adam</strong>优化器或者其他优化器。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3642c894eee19fce479efa42b027b56f.png" alt="3642c894eee19fce479efa42b027b56f"><br>这还是刚才的代码，我稍微整理了一下，尽管这些函数或变量看上去有点神秘，但你在做编程练习时多练习几次就会熟悉起来了。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/b276862d4e931b4b94a7a8d216e2812e.png" alt="b276862d4e931b4b94a7a8d216e2812e"><br>还有最后一点我想提一下，这三行（蓝色大括号部分）在<strong>TensorFlow</strong>里是符合表达习惯的，有些程序员会用这种形式来替代，作用基本上是一样的。</p><p>但这个<strong>with</strong>结构也会在很多<strong>TensorFlow</strong>程序中用到，它的意思基本上和左边的相同，但是<strong>Python</strong>中的<strong>with</strong>命令更方便清理，以防在执行这个内循环时出现错误或例外。所以你也会在编程练习中看到这种写法。那么这个代码到底做了什么呢？让我们看这个等式：</p><p><code>cost =x[0][0]*w**2 +x[1][0]*w + x[2][0]#(w-5)**2</code></p><p><strong>TensorFlow</strong>程序的核心是计算损失函数，然后<strong>TensorFlow</strong>自动计算出导数，以及如何最小化损失，因此这个等式或者这行代码所做的就是让<strong>TensorFlow</strong>建立计算图，计算图所做的就是取$x[0][0]$，取$w$，然后将它平方，然后$x[0][0]$和$w^{2}$相乘，你就得到了$x[0][0]<em>w^{2}$，以此类推，最终整个建立起来计算$cost = [0][0]</em>w*<em>2 + x[1][0]</em>w + x[2][0]$，最后你得到了损失函数。</p><p><strong>TensorFlow</strong>的优点在于，通过用这个计算损失，计算图基本实现前向传播，<strong>TensorFlow</strong>已经内置了所有必要的反向函数，回忆一下训练深度神经网络时的一组前向函数和一组反向函数，而像<strong>TensorFlow</strong>之类的编程框架已经内置了必要的反向函数，这也是为什么通过内置函数来计算前向函数，它也能自动用反向函数来实现反向传播，即便函数非常复杂，再帮你计算导数，这就是为什么你不需要明确实现反向传播，这是编程框架能帮你变得高效的原因之一。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/421ad00776a97e6cd4fd926e35a5a419.png" alt="421ad00776a97e6cd4fd926e35a5a419"><br>如果你看<strong>TensorFlow</strong>的使用说明，我只是指出<strong>TensorFlow</strong>的说明用了一套和我不太一样的符号来画计算图，它用了$x[0][0]$，$w$，然后它不是写出值，想这里的$w^{2}$，<strong>TensorFlow</strong>使用说明倾向于只写运算符，所以这里就是平方运算，而这两者一起指向乘法运算，以此类推，然后在最后的节点，我猜应该是一个将$x[2][0]$加上去得到最终值的加法运算。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/c7c804ba2a909bb914efbfd76eb57784.png" alt="c7c804ba2a909bb914efbfd76eb57784"><br>为本课程起见，我认为计算图用第一种方式会更容易理解，但是如果你去看<strong>TensorFlow</strong>的使用说明，如果你看到说明里的计算图，你会看到另一种表示方式，节点都用运算来标记而不是值，但这两种呈现方式表达的是同样的计算图。</p><p>在编程框架中你可以用一行代码做很多事情，例如，你不想用梯度下降法，而是想用<strong>Adam</strong>优化器，你只要改变这行代码，就能很快换掉它，换成更好的优化算法。所有现代深度学习编程框架都支持这样的功能，让你很容易就能编写复杂的神经网络。</p><p>我希望我帮助你了解了<strong>TensorFlow</strong>程序典型的结构，概括一下这周的内容，你学习了如何系统化地组织超参数搜索过程，我们还讲了<strong>Batch</strong>归一化，以及如何用它来加速神经网络的训练，最后我们讲了深度学习的编程框架，有很多很棒的编程框架，这最后一个视频我们重点讲了<strong>TensorFlow</strong>。有了它，我希望你享受这周的编程练习，帮助你更熟悉这些概念。</p></article><div class="post-donate"><div id="donate_board" class="donate_bar center"><a id="btn_donate" class="btn_donate" href="javascript:;" title="打赏"></a> <span class="donate_txt">↑<br> 欢迎投食,求鼓励，求支持！</span><br></div><div id="donate_guide" class="donate_bar center hidden"> <img src="/images/alipay.png" alt="支付宝打赏"> <img src="/images/wechatpay.png" alt="微信打赏"></div><script type="text/javascript">document.getElementById("btn_donate").onclick=function(){$("#donate_board").addClass("hidden"),$("#donate_guide").removeClass("hidden")}</script></div><div class="nexmoe-post-copyright"><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i> <strong>本文作者：</strong>OneJane<br> <strong>本文链接：</strong><a href="https://onejane.github.io/2019/12/05/new_吴恩达深度学习笔记(第二课时)/" title="https://onejane.github.io/2019/12/05/new_吴恩达深度学习笔记(第二课时)/" target="_blank" rel="noopener">https://onejane.github.io/2019/12/05/new_吴恩达深度学习笔记(第二课时)/</a><br> <strong>版权声明：</strong>本文采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh" target="_blank">CC BY-NC-SA 3.0 CN</a> 协议进行许可</div><section class="nexmoe-comment"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.css"><div id="gitalk"></div><script src="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"e677e59382e1c7a468fd",clientSecret:"717d041bc4ab749f069314862232cfb6ec8adc15",id:decodeURI(window.location.pathname),repo:"onejane.github.io",owner:"onejane",admin:"onejane"});gitalk.render("gitalk")</script></section></div></div></div><script src="https://cdn.jsdelivr.net/npm/mdui@0.4.3/dist/js/mdui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/smoothscroll-for-websites@1.4.9/SmoothScroll.min.js"></script><script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.15.8/build/highlight.min.js"></script><script>hljs.initHighlightingOnLoad()</script><script src="/js/app.js?v=1575538185604"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@5.1.0/lazysizes.min.js"></script><div hidden><script type="text/javascript" src="https://js.users.51.la/20279757.js"></script></div></body><script src="https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js"></script></html>