<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><title>基于CNN的电影推荐系统（10） - OneJane</title><meta charset="UTF-8"><meta name="description" content="微服务,高可用,高并发,人工智能"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="msvalidate.01" content="396E9693347B4D18AAE96D9E75B9B686"><link rel="shortcut icon" href="/images/a.ico" type="image/png"><meta name="description" content="本文从深度学习卷积神经网络入手，基于 Github 的开源项目来完成 MovieLens 数据集的电影推荐系统。"><meta name="keywords" content="cnn"><meta property="og:type" content="article"><meta property="og:title" content="基于CNN的电影推荐系统（10）"><meta property="og:url" content="https://onejane.github.io/2019/11/22/10.基于CNN的电影推荐系统/index.html"><meta property="og:site_name" content="OneJane"><meta property="og:description" content="本文从深度学习卷积神经网络入手，基于 Github 的开源项目来完成 MovieLens 数据集的电影推荐系统。"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422677953.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422683692.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422707432.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422736421.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422771930.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422778217.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422814946.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422850901.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422868421.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422874275.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422924338.png"><meta property="og:updated_time" content="2019-11-22T13:28:05.245Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="基于CNN的电影推荐系统（10）"><meta name="twitter:description" content="本文从深度学习卷积神经网络入手，基于 Github 的开源项目来完成 MovieLens 数据集的电影推荐系统。"><meta name="twitter:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422677953.png"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdui@0.4.3/dist/css/mdui.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.15.8/styles/atom-one-dark.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1038733_0xvrvpg9c0r.css"><link rel="stylesheet" href="/css/style.css?v=1575583208097"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js"></script></head><body class="mdui-drawer-body-left"><div id="nexmoe-background"><div class="nexmoe-bg" style="background-image:url(https://www.github.com/OneJane/blog/raw/master/小书匠/1566388885395.png)"></div><div class="mdui-appbar mdui-shadow-0"><div class="mdui-toolbar"> <a mdui-drawer="{target: '#drawer', swipe: true}" title="menu" class="mdui-btn mdui-btn-icon"><i class="mdui-icon material-icons">menu</i></a><div class="mdui-toolbar-spacer"></div> <a href="/" title="OneJane" class="mdui-btn mdui-btn-icon"><img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388846021.png"></a></div></div></div><div id="nexmoe-header"><div class="nexmoe-drawer mdui-drawer" id="drawer"><div class="nexmoe-avatar mdui-ripple"> <a href="/" title="OneJane"><img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388846021.png" alt="OneJane"></a></div><div class="nexmoe-count"><div><span>文章</span>69</div><div><span>标签</span>83</div><div><span>分类</span>12</div></div><ul class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}"><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/" title="回到首页"><i class="mdui-list-item-icon nexmoefont icon-home"></i><div class="mdui-list-item-content"> 回到首页</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/about.html" title="关于博客"><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i><div class="mdui-list-item-content"> 关于博客</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/py.html" title="我的朋友"><i class="mdui-list-item-icon nexmoefont icon-unorderedlist"></i><div class="mdui-list-item-content"> 我的朋友</div></a></ul><aside id="nexmoe-sidebar"><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">社交按钮</h3><div class="nexmoe-widget nexmoe-social"><a class="mdui-ripple" href="https://www.zhihu.com/people/codewj/activities" target="_blank" mdui-tooltip="{content: 'zhihu'}" style="color:#e76a8d;background-color:rgba(231,106,141,.15)"><i class="nexmoefont icon-zhihu"></i></a><a class="mdui-ripple" href="https://github.com/OneJane" target="_blank" mdui-tooltip="{content: 'GitHub'}" style="color:#191717;background-color:rgba(25,23,23,.15)"><i class="nexmoefont icon-github"></i></a></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">文章分类</h3><div class="nexmoe-widget"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/人工智能/">人工智能</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/定时器/">定时器</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/持续集成/">持续集成</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/注册中心/">注册中心</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/测试/">测试</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/系统/">系统</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/自然语言处理/">自然语言处理</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目实战/">项目实战</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/高可用/">高可用</a><span class="category-list-count">4</span></li></ul></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">标签云</h3><div class="nexmoe-widget tagcloud"> <a href="/tags/Gensim/" style="font-size:10px">Gensim</a> <a href="/tags/Hanlp/" style="font-size:10px">Hanlp</a> <a href="/tags/NLTK/" style="font-size:10px">NLTK</a> <a href="/tags/OpenCV/" style="font-size:12.86px">OpenCV</a> <a href="/tags/Stanford-NLP/" style="font-size:10px">Stanford NLP</a> <a href="/tags/Tensorflow/" style="font-size:15.71px">Tensorflow</a> <a href="/tags/ant-design/" style="font-size:10px">ant design</a> <a href="/tags/ant-design-pro/" style="font-size:11.43px">ant design pro</a> <a href="/tags/auc/" style="font-size:10px">auc</a> <a href="/tags/bottle/" style="font-size:10px">bottle</a> <a href="/tags/chatterbot/" style="font-size:10px">chatterbot</a> <a href="/tags/cnn/" style="font-size:12.86px">cnn</a> <a href="/tags/crf/" style="font-size:12.86px">crf</a> <a href="/tags/doc2vec/" style="font-size:10px">doc2vec</a> <a href="/tags/docker/" style="font-size:17.14px">docker</a> <a href="/tags/dubbo/" style="font-size:11.43px">dubbo</a> <a href="/tags/elasticsearch/" style="font-size:10px">elasticsearch</a> <a href="/tags/elastisearch/" style="font-size:10px">elastisearch</a> <a href="/tags/email/" style="font-size:10px">email</a> <a href="/tags/es6/" style="font-size:10px">es6</a> <a href="/tags/feign/" style="font-size:10px">feign</a> <a href="/tags/flask/" style="font-size:11.43px">flask</a> <a href="/tags/folium/" style="font-size:10px">folium</a> <a href="/tags/freemarker/" style="font-size:10px">freemarker</a> <a href="/tags/function/" style="font-size:10px">function</a> <a href="/tags/gateway/" style="font-size:10px">gateway</a> <a href="/tags/gensim/" style="font-size:11.43px">gensim</a> <a href="/tags/gitlab/" style="font-size:11.43px">gitlab</a> <a href="/tags/gru/" style="font-size:11.43px">gru</a> <a href="/tags/hanlp/" style="font-size:11.43px">hanlp</a> <a href="/tags/haproxy/" style="font-size:10px">haproxy</a> <a href="/tags/hmm/" style="font-size:10px">hmm</a> <a href="/tags/jenkins/" style="font-size:11.43px">jenkins</a> <a href="/tags/jieba/" style="font-size:15.71px">jieba</a> <a href="/tags/jmeter/" style="font-size:10px">jmeter</a> <a href="/tags/keepalived/" style="font-size:10px">keepalived</a> <a href="/tags/lda/" style="font-size:11.43px">lda</a> <a href="/tags/linux/" style="font-size:10px">linux</a> <a href="/tags/lstm/" style="font-size:12.86px">lstm</a> <a href="/tags/maven/" style="font-size:11.43px">maven</a> <a href="/tags/multi-druid/" style="font-size:10px">multi druid</a> <a href="/tags/mybatis/" style="font-size:10px">mybatis</a> <a href="/tags/mybatisplus/" style="font-size:10px">mybatisplus</a> <a href="/tags/mysql/" style="font-size:10px">mysql</a> <a href="/tags/n-gram/" style="font-size:10px">n-gram</a> <a href="/tags/nacos/" style="font-size:11.43px">nacos</a> <a href="/tags/neo4j/" style="font-size:11.43px">neo4j</a> <a href="/tags/nexmoe/" style="font-size:10px">nexmoe</a> <a href="/tags/nlp/" style="font-size:20px">nlp</a> <a href="/tags/numpy/" style="font-size:10px">numpy</a> <a href="/tags/partition/" style="font-size:10px">partition</a> <a href="/tags/procedure/" style="font-size:10px">procedure</a> <a href="/tags/pxc/" style="font-size:10px">pxc</a> <a href="/tags/pyhanlp/" style="font-size:11.43px">pyhanlp</a> <a href="/tags/python/" style="font-size:10px">python</a> <a href="/tags/rabbitmq/" style="font-size:10px">rabbitmq</a> <a href="/tags/react/" style="font-size:11.43px">react</a> <a href="/tags/redis/" style="font-size:11.43px">redis</a> <a href="/tags/redis-cluster/" style="font-size:10px">redis-cluster</a> <a href="/tags/replication/" style="font-size:11.43px">replication</a> <a href="/tags/rnn/" style="font-size:10px">rnn</a> <a href="/tags/rocketmq/" style="font-size:11.43px">rocketmq</a> <a href="/tags/scrapy/" style="font-size:12.86px">scrapy</a> <a href="/tags/selenium/" style="font-size:12.86px">selenium</a> <a href="/tags/sentinel/" style="font-size:14.29px">sentinel</a> <a href="/tags/seq2seq/" style="font-size:10px">seq2seq</a> <a href="/tags/session/" style="font-size:10px">session</a> <a href="/tags/sklearn/" style="font-size:10px">sklearn</a> <a href="/tags/skywalking/" style="font-size:11.43px">skywalking</a> <a href="/tags/snownlp/" style="font-size:10px">snownlp</a> <a href="/tags/spring-cloud-alibaba/" style="font-size:18.57px">spring cloud alibaba</a> <a href="/tags/springboot/" style="font-size:14.29px">springboot</a> <a href="/tags/svm/" style="font-size:10px">svm</a> <a href="/tags/swagger/" style="font-size:10px">swagger</a> <a href="/tags/textrank/" style="font-size:10px">textrank</a> <a href="/tags/tf-idf/" style="font-size:12.86px">tf-idf</a> <a href="/tags/tk-mybatis/" style="font-size:10px">tk mybatis</a> <a href="/tags/umi/" style="font-size:10px">umi</a> <a href="/tags/validate/" style="font-size:10px">validate</a> <a href="/tags/word2vec/" style="font-size:10px">word2vec</a> <a href="/tags/wordcloud/" style="font-size:10px">wordcloud</a> <a href="/tags/xxl-job/" style="font-size:11.43px">xxl-job</a> <a href="/tags/zookeeper/" style="font-size:10px">zookeeper</a></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">文章归档</h3><div class="nexmoe-widget"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li></ul></div></div></aside><div class="nexmoe-copyright"> &copy; 2019 OneJane</div></div></div><div id="nexmoe-content"><div class="nexmoe-primary"><div class="nexmoe-post"><div class="nexmoe-post-cover"> <img src="https://www.github.com/OneJane/blog/raw/master/小书匠/v2-868873e43f590978e8c6f9ba4c6e203d_hd.jpg"><h1>基于CNN的电影推荐系统（10）</h1></div><div class="nexmoe-post-meta"><a><i class="nexmoefont icon-calendar-fill"></i> 2019年11月22日</a><a><i class="nexmoefont icon-areachart"></i> 3.7k 字</a><a><i class="nexmoefont icon-time-circle-fill"></i> 大概 16 分钟</a> <a class="nexmoefont icon-appstore-fill -link" href="/categories/自然语言处理/">自然语言处理</a> <a class="nexmoefont icon-tag-fill -link" href="/tags/cnn/">cnn</a></div><article><p>本文从深度学习卷积神经网络入手，基于 Github 的开源项目来完成 MovieLens 数据集的电影推荐系统。</p><a id="more"></a><h1 id="什么是推荐系统呢？"><a href="#什么是推荐系统呢？" class="headerlink" title="什么是推荐系统呢？"></a>什么是推荐系统呢？</h1><p>什么是推荐系统呢？首先我们来看看几个常见的推荐场景。</p><p>如果你经常通过豆瓣电影评分来找电影，你会发现下图所示的推荐：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422677953.png" alt="enter description here"></p><p>如果你喜欢购物，根据你的选择和购物行为，平台会给你推荐相似商品：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422683692.png" alt="enter description here"></p><p>在互联网的很多场景下都可以看到推荐的影子。因为推荐可以帮助用户和商家满足不同的需求：</p><ul><li><p>对用户而言：找到感兴趣的东西，帮助发现新鲜、有趣的事物。</p></li><li><p>对商家而言：提供个性化服务，提高信任度和粘性，增加营收。</p></li></ul><p>常见的推荐系统主要包含两个方面的内容，基于用户的推荐系统（UserCF）和基于物品的推荐系统（ItemCF）。两者的区别在于，UserCF<br>给用户推荐那些和他有共同兴趣爱好的用户喜欢的商品，而 ItemCF 给用户推荐那些和他之前喜欢的商品类似的商品。这两种方式都会遭遇冷启动问题。</p><p>下面是 UserCF 和 ItemCF 的对比：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422707432.png" alt="enter description here"></p><h1 id="CNN-是如何应用在文本处理上的？"><a href="#CNN-是如何应用在文本处理上的？" class="headerlink" title="CNN 是如何应用在文本处理上的？"></a>CNN 是如何应用在文本处理上的？</h1><p>提到卷积神经网络（CNN），相信大部分人首先想到的是图像分类，比如 MNIST 手写体识别，CAFRI10 图像分类。CNN<br>已经在图像识别方面取得了较大的成果，随着近几年的不断发展，在文本处理领域，基于文本挖掘的文本卷积神经网络被证明是有效的。</p><p>首先，来看看 CNN 是如何应用到 NLP 中的，下面是一个简单的过程图：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422736421.png" alt="enter description here"></p><p>和图像像素处理不一样，自然语言通常是一段文字，那么在特征矩阵中，矩阵的每一个行向量（比如 word2vec 或者 doc2vec）代表一个<br>Token，包括词或者字符。如果一段文字包含有 n 个词，每个词有 m 维的词向量，那么我们可以构造出一个 <code>n*m</code> 的词向量矩阵，在 NLP<br>处理过程中，让过滤器宽度和矩阵宽度保持一致整行滑动。</p><h1 id="动手实战基于-CNN-的电影推荐系统"><a href="#动手实战基于-CNN-的电影推荐系统" class="headerlink" title="动手实战基于 CNN 的电影推荐系统"></a>动手实战基于 CNN 的电影推荐系统</h1><p>将 CNN 的技术应用到自然语言处理中并与电影推荐相结合，来训练一个基于文本的卷积神经网络，实现电影个性化推荐系统。</p><p>首先感谢作者 chengstone 的分享，源码请访问下面网址： <a href="https://github.com/chengstone/movie_recommender" target="_blank" rel="noopener">Github</a></p><p>在验证了 CNN 应用在自然语言处理上是有效的之后，从推荐系统的个性化推荐入手，在文本上，把 CNN成果应用到电影的个性化推荐上。并在特征工程中，对训练集和测试集做了相应的特征处理，其中有部分字段是类型性变量，特征工程上可以采用 <code>one-hot</code>编码，但是对于 UserID、MovieID 这样非常稀疏的变量，如果使用 <code>one-hot</code>，那么数据的维度会急剧膨胀，对于这份数据集来说是不合适的。</p><p>具体算法设计如下：</p><p><strong>1.</strong> 定义用户嵌入矩阵。</p><p>用户的特征矩阵主要是通过用户信息嵌入网络来生成的，在预处理数据的时候，我们将<br>UserID、MovieID、性别、年龄、职业特征全部转成了数字类型，然后把这个数字当作嵌入矩阵的索引，在网络的第一层就使用嵌入层，这样数据输入的维度保持在（N，32）和（N，16）。然后进行全连接层，转成（N，128）的大小，再进行全连接层，转成（N，200）的大小，这样最后输出的用户特征维度相对比较高，也保证了能把每个用户所带有的特征充分携带并通过特征表达。</p><p>具体流程如下：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422771930.png" alt="enter description here"></p><p><strong>2.</strong> 生成用户特征。</p><p>生成用户特征是在用户嵌入矩阵网络输出结果的基础上，通过2层全连接层实现的。第一个全连接层把特征矩阵转成（N，128）的大小，再进行第二次全连接层，转成（N，200）的大小，这样最后输出的用户特征维度相对比较高，也保证了能把每个用户所带有的特征充分携带并通过特征表达。</p><p>具体流程如下：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422778217.png" alt="enter description here"></p><p><strong>3.</strong> 定义电影 ID 嵌入矩阵。</p><p>通过电影 ID 和电影类型分别生成电影 ID 和电影类型特征，电影类型的多个嵌入向量做加和输出。电影 ID的实现过程和上面一样，但是对于电影类型的处理相较于上面，稍微复杂一点。因为电影类型有重叠性，一个电影可以属于多个类别，当把电影类型从嵌入矩阵索引出来之后是一个（N，32）形状的矩阵，因为有多个类别，这里采用的处理方式是矩阵求和，把类别加上去，变成（1，32）形状，这样使得电影的类别信息不会丢失。</p><p>具体流程如下：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422814946.png" alt="enter description here"></p><p><strong>4.</strong> 文本卷积神经网络设计。</p><p>文本卷积神经网络和单纯的 CNN网络结构有点不同，因为自然语言通常是一段文字与图片像素组成的矩阵是不一样的。在电影文本特征矩阵中，矩阵的每一个行构成的行向量代表一个Token，包括词或者字符。如果一段文字有 n 个词，每个词有 m 维的词向量，那么我们可以构造出一个 <code>n*m</code> 的矩阵。而且 NLP处理过程中，会有多个不同大小的过滤器串行执行，且过滤器宽度和矩阵宽度保持一致，是整行滑动。在执行完卷积操作之后采用了 ReLU激活函数，然后采用最大池化操作，最后通过全连接并 Dropout 操作和 Softmax输出。这里电影名称的处理比较特殊，并没有采用循环神经网络，而采用的是文本在 CNN 网络上的应用。</p><p>对于电影数据集，我们对电影名称做 CNN处理，其大致流程，从嵌入矩阵中得到电影名对应的各个单词的嵌入向量，由于电影名称比较特殊一点，名称长度有一定限制，这里过滤器大小使用时，就选择2、3、4、5长度。然后对文本嵌入层使用滑动2、3、4、5个单词尺寸的卷积核做卷积和最大池化，然后Dropout 操作，全连接层输出。</p><p>具体流程如下：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422850901.png" alt="enter description here"></p><p>具体过程描述：</p><p>（1）首先输入一个 <code>32*32</code> 的矩阵；</p><p>（2）第一次卷积核大小为 <code>2*2</code>，得到 <code>31*31</code> 的矩阵，然后通过 <code>[1,14,1,1]</code> 的 <code>max-pooling</code> 操作，得到的矩阵为<br><code>18*31</code>；</p><p>（3）第二次卷积核大小为 <code>3*3</code>，得到 <code>16*29的矩阵，然后通过[1,13,1,1]</code> 的 <code>max-pooling</code> 操作，得到的矩阵为<br><code>4*29</code>；</p><p>（4）第三次卷积核大小 <code>4*4</code>，得到 <code>1*26</code> 的矩阵，然后通过 <code>[1,12,1,1]</code> 的 <code>max-pooling</code> 操作，得到的矩阵为<br><code>1*26</code>；</p><p>（5）第四次卷积核大小 <code>5*5</code>，得到 <code>1*22</code> 的矩阵，然后通过 <code>[1,11,1,1]</code> 的 <code>max-pooling</code> 操作，得到的矩阵为<br><code>1*22</code>；</p><p>（6）最后通过 Dropout 和全连接层，<code>len(window_sizes) * filter_num =32</code>，得到 <code>1*32</code>的矩阵。</p><p><strong>5.</strong> 电影各层做一个全连接层。</p><p>将上面几步生成的特征向量，通过2个全连接层连接在一起，第一个全连接层是电影 ID 特征和电影类型特征先全连接，之后再和 CNN<br>生成的电影名称特征全连接，生成最后的特征集。</p><p>具体流程如下：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422868421.png" alt="enter description here"></p><p><strong>6.</strong> 完整的基于 CNN 的电影推荐流程。</p><p>把以上实现的模块组合成整个算法，将网络模型作为回归问题进行训练，得到训练好的用户特征矩阵和电影特征矩阵进行推荐。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422874275.png" alt="enter description here"></p><h3 id="基于-CNN-的电影推荐系统代码调参过程"><a href="#基于-CNN-的电影推荐系统代码调参过程" class="headerlink" title="基于 CNN 的电影推荐系统代码调参过程"></a>基于 CNN 的电影推荐系统代码调参过程</h3><p>在训练过程中，我们需要对算法预先设置一些超参数，这里给出的最终的设置结果：</p><pre><code class="makefile"># 设置迭代次数
num_epochs = 5
# 设置BatchSize大小
batch_size = 256
#设置dropout保留比例
dropout_keep = 0.5
# 设置学习率
learning_rate = 0.0001
# 设置每轮显示的batches大小
show_every_n_batches = 20</code></pre><p>首先对数据集进行划分，按照 4:1 的比例划分为训练集和测试集，下面给出的是算法模型最终训练集合测试集使用的划分结果：</p><pre><code class="nix">#将数据集分成训练集和测试集，随机种子不固定
train_X,test_X, train_y, test_y = train_test_split(features,  
                                             targets_values,  
                                             test_size = 0.3,  
                                             random_state = 0) </code></pre><p>接下来是具体模型训练过程。训练过程，要不断调参，根据经验调参粒度可以选择从粗到细分阶段进行。</p><p>调参过程对比：</p><p>（1）第一步，先固定，<code>learning_rate=0.01</code> 和 <code>num_epochs=10</code>，测试 <code>batch_size=128</code> 对迭代时间和Loss 的影响；</p><p>（2）第二步，先固定，<code>learning_rate=0.01</code> 和 <code>num_epochs=10</code>，测试 <code>batch_size=256</code> 对迭代时间和Loss 的影响；</p><p>（3）第三步，先固定，<code>learning_rate=0.01</code> 和 <code>num_epochs=10</code>，测试 <code>batch_size=512</code> 对迭代时间和Loss 的影响；</p><p>（4）第四步，先固定，<code>learning_rate=0.01</code> 和 <code>num_epochs=5</code>，测试 <code>batch_size=128</code> 对迭代时间和Loss 的影响；</p><p>（5）第五步，先固定，<code>learning_rate=0.01</code> 和 <code>num_epochs=5</code>，测试 <code>batch_size=256</code> 对迭代时间和Loss 的影响；</p><p>（6）第六步，先固定，<code>learning_rate=0.01</code> 和 <code>num_epochs=5</code>，测试 <code>batch_size=512</code> 对迭代时间和Loss 的影响；</p><p>（7）第七步，先固定，<code>batch_size=256</code> 和 <code>num_epochs=5</code>，测试 <code>learning_rate=0.001</code> 对 Loss的影响；</p><p>（8）第八步，先固定，<code>batch_size=256</code> 和 <code>num_epochs=5</code>，测试 <code>learning_rate=0.0005</code> 对 Loss的影响；</p><p>（9）第九步，先固定，<code>batch_size=256</code> 和 <code>num_epochs=5</code>，测试 <code>learning_rate=0.0001</code> 对 Loss的影响；</p><p>（10）第十步，先固定，<code>batch_size=256</code> 和 <code>num_epochs=5</code>，测试 <code>learning_rate=0.00005</code> 对Loss 的影响。</p><p>得到的调参结果对比表如下：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574422924338.png" alt="enter description here"></p><p>通过上面（1）-（6）步调参比较，在 <code>learning_rate</code>、<code>batch_size</code> 相同的情况下，<code>num_epochs</code>对于训练时间影响较大；而在 <code>learning_rate</code>、<code>num_epochs</code> 相同情况下，<code>batch_size</code> 对 Loss的影响较大，<code>batch_size</code> 选择512，Loss 有抖动情况，权衡之下，最终确定后续调参固定采用<code>batch_size=256</code>、<code>num_epochs=5</code> 的超参数值，后续（7）-（10）步，随着 <code>learning_rate</code> 逐渐减小，发现Loss 是先逐渐减小，而在 <code>learning_rate=0.00005</code> 时反而增大，最终选择出学习率为 <code>learning_rate=0.0001</code>的超参数值。</p><h3 id="基于-CNN-的电影推荐系统电影推荐"><a href="#基于-CNN-的电影推荐系统电影推荐" class="headerlink" title="基于 CNN 的电影推荐系统电影推荐"></a>基于 CNN 的电影推荐系统电影推荐</h3><p>在上面，完成模型训练验证之后，实际来进行推荐电影，这里使用生产的用户特征矩阵和电影特征矩阵做电影推荐，主要有三种方式的推荐。</p><p><strong>1.</strong> 推荐同类型的电影。</p><p>思路是：计算当前看的电影特征向量与整个电影特征矩阵的余弦相似度，取相似度最大的 <code>top_k</code> 个，这里加了些随机选择在里面，保证每次的推荐稍稍有些不同。</p><pre><code class="vim">
def recommend_same_type_movie(movie_id_val, top_k = 20):

    loaded_graph = tf.Graph()  #
    with tf.Session(graph=loaded_graph) as sess:  #
        # Load saved model
        loader = tf.train.import_meta_graph(load_dir + &#39;.meta&#39;)
        loader.restore(sess, load_dir)

        norm_movie_matrics = tf.sqrt(tf.reduce_sum(tf.square(movie_matrics), 1, keep_dims=True))
        normalized_movie_matrics = movie_matrics / norm_movie_matrics

        #推荐同类型的电影
        probs_embeddings = (movie_matrics[movieid2idx[movie_id_val]]).reshape([1, 200])
        probs_similarity = tf.matmul(probs_embeddings, tf.transpose(normalized_movie_matrics))
        sim = (probs_similarity.eval())
        print(&quot;您看的电影是：{}&quot;.format(movies_orig[movieid2idx[movie_id_val]]))
        print(&quot;以下是给您的推荐：&quot;)
        p = np.squeeze(sim)
        p[np.argsort(p)[:-top_k]] = 0
        p = p / np.sum(p)
        results = set()
        while len(results) != 5:
            c = np.random.choice(3883, 1, p=p)[0]
            results.add(c)
        for val in (results):
            print(val)
            print(movies_orig[val])
        return result</code></pre><p><strong>2.</strong> 推荐您喜欢的电影。</p><p>思路是：使用用户特征向量与电影特征矩阵计算所有电影的评分，取评分最高的 <code>top_k</code> 个，同样加了些随机选择部分。</p><pre><code class="vim">def recommend_your_favorite_movie(user_id_val, top_k = 10):

    loaded_graph = tf.Graph()  #
    with tf.Session(graph=loaded_graph) as sess:  #
        # Load saved model
        loader = tf.train.import_meta_graph(load_dir + &#39;.meta&#39;)
        loader.restore(sess, load_dir)

        #推荐您喜欢的电影
        probs_embeddings = (users_matrics[user_id_val-1]).reshape([1, 200])
        probs_similarity = tf.matmul(probs_embeddings, tf.transpose(movie_matrics))
        sim = (probs_similarity.eval())

        print(&quot;以下是给您的推荐：&quot;)
        p = np.squeeze(sim)
        p[np.argsort(p)[:-top_k]] = 0
        p = p / np.sum(p)
        results = set()
        while len(results) != 5:
            c = np.random.choice(3883, 1, p=p)[0]
            results.add(c)
        for val in (results):
            print(val)
            print(movies_orig[val])

        return results</code></pre><p><strong>3.</strong> 看过这个电影的人还看了（喜欢）哪些电影。</p><p>（1）首先选出喜欢某个电影的 <code>top_k</code> 个人，得到这几个人的用户特征向量；</p><p>（2）然后计算这几个人对所有电影的评分 ；</p><p>（3）选择每个人评分最高的电影作为推荐；</p><p>（4）同样加入了随机选择。</p><pre><code class="vim">def recommend_other_favorite_movie(movie_id_val, top_k = 20):
    loaded_graph = tf.Graph()  #
    with tf.Session(graph=loaded_graph) as sess:  #
        # Load saved model
        loader = tf.train.import_meta_graph(load_dir + &#39;.meta&#39;)
        loader.restore(sess, load_dir)
        probs_movie_embeddings = (movie_matrics[movieid2idx[movie_id_val]]).reshape([1, 200])
        probs_user_favorite_similarity = tf.matmul(probs_movie_embeddings, tf.transpose(users_matrics))
        favorite_user_id = np.argsort(probs_user_favorite_similarity.eval())[0][-top_k:]

        print(&quot;您看的电影是：{}&quot;.format(movies_orig[movieid2idx[movie_id_val]]))

        print(&quot;喜欢看这个电影的人是：{}&quot;.format(users_orig[favorite_user_id-1]))
        probs_users_embeddings = (users_matrics[favorite_user_id-1]).reshape([-1, 200])
        probs_similarity = tf.matmul(probs_users_embeddings, tf.transpose(movie_matrics))
        sim = (probs_similarity.eval())
        p = np.argmax(sim, 1)
        print(&quot;喜欢看这个电影的人还喜欢看：&quot;)
        results = set()
        while len(results) != 5:
            c = p[random.randrange(top_k)]
            results.add(c)
        for val in (results):
            print(val)
            print(movies_orig[val])
        return results</code></pre><h1 id="基于-CNN-的电影推荐系统不足"><a href="#基于-CNN-的电影推荐系统不足" class="headerlink" title="基于 CNN 的电影推荐系统不足"></a>基于 CNN 的电影推荐系统不足</h1><p>这里讨论一下基于上述方法所带来的不足：</p><ol><li><p>由于一个新的用户在刚开始的时候并没有任何行为记录，所以系统会出现冷启动的问题；</p></li><li><p>由于神经网络是一个黑盒子过程，我们并不清楚在反向传播的过程中的具体细节，也不知道每一个卷积层抽取的特征细节，所以此算法缺乏一定的可解释性；</p></li><li><p>一般来说，在工业界，用户的数据量是海量的，而卷积神经网络又要耗费大量的计算资源，所以进行集群计算是非常重要的。但是由于本课程所做实验环境有限，还是在单机上运行，所以后期可以考虑在服务器集群上全量跑数据，这样获得的结果也更准确。</p></li></ol><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>上面通过 <a href="https://github.com/chengstone/movie_recommender" target="_blank" rel="noopener">Github</a> 上一个开源的项目，梳理了CNN 在文本推荐上的应用，并通过模型训练调参，给出一般的模型调参思路，最后建议大家自己把源码下载下来跑跑模型，效果更好。</p></article><div class="post-donate"><div id="donate_board" class="donate_bar center"><a id="btn_donate" class="btn_donate" href="javascript:;" title="打赏"></a> <span class="donate_txt">↑<br> 欢迎投食,求鼓励，求支持！</span><br></div><div id="donate_guide" class="donate_bar center hidden"> <img src="/images/alipay.png" alt="支付宝打赏"> <img src="/images/wechatpay.png" alt="微信打赏"></div><script type="text/javascript">document.getElementById("btn_donate").onclick=function(){$("#donate_board").addClass("hidden"),$("#donate_guide").removeClass("hidden")}</script></div><div class="nexmoe-post-copyright"><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i> <strong>本文作者：</strong>OneJane<br> <strong>本文链接：</strong><a href="https://onejane.github.io/2019/11/22/10.基于CNN的电影推荐系统/" title="https://onejane.github.io/2019/11/22/10.基于CNN的电影推荐系统/" target="_blank" rel="noopener">https://onejane.github.io/2019/11/22/10.基于CNN的电影推荐系统/</a><br> <strong>版权声明：</strong>本文采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh" target="_blank">CC BY-NC-SA 3.0 CN</a> 协议进行许可</div><section class="nexmoe-comment"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.css"><div id="gitalk"></div><script src="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"e677e59382e1c7a468fd",clientSecret:"717d041bc4ab749f069314862232cfb6ec8adc15",id:decodeURI(window.location.pathname),repo:"onejane.github.io",owner:"onejane",admin:"onejane"});gitalk.render("gitalk")</script></section></div></div></div><script src="https://cdn.jsdelivr.net/npm/mdui@0.4.3/dist/js/mdui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/smoothscroll-for-websites@1.4.9/SmoothScroll.min.js"></script><script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.15.8/build/highlight.min.js"></script><script>hljs.initHighlightingOnLoad()</script><script src="/js/app.js?v=1575583208112"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@5.1.0/lazysizes.min.js"></script><div hidden><script type="text/javascript" src="https://js.users.51.la/20279757.js"></script></div></body><script src="https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js"></script></html>