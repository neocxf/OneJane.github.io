<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><title>基于情感词典的文本情感分析（12） - OneJane</title><meta charset="UTF-8"><meta name="description" content="微服务,高可用,高并发,人工智能"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="msvalidate.01" content="396E9693347B4D18AAE96D9E75B9B686"><link rel="shortcut icon" href="/images/a.ico" type="image/png"><meta name="description" content="目前情感分析在中文自然语言处理中比较火热，很多场景下，我们都需要用到情感分析。比如，做金融产品量化交易，需要根据爬取的舆论数据来分析政策和舆论对股市或者基金期货的态度；电商交易，根据买家的评论数据，来分析商品的预售率等等。"><meta name="keywords" content="cnn,snownlp"><meta property="og:type" content="article"><meta property="og:title" content="基于情感词典的文本情感分析（12）"><meta property="og:url" content="https://onejane.github.io/2019/11/22/12.基于情感词典的文本情感分析/index.html"><meta property="og:site_name" content="OneJane"><meta property="og:description" content="目前情感分析在中文自然语言处理中比较火热，很多场景下，我们都需要用到情感分析。比如，做金融产品量化交易，需要根据爬取的舆论数据来分析政策和舆论对股市或者基金期货的态度；电商交易，根据买家的评论数据，来分析商品的预售率等等。"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423560104.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423727448.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423816939.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423834599.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423858015.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423962832.png"><meta property="og:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423967077.png"><meta property="og:updated_time" content="2019-11-22T13:25:12.545Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="基于情感词典的文本情感分析（12）"><meta name="twitter:description" content="目前情感分析在中文自然语言处理中比较火热，很多场景下，我们都需要用到情感分析。比如，做金融产品量化交易，需要根据爬取的舆论数据来分析政策和舆论对股市或者基金期货的态度；电商交易，根据买家的评论数据，来分析商品的预售率等等。"><meta name="twitter:image" content="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423560104.png"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdui@0.4.3/dist/css/mdui.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.15.8/styles/atom-one-dark.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1038733_0xvrvpg9c0r.css"><link rel="stylesheet" href="/css/style.css?v=1578434407846"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js"></script></head><body class="mdui-drawer-body-left"><div id="nexmoe-background"><div class="nexmoe-bg" style="background-image:url(https://www.github.com/OneJane/blog/raw/master/小书匠/1566388885395.png)"></div><div class="mdui-appbar mdui-shadow-0"><div class="mdui-toolbar"> <a mdui-drawer="{target: '#drawer', swipe: true}" title="menu" class="mdui-btn mdui-btn-icon"><i class="mdui-icon material-icons">menu</i></a><div class="mdui-toolbar-spacer"></div> <a href="/" title="OneJane" class="mdui-btn mdui-btn-icon"><img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388846021.png"></a></div></div></div><div id="nexmoe-header"><div class="nexmoe-drawer mdui-drawer" id="drawer"><div class="nexmoe-avatar mdui-ripple"> <a href="/" title="OneJane"><img src="https://www.github.com/OneJane/blog/raw/master/小书匠/1566388846021.png" alt="OneJane"></a></div><div class="nexmoe-count"><div><span>文章</span>69</div><div><span>标签</span>83</div><div><span>分类</span>12</div></div><ul class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}"><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/" title="回到首页"><i class="mdui-list-item-icon nexmoefont icon-home"></i><div class="mdui-list-item-content"> 回到首页</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/about.html" title="关于博客"><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i><div class="mdui-list-item-content"> 关于博客</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/py.html" title="我的朋友"><i class="mdui-list-item-icon nexmoefont icon-unorderedlist"></i><div class="mdui-list-item-content"> 我的朋友</div></a></ul><aside id="nexmoe-sidebar"><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">社交按钮</h3><div class="nexmoe-widget nexmoe-social"><a class="mdui-ripple" href="https://github.com/OneJane" target="_blank" mdui-tooltip="{content: 'GitHub'}" style="color:#191717;background-color:rgba(25,23,23,.15)"><i class="nexmoefont icon-github"></i></a></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">文章分类</h3><div class="nexmoe-widget"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/人工智能/">人工智能</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/定时器/">定时器</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/持续集成/">持续集成</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/注册中心/">注册中心</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/测试/">测试</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/系统/">系统</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/自然语言处理/">自然语言处理</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目实战/">项目实战</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/高可用/">高可用</a><span class="category-list-count">4</span></li></ul></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">标签云</h3><div class="nexmoe-widget tagcloud"> <a href="/tags/Gensim/" style="font-size:10px">Gensim</a> <a href="/tags/Hanlp/" style="font-size:10px">Hanlp</a> <a href="/tags/NLTK/" style="font-size:10px">NLTK</a> <a href="/tags/OpenCV/" style="font-size:12.86px">OpenCV</a> <a href="/tags/Stanford-NLP/" style="font-size:10px">Stanford NLP</a> <a href="/tags/Tensorflow/" style="font-size:15.71px">Tensorflow</a> <a href="/tags/ant-design/" style="font-size:10px">ant design</a> <a href="/tags/ant-design-pro/" style="font-size:11.43px">ant design pro</a> <a href="/tags/auc/" style="font-size:10px">auc</a> <a href="/tags/bottle/" style="font-size:10px">bottle</a> <a href="/tags/chatterbot/" style="font-size:10px">chatterbot</a> <a href="/tags/cnn/" style="font-size:12.86px">cnn</a> <a href="/tags/crf/" style="font-size:12.86px">crf</a> <a href="/tags/doc2vec/" style="font-size:10px">doc2vec</a> <a href="/tags/docker/" style="font-size:17.14px">docker</a> <a href="/tags/dubbo/" style="font-size:11.43px">dubbo</a> <a href="/tags/elasticsearch/" style="font-size:10px">elasticsearch</a> <a href="/tags/elastisearch/" style="font-size:10px">elastisearch</a> <a href="/tags/email/" style="font-size:10px">email</a> <a href="/tags/es6/" style="font-size:10px">es6</a> <a href="/tags/feign/" style="font-size:10px">feign</a> <a href="/tags/flask/" style="font-size:11.43px">flask</a> <a href="/tags/folium/" style="font-size:10px">folium</a> <a href="/tags/freemarker/" style="font-size:10px">freemarker</a> <a href="/tags/function/" style="font-size:10px">function</a> <a href="/tags/gateway/" style="font-size:10px">gateway</a> <a href="/tags/gensim/" style="font-size:11.43px">gensim</a> <a href="/tags/gitlab/" style="font-size:11.43px">gitlab</a> <a href="/tags/gru/" style="font-size:11.43px">gru</a> <a href="/tags/hanlp/" style="font-size:11.43px">hanlp</a> <a href="/tags/haproxy/" style="font-size:10px">haproxy</a> <a href="/tags/hmm/" style="font-size:10px">hmm</a> <a href="/tags/jenkins/" style="font-size:11.43px">jenkins</a> <a href="/tags/jieba/" style="font-size:15.71px">jieba</a> <a href="/tags/jmeter/" style="font-size:10px">jmeter</a> <a href="/tags/keepalived/" style="font-size:10px">keepalived</a> <a href="/tags/lda/" style="font-size:11.43px">lda</a> <a href="/tags/linux/" style="font-size:10px">linux</a> <a href="/tags/lstm/" style="font-size:12.86px">lstm</a> <a href="/tags/maven/" style="font-size:11.43px">maven</a> <a href="/tags/multi-druid/" style="font-size:10px">multi druid</a> <a href="/tags/mybatis/" style="font-size:10px">mybatis</a> <a href="/tags/mybatisplus/" style="font-size:10px">mybatisplus</a> <a href="/tags/mysql/" style="font-size:10px">mysql</a> <a href="/tags/n-gram/" style="font-size:10px">n-gram</a> <a href="/tags/nacos/" style="font-size:11.43px">nacos</a> <a href="/tags/neo4j/" style="font-size:11.43px">neo4j</a> <a href="/tags/nexmoe/" style="font-size:10px">nexmoe</a> <a href="/tags/nlp/" style="font-size:20px">nlp</a> <a href="/tags/numpy/" style="font-size:10px">numpy</a> <a href="/tags/partition/" style="font-size:10px">partition</a> <a href="/tags/procedure/" style="font-size:10px">procedure</a> <a href="/tags/pxc/" style="font-size:10px">pxc</a> <a href="/tags/pyhanlp/" style="font-size:11.43px">pyhanlp</a> <a href="/tags/python/" style="font-size:10px">python</a> <a href="/tags/rabbitmq/" style="font-size:10px">rabbitmq</a> <a href="/tags/react/" style="font-size:11.43px">react</a> <a href="/tags/redis/" style="font-size:11.43px">redis</a> <a href="/tags/redis-cluster/" style="font-size:10px">redis-cluster</a> <a href="/tags/replication/" style="font-size:11.43px">replication</a> <a href="/tags/rnn/" style="font-size:10px">rnn</a> <a href="/tags/rocketmq/" style="font-size:11.43px">rocketmq</a> <a href="/tags/scrapy/" style="font-size:12.86px">scrapy</a> <a href="/tags/selenium/" style="font-size:12.86px">selenium</a> <a href="/tags/sentinel/" style="font-size:14.29px">sentinel</a> <a href="/tags/seq2seq/" style="font-size:10px">seq2seq</a> <a href="/tags/session/" style="font-size:10px">session</a> <a href="/tags/sklearn/" style="font-size:10px">sklearn</a> <a href="/tags/skywalking/" style="font-size:11.43px">skywalking</a> <a href="/tags/snownlp/" style="font-size:10px">snownlp</a> <a href="/tags/spring-cloud-alibaba/" style="font-size:18.57px">spring cloud alibaba</a> <a href="/tags/springboot/" style="font-size:14.29px">springboot</a> <a href="/tags/svm/" style="font-size:10px">svm</a> <a href="/tags/swagger/" style="font-size:10px">swagger</a> <a href="/tags/textrank/" style="font-size:10px">textrank</a> <a href="/tags/tf-idf/" style="font-size:12.86px">tf-idf</a> <a href="/tags/tk-mybatis/" style="font-size:10px">tk mybatis</a> <a href="/tags/umi/" style="font-size:10px">umi</a> <a href="/tags/validate/" style="font-size:10px">validate</a> <a href="/tags/word2vec/" style="font-size:10px">word2vec</a> <a href="/tags/wordcloud/" style="font-size:10px">wordcloud</a> <a href="/tags/xxl-job/" style="font-size:11.43px">xxl-job</a> <a href="/tags/zookeeper/" style="font-size:10px">zookeeper</a></div></div><div class="nexmoe-widget-wrap"><h3 class="nexmoe-widget-title">文章归档</h3><div class="nexmoe-widget"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li></ul></div></div></aside><div class="nexmoe-copyright"> &copy; 2020 OneJane</div></div></div><div id="nexmoe-content"><div class="nexmoe-primary"><div class="nexmoe-post"><div class="nexmoe-post-cover"> <img src="https://www.github.com/OneJane/blog/raw/master/小书匠/v2-edc0bbcf3ff79a314c349eba2e34da60_hd.jpg"><h1>基于情感词典的文本情感分析（12）</h1></div><div class="nexmoe-post-meta"><a><i class="nexmoefont icon-calendar-fill"></i> 2019年11月22日</a><a><i class="nexmoefont icon-areachart"></i> 3.6k 字</a><a><i class="nexmoefont icon-time-circle-fill"></i> 大概 16 分钟</a> <a class="nexmoefont icon-appstore-fill -link" href="/categories/自然语言处理/">自然语言处理</a> <a class="nexmoefont icon-tag-fill -link" href="/tags/cnn/">cnn</a> <a class="nexmoefont icon-tag-fill -link" href="/tags/snownlp/">snownlp</a></div><article><p>目前情感分析在中文自然语言处理中比较火热，很多场景下，我们都需要用到情感分析。比如，做金融产品量化交易，需要根据爬取的舆论数据来分析政策和舆论对股市或者基金期货的态度；电商交易，根据买家的评论数据，来分析商品的预售率等等。</p><a id="more"></a><p>下面我们通过以下几点来介绍中文自然语言处理情感分析：</p><ol><li>中文情感分析方法简介；</li><li>SnowNLP 快速进行评论数据情感分析；</li><li>基于标注好的情感词典来计算情感值；</li><li>pytreebank 绘制情感树；</li><li>股吧数据情感分类。</li></ol><h1 id="中文情感分析方法简介"><a href="#中文情感分析方法简介" class="headerlink" title="中文情感分析方法简介"></a>中文情感分析方法简介</h1><p>情感倾向可认为是主体对某一客体主观存在的内心喜恶，内在评价的一种倾向。它由两个方面来衡量：一个情感倾向方向，一个是情感倾向度。</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423560104.png" alt="enter description here"></p><p>目前，情感倾向分析的方法主要分为两类：一种是基于情感词典的方法；一种是基于机器学习的方法，如基于大规模语料库的机器学习。前者需要用到标注好的情感词典；后者则需要大量的人工标注的语料作为训练集，通过提取文本特征，构建分类器来实现情感的分类。</p><p>文本情感分析的分析粒度可以是词语、句子、段落或篇章。</p><p>段落篇章级情感分析主要是针对某个主题或事件进行情感倾向判断，一般需要构建对应事件的情感词典，如电影评论的分析，需要构建电影行业自己的情感词典，这样效果会比通用情感词典更好；也可以通过人工标注大量电影评论来构建分类器。句子级的情感分析大多通过计算句子里包含的所有情感词的值来得到。</p><p>篇章级的情感分析，也可以通过聚合篇章中所有的句子的情感倾向来计算得出。因此，针对句子级的情感倾向分析，既能解决短文本的情感分析，同时也是篇章级文本情感分析的基础。</p><p>中文情感分析的一些难点，比如句子是由词语根据一定的语言规则构成的，应该把句子中词语的依存关系纳入到句子情感的计算过程中去，不同的依存关系，进行情感倾向计算是不一样的。文档的情感，根据句子对文档的重要程度赋予不同权重，调整其对文档情感的贡献程度等。</p><h1 id="SnowNLP-快速进行评论数据情感分析"><a href="#SnowNLP-快速进行评论数据情感分析" class="headerlink" title="SnowNLP 快速进行评论数据情感分析"></a>SnowNLP 快速进行评论数据情感分析</h1><p>如果有人问，有没有比较快速简单的方法能判断一句话的情感倾向，那么 SnowNLP 库就是答案。</p><p>SnowNLP 主要可以进行中文分词、词性标注、情感分析、文本分类、转换拼音、繁体转简体、提取文本关键词、提取摘要、分割句子、文本相似等。</p><p>需要注意的是，用 SnowNLP<br>进行情感分析，官网指出进行电商评论的准确率较高，其实是因为它的语料库主要是电商评论数据，但是可以自己构建相关领域语料库，替换单一的电商评论语料，准确率也挺不错的。</p><p><strong>1.</strong> SnowNLP 安装。</p><p>（1） 使用 pip 安装：</p><pre><code class="lsl">pip install snownlp==0.11.1</code></pre><p>（2）使用 Github 源码安装。</p><p>首先，下载 SnowNLP 的 <a href="https://github.com/isnowfy/snownlp" target="_blank" rel="noopener">Github</a>源码并解压，在解压目录，通过下面命令安装：</p><pre><code class="vim">python  setup.py install </code></pre><p>以上方式，二选一安装完成之后，就可以引入 SnowNLP 库使用了。</p><pre><code class="javascript">from snownlp import SnowNLP</code></pre><p><strong>2.</strong> 评论语料获取情感值。</p><p>首先，SnowNLP 对情感的测试值为0到1，值越大，说明情感倾向越积极。下面我们通过 SnowNLP 测试在京东上找的好评、中评、差评的结果。</p><p>首先，引入 SnowNLP 库：</p><pre><code class="javascript">from snownlp import SnowNLP</code></pre><p>（1） 测试一条京东的好评数据：</p><pre><code class="python">SnowNLP(u&#39;本本已收到，体验还是很好，功能方面我不了解，只看外观还是很不错很薄，很轻，也有质感。&#39;).sentiments</code></pre><p>得到的情感值很高，说明买家对商品比较认可，情感值为：</p><blockquote><p>0.999950702449061</p></blockquote><p>（2）测试一条京东的中评数据：</p><pre><code class="python">SnowNLP(u&#39;屏幕分辨率一般，送了个极丑的鼠标。&#39;).sentiments</code></pre><p>得到的情感值一般，说明买家对商品看法一般，甚至不喜欢，情感值为：</p><blockquote><p>0.03251402883400323</p></blockquote><p>（3）测试一条京东的差评数据：</p><pre><code class="python">SnowNLP(u&#39;很差的一次购物体验，细节做得极差了，还有发热有点严重啊，散热不行，用起来就是烫得厉害，很垃圾！！！&#39;).sentiments</code></pre><p> 得到的情感值一般，说明买家对商品不认可，存在退货嫌疑，情感值为：</p><blockquote><p>0.0036849517156107847</p></blockquote><p>以上就完成了简单快速的情感值计算，对评论数据是不是很好用呀！！！</p><p>使用 SnowNLP 来计算情感值，官方推荐的是电商评论数据计算准确度比较高，难道非评论数据就不能使用 SnowNLP 来计算情感值了吗？当然不是，虽然SnowNLP 默认提供的模型是用评论数据训练的，但是它还支持我们根据现有数据训练自己的模型。</p><p>首先我们来看看自定义训练模型的 <strong>源码 Sentiment 类</strong> ，代码定义如下：</p><pre><code class="ruby">class Sentiment(object):

    def __init__(self):
        self.classifier = Bayes()

    def save(self, fname, iszip=True):
        self.classifier.save(fname, iszip)

    def load(self, fname=data_path, iszip=True):
        self.classifier.load(fname, iszip)

    def handle(self, doc):
        words = seg.seg(doc)
        words = normal.filter_stop(words)
        return words

    def train(self, neg_docs, pos_docs):
        data = []
        for sent in neg_docs:
            data.append([self.handle(sent), &#39;neg&#39;])
        for sent in pos_docs:
            data.append([self.handle(sent), &#39;pos&#39;])
        self.classifier.train(data)

    def classify(self, sent):
        ret, prob = self.classifier.classify(self.handle(sent))
        if ret == &#39;pos&#39;:
            return prob
        return 1-prob</code></pre><p>通过源代码，我们可以看到，可以使用 train方法训练数据，并使用 save 方法和 load 方法保存与加载模型。下面训练自己的模型，训练集<br>pos.txt 和 neg.txt 分别表示积极和消极情感语句，两个 TXT 文本中每行表示一句语料。</p><p>下面代码进行自定义模型训练和保存：</p><pre><code class="sml">from snownlp import sentiment
sentiment.train(&#39;neg.txt&#39;, &#39;pos.txt&#39;)
sentiment.save(&#39;sentiment.marshal&#39;)</code></pre><h1 id="基于标注好的情感词典来计算情感值"><a href="#基于标注好的情感词典来计算情感值" class="headerlink" title="基于标注好的情感词典来计算情感值"></a>基于标注好的情感词典来计算情感值</h1><p>这里我们使用一个行业标准的情感词典——玻森情感词典，来自定义计算一句话、或者一段文字的情感值。</p><p>整个过程如下：</p><ol><li>加载玻森情感词典；</li><li>jieba 分词；</li><li>获取句子得分。</li></ol><p>首先引入包：</p><pre><code class="haskell">import pandas as pd
import jieba</code></pre><p>接下来加载情感词典：</p><pre><code class="ini">df = pd.read_table(&quot;bosonnlp//BosonNLP_sentiment_score.txt&quot;,sep= &quot; &quot;,names=[&#39;key&#39;,&#39;score&#39;])</code></pre><p>查看一下情感词典前5行：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423727448.png" alt="enter description here"></p><p>将词 key 和对应得分 score 转成2个 list 列表，目的是找到词 key 的时候，能对应获取到 score 值：</p><pre><code class="stylus">key = df[&#39;key&#39;].values.tolist()
score = df[&#39;score&#39;].values.tolist()</code></pre><p>定义分词和统计得分函数：</p><pre><code class="python">    def getscore(line):
        segs = jieba.lcut(line)  #分词
        score_list  = [score[key.index(x)] for x in segs if(x in key)]
        return  sum(score_list)  #计算得分</code></pre><p>最后来进行结果测试：</p><pre><code class="lisp">    line = &quot;今天天气很好，我很开心&quot;
    print(round(getscore(line),2))

    line = &quot;今天下雨，心情也受到影响。&quot;
    print(round(getscore(line),2))</code></pre><p>获得的情感得分保留2位小数：</p><blockquote><p>5.26</p></blockquote><blockquote><p>-0.96</p></blockquote><h3 id="pytreebank-绘制情感树"><a href="#pytreebank-绘制情感树" class="headerlink" title="pytreebank 绘制情感树"></a>pytreebank 绘制情感树</h3><p><strong>1.</strong> 安装 pytreebank。</p><p>在 Github 上下载 <a href="https://github.com/JonathanRaiman/pytreebank" target="_blank" rel="noopener">pytreebank源码</a>，解压之后，进入解压目录命令行，执行命令：</p><pre><code class="vim">python setup.py install</code></pre><p>最后通过引入命令，判断是否安装成功：</p><pre><code class="haskell">import pytreebank</code></pre><p>提示，如果在 Windows 下安装之后，报错误：</p><pre><code class="vhdl">UnicodeDecodeError: &#39;gbk&#39; codec can&#39;t decode byte 0x92 in position 24783: illegal multibyte sequence </code></pre><p>这是由于编码问题引起的，可以在安装目录下报错的文件中报错的代码地方加个 <code>encoding=&#39;utf-8&#39;</code> 编码：</p><pre><code class="lisp">import_tag( &quot;script&quot;, contents=format_replacements(open(scriptname,encoding=&#39;utf-8&#39;).read(), replacements), type=&quot;text/javascript&quot; )</code></pre><p><strong>2.</strong> 绘制情感树。<br>首先引入 pytreebank 包：</p><pre><code class="haskell">import pytreebank</code></pre><p>然后，加载用来可视化的 JavaScript 和 CSS 脚本：</p><pre><code class="stylus">pytreebank.LabeledTree.inject_visualization_javascript()</code></pre><p>绘制情感树，把句子首先进行组合再绘制图形：</p><pre><code class="lsl">    line = &#39;(4 (0 你) (3 (2 是) (3 (3 (3 谁) (2 的)) (2 谁))))&#39;
    pytreebank.create_tree_from_string(line).display()</code></pre><p>得到的情感树如下：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423816939.png" alt="enter description here"></p><h3 id="股吧数据情感分类"><a href="#股吧数据情感分类" class="headerlink" title="股吧数据情感分类"></a>股吧数据情感分类</h3><p>但在7月15日之前，随着中美贸易战不断升级，中兴股价又上演了一场“跌跌不休”的惨状，我以中美贸易战背景下中兴通讯在股吧解禁前一段时间的评论数据，来进行情感数据人工打标签和分类。其中，把消极、中性 、积极分别用0、1、2来表示。</p><p>整个文本分类流程主要包括以下6个步骤：</p><ul><li>中文语料；</li><li>分词；</li><li>复杂规则；</li><li>特征向量；</li><li>算法建模；</li><li>情感分析。</li></ul><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423834599.png" alt="enter description here"></p><p>本次分类算法采用 CNN，首先引入需要的包：</p><pre><code class="haskell">import pandas as pd
import numpy as np
import jieba
import random
import keras
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.layers import Embedding
from keras.layers import Conv1D, GlobalMaxPooling1D
from keras.datasets import imdb
from keras.models import model_from_json
from keras.utils import np_utils
import matplotlib.pyplot as plt</code></pre><p>继续引入停用词和语料文件：</p><pre><code class="nix">    dir = &quot;D://ProgramData//PythonWorkSpace//chat//chat8//&quot;
    stopwords=pd.read_csv(dir +&quot;stopwords.txt&quot;,index_col=False,quoting=3,sep=&quot;\t&quot;,names=[&#39;stopword&#39;], encoding=&#39;utf-8&#39;)
    stopwords=stopwords[&#39;stopword&#39;].values
    df_data1 = pd.read_csv(dir+&quot;data1.csv&quot;,encoding=&#39;utf-8&#39;)
    df_data1.head()</code></pre><p>下图展示数据的前5行：<br><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423858015.png" alt="enter description here"><br>接着进行数据预处理，把消极、中性、积极分别为0、1、2的预料分别拿出来：</p><pre><code class="prolog">    #把内容有缺失值的删除
    df_data1.dropna(inplace=True)
    #抽取文本数据和标签
    data_1 = df_data1.loc[:,[&#39;content&#39;,&#39;label&#39;]]
    #把消极  中性  积极分别为0、1、2的预料分别拿出来
    data_label_0 = data_1.loc[data_1[&#39;label&#39;] ==0,:]
    data_label_1 = data_1.loc[data_1[&#39;label&#39;] ==1,:]
    data_label_2 = data_1.loc[data_1[&#39;label&#39;] ==2,:]</code></pre><p>接下来，定义中文分词函数：</p><pre><code class="livecodeserver">#定义分词函数
def preprocess_text(content_lines, sentences, category):
    for line in content_lines:
        try:
            segs=jieba.lcut(line)
            segs = filter(lambda x:len(x)&gt;1, segs)
            segs = [v for v in segs if not str(v).isdigit()]#去数字
            segs = list(filter(lambda x:x.strip(), segs)) #去左右空格
            segs = filter(lambda x:x not in stopwords, segs)
            temp = &quot; &quot;.join(segs)
            if(len(temp)&gt;1):
                sentences.append((temp, category))
        except Exception:
            print(line)
            continue </code></pre><p>生成训练的分词数据，并进行打散，使其分布均匀：</p><pre><code class="stylus">#获取数据
data_label_0_content = data_label_0[&#39;content&#39;].values.tolist()
data_label_1_content = data_label_1[&#39;content&#39;].values.tolist()
data_label_2_content = data_label_2[&#39;content&#39;].values.tolist()
#生成训练数据
sentences = []
preprocess_text(data_label_0_content, sentences, 0)
preprocess_text(data_label_1_content, sentences, 1)
preprocess_text(data_label_2_content, sentences,2)
#我们打乱一下顺序，生成更可靠的训练集
random.shuffle(sentences)</code></pre><p>对数据集进行切分，按照训练集合测试集7:3的比例：</p><pre><code class="nix">#所以把原数据集分成训练集的测试集，咱们用sklearn自带的分割函数。
from sklearn.model_selection import train_test_split
x, y = zip(*sentences)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=1234)</code></pre><p>然后，对特征构造词向量：</p><pre><code class="nix">#抽取特征，我们对文本抽取词袋模型特征
from sklearn.feature_extraction.text import CountVectorizer
vec = CountVectorizer(
    analyzer=&#39;word&#39;, #tokenise by character ngrams
    max_features=4000,  #keep the most common 1000 ngrams
)
vec.fit(x_train)</code></pre><p>定义模型参数：</p><pre><code class="makefile"># 设置参数
max_features = 5001
maxlen = 100
batch_size = 32
embedding_dims = 50
filters = 250
kernel_size = 3
hidden_dims = 250
epochs = 10
nclasses = 3</code></pre><p>输入特征转成 Array 和标签处理，打印训练集和测试集的 shape：</p><pre><code class="nix">    x_train = vec.transform(x_train)
    x_test = vec.transform(x_test)
    x_train = x_train.toarray()
    x_test = x_test.toarray()
    y_train = np_utils.to_categorical(y_train,nclasses)
    y_test = np_utils.to_categorical(y_test,nclasses)
    x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
    x_test = sequence.pad_sequences(x_test, maxlen=maxlen)
    print(&#39;x_train shape:&#39;, x_train.shape)
    print(&#39;x_test shape:&#39;, x_test.shape)</code></pre><p>定义一个绘制 Loss 曲线的类：</p><pre><code class="ruby">class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = {&#39;batch&#39;:[], &#39;epoch&#39;:[]}
        self.accuracy = {&#39;batch&#39;:[], &#39;epoch&#39;:[]}
        self.val_loss = {&#39;batch&#39;:[], &#39;epoch&#39;:[]}
        self.val_acc = {&#39;batch&#39;:[], &#39;epoch&#39;:[]}

    def on_batch_end(self, batch, logs={}):
        self.losses[&#39;batch&#39;].append(logs.get(&#39;loss&#39;))
        self.accuracy[&#39;batch&#39;].append(logs.get(&#39;acc&#39;))
        self.val_loss[&#39;batch&#39;].append(logs.get(&#39;val_loss&#39;))
        self.val_acc[&#39;batch&#39;].append(logs.get(&#39;val_acc&#39;))

    def on_epoch_end(self, batch, logs={}):
        self.losses[&#39;epoch&#39;].append(logs.get(&#39;loss&#39;))
        self.accuracy[&#39;epoch&#39;].append(logs.get(&#39;acc&#39;))
        self.val_loss[&#39;epoch&#39;].append(logs.get(&#39;val_loss&#39;))
        self.val_acc[&#39;epoch&#39;].append(logs.get(&#39;val_acc&#39;))

    def loss_plot(self, loss_type):
        iters = range(len(self.losses[loss_type]))
        plt.figure()
        # acc
        plt.plot(iters, self.accuracy[loss_type], &#39;r&#39;, label=&#39;train acc&#39;)
        # loss
        plt.plot(iters, self.losses[loss_type], &#39;g&#39;, label=&#39;train loss&#39;)
        if loss_type == &#39;epoch&#39;:
            # val_acc
            plt.plot(iters, self.val_acc[loss_type], &#39;b&#39;, label=&#39;val acc&#39;)
            # val_loss
            plt.plot(iters, self.val_loss[loss_type], &#39;k&#39;, label=&#39;val loss&#39;)
        plt.grid(True)
        plt.xlabel(loss_type)
        plt.ylabel(&#39;acc-loss&#39;)
        plt.legend(loc=&quot;upper right&quot;)
        plt.show()</code></pre><p>然后，初始化上面类的对象，并作为模型的回调函数输入，训练模型：</p><pre><code class="gams">history = LossHistory()
print(&#39;Build model...&#39;)
model = Sequential()

model.add(Embedding(max_features,
                        embedding_dims,
                        input_length=maxlen))
model.add(Dropout(0.5))
model.add(Conv1D(filters,
                     kernel_size,
                     padding=&#39;valid&#39;,
                     activation=&#39;relu&#39;,
                     strides=1))
model.add(GlobalMaxPooling1D())
model.add(Dense(hidden_dims))
model.add(Dropout(0.5))
model.add(Activation(&#39;relu&#39;))
model.add(Dense(nclasses))
model.add(Activation(&#39;softmax&#39;))
model.compile(loss=&#39;categorical_crossentropy&#39;,
                  optimizer=&#39;adam&#39;,
                  metrics=[&#39;accuracy&#39;])
model.fit(x_train, y_train,
              batch_size=batch_size,
              epochs=epochs,
              validation_data=(x_test, y_test),callbacks=[history])</code></pre><p>得到的模型迭代次数为10轮的训练过程：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423962832.png" alt="enter description here"></p><p>最后绘制 Loss 图像：</p><p><img src="https://www.github.com/OneJane/blog/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1574423967077.png" alt="enter description here"></p><p>关于本次分类，这里重点讨论的一个知识点就是数据分布不均匀的情况，我们都知道，本次贸易战中兴公司受影响很大，导致整个股票价格处于下跌趋势，所以整个舆论上，大多数评论都是消极的态度，导致数据分布极不均匀。</p><p>那数据分布不均匀一般怎么处理呢？从以下几个方面考虑：</p><ul><li><p>数据采样，包括上采样、下采样和综合采样；</p></li><li><p>改变分类算法，在传统分类算法的基础上对不同类别采取不同的加权方式，使得模型更看重少数类；</p></li><li><p>采用合理的性能评价指标；</p></li><li><p>代价敏感。</p></li></ul><p>总结，本文通过第三方、基于词典等方式计算中文文本情感值，以及通过情感树来进行可视化，然而这些内容只是情感分析的入门知识，情感分析还涉及句法依存等，最后通过一个CNN 分类模型，提供一种有监督的情感分类思路。</p></article><div class="post-donate"><div id="donate_board" class="donate_bar center"><a id="btn_donate" class="btn_donate" href="javascript:;" title="打赏"></a> <span class="donate_txt">↑<br> 欢迎投食,求鼓励，求支持！</span><br></div><div id="donate_guide" class="donate_bar center hidden"> <img src="/images/alipay.png" alt="支付宝打赏"> <img src="/images/wechatpay.png" alt="微信打赏"></div><script type="text/javascript">document.getElementById("btn_donate").onclick=function(){$("#donate_board").addClass("hidden"),$("#donate_guide").removeClass("hidden")}</script></div><div class="nexmoe-post-copyright"><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i> <strong>本文作者：</strong>OneJane<br> <strong>本文链接：</strong><a href="https://onejane.github.io/2019/11/22/12.基于情感词典的文本情感分析/" title="https://onejane.github.io/2019/11/22/12.基于情感词典的文本情感分析/" target="_blank" rel="noopener">https://onejane.github.io/2019/11/22/12.基于情感词典的文本情感分析/</a><br> <strong>版权声明：</strong>本文采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh" target="_blank">CC BY-NC-SA 3.0 CN</a> 协议进行许可</div><section class="nexmoe-comment"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.css"><div id="gitalk"></div><script src="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"e677e59382e1c7a468fd",clientSecret:"717d041bc4ab749f069314862232cfb6ec8adc15",id:decodeURI(window.location.pathname),repo:"onejane.github.io",owner:"onejane",admin:"onejane"});gitalk.render("gitalk")</script></section></div></div></div><script src="https://cdn.jsdelivr.net/npm/mdui@0.4.3/dist/js/mdui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/smoothscroll-for-websites@1.4.9/SmoothScroll.min.js"></script><script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.15.8/build/highlight.min.js"></script><script>hljs.initHighlightingOnLoad()</script><script src="/js/app.js?v=1578434407861"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@5.1.0/lazysizes.min.js"></script><div hidden><script type="text/javascript" src="https://js.users.51.la/20279757.js"></script></div></body><script src="https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js"></script></html>