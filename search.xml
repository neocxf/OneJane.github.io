<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[吴恩达深度学习笔记(第五课时)]]></title>
    <url>%2F2019%2F12%2F05%2Fnew_%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E7%AC%AC%E4%BA%94%E8%AF%BE%E6%97%B6)%2F</url>
    <content type="text"><![CDATA[吴恩达深度学习笔记 序列模型(Sequence Models)第一周 循环序列模型（Recurrent Neural Networks）1.1 为什么选择序列模型？（Why Sequence Models?）在本课程中你将学会序列模型，它是深度学习中最令人激动的内容之一。循环神经网络（RNN）之类的模型在语音识别、自然语言处理和其他领域中引起变革。在本节课中，你将学会如何自行创建这些模型。我们先看一些例子，这些例子都有效使用了序列模型。 在进行语音识别时，给定了一个输入音频片段 $X$，并要求输出对应的文字记录 $Y$。这个例子里输入和输出数据都是序列模型，因为 $X$是一个按时播放的音频片段，输出 $Y$是一系列单词。所以之后将要学到的一些序列模型，如循环神经网络等等在语音识别方面是非常有用的。 音乐生成问题是使用序列数据的另一个例子，在这个例子中，只有输出数据 $Y$是序列，而输入数据可以是空集，也可以是个单一的整数，这个数可能指代你想要生成的音乐风格，也可能是你想要生成的那首曲子的头几个音符。输入的 $X$可以是空的，或者就是个数字，然后输出序列 $Y$。 在处理情感分类时，输入数据 $X$是序列，你会得到类似这样的输入：“There is nothing to like in this movie.”，你认为这句评论对应几星？ 系列模型在DNA序列分析中也十分有用，你的DNA可以用A、C、G、T四个字母来表示。所以给定一段DNA序列，你能够标记出哪部分是匹配某种蛋白质的吗？ 在机器翻译过程中，你会得到这样的输入句：“Voulez-vou chante avecmoi?”（法语：要和我一起唱么？），然后要求你输出另一种语言的翻译结果。 在进行视频行为识别时，你可能会得到一系列视频帧，然后要求你识别其中的行为。 在进行命名实体识别时，可能会给定一个句子要你识别出句中的人名。 所以这些问题都可以被称作使用标签数据 $(X,Y)$作为训练集的监督学习。但从这一系列例子中你可以看出序列问题有很多不同类型。有些问题里，输入数据 $X$和输出数据$Y$都是序列，但就算在那种情况下，$X$和$Y$有时也会不一样长。或者像上图编号1所示和上图编号2的$X$和$Y$有相同的数据长度。在另一些问题里，只有 $X$或者只有$Y$是序列。 所以在本节我们学到适用于不同情况的序列模型。 下节中我们会定义一些定义序列问题要用到的符号。 1.2 数学符号（Notation）本节先从定义符号开始一步步构建序列模型。 比如说你想要建立一个序列模型，它的输入语句是这样的：“Harry Potter and Herminoe Granger invented a new spell.”，(这些人名都是出自于J.K.Rowling笔下的系列小说Harry Potter)。假如你想要建立一个能够自动识别句中人名位置的序列模型，那么这就是一个命名实体识别问题，这常用于搜索引擎，比如说索引过去24小时内所有新闻报道提及的人名，用这种方式就能够恰当地进行索引。命名实体识别系统可以用来查找不同类型的文本中的人名、公司名、时间、地点、国家名和货币名等等。 现在给定这样的输入数据$x$，假如你想要一个序列模型输出$y$，使得输入的每个单词都对应一个输出值，同时这个$y$能够表明输入的单词是否是人名的一部分。技术上来说这也许不是最好的输出形式，还有更加复杂的输出形式，它不仅能够表明输入词是否是人名的一部分，它还能够告诉你这个人名在这个句子里从哪里开始到哪里结束。比如Harry Potter（上图编号1所示）、Hermione Granger（上图标号2所示）。 更简单的那种输出形式: 这个输入数据是9个单词组成的序列，所以最终我们会有9个特征集和来表示这9个单词，并按序列中的位置进行索引，$x^{&lt;1&gt;}$、$x^{&lt;2&gt;}$、$x^{&lt;3&gt;}$等等一直到$x^{&lt;9&gt;}$来索引不同的位置，我将用$x^{&lt;t&gt;}$来索引这个序列的中间位置。$t$意味着它们是时序序列，但不论是否是时序序列，我们都将用$t$来索引序列中的位置。 输出数据也是一样，我们还是用$y^{&lt;1&gt;}$、$y^{&lt;2&gt;}$、$y^{&lt;3&gt;}$等等一直到$y^{&lt;9&gt;}$来表示输出数据。同时我们用$T_{x}$来表示输入序列的长度，这个例子中输入是9个单词，所以$T_{x}= 9$。我们用$T_{y}$来表示输出序列的长度。在这个例子里$T_{x} =T_{y}$，上个视频里你知道$T_{x}$和$T_{y}$可以有不同的值。 你应该记得我们之前用的符号，我们用$x^{(i)}$来表示第$i$个训练样本，所以为了指代第$t$个元素，或者说是训练样本i的序列中第$t$个元素用$x^{\left(i \right) &lt;t&gt;}$这个符号来表示。如果$T_{x}$是序列长度，那么你的训练集里不同的训练样本就会有不同的长度，所以$T_{x}^{(i)}$就代表第$i$个训练样本的输入序列长度。同样$y^{\left( i \right) &lt; t&gt;}$代表第$i$个训练样本中第$t$个元素，$T_{y}^{(i)}$就是第$i$个训练样本的输出序列的长度。 所以在这个例子中，$T_{x}^{(i)}=9$，但如果另一个样本是由15个单词组成的句子，那么对于这个训练样本，$T_{x}^{(i)}=15$。 既然我们这个例子是NLP，也就是自然语言处理，这是我们初次涉足自然语言处理，一件我们需要事先决定的事是怎样表示一个序列里单独的单词，你会怎样表示像Harry这样的单词，$x^{&lt;1&gt;}$实际应该是什么？ 接下来我们讨论一下怎样表示一个句子里单个的词。想要表示一个句子里的单词，第一件事是做一张词表，有时也称为词典，意思是列一列你的表示方法中用到的单词。这个词表（下图所示）中的第一个词是a，也就是说词典中的第一个单词是a，第二个单词是Aaron，然后更下面一些是单词and，再后面你会找到Harry，然后找到Potter，这样一直到最后，词典里最后一个单词可能是Zulu。 因此a是第一个单词，Aaron是第二个单词，在这个词典里，and出现在367这个位置上，Harry是在4075这个位置，Potter在6830，词典里的最后一个单词Zulu可能是第10,000个单词。所以在这个例子中我用了10,000个单词大小的词典，这对现代自然语言处理应用来说太小了。对于商业应用来说，或者对于一般规模的商业应用来说30,000到50,000词大小的词典比较常见，但是100,000词的也不是没有，而且有些大型互联网公司会用百万词，甚至更大的词典。许多商业应用用的词典可能是30,000词，也可能是50,000词。不过我将用10,000词大小的词典做说明，因为这是一个很好用的整数。 如果你选定了10,000词的词典，构建这个词典的一个方法是遍历你的训练集，并且找到前10,000个常用词，你也可以去浏览一些网络词典，它能告诉你英语里最常用的10,000个单词，接下来你可以用one-hot表示法来表示词典里的每个单词。 举个例子，在这里$x^{&lt;1&gt;}$表示Harry这个单词，它就是一个第4075行是1，其余值都是0的向量（上图编号1所示），因为那是Harry在这个词典里的位置。 同样$x^{&lt;2&gt;}$是个第6830行是1，其余位置都是0的向量（上图编号2所示）。 and在词典里排第367，所以$x^{&lt;3&gt;}$就是第367行是1，其余值都是0的向量（上图编号3所示）。如果你的词典大小是10,000的话，那么这里的每个向量都是10,000维的。 因为a是字典第一个单词，$x^{&lt;7&gt;}$对应a，那么这个向量的第一个位置为1，其余位置都是0的向量（上图编号4所示）。 所以这种表示方法中，$x^{&lt;t&gt;}$指代句子里的任意词，它就是个one-hot向量，因为它只有一个值是1，其余值都是0，所以你会有9个one-hot向量来表示这个句中的9个单词，目的是用这样的表示方式表示$X$，用序列模型在$X$和目标输出$Y$之间学习建立一个映射。我会把它当作监督学习的问题，我确信会给定带有$(x，y)$标签的数据。 那么还剩下最后一件事，我们将在之后的视频讨论，如果你遇到了一个不在你词表中的单词，答案就是创建一个新的标记，也就是一个叫做Unknow Word的伪造单词，用&amp;lt;UNK&amp;gt;作为标记，来表示不在词表中的单词，我们之后会讨论更多有关这个的内容。 总结一下本节课的内容，我们描述了一套符号用来表述你的训练集里的序列数据$x$和$y$，在下节课我们开始讲述循环神经网络中如何构建$X$到$Y$的映射。 1.3 循环神经网络模型（Recurrent Neural Network Model）上节视频中，你了解了我们用来定义序列学习问题的符号。现在我们讨论一下怎样才能建立一个模型，建立一个神经网络来学习$X$到$Y$的映射。 可以尝试的方法之一是使用标准神经网络，在我们之前的例子中，我们有9个输入单词。想象一下，把这9个输入单词，可能是9个one-hot向量，然后将它们输入到一个标准神经网络中，经过一些隐藏层，最终会输出9个值为0或1的项，它表明每个输入单词是否是人名的一部分。 但结果表明这个方法并不好，主要有两个问题， 一、是输入和输出数据在不同例子中可以有不同的长度，不是所有的例子都有着同样输入长度$T_{x}$或是同样输出长度的$T_{y}$。即使每个句子都有最大长度，也许你能够填充（pad）或零填充（zero pad）使每个输入语句都达到最大长度，但仍然看起来不是一个好的表达方式。 二、一个像这样单纯的神经网络结构，它并不共享从文本的不同位置上学到的特征。具体来说，如果神经网络已经学习到了在位置1出现的Harry可能是人名的一部分，那么如果Harry出现在其他位置，比如$x^{&lt;t&gt;}$时，它也能够自动识别其为人名的一部分的话，这就很棒了。这可能类似于你在卷积神经网络中看到的，你希望将部分图片里学到的内容快速推广到图片的其他部分，而我们希望对序列数据也有相似的效果。和你在卷积网络中学到的类似，用一个更好的表达方式也能够让你减少模型中参数的数量。 之前我们提到过这些（上图编号1所示的$x^{&lt;1&gt;}$……$x^{&lt;t&gt;}$……$x^{&lt; T_{x}&gt;}$）都是10,000维的one-hot向量，因此这会是十分庞大的输入层。如果总的输入大小是最大单词数乘以10,000，那么第一层的权重矩阵就会有着巨量的参数。但循环神经网络就没有上述的两个问题。 那么什么是循环神经网络呢？我们先建立一个（下图编号1所示）。如果你以从左到右的顺序读这个句子，第一个单词就是，假如说是$x^{&lt;1&gt;}$，我们要做的就是将第一个词输入一个神经网络层，我打算这样画，第一个神经网络的隐藏层，我们可以让神经网络尝试预测输出，判断这是否是人名的一部分。循环神经网络做的是，当它读到句中的第二个单词时，假设是$x^{&lt;2&gt;}$，它不是仅用$x^{&lt;2&gt;}$就预测出${\hat{y} }^{&lt;2&gt;}$，他也会输入一些来自时间步1的信息。具体而言，时间步1的激活值就会传递到时间步2。然后，在下一个时间步，循环神经网络输入了单词$x^{&lt;3&gt;}$，然后它尝试预测输出了预测结果${\hat{y} }^{&lt;3&gt;}$，等等，一直到最后一个时间步，输入了$x^{&lt;T_{x}&gt;}$，然后输出了${\hat{y} }^{&lt; T_{y} &gt;}$。至少在这个例子中$T_{x} =T_{y}$，同时如果$T_{x}$和$T_{y}$不相同，这个结构会需要作出一些改变。所以在每一个时间步中，循环神经网络传递一个激活值到下一个时间步中用于计算。 要开始整个流程，在零时刻需要构造一个激活值$a^{&lt;0&gt;}$，这通常是零向量。有些研究人员会随机用其他方法初始化$a^{&lt;0&gt;}$，不过使用零向量作为零时刻的伪激活值是最常见的选择，因此我们把它输入神经网络。 在一些研究论文中或是一些书中你会看到这类神经网络，用这样的图形来表示（上图编号2所示），在每一个时间步中，你输入$x^{&lt;t&gt;}$然后输出$y^{&lt;t&gt;}$。然后为了表示循环连接有时人们会像这样画个圈，表示输回网络层，有时他们会画一个黑色方块，来表示在这个黑色方块处会延迟一个时间步。我个人认为这些循环图很难理解，所以在本次课程中，我画图更倾向于使用左边这种分布画法（上图编号1所示）。不过如果你在教材中或是研究论文中看到了右边这种图表的画法（上图编号2所示），它可以在心中将这图展开成左图那样。 循环神经网络是从左向右扫描数据，同时每个时间步的参数也是共享的，所以下页幻灯片中我们会详细讲述它的一套参数，我们用$W_{\text{ax} }$来表示管理着从$x^{&lt;1&gt;}$到隐藏层的连接的一系列参数，每个时间步使用的都是相同的参数$W_{\text{ax} }$。而激活值也就是水平联系是由参数$W_{aa}$决定的，同时每一个时间步都使用相同的参数$W_{aa}$，同样的输出结果由$W_{\text{ya} }$决定。下图详细讲述这些参数是如何起作用。 在这个循环神经网络中，它的意思是在预测${\hat{y} }^{&lt; 3 &gt;}$时，不仅要使用$x^{&lt;3&gt;}$的信息，还要使用来自$x^{&lt;1&gt;}$和$x^{&lt;2&gt;}$的信息，因为来自$x^{&lt;1&gt;}$的信息可以通过这样的路径（上图编号1所示的路径）来帮助预测${\hat{y} }^{&lt;3&gt;}$。这个循环神经网络的一个缺点就是它只使用了这个序列中之前的信息来做出预测，尤其当预测${\hat{y} }^{&lt;3&gt;}$时，它没有用到$x^{&lt;4&gt;}$，$x^{&lt;5&gt;}$，$x^{&lt;6&gt;}$等等的信息。所以这就有一个问题，因为如果给定了这个句子，“Teddy Roosevelt was a great President.”，为了判断Teddy是否是人名的一部分，仅仅知道句中前两个词是完全不够的，还需要知道句中后部分的信息，这也是十分有用的，因为句子也可能是这样的，“Teddy bears are on sale!”。因此如果只给定前三个单词，是不可能确切地知道Teddy是否是人名的一部分，第一个例子是人名，第二个例子就不是，所以你不可能只看前三个单词就能分辨出其中的区别。 所以这样特定的神经网络结构的一个限制是它在某一时刻的预测仅使用了从序列之前的输入信息并没有使用序列中后部分的信息，我们会在之后的双向循环神经网络（BRNN）的视频中处理这个问题。但对于现在，这个更简单的单向神经网络结构就够我们来解释关键概念了，之后只要在此基础上作出修改就能同时使用序列中前面和后面的信息来预测${\hat{y} }^{&lt;3&gt;}$，不过我们会在之后的视频讲述这些内容，接下来我们具体地写出这个神经网络计算了些什么。 这里是一张清理后的神经网络示意图，和我之前提及的一样，一般开始先输入$a^{&lt;0&gt;}$，它是一个零向量。接着就是前向传播过程，先计算激活值$a^{&lt;1&gt;}$，然后再计算$y^{&lt;1&gt;}$。 $a^{&lt;1&gt;} = g_{1}(W_{ {aa} }a^{&lt; 0 &gt;} + W_{ {ax} }x^{&lt; 1 &gt;} + b_{a})$ $\hat y^{&lt; 1 &gt;} = g_{2}(W_{ {ya} }a^{&lt; 1 &gt;} + b_{y})$ 我将用这样的符号约定来表示这些矩阵下标，举个例子$W_{\text{ax} }$，第二个下标意味着$W_{\text{ax} }$要乘以某个$x$类型的量，然后第一个下标$a$表示它是用来计算某个$a$类型的变量。同样的，可以看出这里的$W_{\text{ya} }$乘上了某个$a$类型的量，用来计算出某个$\hat {y}$类型的量。 循环神经网络用的激活函数经常是tanh，不过有时候也会用ReLU，但是tanh是更通常的选择，我们有其他方法来避免梯度消失问题，我们将在之后进行讲述。选用哪个激活函数是取决于你的输出$y$，如果它是一个二分问题，那么我猜你会用sigmoid函数作为激活函数，如果是$k$类别分类问题的话，那么可以选用softmax作为激活函数。不过这里激活函数的类型取决于你有什么样类型的输出$y$，对于命名实体识别来说$y$只可能是0或者1，那我猜这里第二个激活函数$g$可以是sigmoid激活函数。 更一般的情况下，在$t$时刻， $a^{&lt; t &gt;} = g_{1}(W_{aa}a^{&lt; t - 1 &gt;} + W_{ax}x^{&lt; t &gt;} + b_{a})$ $\hat y^{&lt; t &gt;} = g_{2}(W_{ {ya} }a^{&lt; t &gt;} + b_{y})$ 所以这些等式定义了神经网络的前向传播，你可以从零向量$a^{&lt;0&gt;}$开始，然后用$a^{&lt;0&gt;}$和$x^{&lt;1&gt;}$来计算出$a^{&lt;1&gt;}$和$\hat y^{&lt;1&gt;}$，然后用$x^{&lt;2&gt;}$和$a^{&lt;1&gt;}$一起算出$a^{&lt;2&gt;}$和$\hat y^{&lt;2&gt;}$等等，像图中这样，从左到右完成前向传播。 现在为了帮我们建立更复杂的神经网络，我实际要将这个符号简化一下，我在下一张幻灯片里复制了这两个等式（上图编号1所示的两个等式）。 接下来为了简化这些符号，我要将这部分（$W_{\text{aa} }a^{&lt;t -1&gt;} +W_{\text{ax} }x^{&lt;t&gt;}$）（上图编号1所示）以更简单的形式写出来，我把它写做$a^{&lt;t&gt;} =g(W_{a}\left\lbrack a^{&lt; t-1 &gt;},x^{&lt;t&gt;} \right\rbrack +b_{a})$（上图编号2所示），那么左右两边划线部分应该是等价的。所以我们定义$W_{a}$的方式是将矩阵$W_{aa}$和矩阵$W_{ {ax} }$水平并列放置，$[ { {W}_{aa} }\vdots { {W}_{ax} }]=W_{a}$（上图编号3所示）。举个例子，如果$a$是100维的，然后延续之前的例子，$x$是10,000维的，那么$W_{aa}$就是个$（100，100）$维的矩阵，$W_{ax}$就是个$（100，10,000）$维的矩阵，因此如果将这两个矩阵堆起来，$W_{a}$就会是个$（100，10,100）$维的矩阵。 用这个符号（$\left\lbrack a^{&lt; t - 1 &gt;},x^{&lt; t &gt;}\right\rbrack$）的意思是将这两个向量堆在一起，我会用这个符号表示，即$\begin{bmatrix}a^{&lt; t-1 &gt;} \\ x^{&lt; t &gt;} \\\end{bmatrix}$（上图编号4所示），最终这就是个10,100维的向量。你可以自己检查一下，用这个矩阵乘以这个向量，刚好能够得到原来的量，因为此时，矩阵$[ { {W}_{aa} }\vdots { {W}_{ax} }]$乘以$\begin{bmatrix} a^{&lt; t - 1 &gt;} \\ x^{&lt; t &gt;} \\ \end{bmatrix}$，刚好等于$W_{ {aa} }a^{&lt;t-1&gt;} + W_{ {ax} }x^{&lt;t&gt;}$，刚好等于之前的这个结论（上图编号5所示）。这种记法的好处是我们可以不使用两个参数矩阵$W_{ {aa} }$和$W_{ {ax} }$，而是将其压缩成一个参数矩阵$W_{a}$，所以当我们建立更复杂模型时这就能够简化我们要用到的符号。 同样对于这个例子（$\hat y^{&lt;t&gt;} = g(W_{ya}a^{&lt;t&gt;} +b_{y})$），我会用更简单的方式重写，$\hat y^{&lt; t &gt;} = g(W_{y}a^{&lt; t &gt;} +b_{y})$（上图编号6所示）。现在$W_{y}$和$b_{y}$符号仅有一个下标，它表示在计算时会输出什么类型的量，所以$W_{y}$就表明它是计算$y$类型的量的权重矩阵，而上面的$W_{a}$和$b_{a}$则表示这些参数是用来计算$a$类型或者说是激活值的。 RNN前向传播示意图： 好就这么多，你现在知道了基本的循环神经网络，下节课我们会一起来讨论反向传播，以及你如何能够用RNN进行学习。 1.4 通过时间的反向传播（Backpropagation through time）之前我们已经学过了循环神经网络的基础结构，在本节视频中我们将来了解反向传播是怎样在循环神经网络中运行的。和之前一样，当你在编程框架中实现循环神经网络时，编程框架通常会自动处理反向传播。但我认为，在循环神经网络中，对反向传播的运行有一个粗略的认识还是非常有用的，让我们来一探究竟。 在之前你已经见过对于前向传播（上图蓝色箭头所指方向）怎样在神经网络中从左到右地计算这些激活项，直到输出所有地预测结果。而对于反向传播，我想你已经猜到了，反向传播地计算方向（上图红色箭头所指方向）与前向传播基本上是相反的。 我们来分析一下前向传播的计算，现在你有一个输入序列，$x^{&lt;1&gt;}$，$x^{&lt;2&gt;}$，$x^{&lt;3&gt;}$一直到$x^{&lt; T_{x} &gt;}$，然后用$x^{&lt;1&gt;}$还有$a^{&lt;0&gt;}$计算出时间步1的激活项，再用$x^{&lt;2&gt;}$和$a^{&lt;1&gt;}$计算出$a^{&lt;2&gt;}$，然后计算$a^{&lt;3&gt;}$等等，一直到$a^{&lt; T_{x} &gt;}$。 为了真正计算出$a^{&lt;1&gt;}$，你还需要一些参数，$W_{a}$和$b_{a}$，用它们来计算出$a^{&lt;1&gt;}$。这些参数在之后的每一个时间步都会被用到，于是继续用这些参数计算$a^{&lt;2&gt;}$，$a^{&lt;3&gt;}$等等，所有的这些激活项都要取决于参数$W_{a}$和$b_{a}$。有了$a^{&lt;1&gt;}$，神经网络就可以计算第一个预测值$\hat y^{&lt;1&gt;}$，接着到下一个时间步，继续计算出$\hat y^{&lt;2&gt;}$，$\hat y^{&lt;3&gt;}$，等等，一直到$\hat y^{&lt;T_{y}&gt;}$。为了计算出${\hat{y} }$，需要参数$W_{y}$和$b_{y}$，它们将被用于所有这些节点。 然后为了计算反向传播，你还需要一个损失函数。我们先定义一个元素损失函数（上图编号1所示） $L^{&lt;t&gt;}( \hat y^{&lt;t&gt;},y^{&lt;t&gt;}) = - y^{&lt;t&gt;}\log\hat y^{&lt;t&gt;}-( 1- y^{&lt;t&gt;})log(1-\hat y^{&lt;t&gt;})$ 它对应的是序列中一个具体的词，如果它是某个人的名字，那么$y^{&lt;t&gt;}$的值就是1，然后神经网络将输出这个词是名字的概率值，比如0.1。我将它定义为标准逻辑回归损失函数，也叫交叉熵损失函数（Cross Entropy Loss），它和之前我们在二分类问题中看到的公式很像。所以这是关于单个位置上或者说某个时间步$t$上某个单词的预测值的损失函数。 现在我们来定义整个序列的损失函数，将$L$定义为（上图编号2所示） $L(\hat y,y) = \ \sum_{t = 1}^{T_{x} }{L^{&lt; t &gt;}(\hat y^{&lt; t &gt;},y^{&lt; t &gt;})}$ 在这个计算图中，通过$\hat y^{&lt;1&gt;}$可以计算对应的损失函数，于是计算出第一个时间步的损失函数（上图编号3所示），然后计算出第二个时间步的损失函数，然后是第三个时间步，一直到最后一个时间步，最后为了计算出总体损失函数，我们要把它们都加起来，通过下面的等式（上图编号2所示的等式）计算出最后的$L$（上图编号4所示），也就是把每个单独时间步的损失函数都加起来。 这就是完整的计算图，在之前的例子中，你已经见过反向传播，所以你应该能够想得到反向传播算法需要在相反的方向上进行计算和传递信息，最终你做的就是把前向传播的箭头都反过来，在这之后你就可以计算出所有合适的量，然后你就可以通过导数相关的参数，用梯度下降法来更新参数。 在这个反向传播的过程中，最重要的信息传递或者说最重要的递归运算就是这个从右到左的运算，这也就是为什么这个算法有一个很别致的名字，叫做“通过（穿越）时间反向传播（backpropagation through time）”。取这个名字的原因是对于前向传播，你需要从左到右进行计算，在这个过程中，时刻$t$不断增加。而对于反向传播，你需要从右到左进行计算，就像时间倒流。“通过时间反向传播”，就像穿越时光，这种说法听起来就像是你需要一台时光机来实现这个算法一样。 RNN反向传播示意图： 希望你大致了解了前向和反向传播是如何在RNN中工作的，到目前为止，你只见到了RNN中一个主要的例子，其中输入序列的长度和输出序列的长度是一样的。在下节课将展示更多的RNN架构，这将让你能够处理一些更广泛的应用。 1.5 不同类型的循环神经网络（Different types of RNNs）现在你已经了解了一种RNN结构，它的输入量$T_{x}$等于输出数量$T_{y}$。事实上，对于其他一些应用，$T_{x}$和$T_{y}$并不一定相等。在这个视频里，你会看到更多的RNN的结构。 你应该还记得这周第一个视频中的那个幻灯片，那里有很多例子输入$x$和输出$y$，有各种类型，并不是所有的情况都满足$T_{x}=T_{y}$。 比如音乐生成这个例子，$T_{x}$可以是长度为1甚至为空集。再比如电影情感分类，输出$y$可以是1到5的整数，而输入是一个序列。在命名实体识别中，这个例子中输入长度和输出长度是一样的。 还有一些情况，输入长度和输出长度不同，他们都是序列但长度不同，比如机器翻译，一个法语句子和一个英语句子不同数量的单词却能表达同一个意思。 所以我们应该修改基本的RNN结构来处理这些问题，这个视频的内容参考了Andrej Karpathy的博客，一篇叫做《循环神经网络的非理性效果》（“The Unreasonable Effectiveness of Recurrent Neural Networks”）的文章，我们看一些例子。 你已经见过$T_{x} = T_{y}$的例子了（下图编号1所示），也就是我们输入序列$x^{&lt;1&gt;}$，$x^{&lt;2&gt;}$，一直到$x^{&lt; T_{x}&gt;}$，我们的循环神经网络这样工作，输入$x^{&lt;1&gt;}$来计算$\hat y^{&lt;1&gt;}$，$\hat y^{&lt;2&gt;}$等等一直到$\hat y^{&lt;T_{y}&gt;}$。在原先的图里，我会画一串圆圈表示神经元，大部分时候为了让符号更加简单，此处就以简单的小圈表示。这个就叫做“多对多”（many-to-many）的结构，因为输入序列有很多的输入，而输出序列也有很多输出。 现在我们看另外一个例子，假如说，你想处理情感分类问题（下图编号2所示），这里$x$可能是一段文本，比如一个电影的评论，“These is nothing to like in this movie.”（“这部电影没什么还看的。”），所以$x$就是一个序列，而$y$可能是从1到5的一个数字，或者是0或1，这代表正面评价和负面评价，而数字1到5代表电影是1星，2星，3星，4星还是5星。所以在这个例子中，我们可以简化神经网络的结构，输入$x^{&lt;1 &gt;}$，$x^{&lt; 2 &gt;}$，一次输入一个单词，如果输入文本是“These is nothing to like in this movie”，那么单词的对应如下图编号2所示。我们不再在每个时间上都有输出了，而是让这个RNN网络读入整个句子，然后在最后一个时间上得到输出，这样输入的就是整个句子，所以这个神经网络叫做“多对一”（many-to-one）结构，因为它有很多输入，很多的单词，然后输出一个数字。 为了完整性，还要补充一个“一对一”（one-to-one）的结构（上图编号3所示），这个可能没有那么重要，这就是一个小型的标准的神经网络，输入$x$然后得到输出$y$，我们这个系列课程的前两个课程已经讨论过这种类型的神经网络了。 除了“多对一”的结构，也可以有“一对多”（one-to-many）的结构。对于一个“一对多”神经网络结构的例子就是音乐生成（上图编号1所示），事实上，你会在这个课后编程练习中去实现这样的模型，你的目标是使用一个神经网络输出一些音符。对应于一段音乐，输入$x$可以是一个整数，表示你想要的音乐类型或者是你想要的音乐的第一个音符，并且如果你什么都不想输入，$x$可以是空的输入，可设为0向量。 这样这个神经网络的结构，首先是你的输入$x$，然后得到RNN的输出，第一个值，然后就没有输入了，再得到第二个输出，接着输出第三个值等等，一直到合成这个音乐作品的最后一个音符，这里也可以写上输入$a^{&lt;0&gt;}$（上图编号3所示）。有一个后面才会讲到的技术细节，当你生成序列时通常会把第一个合成的输出也喂给下一层（上图编号4所示），所以实际的网络结构最终就像这个样子。 我们已经讨论了“多对多”、“多对一”、“一对一”和“一对多”的结构，对于“多对多”的结构还有一个有趣的例子值得详细说一下，就是输入和输出长度不同的情况。你刚才看过的多对多的例子，它的输入长度和输出长度是完全一样的。而对于像机器翻译这样的应用，输入句子的单词的数量，比如说一个法语的句子，和输出句子的单词数量，比如翻译成英语，这两个句子的长度可能不同，所以还需要一个新的网络结构，一个不同的神经网络（上图编号2所示）。首先读入这个句子，读入这个输入，比如你要将法语翻译成英语，读完之后，这个网络就会输出翻译结果。有了这种结构$T_{x}$和$T_{y}$就可以是不同的长度了。同样，你也可以画上这个$a^{&lt;0&gt;}$。这个网络的结构有两个不同的部分，这（上图编号5所示）是一个编码器，获取输入，比如法语句子，这（上图编号6所示）是解码器，它会读取整个句子，然后输出翻译成其他语言的结果。 这就是一个“多对多”结构的例子，到这周结束的时候，你就能对这些各种各样结构的基本构件有一个很好的理解。严格来说，还有一种结构，我们会在第四周涉及到，就是“注意力”（attention based）结构，但是根据我们现在画的这些图不好理解这个模型。 总结一下这些各种各样的RNN结构，这（上图编号1所示）是“一对一”的结构，当去掉$a^{&lt;0&gt;}$时它就是一种标准类型的神经网络。还有一种“一对多”的结构（上图编号2所示），比如音乐生成或者序列生成。还有“多对一”，这（上图编号3所示）是情感分类的例子，首先读取输入，一个电影评论的文本，然后判断他们是否喜欢电影还是不喜欢。还有“多对多”的结构（上图编号4所示），命名实体识别就是“多对多”的例子，其中$T_{x}=T_{y}$。最后还有一种“多对多”结构的其他版本（上图编号5所示），对于像机器翻译这样的应用，$T_{x}$和$T_{y}$就可以不同了。 现在，你已经了解了大部分基本的模块，这些就是差不多所有的神经网络了，除了序列生成，有些细节的问题我们会在下节课讲解。 我希望你从本视频中了解到用这些RNN的基本模块，把它们组合在一起就可以构建各种各样的模型。但是正如我前面提到的，序列生成还有一些不一样的地方，在这周的练习里，你也会实现它，你需要构建一个语言模型，结果好的话会得到一些有趣的序列或者有意思的文本。下节课深入探讨序列生成。 1.6 语言模型和序列生成（Language model and sequence generation）在自然语言处理中，构建语言模型是最基础的也是最重要的工作之一，并且能用RNN很好地实现。在本视频中，你将学习用RNN构建一个语言模型，在本周结束的时候，还会有一个很有趣的编程练习，你能在练习中构建一个语言模型，并用它来生成莎士比亚文风的文本或其他类型文本。 所以什么是语言模型呢？比如你在做一个语音识别系统，你听到一个句子，“the apple and pear（pair） salad was delicious.”，所以我究竟说了什么？我说的是 “the apple and pair salad”，还是“the apple and pear salad”？（pear和pair是近音词）。你可能觉得我说的应该更像第二种，事实上，这就是一个好的语音识别系统要帮助输出的东西，即使这两句话听起来是如此相似。而让语音识别系统去选择第二个句子的方法就是使用一个语言模型，他能计算出这两句话各自的可能性。 举个例子，一个语音识别模型可能算出第一句话的概率是$P( \text{The apple and pair salad}) = 3.2 \times 10^{-13}$，而第二句话的概率是$P\left(\text{The apple and pear salad} \right) = 5.7 \times 10^{-10}$，比较这两个概率值，显然我说的话更像是第二种，因为第二句话的概率比第一句高出1000倍以上，这就是为什么语音识别系统能够在这两句话中作出选择。 所以语言模型所做的就是，它会告诉你某个特定的句子它出现的概率是多少，根据我所说的这个概率，假设你随机拿起一张报纸，打开任意邮件，或者任意网页或者听某人说下一句话，并且这个人是你的朋友，这个你即将从世界上的某个地方得到的句子会是某个特定句子的概率是多少，例如“the apple and pear salad”。它是两种系统的基本组成部分，一个刚才所说的语音识别系统，还有机器翻译系统，它要能正确输出最接近的句子。而语言模型做的最基本工作就是输入一个句子，准确地说是一个文本序列，$y^{&lt;1&gt;}$，$y^{&lt;2&gt;}$一直到$y^{&lt;T_{y}&gt;}$。对于语言模型来说，用$y$来表示这些序列比用$x$来表示要更好，然后语言模型会估计某个句子序列中各个单词出现的可能性。 那么如何建立一个语言模型呢？为了使用RNN建立出这样的模型，你首先需要一个训练集，包含一个很大的英文文本语料库（corpus）或者其它的语言，你想用于构建模型的语言的语料库。语料库是自然语言处理的一个专有名词，意思就是很长的或者说数量众多的英文句子组成的文本。 假如说，你在训练集中得到这么一句话，“Cats average 15 hours of sleep a day.”(猫一天睡15小时)，你要做的第一件事就是将这个句子标记化，意思就是像之前视频中一样，建立一个字典，然后将每个单词都转换成对应的one-hot向量，也就是字典中的索引。可能还有一件事就是你要定义句子的结尾，一般的做法就是增加一个额外的标记，叫做EOS（上图编号1所示），它表示句子的结尾，这样能够帮助你搞清楚一个句子什么时候结束，我们之后会详细讨论这个。EOS标记可以被附加到训练集中每一个句子的结尾，如果你想要你的模型能够准确识别句子结尾的话。在本周的练习中我们不需要使用这个EOS标记，不过在某些应用中你可能会用到它，不过稍后就能见到它的用处。于是在本例中我们，如果你加了EOS标记，这句话就会有9个输入，有$y^{&lt;1&gt;}$，$y^{&lt;2&gt;}$一直到$y^{&lt;9&gt;}$。在标记化的过程中，你可以自行决定要不要把标点符号看成标记，在本例中，我们忽略了标点符号，所以我们只把day看成标志，不包括后面的句号，如果你想把句号或者其他符号也当作标志，那么你可以将句号也加入你的字典中。 现在还有一个问题如果你的训练集中有一些词并不在你的字典里，比如说你的字典有10,000个词，10,000个最常用的英语单词。现在这个句，“The Egyptian Mau is a bread of cat.”其中有一个词Mau，它可能并不是预先的那10,000个最常用的单词，在这种情况下，你可以把Mau替换成一个叫做UNK的代表未知词的标志，我们只针对UNK建立概率模型，而不是针对这个具体的词Mau。 完成标识化的过程后，这意味着输入的句子都映射到了各个标志上，或者说字典中的各个词上。下一步我们要构建一个RNN来构建这些序列的概率模型。在下一张幻灯片中会看到的一件事就是最后你会将$x^{&lt;t&gt;}$设为$y^{&lt;t-1&gt;}$。 现在我们来建立RNN模型，我们继续使用“Cats average 15 hours of sleep a day.”这个句子来作为我们的运行样例，我将会画出一个RNN结构。在第0个时间步，你要计算激活项$a^{&lt;1&gt;}$，它是以$x^{&lt;1 &gt;}$作为输入的函数，而$x^{&lt;1&gt;}$会被设为全为0的集合，也就是0向量。在之前的$a^{&lt;0&gt;}$按照惯例也设为0向量，于是$a^{&lt;1&gt;}$要做的就是它会通过softmax进行一些预测来计算出第一个词可能会是什么，其结果就是$\hat y^{&lt;1&gt;}$（上图编号1所示），这一步其实就是通过一个softmax层来预测字典中的任意单词会是第一个词的概率，比如说第一个词是$a$的概率有多少，第一个词是Aaron的概率有多少，第一个词是cats的概率又有多少，就这样一直到Zulu是第一个词的概率是多少，还有第一个词是UNK（未知词）的概率有多少，还有第一个词是句子结尾标志的概率有多少，表示不必阅读。所以$\hat y^{&lt;1&gt;}$的输出是softmax的计算结果，它只是预测第一个词的概率，而不去管结果是什么。在我们的例子中，最终会得到单词Cats。所以softmax层输出10,000种结果，因为你的字典中有10,000个词，或者会有10,002个结果，因为你可能加上了未知词，还有句子结尾这两个额外的标志。 然后RNN进入下个时间步，在下一时间步中，仍然使用激活项$a^{&lt;1&gt;}$，在这步要做的是计算出第二个词会是什么。现在我们依然传给它正确的第一个词，我们会告诉它第一个词就是Cats，也就是$\hat y^{&lt;1&gt;}$，告诉它第一个词就是Cats，这就是为什么$y^{&lt;1&gt;} = x^{&lt;2&gt;}$（上图编号2所示）。然后在第二个时间步中，输出结果同样经过softmax层进行预测，RNN的职责就是预测这些词的概率（上图编号3所示），而不会去管结果是什么，可能是b或者arron，可能是Cats或者Zulu或者UNK（未知词）或者EOS或者其他词，它只会考虑之前得到的词。所以在这种情况下，我猜正确答案会是average，因为句子确实就是Cats average开头的。 然后再进行RNN的下个时间步，现在要计算$a^{&lt;3&gt;}$。为了预测第三个词，也就是15，我们现在给它之前两个词，告诉它Cats average是句子的前两个词，所以这是下一个输入，$x^{&lt;3&gt;} = y^{&lt;2&gt;}$，输入average以后，现在要计算出序列中下一个词是什么，或者说计算出字典中每一个词的概率（上图编号4所示），通过之前得到的Cats和average，在这种情况下，正确结果会是15，以此类推。 一直到最后，没猜错的话，你会停在第9个时间步，然后把$x^{&lt;9&gt;}$也就是$y^{&lt;8&gt;}$传给它（上图编号5所示），也就是单词day，这里是$a^{&lt;9&gt;}$，它会输出$y^{&lt;9&gt;}$，最后的得到结果会是EOS标志，在这一步中，通过前面这些得到的单词，不管它们是什么，我们希望能预测出EOS句子结尾标志的概率会很高（上图编号6所示）。 所以RNN中的每一步都会考虑前面得到的单词，比如给它前3个单词（上图编号7所示），让它给出下个词的分布，这就是RNN如何学习从左往右地每次预测一个词。 接下来为了训练这个网络，我们要定义代价函数。于是，在某个时间步$t$，如果真正的词是$y^{&lt;t&gt;}$，而神经网络的softmax层预测结果值是$y^{&lt;t&gt;}$，那么这（上图编号8所示）就是softmax损失函数，$L\left( \hat y^{&lt;t&gt;},y^{&lt;t&gt;}&gt;\right) = - \sum_{i}^{}{y_{i}^{&lt;t&gt;}\log\hat y_{i}^{&lt;t&gt;} }$。而总体损失函数（上图编号9所示）$L = \sum_{t}^{}{L^{&lt; t &gt;}\left( \hat y^{&lt;t&gt;},y^{&lt;t&gt;} \right)}$，也就是把所有单个预测的损失函数都相加起来。 如果你用很大的训练集来训练这个RNN，你就可以通过开头一系列单词像是Cars average 15或者Cars average 15 hours of来预测之后单词的概率。现在有一个新句子，它是$y^{&lt;1&gt;}$，$y^{&lt;2&gt;}$，$y^{&lt;3&gt;}$，为了简单起见，它只包含3个词（如上图所示），现在要计算出整个句子中各个单词的概率，方法就是第一个softmax层会告诉你$y^{&lt;1&gt;}$的概率（上图编号1所示），这也是第一个输出，然后第二个softmax层会告诉你在考虑$y^{&lt;1&gt;}$的情况下$y^{&lt;2&gt;}$的概率（上图编号2所示），然后第三个softmax层告诉你在考虑$y^{&lt;1&gt;}$和$y^{&lt;2&gt;}$的情况下$y^{&lt;3&gt;}$的概率（上图编号3所示），把这三个概率相乘，最后得到这个含3个词的整个句子的概率。 这就是用RNN训练一个语言模型的基础结构，可能我说的这些东西听起来有些抽象，不过别担心，你可以在编程练习中亲自实现这些东西。下一节课用语言模型做的一件最有趣的事就是从模型中进行采样。 1.7 对新序列采样（Sampling novel sequences）在你训练一个序列模型之后，要想了解到这个模型学到了什么，一种非正式的方法就是进行一次新序列采样，来看看到底应该怎么做。 记住一个序列模型模拟了任意特定单词序列的概率，我们要做的就是对这些概率分布进行采样来生成一个新的单词序列。下图编号1所示的网络已经被上方所展示的结构训练训练过了，而为了进行采样（下图编号2所示的网络），你要做一些截然不同的事情。 第一步要做的就是对你想要模型生成的第一个词进行采样，于是你输入$x^{&lt;1&gt;} =0$，$a^{&lt;0&gt;} =0$，现在你的第一个时间步得到的是所有可能的输出是经过softmax层后得到的概率，然后根据这个softmax的分布进行随机采样。Softmax分布给你的信息就是第一个词a的概率是多少，第一个词是aaron的概率是多少，第一个词是zulu的概率是多少，还有第一个词是UNK（未知标识）的概率是多少，这个标识可能代表句子的结尾，然后对这个向量使用例如numpy命令，np.random.choice（上图编号3所示），来根据向量中这些概率的分布进行采样，这样就能对第一个词进行采样了。 然后继续下一个时间步，记住第二个时间步需要$\hat y^{&lt;1&gt;}$作为输入，而现在要做的是把刚刚采样得到的$\hat y^{&lt;1&gt;}$放到$a^{&lt;2&gt;}$（上图编号4所示），作为下一个时间步的输入，所以不管你在第一个时间步得到的是什么词，都要把它传递到下一个位置作为输入，然后softmax层就会预测$\hat y^{&lt;2&gt;}$是什么。举个例子，假如说对第一个词进行抽样后，得到的是The，The作为第一个词的情况很常见，然后把The当成$x^{&lt;2&gt;}$，现在$x^{&lt;2&gt;}$就是$\hat y^{&lt;1&gt;}$，现在你要计算出在第一词是The的情况下，第二个词应该是什么（上图编号5所示），然后得到的结果就是$\hat y^{&lt;2&gt;}$，然后再次用这个采样函数来对$\hat y^{&lt;2&gt;}$进行采样。 然后再到下一个时间步，无论你得到什么样的用one-hot码表示的选择结果，都把它传递到下一个时间步，然后对第三个词进行采样。不管得到什么都把它传递下去，一直这样直到最后一个时间步。 那么你要怎样知道一个句子结束了呢？方法之一就是，如果代表句子结尾的标识在你的字典中，你可以一直进行采样直到得到EOS标识（上图编号6所示），这代表着已经抵达结尾，可以停止采样了。另一种情况是，如果你的字典中没有这个词，你可以决定从20个或100个或其他个单词进行采样，然后一直将采样进行下去直到达到所设定的时间步。不过这种过程有时候会产生一些未知标识（上图编号7所示），如果你要确保你的算法不会输出这种标识，你能做的一件事就是拒绝采样过程中产生任何未知的标识，一旦出现就继续在剩下的词中进行重采样，直到得到一个不是未知标识的词。如果你不介意有未知标识产生的话，你也可以完全不管它们。 这就是你如何从你的RNN语言模型中生成一个随机选择的句子。直到现在我们所建立的是基于词汇的RNN模型，意思就是字典中的词都是英语单词（下图编号1所示）。 根据你实际的应用，你还可以构建一个基于字符的RNN结构，在这种情况下，你的字典仅包含从a到z的字母，可能还会有空格符，如果你需要的话，还可以有数字0到9，如果你想区分字母大小写，你可以再加上大写的字母，你还可以实际地看一看训练集中可能会出现的字符，然后用这些字符组成你的字典（上图编号2所示）。 如果你建立一个基于字符的语言模型，比起基于词汇的语言模型，你的序列$\hat y^{&lt;1&gt;}$，$\hat y^{&lt;2&gt;}$，$\hat y^{&lt;3&gt;}$在你的训练数据中将会是单独的字符，而不是单独的词汇。所以对于前面的例子来说，那个句子（上图编号3所示），“Cats average 15 hours of sleep a day.”，在该例中C就是$\hat y^{&lt;1&gt;}$，a就是$\hat y^{&lt;2&gt;}$，t就是$\hat y^{&lt;3&gt;}$，空格符就是$\hat y^{&lt;4&gt;}$等等。 使用基于字符的语言模型有有点也有缺点，优点就是你不必担心会出现未知的标识，例如基于字符的语言模型会将Mau这样的序列也视为可能性非零的序列。而对于基于词汇的语言模型，如果Mau不在字典中，你只能把它当作未知标识UNK。不过基于字符的语言模型一个主要缺点就是你最后会得到太多太长的序列，大多数英语句子只有10到20个的单词，但却可能包含很多很多字符。所以基于字符的语言模型在捕捉句子中的依赖关系也就是句子较前部分如何影响较后部分不如基于词汇的语言模型那样可以捕捉长范围的关系，并且基于字符的语言模型训练起来计算成本比较高昂。所以我见到的自然语言处理的趋势就是，绝大多数都是使用基于词汇的语言模型，但随着计算机性能越来越高，会有更多的应用。在一些特殊情况下，会开始使用基于字符的模型。但是这确实需要更昂贵的计算力来训练，所以现在并没有得到广泛地使用，除了一些比较专门需要处理大量未知的文本或者未知词汇的应用，还有一些要面对很多专有词汇的应用。 在现有的方法下，现在你可以构建一个RNN结构，看一看英文文本的语料库，然后建立一个基于词汇的或者基于字符的语言模型，然后从训练的语言模型中进行采样。 这里有一些样本，它们是从一个语言模型中采样得到的，准确来说是基于字符的语言模型，你可以在编程练习中自己实现这样的模型。如果模型是用新闻文章训练的，它就会生成左边这样的文本，这有点像一篇不太合乎语法的新闻文本，不过听起来，这句“Concussion epidemic”，to be examined，确实有点像新闻报道。用莎士比亚的文章训练后生成了右边这篇东西，听起来很像是莎士比亚写的东西： “The mortal moon hath her eclipse in love. And subject of this thou art another this fold. When besser be my love to me see sabl’s. For whose are ruse of mine eyes heaves.” 这些就是基础的RNN结构和如何去建立一个语言模型并使用它，对于训练出的语言模型进行采样。在之后的视频中，我想探讨在训练RNN时一些更加深入的挑战以及如何适应这些挑战，特别是梯度消失问题来建立更加强大的RNN模型。下节课，我们将谈到梯度消失并且会开始谈到GRU，也就是门控循环单元和LSTM长期记忆网络模型。 1.8 循环神经网络的梯度消失（Vanishing gradients with RNNs）你已经了解了RNN时如何工作的了，并且知道如何应用到具体问题上，比如命名实体识别，比如语言模型，你也看到了怎么把反向传播用于RNN。其实，基本的RNN算法还有一个很大的问题，就是梯度消失的问题。这节课我们会讨论，在下几节课我们会讨论一些方法用来解决这个问题。 你已经知道了RNN的样子，现在我们举个语言模型的例子，假如看到这个句子（上图编号1所示），“The cat, which already ate ……, was full.”，前后应该保持一致，因为cat是单数，所以应该用was。“The cats, which ate ……, were full.”（上图编号2所示），cats是复数，所以用were。这个例子中的句子有长期的依赖，最前面的单词对句子后面的单词有影响。但是我们目前见到的基本的RNN模型（上图编号3所示的网络模型），不擅长捕获这种长期依赖效应，解释一下为什么。 你应该还记得之前讨论的训练很深的网络，我们讨论了梯度消失的问题。比如说一个很深很深的网络（上图编号4所示），100层，甚至更深，对这个网络从左到右做前向传播然后再反向传播。我们知道如果这是个很深的神经网络，从输出$\hat y$得到的梯度很难传播回去，很难影响靠前层的权重，很难影响前面层（编号5所示的层）的计算。 对于有同样问题的RNN，首先从左到右前向传播，然后反向传播。但是反向传播会很困难，因为同样的梯度消失的问题，后面层的输出误差（上图编号6所示）很难影响前面层（上图编号7所示的层）的计算。这就意味着，实际上很难让一个神经网络能够意识到它要记住看到的是单数名词还是复数名词，然后在序列后面生成依赖单复数形式的was或者were。而且在英语里面，这中间的内容（上图编号8所示）可以任意长，对吧？所以你需要长时间记住单词是单数还是复数，这样后面的句子才能用到这些信息。也正是这个原因，所以基本的RNN模型会有很多局部影响，意味着这个输出$\hat y^{&lt;3&gt;}$（上图编号9所示）主要受$\hat y^{&lt;3&gt;}$附近的值（上图编号10所示）的影响，上图编号11所示的一个数值主要与附近的输入（上图编号12所示）有关，上图编号6所示的输出，基本上很难受到序列靠前的输入（上图编号10所示）的影响，这是因为不管输出是什么，不管是对的，还是错的，这个区域都很难反向传播到序列的前面部分，也因此网络很难调整序列前面的计算。这是基本的RNN算法的一个缺点，我们会在下几节视频里处理这个问题。如果不管的话，RNN会不擅长处理长期依赖的问题。 尽管我们一直在讨论梯度消失问题，但是，你应该记得我们在讲很深的神经网络时，我们也提到了梯度爆炸，我们在反向传播的时候，随着层数的增多，梯度不仅可能指数型的下降，也可能指数型的上升。事实上梯度消失在训练RNN时是首要的问题，尽管梯度爆炸也是会出现，但是梯度爆炸很明显，因为指数级大的梯度会让你的参数变得极其大，以至于你的网络参数崩溃。所以梯度爆炸很容易发现，因为参数会大到崩溃，你会看到很多NaN，或者不是数字的情况，这意味着你的网络计算出现了数值溢出。如果你发现了梯度爆炸的问题，一个解决方法就是用梯度修剪。梯度修剪的意思就是观察你的梯度向量，如果它大于某个阈值，缩放梯度向量，保证它不会太大，这就是通过一些最大值来修剪的方法。所以如果你遇到了梯度爆炸，如果导数值很大，或者出现了NaN，就用梯度修剪，这是相对比较鲁棒的，这是梯度爆炸的解决方法。然而梯度消失更难解决，这也是我们下几节视频的主题。 总结一下，在前面的课程，我们了解了训练很深的神经网络时，随着层数的增加，导数有可能指数型的下降或者指数型的增加，我们可能会遇到梯度消失或者梯度爆炸的问题。加入一个RNN处理1,000个时间序列的数据集或者10,000个时间序列的数据集，这就是一个1,000层或者10,000层的神经网络，这样的网络就会遇到上述类型的问题。梯度爆炸基本上用梯度修剪就可以应对，但梯度消失比较棘手。我们下节会介绍GRU，门控循环单元网络，这个网络可以有效地解决梯度消失的问题，并且能够使你的神经网络捕获更长的长期依赖，我们去下个视频一探究竟吧。 1.9 GRU单元（Gated Recurrent Unit（GRU））你已经了解了基础的RNN模型的运行机制，在本节视频中你将会学习门控循环单元，它改变了RNN的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题，让我们看一看。 你已经见过了这个公式，$a^{&lt; t &gt;} = g(W_{a}\left\lbrack a^{&lt; t - 1 &gt;},x^{&lt; t &gt;}\right\rbrack +b_{a})$，在RNN的时间$t$处，计算激活值。我把这个画个图，把RNN的单元画个图，画一个方框，输入$a^{&lt;t-1&gt;}$（上图编号1所示），即上一个时间步的激活值，再输入$x^{&lt;t&gt;}$（上图编号2所示），再把这两个并起来，然后乘上权重项，在这个线性计算之后（上图编号3所示），如果$g$是一个tanh激活函数，再经过tanh计算之后，它会计算出激活值$a^{&lt;t&gt;}$。然后激活值$a^{&lt;t&gt;}$将会传softmax单元（上图编号4所示），或者其他用于产生输出$y^{&lt;t&gt;}$的东西。就这张图而言，这就是RNN隐藏层的单元的可视化呈现。我向展示这张图，因为我们将使用相似的图来讲解门控循环单元。 许多GRU的想法都来分别自于Yu Young Chang, Kagawa，Gaza Hera, Chang Hung Chu和Jose Banjo的两篇论文。我再引用上个视频中你已经见过的这个句子，“The cat, which already ate……, was full.”，你需要记得猫是单数的，为了确保你已经理解了为什么这里是was而不是were，“The cat was full.”或者是“The cats were full”。当我们从左到右读这个句子，GRU单元将会有个新的变量称为$c$，代表细胞（cell），即记忆细胞（下图编号1所示）。记忆细胞的作用是提供了记忆的能力，比如说一只猫是单数还是复数，所以当它看到之后的句子的时候，它仍能够判断句子的主语是单数还是复数。于是在时间$t$处，有记忆细胞$c^{&lt;t&gt;}$，然后我们看的是，GRU实际上输出了激活值$a^{&lt;t&gt;}$，$c^{&lt;t&gt;} = a^{&lt;t&gt;}$（下图编号2所示）。于是我们想要使用不同的符号$c$和$a$来表示记忆细胞的值和输出的激活值，即使它们是一样的。我现在使用这个标记是因为当我们等会说到LSTMs的时候，这两个会是不同的值，但是现在对于GRU，$c^{&lt;t&gt;}$的值等于$a^{&lt;t&gt;}$的激活值。 所以这些等式表示了GRU单元的计算，在每个时间步，我们将用一个候选值重写记忆细胞，即${\tilde{c} }^{&lt;t&gt;}$的值，所以它就是个候选值，替代了$c^{&lt;t&gt;}$的值。然后我们用tanh激活函数来计算，${\tilde{c} }^{&lt;t&gt;} =tanh(W_{c}\left\lbrack c^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{c})$，所以${\tilde{c} }^{&lt;t&gt;}$的值就是个替代值，代替表示$c^{&lt;t&gt;}$的值（下图编号3所示）。 重点来了，在GRU中真正重要的思想是我们有一个门，我先把这个门叫做$\Gamma_{u}$（上图编号4所示），这是个下标为$u$的大写希腊字母$\Gamma$，$u$代表更新门，这是一个0到1之间的值。为了让你直观思考GRU的工作机制，先思考$\Gamma_{u}$，这个一直在0到1之间的门值，实际上这个值是把这个式子带入sigmoid函数得到的，$\Gamma_{u}= \sigma(W_{u}\left\lbrack c^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{u})$。我们还记得sigmoid函数是上图编号5所示这样的，它的输出值总是在0到1之间，对于大多数可能的输入，sigmoid函数的输出总是非常接近0或者非常接近1。在这样的直觉下，可以想到$\Gamma_{u}$在大多数的情况下非常接近0或1。然后这个字母u表示“update”，我选了字母$\Gamma$是因为它看起来像门。还有希腊字母G，G是门的首字母，所以G表示门。 然后GRU的关键部分就是上图编号3所示的等式，我们刚才写出来的用$\tilde{c}$更新$c$的等式。然后门决定是否要真的更新它。于是我们这么看待它，记忆细胞$c^{&lt;t&gt;}$将被设定为0或者1，这取决于你考虑的单词在句子中是单数还是复数，因为这里是单数情况，所以我们先假定它被设为了1，或者如果是复数的情况我们就把它设为0。然后GRU单元将会一直记住$c^{&lt;t&gt;}$的值，直到上图编号7所示的位置，$c^{&lt;t&gt;}$的值还是1，这就告诉它，噢，这是单数，所以我们用was。于是门，即$\Gamma_{u}$的作用就是决定什么时候你会更新这个值，特别是当你看到词组the cat，即句子的主语猫，这就是一个好时机去更新这个值。然后当你使用完它的时候，“The cat, which already ate……, was full.”，然后你就知道，我不需要记住它了，我可以忘记它了。 所以我们接下来要给GRU用的式子就是$c^{&lt;t&gt;} = \Gamma_{u}{\tilde{c} }^{&lt;t&gt;} +\left( 1- \Gamma_{u} \right)c^{&lt;t-1&gt;}$（上图编号1所示）。你应该注意到了，如果这个更新值$\Gamma_{u} =1$，也就是说把这个新值，即$c^{&lt;t&gt;}$设为候选值（$\Gamma_{u} =1$时简化上式，$c^{&lt;t&gt;} = {\tilde{c} }^{&lt;t&gt;}$）。将门值设为1（上图编号2所示），然后往前再更新这个值。对于所有在这中间的值，你应该把门的值设为0，即$\Gamma_{u}= 0$，意思就是说不更新它，就用旧的值。因为如果$\Gamma_{u} = 0$，则$c^{&lt;t&gt;} =c^{&lt;t-1&gt;}$，$c^{&lt;t&gt;}$等于旧的值。甚至你从左到右扫描这个句子，当门值为0的时候（上图编号3所示，中间$\Gamma_{u}=0$一直为0，表示一直不更新），就是说不更新它的时候，不要更新它，就用旧的值，也不要忘记这个值是什么，这样即使你一直处理句子到上图编号4所示，$c^{&lt;t&gt;}$应该会一直等$c^{&lt;t-1&gt;}$，于是它仍然记得猫是单数的。 让我再画个图来（下图所示）解释一下GRU单元，顺便说一下，当你在看网络上的博客或者教科书或者教程之类的，这些图对于解释GRU和我们稍后会讲的LSTM是相当流行的，我个人感觉式子在图片中比较容易理解，那么即使看不懂图片也没关系，我就画画，万一能帮得上忙就最好了。 GRU单元输入$c^{&lt;t-1&gt;}$（下图编号1所示），对于上一个时间步，先假设它正好等于$a^{&lt;t-1&gt;}$，所以把这个作为输入。然后$x^{&lt;t&gt;}$也作为输入（下图编号2所示），然后把这两个用合适权重结合在一起，再用tanh计算，算出${\tilde{c} }^{&lt;t&gt;}$，${\tilde{c} }^{&lt;t&gt;} =tanh(W_{c}\left\lbrack c^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{c})$，即$c^{&lt;t&gt;}$的替代值。 再用一个不同的参数集，通过sigmoid激活函数算出$\Gamma_{u}$，$\Gamma_{u}= \sigma(W_{u}\left\lbrack c^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{u})$，即更新门。最后所有的值通过另一个运算符结合，我并不会写出公式，但是我用紫色阴影标注的这个方框（下图编号5所示，其所代表的运算过程即下图编号13所示的等式），代表了这个式子。所以这就是紫色运算符所表示的是，它输入一个门值（下图编号6所示），新的候选值（下图编号7所示），这再有一个门值（下图编号8所示）和$c^{&lt;t&gt;}$的旧值（下图编号9所示），所以它把这个（下图编号1所示）、这个（下图编号3所示）和这个（下图编号4所示）作为输入一起产生记忆细胞的新值$c^{&lt;t&gt;}$，所以$c^{&lt;t&gt;}$等于$a^{&lt;t&gt;}$。如果你想，你也可以也把这个代入softmax或者其他预测$y^{&lt;t&gt;}$的东西。 这就是GRU单元或者说是一个简化过的GRU单元，它的优点就是通过门决定，当你从左（上图编号10所示）到右扫描一个句子的时候，这个时机是要更新某个记忆细胞，还是不更新，不更新（上图编号11所示，中间$\Gamma_{u}=0$一直为0，表示一直不更新）直到你到你真的需要使用记忆细胞的时候（上图编号12所示），这可能在句子之前就决定了。因为sigmoid的值，现在因为门很容易取到0值，只要这个值是一个很大的负数，再由于数值上的四舍五入，上面这些门大体上就是0，或者说非常非常非常接近0。所以在这样的情况下，这个更新式子（上图编号13所示的等式）就会变成$c^{&lt;t&gt;} = c^{&lt;t-1&gt;}$，这非常有利于维持细胞的值。因为$\Gamma_{u}$很接近0，可能是0.000001或者更小，这就不会有梯度消失的问题了。因为$\Gamma_{u}$很接近0，这就是说$c^{&lt;t&gt;}$几乎就等于$c^{&lt;t-1&gt;}$，而且$c^{&lt;t&gt;}$的值也很好地被维持了，即使经过很多很多的时间步（上图编号14所示）。这就是缓解梯度消失问题的关键，因此允许神经网络运行在非常庞大的依赖词上，比如说cat和was单词即使被中间的很多单词分割开。 现在我想说下一些实现的细节，在这个我写下的式子中$c^{&lt;t&gt;}$可以是一个向量（上图编号1所示），如果你有100维的隐藏的激活值，那么$c^{&lt;t&gt;}$也是100维的，${\tilde{c} }^{&lt;t&gt;}$也是相同的维度（${\tilde{c} }^{&lt;t&gt;} =tanh(W_{c}\left\lbrack c^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{c})$），$\Gamma_{u}$也是相同的维度（$\Gamma_{u}= \sigma(W_{u}\left\lbrack c^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{u})$），还有画在框中的其他值。这样的话“*”实际上就是元素对应的乘积（$c^{&lt;t&gt;} = \Gamma_{u}{\tilde{c} }^{&lt;t&gt;} +\left( 1- \Gamma_{u} \right)c^{&lt;t-1&gt;}$），所以这里的$\Gamma_{u}$：（$\Gamma_{u}= \sigma(W_{u}\left\lbrack c^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{u})$），即如果门是一个100维的向量，$\Gamma_{u}$也就100维的向量，里面的值几乎都是0或者1，就是说这100维的记忆细胞$c^{&lt;t&gt;}$（$c^{&lt;t&gt;}=a^{&lt;t&gt;}$上图编号1所示）就是你要更新的比特。 当然在实际应用中$\Gamma_{u}$不会真的等于0或者1，有时候它是0到1的一个中间值（上图编号5所示），但是这对于直观思考是很方便的，就把它当成确切的0，完全确切的0或者就是确切的1。元素对应的乘积做的就是告诉GRU单元哪个记忆细胞的向量维度在每个时间步要做更新，所以你可以选择保存一些比特不变，而去更新其他的比特。比如说你可能需要一个比特来记忆猫是单数还是复数，其他比特来理解你正在谈论食物，因为你在谈论吃饭或者食物，然后你稍后可能就会谈论“The cat was full.”，你可以每个时间点只改变一些比特。 你现在已经理解GRU最重要的思想了，幻灯片中展示的实际上只是简化过的GRU单元，现在来描述一下完整的GRU单元。 对于完整的GRU单元我要做的一个改变就是在我们计算的第一个式子中给记忆细胞的新候选值加上一个新的项，我要添加一个门$\Gamma_{r}$（下图编号1所示），你可以认为$r$代表相关性（relevance）。这个$\Gamma_{r}$门告诉你计算出的下一个$c^{&lt;t&gt;}$的候选值${\tilde{c} }^{&lt;t&gt;}$跟$c^{&lt;t-1&gt;}$有多大的相关性。计算这个门$\Gamma_{r}$需要参数，正如你看到的这个，一个新的参数矩阵$W_{r}$，$\Gamma_{r}= \sigma(W_{r}\left\lbrack c^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack + b_{r})$。 正如你所见，有很多方法可以来设计这些类型的神经网络，然后我们为什么有$\Gamma_{r}$？为什么不用上一张幻灯片里的简单的版本？这是因为多年来研究者们试验过很多很多不同可能的方法来设计这些单元，去尝试让神经网络有更深层的连接，去尝试产生更大范围的影响，还有解决梯度消失的问题，GRU就是其中一个研究者们最常使用的版本，也被发现在很多不同的问题上也是非常健壮和实用的。你可以尝试发明新版本的单元，只要你愿意。但是GRU是一个标准版本，也就是最常使用的。你可以想象到研究者们也尝试了很多其他版本，类似这样的但不完全是，比如我这里写的这个。然后另一个常用的版本被称为LSTM，表示长短时记忆网络，这个我们会在下节视频中讲到，但是GRU和LSTM是在神经网络结构中最常用的两个具体实例。 还有在符号上的一点，我尝试去定义固定的符号让这些概念容易理解，如果你看学术文章的话，你有的时候会看到有些人使用另一种符号$\tilde{x}$，$u$，$r$和$h$表示这些量。但我试着在GRU和LSTM之间用一种更固定的符号，比如使用更固定的符号$\Gamma$来表示门，所以希望这能让这些概念更好理解。 所以这就是GRU，即门控循环单元，这是RNN的其中之一。这个结构可以更好捕捉非常长范围的依赖，让RNN更加有效。然后我简单提一下其他常用的神经网络，比较经典的是这个叫做LSTM，即长短时记忆网络，我们在下节视频中讲解。 （Chung J, Gulcehre C, Cho K H, et al. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling[J]. Eprint Arxiv, 2014. Cho K, Merrienboer B V, Bahdanau D, et al. On the Properties of Neural Machine Translation: Encoder-Decoder Approaches[J]. Computer Science, 2014.） 1.10 长短期记忆（LSTM（long short term memory）unit）在上一个视频中你已经学了GRU（门控循环单元）。它能够让你可以在序列中学习非常深的连接。其他类型的单元也可以让你做到这个，比如LSTM即长短时记忆网络，甚至比GRU更加有效，让我们看看。 这里是上个视频中的式子，对于GRU我们有$a^{&lt; t &gt;} = c^{&lt;t&gt;}$。 还有两个门: 更新门$\Gamma_{u}$（the update gate） 相关门$\Gamma_{r}$（the relevance gate） ${\tilde{c} }^{&lt;t&gt;}$，这是代替记忆细胞的候选值，然后我们使用更新门$\Gamma_{u}$来决定是否要用${\tilde{c} }^{&lt;t&gt;}$ 更新$c^{&lt;t&gt;}$。 LSTM是一个比GRU更加强大和通用的版本，这多亏了 Sepp Hochreiter和 Jurgen Schmidhuber，感谢那篇开创性的论文，它在序列模型上有着巨大影响。我感觉这篇论文是挺难读懂的，虽然我认为这篇论文在深度学习社群有着重大的影响，它深入讨论了梯度消失的理论，我感觉大部分的人学到LSTM的细节是在其他的地方，而不是这篇论文。 这就是LSTM主要的式子（上图编号2所示），我们继续回到记忆细胞c上面来，使用${\tilde{c} }^{&lt;t&gt;} = tanh(W_{c}\left\lbrack a^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{c}$来更新它的候选值${\tilde{c} }^{&lt;t&gt;}$（上图编号3所示）。注意了，在LSTM中我们不再有$a^{&lt;t&gt;} = c^{&lt;t&gt;}$的情况，这是现在我们用的是类似于左边这个式子（上图编号4所示），但是有一些改变，现在我们专门使用$a^{&lt;t&gt;}$或者$a^{&lt;t-1&gt;}$，而不是用$c^{&lt;t-1&gt;}$，我们也不用$\Gamma_{r}$，即相关门。虽然你可以使用LSTM的变体，然后把这些东西（左边所示的GRU公式）都放回来，但是在更加典型的LSTM里面，我们先不那样做。 我们像以前那样有一个更新门$\Gamma_{u}$和表示更新的参数$W_{u}$，$\Gamma_{u}= \sigma(W_{u}\left\lbrack a^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{u})$（上图编号5所示）。一个LSTM的新特性是不只有一个更新门控制，这里的这两项（上图编号6，7所示），我们将用不同的项来代替它们，要用别的项来取代$\Gamma_{u}$和$1-\Gamma_{u}$，这里（上图编号6所示）我们用$\Gamma_{u}$。 然后这里（上图编号7所示）用遗忘门（the forget gate），我们叫它$\Gamma_{f}$，所以这个$\Gamma_{f} =\sigma(W_{f}\left\lbrack a^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{f})$（上图编号8所示）； 然后我们有一个新的输出门，$\Gamma_{o} =\sigma(W_{o}\left\lbrack a^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +&gt;b_{o})$（上图编号9所示）； 于是记忆细胞的更新值$c^{&lt;t&gt;} =\Gamma_{u}{\tilde{c} }^{&lt;t&gt;} + \Gamma_{f}c^{&lt;t-1&gt;}$（上图编号10所示）； 所以这给了记忆细胞选择权去维持旧的值$c^{&lt;t-1&gt;}$或者就加上新的值${\tilde{c} }^{&lt;t&gt;}$，所以这里用了单独的更新门$\Gamma_{u}$和遗忘门$\Gamma_{f}$， 然后这个表示更新门（$\Gamma_{u}= \sigma(W_{u}\left\lbrack a^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{u})$上图编号5所示）； 遗忘门（$\Gamma_{f} =\sigma(W_{f}\left\lbrack a^{&lt;t-1&gt;},x^{&lt;t&gt;} \right\rbrack +b_{f})$上图编号8所示）和输出门（上图编号9所示）。 最后$a^{&lt;t&gt;} = c^{&lt;t&gt;}$的式子会变成$a^{&lt;t&gt;} = \Gamma_{o}c^{&lt;t&gt;}$。这就是*LSTM**主要的式子了，然后这里（上图编号11所示）有三个门而不是两个，这有点复杂，它把门放到了和之前有点不同的地方。 再提一下，这些式子就是控制LSTM行为的主要的式子了（上图编号1所示）。像之前一样用图片稍微解释一下，先让我把图画在这里（上图编号2所示）。如果图片过于复杂，别担心，我个人感觉式子比图片好理解，但是我画图只是因为它比较直观。这个右上角的图的灵感来自于Chris Ola的一篇博客，标题是《理解LSTM网络》（Understanding LSTM Network），这里的这张图跟他博客上的图是很相似的，但关键的不同可能是这里的这张图用了$a^{&lt;t-1&gt;}$和$x^{&lt;t&gt;}$来计算所有门值（上图编号3，4所示），在这张图里是用$a^{&lt;t-1&gt;}$， $x^{&lt;t&gt;}$一起来计算遗忘门$\Gamma_{f}$的值，还有更新门$\Gamma_{u}$以及输出门$\Gamma_{o}$（上图编号4所示）。然后它们也经过tanh函数来计算${\tilde{c} }^{&lt;t&gt;}$（上图编号5所示），这些值被用复杂的方式组合在一起，比如说元素对应的乘积或者其他的方式来从之前的$c^{&lt;t-1&gt;}$（上图编号6所示）中获得$c^{&lt;t&gt;}$（上图编号7所示）。 这里其中一个元素很有意思，如你在这一堆图（上图编号8所示的一系列图片）中看到的，这是其中一个，再把他们连起来，就是把它们按时间次序连起来，这里（上图编号9所示）输入$x^{&lt;1&gt;}$，然后$x^{&lt;2&gt;}$，$x^{&lt;3&gt;}$，然后你可以把这些单元依次连起来，这里输出了上一个时间的$a$，$a$会作为下一个时间步的输入，$c$同理。在下面这一块，我把图简化了一下（相对上图编号2所示的图有所简化）。然后这有个有意思的事情，你会注意到上面这里有条线（上图编号10所示的线），这条线显示了只要你正确地设置了遗忘门和更新门，LSTM是相当容易把$c^{&lt;0&gt;}$的值（上图编号11所示）一直往下传递到右边，比如$c^{&lt;3&gt;} = c^{&lt;0&gt;}$（上图编号12所示）。这就是为什么LSTM和GRU非常擅长于长时间记忆某个值，对于存在记忆细胞中的某个值，即使经过很长很长的时间步。 这就是LSTM，你可能会想到这里和一般使用的版本会有些不同，最常用的版本可能是门值不仅取决于$a^{&lt;t-1&gt;}$和$x^{&lt;t&gt;}$，有时候也可以偷窥一下$c^{&lt;t-1&gt;}$的值（上图编号13所示），这叫做“窥视孔连接”（peephole connection）。虽然不是个好听的名字，但是你想，“偷窥孔连接”其实意思就是门值不仅取决于$a^{&lt;t-1&gt;}$和$x^{&lt;t&gt;}$，也取决于上一个记忆细胞的值（$c^{&lt;t-1&gt;}$），然后“偷窥孔连接”就可以结合这三个门（$\Gamma_{u}$、$\Gamma_{f}$、$\Gamma_{o}$）来计算了。 如你所见LSTM主要的区别在于一个技术上的细节，比如这（上图编号13所示）有一个100维的向量，你有一个100维的隐藏的记忆细胞单元，然后比如第50个$c^{&lt;t-1&gt;}$的元素只会影响第50个元素对应的那个门，所以关系是一对一的，于是并不是任意这100维的$c^{&lt;t-1&gt;}$可以影响所有的门元素。相反的，第一个$c^{&lt;t-1&gt;}$的元素只能影响门的第一个元素，第二个元素影响对应的第二个元素，如此类推。但如果你读过论文，见人讨论“偷窥孔连接”，那就是在说$c^{&lt;t-1&gt;}$也能影响门值。 LSTM前向传播图： LSTM反向传播计算： 门求偏导： $d \Gamma_o^{\langle t \rangle} = da_{next}\tanh(c_{next}) * \Gamma_o^{\langle t \rangle}(1-\Gamma_o^{\langle t \rangle})\tag{1}$ $d\tilde c^{\langle t \rangle} = dc_{next}*\Gamma_i^{\langle t \rangle}+ \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) * i_t * da_{next} * \tilde c^{\langle t \rangle} * (1-\tanh(\tilde c)^2) \tag{2}$ $d\Gamma_u^{\langle t \rangle} = dc_{next}\tilde c^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) * \tilde c^{\langle t \rangle} * da_{next}*\Gamma_u^{\langle t \rangle}(1-\Gamma_u^{\langle t \rangle})\tag{3}$ $d\Gamma_f^{\langle t \rangle} = dc_{next}\tilde c_{prev} + \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) * c_{prev} * da_{next}*\Gamma_f^{\langle t \rangle}(1-\Gamma_f^{\langle t \rangle})\tag{4}$ 参数求偏导 ： $ dW_f = d\Gamma_f^{\langle t \rangle} * \begin{pmatrix} a_{prev} \ x_t\end{pmatrix}^T \tag{5} $$ dW_u = d\Gamma_u^{\langle t \rangle} * \begin{pmatrix} a_{prev} \ x_t\end{pmatrix}^T \tag{6} $$ dW_c = d\tilde c^{\langle t \rangle} * \begin{pmatrix} a_{prev} \ x_t\end{pmatrix}^T \tag{7} $$ dW_o = d\Gamma_o^{\langle t \rangle} * \begin{pmatrix} a_{prev} \ x_t\end{pmatrix}^T \tag{8}$ 为了计算$db_f, db_u, db_c, db_o$ 需要各自对$d\Gamma_f^{\langle t \rangle}, d\Gamma_u^{\langle t \rangle}, d\tilde c^{\langle t \rangle}, d\Gamma_o^{\langle t \rangle}$ 求和。 最后，计算隐藏状态、记忆状态和输入的偏导数： $ da_{prev} = W_f^T*d\Gamma_f^{\langle t \rangle} + W_u^T * d\Gamma_u^{\langle t \rangle}+ W_c^T * d\tilde c^{\langle t \rangle} + W_o^T * d\Gamma_o^{\langle t \rangle} \tag{9}$ $ dc_{prev} = dc_{next}\Gamma_f^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} * (1- \tanh(c_{next})^2)\Gamma_f^{\langle t \rangle}da_{next} \tag{10}$$ dx^{\langle t \rangle} = W_f^T*d\Gamma_f^{\langle t \rangle} + W_u^T * d\Gamma_u^{\langle t \rangle}+ W_c^T * d\tilde c_t + W_o^T * d\Gamma_o^{\langle t \rangle}\tag{11} $ 这就是LSTM，我们什么时候应该用GRU？什么时候用LSTM？这里没有统一的准则。而且即使我先讲解了GRU，在深度学习的历史上，LSTM也是更早出现的，而GRU是最近才发明出来的，它可能源于Pavia在更加复杂的LSTM模型中做出的简化。研究者们在很多不同问题上尝试了这两种模型，看看在不同的问题不同的算法中哪个模型更好，所以这不是个学术和高深的算法，我才想要把这两个模型展示给你。 GRU的优点是这是个更加简单的模型，所以更容易创建一个更大的网络，而且它只有两个门，在计算性上也运行得更快，然后它可以扩大模型的规模。 但是LSTM更加强大和灵活，因为它有三个门而不是两个。如果你想选一个使用，我认为LSTM在历史进程上是个更优先的选择，所以如果你必须选一个，我感觉今天大部分的人还是会把LSTM作为默认的选择来尝试。虽然我认为最近几年GRU获得了很多支持，而且我感觉越来越多的团队也正在使用GRU，因为它更加简单，而且还效果还不错，它更容易适应规模更加大的问题。 所以这就是LSTM，无论是GRU还是LSTM，你都可以用它们来构建捕获更加深层连接的神经网络。 （Hochreiter S, Schmidhuber J. Long Short-Term Memory[J]. Neural Computation, 1997, 9(8):1735-1780.） 1.11 双向循环神经网络（Bidirectional RNN）现在，你已经了解了大部分RNN模型的关键的构件，还有两个方法可以让你构建更好的模型，其中之一就是双向RNN模型，这个模型可以让你在序列的某点处不仅可以获取之前的信息，还可以获取未来的信息，我们会在这个视频里讲解。第二个就是深层的RNN，我们会在下个视频里见到，现在先从双向RNN开始吧。 为了了解双向RNN的动机，我们先看一下之前在命名实体识别中已经见过多次的神经网络。这个网络有一个问题，在判断第三个词Teddy（上图编号1所示）是不是人名的一部分时，光看句子前面部分是不够的，为了判断$\hat y^{&lt;3&gt;}$（上图编号2所示）是0还是1，除了前3个单词，你还需要更多的信息，因为根据前3个单词无法判断他们说的是Teddy熊，还是前美国总统Teddy Roosevelt，所以这是一个非双向的或者说只有前向的RNN。我刚才所说的总是成立的，不管这些单元（上图编号3所示）是标准的RNN块，还是GRU单元或者是LSTM单元，只要这些构件都是只有前向的。 那么一个双向的RNN是如何解决这个问题的？下面解释双向RNN的工作原理。为了简单，我们用四个输入或者说一个只有4个单词的句子，这样输入只有4个，$x^{&lt;1&gt;}$到$x^{&lt;4&gt;}$。从这里开始的这个网络会有一个前向的循环单元叫做${\overrightarrow{a} }^{&lt;1&gt;}$，${\overrightarrow{a} }^{&lt;2&gt;}$，${\overrightarrow{a} }^{&lt;3&gt;}$还有${\overrightarrow{a} }^{&lt;4&gt;}$，我在这上面加个向右的箭头来表示前向的循环单元，并且他们这样连接（下图编号1所示）。这四个循环单元都有一个当前输入$x$输入进去，得到预测的$\hat y^{&lt;1&gt;}$，$\hat y^{&lt;2&gt;}$，$\hat y^{&lt;3&gt;}$和$\hat y^{&lt;4&gt;}$。 到目前为止，我还没做什么，仅仅是把前面幻灯片里的RNN画在了这里，只是在这些地方画上了箭头。我之所以在这些地方画上了箭头是因为我们想要增加一个反向循环层，这里有个${\overleftarrow{a} }^{&lt;1&gt;}$，左箭头代表反向连接，${\overleftarrow{a} }^{&lt;2&gt;}$反向连接，${\overleftarrow{a} }^{&lt;3&gt;}$反向连接，${\overleftarrow{a} }^{&lt;4&gt;}$反向连接，所以这里的左箭头代表反向连接。 同样，我们把网络这样向上连接，这个$a$反向连接就依次反向向前连接（上图编号2所示）。这样，这个网络就构成了一个无环图。给定一个输入序列$x^{&lt;1&gt;}$到$x^{&lt;4&gt;}$，这个序列首先计算前向的${\overrightarrow{a} }^{&lt;1&gt;}$，然后计算前向的${\overrightarrow{a} }^{&lt;2&gt;}$，接着${\overrightarrow{a} }^{&lt;3&gt;}$，${\overrightarrow{a} }^{&lt;4&gt;}$。而反向序列从计算${\overleftarrow{a} }^{&lt;4&gt;}$开始，反向进行，计算反向的${\overleftarrow{a} }^{&lt;3&gt;}$。你计算的是网络激活值，这不是反向而是前向的传播，而图中这个前向传播一部分计算是从左到右，一部分计算是从右到左。计算完了反向的${\overleftarrow{a} }^{&lt;3&gt;}$，可以用这些激活值计算反向的${\overleftarrow{a} }^{&lt;2&gt;}$，然后是反向的${\overleftarrow{a} }^{&lt;1&gt;}$，把所有这些激活值都计算完了就可以计算预测结果了。 举个例子，为了预测结果，你的网络会有如$\hat y^{&lt;t&gt;}$，$\hat y^{&lt;t&gt;} =g(W_{g}\left\lbrack {\overrightarrow{a} }^{&lt; t &gt;},{\overleftarrow{a} }^{&lt; t &gt;} \right\rbrack +b_{y})$（上图编号1所示）。比如你要观察时间3这里的预测结果，信息从$x^{&lt;1&gt;}$过来，流经这里，前向的${\overrightarrow{a} }^{&lt;1&gt;}$到前向的${\overrightarrow{a} }^{&lt;2&gt;}$，这些函数里都有表达，到前向的${\overrightarrow{a} }^{&lt;3&gt;}$再到$\hat y^{&lt;3&gt;}$（上图编号2所示的路径），所以从$x^{&lt;1&gt;}$，$x^{&lt;2&gt;}$，$x^{&lt;3&gt;}$来的信息都会考虑在内，而从$x^{&lt;4&gt;}$来的信息会流过反向的${\overleftarrow{a} }^{&lt;4&gt;}$，到反向的${\overleftarrow{a} }^{&lt;3&gt;}$再到$\hat y^{&lt;3&gt;}$（上图编号3所示的路径）。这样使得时间3的预测结果不仅输入了过去的信息，还有现在的信息，这一步涉及了前向和反向的传播信息以及未来的信息。给定一个句子”He said Teddy Roosevelt…“来预测Teddy是不是人名的一部分，你需要同时考虑过去和未来的信息。 这就是双向循环神经网络，并且这些基本单元不仅仅是标准RNN单元，也可以是GRU单元或者LSTM单元。事实上，很多的NLP问题，对于大量有自然语言处理问题的文本，有LSTM单元的双向RNN模型是用的最多的。所以如果有NLP问题，并且文本句子都是完整的，首先需要标定这些句子，一个有LSTM单元的双向RNN模型，有前向和反向过程是一个不错的首选。 以上就是双向RNN的内容，这个改进的方法不仅能用于基本的RNN结构，也能用于GRU和LSTM。通过这些改变，你就可以用一个用RNN或GRU或LSTM构建的模型，并且能够预测任意位置，即使在句子的中间，因为模型能够考虑整个句子的信息。这个双向RNN网络模型的缺点就是你需要完整的数据的序列，你才能预测任意位置。比如说你要构建一个语音识别系统，那么双向RNN模型需要你考虑整个语音表达，但是如果直接用这个去实现的话，你需要等待这个人说完，然后获取整个语音表达才能处理这段语音，并进一步做语音识别。对于实际的语音识别的应用通常会有更加复杂的模块，而不是仅仅用我们见过的标准的双向RNN模型。但是对于很多自然语言处理的应用，如果你总是可以获取整个句子，这个标准的双向RNN算法实际上很高效。 好的，这就是双向RNN，下一个视频，也是这周的最后一个，我们会讨论如何用这些概念，标准的RNN，LSTM单元，GRU单元，还有双向的版本，构建更深的网络。 1.12 深层循环神经网络（Deep RNNs）目前你学到的不同RNN的版本，每一个都可以独当一面。但是要学习非常复杂的函数，通常我们会把RNN的多个层堆叠在一起构建更深的模型。这节视频里我们会学到如何构建这些更深的RNN。 一个标准的神经网络，首先是输入$x$，然后堆叠上隐含层，所以这里应该有激活值，比如说第一层是$a^{\left\lbrack 1 \right\rbrack}$，接着堆叠上下一层，激活值$a^{\left\lbrack 2 \right\rbrack}$，可以再加一层$a^{\left\lbrack 3 \right\rbrack}$，然后得到预测值$\hat{y}$。深层的RNN网络跟这个有点像，用手画的这个网络（下图编号1所示），然后把它按时间展开就是了，我们看看。 这是我们一直见到的标准的RNN（上图编号3所示方框内的RNN），只是我把这里的符号稍微改了一下，不再用原来的$a^{&lt;0 &gt;}$表示0时刻的激活值了，而是用$a^{\lbrack 1\rbrack &lt;0&gt;}$来表示第一层（上图编号4所示），所以我们现在用$a^{\lbrack l\rbrack &lt;t&gt;}$来表示第l层的激活值，这个$\&lt;t\&gt;$表示第$t$个时间点，这样就可以表示。第一层第一个时间点的激活值$a^{\lbrack 1\rbrack &lt;1&gt;}$，这（$a^{\lbrack 1\rbrack &lt;2&gt;}$）就是第一层第二个时间点的激活值，$a^{\lbrack 1\rbrack &lt;3&gt;}$和$a^{\lbrack 1\rbrack &lt;4&gt;}$。然后我们把这些（上图编号4方框内所示的部分）堆叠在上面，这就是一个有三个隐层的新的网络。 我们看个具体的例子，看看这个值（$a^{\lbrack 2\rbrack &lt;3&gt;}$，上图编号5所示）是怎么算的。激活值$a^{\lbrack 2\rbrack &lt;3&gt;}$有两个输入，一个是从下面过来的输入（上图编号6所示），还有一个是从左边过来的输入（上图编号7所示），$a^{\lbrack 2\rbrack &lt; 3 &gt;} = g(W_{a}^{\left\lbrack 2 \right\rbrack}\left\lbrack a^{\left\lbrack 2 \right\rbrack &lt; 2 &gt;},a^{\left\lbrack 1 \right\rbrack &lt; 3 &gt;} \right\rbrack + b_{a}^{\left\lbrack 2 \right\rbrack})$，这就是这个激活值的计算方法。参数$W_{a}^{\left\lbrack 2 \right\rbrack}$和$b_{a}^{\left\lbrack 2 \right\rbrack}$在这一层的计算里都一样，相对应地第一层也有自己的参数$W_{a}^{\left\lbrack 1 \right\rbrack}$和$b_{a}^{\left\lbrack 1 \right\rbrack}$。 对于像左边这样标准的神经网络，你可能见过很深的网络，甚至于100层深，而对于RNN来说，有三层就已经不少了。由于时间的维度，RNN网络会变得相当大，即使只有很少的几层，很少会看到这种网络堆叠到100层。但有一种会容易见到，就是在每一个上面堆叠循环层，把这里的输出去掉（上图编号1所示），然后换成一些深的层，这些层并不水平连接，只是一个深层的网络，然后用来预测$y^{&lt;1&gt;}$。同样这里（上图编号2所示）也加上一个深层网络，然后预测$y^{&lt;2&gt;}$。这种类型的网络结构用的会稍微多一点，这种结构有三个循环单元，在时间上连接，接着一个网络在后面接一个网络，当然$y^{&lt;3&gt;}$和$y^{&lt;4&gt;}$也一样，这是一个深层网络，但没有水平方向上的连接，所以这种类型的结构我们会见得多一点。通常这些单元（上图编号3所示）没必要非是标准的RNN，最简单的RNN模型，也可以是GRU单元或者LSTM单元，并且，你也可以构建深层的双向RNN网络。由于深层的RNN训练需要很多计算资源，需要很长的时间，尽管看起来没有多少循环层，这个也就是在时间上连接了三个深层的循环层，你看不到多少深层的循环层，不像卷积神经网络一样有大量的隐含层。 这就是深层RNN的内容，从基本的RNN网络，基本的循环单元到GRU，LSTM，再到双向RNN，还有深层版的模型。这节课后，你已经可以构建很不错的学习序列的模型了。 自然语言处理与词嵌入（Natural Language Processing and Word Embeddings）2.1 词汇表征（Word Representation）上周我们学习了RNN、GRU单元和LSTM单元。本周你会看到我们如何把这些知识用到NLP上，用于自然语言处理，深度学习已经给这一领域带来了革命性的变革。其中一个很关键的概念就是词嵌入（word embeddings），这是语言表示的一种方式，可以让算法自动的理解一些类似的词，比如男人对女人，比如国王对王后，还有其他很多的例子。通过词嵌入的概念你就可以构建NLP应用了，即使你的模型标记的训练集相对较小。这周的最后我们会消除词嵌入的偏差，就是去除不想要的特性，或者学习算法有时会学到的其他类型的偏差。 现在我们先开始讨论词汇表示，目前为止我们一直都是用词汇表来表示词，上周提到的词汇表，可能是10000个单词，我们一直用one-hot向量来表示词。比如如果man（上图编号1所示）在词典里是第5391个，那么就可以表示成一个向量，只在第5391处为1（上图编号2所示），我们用$O_{5391}$代表这个量，这里的$O$代表one-hot。接下来，如果woman是编号9853（上图编号3所示），那么就可以用$O_{9853}$来表示，这个向量只在9853处为1（上图编号4所示），其他为0，其他的词king、queen、apple、orange都可以这样表示出来这种表示方法的一大缺点就是它把每个词孤立起来，这样使得算法对相关词的泛化能力不强。 举个例子，假如你已经学习到了一个语言模型，当你看到“I want a glass of orange ___”，那么下一个词会是什么？很可能是juice。即使你的学习算法已经学到了“I want a glass of orange juice”这样一个很可能的句子，但如果看到“I want a glass of apple ___”，因为算法不知道apple和orange的关系很接近，就像man和woman，king和queen一样。所以算法很难从已经知道的orange juice是一个常见的东西，而明白apple juice也是很常见的东西或者说常见的句子。这是因为任何两个one-hot向量的内积都是0，如果你取两个向量，比如king和queen，然后计算它们的内积，结果就是0。如果用apple和orange来计算它们的内积，结果也是0。很难区分它们之间的差别，因为这些向量内积都是一样的，所以无法知道apple和orange要比king和orange，或者queen和orange相似地多。 换一种表示方式会更好，如果我们不用one-hot表示，而是用特征化的表示来表示每个词，man，woman，king，queen，apple，orange或者词典里的任何一个单词，我们学习这些词的特征或者数值。 举个例子，对于这些词，比如我们想知道这些词与Gender（性别）的关系。假定男性的性别为-1，女性的性别为+1，那么man的性别值可能就是-1，而woman就是-1。最终根据经验king就是-0.95，queen是+0.97，apple和orange没有性别可言。 另一个特征可以是这些词有多Royal（高贵），所以这些词，man，woman和高贵没太关系，所以它们的特征值接近0。而king和queen很高贵，apple和orange跟高贵也没太大关系。 那么Age（年龄）呢？man和woman一般没有年龄的意思，也许man和woman隐含着成年人的意思，但也可能是介于young和old之间，所以它们（man和woman）的值也接近0。而通常king和queen都是成年人，apple和orange跟年龄更没什么关系了。 还有一个特征，这个词是否是Food（食物），man不是食物，woman不是食物，king和queen也不是，但apple和orange是食物。 当然还可以有很多的其他特征，从Size（尺寸大小），Cost（花费多少），这个东西是不是alive（活的），是不是一个Action（动作），或者是不是Noun（名词）或者是不是Verb（动词），还是其他的等等。 所以你可以想很多的特征，为了说明，我们假设有300个不同的特征，这样的话你就有了这一列数字（上图编号1所示），这里我只写了4个，实际上是300个数字，这样就组成了一个300维的向量来表示man这个词。接下来，我想用$e_{5391}$这个符号来表示，就像这样（上图编号2所示）。同样这个300维的向量，我用$e_{9853}$代表这个300维的向量用来表示woman这个词（上图编号3所示），这些其他的例子也一样。现在，如果用这种表示方法来表示apple和orange这些词，那么apple和orange的这种表示肯定会非常相似，可能有些特征不太一样，因为orange的颜色口味，apple的颜色口味，或者其他的一些特征会不太一样，但总的来说apple和orange的大部分特征实际上都一样，或者说都有相似的值。这样对于已经知道orange juice的算法很大几率上也会明白applejuice这个东西，这样对于不同的单词算法会泛化的更好。 后面的几个视频，我们会找到一个学习词嵌入的方式，这里只是希望你能理解这种高维特征的表示能够比one-hot更好的表示不同的单词。而我们最终学习的特征不会像这里一样这么好理解，没有像第一个特征是性别，第二个特征是高贵，第三个特征是年龄等等这些，新的特征表示的东西肯定会更难搞清楚。尽管如此，接下来要学的特征表示方法却能使算法高效地发现apple和orange会比king和orange，queen和orange更加相似。 如果我们能够学习到一个300维的特征向量，或者说300维的词嵌入，通常我们可以做一件事，把这300维的数据嵌入到一个二维空间里，这样就可以可视化了。常用的可视化算法是t-SNE算法，来自于Laurens van der Maaten 和 Geoff Hinton的论文。如果观察这种词嵌入的表示方法，你会发现man和woman这些词聚集在一块（上图编号1所示），king和queen聚集在一块（上图编号2所示），这些都是人，也都聚集在一起（上图编号3所示）。动物都聚集在一起（上图编号4所示），水果也都聚集在一起（上图编号5所示），像1、2、3、4这些数字也聚集在一起（上图编号6所示）。如果把这些生物看成一个整体，他们也聚集在一起（上图编号7所示）。 在网上你可能会看到像这样的图用来可视化，300维或者更高维度的嵌入。希望你能有个整体的概念，这种词嵌入算法对于相近的概念，学到的特征也比较类似，在对这些概念可视化的时候，这些概念就比较相似，最终把它们映射为相似的特征向量。这种表示方式用的是在300维空间里的特征表示，这叫做嵌入（embeddings）。之所以叫嵌入的原因是，你可以想象一个300维的空间，我画不出来300维的空间，这里用个3维的代替（上图编号8所示）。现在取每一个单词比如orange，它对应一个3维的特征向量，所以这个词就被嵌在这个300维空间里的一个点上了（上图编号9所示），apple这个词就被嵌在这个300维空间的另一个点上了（上图编号10所示）。为了可视化，t-SNE算法把这个空间映射到低维空间，你可以画出一个2维图像然后观察，这就是这个术语嵌入的来源。 词嵌入已经是NLP领域最重要的概念之一了，在自然语言处理领域。本节视频中你已经知道为什么要学习或者使用词嵌入了，下节视频我们会深入讲解如何用这些算法构建NLP算法。 2.2 使用词嵌入（Using Word Embeddings）上一个视频中，你已经了解不同单词的特征化表示了。这节你会看到我们如何把这种表示方法应用到NLP应用中。 我们从一个例子开始，我们继续用命名实体识别的例子，如果你要找出人名，假如有一个句子：“Sally Johnson is an orange farmer.”（Sally Johnson是一个种橙子的农民），你会发现Sally Johnson就是一个人名，所以这里的输出为1。之所以能确定Sally Johnson是一个人名而不是一个公司名，是因为你知道种橙子的农民一定是一个人，前面我们已经讨论过用one-hot来表示这些单词，$x^{&lt;1&gt;}$ ，$x^{&lt; 2 &gt;}$等等。 但是如果你用特征化表示方法，嵌入的向量，也就是我们在上个视频中讨论的。那么用词嵌入作为输入训练好的模型，如果你看到一个新的输入：“Robert Lin is an apple farmer.”（Robert Lin是一个种苹果的农民），因为知道orange和apple很相近，那么你的算法很容易就知道Robert Lin也是一个人，也是一个人的名字。一个有意思的情况是，要是测试集里这句话不是“Robert Lin is an apple farmer.”，而是不太常见的词怎么办？要是你看到：“Robert Lin is a durian cultivator.”（Robert Lin是一个榴莲培育家）怎么办？榴莲（durian）是一种比较稀罕的水果，这种水果在新加坡和其他一些国家流行。如果对于一个命名实体识别任务，你只有一个很小的标记的训练集，你的训练集里甚至可能没有durian（榴莲）或者cultivator（培育家）这两个词。但是如果你有一个已经学好的词嵌入，它会告诉你durian（榴莲）是水果，就像orange（橙子）一样，并且cultivator（培育家），做培育工作的人其实跟farmer（农民）差不多，那么你就有可能从你的训练集里的“an orange farmer”（种橙子的农民）归纳出“a durian cultivator”（榴莲培育家）也是一个人。 词嵌入能够达到这种效果，其中一个原因就是学习词嵌入的算法会考察非常大的文本集，也许是从网上找到的，这样你可以考察很大的数据集可以是1亿个单词，甚至达到100亿也都是合理的，大量的无标签的文本的训练集。通过考察大量的无标签文本，很多都是可以免费下载的，你可以发现orange（橙子）和durian（榴莲）相近，farmer（农民）和cultivator（培育家）相近。因此学习这种嵌入表达，把它们都聚集在一块，通过读取大量的互联网文本发现了orange（橙子）和durian（榴莲）都是水果。接下来你可以把这个词嵌入应用到你的命名实体识别任务当中，尽管你只有一个很小的训练集，也许训练集里有100,000个单词，甚至更小，这就使得你可以使用迁移学习，把你从互联网上免费获得的大量的无标签文本中学习到的知识，能够分辨orange（橙子）、apple（苹果）和durian（榴莲）都是水果的知识，然后把这些知识迁移到一个任务中，比如你只有少量标记的训练数据集的命名实体识别任务中。当然了，这里为了简化我只画了单向的RNN，事实上如果你想用在命名实体识别任务上，你应该用一个双向的RNN，而不是这样一个简单的。 总结一下，这是如何用词嵌入做迁移学习的步骤。 第一步，先从大量的文本集中学习词嵌入。一个非常大的文本集，或者可以下载网上预训练好的词嵌入模型，网上你可以找到不少，词嵌入模型并且都有许可。 第二步，你可以用这些词嵌入模型把它迁移到你的新的只有少量标注训练集的任务中，比如说用这个300维的词嵌入来表示你的单词。这样做的一个好处就是你可以用更低维度的特征向量代替原来的10000维的one-hot向量，现在你可以用一个300维更加紧凑的向量。尽管one-hot向量很快计算，而学到的用于词嵌入的300维的向量会更加紧凑。 第三步，当你在你新的任务上训练模型时，在你的命名实体识别任务上，只有少量的标记数据集上，你可以自己选择要不要继续微调，用新的数据调整词嵌入。实际中，只有这个第二步中有很大的数据集你才会这样做，如果你标记的数据集不是很大，通常我不会在微调词嵌入上费力气。 当你的任务的训练集相对较小时，词嵌入的作用最明显，所以它广泛用于NLP领域。我只提到一些，不要太担心这些术语（下问列举的一些NLP任务），它已经用在命名实体识别，用在文本摘要，用在文本解析、指代消解，这些都是非常标准的NLP任务。 词嵌入在语言模型、机器翻译领域用的少一些，尤其是你做语言模型或者机器翻译任务时，这些任务你有大量的数据。在其他的迁移学习情形中也一样，如果你从某一任务A迁移到某个任务B，只有A中有大量数据，而B中数据少时，迁移的过程才有用。所以对于很多NLP任务这些都是对的，而对于一些语言模型和机器翻译则不然。 最后，词嵌入和人脸编码之间有奇妙的关系，你已经在前面的课程学到了关于人脸编码的知识了，如果你上了卷积神经网络的课程的话。你应该还记得对于人脸识别，我们训练了一个Siamese网络结构，这个网络会学习不同人脸的一个128维表示，然后通过比较编码结果来判断两个图片是否是同一个人脸，这个词嵌入的意思和这个差不多。在人脸识别领域大家喜欢用编码这个词来指代这些向量$f(x^{\left(i \right)})$，$f(x^{\left( j\right)})$（上图编号1所示），人脸识别领域和这里的词嵌入有一个不同就是，在人脸识别中我们训练一个网络，任给一个人脸照片，甚至是没有见过的照片，神经网络都会计算出相应的一个编码结果。上完后面几节课，你会更明白，我们学习词嵌入则是有一个固定的词汇表，比如10000个单词，我们学习向量$e_{1}$到$e_{10000}$，学习一个固定的编码，每一个词汇表的单词的固定嵌入，这就是人脸识别与我们接下来几节视频要讨论的算法之间的一个不同之处。这里的术语编码（encoding）和嵌入（embedding）可以互换，所以刚才讲的差别不是因为术语不一样，这个差别就是，人脸识别中的算法未来可能涉及到海量的人脸照片，而自然语言处理有一个固定的词汇表，而像一些没有出现过的单词我们就记为未知单词。 这节视频里，你看到如何用词嵌入来实现这种类型的迁移学习，并且通过替换原来的one-hot表示，而是用之前的嵌入的向量，你的算法会泛化的更好，你也可以从较少的标记数据中进行学习。接下来我会给你展示一些词嵌入的特性，这之后再讨论学习这些词嵌入的算法。下个视频我们会看到词嵌入在做类比推理中发挥的作用。 2.3 词嵌入的特性（Properties of Word Embeddings）到现在，你应该明白了词嵌入是如何帮助你构建自然语言处理应用的。词嵌入还有一个迷人的特性就是它还能帮助实现类比推理，尽管类比推理可能不是自然语言处理应用中最重要的，不过它能帮助人们理解词嵌入做了什么，以及词嵌入能够做什么，让我们来一探究竟。 这是一系列你希望词嵌入可以捕捉的单词的特征表示，假如我提出一个问题，man如果对应woman，那么king应该对应什么？你们应该都能猜到king应该对应queen。能否有一种算法来自动推导出这种关系，下面就是实现的方法。 我们用一个四维向量来表示man，我们用$e_{5391}$来表示，不过在这节视频中我们先把它（上图编号1所示）称为$e_{\text{man} }$，而旁边这个（上图编号2所示）表示woman的嵌入向量，称它为$e_{\text{woman} }$，对king和queen也是用一样的表示方法。在该例中，假设你用的是四维的嵌入向量，而不是比较典型的50到1000维的向量。这些向量有一个有趣的特性，就是假如你有向量$e_{\text{man} }$和$e_{\text{woman} }$，将它们进行减法运算，即 $$e_{\text{man} } - e_{\text{woman} } = \begin{bmatrix} 1 \ 0.01 \0.03 \0.09 \\end{bmatrix} - \begin{bmatrix}1 \0.02 \0.02 \0.01 \\end{bmatrix} = \begin{bmatrix} 2 \ 0.01 \ 0.01 \0.08 \\end{bmatrix} \approx \begin{bmatrix} 2 \0 \0 \0 \\end{bmatrix}$$ 类似的，假如你用$e_{\text{king} }$减去$e_{\text{queen} }$，最后也会得到一样的结果，即 $$e_{\text{king} } - e_{\text{queen} } = \begin{bmatrix} 0.95 \ 0.93 \0.70 \0.02 \\end{bmatrix} - \begin{bmatrix}0.97 \0.95 \0.69 \0.01 \\end{bmatrix} = \begin{bmatrix} 1.92 \ 0.02 \ 0.01 \0.01 \\end{bmatrix} \approx \begin{bmatrix} 2 \0 \0 \0 \\end{bmatrix}$$ 这个结果表示，man和woman主要的差异是gender（性别）上的差异，而king和queen之间的主要差异，根据向量的表示，也是gender（性别）上的差异，这就是为什么$e_{\text{man} }- e_{\text{woman} }$和$e_{\text{king} } - e_{\text{queen} }$结果是相同的。所以得出这种类比推理的结论的方法就是，当算法被问及man对woman相当于king对什么时，算法所做的就是计算$e_{\text{man} }-e_{\text{woman} }$，然后找出一个向量也就是找出一个词，使得$e_{\text{man} }-e_{\text{woman} }$≈$\ e_{\text{king} }- e_{?}$，也就是说，当这个新词是queen时，式子的左边会近似地等于右边。这种思想首先是被Tomas Mikolov 和 Wen-tau Yih还有Geoffrey Zweig提出的，这是词嵌入领域影响力最为惊人和显著的成果之一，这种思想帮助了研究者们对词嵌入领域建立了更深刻的理解。 （Mikolov T, Yih W T, Zweig G. Linguistic regularities in continuous space word representations[J]. In HLT-NAACL, 2013.） 让我们来正式地探讨一下应该如何把这种思想写成算法。在图中，词嵌入向量在一个可能有300维的空间里，于是单词man代表的就是空间中的一个点，另一个单词woman代表空间另一个点，单词king也代表一个点，还有单词queen也在另一点上（上图编号1方框内所示的点）。事实上，我们在上个幻灯片所展示的就是向量man和woman的差值非常接近于向量king和queen之间的差值，我所画的这个箭头（上图编号2所示）代表的就是向量在gender（性别）这一维的差，不过不要忘了这些点是在300维的空间里。为了得出这样的类比推理，计算当man对于woman，那么king对于什么，你能做的就是找到单词w来使得，$e_{\text{man} }-e_{\text{woman} }≈ e_{\text{king} } - e_{w}$这个等式成立，你需要的就是找到单词w来最大化$e_{w}$与$e_{\text{king} } - e_{\text{man} } + e_{\text{woman} }$的相似度，即 $Find\ word\ w:argmax \ Sim(e_{w},e_{\text{king} } - e_{\text{man} } + e_{\text{woman} })$ 所以我做的就是我把这个$e_{w}$全部放到等式的一边，于是等式的另一边就会是$e_{\text{king} }- e_{\text{man} } + e_{\text{woman} }$。我们有一些用于测算$e_{w}$和$e_{\text{king} } -e_{\text{man} } + e_{\text{woman} }$之间的相似度的函数，然后通过方程找到一个使得相似度最大的单词，如果结果理想的话会得到单词queen。值得注意的是这种方法真的有效，如果你学习一些词嵌入，通过算法来找到使得相似度最大化的单词w，你确实可以得到完全正确的答案。不过这取决于过程中的细节，如果你查看一些研究论文就不难发现，通过这种方法来做类比推理准确率大概只有30%~75%，只要算法猜中了单词，就把该次计算视为正确，从而计算出准确率，在该例子中，算法选出了单词queen。 在继续下一步之前，我想再说明一下左边的这幅图（上图编号1所示），在之前我们谈到过用t-SNE算法来将单词可视化。t-SNE算法所做的就是把这些300维的数据用一种非线性的方式映射到2维平面上，可以得知t-SNE中这种映射很复杂而且很非线性。在进行t-SNE映射之后，你不能总是期望使等式成立的关系，会像左边那样成一个平行四边形，尽管在这个例子最初的300维的空间内你可以依赖这种平行四边形的关系来找到使等式成立的一对类比，通过t-SNE算法映射出的图像可能是正确的。但在大多数情况下，由于t-SNE的非线性映射，你就没法再指望这种平行四边形了，很多这种平行四边形的类比关系在t-SNE映射中都会失去原貌。 现在，再继续之前，我想再快速地列举一个最常用的相似度函数，这个最常用的相似度函数叫做余弦相似度。这是我们上个幻灯片所得到的等式（下图编号1所示），在余弦相似度中，假如在向量$u$和$v$之间定义相似度:$\text{sim}\left( u,v \right) = \frac{u^{T}v}{\left| \left| u \right| \right|_{2}\left| \left| v \right| \right|_{2} }$ 现在我们先不看分母，分子其实就是$u$和$v$的内积。如果u和v非常相似，那么它们的内积将会很大，把整个式子叫做余弦相似度，其实就是因为该式是$u$和$v$的夹角的余弦值，所以这个角（下图编号2所示）就是Φ角，这个公式实际就是计算两向量夹角Φ角的余弦。你应该还记得在微积分中，Φ角的余弦图像是这样的（下图编号3所示），所以夹角为0度时，余弦相似度就是1，当夹角是90度角时余弦相似度就是0，当它们是180度时，图像完全跑到了相反的方向，这时相似度等于-1，这就是为什么余弦相似度对于这种类比工作能起到非常好的效果。距离用平方距离或者欧氏距离来表示:$\left| \left| u - v \right| \right|^{2}$参考资料：余弦相似度为了测量两个词的相似程度，我们需要一种方法来测量两个词的两个嵌入向量之间的相似程度。 给定两个向量$u$和$v$，余弦相似度定义如下： ${CosineSimilarity(u, v)} = \frac {u . v} {||u||_2 ||v||_2} = cos(\theta) \tag{1}$ 其中 $u.v$ 是两个向量的点积（或内积），$||u||_2$是向量$u$的范数（或长度），并且 $\theta$ 是向量$u$和$v$之间的角度。这种相似性取决于角度在向量$u$和$v$之间。如果向量$u$和$v$非常相似，它们的余弦相似性将接近1; 如果它们不相似，则余弦相似性将取较小的值。图1：两个向量之间角度的余弦是衡量它们有多相似的指标，角度越小，两个向量越相似。 从学术上来说，比起测量相似度，这个函数更容易测量的是相异度，所以我们需要对其取负，这个函数才能正常工作，不过我还是觉得余弦相似度用得更多一点，这两者的主要区别是它们对$u$和$v$之间的距离标准化的方式不同。 词嵌入的一个显著成果就是，可学习的类比关系的一般性。举个例子，它能学会man对于woman相当于boy对于girl，因为man和woman之间和king和queen之间，还有boy和girl之间的向量差在gender（性别）这一维都是一样的。它还能学习Canada（加拿大）的首都是Ottawa（渥太华），而渥太华对于加拿大相当于Nairobi（内罗毕）对于Kenya（肯尼亚），这些都是国家中首都城市名字。它还能学习big对于bigger相当于tall对于taller，还能学习Yen（円）对于Janpan（日本），円是日本的货币单位，相当于Ruble（卢比）对于Russia（俄罗斯）。这些东西都能够学习，只要你在大型的文本语料库上实现一个词嵌入学习算法，只要从足够大的语料库中进行学习，它就能自主地发现这些模式。 在本节视频中，你见到了词嵌入是如何被用于类比推理的，可能你不会自己动手构建一个类比推理系统作为一项应用，不过希望在这些可学习的类特征的表示方式能够给你一些直观的感受。你还看知道了余弦相似度可以作为一种衡量两个词嵌入向量间相似度的办法，我们谈了许多有关这些嵌入的特性，以及如何使用它们。下节视频中，我们来讨论如何真正的学习这些词嵌入。 2.4 嵌入矩阵（Embedding Matrix）接下来我们要将学习词嵌入这一问题具体化，当你应用算法来学习词嵌入时，实际上是学习一个嵌入矩阵，我们来看一下这是什么意思。 和之前一样，假设我们的词汇表含有10,000个单词，词汇表里有a，aaron，orange，zulu，可能还有一个未知词标记&amp;lt;UNK&amp;gt;。我们要做的就是学习一个嵌入矩阵$E$，它将是一个300×10,000的矩阵，如果你的词汇表里有10,000个，或者加上未知词就是10,001维。这个矩阵的各列代表的是词汇表中10,000个不同的单词所代表的不同向量。假设orange的单词编号是6257（下图编号1所示），代表词汇表中第6257个单词，我们用符号$O_{6527}$来表示这个one-hot向量，这个向量除了第6527个位置上是1（下图编号2所示），其余各处都为0，显然它是一个10,000维的列向量，它只在一个位置上有1，它不像图上画的那么短，它的高度应该和左边的嵌入矩阵的宽度相等。 假设这个嵌入矩阵叫做矩阵$E$，注意如果用$E$去乘以右边的one-hot向量（上图编号3所示），也就是$O_{6527}$，那么就会得到一个300维的向量，$E$是300×10,000的，$O_{6527}$是10,000×1的，所以它们的积是300×1的，即300维的向量。要计算这个向量的第一个元素，你需要做的是把$E$的第一行（上图编号4所示）和$O_{6527}$的整列相乘，不过$O_{6527}$的所有元素都是0，只有6257位置上是1，最后你得到的这个向量的第一个元素（上图编号5所示）就是orange这一列下的数字（上图编号6所示）。然后我们要计算这个向量的第二个元素，就是把$E$的第二行（上图编号7所示）和这个$O_{6527}$相乘，和之前一样，然后得到第二个元素（上图编号8所示），以此类推，直到你得到这个向量剩下的所有元素（上图编号9所示）。 这就是为什么把矩阵$E$和这个one-hot向量相乘，最后得到的其实就是这个300维的列，就是单词orange下的这一列，它等于$e_{6257}$，这个符号是我们用来表示这个300×1的嵌入向量的符号，它表示的单词是orange。 更广泛来说，假如说有某个单词w，那么$e_{w}$就代表单词w的嵌入向量。同样，$EO_{j}$，$O_{j}$就是只有第$j$个位置是1的one-hot向量，得到的结果就是$e_{j}$，它表示的是字典中单词j的嵌入向量。 在这一小节中，要记住的一件事就是我们的目标是学习一个嵌入矩阵$E$。在下节视频中你将会随机地初始化矩阵$E$，然后使用梯度下降法来学习这个300×10,000的矩阵中的各个参数，$E$乘以这个one-hot向量（上图编号1所示）会得到嵌入向量。再多说一点，当我们写这个等式（上图编号2所示）的时候，写出这些符号是很方便的，代表用矩阵$E$乘以one-hot向量$O_{j}$。但当你动手实现时，用大量的矩阵和向量相乘来计算它，效率是很低下的，因为one-hot向量是一个维度非常高的向量，并且几乎所有元素都是0，所以矩阵向量相乘效率太低，因为我们要乘以一大堆的0。所以在实践中你会使用一个专门的函数来单独查找矩阵$E$的某列，而不是用通常的矩阵乘法来做，但是在画示意图时（上图所示，即矩阵$E$乘以one-hot向量示意图），这样写比较方便。但是例如在Keras中就有一个嵌入层，然后我们用这个嵌入层更有效地从嵌入矩阵中提取出你需要的列，而不是对矩阵进行很慢很复杂的乘法运算。 在本视频中你见到了在学习嵌入向量的过程中用来描述这些算法的符号以及关键术语，矩阵$E$它包含了词汇表中所有单词的嵌入向量。在下节视频中，我们将讨论学习矩阵$E$的具体算法。 2.5 学习词嵌入（Learning Word Embeddings）在本节视频中，你将要学习一些具体的算法来学习词嵌入。在深度学习应用于学习词嵌入的历史上，人们一开始使用的算法比较复杂，但随着时间推移，研究者们不断发现他们能用更加简单的算法来达到一样好的效果，特别是在数据集很大的情况下。但有一件事情就是，现在很多最流行的算法都十分简单，如果我一开始就介绍这些简单的算法，你可能会觉得这有点神奇，这么简单的算法究竟是怎么起作用的？稍微复杂一些的算法开始，因为我觉得这样更容易对算法的运作方式有一个更直观的了解，之后我们会对这些算法进行简化，使你能够明白即使一些简单的算法也能得到非常好的结果，我们开始吧。 假如你在构建一个语言模型，并且用神经网络来实现这个模型。于是在训练过程中，你可能想要你的神经网络能够做到比如输入：“I want a glass of orange ___.”，然后预测这句话的下一个词。在每个单词下面，我都写上了这些单词对应词汇表中的索引。实践证明，建立一个语言模型是学习词嵌入的好方法，我提出的这些想法是源于Yoshua Bengio，Rejean Ducharme，Pascal Vincent，Rejean Ducharme，Pascal Vincent还有Christian Jauvin。 下面我将介绍如何建立神经网络来预测序列中的下一个单词，让我为这些词列一个表格，“I want a glass of orange”，我们从第一个词I开始，建立一个one-hot向量表示这个单词I。这是一个one-hot向量（上图编号1所示），在第4343个位置是1，它是一个10,000维的向量。然后要做的就是生成一个参数矩阵$E$，然后用$E$乘以$O_{4343}$，得到嵌入向量$e_{4343}$，这一步意味着$e_{4343}$是由矩阵$E$乘以one-hot向量得到的（上图编号2所示）。然后我们对其他的词也做相同的操作，单词want在第9665个，我们将$E$与这个one-hot向量（$O_{9665}$）相乘得到嵌入向量$e_{9665}$。对其他单词也是一样，a是字典中的第一个词，因为a是第一个字母，由$O_{1}$得到$e_{1}$。同样地，其他单词也这样操作。 于是现在你有许多300维的嵌入向量。我们能做的就是把它们全部放进神经网络中（上图编号3所示），经过神经网络以后再通过softmax层（上图编号4所示），这个softmax也有自己的参数，然后这个softmax分类器会在10,000个可能的输出中预测结尾这个单词。假如说在训练集中有juice这个词，训练过程中softmax的目标就是预测出单词juice，就是结尾的这个单词。这个隐藏层（上图编号3所示）有自己的参数，我这里用$W^{\left\lbrack1 \right\rbrack}$和$b^{\left\lbrack 1\right\rbrack}$来表示，这个softmax层（上图编号4所示）也有自己的参数$W^{\left\lbrack2 \right\rbrack}$和$b^{\left\lbrack 2\right\rbrack}$。如果它们用的是300维大小的嵌入向量，而这里有6个词，所以用6×300，所以这个输入会是一个1800维的向量，这是通过将这6个嵌入向量堆在一起得到的。 实际上更常见的是有一个固定的历史窗口，举个例子，你总是想预测给定四个单词（上图编号1所示）后的下一个单词，注意这里的4是算法的超参数。这就是如何适应很长或者很短的句子，方法就是总是只看前4个单词，所以说我只用这4个单词（上图编号2所示）而不去看这几个词（上图编号3所示）。如果你一直使用一个4个词的历史窗口，这就意味着你的神经网络会输入一个1200维的特征变量到这个层中（上图编号4所示），然后再通过softmax来预测输出，选择有很多种，用一个固定的历史窗口就意味着你可以处理任意长度的句子，因为输入的维度总是固定的。所以这个模型的参数就是矩阵$E$，对所有的单词用的都是同一个矩阵$E$，而不是对应不同的位置上的不同单词用不同的矩阵。然后这些权重（上图编号5所示）也都是算法的参数，你可以用反向传播来进行梯度下降来最大化训练集似然，通过序列中给定的4个单词去重复地预测出语料库中下一个单词什么。 事实上通过这个算法能很好地学习词嵌入，原因是，如果你还记得我们的orange jucie，apple juice的例子，在这个算法的激励下，apple和orange会学到很相似的嵌入，这样做能够让算法更好地拟合训练集，因为它有时看到的是orange juice，有时看到的是apple juice。如果你只用一个300维的特征向量来表示所有这些词，算法会发现要想最好地拟合训练集，就要使apple（苹果）、orange（橘子）、grape（葡萄）和pear（梨）等等，还有像durian（榴莲）这种很稀有的水果都拥有相似的特征向量。 这就是早期最成功的学习词嵌入，学习这个矩阵$E$的算法之一。现在我们先概括一下这个算法，看看我们该怎样来推导出更加简单的算法。现在我想用一个更复杂的句子作为例子来解释这些算法，假设在你的训练集中有这样一个更长的句子：“I want a glass of orange juice to go along with my cereal.”。我们在上个幻灯片看到的是算法预测出了某个单词juice，我们把它叫做目标词（下图编号1所示），它是通过一些上下文，在本例中也就是这前4个词（下图编号2所示）推导出来的。如果你的目标是学习一个嵌入向量，研究人员已经尝试过很多不同类型的上下文。如果你要建立一个语言模型，那么一般选取目标词之前的几个词作为上下文。但如果你的目标不是学习语言模型本身的话，那么你可以选择其他的上下文。 比如说，你可以提出这样一个学习问题，它的上下文是左边和右边的四个词，你可以把目标词左右各4个词作为上下文（上图编号3所示）。这就意味着我们提出了一个这样的问题，算法获得左边4个词，也就是a glass of orange，还有右边四个词to go along with，然后要求预测出中间这个词（上图编号4所示）。提出这样一个问题，这个问题需要将左边的还有右边这4个词的嵌入向量提供给神经网络，就像我们之前做的那样来预测中间的单词是什么，来预测中间的目标词，这也可以用来学习词嵌入。 或者你想用一个更简单的上下文，也许只提供目标词的前一个词，比如只给出orange这个词来预测orange后面是什么（上图编号5所示），这将会是不同的学习问题。只给出一个词orange来预测下一个词是什么（上图编号6所示），你可以构建一个神经网络，只把目标词的前一个词或者说前一个词的嵌入向量输入神经网络来预测该词的下一个词。 还有一个效果非常好的做法就是上下文是附近一个单词，它可能会告诉你单词glass（上图编号7所示）是一个邻近的单词。或者说我看见了单词glass，然后附近有一个词和glass位置相近，那么这个词会是什么（上图编号8所示）？这就是用附近的一个单词作为上下文。我们将在下节视频中把它公式化，这用的是一种Skip-Gram模型的思想。这是一个简单算法的例子，因为上下文相当的简单，比起之前4个词，现在只有1个，但是这种算法依然能工作得很好。 研究者发现，如果你真想建立一个语言模型，用目标词的前几个单词作为上下文是常见做法（上图编号9所示）。但如果你的目标是学习词嵌入，那么你就可以用这些其他类型的上下文（上图编号10所示），它们也能得到很好的词嵌入。我会在下节视频详细介绍这些，我们会谈到Word2Vec模型。 总结一下，在本节视频中你学习了语言模型问题，模型提出了一个机器学习问题，即输入一些上下文，例如目标词的前4个词然后预测出目标词，学习了提出这些问题是怎样帮助学习词嵌入的。在下节视频，你将看到如何用更简单的上下文和更简单的算法来建立从上下文到目标词的映射，这将让你能够更好地学习词嵌入，一起进入下节视频学习Word2Vec模型。 2.6 Word2Vec在上个视频中你已经见到了如何学习一个神经语言模型来得到更好的词嵌入，在本视频中你会见到 Word2Vec算法，这是一种简单而且计算时更加高效的方式来学习这种类型的嵌入，让我们来看看。 本视频中的大多数的想法来源于Tomas Mikolov，Kai Chen，Greg Corrado 和 Jeff Dean。 （Mikolov T, Chen K, Corrado G, et al. Efficient Estimation of Word Representations in Vector Space[J]. Computer Science, 2013.） 假设在训练集中给定了一个这样的句子：“I want a glass of orange juice to go along with my cereal.”，在Skip-Gram模型中，我们要做的是抽取上下文和目标词配对，来构造一个监督学习问题。上下文不一定总是目标单词之前离得最近的四个单词，或最近的$n$个单词。我们要的做的是随机选一个词作为上下文词，比如选orange这个词，然后我们要做的是随机在一定词距内选另一个词，比如在上下文词前后5个词内或者前后10个词内，我们就在这个范围内选择目标词。可能你正好选到了juice作为目标词，正好是下一个词（表示orange的下一个词），也有可能你选到了前面第二个词，所以另一种配对目标词可以是glass，还可能正好选到了单词my作为目标词。 于是我们将构造一个监督学习问题，它给定上下文词，要求你预测在这个词正负10个词距或者正负5个词距内随机选择的某个目标词。显然，这不是个非常简单的学习问题，因为在单词orange的正负10个词距之间，可能会有很多不同的单词。但是构造这个监督学习问题的目标并不是想要解决这个监督学习问题本身，而是想要使用这个学习问题来学到一个好的词嵌入模型。 接下来说说模型的细节，我们继续假设使用一个10,000词的词汇表，有时训练使用的词汇表会超过一百万词。但我们要解决的基本的监督学习问题是学习一种映射关系，从上下文c，比如单词orange，到某个目标词，记为t，可能是单词juice或者单词glass或者单词my。延续上一张幻灯片的例子，在我们的词汇表中，orange是第6257个单词，juice是10,000个单词中的第4834个，这就是你想要的映射到输出$y$的输入$x$。 为了表示输入，比如单词orange，你可以先从one-hot向量开始，我们将其写作$O_{c}$，这就是上下文词的one-hot向量（上图编号1所示）。然后和你在上节视频中看到的类似，你可以拿嵌入矩阵$E$乘以向量$O_{c}$，然后得到了输入的上下文词的嵌入向量，于是这里$e_{c}=EO_{c}$。在这个神经网络中（上图编号2所示），我们将把向量$e_{c}$喂入一个softmax单元。我通常把softmax单元画成神经网络中的一个节点（上图编号3所示），这不是字母O，而是softmax单元，softmax单元要做的就是输出$\hat y$。然后我们再写出模型的细节，这是softmax模型（上图编号4所示），预测不同目标词的概率： $Softmax:p\left( t \middle| c \right) = \frac{e^{\theta_{t}^{T}e_{c} }}{\sum_{j = 1}^{10,000}e^{\theta_{j}^{T}e_{c} }}$ 这里$\theta_{t}$是一个与输出$t$有关的参数，即某个词$t$和标签相符的概率是多少。我省略了softmax中的偏差项，想要加上的话也可以加上。 最终softmax的损失函数就会像之前一样，我们用$y$表示目标词，我们这里用的$y$和$\hat y$都是用one-hot表示的，于是损失函数就会是： $L\left( \hat y,y \right) = - \sum_{i = 1}^{10,000}{y_{i}\log \hat y_{i} }$ 这是常用的softmax损失函数，$y$ 就是只有一个1其他都是0的one-hot向量，如果目标词是juice，那么第4834个元素就是1，其余是0（上图编号5所示）。类似的$\hat y$是一个从softmax单元输出的10,000维的向量，这个向量是所有可能目标词的概率。 总结一下，这大体上就是一个可以找到词嵌入的简化模型和神经网络（上图编号2所示），其实就是个softmax单元。矩阵$E$将会有很多参数，所以矩阵$E$有对应所有嵌入向量$e_{c}$的参数（上图编号6所示），softmax单元也有$\theta_{t}$的参数（上图编号3所示）。如果优化这个关于所有这些参数的损失函数，你就会得到一个较好的嵌入向量集，这个就叫做Skip-Gram模型。它把一个像orange这样的词作为输入，并预测这个输入词，从左数或从右数的某个词，预测上下文词的前面一些或者后面一些是什么词。 实际上使用这个算法会遇到一些问题，首要的问题就是计算速度。尤其是在softmax模型中，每次你想要计算这个概率，你需要对你词汇表中的所有10,000个词做求和计算，可能10,000个词的情况还不算太差。如果你用了一个大小为100,000或1,000,000的词汇表，那么这个分母的求和操作是相当慢的，实际上10,000已经是相当慢的了，所以扩大词汇表就更加困难了。 这里有一些解决方案，如分级（hierarchical）的softmax分类器和负采样（Negative Sampling）。 在文献中你会看到的方法是使用一个分级（hierarchical）的softmax分类器，意思就是说不是一下子就确定到底是属于10,000类中的哪一类。想象如果你有一个分类器（上图编号1所示），它告诉你目标词是在词汇表的前5000个中还是在词汇表的后5000个词中，假如这个二分类器告诉你这个词在前5000个词中（上图编号2所示），然后第二个分类器会告诉你这个词在词汇表的前2500个词中，或者在词汇表的第二组2500个词中，诸如此类，直到最终你找到一个词准确所在的分类器（上图编号3所示），那么就是这棵树的一个叶子节点。像这样有一个树形的分类器，意味着树上内部的每一个节点都可以是一个二分类器，比如逻辑回归分类器，所以你不需要再为单次分类，对词汇表中所有的10,000个词求和了。实际上用这样的分类树，计算成本与词汇表大小的对数成正比（上图编号4所示），而不是词汇表大小的线性函数，这个就叫做分级softmax分类器。 我要提一下，在实践中分级softmax分类器不会使用一棵完美平衡的分类树或者说一棵左边和右边分支的词数相同的对称树（上图编号1所示的分类树）。实际上，分级的softmax分类器会被构造成常用词在顶部，然而不常用的词像durian会在树的更深处（上图编号2所示的分类树），因为你想更常见的词会更频繁，所以你可能只需要少量检索就可以获得常用单词像the和of。然而你更少见到的词比如durian就更合适在树的较深处，因为你一般不需要到那样的深处，所以有不同的经验法则可以帮助构造分类树形成分级softmax分类器。所以这是你能在文献中见到的一个加速softmax分类的方法，但是我不会再花太多时间在这上面了，你可以从我在第一张幻灯片中提到的Tomas Mikolov等人的论文中参阅更多的细节，所以我不会再花更多时间讲这个了。因为在下个视频中，我们会讲到另一个方法叫做负采样，我感觉这个会更简单一点，对于加速softmax和解决需要在分母中对整个词汇表求和的问题也很有作用，下个视频中你会看到更多的细节。 但是在进入下个视频前，我想要你理解一个东西，那就是怎么对上下文c进行采样，一旦你对上下文c进行采样，那么目标词t就会在上下文c的正负10个词距内进行采样。但是你要如何选择上下文c？一种选择是你可以就对语料库均匀且随机地采样，如果你那么做，你会发现有一些词，像the、of、a、and、to诸如此类是出现得相当频繁的，于是你那么做的话，你会发现你的上下文到目标词的映射会相当频繁地得到这些种类的词，但是其他词，像orange、apple或durian就不会那么频繁地出现了。你可能不会想要你的训练集都是这些出现得很频繁的词，因为这会导致你花大部分的力气来更新这些频繁出现的单词的$e_{c}$（上图编号1所示），但你想要的是花时间来更新像durian这些更少出现的词的嵌入，即$e_{\text{durian} }$。实际上词$p(c)$的分布并不是单纯的在训练集语料库上均匀且随机的采样得到的，而是采用了不同的分级来平衡更常见的词和不那么常见的词。 这就是Word2Vec的Skip-Gram模型，如果你读过我之前提到的论文原文，你会发现那篇论文实际上有两个不同版本的Word2Vec模型，Skip-Gram只是其中的一个，另一个叫做CBOW，即连续词袋模型（ContinuousBag-Of-Words Model），它获得中间词两边的的上下文，然后用周围的词去预测中间的词，这个模型也很有效，也有一些优点和缺点。 总结下：CBOW是从原始语句推测目标字词；而Skip-Gram正好相反，是从目标字词推测出原始语句。CBOW对小型数据库比较合适，而Skip-Gram在大型语料中表现更好。 （下图左边为CBOW，右边为Skip-Gram） 而刚才讲的Skip-Gram模型，关键问题在于softmax这个步骤的计算成本非常昂贵，因为它需要在分母里对词汇表中所有词求和。通常情况下，Skip-Gram模型用到更多点。在下个视频中，我会展示给你一个算法，它修改了训练目标使其可以运行得更有效，因此它可以让你应用在一个更大的训练集上面，也可以学到更好的词嵌入。 2.7 负采样（Negative Sampling）在上个视频中，你见到了Skip-Gram模型如何帮助你构造一个监督学习任务，把上下文映射到了目标词上，它如何让你学到一个实用的词嵌入。但是它的缺点就在于softmax计算起来很慢。在本视频中，你会看到一个改善过的学习问题叫做负采样，它能做到与你刚才看到的Skip-Gram模型相似的事情，但是用了一个更加有效的学习算法，让我们来看看这是怎么做到的。 在本视频中大多数的想法源于Tomas Mikolov，Ilya Sutskever，Kai Chen，Greg Corrado 和 Jeff Dean。 （Mikolov T, Sutskever I, Chen K, et al. Distributed Representations of Words and Phrases and their Compositionality[J]. 2013, 26:3111-3119.） 我们在这个算法中要做的是构造一个新的监督学习问题，那么问题就是给定一对单词，比如orange和juice，我们要去预测这是否是一对上下文词-目标词（context-target）。 在这个例子中orange和juice就是个正样本，那么orange和king就是个负样本，我们把它标为0。我们要做的就是采样得到一个上下文词和一个目标词，在这个例子中就是orange 和juice，我们用1作为标记，我把中间这列（下图编号1所示）叫做词（word）。这样生成一个正样本，正样本跟上个视频中生成的方式一模一样，先抽取一个上下文词，在一定词距内比如说正负10个词距内选一个目标词，这就是生成这个表的第一行，即orange– juice -1的过程。然后为了生成一个负样本，你将用相同的上下文词，再在字典中随机选一个词，在这里我随机选了单词king，标记为0。然后我们再拿orange，再随机从词汇表中选一个词，因为我们设想，如果随机选一个词，它很可能跟orange没关联，于是orange–book–0。我们再选点别的，orange可能正好选到the，然后是0。还是orange，再可能正好选到of这个词，再把这个标记为0，注意of被标记为0，即使of的确出现在orange词的前面。 总结一下，生成这些数据的方式是我们选择一个上下文词（上图编号2所示），再选一个目标词（上图编号3所示），这（上图编号4所示）就是表的第一行，它给了一个正样本，上下文，目标词，并给定标签为1。然后我们要做的是给定几次，比如$K$次（上图编号5所示），我们将用相同的上下文词，再从字典中选取随机的词，king、book、the、of等，从词典中任意选取的词，并标记0，这些就会成为负样本（上图编号6所示）。出现以下情况也没关系，就是如果我们从字典中随机选到的词，正好出现在了词距内，比如说在上下文词orange正负10个词之内。 接下来我们将构造一个监督学习问题，其中学习算法输入$x$，输入这对词（上图编号7所示），要去预测目标的标签（上图编号8所示），即预测输出$y$。因此问题就是给定一对词，像orange和juice，你觉得它们会一起出现么？你觉得这两个词是通过对靠近的两个词采样获得的吗？或者你觉得我是分别在文本和字典中随机选取得到的？这个算法就是要分辨这两种不同的采样方式，这就是如何生成训练集的方法。 那么如何选取$K$？Mikolov等人推荐小数据集的话，$K$从5到20比较好。如果你的数据集很大，$K$就选的小一点。对于更大的数据集$K$就等于2到5，数据集越小$K$就越大。那么在这个例子中，我们就用$K=4$。 下面我们讲讲学习从$x$映射到$y$的监督学习模型，这（上图编号1所示:$Softmax:p\left( t \middle| c \right) = \frac{e^{\theta_{t}^{T}e_{c} }}{\sum_{j = 1}^{10,000}e^{\theta_{j}^{T}e_{c} }}$）的softmax模型。这是我们从上张幻灯片中得到的训练集，这个（上图编号2所示）将是新的输入$x$，这个（上图编号3所示）将是你要预测的值$y$。为了定义模型，我们将使用记号$c$表示上下文词，记号$t$表示可能的目标词，我再用$y$表示0和1，表示是否是一对上下文-目标词。我们要做的就是定义一个逻辑回归模型，给定输入的$c$，$t$对的条件下，$y=1$的概率，即： $P\left( y = 1 \middle| c,t \right) = \sigma(\theta_{t}^{T}e_{c})$ 这个模型基于逻辑回归模型，但不同的是我们将一个sigmoid函数作用于$\theta_{t}^{T}e_{c}$，参数和之前一样，你对每一个可能的目标词有一个参数向量$\theta_{t}$和另一个参数向量$e_{c}$，即每一个可能上下文词的的嵌入向量，我们将用这个公式估计$y=1$的概率。如果你有$K$个样本，你可以把这个看作$\frac{1}{K}$的正负样本比例，即每一个正样本你都有$K$个对应的负样本来训练一个类似逻辑回归的模型。 我们把这个画成一个神经网络，如果输入词是orange，即词6257，你要做的就是输入one-hot向量，再传递给$E$，通过两者相乘获得嵌入向量$e_{6257}$，你就得到了10,000个可能的逻辑回归分类问题，其中一个（上图编号4所示）将会是用来判断目标词是否是juice的分类器，还有其他的词，比如说可能下面的某个分类器（上图编号5所示）是用来预测king是否是目标词，诸如此类，预测词汇表中这些可能的单词。把这些看作10,000个二分类逻辑回归分类器，但并不是每次迭代都训练全部10,000个，我们只训练其中的5个，我们要训练对应真正目标词那一个分类器，再训练4个随机选取的负样本，这就是$K=4$的情况。所以不使用一个巨大的10,000维度的softmax，因为计算成本很高，而是把它转变为10,000个二分类问题，每个都很容易计算，每次迭代我们要做的只是训练它们其中的5个，一般而言就是$K+1$个，其中$K$个负样本和1个正样本。这也是为什么这个算法计算成本更低，因为只需更新$K+1$个逻辑单元，$K+1$个二分类问题，相对而言每次迭代的成本比更新10,000维的softmax分类器成本低。 你也会在本周的编程练习中用到这个算法，这个技巧就叫负采样。因为你做的是，你有一个正样本词orange和juice，然后你会特意生成一系列负样本，这些（上图编号6所示）是负样本，所以叫负采样，即用这4个负样本训练，4个额外的二分类器，在每次迭代中你选择4个不同的随机的负样本词去训练你的算法。 这个算法有一个重要的细节就是如何选取负样本，即在选取了上下文词orange之后，你如何对这些词进行采样生成负样本？一个办法是对中间的这些词进行采样，即候选的目标词，你可以根据其在语料中的经验频率进行采样，就是通过词出现的频率对其进行采样。但问题是这会导致你在like、the、of、and诸如此类的词上有很高的频率。另一个极端就是用1除以词汇表总词数，即$\frac{1}{\left|v\right|}$，均匀且随机地抽取负样本，这对于英文单词的分布是非常没有代表性的。所以论文的作者Mikolov等人根据经验，他们发现这个经验值的效果最好，它位于这两个极端的采样方法之间，既不用经验频率，也就是实际观察到的英文文本的分布，也不用均匀分布，他们采用以下方式： $P\left( w_{i} \right) = \frac{f\left( w_{i} \right)^{\frac{3}{4} }}{\sum_{j = 1}^{10,000}{f\left( w_{j} \right)^{\frac{3}{4} }} }$ 进行采样，所以如果$f(w_{i})$是观测到的在语料库中的某个英文词的词频，通过$\frac{3}{4}$次方的计算，使其处于完全独立的分布和训练集的观测分布两个极端之间。我并不确定这是否有理论证明，但是很多研究者现在使用这个方法，似乎也效果不错。 总结一下，你已经知道了在softmax分类器中如何学到词向量，但是计算成本很高。在这个视频中，你见到了如何通过将其转化为一系列二分类问题使你可以非常有效的学习词向量。如果你使用这个算法，你将可以学到相当好的词向量。当然和深度学习的其他领域一样，有很多开源的实现，当然也有预训练过的词向量，就是其他人训练过的然后授权许可发布在网上的，所以如果你想要在NLP问题上取得进展，去下载其他人的词向量是很好的方法，在此基础上改进。 Skip-Gram模型就介绍到这里，在下个视频中，我会跟你分享另一个版本的词嵌入学习算法GloVe，而且这可能比你之前看到的都要简单。 2.8 GloVe 词向量（GloVe Word Vectors）你已经了解了几个计算词嵌入的算法，另一个在NLP社区有着一定势头的算法是GloVe算法，这个算法并不如Word2Vec或是Skip-Gram模型用的多，但是也有人热衷于它，我认为可能是因为它简便吧，我们来看看这个算法。 Glove算法是由Jeffrey Pennington，Richard Socher和Chris Manning发明的。 (Pennington J, Socher R, Manning C. Glove: Global Vectors for Word Representation[C]// Conference on Empirical Methods in Natural Language Processing. 2014:1532-1543.) GloVe代表用词表示的全局变量（global vectors for word representation）。在此之前，我们曾通过挑选语料库中位置相近的两个词，列举出词对，即上下文和目标词，GloVe算法做的就是使其关系开始明确化。假定$X_{ {ij} }$是单词$i$在单词$j$上下文中出现的次数，那么这里$i$和$j$就和$t$和$c$的功能一样，所以你可以认为$X_{ {ij} }$等同于$X_{ {tc} }$。你也可以遍历你的训练集，然后数出单词$i$在不同单词$j$上下文中出现的个数，单词$t$在不同单词$c$的上下文中共出现多少次。根据上下文和目标词的定义，你大概会得出$X_{ {ij} }$等于$X_{ji}$这个结论。事实上，如果你将上下文和目标词的范围定义为出现于左右各10词以内的话，那么就会有一种对称关系。如果你对上下文的选择是，上下文总是目标词前一个单词的话，那么$X_{ {ij} }$和$X_{ji}$就不会像这样对称了。不过对于GloVe算法，我们可以定义上下文和目标词为任意两个位置相近的单词，假设是左右各10词的距离，那么$X_{ {ij} }$就是一个能够获取单词$i$和单词$j$出现位置相近时或是彼此接近的频率的计数器。 GloVe模型做的就是进行优化，我们将他们之间的差距进行最小化处理： $\text{mini}\text{mize}\sum_{i = 1}^{10,000}{\sum_{j = 1}^{10,000}{f\left( X_{ {ij} } \right)\left( \theta_{i}^{T}e_{j} + b_{i} + b_{j}^{'} - logX_{ {ij} } \right)^{2} }}$ 其中$\theta_{i}^{T}e_{j}$，想一下$i$和$j$与$t$和$c$的功能一样，因此这就和你之前看的有些类似了，即$\theta_{t}^{T}e_{c}$。同时对于这个（$\theta_{t}^{T}e_{c}$，下图编号1所示）来说，你想要知道的是告诉你这两个单词之间有多少联系，$t$和$c$之间有多紧密，$i$和$j$之间联系程度如何，换句话说就是他们同时出现的频率是多少，这是由这个$X_{ {ij} }$影响的。然后，我们要做的是解决参数$\theta$和$e$的问题，然后准备用梯度下降来最小化上面的公式，你只想要学习一些向量，这样他们的输出能够对这两个单词同时出现的频率进行良好的预测。 现在一些附加的细节是如果$X_{ {ij} }$是等于0的话，那么$log0$就是未定义的，是负无穷大的，所以我们想要对$X_{ {ij} }$为0时进行求和，因此要做的就是添加一个额外的加权项$f\left(X_{ {ij} }\right)$（上图编号2所示）。如果$X_{ {ij} }$等于0的话，同时我们会用一个约定，即$0log0= 0$，这个的意思是如果$X_{ {ij} } =0$，先不要进行求和，所以这个$log0$项就是不相关项。上面的求和公式表明，这个和仅是一个上下文和目标词关系里连续出现至少一次的词对的和。$f\left(X_{ {ij} }\right)$的另一个作用是，有些词在英语里出现十分频繁，比如说this，is，of，a等等，有些情况，这叫做停止词，但是在频繁词和不常用词之间也会有一个连续统（continuum）。不过也有一些不常用的词，比如durion，你还是想将其考虑在内，但又不像那些常用词这样频繁。因此，这个加权因子$f\left(X_{ {ij} }\right)$就可以是一个函数，即使是像durion这样不常用的词，它也能给予大量有意义的运算，同时也能够给像this，is，of，a这样在英语里出现更频繁的词更大但不至于过分的权重。因此有一些对加权函数f的选择有着启发性的原则，就是既不给这些词（this，is，of，a）过分的权重，也不给这些不常用词（durion）太小的权值。如果你想要知道f是怎么能够启发性地完成这个功能的话，你可以看一下我之前的幻灯片里引用的GloVe算法论文。 最后，一件有关这个算法有趣的事是$\theta$和$e$现在是完全对称的，所以那里的$\theta_{i}$和$e_{j}$就是对称的。如果你只看数学式的话，他们（$\theta_{i}$和$e_{j}$）的功能其实很相近，你可以将它们颠倒或者将它们进行排序，实际上他们都输出了最佳结果。因此一种训练算法的方法是一致地初始化$\theta$和$e$，然后使用梯度下降来最小化输出，当每个词都处理完之后取平均值，所以，给定一个词$w$，你就会有$e_{w}^{(final)}= \frac{e_{w} +\theta_{w} }{2}$。因为$\theta$和$e$在这个特定的公式里是对称的，而不像之前视频里我们了解的模型，$\theta$和$e$功能不一样，因此也不能像那样取平均。 这就是GloVe算法的内容，我认为这个算法的一个疑惑之处是如果你看着这个等式，它实在是太简单了，对吧？仅仅是最小化，像这样的一个二次代价函数（上图编号3所示）是怎么能够让你学习有意义的词嵌入的呢？但是结果证明它确实有效，发明者们发明这个算法的过程是他们以历史上更为复杂的算法，像是newer language模型，以及之后的Word2Vec、Skip-Gram模型等等为基础，同时希望能够简化所有之前的算法才发明的。 在我们总结词嵌入学习算法之前，有一件更优先的事，我们会简单讨论一下。就是说，我们以这个特制的表格作为例子来开始学习词向量，我们说，第一行的嵌入向量是来表示Gender的，第二行是来表示Royal的，然后是是Age，在之后是Food等等。但是当你在使用我们了解过的算法的一种来学习一个词嵌入时，例如我们之前的幻灯片里提到的GloVe算法，会发生一件事就是你不能保证嵌入向量的独立组成部分是能够理解的，为什么呢？ 假设说有个空间，里面的第一个轴（上图编号1所示）是Gender，第二个轴（上图编号2所示）是Royal，你能够保证的是第一个嵌入向量对应的轴（上图编号3所示）是和这个轴（上面提到的第一和第二基轴，编号1，2所示）有联系的，它的意思可能是Gender、Royal、Age和Food。具体而言，这个学习算法会选择这个（上图编号3所示）作为第一维的轴，所以给定一些上下文词，第一维可能是这个轴（上图编号3所示），第二维也许是这个（上图编号4所示），或者它可能不是正交的，它也可能是第二个非正交轴（上图编号5所示），它可以是你学习到的词嵌入中的第二部分。当我们看到这个（上图编号6所示）的时候，如果有某个可逆矩阵$A$，那么这项（上图编号6所示）就可以简单地替换成$\left(A\theta_{i} \right)^{T}(A^{- T}e_{j})$，因为我们将其展开： $\left( A\theta_{i} \right)^{T}\left( A^{- T}e_{j} \right) = \theta_{i}^{T}A^{T}A^{- T}e_{j} = \theta_{i}^{T}e_{j}$ 不必担心，如果你没有学过线性代数的话会，和这个算法一样有一个简单证明过程。你不能保证这些用来表示特征的轴能够等同于人类可能简单理解的轴，具体而言，第一个特征可能是个Gender、Roya、Age、Food Cost和Size的组合，它也许是名词或是一个行为动词和其他所有特征的组合，所以很难看出独立组成部分，即这个嵌入矩阵的单行部分，然后解释出它的意思。尽管有这种类型的线性变换，这个平行四边形映射也说明了我们解决了这个问题，当你在类比其他问题时，这个方法也是行得通的。因此尽管存在特征量潜在的任意线性变换，你最终还是能学习出解决类似问题的平行四边形映射。 这就是词嵌入学习的内容，你现在已经了解了一些学习词嵌入的算法了，你可以在本周的编程练习里更多地运用它们。下节课讲解怎样使用这些算法来解决情感分类问题。 2.9 情感分类（Sentiment Classification）情感分类任务就是看一段文本，然后分辨这个人是否喜欢他们在讨论的这个东西，这是NLP中最重要的模块之一，经常用在许多应用中。情感分类一个最大的挑战就是可能标记的训练集没有那么多，但是有了词嵌入，即使只有中等大小的标记的训练集，你也能构建一个不错的情感分类器，让我们看看是怎么做到的。 这是一个情感分类问题的一个例子（上图所示），输入$x$是一段文本，而输出$y$是你要预测的相应情感。比如说是一个餐馆评价的星级， 比如有人说，”The dessert is excellent.“（甜点很棒），并给出了四星的评价； “Service was quite slow“（服务太慢），两星评价； “Good for a quick meal but nothing special“（适合吃快餐但没什么亮点），三星评价； 还有比较刁钻的评论，”Completely lacking in good taste, good service and good ambiance.“（完全没有好的味道，好的服务，好的氛围），给出一星评价。 如果你能训练一个从$x$到$y$的映射，基于这样的标记的数据集，那么你就可以用来搜集大家对你运营的餐馆的评价。一些人可能会把你的餐馆信息放到一些社交媒体上，Twitter、Facebook、Instagram或者其他的社交媒体，如果你有一个情感分类器，那么它就可以看一段文本然后分析出这个人对你的餐馆的评论的情感是正面的还是负面的，这样你就可以一直记录是否存在一些什么问题，或者你的餐馆是在蒸蒸日上还是每况愈下。 情感分类一个最大的挑战就是可能标记的训练集没有那么多。对于情感分类任务来说，训练集大小从10,000到100,000个单词都很常见，甚至有时会小于10,000个单词，采用了词嵌入能够带来更好的效果，尤其是只有很小的训练集时。 接下来你可以这样做，这节我们会讲几个不同的算法。这是一个简单的情感分类的模型，假设有一个句子”dessert is excellent“，然后在词典里找这些词，我们通常用10,000个词的词汇表。我们要构建一个分类器能够把它映射成输出四个星，给定这四个词（”dessert is excellent“），我们取这些词，找到相应的one-hot向量，所以这里（上图编号1所示）就是$o_{8928}$，乘以嵌入矩阵$E$，$E$可以从一个很大的文本集里学习到，比如它可以从一亿个词或者一百亿个词里学习嵌入，然后用来提取单词the的嵌入向量$e_{8928}$，对dessert、is、excellent做同样的步骤。 如果在很大的训练集上训练$E$，比如一百亿的单词，这样你就会获得很多知识，甚至从有些不常用的词中获取，然后应用到你的问题上，即使你的标记数据集里没有这些词。我们可以这样构建一个分类器，取这些向量（上图编号2所示），比如是300维度的向量。然后把它们求和或者求平均，这里我画一个大点的平均值计算单元（上图编号3所示），你也可以用求和或者平均。这个单元（上图编号3所示）会得到一个300维的特征向量，把这个特征向量送进softmax分类器，然后输出$\hat y$。这个softmax能够输出5个可能结果的概率值，从一星到五星，这个就是5个可能输出的softmax结果用来预测$y$的值。 这里用的平均值运算单元，这个算法适用于任何长短的评论，因为即使你的评论是100个词长，你也可以对这一百个词的特征向量求和或者平均它们，然后得到一个表示一个300维的特征向量表示，然后把它送进你的softmax分类器，所以这个平均值运算效果不错。它实际上会把所有单词的意思给平均起来，或者把你的例子中所有单词的意思加起来就可以用了。 这个算法有一个问题就是没考虑词序，尤其是这样一个负面的评价，”Completely lacking in good taste, good service, and good ambiance.“，但是good这个词出现了很多次，有3个good，如果你用的算法跟这个一样，忽略词序，仅仅把所有单词的词嵌入加起来或者平均下来，你最后的特征向量会有很多good的表示，你的分类器很可能认为这是一个好的评论，尽管事实上这是一个差评，只有一星的评价。 我们有一个更加复杂的模型，不用简单的把所有的词嵌入都加起来，我们用一个RNN来做情感分类。我们这样做，首先取这条评论，”Completely lacking in good taste, good service, and good ambiance.“，找出每一个one-hot向量，这里我跳过去每一个one-hot向量的表示。用每一个one-hot向量乘以词嵌入矩阵$E$，得到词嵌入表达$e$，然后把它们送进RNN里。RNN的工作就是在最后一步（上图编号1所示）计算一个特征表示，用来预测$\hat y$，这是一个多对一的网络结构的例子，我们之前已经见过了。有了这样的算法，考虑词的顺序效果就更好了，它就能意识到”things are lacking in good taste“，这是个负面的评价，“not good”也是一个负面的评价。而不像原来的算法一样，只是把所有的加在一起得到一个大的向量，根本意识不到“not good”和 “good”不是一个意思，”lacking in good taste“也是如此，等等。 如果你训练一个这样的算法，最后会得到一个很合适的情感分类的算法。由于你的词嵌入是在一个更大的数据集里训练的，这样效果会更好，更好的泛化一些没有见过的新的单词。比如其他人可能会说，”Completely absent of good taste, good service, and good ambiance.“，即使absent这个词不在标记的训练集里，如果是在一亿或者一百亿单词集里训练词嵌入，它仍然可以正确判断，并且泛化的很好，甚至这些词是在训练集中用于训练词嵌入的，但是可以不在专门用来做情感分类问题的标记的训练集中。 以上就是情感分类的问题，我希望你能大体了解。一旦你学习到或者从网上下载词嵌入，你就可以很快构建一个很有效的NLP系统。 2.10 词嵌入除偏（Debiasing Word Embeddings）现在机器学习和人工智能算法正渐渐地被信任用以辅助或是制定极其重要的决策，因此我们想尽可能地确保它们不受非预期形式偏见影响，比如说性别歧视、种族歧视等等。本节视频中我会向你展示词嵌入中一些有关减少或是消除这些形式的偏见的办法。 本节视频中当我使用术语bias时，我不是指bias本身这个词，或是偏见这种感觉，而是指性别、种族、性取向方面的偏见，那是不同的偏见，同时这也通常用于机器学习的学术讨论中。不过我们讨论的大部分内容是词嵌入是怎样学习类比像Man：Woman，就像King：Queen，不过如果你这样问，如果Man对应Computer Programmer，那么Woman会对应什么呢？所以这篇论文（上图编号1所示:Bolukbasi T, Chang K W, Zou J, et al. Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings[J]. 2016.）的作者Tolga Bolukbasi、Kai-Wei Chang、James Zou、Venkatesh Saligrama和 Adam Kalai发现了一个十分可怕的结果，就是说一个已经完成学习的词嵌入可能会输出Man：Computer Programmer，同时输出Woman：Homemaker，那个结果看起来是错的，并且它执行了一个十分不良的性别歧视。如果算法输出的是Man：Computer Programmer，同时Woman：Computer Programmer这样子会更合理。同时他们也发现如果Father：Doctor，那么Mother应该对应什么呢？一个十分不幸的结果是，有些完成学习的词嵌入会输出Mother：Nurse。 因此根据训练模型所使用的文本，词嵌入能够反映出性别、种族、年龄、性取向等其他方面的偏见，一件我尤其热衷的事是，这些偏见都和社会经济状态相关，我认为每个人不论你出身富裕还是贫穷，亦或是二者之间，我认为每个人都应当拥有好的机会，同时因为机器学习算法正用来制定十分重要的决策，它也影响着世间万物，从大学录取到人们找工作的途径，到贷款申请，不论你的的贷款申请是否会被批准，再到刑事司法系统，甚至是判决标准，学习算法都在作出非常重要的决策，所以我认为我们尽量修改学习算法来尽可能减少或是理想化消除这些非预期类型的偏见是十分重要的。 至于词嵌入，它们能够轻易学会用来训练模型的文本中的偏见内容，所以算法获取到的偏见内容就可以反映出人们写作中的偏见。在漫长的世纪里，我认为人类已经在减少这些类型的偏见上取得了进展，幸运的是对于人工智能来说，实际上我认为有更好的办法来实现更快地减少AI领域中相比与人类社会中的偏见。虽然我认为我们仍未实现人工智能，仍然有许多研究许多难题需要完成来减少学习算法中这些类型的偏见。 本节视频里我想要做的是与你们分享一个例子，它是一篇论文的一套办法，就是下面引用的这篇由Bolukbasi和其他人共同撰写的论文，它是研究减少词嵌入中偏见问题的。就是这些，假设说我们已经完成一个词嵌入的学习，那么babysitter就是在这里，doctor在这里，grandmother在这里，grandfather在这里，也许girl嵌入在这里，boy嵌入在这里，也许she嵌在这里，he在这里（上图编号1所示的区域内），所以首先我们要做的事就是辨别出我们想要减少或想要消除的特定偏见的趋势。 为了便于说明，我会集中讨论性别歧视，不过这些想法对于所有我在上个幻灯片里提及的其他类型的偏见都是通用的。这个例子中，你会怎样辨别出与这个偏见相似的趋势呢？主要有以下三个步骤： 一、对于性别歧视这种情况来说，我们能做的是$e_{\text{he} }-e_{\text{she} }$，因为它们的性别不同，然后将$e_{\text{male} }-e_{\text{female} }$，然后将这些值取平均（上图编号2所示），将这些差简单地求平均。这个趋势（上图编号3所示）看起来就是性别趋势或说是偏见趋势，然后这个趋势（上图编号4所示）与我们想要尝试处理的特定偏见并不相关，因此这就是个无偏见趋势。在这种情况下，偏见趋势可以将它看做1D子空间，所以这个无偏见趋势就会是299D的子空间。我已经略微简化了，原文章中的描述这个偏见趋势可以比1维更高，同时相比于取平均值，如同我在这里描述的这样，实际上它会用一个更加复杂的算法叫做SVU，也就是奇异值分解，如果你对主成分分析（Principle Component Analysis）很熟悉的话，奇异值分解这个算法的一些方法和主成分分析 (PCA)其实很类似。 二、中和步骤，所以对于那些定义不确切的词可以将其处理一下，避免偏见。有些词本质上就和性别有关，像grandmother、grandfather、girl、boy、she、he，他们的定义中本就含有性别的内容，不过也有一些词像doctor和babysitter我们想使之在性别方面是中立的。同时在更通常的情况下，你可能会希望像doctor或babysitter这些词成为种族中立的，或是性取向中立的等等，不过这里我们仍然只用性别来举例说明。对于那些定义不明确的词，它的基本意思是不像grandmother和grandfather这种定义里有着十分合理的性别含义的，因为从定义上来说grandmothers是女性，grandfather是男性。所以对于像doctor和babysitter这种单词我们就可以将它们在这个轴（上图编号1所示）上进行处理，来减少或是消除他们的性别歧视趋势的成分，也就是说减少他们在这个水平方向上的距离（上图编号2方框内所示的投影），所以这就是第二个中和步。 三、均衡步，意思是说你可能会有这样的词对，grandmother和grandfather，或者是girl和boy，对于这些词嵌入，你只希望性别是其区别。那为什么要那样呢？在这个例子中，babysitter和grandmother之间的距离或者说是相似度实际上是小于babysitter和grandfather之间的（上图编号1所示），因此这可能会加重不良状态，或者可能是非预期的偏见，也就是说grandmothers相比于grandfathers最终更有可能输出babysitting。所以在最后的均衡步中，我们想要确保的是像grandmother和grandfather这样的词都能够有一致的相似度，或者说是相等的距离，和babysitter或是doctor这样性别中立的词一样。这其中会有一些线性代数的步骤，但它主要做的就是将grandmother和grandfather移至与中间轴线等距的一对点上（上图编号2所示），现在性别歧视的影响也就是这两个词与babysitter的距离就完全相同了（上图编号3所示）。所以总体来说，会有许多对像grandmother-grandfather，boy-girl，sorority-fraternity，girlhood-boyhood，sister-brother，niece-nephew，daughter-son这样的词对，你可能想要通过均衡步来解决他们。 最后一个细节是你怎样才能够决定哪个词是中立的呢？对于这个例子来说doctor看起来像是一个应该对其中立的单词来使之性别不确定或是种族不确定。相反地，grandmother和grandfather就不应是性别不确定的词。也会有一些像是beard词，一个统计学上的事实是男性相比于比女性更有可能拥有胡子，因此也许beard应该比female更靠近male一些。 因此论文作者做的就是训练一个分类器来尝试解决哪些词是有明确定义的，哪些词是性别确定的，哪些词不是。结果表明英语里大部分词在性别方面上是没有明确定义的，意思就是说性别并是其定义的一部分，只有一小部分词像是grandmother-grandfather，girl-boy，sorority-fraternity等等，不是性别中立的。因此一个线性分类器能够告诉你哪些词能够通过中和步来预测这个偏见趋势，或将其与这个本质是299D的子空间进行处理。 最后，你需要平衡的词对的数实际上是很小的，至少对于性别歧视这个例子来说，用手都能够数出来你需要平衡的大部分词对。完整的算法会比我在这里展示的更复杂一些，你可以去看一下这篇论文了解详细内容，你也可以通过编程作业来练习一下这些想法。 参考资料：针对性别特定词汇的均衡算法 如何对两个单词除偏，比如：”actress“（“女演员”）和“actor”（“演员”）。 均衡算法适用于您可能希望仅通过性别属性不同的单词对。 举一个具体的例子，假设”actress“（“女演员”）比“actor”（“演员”）更接近“保姆”。 通过将中和应用于”babysit“（“保姆”），我们可以减少与保姆相关的性别刻板印象。 但是这仍然不能保证”actress“（“女演员”）和“actor”（“演员”）与”babysit“（“保姆”）等距。 均衡算法可以解决这个问题。 均衡背后的关键思想是确保一对特定的单词与49维$g_\perp$距离相等 。均衡步骤还可以确保两个均衡步骤现在与$e_{receptionist}^{debiased}$ 距离相同，或者用其他方法进行均衡。下图演示了均衡算法的工作原理： 公式的推导有点复杂(参考论文：Bolukbasi T, Chang K W, Zou J, et al. Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings[J]. 2016.) 主要步骤如下: $ \mu = \frac{e_{w1} + e_{w2} }{2}\tag{1}$ $ \mu_{B} = \frac {\mu * \text{bias_axis} }{||\text{bias_axis}||_2} + ||\text{bias_axis}||_2 *\text{bias_axis}\tag{2}$ $\mu_{\perp} = \mu - \mu_{B} \tag{3}$ $e_{w1B} = \sqrt{ |{1 - ||\mu_{\perp} ||^2_2} |} * \frac{(e_{ {w1} } - \mu_{\perp}) - \mu_B} {|(e_{w1} - \mu_{\perp}) - \mu_B)|} \tag{4}$ $e_{w2B} = \sqrt{ |{1 - ||\mu_{\perp} ||^2_2} |} * \frac{(e_{\text{w2} } - \mu_{\perp}) - \mu_B} {|(e_{w2} - \mu_{\perp}) - \mu_B)|} \tag{5}$ $e_1 = e_{w1B} + \mu_{\perp} \tag{6}$ $e_2 = e_{w2B} + \mu_{\perp} \tag{7}$ 总结一下，减少或者是消除学习算法中的偏见问题是个十分重要的问题，因为这些算法会用来辅助制定越来越多的社会中的重要决策，在本节视频中分享了一套如何尝试处理偏见问题的办法，不过这仍是一个许多学者正在进行主要研究的领域。 序列模型和注意力机制（Sequence models &amp; Attention mechanism）**3.1 基础模型（Basic Models）在这一周，你将会学习seq2seq（sequence to sequence）模型，从机器翻译到语音识别，它们都能起到很大的作用，从最基本的模型开始。之后你还会学习集束搜索（Beam search）和注意力模型（Attention Model），一直到最后的音频模型，比如语音。 现在就开始吧，比如你想通过输入一个法语句子，比如这句 “Jane visite I’Afrique en septembre.”，将它翻译成一个英语句子，“Jane is visiting Africa in September.”。和之前一样，我们用$x^{&lt;1&gt;}$ 一直到$x^{&lt; 5&gt;}$来表示输入的句子的单词，然后我们用$y^{&lt;1&gt;}$到$y^{&lt;6&gt;}$来表示输出的句子的单词，那么，如何训练出一个新的网络来输入序列$x$和输出序列$y$呢？ 这里有一些方法，这些方法主要都来自于两篇论文，作者是Sutskever，Oriol Vinyals 和 Quoc Le，另一篇的作者是Kyunghyun Cho，Bart van Merrienboer，Caglar Gulcehre，Dzmitry Bahdanau，Fethi Bougares，Holger Schwen 和 Yoshua Bengio。 首先，我们先建立一个网络，这个网络叫做编码网络（encoder network）（上图编号1所示），它是一个RNN的结构， RNN的单元可以是GRU 也可以是LSTM。每次只向该网络中输入一个法语单词，将输入序列接收完毕后，这个RNN网络会输出一个向量来代表这个输入序列。之后你可以建立一个解码网络，我把它画出来（上图编号2所示），它以编码网络的输出作为输入，编码网络是左边的黑色部分（上图编号1所示），之后它可以被训练为每次输出一个翻译后的单词，一直到它输出序列的结尾或者句子结尾标记，这个解码网络的工作就结束了。和往常一样我们把每次生成的标记都传递到下一个单元中来进行预测，就像之前用语言模型合成文本时一样。 深度学习在近期最卓越的成果之一就是这个模型确实有效，在给出足够的法语和英语文本的情况下，如果你训练这个模型，通过输入一个法语句子来输出对应的英语翻译，这个模型将会非常有效。这个模型简单地用一个编码网络来对输入的法语句子进行编码，然后用一个解码网络来生成对应的英语翻译。 还有一个与此类似的结构被用来做图像描述，给出一张图片，比如这张猫的图片（上图编号1所示），它能自动地输出该图片的描述，一只猫坐在椅子上，那么你如何训练出这样的网络？通过输入图像来输出描述，像这个句子一样。 方法如下，在之前的卷积网络课程中，你已经知道了如何将图片输入到卷积神经网络中，比如一个预训练的AlexNet结构（上图编号2方框所示），然后让其学习图片的编码，或者学习图片的一系列特征。现在幻灯片所展示的就是AlexNet结构，我们去掉最后的softmax单元（上图编号3所示），这个预训练的AlexNet结构会给你一个4096维的特征向量，向量表示的就是这只猫的图片，所以这个预训练网络可以是图像的编码网络。现在你得到了一个4096维的向量来表示这张图片，接着你可以把这个向量输入到RNN中（上图编号4方框所示），RNN要做的就是生成图像的描述，每次生成一个单词，这和我们在之前将法语译为英语的机器翻译中看到的结构很像，现在你输入一个描述输入的特征向量，然后让网络生成一个输出序列，或者说一个一个地输出单词序列。 事实证明在图像描述领域，这种方法相当有效，特别是当你想生成的描述不是特别长时。据我所知，这种模型首先是由Junhua Mao，Wei Xu，Yi Yang，Jiang Wang，Zhiheng Huang和Alan Yuille提出的，尽管有几个团队都几乎在同一时间构造出了非常相似的模型，因为还有另外两个团队也在同一时间得出了相似的结论。我觉得有可能Mao的团队和Oriol Vinyals，Alexander Toshev，Samy Bengio和Dumitru Erhan，还有Andrej Karpathy和Fei-Fei Yi是同一个团队。 现在你知道了基本的seq2seq模型是怎样运作的，以及image to sequence模型或者说图像描述模型是怎样运作的。不过这两个模型运作方式有一些不同，主要体现在如何用语言模型合成新的文本，并生成对应序列的方面。一个主要的区别就是你大概不会想得到一个随机选取的翻译，你想要的是最准确的翻译，或者说你可能不想要一个随机选取的描述，你想要的是最好的最贴切的描述，我们将在下节视频中介绍如何生成这些序列。 3.2 选择最可能的句子（Picking the most likely sentence）在seq2seq机器翻译模型和我们在第一周课程所用的语言模型之间有很多相似的地方，但是它们之间也有许多重要的区别，让我们来一探究竟。 你可以把机器翻译想成是建立一个条件语言模型，在语言模型中上方是一个我们在第一周所建立的模型，这个模型可以让你能够估计句子的可能性，这就是语言模型所做的事情。你也可以将它用于生成一个新的句子，如果你在图上的该处（下图编号1所示），有$x^{&lt;1&gt;}$和$x^{&lt;2&gt;}$，那么在该例中$x^{&lt;2&gt;} = y^{&lt;1&gt;}$，但是$x^{&lt;1&gt;}$、$x^{&lt;2&gt;}$等在这里并不重要。为了让图片看起来更简洁，我把它们先抹去，可以理解为$x^{&lt;1&gt;}$是一个全为0的向量，然后$x^{&lt;2&gt;}$、$x^{&lt;3&gt;}$等都等于之前所生成的输出，这就是所说的语言模型。 而机器翻译模型是下面这样的，我这里用两种不同的颜色来表示，即绿色和紫色，用绿色（上图编号2所示）表示encoder网络，用紫色（上图编号3所示）表示decoder网络。你会发现decoder网络看起来和刚才所画的语言模型几乎一模一样，机器翻译模型其实和语言模型非常相似，不同在于语言模型总是以零向量（上图编号4所示）开始，而encoder网络会计算出一系列向量（上图编号2所示）来表示输入的句子。有了这个输入句子，decoder网络就可以以这个句子开始，而不是以零向量开始，所以我把它叫做条件语言模型（conditional language model）。相比语言模型，输出任意句子的概率，翻译模型会输出句子的英文翻译（上图编号5所示），这取决于输入的法语句子（上图编号6所示）。换句话说，你将估计一个英文翻译的概率，比如估计这句英语翻译的概率，”Jane is visiting Africa in September.“，这句翻译是取决于法语句子，”Jane visite I’Afrique en septembre.“，这就是英语句子相对于输入的法语句子的可能性，所以它是一个条件语言模型。 现在，假如你想真正地通过模型将法语翻译成英文，通过输入的法语句子模型将会告诉你各种英文翻译所对应的可能性。$x$在这里是法语句子”Jane visite l’Afrique en septembre.“，而它将告诉你不同的英语翻译所对应的概率。显然你不想让它随机地进行输出，如果你从这个分布中进行取样得到$P(y|x)$，可能取样一次就能得到很好的翻译，”Jane is visiting Africa in September.“。但是你可能也会得到一个截然不同的翻译，”Jane is going to be visiting Africa in September.“，这句话听起来有些笨拙，但它不是一个糟糕的翻译，只是不是最好的而已。有时你也会偶然地得到这样的翻译，”In September, Jane will visit Africa.“，或者有时候你还会得到一个很糟糕的翻译，”Her African friend welcomed Jane in September.“。所以当你使用这个模型来进行机器翻译时，你并不是从得到的分布中进行随机取样，而是你要找到一个英语句子$y$（上图编号1所示），使得条件概率最大化。所以在开发机器翻译系统时，你需要做的一件事就是想出一个算法，用来找出合适的$y$值，使得该项最大化，而解决这种问题最通用的算法就是束搜索(Beam Search)，你将会在下节课见到它。 不过在了解束搜索之前，你可能会问一个问题，为什么不用贪心搜索(Greedy Search)呢？贪心搜索是一种来自计算机科学的算法，生成第一个词的分布以后，它将会根据你的条件语言模型挑选出最有可能的第一个词进入你的机器翻译模型中，在挑选出第一个词之后它将会继续挑选出最有可能的第二个词，然后继续挑选第三个最有可能的词，这种算法就叫做贪心搜索，但是你真正需要的是一次性挑选出整个单词序列，从$y^{&lt;1&gt;}$、$y^{&lt;2&gt;}$到$y^{&lt;T_{y}&gt;}$来使得整体的概率最大化。所以这种贪心算法先挑出最好的第一个词，在这之后再挑最好的第二词，然后再挑第三个，这种方法其实并不管用，为了证明这个观点，我们来考虑下面两种翻译。 第一串（上图编号1所示）翻译明显比第二个（上图编号2所示）好，所以我们希望机器翻译模型会说第一个句子的$P(y|x)$比第二个句子要高，第一个句子对于法语原文来说更好更简洁，虽然第二个也不错，但是有些啰嗦，里面有很多不重要的词。但如果贪心算法挑选出了”Jane is“作为前两个词，因为在英语中going更加常见，于是对于法语句子来说”Jane is going“相比”Jane is visiting“会有更高的概率作为法语的翻译，所以很有可能如果你仅仅根据前两个词来估计第三个词的可能性，得到的就是going，最终你会得到一个欠佳的句子，在$P(y|x)$模型中这不是一个最好的选择。 我知道这种说法可能比较粗略，但是它确实是一种广泛的现象，当你想得到单词序列$y^{&lt;1&gt;}$、$y^{&lt;2&gt;}$一直到最后一个词总体的概率时，一次仅仅挑选一个词并不是最佳的选择。当然，在英语中各种词汇的组合数量还有很多很多，如果你的字典中有10,000个单词，并且你的翻译可能有10个词那么长，那么可能的组合就有10,000的10次方这么多，这仅仅是10个单词的句子，从这样大一个字典中来挑选单词，所以可能的句子数量非常巨大，不可能去计算每一种组合的可能性。所以这时最常用的办法就是用一个近似的搜索算法，这个近似的搜索算法做的就是它会尽力地，尽管不一定总会成功，但它将挑选出句子$y$使得条件概率最大化，尽管它不能保证找到的$y$值一定可以使概率最大化，但这已经足够了。 最后总结一下，在本视频中，你看到了机器翻译是如何用来解决条件语言模型问题的，这个模型和之前的语言模型一个主要的区别就是，相比之前的模型随机地生成句子，在该模型中你要找到最有可能的英语句子，最可能的英语翻译，但是可能的句子组合数量过于巨大，无法一一列举，所以我们需要一种合适的搜索算法，让我们在下节课中学习集束搜索。 3.3 集束搜索（Beam Search）这节视频中你会学到集束搜索（beam search）算法，上节视频中我们讲了对于机器翻译来说，给定输入，比如法语句子，你不会想要输出一个随机的英语翻译结果，你想要一个最好的，最可能的英语翻译结果。对于语音识别也一样，给定一个输入的语音片段，你不会想要一个随机的文本翻译结果，你想要最好的，最接近原意的翻译结果，集束搜索就是解决这个最常用的算法。这节视频里，你会明白怎么把集束搜索算法应用到你自己的工作中，就用我们的法语句子的例子来试一下集束搜索吧。 “Jane visite l’Afrique en Septembre.”（法语句子），我们希望翻译成英语，”Jane is visiting Africa in September“.（英语句子），集束搜索算法首先做的就是挑选要输出的英语翻译中的第一个单词。这里我列出了10,000个词的词汇表（下图编号1所示），为了简化问题，我们忽略大小写，所有的单词都以小写列出来。在集束搜索的第一步中我用这个网络部分，绿色是编码部分（下图编号2所示），紫色是解码部分（下图编号3所示），来评估第一个单词的概率值，给定输入序列$x$，即法语作为输入，第一个输出$y$的概率值是多少。 贪婪算法只会挑出最可能的那一个单词，然后继续。而集束搜索则会考虑多个选择，集束搜索算法会有一个参数B，叫做集束宽（beam width）。在这个例子中我把这个集束宽设成3，这样就意味着集束搜索不会只考虑一个可能结果，而是一次会考虑3个，比如对第一个单词有不同选择的可能性，最后找到in、jane、september，是英语输出的第一个单词的最可能的三个选项，然后集束搜索算法会把结果存到计算机内存里以便后面尝试用这三个词。如果集束宽设的不一样，如果集束宽这个参数是10的话，那么我们跟踪的不仅仅3个，而是10个第一个单词的最可能的选择。所以要明白，为了执行集束搜索的第一步，你需要输入法语句子到编码网络，然后会解码这个网络，这个softmax层（上图编号3所示）会输出10,000个概率值，得到这10,000个输出的概率值，取前三个存起来。 让我们看看集束搜索算法的第二步，已经选出了in、jane、september作为第一个单词三个最可能的选择，集束算法接下来会针对每个第一个单词考虑第二个单词是什么，单词in后面的第二个单词可能是a或者是aaron，我就是从词汇表里把这些词列了出来，或者是列表里某个位置，september，可能是列表里的 visit，一直到字母z，最后一个单词是zulu（下图编号1所示）。 为了评估第二个词的概率值，我们用这个神经网络的部分，绿色是编码部分（上图编号2所示），而对于解码部分，当决定单词in后面是什么，别忘了解码器的第一个输出$y^{&lt;1&gt;}$，我把$y^{&lt;1&gt;}$设为单词in（上图编号3所示），然后把它喂回来，这里就是单词in（上图编号4所示），因为它的目的是努力找出第一个单词是in的情况下，第二个单词是什么。这个输出就是$y^{&lt;2&gt;}$（上图编号5所示），有了这个连接（上图编号6所示），就是这里的第一个单词in（上图编号4所示）作为输入，这样这个网络就可以用来评估第二个单词的概率了，在给定法语句子和翻译结果的第一个单词in的情况下。 注意，在第二步里我们更关心的是要找到最可能的第一个和第二个单词对，所以不仅仅是第二个单词有最大的概率，而是第一个、第二个单词对有最大的概率（上图编号7所示）。按照条件概率的准则，这个可以表示成第一个单词的概率（上图编号8所示）乘以第二个单词的概率（上图编号9所示），这个可以从这个网络部分里得到（上图编号10所示），对于已经选择的in、jane、september这三个单词，你可以先保存这个概率值（上图编号8所示），然后再乘以第二个概率值（上图编号9所示）就得到了第一个和第二个单词对的概率（上图编号7所示）。 现在你已经知道在第一个单词是in的情况下如何评估第二个单词的概率，现在第一个单词是jane，道理一样，句子可能是”jane a“、”jane aaron“，等等到”jane is“、”jane visits“等等（上图编号1所示）。你会用这个新的网络部分（上图编号2所示），我在这里画一条线，代表从$y^{&lt;1&gt;}$，即jane，$y^{&lt; 1 &gt;}$连接jane（上图编号3所示），那么这个网络部分就可以告诉你给定输入$x$和第一个词是jane下，第二个单词的概率了（上图编号4所示），和上面一样，你可以乘以$P(y^{&lt;1&gt;}|x)$得到$P(y^{&lt;1&gt;},y^{&lt;2&gt;}|x)$。 针对第二个单词所有10,000个不同的选择，最后对于单词september也一样，从单词a到单词zulu，用这个网络部分，我把它画在这里。来看看如果第一个单词是september，第二个单词最可能是什么。所以对于集束搜索的第二步，由于我们一直用的集束宽为3，并且词汇表里有10,000个单词，那么最终我们会有3乘以10,000也就是30,000个可能的结果，因为这里（上图编号1所示）是10,000，这里（上图编号2所示）是10,000，这里（上图编号3所示）是10,000，就是集束宽乘以词汇表大小，你要做的就是评估这30,000个选择。按照第一个词和第二个词的概率，然后选出前三个，这样又减少了这30,000个可能性，又变成了3个，减少到集束宽的大小。假如这30,000个选择里最可能的是“in September”（上图编号4所示）和“jane is”（上图编号5所示），以及“jane visits”（上图编号6所示），画的有点乱，但这就是这30,000个选择里最可能的三个结果，集束搜索算法会保存这些结果，然后用于下一次集束搜索。 注意一件事情，如果集束搜索找到了第一个和第二个单词对最可能的三个选择是“in September”或者“jane is”或者“jane visits”，这就意味着我们去掉了september作为英语翻译结果的第一个单词的选择，所以我们的第一个单词现在减少到了两个可能结果，但是我们的集束宽是3，所以还是有$y^{&lt;1&gt;}$，$y^{&lt;2&gt;}$对的三个选择。 在我们进入集束搜索的第三步之前，我还想提醒一下因为我们的集束宽等于3，每一步我们都复制3个，同样的这种网络来评估部分句子和最后的结果，由于集束宽等于3，我们有三个网络副本（上图编号7所示），每个网络的第一个单词不同，而这三个网络可以高效地评估第二个单词所有的30,000个选择。所以不需要初始化30,000个网络副本，只需要使用3个网络的副本就可以快速的评估softmax的输出，即$y^{&lt;2&gt;}$的10,000个结果。 让我们快速解释一下集束搜索的下一步，前面说过前两个单词最可能的选择是“in September”和“jane is”以及“jane visits”，对于每一对单词我们应该保存起来，给定输入$x$，即法语句子作为$x$的情况下，$y^{&lt;1&gt;}$和$y^{&lt;2&gt;}$的概率值和前面一样，现在我们考虑第三个单词是什么，可以是“in September a”，可以是“in September aaron”，一直到“in September zulu”。为了评估第三个单词可能的选择，我们用这个网络部分，第一单词是in（上图编号1所示），第二个单词是september（上图编号2所示），所以这个网络部分可以用来评估第三个单词的概率，在给定输入的法语句子$x$和给定的英语输出的前两个单词“in September”情况下（上图编号3所示）。对于第二个片段来说也一样，就像这样一样（上图编号4所示），对于“jane visits”也一样，然后集束搜索还是会挑选出针对前三个词的三个最可能的选择，可能是“in september jane”（上图编号5所示），“Jane is visiting”也很有可能（上图编号6所示），也很可能是“Jane visits Africa”（上图编号7所示）。 然后继续，接着进行集束搜索的第四步，再加一个单词继续，最终这个过程的输出一次增加一个单词，集束搜索最终会找到“Jane visits africa in september”这个句子，终止在句尾符号（上图编号8所示），用这种符号的系统非常常见，它们会发现这是最有可能输出的一个英语句子。在本周的练习中，你会看到更多的执行细节，同时，你会运用到这个集束算法，在集束宽为3时，集束搜索一次只考虑3个可能结果。注意如果集束宽等于1，只考虑1种可能结果，这实际上就变成了贪婪搜索算法，上个视频里我们已经讨论过了。但是如果同时考虑多个，可能的结果比如3个，10个或者其他的个数，集束搜索通常会找到比贪婪搜索更好的输出结果。 你已经了解集束搜索是如何工作的了，事实上还有一些额外的提示和技巧的改进能够使集束算法更高效，我们在下个视频中一探究竟。 3.4 改进集束搜索（Refinements to Beam Search）上个视频中, 你已经学到了基本的束搜索算法(the basic beam search algorithm)，这个视频里,我们会学到一些技巧, 能够使算法运行的更好。长度归一化（Length normalization）就是对束搜索算法稍作调整的一种方式，帮助你得到更好的结果，下面介绍一下它。 前面讲到束搜索就是最大化这个概率，这个乘积就是$P(y^{&lt; 1 &gt;}\ldots y^{&lt; T_{y} }|X)$，可以表示成:$P(y^{&lt;1&gt;}|X)$ $P(y^{&lt; 2 &gt;}|X,y^{&lt; 1 &gt;})$ $P(y^{&lt; 3 &gt;}|X,y^{&lt; 1 &gt;},y^{&lt; 2&gt;})$…$P(y^{&lt; T_{y} &gt;}|X,y^{&lt;1 &gt;},y^{&lt;2 &gt;}\ldots y^{&lt; T_{y} - 1 &gt;})$ 这些符号看起来可能比实际上吓人，但这就是我们之前见到的乘积概率（the product probabilities）。如果计算这些，其实这些概率值都是小于1的，通常远小于1。很多小于1的数乘起来，会得到很小很小的数字，会造成数值下溢（numerical underflow）。数值下溢就是数值太小了，导致电脑的浮点表示不能精确地储存，因此在实践中,我们不会最大化这个乘积，而是取$log$值。如果在这加上一个$log$，最大化这个$log$求和的概率值，在选择最可能的句子$y$时，你会得到同样的结果。所以通过取$log$，我们会得到一个数值上更稳定的算法，不容易出现四舍五入的误差，数值的舍入误差（rounding errors）或者说数值下溢（numerical underflow）。因为$log$函数它是严格单调递增的函数，最大化$P(y)$，因为对数函数，这就是$log$函数，是严格单调递增的函数，所以最大化$logP(y|x)$和最大化$P(y|x)$结果一样。如果一个$y$值能够使前者最大，就肯定能使后者也取最大。所以实际工作中，我们总是记录概率的对数和（the sum of logs of the probabilities），而不是概率的乘积（the production of probabilities）。 对于目标函数（this objective function），还可以做一些改变，可以使得机器翻译表现的更好。如果参照原来的目标函数（this original objective），如果有一个很长的句子，那么这个句子的概率会很低，因为乘了很多项小于1的数字来估计句子的概率。所以如果乘起来很多小于1的数字，那么就会得到一个更小的概率值，所以这个目标函数有一个缺点，它可能不自然地倾向于简短的翻译结果，它更偏向短的输出，因为短句子的概率是由更少数量的小于1的数字乘积得到的，所以这个乘积不会那么小。顺便说一下，这里也有同样的问题，概率的$log$值通常小于等于1，实际上在$log$的这个范围内，所以加起来的项越多，得到的结果越负，所以对这个算法另一个改变也可以使它表现的更好，也就是我们不再最大化这个目标函数了，我们可以把它归一化，通过除以翻译结果的单词数量（normalize this by the number of words in your translation）。这样就是取每个单词的概率对数值的平均了，这样很明显地减少了对输出长的结果的惩罚（this significantly reduces the penalty for outputting longer translations.）。 在实践中，有个探索性的方法，相比于直接除$T_{y}$，也就是输出句子的单词总数，我们有时会用一个更柔和的方法（a softer approach），在$T_{y}$上加上指数$a$，$a$可以等于0.7。如果$a$等于1，就相当于完全用长度来归一化，如果$a$等于0，$T_{y}$的0次幂就是1，就相当于完全没有归一化，这就是在完全归一化和没有归一化之间。$a$就是算法另一个超参数（hyper parameter），需要调整大小来得到最好的结果。不得不承认，这样用$a$实际上是试探性的，它并没有理论验证。但是大家都发现效果很好，大家都发现实践中效果不错，所以很多人都会这么做。你可以尝试不同的$a$值，看看哪一个能够得到最好的结果。 总结一下如何运行束搜索算法。当你运行束搜索时，你会看到很多长度等于1的句子，很多长度等于2的句子，很多长度等于3的句子，等等。可能运行束搜索30步，考虑输出的句子可能达到，比如长度30。因为束宽为3，你会记录所有这些可能的句子长度，长度为1、2、 3、 4 等等一直到30的三个最可能的选择。然后针对这些所有的可能的输出句子，用这个式子（上图编号1所示）给它们打分，取概率最大的几个句子，然后对这些束搜索得到的句子，计算这个目标函数。最后从经过评估的这些句子中，挑选出在归一化的$log$ 概率目标函数上得分最高的一个（you pick the one that achieves the highest value on this normalized log probability objective.），有时这个也叫作归一化的对数似然目标函数（a normalized log likelihood objective）。这就是最终输出的翻译结果，这就是如何实现束搜索。这周的练习中你会自己实现这个算法。 最后还有一些实现的细节，如何选择束宽B。B越大，你考虑的选择越多，你找到的句子可能越好，但是B越大，你的算法的计算代价越大，因为你要把很多的可能选择保存起来。最后我们总结一下关于如何选择束宽B的一些想法。接下来是针对或大或小的B各自的优缺点。如果束宽很大，你会考虑很多的可能，你会得到一个更好的结果，因为你要考虑很多的选择，但是算法会运行的慢一些，内存占用也会增大，计算起来会慢一点。而如果你用小的束宽，结果会没那么好，因为你在算法运行中，保存的选择更少，但是你的算法运行的更快，内存占用也小。在前面视频里，我们例子中用了束宽为3，所以会保存3个可能选择，在实践中这个值有点偏小。在产品中，经常可以看到把束宽设到10，我认为束宽为100对于产品系统来说有点大了，这也取决于不同应用。但是对科研而言，人们想压榨出全部性能，这样有个最好的结果用来发论文，也经常看到大家用束宽为1000或者3000，这也是取决于特定的应用和特定的领域。在你实现你的应用时，尝试不同的束宽的值，当B很大的时候，性能提高会越来越少。对于很多应用来说，从束宽1，也就是贪心算法，到束宽为3、到10，你会看到一个很大的改善。但是当束宽从1000增加到3000时，效果就没那么明显了。对于之前上过计算机科学课程的同学来说，如果你熟悉计算机科学里的搜索算法（computer science search algorithms）, 比如广度优先搜索（BFS, Breadth First Search algorithms），或者深度优先搜索（DFS, Depth First Search），你可以这样想束搜索，不像其他你在计算机科学算法课程中学到的算法一样。如果你没听说过这些算法也不要紧，但是如果你听说过广度优先搜索和深度优先搜索，不同于这些算法，这些都是精确的搜索算法（exact search algorithms），束搜索运行的更快，但是不能保证一定能找到argmax的准确的最大值。如果你没听说过广度优先搜索和深度优先搜索，也不用担心，这些对于我们的目标也不重要，如果你听说过，这就是束搜索和其他算法的关系。 好，这就是束搜索。这个算法广泛应用在多产品系统或者许多商业系统上，在深度学习系列课程中的第三门课中，我们讨论了很多关于误差分析（error analysis）的问题。事实上在束搜索上做误差分析是我发现的最有用的工具之一。有时你想知道是否应该增大束宽，我的束宽是否足够好，你可以计算一些简单的东西来指导你需要做什么，来改进你的搜索算法。我们在下个视频里进一步讨论。 3.5 集束搜索的误差分析（Error analysis in beam search）在这五门课中的第三门课里，你了解了误差分析是如何能够帮助你集中时间做你的项目中最有用的工作，束搜索算法是一种近似搜索算法（an approximate search algorithm），也被称作启发式搜索算法（a heuristic search algorithm），它不总是输出可能性最大的句子，它仅记录着B为前3或者10或是100种可能。那么如果束搜索算法出现错误会怎样呢? 本节视频中，你将会学习到误差分析和束搜索算法是如何相互起作用的，以及你怎样才能发现是束搜索算法出现了问题，需要花时间解决，还是你的RNN模型出了问题，要花时间解决。我们先来看看如何对束搜索算法进行误差分析。 我们来用这个例子说明： “Jane visite l’Afrique en septembre”。假如说，在你的机器翻译的dev集中，也就是开发集（development set），人工是这样翻译的: Jane visits Africa in September,我会将这个标记为$y^$。这是一个十分不错的人工翻译结果，不过假如说，当你在已经完成学习的*RNN模型，也就是已完成学习的翻译模型中运行束搜索算法时，它输出了这个翻译结果：Jane visited Africa last September**，我们将它标记为$\hat y$。这是一个十分糟糕的翻译，它实际上改变了句子的原意，因此这不是个好翻译。 你的模型有两个主要部分，一个是神经网络模型，或说是序列到序列模型（sequence to sequence model），我们将这个称作是RNN模型，它实际上是个编码器和解码器（ an encoder and a decoder）。另一部分是束搜索算法，以某个集束宽度B运行。如果你能够找出造成这个错误，这个不太好的翻译的原因，是两个部分中的哪一个，不是很好吗? RNN (循环神经网络)是更可能是出错的原因呢，还是束搜索算法更可能是出错的原因呢？你在第三门课中了解到了大家很容易想到去收集更多的训练数据，这总归没什么坏处。所以同样的，大家也会觉得不行就增大束宽，也是不会错的，或者说是很大可能是没有危害的。但是就像单纯获取更多训练数据，可能并不能得到预期的表现结果。相同的，单纯增大束宽也可能得不到你想要的结果，不过你怎样才能知道是不是值得花时间去改进搜索算法呢?下面我们来分解这个问题弄清楚什么情况下该用什么解决办法。 RNN (循环神经网络)实际上是个编码器和解码器（the encoder and the decoder），它会计算$P(y|x)$。所以举个例子，对于这个句子：Jane visits Africa in September，你将Jane visits Africa填入这里（上图编号1所示），同样，我现在忽略了字母的大小写，后面也是一样，然后这个就会计算。$P(y|x)$结果表明，你此时能做的最有效的事就是用这个模型来计算$P(y^|x)$，同时也用你的RNN模型来计算$P(\hat y|x)$，然后比较一下这两个值哪个更大。有可能是左边大于右边，也有可能是$P(y^)$小于$P(\hat y)$，其实应该是小于或等于，对吧。取决于实际是哪种情况，你就能够更清楚地将这个特定的错误归咎于RNN或是束搜索算法，或说是哪个负有更大的责任。我们来探究一下其中的逻辑。 这是之前幻灯片里的两个句子。记住，我们是要计算$P(y^*|x)$和$P(\hat y|x)$，然后比较这两个哪个更大，所以就会有两种情况。 第一种情况，RNN模型的输出结果$P(y^|x)$ 大于$P(\hat y|x)$，这意味着什么呢?束搜索算法选择了$\hat y$ ，对吧?你得到$\hat y$的方式是，你用一个RNN模型来计算$P(y|x)$，然后束搜索算法做的就是尝试寻找使$P(y|x)$最大的$y$，不过在这种情况下，相比于$\hat y$，$y^$的值更$P(y|x)$大，因此你能够得出束搜索算法实际上不能够给你一个能使$P(y|x)$最大化的$y$值，因为束搜索算法的任务就是寻找一个$y$的值来使这项更大，但是它却选择了$\hat y$，而$y^*$实际上能得到更大的值。因此这种情况下你能够得出是束搜索算法出错了。那另一种情况是怎样的呢? 第二种情况是$P(y^|x)$小于或等于$P(\hat y|x)$对吧？这两者之中总有一个是真的。情况1或是情况2总有一个为真。情况2你能够总结出什么呢?在我们的例子中，$y^$ 是比 $\hat y$更好的翻译结果，不过根据RNN模型的结果，$P(y^)$ 是小于$P(\hat y)$的，也就是说，相比于$\hat y$，$y^$成为输出的可能更小。因此在这种情况下，看来是RNN模型出了问题。同时可能值得在RNN模型上花更多时间。这里我少讲了一些有关长度归一化（length normalizations）的细节。这里我略过了有关长度归一化的细节，如果你用了某种长度归一化，那么你要做的就不是比较这两种可能性大小，而是比较长度归一化后的最优化目标函数值。不过现在先忽略这种复杂的情况。第二种情况表明虽然$y^$是一个更好的翻译结果，*RNN模型却赋予它更低的可能性，是RNN**模型出现了问题。 所以误差分析过程看起来就像下面这样。你先遍历开发集，然后在其中找出算法产生的错误，这个例子中，假如说$P(y^|x)$的值为2 x 10-10，而$P(\hat y|x)$的值为 1 x10-10，根据上页幻灯片中的逻辑关系，这种情况下我们得知束搜索算法实际上选择了比$y^$可能性更低的$\hat y$，因此我会说束搜索算法出错了。我将它缩写为B。接着你继续遍历第二个错误，再来看这些可能性。也许对于第二个例子来说，你认为是RNN模型出现了问题，我会用缩写R来代表RNN。再接着你遍历了更多的例子，有时是束搜索算法出现了问题，有时是模型出现了问题，等等。通过这个过程，你就能够执行误差分析，得出束搜索算法和RNN模型出错的比例是多少。有了这样的误差分析过程，你就可以对开发集中每一个错误例子，即算法输出了比人工翻译更差的结果的情况，尝试确定这些错误，是搜索算法出了问题，还是生成目标函数(束搜索算法使之最大化)的RNN模型出了问题。并且通过这个过程，你能够发现这两个部分中哪个是产生更多错误的原因，并且只有当你发现是束搜索算法造成了大部分错误时，才值得花费努力增大集束宽度。相反地，如果你发现是RNN模型出了更多错，那么你可以进行更深层次的分析，来决定是需要增加正则化还是获取更多的训练数据，抑或是尝试一个不同的网络结构，或是其他方案。你在第三门课中，了解到各种技巧都能够应用在这里。 这就是束搜索算法中的误差分析，我认为这个特定的误差分析过程是十分有用的，它可以用于分析近似最佳算法(如束搜索算法)，这些算法被用来优化学习算法(例如序列到序列模型/RNN)输出的目标函数。也就是我们这些课中一直讨论的。学会了这个方法，我希望你能够在你的应用里更有效地运用好这些类型的模型。 3.6 Bleu 得分（选修）（Bleu Score (optional)）机器翻译（machine translation）的一大难题是一个法语句子可以有多种英文翻译而且都同样好，所以当有多个同样好的答案时，怎样评估一个机器翻译系统呢？不像图像识别（image recognition），只有一个正确答案，就只要测量准确性就可以了。如果有多个不错的答案，要怎样衡量准确性呢?常见的解决办法是，通过一个叫做BLEU得分（the BLEU score）的东西来解决。所以，在这个选修视频中，我想与你分享，我想让你了解BLEU得分是怎样工作的。 假如给你一个法语句子：Le chat est sur le tapis，然后给你一个这个句子的人工翻译作参考：The cat is on the mat。不过有多种相当不错的翻译。所以一个不同的人，也许会将其翻译为：There is a cat on the mat，同时，实际上这两个都是很好的，都准确地翻译了这个法语句子。BLEU得分做的就是，给定一个机器生成的翻译，它能够自动地计算一个分数来衡量机器翻译的好坏。直觉告诉我们，只要这个机器生成的翻译与任何一个人工翻译的结果足够接近，那么它就会得到一个高的BLEU分数。顺便提一下BLEU代表bilingual evaluation understudy (双语评估替补)。在戏剧界，侯补演员(understudy)学习资深的演员的角色，这样在必要的时候，他们就能够接替这些资深演员。而BLEU的初衷是相对于请评估员（ask human evaluators），人工评估机器翻译系统（the machine translation system），BLEU得分就相当于一个侯补者，它可以代替人类来评估机器翻译的每一个输出结果。BLEU得分是由Kishore Papineni, Salim Roukos，Todd Ward和Wei-Jing Zhu发表的这篇论文十分有影响力并且实际上也是一篇很好读的文章。所以如果有时间的话，我推荐你读一下。BLEU得分背后的理念是观察机器生成的翻译，然后看生成的词是否出现在少一个人工翻译参考之中。因此这些人工翻译的参考会包含在开发集或是测试集中。 （参考论文：Papineni, Kishore&amp; Roukos, Salim &amp; Ward, Todd &amp; Zhu, Wei-jing. (2002). BLEU: a Method for Automatic Evaluation of Machine Translation.10.3115/1073083.1073135.） 现在，我们来看一个极端的例子。我们假设机器翻译系统缩写为MT。机器翻译 (MT)的输出是：the the the the the the the。这显然是一个十分糟糕的翻译。衡量机器翻译输出质量的方法之一是观察输出结果的每一个词看其是否出现在参考中，这被称做是机器翻译的精确度（a precision of the machine translation output）。这个情况下，机器翻译输出了七个单词并且这七个词中的每一个都出现在了参考1或是参考2。单词the在两个参考中都出现了，所以看上去每个词都是很合理的。因此这个输出的精确度就是7/7，看起来是一个极好的精确度。这就是为什么把出现在参考中的词在MT输出的所有词中所占的比例作为精确度评估标准并不是很有用的原因。因为它似乎意味着，例子中MT输出的翻译有很高的精确度，因此取而代之的是我们要用的这个改良后的精确度评估方法，我们把每一个单词的记分上限定为它在参考句子中出现的最多次数。在参考1中，单词the出现了两次，在参考2中，单词the只出现了一次。而2比1大，所以我们会说，单词the的得分上限为2。有了这个改良后的精确度，我们就说，这个输出句子的得分为2/7，因为在7个词中，我们最多只能给它2分。所以这里分母就是7个词中单词the总共出现的次数，而分子就是单词the出现的计数。我们在达到上限时截断计数，这就是改良后的精确度评估（the modified precision measure）。 到目前为止，我们都只是关注单独的单词，在BLEU得分中，你不想仅仅考虑单个的单词，你也许也想考虑成对的单词，我们定义一下二元词组（bigrams）的BLEU得分。bigram的意思就是相邻的两个单词。现在我们来看看怎样用二元词组来定义BLEU得分，并且这仅仅只是最终的BLEU得分的一部分。我们会考虑一元词组（unigrams）也就是单个单词以及二元词组（bigrams），即成对的词，同时也许会有更长的单词序列，比如说三元词组（trigrams）。意思是三个挨在一起的词。我们继续刚才的例子，还是前面出现过的参考1和2，不过现在我们假定机器翻译输出了稍微好一点的翻译:The cat the cat on the mat，仍然不是一个好的翻译，不过也许比上一个好一些。这里，可能的二元词组有the cat ，忽略大小写，接着是cat the， 这是另一个二元词组，然后又是the cat。不过我已经有了，所以我们跳过它，然后下一个是cat on，然后是on the，再然后是the mat。所以这些就是机器翻译中的二元词组。好，我们来数一数每个二元词组出现了多少次。the cat出现了两次 ，cat the出现了一次，剩下的都只出现了一次。最后 ，我们来定义一下截取计数（the clipped count）。也就是Count_clip。为了定义它，我们以这列的值为基础，但是给算法设置得分上限，上限值为二元词组出现在参考1或2中的最大次数。the cat在两个参考中最多出现一次，所以我将截取它的计数为1。cat the它并没有出现在参考1和参考2中，所以我将它截取为0。cat on ，好，它出现了一次，我们就记1分。on the出现一次就记1分，the mat出现了一次，所以这些就是截取完的计数（the clipped counts）。我们把所有的这些计数都截取了一遍，实际上就是将它们降低使之不大于二元词组出现在参考中的次数。最后，修改后的二元词组的精确度就是count_clip之和。因此那就是4除以二元词组的总个数，也就是6。因此是4/6也就是2/3为二元词组改良后的精确度。 现在我们将它公式化。基于我们在一元词组中学到的内容，我们将改良后的一元词组精确度定义为$P_1$，$P$代表的是精确度。这里的下标1的意思是一元词组。不过它定义为一元词组之和，也就是对机器翻译结果中所有单词求和，MT 输出就是$\hat y$，Countclip(unigram)。除以机器翻译输出中的一元词组出现次数之和。因此这个就是最终结果应该是两页幻灯片前得到的2/7。这里的1指代的是一元词组，意思是我们在考虑单独的词，你也可以定义$P_n$为$n$元词组精确度，用n-gram替代掉一元词组。所以这就是机器翻译输出中的$n$元词组的countclip之和除以$n$元词组的出现次数之和。因此这些精确度或说是这些改良后的精确度得分评估的是一元词组或是二元词组。就是我们前页幻灯片中做的，或者是三元词组，也就是由三个词组成的，甚至是$n$取更大数值的$n$元词组。这个方法都能够让你衡量机器翻译输出中与参考相似重复的程度。另外，你能够确信如果机器翻译输出与参考1或是参考2完全一致的话，那么所有的这些$P_1$、$P_2$等等的值，都会等于1.0。为了得到改良后的1.0的精确度，只要你的输出与参考之一完全相同就能满足，不过有时即使输出结果并不完全与参考相同，这也是有可能实现的。你可以将它们以另一种方式组合，但愿仍能得到不错的翻译结果。 最后，我们将这些组合一下来构成最终的BLEU得分。$P_n$就是$n$元词组这一项的BLEU得分，也是计算出的$n$元词组改良后的精确度，按照惯例，为了用一个值来表示你需要计算$P_1$，$P_2$， $P_3$，$P_4$。然后将它们用这个公式组合在一起，就是取平均值。按照惯例BLEU得分被定义为，$exp (\frac{1}{4}\sum\limits_{n=1}^{4}{ {{P}_{n} }})$，对这个线性运算进行乘方运算，乘方是严格单调递增的运算，我们实际上会用额外的一个叫做BP 的惩罚因子（the BP penalty）来调整这项。BP的意思是“简短惩罚”（ brevity penalty）。这些细节也许并不是十分重要，但是你可以大致了解一下。事实表明，如果你输出了一个非常短的翻译，那么它会更容易得到一个高精确度。因为输出的大部分词可能都出现在参考之中，不过我们并不想要特别短的翻译结果。因此简短惩罚(BP)就是一个调整因子，它能够惩罚输出了太短翻译结果的翻译系统。BP的公式如上图所示。如果你的机器翻译系统实际上输出了比人工翻译结果更长的翻译，那么它就等于1，其他情况下就是像这样的公式，惩罚所有更短的翻译，细节部分你能够在这篇论文中找到。 再说一句，在之前的视频中，你了解了拥有单一实数评估指标（a single real number evaluation metric）的重要性，因为它能够让你尝试两种想法，然后看一下哪个得分更高，尽量选择得分更高的那个，BLEU得分对于机器翻译来说，具有革命性的原因是因为它有一个相当不错的虽然不是完美的但是非常好的单一实数评估指标，因此它加快了整个机器翻译领域的进程，我希望这节视频能够让你了解BLEU得分是如何操作的。实践中，很少人会从零实现一个BLEU得分（implement a BLEU score from scratch），有很多开源的实现结果，你可以下载下来然后直接用来评估你的系统。不过今天，BLEU得分被用来评估许多生成文本的系统（systems that generate text），比如说机器翻译系统（machine translation systems），也有我之前简单提到的图像描述系统（image captioning systems）。也就是说你会用神经网络来生成图像描述，然后使用BLEU得分来看一下，结果在多大程度上与参考描述或是多个人工完成的参考描述内容相符。BLEU得分是一个有用的单一实数评估指标，用于评估生成文本的算法，判断输出的结果是否与人工写出的参考文本的含义相似。不过它并没有用于语音识别（speech recognition）。因为在语音识别当中，通常只有一个答案，你可以用其他的评估方法，来看一下你的语音识别结果，是否十分相近或是字字正确（pretty much, exactly word for word correct）。不过在图像描述应用中，对于同一图片的不同描述，可能是同样好的。或者对于机器翻译来说，有多个一样好的翻译结果，BLEU得分就给了你一个能够自动评估的方法，帮助加快算法开发进程。说了这么多，希望你明白了BLEU得分是怎么运行的。 3.7 注意力模型直观理解（Attention Model Intuition）在本周大部分时间中，你都在使用这个编码解码的构架（a Encoder-Decoder architecture）来完成机器翻译。当你使用RNN读一个句子，于是另一个会输出一个句子。我们要对其做一些改变，称为注意力模型（the Attention Model），并且这会使它工作得更好。注意力模型或者说注意力这种思想（The attention algorithm, the attention idea）已经是深度学习中最重要的思想之一，我们看看它是怎么运作的。 像这样给定一个很长的法语句子，在你的神经网络中，这个绿色的编码器要做的就是读整个句子，然后记忆整个句子，再在感知机中传递（to read in the whole sentence and then memorize the whole sentences and store it in the activations conveyed her）。而对于这个紫色的神经网络，即解码网络（the decoder network）将生成英文翻译，Jane去年九月去了非洲，非常享受非洲文化，遇到了很多奇妙的人，她回来就嚷嚷道，她经历了一个多棒的旅行，并邀请我也一起去。人工翻译并不会通过读整个法语句子，再记忆里面的东西，然后从零开始，机械式地翻译成一个英语句子。而人工翻译，首先会做的可能是先翻译出句子的部分，再看下一部分，并翻译这一部分。看一部分，翻译一部分，一直这样下去。你会通过句子，一点一点地翻译，因为记忆整个的像这样的的句子是非常困难的。你在下面这个编码解码结构中，会看到它对于短句子效果非常好，于是它会有一个相对高的Bleu分（Bleu score），但是对于长句子而言，比如说大于30或者40词的句子，它的表现就会变差。Bleu评分看起来就会像是这样，随着单词数量变化，短的句子会难以翻译，因为很难得到所有词。对于长的句子，效果也不好，因为在神经网络中，记忆非常长句子是非常困难的。在这个和下个视频中，你会见识到注意力模型，它翻译得很像人类，一次翻译句子的一部分。而且有了注意力模型，机器翻译系统的表现会像这个一样，因为翻译只会翻译句子的一部分，你不会看到这个有一个巨大的下倾（huge dip），这个下倾实际上衡量了神经网络记忆一个长句子的能力，这是我们不希望神经网络去做的事情。在这个视频中，我想要给你们注意力机制运行的一些直观的东西。然后在下个视频中，完善细节。 注意力模型源于Dimitri, Bahdanau, Camcrun Cho, Yoshe Bengio。（Bahdanau D, Cho K, Bengio Y. Neural Machine Translation by Jointly Learning to Align and Translate[J]. Computer Science,2014.）虽然这个模型源于机器翻译，但它也推广到了其他应用领域。我认为在深度学习领域，这个是个非常有影响力的，非常具有开创性的论文。 让我们用一个短句举例说明一下，即使这些思想可能是应用于更长的句子。但是用短句来举例说明，讲解这些思想会更简单。我们有一个很平常的句子：(法语)Jane visite l’Afrique en Septembre。假定我们使用RNN，在这个情况中，我们将使用一个双向的RNN（a bidirectional RNN），为了计算每个输入单词的的特征集（set of features），你必须要理解输出$\hat y^{&lt;1&gt;}$到$\hat y^{&lt;3&gt;}$一直到$\hat y^{&lt;5&gt;}$的双向RNN。但是我们并不是只翻译一个单词，让我们先去掉上面的$Y$，就用双向的RNN。我们要对单词做的就是，对于句子里的每五个单词，计算一个句子中单词的特征集，也有可能是周围的词，让我们试试，生成英文翻译。我们将使用另一个RNN生成英文翻译，这是我平时用的RNN记号。我不用$A$来表示感知机（the activation），这是为了避免和这里的感知机（the activations）混淆。我会用另一个不同的记号，我会用$S$来表示RNN的隐藏状态（the hidden state in this RNN），不用$A^{&lt;1&gt;}$，而是用$S^{&lt;1&gt;}$。我们希望在这个模型里第一个生成的单词将会是Jane，为了生成Jane visits Africa in September。于是等式就是，当你尝试生成第一个词，即输出，那么我们应该看输入的法语句子的哪个部分？似乎你应该先看第一个单词，或者它附近的词。但是你别看太远了，比如说看到句尾去了。所以注意力模型就会计算注意力权重（a set of attention weights），我们将用$a^{&lt;1,1&gt;}$来表示当你生成第一个词时你应该放多少注意力在这个第一块信息处。然后我们算第二个，这个叫注意力权重，$a^{&lt;1,2&gt;}$它告诉我们当你尝试去计算第一个词Jane时，我们应该花多少注意力在输入的第二个词上面。同理这里是$a^{&lt;1,3&gt;}$，接下去也同理。这些将会告诉我们，我们应该花多少注意力在记号为$C$的内容上。这就是RNN的一个单元，如何尝试生成第一个词的，这是RNN的其中一步，我们将会在下个视频中讲解细节。对于RNN的第二步，我们将有一个新的隐藏状态$S^{&lt;2&gt;}$，我们也会用一个新的注意力权值集(a new set of the attention weights),我们将用$a^{&lt;2,1&gt;}$来告诉我们什么时候生成第二个词, 那么visits就会是第二个标签了(the ground trip label)。我们应该花多少注意力在输入的第一个法语词上。然后同理$a^{&lt;2,2&gt;}$，接下去也同理，我们应该花多少注意力在visite词上，我们应该花多少注意在词l’Afique上面。当然我们第一个生成的词Jane也会输入到这里，于是我们就有了需要花注意力的上下文。第二步，这也是个输入，然后会一起生成第二个词，这会让我们来到第三步$S^{&lt;3&gt;}$，这是输入，我们再有上下文C，它取决于在不同的时间集（time sets）,上面的$a^{&lt;3&gt;}$。这个告诉了我们我们要花注意力在不同的法语的输入词上面。然后同理。有些事情我还没说清楚，但是在下个视频中，我会讲解一些细节，比如如何准确定义上下文，还有第三个词的上下文，是否真的需要去注意句子中的周围的词。这里要用到的公式以及如何计算这些注意力权重（these attention weights），将会在下个视频中讲解到。在下个视频中你会看到$a^{&lt;3,t&gt;}$，即当你尝试去生成第三个词，应该是l’Afique，就得到了右边这个输出，这个RNN步骤应该要花注意力在$t$时的法语词上，这取决于在$t$时的双向RNN的激活值。那么它应该是取决于第四个激活值，它会取决于上一步的状态，它会取决于$S^{&lt;2&gt;}$。然后这些一起影响你应该花多少注意在输入的法语句子的某个词上面。我们会在下个视频中讲解这些细节。但是直观来想就是RNN向前进一次生成一个词，在每一步直到最终生成可能是&amp;lt;EOS&amp;gt;。这些是注意力权重，即$a^{&lt;t,t&gt;}$告诉你，当你尝试生成第$t$个英文词，它应该花多少注意力在第$t$个法语词上面。当生成一个特定的英文词时，这允许它在每个时间步去看周围词距内的法语词要花多少注意力。 我希望这个视频传递了关于注意力模型的一些直观的东西。我们现在可能对算法的运行有了大概的感觉，让我们进入到下个视频中，看看具体的细节。 3.8注意力模型（Attention Model）在上个视频中你已经见到了,注意力模型如何让一个神经网络只注意到一部分的输入句子。当它在生成句子的时候，更像人类翻译。让我们把这些想法转化成确切的式子，来实现注意力模型。 跟上个视频一样，我们先假定有一个输入句子，并使用双向的RNN，或者双向的GRU或者双向的LSTM，去计算每个词的特征。实际上GRU和LSTM经常应用于这个，可能LSTM更经常一点。对于前向传播（the forward occurrence），你有第一个时间步的前向传播的激活值（a forward occurrence first time step），第一个时间步后向传播的激活值，后向的激活值，以此类推。他们一共向前了五个时间步，也向后了五个时间步，技术上我们把这里设置为0。我们也可以后向传播6次，设一个都是0的因子，实际上就是个都是0的因子。为了简化每个时间步的记号，即使你在双向RNN已经计算了前向的特征值和后向的特征值，我就用$a^{&lt;t&gt;}$来一起表示这些联系。所以$a^{&lt;t&gt;}$就是时间步$t$上的特征向量。但是为了保持记号的一致性，我们用第二个，也就是$t'$，实际上我将用$t'$来索引法语句子里面的词。接下来我们只进行前向计算，就是说这是个单向的RNN，用状态$S$表示生成翻译。所以第一个时间步，它应该生成$y^{&lt;1&gt;}$，当你输入上下文$C$的时候就会这样，如果你想用时间来索引它，你可以写$C^{&lt;1&gt;}$，但有时候我就写个$C$，就是没有上标的$C$，这个会取决于注意力参数，即$a^{&lt;1,1&gt;}$，$a^{&lt;1,2&gt;}$以此类推，告诉我们应该花多少注意力。同样的，这个$a$参数告诉我们上下文有多少取决于我们得到的特征，或者我们从不同时间步中得到的激活值。所以我们定义上下文的方式实际上来源于被注意力权重加权的不同时间步中的特征值。于是更公式化的注意力权重将会满足非负的条件，所以这就是个0或正数，它们加起来等于1。我们等会会见到我们如何确保这个成立，我们将会有上下文，或者说在$t=1$时的上下文，我会经常省略上标，这就会变成对$t'$的求和。这个权重的所有的$t'$值，加上这些激活值。所以这里的这项（上图编号1所示）就是注意力权重，这里的这项（上图编号2）来自于这里（上图编号3），于是$a^{&lt;t,t'&gt;}$就是$y^{&lt;t&gt;}$应该在$t'$时花在$a$上注意力的数量。换句话来说，当你在$t$处生成输出词，你应该花多少注意力在第$t'$个输入词上面，这是生成输出的其中一步。然后下一个时间步，你会生成第二个输出。于是相似的，你现在有了一个新的注意力权重集，再找到一个新的方式将它们相加，这就产生了一个新的上下文，这个也是输入，且允许你生成第二个词。只有现在才用这种方式相加，它会变成第二个时间步的上下文。即对$t'$的$a^{&lt;2,t'&gt;}$进行求和，于是使用这些上下文向量，$C^{&lt;1&gt;}$写到这里，$C^{&lt;2&gt;}$也同理。这里的神经网络看起来很像相当标准的RNN序列，这里有着上下文向量作为输出，我们可以一次一个词地生成翻译，我们也定义了如何通过这些注意力权重和输入句子的特征值来计算上下文向量。剩下唯一要做的事情就是定义如何计算这些注意力权重。让我们下张幻灯片看看。 回忆一下$a^{&lt;t,t'&gt;}$，是你应该花费在$a^{&lt;t'&gt;}$上的注意力的数量，当你尝试去生成第$t$个输出的翻译词，让我们先把式子写下来，再讨论它是怎么来的。这个式子你可以用来计算$a^{&lt;t,t'&gt;}$，在此之前我们要先计算$e^{&lt;t,t'&gt;}$，关键要用softmax，来确保这些权重加起来等于1。如果你对$t'$求和，比如每一个固定的$t$值，这些加起来等于1。如果你对$t'$求和，然后优先使用softmax，确保这些值加起来等于1。 现在我们如何计算这些$e$项，一种我们可以用的方式是用下面这样的小的神经网络，于是$s^{&lt;t-1&gt;}$就是神经网络在上个时间步的状态，于是这里我们有一个神经网络，如果你想要生成$y^{&lt;t&gt;}$，那么$s^{&lt;t-1&gt;}$就是上一时间步的隐藏状态，即$s^{&lt;t&gt;}$。这是给小神经网络的其中一个输入，也就是在神经网络中的一个隐藏层，因为你需要经常计算它们，然后$a^{&lt;t'&gt;}$，即上个时间步的的特征是另一个输入。直观来想就是，如果你想要决定要花多少注意力在$t'$的激活值上。于是，似乎它会很大程度上取决于你上一个时间步的的隐藏状态的激活值。你还没有当前状态的激活值，因为上下文会输入到这里，所以你还没计算出来，但是看看你生成上一个翻译的RNN的隐藏状态，然后对于每一个位置，每一个词都看向他们的特征值，这看起来很自然，即$a^{&lt;t,t'&gt;}$和$e^{&lt;t,t'&gt;}$应该取决于这两个量。但是我们不知道具体函数是什么，所以我们可以做的事情就是训练一个很小的神经网络，去学习这个函数到底是什么。相信反向传播算法，相信梯度下降算法学到一个正确的函数。这表示，如果你应用这整个的模型，然后用梯度下降来训练它，这是可行的。这个小型的神经网络做了一件相当棒的事情，告诉你$y^{&lt;t&gt;}$应该花多少注意力在$a^{&lt;t&gt;}$上面，然后这个式子确保注意力权重加起来等于1，于是当你持续地一次生成一个词，这个神经网络实际上会花注意力在右边的这个输入句子上，它会完全自动的通过梯度下降来学习。 这个算法的一个缺点就是它要花费三次方的时间，就是说这个算法的复杂是$O(n3)$的，如果你有$T_x$个输入单词和$T_y$个输出单词，于是注意力参数的总数就会是$T_x\times T_y$，所以这个算法有着三次方的消耗。但是在机器翻译的应用上，输入和输出的句子一般不会太长，可能三次方的消耗是可以接受，但也有很多研究工作，尝试去减少这样的消耗。那么讲解注意想法在机器翻译中的应用，就到此为止了。虽然没有讲到太多的细节，但这个想法也被应用到了其他的很多问题中去了，比如图片加标题（image captioning），图片加标题就是看一张图，写下这张图的标题。底下的这篇论文来源于Kevin Chu，Jimmy Barr, Ryan Kiros, Kelvin Shaw, Aaron Korver, Russell Zarkutnov, Virta Zemo, 和 Andrew Benjo。他们也显示了你可以有一个很相似的结构看图片，然后，当你在写图片标题的时候，一次只花注意力在一部分的图片上面。如果你感兴趣，那么我鼓励你，也去看看这篇论文，做一些编程练习。 因为机器翻译是一个非常复杂的问题，在之前的练习中，你应用了注意力，在日期标准化的问题（the date normalization problem）上面，问题输入了像这样的一个日期，这个日期实际上是阿波罗登月的日期，把它标准化成标准的形式，或者这样的日期。用一个序列的神经网络，即序列模型去标准化到这样的形式，这个日期实际上是威廉·莎士比亚的生日。一般认为是这个日期正如你之前联系中见到的，你可以训练一个神经网络，输入任何形式的日期，生成标准化的日期形式。其他可以做的有意思的事情是看看可视化的注意力权重（the visualizations of the attention weights）。这个一个机器翻译的例子，这里被画上了不同的颜色，不同注意力权重的大小，我不想在这上面花太多时间，但是你可以发现，对应的输入输出词，你会发现注意力权重，会变高，因此这显示了当它生成特定的输出词时通常会花注意力在输入的正确的词上面，包括学习花注意在哪。在注意力模型中，使用反向传播时， 什么时候学习完成。 这就是注意力模型，在深度学习中真的是个非常强大的想法。在本周的编程练习中，我希望你可以享受自己应用它的过程。 3.9语音识别（Speech recognition）现今，最令人振奋的发展之一，就是seq2seq模型（sequence-to-sequence models）在语音识别方面准确性有了很大的提升。这门课程已经接近尾声，现在我想通过剩下几节视频，来告诉你们，seq2seq模型是如何应用于音频数据的（audio data），比如语音（the speech）。 什么是语音视频问题呢？现在你有一个音频片段$x$（an audio clip,x），你的任务是自动地生成文本$y$。现在有一个音频片段，画出来是这样，该图的横轴是时间。一个麦克风的作用是测量出微小的气压变化，现在你之所以能听到我的声音，是因为你的耳朵能够探测到这些微小的气压变化，它可能是由你的扬声器或者耳机产生的，也就是像图上这样的音频片段，气压随着时间而变化。假如这个我说的音频片段的内容是：”the quick brown fox“(敏捷的棕色狐狸)，这时我们希望一个语音识别算法（a speech recognition algorithm），通过输入这段音频，然后输出音频的文本内容。考虑到人的耳朵并不会处理声音的原始波形，而是通过一种特殊的物理结构来测量这些，不同频率和强度的声波。音频数据的常见预处理步骤，就是运行这个原始的音频片段，然后生成一个声谱图（a spectrogram），就像这样。同样地，横轴是时间，纵轴是声音的频率（frequencies），而图中不同的颜色，显示了声波能量的大小（the amount of energy），也就是在不同的时间和频率上这些声音有多大。通过这样的声谱图，或者你可能还听过人们谈到过伪空白输出（the false blank outputs），也经常应用于预处理步骤，也就是在音频被输入到学习算法之前，而人耳所做的计算和这个预处理过程非常相似。语音识别方面，最令人振奋的趋势之一就是曾经有一段时间，语音识别系统是用音位（phonemes）来构建的，也就是人工设计的基本单元（hand-engineered basic units of cells），如果用音位来表示”the quick brown fox“，我这里稍微简化一些，”the“含有”th“和”e“的音，而”quick“有”k“ “w“ “i“ “k“的音，语音学家过去把这些音作为声音的基本单元写下来，把这些语音分解成这些基本的声音单元，而”brown“不是一个很正式的音位，因为它的音写起来比较复杂，不过语音学家（linguists）们认为用这些基本的音位单元（basic units of sound called phonemes）来表示音频（audio），是做语音识别最好的办法。不过在end-to-end模型中，我们发现这种音位表示法（phonemes representations）已经不再必要了，而是可以构建一个系统，通过向系统中输入音频片段（audio clip），然后直接输出音频的文本（a transcript），而不需要使用这种人工设计的表示方法。使这种方法成为可能的一件事就是用一个很大的数据集，所以语音识别的研究数据集可能长达300个小时，在学术界，甚至3000小时的文本音频数据集，都被认为是合理的大小。大量的研究，大量的论文所使用的数据集中，有几千种不同的声音，而且，最好的商业系统现在已经训练了超过1万个小时的数据，甚至10万个小时，并且它还会继续变得更大。在文本音频数据集中（Transcribe audio data sets）同时包含$x$和$y$，通过深度学习算法大大推进了语音识别的进程。那么，如何建立一个语音识别系统呢？ 在上一节视频中，我们谈到了注意力模型，所以，一件你能做的事就是在横轴上，也就是在输入音频的不同时间帧上，你可以用一个注意力模型，来输出文本描述，如”the quick brown fox“，或者其他语音内容。 还有一种效果也不错的方法，就是用CTC损失函数（CTC cost）来做语音识别。CTC就是Connectionist Temporal Classification，它是由Alex Graves、Santiago Fernandes, Faustino Gomez、和Jürgen Schmidhuber提出的。（Graves A, Gomez F. Connectionist temporal classification:labelling unsegmented sequence data with recurrent neural networks[C]// International Conference on Machine Learning. ACM, 2006:369-376.） 算法思想如下: 假设语音片段内容是某人说：”the quick brown fox“，这时我们使用一个新的网络，结构像这个样子，这里输入$x$和输出$y$的数量都是一样的，因为我在这里画的，只是一个简单的单向RNN结构。然而在实际中，它有可能是双向的LSTM结构，或者双向的GIU结构，并且通常是很深的模型。但注意一下这里时间步的数量，它非常地大。在语音识别中，通常输入的时间步数量（the number of input time steps）要比输出的时间步的数量（the number of output time steps）多出很多。举个例子，比如你有一段10秒的音频，并且特征（features）是100赫兹的，即每秒有100个样本，于是这段10秒的音频片段就会有1000个输入，就是简单地用100赫兹乘上10秒。所以有1000个输入，但可能你的输出就没有1000个字母了，或者说没有1000个字符。这时要怎么办呢？CTC损失函数允许RNN生成这样的输出：ttt，这是一个特殊的字符，叫做空白符，我们这里用下划线表示，这句话开头的音可表示为h_eee_ _ _，然后这里可能有个空格，我们用这个来表示空格，之后是_ _ _qqq__，这样的输出也被看做是正确的输出。下面这段输出对应的是”the q“。CTC损失函数的一个基本规则是将空白符之间的重复的字符折叠起来，再说清楚一些，我这里用下划线来表示这个特殊的空白符（a special blank character），它和空格（the space character）是不一样的。所以the和quick之间有一个空格符，所以我要输出一个空格，通过把用空白符所分割的重复的字符折叠起来，然后我们就可以把这段序列折叠成”the q“。这样一来你的神经网络因为有很多这种重复的字符，和很多插入在其中的空白符（blank characters），所以最后我们得到的文本会短上很多。于是这句”the quick brown fox“包括空格一共有19个字符，在这样的情况下，通过允许神经网络有重复的字符和插入空白符使得它能强制输出1000个字符，甚至你可以输出1000个$y$值来表示这段19个字符长的输出。这篇论文来自于Alex Grace以及刚才提到的那些人。我所参与的深度语音识别系统项目就使用这种思想来构建有效的语音识别系统。 希望这能给你一个粗略的理解，理解语音识别模型是如何工作的：注意力模型是如何工作的，以及CTC模型是如何工作的，以及这两种不同的构建这些系统的方法。现今，在生产技术中，构建一个有效语音识别系统，是一项相当重要的工作，并且它需要很大的数据集，下节视频我想做的是告诉你如何构建一个触发字检测系统（a rigger word detection system），其中的关键字检测系统（keyword detection system）将会更加简单，它可以通过一个更简洁的数量更合理的数据来完成。所以我们下节课再见。 3.10触发字检测（Trigger Word Detection）现在你已经学习了很多关于深度学习和序列模型的内容，于是我们可以真正去简便地描绘出一个触发字系统（a trigger word system），就像上节视频中你看到的那样。随着语音识别的发展，越来越多的设备可以通过你的声音来唤醒，这有时被叫做触发字检测系统（rigger word detection systems）。我们来看一看如何建立一个触发字系统。 触发字系统的例子包括Amazon echo，它通过单词Alexa唤醒；还有百度DuerOS设备，通过”小度你好”来唤醒；苹果的Siri用Hey Siri来唤醒；Google Home使用Okay Google来唤醒，这就是触发字检测系统。假如你在卧室中，有一台Amazon echo，你可以在卧室中简单说一句: Alexa, 现在几点了?就能唤醒这个设备。它将会被单词”Alexa“唤醒，并回答你的询问。如果你能建立一个触发字检测系统，也许你就能让你的电脑通过你的声音来执行某些事，我有个朋友也在做一种用触发字来打开的特殊的灯，这是个很有趣的项目。但我想教会你的，是如何构建一个触发字检测系统。 有关于触发字检测系统的文献，还处于发展阶段。对于触发字检测，最好的算法是什么，目前还没有一个广泛的定论。我这里就简单向你介绍一个你能够使用的算法好了。现在有一个这样的RNN结构，我们要做的就是把一个音频片段（an audio clip）计算出它的声谱图特征（spectrogram features）得到特征向量$x^{&lt;1&gt;}$, $x^{&lt;2&gt;}$, $x^{&lt;3&gt;}$..，然后把它放到RNN中，最后要做的，就是定义我们的目标标签$y$。假如音频片段中的这一点是某人刚刚说完一个触发字，比如”Alexa“，或者”小度你好” 或者”Okay Google“，那么在这一点之前，你就可以在训练集中把目标标签都设为0，然后在这个点之后把目标标签设为1。假如在一段时间之后，触发字又被说了一次，比如是在这个点说的，那么就可以再次在这个点之后把目标标签设为1。这样的标签方案对于RNN来说是可行的，并且确实运行得非常不错。不过该算法一个明显的缺点就是它构建了一个很不平衡的训练集（a very imbalanced training set），0的数量比1多太多了。 这里还有一个解决方法，虽然听起来有点简单粗暴，但确实能使其变得更容易训练。比起只在一个时间步上去输出1，其实你可以在输出变回0之前，多次输出1，或说在固定的一段时间内输出多个1。这样的话，就稍微提高了1与0的比例，这确实有些简单粗暴。在音频片段中，触发字刚被说完之后，就把多个目标标签设为1，这里触发字又被说了一次。说完以后，又让RNN去输出1。在之后的编程练习中，你可以进行更多这样的操作，我想你应该会对自己学会了这么多东西而感到自豪。我们仅仅用了一张幻灯片来描述这种复杂的触发字检测系统。在这个基础上，希望你能够实现一个能有效地让你能够检测出触发字的算法，不过在编程练习中你可以看到更多的学习内容。这就是触发字检测，希望你能对自己感到自豪。因为你已经学了这么多深度学习的内容，现在你可以只用几分钟时间，就能用一张幻灯片来描述触发字能够实现它，并让它发挥作用。你甚至可能在你的家里用触发字系统做一些有趣的事情，比如打开或关闭电器，或者可以改造你的电脑，使得你或者其他人可以用触发字来操作它。]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达深度学习笔记(第四课时)]]></title>
    <url>%2F2019%2F12%2F05%2Fnew_%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E7%AC%AC%E5%9B%9B%E8%AF%BE%E6%97%B6)%2F</url>
    <content type="text"><![CDATA[吴恩达深度学习笔记 卷积神经网络（Convolutional Neural Networks）第一周 卷积神经网络（Foundations of Convolutional Neural Networks）1.1 计算机视觉（Computer vision）欢迎参加这次的卷积神经网络课程，计算机视觉是一个飞速发展的一个领域，这多亏了深度学习。深度学习与计算机视觉可以帮助汽车，查明周围的行人和汽车，并帮助汽车避开它们。还使得人脸识别技术变得更加效率和精准，你们即将能够体验到或早已体验过仅仅通过刷脸就能解锁手机或者门锁。当你解锁了手机，我猜手机上一定有很多分享图片的应用。在上面，你能看到美食，酒店或美丽风景的图片。有些公司在这些应用上使用了深度学习技术来向你展示最为生动美丽以及与你最为相关的图片。机器学习甚至还催生了新的艺术类型。深度学习之所以让我兴奋有下面两个原因，我想你们也是这么想的。 第一，计算机视觉的高速发展标志着新型应用产生的可能，这是几年前，人们所不敢想象的。通过学习使用这些工具，你也许能够创造出新的产品和应用。 其次，即使到头来你未能在计算机视觉上有所建树，但我发现，人们对于计算机视觉的研究是如此富有想象力和创造力，由此衍生出新的神经网络结构与算法，这实际上启发人们去创造出计算机视觉与其他领域的交叉成果。举个例子，之前我在做语音识别的时候，我经常从计算机视觉领域中寻找灵感，并将其应用于我的文献当中。所以即使你在计算机视觉方面没有做出成果，我也希望你也可以将所学的知识应用到其他算法和结构。就介绍到这儿，让我们开始学习吧。 这是我们本节课将要学习的一些问题，你应该早就听说过图片分类，或者说图片识别。比如给出这张64×64的图片，让计算机去分辨出这是一只猫。 还有一个例子，在计算机视觉中有个问题叫做目标检测，比如在一个无人驾驶项目中，你不一定非得识别出图片中的物体是车辆，但你需要计算出其他车辆的位置，以确保自己能够避开它们。所以在目标检测项目中，首先需要计算出图中有哪些物体，比如汽车，还有图片中的其他东西，再将它们模拟成一个个盒子，或用一些其他的技术识别出它们在图片中的位置。注意在这个例子中，在一张图片中同时有多个车辆，每辆车相对与你来说都有一个确切的距离。 还有一个更有趣的例子，就是神经网络实现的图片风格迁移，比如说你有一张图片，但你想将这张图片转换为另外一种风格。所以图片风格迁移，就是你有一张满意的图片和一张风格图片，实际上右边这幅画是毕加索的画作，而你可以利用神经网络将它们融合到一起，描绘出一张新的图片。它的整体轮廓来自于左边，却是右边的风格，最后生成下面这张图片。这种神奇的算法创造出了新的艺术风格，所以在这门课程中，你也能通过学习做到这样的事情。 但在应用计算机视觉时要面临一个挑战，就是数据的输入可能会非常大。举个例子，在过去的课程中，你们一般操作的都是64×64的小图片，实际上，它的数据量是64×64×3，因为每张图片都有3个颜色通道。如果计算一下的话，可得知数据量为12288，所以我们的特征向量$x$维度为12288。这其实还好，因为64×64真的是很小的一张图片。 如果你要操作更大的图片，比如一张1000×1000的图片，它足有1兆那么大，但是特征向量的维度达到了1000×1000×3，因为有3个RGB通道，所以数字将会是300万。如果你在尺寸很小的屏幕上观察，可能察觉不出上面的图片只有64×64那么大，而下面一张是1000×1000的大图。 如果你要输入300万的数据量，这就意味着，特征向量$x$的维度高达300万。所以在第一隐藏层中，你也许会有1000个隐藏单元，而所有的权值组成了矩阵 $W^{[1]}$。如果你使用了标准的全连接网络，就像我们在第一门和第二门的课程里说的，这个矩阵的大小将会是1000×300万。因为现在$x$的维度为$3m$，$3m$通常用来表示300万。这意味着矩阵$W^{[1]}$会有30亿个参数，这是个非常巨大的数字。在参数如此大量的情况下，难以获得足够的数据来防止神经网络发生过拟合和竞争需求，要处理包含30亿参数的神经网络，巨大的内存需求让人不太能接受。 但对于计算机视觉应用来说，你肯定不想它只处理小图片，你希望它同时也要能处理大图。为此，你需要进行卷积计算，它是卷积神经网络中非常重要的一块。下节课中，我会为你介绍如何进行这种运算，我将用边缘检测的例子来向你说明卷积的含义。 1.2 边缘检测示例（Edge detection example）卷积运算是卷积神经网络最基本的组成部分，使用边缘检测作为入门样例。在这个视频中，你会看到卷积是如何进行运算的。 在之前的视频中，我说过神经网络的前几层是如何检测边缘的，然后，后面的层有可能检测到物体的部分区域，更靠后的一些层可能检测到完整的物体，这个例子中就是人脸。在这个视频中，你会看到如何在一张图片中进行边缘检测。 让我们举个例子，给了这样一张图片，让电脑去搞清楚这张照片里有什么物体，你可能做的第一件事是检测图片中的垂直边缘。比如说，在这张图片中的栏杆就对应垂直线，与此同时，这些行人的轮廓线某种程度上也是垂线，这些线是垂直边缘检测器的输出。同样，你可能也想检测水平边缘，比如说这些栏杆就是很明显的水平线，它们也能被检测到，结果在这。所以如何在图像中检测这些边缘？ 看一个例子，这是一个6×6的灰度图像。因为是灰度图像，所以它是6×6×1的矩阵，而不是6×6×3的，因为没有RGB三通道。为了检测图像中的垂直边缘，你可以构造一个3×3矩阵。在共用习惯中，在卷积神经网络的术语中，它被称为过滤器。我要构造一个3×3的过滤器，像这样$\begin{bmatrix}1 & 0 & -1\\ 1 & 0 & -1\\ 1 & 0 & -1\end{bmatrix}$。在论文它有时候会被称为核，而不是过滤器，但在这个视频中，我将使用过滤器这个术语。对这个6×6的图像进行卷积运算，卷积运算用“$*$”来表示，用3×3的过滤器对其进行卷积。 关于符号表示，有一些问题，在数学中“$$”就是卷积的标准标志，但是在Python中，这个标识常常被用来表示乘法或者元素乘法。所以这个“$$”有多层含义，它是一个重载符号，在这个视频中，当“$*$”表示卷积的时候我会特别说明。 这个卷积运算的输出将会是一个4×4的矩阵，你可以将它看成一个4×4的图像。下面来说明是如何计算得到这个4×4矩阵的。为了计算第一个元素，在4×4左上角的那个元素，使用3×3的过滤器，将其覆盖在输入图像，如下图所示。然后进行元素乘法（element-wise products）运算，所以$\begin{bmatrix} 3 \times 1 & 0 \times 0 & 1 \times \left(1 \right) \\ 1 \times 1 & 5 \times 0 & 8 \times \left( - 1 \right) \\ 2 \times1 & 7 \times 0 & 2 \times \left( - 1 \right) \\ \end{bmatrix} = \begin{bmatrix}3 & 0 & - 1 \\ 1 & 0 & - 8 \\ 2 & 0 & - 2 \\\end{bmatrix}$，然后将该矩阵每个元素相加得到最左上角的元素，即$3+1+2+0+0 +0+(-1)+(-8) +(-2)=-5$。 把这9个数加起来得到-5，当然，你可以把这9个数按任何顺序相加，我只是先写了第一列，然后第二列，第三列。 接下来，为了弄明白第二个元素是什么，你要把蓝色的方块，向右移动一步，像这样，把这些绿色的标记去掉： 继续做同样的元素乘法，然后加起来，所以是 $0×1+5×1+7×1+1×0+8×0+2×0+2×(-1)+ 9×(-1)+5×(-1)=-4 $。 接下来也是一样，继续右移一步，把9个数的点积加起来得到0。 继续移得到8，验证一下：$2×1+9×1+5×1+7×0+3×0+1×0+4×(-1)+ 1×(-1)+ 3×(-1)=8$。 接下来为了得到下一行的元素，现在把蓝色块下移，现在蓝色块在这个位置： 重复进行元素乘法，然后加起来。通过这样做得到-10。再将其右移得到-2，接着是2，3。以此类推，这样计算完矩阵中的其他元素。 为了说得更清楚一点，这个-16是通过底部右下角的3×3区域得到的。 因此6×6矩阵和3×3矩阵进行卷积运算得到4×4矩阵。这些图片和过滤器是不同维度的矩阵，但左边矩阵容易被理解为一张图片，中间的这个被理解为过滤器，右边的图片我们可以理解为另一张图片。这个就是垂直边缘检测器，下一页中你就会明白。 在往下讲之前，多说一句，如果你要使用编程语言实现这个运算，不同的编程语言有不同的函数，而不是用“$$”来表示卷积。所以在编程练习中，你会使用一个叫*conv_forward的函数。如果在tensorflow下，这个函数叫tf.conv2d。在其他深度学习框架中，在后面的课程中，你将会看到Keras这个框架，在这个框架下用Conv2D**实现卷积运算。所有的编程框架都有一些函数来实现卷积运算。 为什么这个可以做垂直边缘检测呢？让我们来看另外一个例子。为了讲清楚，我会用一个简单的例子。这是一个简单的6×6图像，左边的一半是10，右边一般是0。如果你把它当成一个图片，左边那部分看起来是白色的，像素值10是比较亮的像素值，右边像素值比较暗，我使用灰色来表示0，尽管它也可以被画成黑的。图片里，有一个特别明显的垂直边缘在图像中间，这条垂直线是从黑到白的过渡线，或者从白色到深色。 所以，当你用一个3×3过滤器进行卷积运算的时候，这个3×3的过滤器可视化为下面这个样子，在左边有明亮的像素，然后有一个过渡，0在中间，然后右边是深色的。卷积运算后，你得到的是右边的矩阵。如果你愿意，可以通过数学运算去验证。举例来说，最左上角的元素0，就是由这个3×3块（绿色方框标记）经过元素乘积运算再求和得到的，$10×1+10×1+10×1+10×0+10×0+10×0+10×(-1)+10×(-1)+10×(-1)=0$ 。相反这个30是由这个（红色方框标记）得到的， $10×1+10×1+10×1+10×0+10×0+10×0+0×(-1)+0×(-1)+ 0×(-1)=30$。 如果把最右边的矩阵当成图像，它是这个样子。在中间有段亮一点的区域，对应检查到这个6×6图像中间的垂直边缘。这里的维数似乎有点不正确，检测到的边缘太粗了。因为在这个例子中，图片太小了。如果你用一个1000×1000的图像，而不是6×6的图片，你会发现其会很好地检测出图像中的垂直边缘。在这个例子中，在输出图像中间的亮处，表示在图像中间有一个特别明显的垂直边缘。从垂直边缘检测中可以得到的启发是，因为我们使用3×3的矩阵（过滤器），所以垂直边缘是一个3×3的区域，左边是明亮的像素，中间的并不需要考虑，右边是深色像素。在这个6×6图像的中间部分，明亮的像素在左边，深色的像素在右边，就被视为一个垂直边缘，卷积运算提供了一个方便的方法来发现图像中的垂直边缘。 所以你已经了解卷积是怎么工作的，在下一个视频中，你将会看到如何使用卷积运算作为卷积神经网络的基本模块的。 1.3 更多边缘检测内容（More edge detection）你已经见识到用卷积运算实现垂直边缘检测，在本视频中，你将学习如何区分正边和负边，这实际就是由亮到暗与由暗到亮的区别，也就是边缘的过渡。你还能了解到其他类型的边缘检测以及如何去实现这些算法，而不要总想着去自己编写一个边缘检测程序，让我们开始吧。 还是上一个视频中的例子，这张6×6的图片，左边较亮，而右边较暗，将它与垂直边缘检测滤波器进行卷积，检测结果就显示在了右边这幅图的中间部分。 现在这幅图有什么变化呢？它的颜色被翻转了，变成了左边比较暗，而右边比较亮。现在亮度为10的点跑到了右边，为0的点则跑到了左边。如果你用它与相同的过滤器进行卷积，最后得到的图中间会是-30，而不是30。如果你将矩阵转换为图片，就会是该矩阵下面图片的样子。现在中间的过渡部分被翻转了，之前的30翻转成了-30，表明是由暗向亮过渡，而不是由亮向暗过渡。 如果你不在乎这两者的区别，你可以取出矩阵的绝对值。但这个特定的过滤器确实可以为我们区分这两种明暗变化的区别。 再来看看更多的边缘检测的例子，我们已经见过这个3×3的过滤器，它可以检测出垂直的边缘。所以，看到右边这个过滤器，我想你应该猜出来了，它能让你检测出水平的边缘。提醒一下，一个垂直边缘过滤器是一个3×3的区域，它的左边相对较亮，而右边相对较暗。相似的，右边这个水平边缘过滤器也是一个3×3的区域，它的上边相对较亮，而下方相对较暗。 这里还有个更复杂的例子，左上方和右下方都是亮度为10的点。如果你将它绘成图片，右上角是比较暗的地方，这边都是亮度为0的点，我把这些比较暗的区域都加上阴影。而左上方和右下方都会相对较亮。如果你用这幅图与水平边缘过滤器卷积，就会得到右边这个矩阵。 再举个例子，这里的30（右边矩阵中绿色方框标记元素）代表了左边这块3×3的区域（左边矩阵绿色方框标记部分），这块区域确实是上边比较亮，而下边比较暗的，所以它在这里发现了一条正边缘。而这里的-30（右边矩阵中紫色方框标记元素）又代表了左边另一块区域（左边矩阵紫色方框标记部分），这块区域确实是底部比较亮，而上边则比较暗，所以在这里它是一条负边。 再次强调，我们现在所使用的都是相对很小的图片，仅有6×6。但这些中间的数值，比如说这个10（右边矩阵中黄色方框标记元素）代表的是左边这块区域（左边6×6矩阵中黄色方框标记的部分）。这块区域左边两列是正边，右边一列是负边，正边和负边的值加在一起得到了一个中间值。但假如这个一个非常大的1000×1000的类似这样棋盘风格的大图，就不会出现这些亮度为10的过渡带了，因为图片尺寸很大，这些中间值就会变得非常小。 总而言之，通过使用不同的过滤器，你可以找出垂直的或是水平的边缘。但事实上，对于这个3×3的过滤器来说，我们使用了其中的一种数字组合。 但在历史上，在计算机视觉的文献中，曾公平地争论过怎样的数字组合才是最好的，所以你还可以使用这种：$\begin{bmatrix}1 & 0 & - 1 \\ 2 & 0 & - 2 \\ 1 & 0 & - 1 \\\end{bmatrix}$，叫做Sobel的过滤器，它的优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些。 但计算机视觉的研究者们也会经常使用其他的数字组合，比如这种：$\begin{bmatrix} 3& 0 & - 3 \\ 10 & 0 & - 10 \\ 3 & 0 & - 3 \\\end{bmatrix}$，这叫做Scharr过滤器，它有着和之前完全不同的特性，实际上也是一种垂直边缘检测，如果你将其翻转90度，你就能得到对应水平边缘检测。 随着深度学习的发展，我们学习的其中一件事就是当你真正想去检测出复杂图像的边缘，你不一定要去使用那些研究者们所选择的这九个数字，但你可以从中获益匪浅。把这矩阵中的9个数字当成9个参数，并且在之后你可以学习使用反向传播算法，其目标就是去理解这9个参数。 当你得到左边这个6×6的图片，将其与这个3×3的过滤器进行卷积，将会得到一个出色的边缘检测。这就是你在下节视频中将会看到的，把这9个数字当成参数的过滤器，通过反向传播，你可以学习这种$\begin{bmatrix}1 & 0 & - 1 \\ 1 & 0 & - 1 \\ 1 & 0 & - 1 \\\end{bmatrix}$的过滤器，或者Sobel过滤器和Scharr过滤器。还有另一种过滤器，这种过滤器对于数据的捕捉能力甚至可以胜过任何之前这些手写的过滤器。相比这种单纯的垂直边缘和水平边缘，它可以检测出45°或70°或73°，甚至是任何角度的边缘。所以将矩阵的所有数字都设置为参数，通过数据反馈，让神经网络自动去学习它们，我们会发现神经网络可以学习一些低级的特征，例如这些边缘的特征。尽管比起那些研究者们，我们要更费劲一些，但确实可以动手写出这些东西。不过构成这些计算的基础依然是卷积运算，使得反向传播算法能够让神经网络学习任何它所需要的3×3的过滤器，并在整幅图片上去应用它。这里，这里，还有这里（左边矩阵蓝色方框标记部分），去输出这些，任何它所检测到的特征，不管是垂直的边缘，水平的边缘，还有其他奇怪角度的边缘，甚至是其它的连名字都没有的过滤器。 所以这种将这9个数字当成参数的思想，已经成为计算机视觉中最为有效的思想之一。在接下来的课程中，也就是下个星期，我们将详细去探讨如何使用反向传播去让神经网络学习这9个数字。但在此之前，我们需要先讨论一些其它细节，比如一些基础的卷积运算的变量。在下面两节视频中，我将与你们讨论如何去使用padding，以及卷积各种不同的发展，这两节内容将会是卷积神经网络中卷积模块的重要组成部分，所以我们下节视频再见。 1.4 Padding为了构建深度神经网络，你需要学会使用的一个基本的卷积操作就是padding，让我们来看看它是如何工作的。 我们在之前视频中看到，如果你用一个3×3的过滤器卷积一个6×6的图像，你最后会得到一个4×4的输出，也就是一个4×4矩阵。那是因为你的3×3过滤器在6×6矩阵中，只可能有4×4种可能的位置。这背后的数学解释是，如果我们有一个$n×n$的图像，用$f×f$的过滤器做卷积，那么输出的维度就是$(n-f+1)×(n-f+1)$。在这个例子里是$6-3+1=4$，因此得到了一个4×4的输出。 这样的话会有两个缺点，第一个缺点是每次做卷积操作，你的图像就会缩小，从6×6缩小到4×4，你可能做了几次之后，你的图像就会变得很小了，可能会缩小到只有1×1的大小。你可不想让你的图像在每次识别边缘或其他特征时都缩小，这就是第一个缺点。 第二个缺点时，如果你注意角落边缘的像素，这个像素点（绿色阴影标记）只被一个输出所触碰或者使用，因为它位于这个3×3的区域的一角。但如果是在中间的像素点，比如这个（红色方框标记），就会有许多3×3的区域与之重叠。所以那些在角落或者边缘区域的像素点在输出中采用较少，意味着你丢掉了图像边缘位置的许多信息。 为了解决这两个问题，一是输出缩小。当我们建立深度神经网络时，你就会知道你为什么不希望每进行一步操作图像都会缩小。比如当你有100层深层的网络，如果图像每经过一层都缩小的话，经过100层网络后，你就会得到一个很小的图像，所以这是个问题。另一个问题是图像边缘的大部分信息都丢失了。 为了解决这些问题，你可以在卷积操作之前填充这幅图像。在这个案例中，你可以沿着图像边缘再填充一层像素。如果你这样操作了，那么6×6的图像就被你填充成了一个8×8的图像。如果你用3×3的图像对这个8×8的图像卷积，你得到的输出就不是4×4的，而是6×6的图像，你就得到了一个尺寸和原始图像6×6的图像。习惯上，你可以用0去填充，如果$p$是填充的数量，在这个案例中，$p=1$，因为我们在周围都填充了一个像素点，输出也就变成了$(n+2p-f+1)×(n+2p-f+1)$，所以就变成了$(6+2×1-3+1)×(6+2×1-3+1)=6×6$，和输入的图像一样大。这个涂绿的像素点（左边矩阵）影响了输出中的这些格子（右边矩阵）。这样一来，丢失信息或者更准确来说角落或图像边缘的信息发挥的作用较小的这一缺点就被削弱了。 刚才我已经展示过用一个像素点来填充边缘，如果你想的话，也可以填充两个像素点，也就是说在这里填充一层。实际上你还可以填充更多像素。我这里画的这种情况，填充后$p=2$。 至于选择填充多少像素，通常有两个选择，分别叫做Valid卷积和Same卷积。 Valid卷积意味着不填充，这样的话，如果你有一个$n×n$的图像，用一个$f×f$的过滤器卷积，它将会给你一个$(n-f+1)×(n-f+1)$维的输出。这类似于我们在前面的视频中展示的例子，有一个6×6的图像，通过一个3×3的过滤器，得到一个4×4的输出。 另一个经常被用到的填充方法叫做Same卷积，那意味你填充后，你的输出大小和输入大小是一样的。根据这个公式$n-f+1$，当你填充$p$个像素点，$n$就变成了$n+2p$，最后公式变为$n+2p-f+1$。因此如果你有一个$n×n$的图像，用$p$个像素填充边缘，输出的大小就是这样的$(n+2p-f+1)×(n+2p-f+1)$。如果你想让$n+2p-f+1=n$的话，使得输出和输入大小相等，如果你用这个等式求解$p$，那么$p=(f-1)/2$。所以当$f$是一个奇数的时候，只要选择相应的填充尺寸，你就能确保得到和输入相同尺寸的输出。这也是为什么前面的例子，当过滤器是3×3时，和上一张幻灯片的例子一样，使得输出尺寸等于输入尺寸，所需要的填充是(3-1)/2，也就是1个像素。另一个例子，当你的过滤器是5×5，如果$f=5$，然后代入那个式子，你就会发现需要2层填充使得输出和输入一样大，这是过滤器5×5的情况。 习惯上，计算机视觉中，$f$通常是奇数，甚至可能都是这样。你很少看到一个偶数的过滤器在计算机视觉里使用，我认为有两个原因。 其中一个可能是，如果$f$是一个偶数，那么你只能使用一些不对称填充。只有$f$是奇数的情况下，Same卷积才会有自然的填充，我们可以以同样的数量填充四周，而不是左边填充多一点，右边填充少一点，这样不对称的填充。 第二个原因是当你有一个奇数维过滤器，比如3×3或者5×5的，它就有一个中心点。有时在计算机视觉里，如果有一个中心像素点会更方便，便于指出过滤器的位置。 也许这些都不是为什么$f$通常是奇数的充分原因，但如果你看了卷积的文献，你经常会看到3×3的过滤器，你也可能会看到一些5×5，7×7的过滤器。后面我们也会谈到1×1的过滤器，以及什么时候它是有意义的。但是习惯上，我推荐你只使用奇数的过滤器。我想如果你使用偶数f也可能会得到不错的表现，如果遵循计算机视觉的惯例，我通常使用奇数值的$f$。 你已经看到如何使用padding卷积，为了指定卷积操作中的padding，你可以指定$p$的值。也可以使用Valid卷积，也就是$p=0$。也可使用Same卷积填充像素，使你的输出和输入大小相同。以上就是padding，在接下来的视频中我们讨论如何在卷积中设置步长。 1.5 卷积步长（Strided convolutions）卷积中的步幅是另一个构建卷积神经网络的基本操作，让我向你展示一个例子。 如果你想用3×3的过滤器卷积这个7×7的图像，和之前不同的是，我们把步幅设置成了2。你还和之前一样取左上方的3×3区域的元素的乘积，再加起来，最后结果为91。 只是之前我们移动蓝框的步长是1，现在移动的步长是2，我们让过滤器跳过2个步长，注意一下左上角，这个点移动到其后两格的点，跳过了一个位置。然后你还是将每个元素相乘并求和，你将会得到的结果是100。 现在我们继续，将蓝色框移动两个步长，你将会得到83的结果。当你移动到下一行的时候，你也是使用步长2而不是步长1，所以我们将蓝色框移动到这里： 注意到我们跳过了一个位置，得到69的结果，现在你继续移动两个步长，会得到91，127，最后一行分别是44，72，74。 所以在这个例子中，我们用3×3的矩阵卷积一个7×7的矩阵，得到一个3×3的输出。输入和输出的维度是由下面的公式决定的。如果你用一个$f×f$的过滤器卷积一个$n×n$的图像，你的padding为$p$，步幅为$s$，在这个例子中$s=2$，你会得到一个输出，因为现在你不是一次移动一个步子，而是一次移动$s$个步子，输出于是变为$\frac{n+2p - f}{s} + 1 \times \frac{n+2p - f}{s} + 1$ 在我们的这个例子里，$n=7$，$p=0$，$f=3$，$s=2$，$\ \frac{7 + 0 - 3}{2} + 1 =3$，即3×3的输出。 现在只剩下最后的一个细节了，如果商不是一个整数怎么办？在这种情况下，我们向下取整。$⌊ ⌋$这是向下取整的符号，这也叫做对$z$进行地板除(floor)，这意味着$z$向下取整到最近的整数。这个原则实现的方式是，你只在蓝框完全包括在图像或填充完的图像内部时，才对它进行运算。如果有任意一个蓝框移动到了外面，那你就不要进行相乘操作，这是一个惯例。你的3×3的过滤器必须完全处于图像中或者填充之后的图像区域内才输出相应结果，这就是惯例。因此正确计算输出维度的方法是向下取整，以免$\frac{n + 2p - f}{s}$不是整数。 总结一下维度情况，如果你有一个$n×n$的矩阵或者$n×n$的图像，与一个$f×f$的矩阵卷积，或者说$f×f$的过滤器。Padding是$p$，步幅为$s$没输出尺寸就是这样： 可以选择所有的数使结果是整数是挺不错的，尽管一些时候，你不必这样做，只要向下取整也就可以了。你也可以自己选择一些$n$，$f$，$p$和$s$的值来验证这个输出尺寸的公式是对的。 在讲下一部分之前，这里有一个关于互相关和卷积的技术性建议，这不会影响到你构建卷积神经网络的方式，但取决于你读的是数学教材还是信号处理教材，在不同的教材里符号可能不一致。如果你看的是一本典型的数学教科书，那么卷积的定义是做元素乘积求和，实际上还有一个步骤是你首先要做的，也就是在把这个6×6的矩阵和3×3的过滤器卷积之前，首先你将3×3的过滤器沿水平和垂直轴翻转，所以$\begin{bmatrix}3 & 4 & 5 \\ 1 & 0 & 2 \\ - 1 & 9 & 7 \\ \end{bmatrix}$变为$\begin{bmatrix} 7& 2 & 5 \\ 9 & 0 & 4 \\ - 1 & 1 & 3 \\\end{bmatrix}$，这相当于将3×3的过滤器做了个镜像，在水平和垂直轴上（整理者注：此处应该是先顺时针旋转90得到$\begin{bmatrix}-1 & 1 & 3 \\ 9 & 0 & 4 \\ 7 & 2 & 5 \\\end{bmatrix}$，再水平翻转得到$\begin{bmatrix} 7& 2 & 5 \\ 9 & 0 & 4 \\ - 1& 1 & 3 \\\end{bmatrix}$）。然后你再把这个翻转后的矩阵复制到这里（左边的图像矩阵），你要把这个翻转矩阵的元素相乘来计算输出的4×4矩阵左上角的元素，如图所示。然后取这9个数字，把它们平移一个位置，再平移一格，以此类推。 所以我们在这些视频中定义卷积运算时，我们跳过了这个镜像操作。从技术上讲，我们实际上做的，我们在前面视频中使用的操作，有时被称为互相关（cross-correlation）而不是卷积（convolution）。但在深度学习文献中，按照惯例，我们将这（不进行翻转操作）叫做卷积操作。 总结来说，按照机器学习的惯例，我们通常不进行翻转操作。从技术上说，这个操作可能叫做互相关更好。但在大部分的深度学习文献中都把它叫做卷积运算，因此我们将在这些视频中使用这个约定。如果你读了很多机器学习文献的话，你会发现许多人都把它叫做卷积运算，不需要用到这些翻转。 事实证明在信号处理中或某些数学分支中，在卷积的定义包含翻转，使得卷积运算符拥有这个性质，即$(AB)*C=A(B*C)$，这在数学中被称为结合律。这对于一些信号处理应用来说很好，但对于深度神经网络来说它真的不重要，因此省略了这个双重镜像操作，就简化了代码，并使神经网络也能正常工作。 根据惯例，我们大多数人都叫它卷积，尽管数学家们更喜欢称之为互相关，但这不会影响到你在编程练习中要实现的任何东西，也不会影响你阅读和理解深度学习文献。 现在你已经看到了如何进行卷积，以及如何使用填充，如何在卷积中选择步幅。但到目前为止，我们所使用的是关于矩阵的卷积，例如6×6的矩阵。在下一集视频中，你将看到如何对立体进行卷积，这将会使你的卷积变得更加强大，让我们继续下一个视频。 1.6 三维卷积（Convolutions over volumes）你已经知道如何对二维图像做卷积了，现在看看如何执行卷积不仅仅在二维图像上，而是三维立体上。 我们从一个例子开始，假如说你不仅想检测灰度图像的特征，也想检测RGB彩色图像的特征。彩色图像如果是6×6×3，这里的3指的是三个颜色通道，你可以把它想象成三个6×6图像的堆叠。为了检测图像的边缘或者其他的特征，不是把它跟原来的3×3的过滤器做卷积，而是跟一个三维的过滤器，它的维度是3×3×3，这样这个过滤器也有三层，对应红绿、蓝三个通道。 给这些起个名字（原图像），这里的第一个6代表图像高度，第二个6代表宽度，这个3代表通道的数目。同样你的过滤器也有一个高，宽和通道数，并且图像的通道数必须和过滤器的通道数匹配，所以这两个数（紫色方框标记的两个数）必须相等。下个幻灯片里，我们就会知道这个卷积操作是如何进行的了，这个的输出会是一个4×4的图像，注意是4×4×1，最后一个数不是3了。 我们研究下这背后的细节，首先先换一张好看的图片。这个是6×6×3的图像，这个是3×3×3的过滤器，最后一个数字通道数必须和过滤器中的通道数相匹配。为了简化这个3×3×3过滤器的图像，我们不把它画成3个矩阵的堆叠，而画成这样，一个三维的立方体。 为了计算这个卷积操作的输出，你要做的就是把这个3×3×3的过滤器先放到最左上角的位置，这个3×3×3的过滤器有27个数，27个参数就是3的立方。依次取这27个数，然后乘以相应的红绿蓝通道中的数字。先取红色通道的前9个数字，然后是绿色通道，然后再是蓝色通道，乘以左边黄色立方体覆盖的对应的27个数，然后把这些数都加起来，就得到了输出的第一个数字。 如果要计算下一个输出，你把这个立方体滑动一个单位，再与这27个数相乘，把它们都加起来，就得到了下一个输出，以此类推。 那么，这个能干什么呢？举个例子，这个过滤器是3×3×3的，如果你想检测图像红色通道的边缘，那么你可以将第一个过滤器设为$\begin{bmatrix}1 & 0 & - 1 \\ 1 & 0 & - 1 \\ 1 & 0 & - 1 \\\end{bmatrix}$，和之前一样，而绿色通道全为0，$\begin{bmatrix} 0& 0 & 0 \\ 0 &0 & 0 \\ 0 & 0 & 0 \\\end{bmatrix}$，蓝色也全为0。如果你把这三个堆叠在一起形成一个3×3×3的过滤器，那么这就是一个检测垂直边界的过滤器，但只对红色通道有用。 或者如果你不关心垂直边界在哪个颜色通道里，那么你可以用一个这样的过滤器，$\begin{bmatrix}1 & 0 & - 1 \\ 1 & 0 & - 1 \\ 1 & 0 & - 1 \\ \end{bmatrix}$，$\begin{bmatrix}1 & 0 & - 1 \\ 1 & 0 & - 1 \\ 1 & 0 & - 1 \\ \end{bmatrix}$，$\begin{bmatrix}1 & 0 & - 1 \\ 1 & 0 & - 1 \\ 1 & 0 & - 1 \\\end{bmatrix}$，所有三个通道都是这样。所以通过设置第二个过滤器参数，你就有了一个边界检测器，3×3×3的边界检测器，用来检测任意颜色通道里的边界。参数的选择不同，你就可以得到不同的特征检测器，所有的都是3×3×3的过滤器。 按照计算机视觉的惯例，当你的输入有特定的高宽和通道数时，你的过滤器可以有不同的高，不同的宽，但是必须一样的通道数。理论上，我们的过滤器只关注红色通道，或者只关注绿色或者蓝色通道也是可行的。 再注意一下这个卷积立方体，一个6×6×6的输入图像卷积上一个3×3×3的过滤器，得到一个4×4的二维输出。 现在你已经了解了如何对立方体卷积，还有最后一个概念，对建立卷积神经网络至关重要。就是，如果我们不仅仅想要检测垂直边缘怎么办？如果我们同时检测垂直边缘和水平边缘，还有45°倾斜的边缘，还有70°倾斜的边缘怎么做？换句话说，如果你想同时用多个过滤器怎么办？ 这是我们上一张幻灯片的图片，我们让这个6×6×3的图像和这个3×3×3的过滤器卷积，得到4×4的输出。（第一个）这可能是一个垂直边界检测器或者是学习检测其他的特征。第二个过滤器可以用橘色来表示，它可以是一个水平边缘检测器。 所以和第一个过滤器卷积，可以得到第一个4×4的输出，然后卷积第二个过滤器，得到一个不同的4×4的输出。我们做完卷积，然后把这两个4×4的输出，取第一个把它放到前面，然后取第二个过滤器输出，我把它画在这，放到后面。所以把这两个输出堆叠在一起，这样你就都得到了一个4×4×2的输出立方体，你可以把这个立方体当成，重新画在这，就是一个这样的盒子，所以这就是一个4×4×2的输出立方体。它用6×6×3的图像，然后卷积上这两个不同的3×3的过滤器，得到两个4×4的输出，它们堆叠在一起，形成一个4×4×2的立方体，这里的2的来源于我们用了两个不同的过滤器。 我们总结一下维度，如果你有一个$n \times n \times n_{c}$（通道数）的输入图像，在这个例子中就是6×6×3，这里的$n_{c}$就是通道数目，然后卷积上一个$f×f×n_{c}$，这个例子中是3×3×3，按照惯例，这个（前一个$n_{c}$）和这个（后一个$n_{c}$）必须数值相同。然后你就得到了$（n-f+1）×（n-f+1）×n_{c^{'} }$，这里$n_{c^{'} }$其实就是下一层的通道数，它就是你用的过滤器的个数，在我们的例子中，那就是4×4×2。我写下这个假设时，用的步幅为1，并且没有padding。如果你用了不同的步幅或者padding，那么这个$n-f+1$数值会变化，正如前面的视频演示的那样。 这个对立方体卷积的概念真的很有用，你现在可以用它的一小部分直接在三个通道的RGB图像上进行操作。更重要的是，你可以检测两个特征，比如垂直和水平边缘或者10个或者128个或者几百个不同的特征，并且输出的通道数会等于你要检测的特征数。 对于这里的符号，我一直用通道数（$n_{c}$）来表示最后一个维度，在文献里大家也把它叫做3维立方体的深度。这两个术语，即通道或者深度，经常被用在文献中。但我觉得深度容易让人混淆，因为你通常也会说神经网络的深度。所以，在这些视频里我会用通道这个术语来表示过滤器的第三个维度的大小。 所以你已经知道怎么对立方体做卷积了，你已经准备好了实现卷积神经其中一层了，在下个视频里让我们看看是怎么做的。 1.7 单层卷积网络（One layer of a convolutional network）今天我们要讲的是如何构建卷积神经网络的卷积层，下面来看个例子。 上节课，我们已经讲了如何通过两个过滤器卷积处理一个三维图像，并输出两个不同的4×4矩阵。假设使用第一个过滤器进行卷积，得到第一个4×4矩阵。使用第二个过滤器进行卷积得到另外一个4×4矩阵。 最终各自形成一个卷积神经网络层，然后增加偏差，它是一个实数，通过Python的广播机制给这16个元素都加上同一偏差。然后应用非线性函数，为了说明，它是一个非线性激活函数ReLU，输出结果是一个4×4矩阵。 对于第二个4×4矩阵，我们加上不同的偏差，它也是一个实数，16个数字都加上同一个实数，然后应用非线性函数，也就是一个非线性激活函数ReLU，最终得到另一个4×4矩阵。然后重复我们之前的步骤，把这两个矩阵堆叠起来，最终得到一个4×4×2的矩阵。我们通过计算，从6×6×3的输入推导出一个4×4×2矩阵，它是卷积神经网络的一层，把它映射到标准神经网络中四个卷积层中的某一层或者一个非卷积神经网络中。 注意前向传播中一个操作就是$z^{[1]} = W^{[1]}a^{[0]} + b^{[1]}$，其中$a^{[0]} =x$，执行非线性函数得到$a^{[1]}$，即$a^{[1]} = g(z^{[1]})$。这里的输入是$a^{\left\lbrack 0\right\rbrack}$，也就是$x$，这些过滤器用变量$W^{[1]}$表示。在卷积过程中，我们对这27个数进行操作，其实是27×2，因为我们用了两个过滤器，我们取这些数做乘法。实际执行了一个线性函数，得到一个4×4的矩阵。卷积操作的输出结果是一个4×4的矩阵，它的作用类似于$W^{[1]}a^{[0]}$，也就是这两个4×4矩阵的输出结果，然后加上偏差。 这一部分（图中蓝色边框标记的部分）就是应用激活函数ReLU之前的值，它的作用类似于$z^{[1]}$，最后应用非线性函数，得到的这个4×4×2矩阵，成为神经网络的下一层，也就是激活层。 这就是$a^{[0]}$到$a^{[1]}$的演变过程，首先执行线性函数，然后所有元素相乘做卷积，具体做法是运用线性函数再加上偏差，然后应用激活函数ReLU。这样就通过神经网络的一层把一个6×6×3的维度$a^{[0]}$演化为一个4×4×2维度的$a^{[1]}$，这就是卷积神经网络的一层。 示例中我们有两个过滤器，也就是有两个特征，因此我们才最终得到一个4×4×2的输出。但如果我们用了10个过滤器，而不是2个，我们最后会得到一个4×4×10维度的输出图像，因为我们选取了其中10个特征映射，而不仅仅是2个，将它们堆叠在一起，形成一个4×4×10的输出图像，也就是$a^{\left\lbrack1 \right\rbrack}$。 为了加深理解，我们来做一个练习。假设你有10个过滤器，而不是2个，神经网络的一层是3×3×3，那么，这一层有多少个参数呢？我们来计算一下，每一层都是一个3×3×3的矩阵，因此每个过滤器有27个参数，也就是27个数。然后加上一个偏差，用参数$b$表示，现在参数增加到28个。上一页幻灯片里我画了2个过滤器，而现在我们有10个，加在一起是28×10，也就是280个参数。 请注意一点，不论输入图片有多大，1000×1000也好，5000×5000也好，参数始终都是280个。用这10个过滤器来提取特征，如垂直边缘，水平边缘和其它特征。即使这些图片很大，参数却很少，这就是卷积神经网络的一个特征，叫作“避免过拟合”。你已经知道到如何提取10个特征，可以应用到大图片中，而参数数量固定不变，此例中只有28个，相对较少。 最后我们总结一下用于描述卷积神经网络中的一层（以$l$层为例），也就是卷积层的各种标记。 这一层是卷积层，用$f^{[l]}$表示过滤器大小，我们说过过滤器大小为$f×f$，上标$\lbrack l\rbrack$表示$l$层中过滤器大小为$f×f$。通常情况下，上标$\lbrack l\rbrack$用来标记$l$层。用$p^{[l]}$来标记padding的数量，padding数量也可指定为一个valid卷积，即无padding。或是same卷积，即选定padding，如此一来，输出和输入图片的高度和宽度就相同了。用$s^{[l]}$标记步幅。 这一层的输入会是某个维度的数据，表示为$n \times n \times n_{c}$，$n_{c}$某层上的颜色通道数。 我们要稍作修改，增加上标$\lbrack l -1\rbrack$，即$n^{\left\lbrack l - 1 \right\rbrack} \times n^{\left\lbrack l -1 \right\rbrack} \times n_{c}^{\left\lbrack l - 1\right\rbrack}$，因为它是上一层的激活值。 此例中，所用图片的高度和宽度都一样，但它们也有可能不同，所以分别用上下标$H$和$W$来标记，即$n_{H}^{\left\lbrack l - 1 \right\rbrack} \times n_{W}^{\left\lbrack l - 1 \right\rbrack} \times n_{c}^{\left\lbrack l - 1\right\rbrack}$。那么在第$l$层，图片大小为$n_{H}^{\left\lbrack l - 1 \right\rbrack} \times n_{W}^{\left\lbrack l - 1 \right\rbrack} \times n_{c}^{\left\lbrack l - 1\right\rbrack}$，$l$层的输入就是上一层的输出，因此上标要用$\lbrack l - 1\rbrack$。神经网络这一层中会有输出，它本身会输出图像。其大小为$n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}$，这就是输出图像的大小。 前面我们提到过，这个公式给出了输出图片的大小，至少给出了高度和宽度，$\lfloor\frac{n+2p - f}{s} + 1\rfloor$（注意：（$\frac{n + 2p - f}{s} +1)$直接用这个运算结果，也可以向下取整）。在这个新表达式中，$l$层输出图像的高度，即$n_{H}^{[l]} = \lfloor\frac{n_{H}^{\left\lbrack l - 1 \right\rbrack} +2p^{[l]} - f^{[l]} }{s^{[l]} } +1\rfloor$，同样我们可以计算出图像的宽度，用$W$替换参数$H$，即$n_{W}^{[l]} = \lfloor\frac{n_{W}^{\left\lbrack l - 1 \right\rbrack} +2p^{[l]} - f^{[l]} }{s^{[l]} } +1\rfloor$，公式一样，只要变化高度和宽度的参数我们便能计算输出图像的高度或宽度。这就是由$n_{H}^{\left\lbrack l - 1 \right\rbrack}$推导$n_{H}^{[l]}$以及$n_{W}^{\left\lbrack l - 1\right\rbrack}$推导$n_{W}^{[l]}$的过程。 那么通道数量又是什么？这些数字从哪儿来的？我们来看一下。输出图像也具有深度，通过上一个示例，我们知道它等于该层中过滤器的数量，如果有2个过滤器，输出图像就是4×4×2，它是二维的，如果有10个过滤器，输出图像就是4×4×10。输出图像中的通道数量就是神经网络中这一层所使用的过滤器的数量。如何确定过滤器的大小呢？我们知道卷积一个6×6×3的图片需要一个3×3×3的过滤器，因此过滤器中通道的数量必须与输入中通道的数量一致。因此，输出通道数量就是输入通道数量，所以过滤器维度等于$f^{[l]} \times f^{[l]} \times n_{c}^{\left\lbrack l - 1 \right\rbrack}$。 应用偏差和非线性函数之后，这一层的输出等于它的激活值$a^{[l]}$，也就是这个维度（输出维度）。$a^{[l]}$是一个三维体，即$n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}$。当你执行批量梯度下降或小批量梯度下降时，如果有$m$个例子，就是有$m$个激活值的集合，那么输出$A^{[l]} = m \times n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}$。如果采用批量梯度下降，变量的排列顺序如下，首先是索引和训练示例，然后是其它三个变量。 该如何确定权重参数，即参数W呢？过滤器的维度已知，为$f^{[l]} \times f^{[l]} \times n_{c}^{[l - 1]}$，这只是一个过滤器的维度，有多少个过滤器，这（$n_{c}^{[l]}$）是过滤器的数量，权重也就是所有过滤器的集合再乘以过滤器的总数量，即$f^{[l]} \times f^{[l]} \times n_{c}^{[l - 1]} \times n_{c}^{[l]}$，损失数量L就是$l$层中过滤器的个数。 最后我们看看偏差参数，每个过滤器都有一个偏差参数，它是一个实数。偏差包含了这些变量，它是该维度上的一个向量。后续课程中我们会看到，为了方便，偏差在代码中表示为一个1×1×1×$n_{c}^{[l]}$的四维向量或四维张量。 卷积有很多种标记方法，这是我们最常用的卷积符号。大家在线搜索或查看开源代码时，关于高度，宽度和通道的顺序并没有完全统一的标准卷积，所以在查看GitHub上的源代码或阅读一些开源实现的时候，你会发现有些作者会采用把通道放在首位的编码标准，有时所有变量都采用这种标准。实际上在某些架构中，当检索这些图片时，会有一个变量或参数来标识计算通道数量和通道损失数量的先后顺序。只要保持一致，这两种卷积标准都可用。很遗憾，这只是一部分标记法，因为深度学习文献并未对标记达成一致，但课上我会采用这种卷积标识法，按高度，宽度和通道损失数量的顺序依次计算。 我知道，忽然间接触到这么多新的标记方法，你可能会说，这么多怎么记呢？别担心，不用全都记住，你可以通过本周的练习来熟悉它们。而这节课我想讲的重点是，卷积神经网络的某一卷积层的工作原理，以及如何计算某一卷积层的激活函数，并映射到下一层的激活值。了解了卷积神经网络中某一卷积层的工作原理，我们就可以把它们堆叠起来形成一个深度卷积神经网络，我们下节课再讲。 1.8 简单卷积网络示例（A simple convolution network example）上节课，我们讲了如何为卷积网络构建一个卷积层。今天我们看一个深度卷积神经网络的具体示例，顺便练习一下我们上节课所学的标记法。 假设你有一张图片，你想做图片分类或图片识别，把这张图片输入定义为$x$，然后辨别图片中有没有猫，用0或1表示，这是一个分类问题，我们来构建适用于这项任务的卷积神经网络。针对这个示例，我用了一张比较小的图片，大小是39×39×3，这样设定可以使其中一些数字效果更好。所以$n_{H}^{[0]} = n_{W}^{[0]}$，即高度和宽度都等于39，$n_{c}^{[0]} =3$，即0层的通道数为3。 假设第一层我们用一个3×3的过滤器来提取特征，那么$f^{[1]} = 3$，因为过滤器时3×3的矩阵。$s^{[1]} = 1$，$p^{[1]} =0$，所以高度和宽度使用valid卷积。如果有10个过滤器，神经网络下一层的激活值为37×37×10，写10是因为我们用了10个过滤器，37是公式$\frac{n + 2p - f}{s} + 1$的计算结果，也就是$\frac{39 + 0 - 3}{1} + 1 = 37$，所以输出是37×37，它是一个vaild卷积，这是输出结果的大小。第一层标记为$n_{H}^{[1]} = n_{W}^{[1]} = 37$，$n_{c}^{[1]} = 10$，$n_{c}^{[1]}$等于第一层中过滤器的个数，这（37×37×10）是第一层激活值的维度。 假设还有另外一个卷积层，这次我们采用的过滤器是5×5的矩阵。在标记法中，神经网络下一层的$f=5$，即$f^{\left\lbrack 2 \right\rbrack} = 5$步幅为2，即$s^{\left\lbrack 2 \right\rbrack} = 2$。padding为0，即$p^{\left\lbrack 2 \right\rbrack} = 0$，且有20个过滤器。所以其输出结果会是一张新图像，这次的输出结果为17×17×20，因为步幅是2，维度缩小得很快，大小从37×37减小到17×17，减小了一半还多，过滤器是20个，所以通道数也是20，17×17×20即激活值$a^{\left\lbrack 2 \right\rbrack}$的维度。因此$n_{H}^{\left\lbrack 2 \right\rbrack} = n_{W}^{\left\lbrack 2 \right\rbrack} = 17$，$n_{c}^{\left\lbrack 2 \right\rbrack} = 20$。 我们来构建最后一个卷积层，假设过滤器还是5×5，步幅为2，即$f^{\left\lbrack 2 \right\rbrack} = 5$，$s^{\left\lbrack 3 \right\rbrack} = 2$，计算过程我跳过了，最后输出为7×7×40，假设使用了40个过滤器。padding为0，40个过滤器，最后结果为7×7×40。 到此，这张39×39×3的输入图像就处理完毕了，为图片提取了7×7×40个特征，计算出来就是1960个特征。然后对该卷积进行处理，可以将其平滑或展开成1960个单元。平滑处理后可以输出一个向量，其填充内容是logistic回归单元还是softmax回归单元，完全取决于我们是想识图片上有没有猫，还是想识别$K$种不同对象中的一种，用$\hat y$表示最终神经网络的预测输出。明确一点，最后这一步是处理所有数字，即全部的1960个数字，把它们展开成一个很长的向量。为了预测最终的输出结果，我们把这个长向量填充到softmax回归函数中。 这是卷积神经网络的一个典型范例，设计卷积神经网络时，确定这些超参数比较费工夫。要决定过滤器的大小、步幅、padding以及使用多少个过滤器。这周和下周，我会针对选择参数的问题提供一些建议和指导。 而这节课你要掌握的一点是，随着神经网络计算深度不断加深，通常开始时的图像也要更大一些，初始值为39×39，高度和宽度会在一段时间内保持一致，然后随着网络深度的加深而逐渐减小，从39到37，再到17，最后到7。而通道数量在增加，从3到10，再到20，最后到40。在许多其它卷积神经网络中，你也可以看到这种趋势。关于如何确定这些参数，后面课上我会更详细讲解，这是我们讲的第一个卷积神经网络示例。 一个典型的卷积神经网络通常有三层，一个是卷积层，我们常常用Conv来标注。上一个例子，我用的就是CONV。还有两种常见类型的层，我们留在后两节课讲。一个是池化层，我们称之为POOL。最后一个是全连接层，用FC表示。虽然仅用卷积层也有可能构建出很好的神经网络，但大部分神经望楼架构师依然会添加池化层和全连接层。幸运的是，池化层和全连接层比卷积层更容易设计。后两节课我们会快速讲解这两个概念以便你更好的了解神经网络中最常用的这几种层，你就可以利用它们构建更强大的网络了。 再次恭喜你已经掌握了第一个卷积神经网络，本周后几节课，我们会学习如何训练这些卷积神经网络。不过在这之前，我还要简单介绍一下池化层和全连接层。然后再训练这些网络，到时我会用到大家熟悉的反向传播训练方法。那么下节课，我们就先来了解如何构建神经网络的池化层。 1.9 池化层（Pooling layers）除了卷积层，卷积网络也经常使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性，我们来看一下。 先举一个池化层的例子，然后我们再讨论池化层的必要性。假如输入是一个4×4矩阵，用到的池化类型是最大池化（max pooling）。执行最大池化的树池是一个2×2矩阵。执行过程非常简单，把4×4的输入拆分成不同的区域，我把这个区域用不同颜色来标记。对于2×2的输出，输出的每个元素都是其对应颜色区域中的最大元素值。 左上区域的最大值是9，右上区域的最大元素值是2，左下区域的最大值是6，右下区域的最大值是3。为了计算出右侧这4个元素值，我们需要对输入矩阵的2×2区域做最大值运算。这就像是应用了一个规模为2的过滤器，因为我们选用的是2×2区域，步幅是2，这些就是最大池化的超参数。 因为我们使用的过滤器为2×2，最后输出是9。然后向右移动2个步幅，计算出最大值2。然后是第二行，向下移动2步得到最大值6。最后向右移动3步，得到最大值3。这是一个2×2矩阵，即$f=2$，步幅是2，即$s=2$。 这是对最大池化功能的直观理解，你可以把这个4×4输入看作是某些特征的集合，也许不是。你可以把这个4×4区域看作是某些特征的集合，也就是神经网络中某一层的非激活值集合。数字大意味着可能探测到了某些特定的特征，左上象限具有的特征可能是一个垂直边缘，一只眼睛，或是大家害怕遇到的CAP特征。显然左上象限中存在这个特征，这个特征可能是一只猫眼探测器。然而，右上象限并不存在这个特征。最大化操作的功能就是只要在任何一个象限内提取到某个特征，它都会保留在最大化的池化输出里。所以最大化运算的实际作用就是，如果在过滤器中提取到某个特征，那么保留其最大值。如果没有提取到这个特征，可能在右上象限中不存在这个特征，那么其中的最大值也还是很小，这就是最大池化的直观理解。 必须承认，人们使用最大池化的主要原因是此方法在很多实验中效果都很好。尽管刚刚描述的直观理解经常被引用，不知大家是否完全理解它的真正原因，不知大家是否理解最大池化效率很高的真正原因。 其中一个有意思的特点就是，它有一组超参数，但并没有参数需要学习。实际上，梯度下降没有什么可学的，一旦确定了$f$和$s$，它就是一个固定运算，梯度下降无需改变任何值。 我们来看一个有若干个超级参数的示例，输入是一个5×5的矩阵。我们采用最大池化法，它的过滤器参数为3×3，即$f=3$，步幅为1，$s=1$，输出矩阵是3×3.之前讲的计算卷积层输出大小的公式同样适用于最大池化，即$\frac{n + 2p - f}{s} + 1$，这个公式也可以计算最大池化的输出大小。 此例是计算3×3输出的每个元素，我们看左上角这些元素，注意这是一个3×3区域，因为有3个过滤器，取最大值9。然后移动一个元素，因为步幅是1，蓝色区域的最大值是9.继续向右移动，蓝色区域的最大值是5。然后移到下一行，因为步幅是1，我们只向下移动一个格，所以该区域的最大值是9。这个区域也是9。这两个区域的最大值都是5。最后这三个区域的最大值分别为8，6和9。超参数$f=3$，$s=1$，最终输出如图所示。 以上就是一个二维输入的最大池化的演示，如果输入是三维的，那么输出也是三维的。例如，输入是5×5×2，那么输出是3×3×2。计算最大池化的方法就是分别对每个通道执行刚刚的计算过程。如上图所示，第一个通道依然保持不变。对于第二个通道，我刚才画在下面的，在这个层做同样的计算，得到第二个通道的输出。一般来说，如果输入是5×5×$n_{c}$，输出就是3×3×$n_{c}$，$n_{c}$个通道中每个通道都单独执行最大池化计算，以上就是最大池化算法。 另外还有一种类型的池化，平均池化，它不太常用。我简单介绍一下，这种运算顾名思义，选取的不是每个过滤器的最大值，而是平均值。示例中，紫色区域的平均值是3.75，后面依次是1.25、4和2。这个平均池化的超级参数$f=2$，$s=2$，我们也可以选择其它超级参数。 目前来说，最大池化比平均池化更常用。但也有例外，就是深度很深的神经网络，你可以用平均池化来分解规模为7×7×1000的网络的表示层，在整个空间内求平均值，得到1×1×1000，一会我们看个例子。但在神经网络中，最大池化要比平均池化用得更多。 总结一下，池化的超级参数包括过滤器大小$f$和步幅$s$，常用的参数值为$f=2$，$s=2$，应用频率非常高，其效果相当于高度和宽度缩减一半。也有使用$f=3$，$s=2$的情况。至于其它超级参数就要看你用的是最大池化还是平均池化了。你也可以根据自己意愿增加表示padding的其他超级参数，虽然很少这么用。最大池化时，往往很少用到超参数padding，当然也有例外的情况，我们下周会讲。大部分情况下，最大池化很少用padding。目前$p$最常用的值是0，即$p=0$。最大池化的输入就是$n_{H} \times n_{W} \times n_{c}$，假设没有padding，则输出$\lfloor\frac{n_{H} - f}{s} +1\rfloor \times \lfloor\frac{n_{w} - f}{s} + 1\rfloor \times n_{c}$。输入通道与输出通道个数相同，因为我们对每个通道都做了池化。需要注意的一点是，池化过程中没有需要学习的参数。执行反向传播时，反向传播没有参数适用于最大池化。只有这些设置过的超参数，可能是手动设置的，也可能是通过交叉验证设置的。 除了这些，池化的内容就全部讲完了。最大池化只是计算神经网络某一层的静态属性，没有什么需要学习的，它只是一个静态属性。 关于池化我们就讲到这儿，现在我们已经知道如何构建卷积层和池化层了。下节课，我们会分析一个更复杂的可以引进全连接层的卷积网络示例。 1.10 卷积神经网络示例（Convolutional neural network example）构建全卷积神经网络的构造模块我们已经掌握得差不多了，下面来看个例子。 假设，有一张大小为32×32×3的输入图片，这是一张RGB模式的图片，你想做手写体数字识别。32×32×3的RGB图片中含有某个数字，比如7，你想识别它是从0-9这10个数字中的哪一个，我们构建一个神经网络来实现这个功能。 我用的这个网络模型和经典网络LeNet-5非常相似，灵感也来源于此。LeNet-5是多年前Yann LeCun创建的，我所采用的模型并不是LeNet-5，但是受它启发，许多参数选择都与LeNet-5相似。输入是32×32×3的矩阵，假设第一层使用过滤器大小为5×5，步幅是1，padding是0，过滤器个数为6，那么输出为28×28×6。将这层标记为CONV1，它用了6个过滤器，增加了偏差，应用了非线性函数，可能是ReLU非线性函数，最后输出CONV1的结果。 然后构建一个池化层，这里我选择用最大池化，参数$f=2$，$s=2$，因为padding为0，我就不写出来了。现在开始构建池化层，最大池化使用的过滤器为2×2，步幅为2，表示层的高度和宽度会减少一半。因此，28×28变成了14×14，通道数量保持不变，所以最终输出为14×14×6，将该输出标记为POOL1。 人们发现在卷积神经网络文献中，卷积有两种分类，这与所谓层的划分存在一致性。一类卷积是一个卷积层和一个池化层一起作为一层，这就是神经网络的Layer1。另一类卷积是把卷积层作为一层，而池化层单独作为一层。人们在计算神经网络有多少层时，通常只统计具有权重和参数的层。因为池化层没有权重和参数，只有一些超参数。这里，我们把CONV1和POOL1共同作为一个卷积，并标记为Layer1。虽然你在阅读网络文章或研究报告时，你可能会看到卷积层和池化层各为一层的情况，这只是两种不同的标记术语。一般我在统计网络层数时，只计算具有权重的层，也就是把CONV1和POOL1作为Layer1。这里我们用CONV1和POOL1来标记，两者都是神经网络Layer1的一部分，POOL1也被划分在Layer1中，因为它没有权重，得到的输出是14×14×6。 我们再为它构建一个卷积层，过滤器大小为5×5，步幅为1，这次我们用10个过滤器，最后输出一个10×10×10的矩阵，标记为CONV2。 然后做最大池化，超参数$f=2$，$s=2$。你大概可以猜出结果，$f=2$，$s=2$，高度和宽度会减半，最后输出为5×5×10，标记为POOL2，这就是神经网络的第二个卷积层，即Layer2。 如果对Layer1应用另一个卷积层，过滤器为5×5，即$f=5$，步幅是1，padding为0，所以这里省略了，过滤器16个，所以CONV2输出为10×10×16。我们看看CONV2，这是CONV2层。 继续执行做大池化计算，参数$f=2$，$s=2$，你能猜到结果么？对10×10×16输入执行最大池化计算，参数$f=2$，$s=2$，高度和宽度减半，计算结果猜到了吧。最大池化的参数$f=2$，$s=2$，输入的高度和宽度会减半，结果为5×5×16，通道数和之前一样，标记为POOL2。这是一个卷积，即Layer2，因为它只有一个权重集和一个卷积层CONV2。 5×5×16矩阵包含400个元素，现在将POOL2平整化为一个大小为400的一维向量。我们可以把平整化结果想象成这样的一个神经元集合，然后利用这400个单元构建下一层。下一层含有120个单元，这就是我们第一个全连接层，标记为FC3。这400个单元与120个单元紧密相连，这就是全连接层。它很像我们在第一和第二门课中讲过的单神经网络层，这是一个标准的神经网络。它的权重矩阵为$W^{\left\lbrack 3 \right\rbrack}$，维度为120×400。这就是所谓的“全连接”，因为这400个单元与这120个单元的每一项连接，还有一个偏差参数。最后输出120个维度，因为有120个输出。 然后我们对这个120个单元再添加一个全连接层，这层更小，假设它含有84个单元，标记为FC4。 最后，用这84个单元填充一个softmax单元。如果我们想通过手写数字识别来识别手写0-9这10个数字，这个softmax就会有10个输出。 此例中的卷积神经网络很典型，看上去它有很多超参数，关于如何选定这些参数，后面我提供更多建议。常规做法是，尽量不要自己设置超参数，而是查看文献中别人采用了哪些超参数，选一个在别人任务中效果很好的架构，那么它也有可能适用于你自己的应用程序，这块下周我会细讲。 现在，我想指出的是，随着神经网络深度的加深，高度$n_{H}$和宽度$n_{W}$通常都会减少，前面我就提到过，从32×32到28×28，到14×14，到10×10，再到5×5。所以随着层数增加，高度和宽度都会减小，而通道数量会增加，从3到6到16不断增加，然后得到一个全连接层。 在神经网络中，另一种常见模式就是一个或多个卷积后面跟随一个池化层，然后一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个softmax。这是神经网络的另一种常见模式。 接下来我们讲讲神经网络的激活值形状，激活值大小和参数数量。输入为32×32×3，这些数做乘法，结果为3072，所以激活值$a^{[0]}$有3072维，激活值矩阵为32×32×3，输入层没有参数。计算其他层的时候，试着自己计算出激活值，这些都是网络中不同层的激活值形状和激活值大小。 有几点要注意，第一，池化层和最大池化层没有参数；第二卷积层的参数相对较少，前面课上我们提到过，其实许多参数都存在于神经网络的全连接层。观察可发现，随着神经网络的加深，激活值尺寸会逐渐变小，如果激活值尺寸下降太快，也会影响神经网络性能。示例中，激活值尺寸在第一层为6000，然后减少到1600，慢慢减少到84，最后输出softmax结果。我们发现，许多卷积网络都具有这些属性，模式上也相似。 神经网络的基本构造模块我们已经讲完了，一个卷积神经网络包括卷积层、池化层和全连接层。许多计算机视觉研究正在探索如何把这些基本模块整合起来，构建高效的神经网络，整合这些基本模块确实需要深入的理解。根据我的经验，找到整合基本构造模块最好方法就是大量阅读别人的案例。下周我会演示一些整合基本模块，成功构建高效神经网络的具体案例。我希望下周的课程可以帮助你找到构建有效神经网络的感觉，或许你也可以将别人开发的框架应用于自己的应用程序，这是下周的内容。下节课，也是本周最后一节课，我想花点时间讨论下，为什么大家愿意使用卷积，使用卷积的好处和优势是什么，以及如何整合多个卷积，如何检验神经网络，如何在训练集上训练神经网络来识别图片或执行其他任务，我们下节课继续讲。 1.11 为什么使用卷积？（Why convolutions?）这是本周最后一节课，我们来分析一下卷积在神经网络中如此受用的原因，然后对如何整合这些卷积，如何通过一个标注过的训练集训练卷积神经网络做个简单概括。和只用全连接层相比，卷积层的两个主要优势在于参数共享和稀疏连接，举例说明一下。 假设有一张32×32×3维度的图片，这是上节课的示例，假设用了6个大小为5×5的过滤器，输出维度为28×28×6。32×32×3=3072，28×28×6=4704。我们构建一个神经网络，其中一层含有3072个单元，下一层含有4074个单元，两层中的每个神经元彼此相连，然后计算权重矩阵，它等于4074×3072≈1400万，所以要训练的参数很多。虽然以现在的技术，我们可以用1400多万个参数来训练网络，因为这张32×32×3的图片非常小，训练这么多参数没有问题。如果这是一张1000×1000的图片，权重矩阵会变得非常大。我们看看这个卷积层的参数数量，每个过滤器都是5×5，一个过滤器有25个参数，再加上偏差参数，那么每个过滤器就有26个参数，一共有6个过滤器，所以参数共计156个，参数数量还是很少。 卷积网络映射这么少参数有两个原因： 一是参数共享。观察发现，特征检测如垂直边缘检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。也就是说，如果你用一个3×3的过滤器检测垂直边缘，那么图片的左上角区域，以及旁边的各个区域（左边矩阵中蓝色方框标记的部分）都可以使用这个3×3的过滤器。每个特征检测器以及输出都可以在输入图片的不同区域中使用同样的参数，以便提取垂直边缘或其它特征。它不仅适用于边缘特征这样的低阶特征，同样适用于高阶特征，例如提取脸上的眼睛，猫或者其他特征对象。即使减少参数个数，这9个参数同样能计算出16个输出。直观感觉是，一个特征检测器，如垂直边缘检测器用于检测图片左上角区域的特征，这个特征很可能也适用于图片的右下角区域。因此在计算图片左上角和右下角区域时，你不需要添加其它特征检测器。假如有一个这样的数据集，其左上角和右下角可能有不同分布，也有可能稍有不同，但很相似，整张图片共享特征检测器，提取效果也很好。 第二个方法是使用稀疏连接，我来解释下。这个0是通过3×3的卷积计算得到的，它只依赖于这个3×3的输入的单元格，右边这个输出单元（元素0）仅与36个输入特征中9个相连接。而且其它像素值都不会对输出产生任影响，这就是稀疏连接的概念。 再举一个例子，这个输出（右边矩阵中红色标记的元素 30）仅仅依赖于这9个特征（左边矩阵红色方框标记的区域），看上去只有这9个输入特征与输出相连接，其它像素对输出没有任何影响。 神经网络可以通过这两种机制减少参数，以便我们用更小的训练集来训练它，从而预防过度拟合。你们也可能听过，卷积神经网络善于捕捉平移不变。通过观察可以发现，向右移动两个像素，图片中的猫依然清晰可见，因为神经网络的卷积结构使得即使移动几个像素，这张图片依然具有非常相似的特征，应该属于同样的输出标记。实际上，我们用同一个过滤器生成各层中，图片的所有像素值，希望网络通过自动学习变得更加健壮，以便更好地取得所期望的平移不变属性。 这就是卷积或卷积网络在计算机视觉任务中表现良好的原因。 最后，我们把这些层整合起来，看看如何训练这些网络。比如我们要构建一个猫咪检测器，我们有下面这个标记训练集，$x$表示一张图片，$\hat{y}$是二进制标记或某个重要标记。我们选定了一个卷积神经网络，输入图片，增加卷积层和池化层，然后添加全连接层，最后输出一个softmax，即$\hat{y}$。卷积层和全连接层有不同的参数$w$和偏差$b$，我们可以用任何参数集合来定义代价函数。一个类似于我们之前讲过的那种代价函数，并随机初始化其参数$w$和$b$，代价函数$J$等于神经网络对整个训练集的预测的损失总和再除以$m$（即$\text{Cost}\ J = \frac{1}{m}\sum_{i = 1}^{m}{L(\hat{y}^{(i)},y^{(i)})}$）。所以训练神经网络，你要做的就是使用梯度下降法，或其它算法，例如Momentum梯度下降法，含RMSProp或其它因子的梯度下降来优化神经网络中所有参数，以减少代价函数$J$的值。通过上述操作你可以构建一个高效的猫咪检测器或其它检测器。 恭喜你完成了这一周的课程，你已经学习了卷积神经网络的所有基本构造模块，以及如何在高效图片识别系统中整合这些模块。透过本周编程练习，你可以更加具体了解这些概念，试着整合这些构造模块，并用它们解决自己的问题。 下周，我们将继续深入学习卷积神经网络。我曾提到卷积神经网络中有很多超参数，下周，我打算具体展示一些最有效的卷积神经网络示例，你也可以尝试去判断哪些网络架构类型效率更高。人们通常的做法是将别人发现和发表在研究报告上的架构应用于自己的应用程序。下周看过更多具体的示例后，相信你会做的更好。此外，下星期我们也会深入分析卷积神经网络如此高效的原因，同时讲解一些新的计算机视觉应用程序，例如，对象检测和神经风格迁移以及如何利用这些算法创造新的艺术品形式。 深度卷积网络：实例探究（Deep convolutional models: case studies）2.1 为什么要进行实例探究？（Why look at case studies?）这周我们首先来看看一些卷积神经网络的实例分析，为什么要看这些实例分析呢？上周我们讲了基本构建，比如卷积层、池化层以及全连接层这些组件。事实上，过去几年计算机视觉研究中的大量研究都集中在如何把这些基本构件组合起来，形成有效的卷积神经网络。最直观的方式之一就是去看一些案例，就像很多人通过看别人的代码来学习编程一样，通过研究别人构建有效组件的案例是个不错的办法。实际上在计算机视觉任务中表现良好的神经网络框架往往也适用于其它任务，也许你的任务也不例外。也就是说，如果有人已经训练或者计算出擅长识别猫、狗、人的神经网络或者神经网络框架，而你的计算机视觉识别任务是构建一个自动驾驶汽车，你完全可以借鉴别人的神经网络框架来解决自己的问题。 最后，学完这几节课，你应该可以读一些计算机视觉方面的研究论文了，我希望这也是你学习本课程的收获。当然，读论文并不是必须的，但是我希望当你发现你可以读懂一些计算机视觉方面的研究论文或研讨会内容时会有一种满足感。言归正传，我们进入主题。 这是后面几节课的提纲，首先我们来看几个经典的网络。 LeNet-5网络，我记得应该是1980年代的，经常被引用的AlexNet，还有VGG网络。这些都是非常有效的神经网络范例，当中的一些思路为现代计算机视觉技术的发展奠定了基础。论文中的这些想法可能对你大有裨益，对你的工作也可能有所帮助。 然后是ResNet，又称残差网络。神经网络正在不断加深，对此你可能有所了解。ResNet神经网络训练了一个深达152层的神经网络，并且在如何有效训练方面，总结出了一些有趣的想法和窍门。课程最后，我们还会讲一个Inception神经网络的实例分析。 了解了这些神经网络，我相信你会对如何构建有效的卷积神经网络更有感觉。即使计算机视觉并不是你的主要方向，但我相信你会从ResNet和Inception网络这样的实例中找到一些不错的想法。这里面有很多思路都是多学科融合的产物。总之，即便你不打算构建计算机视觉应用程序，试着从中发现一些有趣的思路，对你的工作也会有所帮助。 2.2 经典网络（Classic networks）这节课，我们来学习几个经典的神经网络结构，分别是LeNet-5、AlexNet和VGGNet，开始吧。 首先看看LeNet-5的网络结构，假设你有一张32×32×1的图片，LeNet-5可以识别图中的手写数字，比如像这样手写数字7。LeNet-5是针对灰度图片训练的，所以图片的大小只有32×32×1。实际上LeNet-5的结构和我们上周讲的最后一个范例非常相似，使用6个5×5的过滤器，步幅为1。由于使用了6个过滤器，步幅为1，padding为0，输出结果为28×28×6，图像尺寸从32×32缩小到28×28。然后进行池化操作，在这篇论文写成的那个年代，人们更喜欢使用平均池化，而现在我们可能用最大池化更多一些。在这个例子中，我们进行平均池化，过滤器的宽度为2，步幅为2，图像的尺寸，高度和宽度都缩小了2倍，输出结果是一个14×14×6的图像。我觉得这张图片应该不是完全按照比例绘制的，如果严格按照比例绘制，新图像的尺寸应该刚好是原图像的一半。 接下来是卷积层，我们用一组16个5×5的过滤器，新的输出结果有16个通道。LeNet-5的论文是在1998年撰写的，当时人们并不使用padding，或者总是使用valid卷积，这就是为什么每进行一次卷积，图像的高度和宽度都会缩小，所以这个图像从14到14缩小到了10×10。然后又是池化层，高度和宽度再缩小一半，输出一个5×5×16的图像。将所有数字相乘，乘积是400。 下一层是全连接层，在全连接层中，有400个节点，每个节点有120个神经元，这里已经有了一个全连接层。但有时还会从这400个节点中抽取一部分节点构建另一个全连接层，就像这样，有2个全连接层。 最后一步就是利用这84个特征得到最后的输出，我们还可以在这里再加一个节点用来预测$\hat{y}$的值，$\hat{y}$有10个可能的值，对应识别0-9这10个数字。在现在的版本中则使用softmax函数输出十种分类结果，而在当时，LeNet-5网络在输出层使用了另外一种，现在已经很少用到的分类器。 相比现代版本，这里得到的神经网络会小一些，只有约6万个参数。而现在，我们经常看到含有一千万到一亿个参数的神经网络，比这大1000倍的神经网络也不在少数。 不管怎样，如果我们从左往右看，随着网络越来越深，图像的高度和宽度在缩小，从最初的32×32缩小到28×28，再到14×14、10×10，最后只有5×5。与此同时，随着网络层次的加深，通道数量一直在增加，从1增加到6个，再到16个。 这个神经网络中还有一种模式至今仍然经常用到，就是一个或多个卷积层后面跟着一个池化层，然后又是若干个卷积层再接一个池化层，然后是全连接层，最后是输出，这种排列方式很常用。 对于那些想尝试阅读论文的同学，我再补充几点。接下来的部分主要针对那些打算阅读经典论文的同学，所以会更加深入。这些内容你完全可以跳过，算是对神经网络历史的一种回顾吧，听不懂也不要紧。 读到这篇经典论文时，你会发现，过去，人们使用sigmod函数和tanh函数，而不是ReLu函数，这篇论文中使用的正是sigmod函数和tanh函数。这种网络结构的特别之处还在于，各网络层之间是有关联的，这在今天看来显得很有趣。 比如说，你有一个$n_{H} \times n_{W} \times n_{C}$的网络，有$n_{C}$个通道，使用尺寸为$f×f×n_{C}$的过滤器，每个过滤器的通道数和它上一层的通道数相同。这是由于在当时，计算机的运行速度非常慢，为了减少计算量和参数，经典的LeNet-5网络使用了非常复杂的计算方式，每个过滤器都采用和输入模块一样的通道数量。论文中提到的这些复杂细节，现在一般都不用了。 我认为当时所进行的最后一步其实到现在也还没有真正完成，就是经典的LeNet-5网络在池化后进行了非线性函数处理，在这个例子中，池化层之后使用了sigmod函数。如果你真的去读这篇论文，这会是最难理解的部分之一，我们会在后面的课程中讲到。 下面要讲的网络结构简单一些，幻灯片的大部分类容来自于原文的第二段和第三段，原文的后几段介绍了另外一种思路。文中提到的这种图形变形网络如今并没有得到广泛应用，所以在读这篇论文的时候，我建议精读第二段，这段重点介绍了这种网络结构。泛读第三段，这里面主要是一些有趣的实验结果。 我要举例说明的第二种神经网络是AlexNet，是以论文的第一作者Alex Krizhevsky的名字命名的，另外两位合著者是ilya Sutskever和Geoffery Hinton。 AlexNet首先用一张227×227×3的图片作为输入，实际上原文中使用的图像是224×224×3，但是如果你尝试去推导一下，你会发现227×227这个尺寸更好一些。第一层我们使用96个11×11的过滤器，步幅为4，由于步幅是4，因此尺寸缩小到55×55，缩小了4倍左右。然后用一个3×3的过滤器构建最大池化层，$f=3$，步幅$s$为2，卷积层尺寸缩小为27×27×96。接着再执行一个5×5的卷积，padding之后，输出是27×27×276。然后再次进行最大池化，尺寸缩小到13×13。再执行一次same卷积，相同的padding，得到的结果是13×13×384，384个过滤器。再做一次same卷积，就像这样。再做一次同样的操作，最后再进行一次最大池化，尺寸缩小到6×6×256。6×6×256等于9216，将其展开为9216个单元，然后是一些全连接层。最后使用softmax函数输出识别的结果，看它究竟是1000个可能的对象中的哪一个。 实际上，这种神经网络与LeNet有很多相似之处，不过AlexNet要大得多。正如前面讲到的LeNet或LeNet-5大约有6万个参数，而AlexNet包含约6000万个参数。当用于训练图像和数据集时，AlexNet能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐藏单元或数据，这一点AlexNet表现出色。AlexNet比LeNet表现更为出色的另一个原因是它使用了ReLu激活函数。 同样的，我还会讲一些比较深奥的内容，如果你并不打算阅读论文，不听也没有关系。第一点，在写这篇论文的时候，GPU的处理速度还比较慢，所以AlexNet采用了非常复杂的方法在两个GPU上进行训练。大致原理是，这些层分别拆分到两个不同的GPU上，同时还专门有一个方法用于两个GPU进行交流。 论文还提到，经典的AlexNet结构还有另一种类型的层，叫作“局部响应归一化层”（Local Response Normalization），即LRN层，这类层应用得并不多，所以我并没有专门讲。局部响应归一层的基本思路是，假如这是网络的一块，比如是13×13×256，LRN要做的就是选取一个位置，比如说这样一个位置，从这个位置穿过整个通道，能得到256个数字，并进行归一化。进行局部响应归一化的动机是，对于这张13×13的图像中的每个位置来说，我们可能并不需要太多的高激活神经元。但是后来，很多研究者发现LRN起不到太大作用，这应该是被我划掉的内容之一，因为并不重要，而且我们现在并不用LRN来训练网络。 如果你对深度学习的历史感兴趣的话，我认为在AlexNet之前，深度学习已经在语音识别和其它几个领域获得了一些关注，但正是通过这篇论文，计算机视觉群体开始重视深度学习，并确信深度学习可以应用于计算机视觉领域。此后，深度学习在计算机视觉及其它领域的影响力与日俱增。如果你并不打算阅读这方面的论文，其实可以不用学习这节课。但如果你想读懂一些相关的论文，这是比较好理解的一篇，学起来会容易一些。 AlexNet网络结构看起来相对复杂，包含大量超参数，这些数字（55×55×96、27×27×96、27×27×256……）都是Alex Krizhevsky及其合著者不得不给出的。 这节课要讲的第三个，也是最后一个范例是VGG，也叫作VGG-16网络。值得注意的一点是，VGG-16网络没有那么多超参数，这是一种只需要专注于构建卷积层的简单网络。首先用3×3，步幅为1的过滤器构建卷积层，padding参数为same卷积中的参数。然后用一个2×2，步幅为2的过滤器构建最大池化层。因此VGG网络的一大优点是它确实简化了神经网络结构，下面我们具体讲讲这种网络结构。 假设要识别这个图像，在最开始的两层用64个3×3的过滤器对输入图像进行卷积，输出结果是224×224×64，因为使用了same卷积，通道数量也一样。VGG-16其实是一个很深的网络，这里我并没有把所有卷积层都画出来。 假设这个小图是我们的输入图像，尺寸是224×224×3，进行第一个卷积之后得到224×224×64的特征图，接着还有一层224×224×64，得到这样2个厚度为64的卷积层，意味着我们用64个过滤器进行了两次卷积。正如我在前面提到的，这里采用的都是大小为3×3，步幅为1的过滤器，并且都是采用same卷积，所以我就不再把所有的层都画出来了，只用一串数字代表这些网络。 接下来创建一个池化层，池化层将输入图像进行压缩，从224×224×64缩小到多少呢？没错，减少到112×112×64。然后又是若干个卷积层，使用129个过滤器，以及一些same卷积，我们看看输出什么结果，112×112×128.然后进行池化，可以推导出池化后的结果是这样（56×56×128）。接着再用256个相同的过滤器进行三次卷积操作，然后再池化，然后再卷积三次，再池化。如此进行几轮操作后，将最后得到的7×7×512的特征图进行全连接操作，得到4096个单元，然后进行softmax激活，输出从1000个对象中识别的结果。 顺便说一下，VGG-16的这个数字16，就是指在这个网络中包含16个卷积层和全连接层。确实是个很大的网络，总共包含约1.38亿个参数，即便以现在的标准来看都算是非常大的网络。但VGG-16的结构并不复杂，这点非常吸引人，而且这种网络结构很规整，都是几个卷积层后面跟着可以压缩图像大小的池化层，池化层缩小图像的高度和宽度。同时，卷积层的过滤器数量变化存在一定的规律，由64翻倍变成128，再到256和512。作者可能认为512已经足够大了，所以后面的层就不再翻倍了。无论如何，每一步都进行翻倍，或者说在每一组卷积层进行过滤器翻倍操作，正是设计此种网络结构的另一个简单原则。这种相对一致的网络结构对研究者很有吸引力，而它的主要缺点是需要训练的特征数量非常巨大。 有些文章还介绍了VGG-19网络，它甚至比VGG-16还要大，如果你想了解更多细节，请参考幻灯片下方的注文，阅读由Karen Simonyan和Andrew Zisserman撰写的论文。由于VGG-16的表现几乎和VGG-19不分高下，所以很多人还是会使用VGG-16。我最喜欢它的一点是，文中揭示了，随着网络的加深，图像的高度和宽度都在以一定的规律不断缩小，每次池化后刚好缩小一半，而通道数量在不断增加，而且刚好也是在每组卷积操作后增加一倍。也就是说，图像缩小的比例和通道数增加的比例是有规律的。从这个角度来看，这篇论文很吸引人。 以上就是三种经典的网络结构，如果你对这些论文感兴趣，我建议从介绍AlexNet的论文开始，然后就是VGG的论文，最后是LeNet的论文。虽然有些晦涩难懂，但对于了解这些网络结构很有帮助。 学过这些经典的网络之后，下节课我们会学习一些更先高级更强大的神经网络结构，下节课见。 2.3 残差网络(ResNets)（Residual Networks (ResNets)）非常非常深的神经网络是很难训练的，因为存在梯度消失和梯度爆炸问题。这节课我们学习跳跃连接（Skip connection），它可以从某一层网络层获取激活，然后迅速反馈给另外一层，甚至是神经网络的更深层。我们可以利用跳跃连接构建能够训练深度网络的ResNets，有时深度能够超过100层，让我们开始吧。 ResNets是由残差块（Residual block）构建的，首先我解释一下什么是残差块。 这是一个两层神经网络，在$L$层进行激活，得到$a^{\left\lbrack l + 1 \right\rbrack}$，再次进行激活，两层之后得到$a^{\left\lbrack l + 2 \right\rbrack}$。计算过程是从$a^{[l]}$开始，首先进行线性激活，根据这个公式：$z^{\left\lbrack l + 1 \right\rbrack} = W^{\left\lbrack l + 1 \right\rbrack}a^{[l]} + b^{\left\lbrack l + 1 \right\rbrack}$，通过$a^{[l]}$算出$z^{\left\lbrack l + 1 \right\rbrack}$，即$a^{[l]}$乘以权重矩阵，再加上偏差因子。然后通过ReLU非线性激活函数得到$a^{\left\lbrack l + 1 \right\rbrack}$，$a^{\left\lbrack l + 1 \right\rbrack} =g(z^{\left\lbrack l + 1 \right\rbrack})$计算得出。接着再次进行线性激活，依据等式$z^{\left\lbrack l + 2 \right\rbrack} = W^{\left\lbrack 2 + 1 \right\rbrack}a^{\left\lbrack l + 1 \right\rbrack} + b^{\left\lbrack l + 2 \right\rbrack}$，最后根据这个等式再次进行ReLu非线性激活，即$a^{\left\lbrack l + 2 \right\rbrack} = g(z^{\left\lbrack l + 2 \right\rbrack})$，这里的$g$是指ReLU非线性函数，得到的结果就是$a^{\left\lbrack l + 2 \right\rbrack}$。换句话说，信息流从$a^{\left\lbrack l \right\rbrack}$到$a^{\left\lbrack l + 2 \right\rbrack}$需要经过以上所有步骤，即这组网络层的主路径。 在残差网络中有一点变化，我们将$a^{[l]}$直接向后，拷贝到神经网络的深层，在ReLU非线性激活函数前加上$a^{[l]}$，这是一条捷径。$a^{[l]}$的信息直接到达神经网络的深层，不再沿着主路径传递，这就意味着最后这个等式($a^{\left\lbrack l + 2 \right\rbrack} = g(z^{\left\lbrack l + 2 \right\rbrack})$)去掉了，取而代之的是另一个ReLU非线性函数，仍然对$z^{\left\lbrack l + 2 \right\rbrack}$进行$g$函数处理，但这次要加上$a^{[l]}$，即：$\ a^{\left\lbrack l + 2 \right\rbrack} = g\left(z^{\left\lbrack l + 2 \right\rbrack} + a^{[l]}\right)$，也就是加上的这个$a^{[l]}$产生了一个残差块。 在上面这个图中，我们也可以画一条捷径，直达第二层。实际上这条捷径是在进行ReLU非线性激活函数之前加上的，而这里的每一个节点都执行了线性函数和ReLU激活函数。所以$a^{[l]}$插入的时机是在线性激活之后，ReLU激活之前。除了捷径，你还会听到另一个术语“跳跃连接”，就是指$a^{[l]}$跳过一层或者好几层，从而将信息传递到神经网络的更深层。 ResNet的发明者是何凯明（Kaiming He）、张翔宇（Xiangyu Zhang）、任少卿（Shaoqing Ren）和孙剑（Jiangxi Sun），他们发现使用残差块能够训练更深的神经网络。所以构建一个ResNet网络就是通过将很多这样的残差块堆积在一起，形成一个很深神经网络，我们来看看这个网络。 这并不是一个残差网络，而是一个普通网络（Plain network），这个术语来自ResNet论文。 把它变成ResNet的方法是加上所有跳跃连接，正如前一张幻灯片中看到的，每两层增加一个捷径，构成一个残差块。如图所示，5个残差块连接在一起构成一个残差网络。 如果我们使用标准优化算法训练一个普通网络，比如说梯度下降法，或者其它热门的优化算法。如果没有残差，没有这些捷径或者跳跃连接，凭经验你会发现随着网络深度的加深，训练错误会先减少，然后增多。而理论上，随着网络深度的加深，应该训练得越来越好才对。也就是说，理论上网络深度越深越好。但实际上，如果没有残差网络，对于一个普通网络来说，深度越深意味着用优化算法越难训练。实际上，随着网络深度的加深，训练错误会越来越多。 但有了ResNets就不一样了，即使网络再深，训练的表现却不错，比如说训练误差减少，就算是训练深达100层的网络也不例外。有人甚至在1000多层的神经网络中做过实验，尽管目前我还没有看到太多实际应用。但是对$x$的激活，或者这些中间的激活能够到达网络的更深层。这种方式确实有助于解决梯度消失和梯度爆炸问题，让我们在训练更深网络的同时，又能保证良好的性能。也许从另外一个角度来看，随着网络越来深，网络连接会变得臃肿，但是ResNet确实在训练深度网络方面非常有效。 现在大家对ResNet已经有了一个大致的了解，通过本周的编程练习，你可以尝试亲自实现一下这些想法。至于为什么ResNets能有如此好的表现，接下来我会有更多更棒的内容分享给大家，我们下个视频见。 2.4 残差网络为什么有用？（Why ResNets work?）为什么ResNets能有如此好的表现，我们来看个例子，它解释了其中的原因，至少可以说明，如何构建更深层次的ResNets网络的同时还不降低它们在训练集上的效率。希望你已经通过第三门课了解到，通常来讲，网络在训练集上表现好，才能在Hold-Out交叉验证集或dev集和测试集上有好的表现，所以至少在训练集上训练好ResNets是第一步。 先来看个例子，上节课我们了解到，一个网络深度越深，它在训练集上训练的效率就会有所减弱，这也是有时候我们不希望加深网络的原因。而事实并非如此，至少在训练ResNets网络时，并非完全如此，举个例子。 假设有一个大型神经网络，其输入为$X$，输出激活值$a^{[l]}$。假如你想增加这个神经网络的深度，那么用Big NN表示，输出为$ a^{\left\lbrack l\right\rbrack}$。再给这个网络额外添加两层，依次添加两层，最后输出为$a^{\left\lbrack l + 2 \right\rbrack}$，可以把这两层看作一个ResNets块，即具有捷径连接的残差块。为了方便说明，假设我们在整个网络中使用ReLU激活函数，所以激活值都大于等于0，包括输入$X$的非零异常值。因为ReLU激活函数输出的数字要么是0，要么是正数。 我们看一下$a^{\left\lbrack l + 2\right\rbrack}$的值，也就是上节课讲过的表达式，即$a^{\left\lbrack l + 2\right\rbrack} = g(z^{\left\lbrack l + 2 \right\rbrack} + a^{\left\lbrack l\right\rbrack})$，添加项$a^{\left\lbrack l\right\rbrack}$是刚添加的跳跃连接的输入。展开这个表达式$a^{\left\lbrack l + 2 \right\rbrack} = g(W^{\left\lbrack l + 2 \right\rbrack}a^{\left\lbrack l + 1 \right\rbrack} + b^{\left\lbrack l + 2 \right\rbrack} + a^{\left\lbrack l\right\rbrack})$，其中$z^{\left\lbrack l + 2 \right\rbrack} = W^{\left\lbrack l + 2 \right\rbrack}a^{\left\lbrack l + 1 \right\rbrack} + b^{\left\lbrack l + 2\right\rbrack}$。注意一点，如果使用L2正则化或权重衰减，它会压缩$W^{\left\lbrack l + 2\right\rbrack}$的值。如果对$b$应用权重衰减也可达到同样的效果，尽管实际应用中，你有时会对$b$应用权重衰减，有时不会。这里的$W$是关键项，如果$W^{\left\lbrack l + 2 \right\rbrack} = 0$，为方便起见，假设$b^{\left\lbrack l + 2 \right\rbrack} = 0$，这几项就没有了，因为它们（$W^{\left\lbrack l + 2 \right\rbrack}a^{\left\lbrack l + 1 \right\rbrack} + b^{\left\lbrack l + 2\right\rbrack}$）的值为0。最后$ a^{\left\lbrack l + 2 \right\rbrack} = \ g\left( a^{[l]} \right) = a^{\left\lbrack l\right\rbrack}$，因为我们假定使用ReLU激活函数，并且所有激活值都是非负的，$g\left(a^{[l]} \right)$是应用于非负数的ReLU函数，所以$a^{[l+2]} =a^{[l]}$。 结果表明，残差块学习这个恒等式函数并不难，跳跃连接使我们很容易得出$ a^{\left\lbrack l + 2 \right\rbrack} = a^{\left\lbrack l\right\rbrack}$。这意味着，即使给神经网络增加了这两层，它的效率也并不逊色于更简单的神经网络，因为学习恒等函数对它来说很简单。尽管它多了两层，也只把$a^{[l]}$的值赋值给$a^{\left\lbrack l + 2 \right\rbrack}$。所以给大型神经网络增加两层，不论是把残差块添加到神经网络的中间还是末端位置，都不会影响网络的表现。 当然，我们的目标不仅仅是保持网络的效率，还要提升它的效率。想象一下，如果这些隐藏层单元学到一些有用信息，那么它可能比学习恒等函数表现得更好。而这些不含有残差块或跳跃连接的深度普通网络情况就不一样了，当网络不断加深时，就算是选用学习恒等函数的参数都很困难，所以很多层最后的表现不但没有更好，反而更糟。 我认为残差网络起作用的主要原因就是这些残差块学习恒等函数非常容易，你能确定网络性能不会受到影响，很多时候甚至可以提高效率，或者说至少不会降低网络的效率，因此创建类似残差网络可以提升网络性能。 除此之外，关于残差网络，另一个值得探讨的细节是，假设$ z^{\left\lbrack l + 2\right\rbrack}$与$a^{[l]}$具有相同维度，所以ResNets使用了许多same卷积，所以这个$a^{\left\lbrack l\right\rbrack}$的维度等于这个输出层的维度。之所以能实现跳跃连接是因为same卷积保留了维度，所以很容易得出这个捷径连接，并输出这两个相同维度的向量。 如果输入和输出有不同维度，比如输入的维度是128，$ a^{\left\lbrack l + 2\right\rbrack}$的维度是256，再增加一个矩阵，这里标记为$W_{s}$，$W_{s}$是一个256×128维度的矩阵，所以$W_{s}a^{\left\lbrack l\right\rbrack}$的维度是256，这个新增项是256维度的向量。你不需要对$W_{s}$做任何操作，它是网络通过学习得到的矩阵或参数，它是一个固定矩阵，padding值为0，用0填充$a^{[l]}$，其维度为256，所以者几个表达式都可以。 最后，我们来看看ResNets的图片识别。这些图片是我从何凯明等人论文中截取的，这是一个普通网络，我们给它输入一张图片，它有多个卷积层，最后输出了一个Softmax。 如何把它转化为ResNets呢？只需要添加跳跃连接。这里我们只讨论几个细节，这个网络有很多层3×3卷积，而且它们大多都是same卷积，这就是添加等维特征向量的原因。所以这些都是卷积层，而不是全连接层，因为它们是same卷积，维度得以保留，这也解释了添加项$ z^{\left\lbrack l + 2 \right\rbrack} + a^{\left\lbrack l\right\rbrack}$（维度相同所以能够相加）。 ResNets类似于其它很多网络，也会有很多卷积层，其中偶尔会有池化层或类池化层的层。不论这些层是什么类型，正如我们在上一张幻灯片看到的，你都需要调整矩阵$W_{s}$的维度。普通网络和ResNets网络常用的结构是：卷积层-卷积层-卷积层-池化层-卷积层-卷积层-卷积层-池化层……依此重复。直到最后，有一个通过softmax进行预测的全连接层。 以上就是ResNets的内容。使用1×1的过滤器，即1×1卷积，这个想法很有意思，为什么呢？我们下节课再讲。 2.5 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions）在架构内容设计方面，其中一个比较有帮助的想法是使用1×1卷积。也许你会好奇，1×1的卷积能做什么呢？不就是乘以数字么？听上去挺好笑的，结果并非如此，我们来具体看看。 过滤器为1×1，这里是数字2，输入一张6×6×1的图片，然后对它做卷积，起过滤器大小为1×1×1，结果相当于把这个图片乘以数字2，所以前三个单元格分别是2、4、6等等。用1×1的过滤器进行卷积，似乎用处不大，只是对输入矩阵乘以某个数字。但这仅仅是对于6×6×1的一个通道图片来说，1×1卷积效果不佳。 如果是一张6×6×32的图片，那么使用1×1过滤器进行卷积效果更好。具体来说，1×1卷积所实现的功能是遍历这36个单元格，计算左图中32个数字和过滤器中32个数字的元素积之和，然后应用ReLU非线性函数。 我们以其中一个单元为例，它是这个输入层上的某个切片，用这36个数字乘以这个输入层上1×1切片，得到一个实数，像这样把它画在输出中。 这个1×1×32过滤器中的32个数字可以这样理解，一个神经元的输入是32个数字（输入图片中左下角位置32个通道中的数字），即相同高度和宽度上某一切片上的32个数字，这32个数字具有不同通道，乘以32个权重（将过滤器中的32个数理解为权重），然后应用ReLU非线性函数，在这里输出相应的结果。 一般来说，如果过滤器不止一个，而是多个，就好像有多个输入单元，其输入内容为一个切片上所有数字，输出结果是6×6过滤器数量。 所以1×1卷积可以从根本上理解为对这32个不同的位置都应用一个全连接层，全连接层的作用是输入32个数字（过滤器数量标记为$n_{C}^{\left\lbrack l + 1\right\rbrack}$，在这36个单元上重复此过程）,输出结果是6×6×#filters（过滤器数量），以便在输入层上实施一个非平凡（non-trivial）计算。 这种方法通常称为1×1卷积，有时也被称为Network in Network，在林敏、陈强和杨学成的论文中有详细描述。虽然论文中关于架构的详细内容并没有得到广泛应用，但是1×1卷积或Network in Network这种理念却很有影响力，很多神经网络架构都受到它的影响，包括下节课要讲的Inception网络。 举个1×1卷积的例子，相信对大家有所帮助，这是它的一个应用。 假设这是一个28×28×192的输入层，你可以使用池化层压缩它的高度和宽度，这个过程我们很清楚。但如果通道数量很大，该如何把它压缩为28×28×32维度的层呢？你可以用32个大小为1×1的过滤器，严格来讲每个过滤器大小都是1×1×192维，因为过滤器中通道数量必须与输入层中通道的数量保持一致。但是你使用了32个过滤器，输出层为28×28×32，这就是压缩通道数（$n_{c}$）的方法，对于池化层我只是压缩了这些层的高度和宽度。 在之后我们看到在某些网络中1×1卷积是如何压缩通道数量并减少计算的。当然如果你想保持通道数192不变，这也是可行的，1×1卷积只是添加了非线性函数，当然也可以让网络学习更复杂的函数，比如，我们再添加一层，其输入为28×28×192，输出为28×28×192。 1×1卷积层就是这样实现了一些重要功能的（doing something pretty non-trivial），它给神经网络添加了一个非线性函数，从而减少或保持输入层中的通道数量不变，当然如果你愿意，也可以增加通道数量。后面你会发现这对构建Inception网络很有帮助，我们放在下节课讲。 这节课我们演示了如何根据自己的意愿通过1×1卷积的简单操作来压缩或保持输入层中的通道数量，甚至是增加通道数量。下节课，我们再讲讲1×1卷积是如何帮助我们构建Inception网络的，下节课见。 2.6 谷歌 Inception 网络简介（Inception network motivation）构建卷积层时，你要决定过滤器的大小究竟是1×1（原来是1×3，猜测为口误），3×3还是5×5，或者要不要添加池化层。而Inception网络的作用就是代替你来决定，虽然网络架构因此变得更加复杂，但网络表现却非常好，我们来了解一下其中的原理。 例如，这是你28×28×192维度的输入层，Inception网络或Inception层的作用就是代替人工来确定卷积层中的过滤器类型，或者确定是否需要创建卷积层或池化层，我们演示一下。 如果使用1×1卷积，输出结果会是28×28×#（某个值），假设输出为28×28×64，并且这里只有一个层。 如果使用3×3的过滤器，那么输出是28×28×128。然后我们把第二个值堆积到第一个值上，为了匹配维度，我们应用same卷积，输出维度依然是28×28，和输入维度相同，即高度和宽度相同。 或许你会说，我希望提升网络的表现，用5×5过滤器或许会更好，我们不妨试一下，输出变成28×28×32，我们再次使用same卷积，保持维度不变。 或许你不想要卷积层，那就用池化操作，得到一些不同的输出结果，我们把它也堆积起来，这里的池化输出是28×28×32。为了匹配所有维度，我们需要对最大池化使用padding，它是一种特殊的池化形式，因为如果输入的高度和宽度为28×28，则输出的相应维度也是28×28。然后再进行池化，padding不变，步幅为1。 这个操作非常有意思，但我们要继续学习后面的内容，一会再实现这个池化过程。 有了这样的Inception模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。Inception模块的输入为28×28×192，输出为28×28×256。这就是Inception网络的核心内容，提出者包括Christian Szegedy、刘伟、贾阳青、Pierre Sermanet、Scott Reed、Dragomir Anguelov、Dumitru Erhan、Vincent Vanhoucke和Andrew Rabinovich。基本思想是Inception网络不需要人为决定使用哪个过滤器或者是否需要池化，而是由网络自行确定这些参数，你可以给网络添加这些参数的所有可能值，然后把这些输出连接起来，让网络自己学习它需要什么样的参数，采用哪些过滤器组合。 不难发现，我所描述的Inception层有一个问题，就是计算成本，下一张幻灯片，我们就来计算这个5×5过滤器在该模块中的计算成本。 我们把重点集中在前一张幻灯片中的5×5的过滤器，这是一个28×28×192的输入块，执行一个5×5卷积，它有32个过滤器，输出为28×28×32。前一张幻灯片中，我用一个紫色的细长块表示，这里我用一个看起来更普通的蓝色块表示。我们来计算这个28×28×32输出的计算成本，它有32个过滤器，因为输出有32个通道，每个过滤器大小为5×5×192，输出大小为28×28×32，所以你要计算28×28×32个数字。对于输出中的每个数字来说，你都需要执行5×5×192次乘法运算，所以乘法运算的总次数为每个输出值所需要执行的乘法运算次数（5×5×192）乘以输出值个数（28×28×32），把这些数相乘结果等于1.2亿(120422400)。即使在现在，用计算机执行1.2亿次乘法运算，成本也是相当高的。下一张幻灯片会介绍1×1卷积的应用，也就是我们上节课所学的。为了降低计算成本，我们用计算成本除以因子10，结果它从1.2亿减小到原来的十分之一。请记住120这个数字，一会还要和下一页看到的数字做对比。 这里还有另外一种架构，其输入为28×28×192，输出为28×28×32。其结果是这样的，对于输入层，使用1×1卷积把输入值从192个通道减少到16个通道。然后对这个较小层运行5×5卷积，得到最终输出。请注意，输入和输出的维度依然相同，输入是28×28×192，输出是28×28×32，和上一页的相同。但我们要做的就是把左边这个大的输入层压缩成这个较小的的中间层，它只有16个通道，而不是192个。 有时候这被称为瓶颈层，瓶颈通常是某个对象最小的部分，假如你有这样一个玻璃瓶，这是瓶塞位置，瓶颈就是这个瓶子最小的部分。 同理，瓶颈层也是网络中最小的部分，我们先缩小网络表示，然后再扩大它。 接下来我们看看这个计算成本，应用1×1卷积，过滤器个数为16，每个过滤器大小为1×1×192，这两个维度相匹配（输入通道数与过滤器通道数），28×28×16这个层的计算成本是，输出28×28×192中每个元素都做192次乘法，用1×1×192来表示，相乘结果约等于240万。 那第二个卷积层呢？240万只是第一个卷积层的计算成本，第二个卷积层的计算成本又是多少呢？这是它的输出，28×28×32，对每个输出值应用一个5×5×16维度的过滤器，计算结果为1000万。 所以所需要乘法运算的总次数是这两层的计算成本之和，也就是1204万，与上一张幻灯片中的值做比较，计算成本从1.2亿下降到了原来的十分之一，即1204万。所需要的加法运算与乘法运算的次数近似相等，所以我只统计了乘法运算的次数。 总结一下，如果你在构建神经网络层的时候，不想决定池化层是使用1×1，3×3还是5×5的过滤器，那么Inception模块就是最好的选择。我们可以应用各种类型的过滤器，只需要把输出连接起来。之后我们讲到计算成本问题，我们学习了如何通过使用1×1卷积来构建瓶颈层，从而大大降低计算成本。 你可能会问，仅仅大幅缩小表示层规模会不会影响神经网络的性能？事实证明，只要合理构建瓶颈层，你既可以显著缩小表示层规模，又不会降低网络性能，从而节省了计算。 这就是Inception模块的主要思想，我们在这总结一下。下节课，我们将演示一个完整的Inception网络。 2.7 Inception 网络（Inception network）在上节视频中，你已经见到了所有的Inception网络基础模块。在本视频中，我们将学习如何将这些模块组合起来，构筑你自己的Inception网络。 Inception模块会将之前层的激活或者输出作为它的输入，作为前提，这是一个28×28×192的输入，和我们之前视频中的一样。我们详细分析过的例子是，先通过一个1×1的层，再通过一个5×5的层，1×1的层可能有16个通道，而5×5的层输出为28×28×32，共32个通道，这就是上个视频最后讲到的我们处理的例子。 为了在这个3×3的卷积层中节省运算量，你也可以做相同的操作，这样的话3×3的层将会输出28×28×128。 或许你还想将其直接通过一个1×1的卷积层，这时就不必在后面再跟一个1×1的层了，这样的话过程就只有一步，假设这个层的输出是28×28×64。 最后是池化层。 这里我们要做些有趣的事情，为了能在最后将这些输出都连接起来，我们会使用same类型的padding来池化，使得输出的高和宽依然是28×28，这样才能将它与其他输出连接起来。但注意，如果你进行了最大池化，即便用了same padding，3×3的过滤器，stride为1，其输出将会是28×28×192，其通道数或者说深度与这里的输入（通道数）相同。所以看起来它会有很多通道，我们实际要做的就是再加上一个1×1的卷积层，去进行我们在1×1卷积层的视频里所介绍的操作，将通道的数量缩小，缩小到28×28×32。也就是使用32个维度为1×1×192的过滤器，所以输出的维度其通道数缩小为32。这样就避免了最后输出时，池化层占据所有的通道。 最后，将这些方块全都连接起来。在这过程中，把得到的各个层的通道都加起来，最后得到一个28×28×256的输出。通道连接实际就是之前视频中看到过的，把所有方块连接在一起的操作。这就是一个Inception模块，而Inception网络所做的就是将这些模块都组合到一起。 这是一张取自Szegety et al的论文中关于Inception网络的图片，你会发现图中有许多重复的模块，可能整张图看上去很复杂，但如果你只截取其中一个环节（编号1），就会发现这是在前一页ppt中所见的Inception模块。 我们深入看看里边的一些细节，这是另一个Inception模块（编号2），这也是一个Inception模块（编号3）。这里有一些额外的最大池化层（编号6）来修改高和宽的维度。这是另外一个Inception模块（编号4），这是另外一个最大池化层（编号7），它改变了高和宽。而这里又是另一个Inception模块（编号5）。 所以Inception网络只是很多这些你学过的模块在不同的位置重复组成的网络，所以如果你理解了之前所学的Inception模块，你就也能理解Inception网络。 事实上，如果你读过论文的原文，你就会发现，这里其实还有一些分支，我现在把它们加上去。所以这些分支有什么用呢？在网络的最后几层，通常称为全连接层，在它之后是一个softmax层（编号1）来做出预测，这些分支（编号2）所做的就是通过隐藏层（编号3）来做出预测，所以这其实是一个softmax输出（编号2），这（编号1）也是。这是另一条分支（编号4），它也包含了一个隐藏层，通过一些全连接层，然后有一个softmax来预测，输出结果的标签。 你应该把它看做Inception网络的一个细节，它确保了即便是隐藏单元和中间层（编号5）也参与了特征计算，它们也能预测图片的分类。它在Inception网络中，起到一种调整的效果，并且能防止网络发生过拟合。 还有这个特别的Inception网络是由Google公司的作者所研发的，它被叫做GoogleLeNet，这个名字是为了向LeNet网络致敬。在之前的视频中你应该了解了LeNet网络。我觉得这样非常好，因为深度学习研究人员是如此重视协作，深度学习工作者对彼此的工作成果有一种强烈的敬意。 最后，有个有趣的事实，Inception网络这个名字又是缘何而来呢？Inception的论文特地提到了这个模因（meme，网络用语即“梗”），就是“我们需要走的更深”（We need to go deeper），论文还引用了这个网址（http://knowyourmeme.com/memes/we-need-to-go-deeper），连接到这幅图片上，如果你看过Inception（盗梦空间）这个电影，你应该能看懂这个由来。作者其实是通过它来表明了建立更深的神经网络的决心，他们正是这样构建了Inception。我想一般研究论文，通常不会引用网络流行模因（梗），但这里显然很合适。 最后总结一下，如果你理解了Inception模块，你就能理解Inception网络，无非是很多个Inception模块一环接一环，最后组成了网络。自从Inception模块诞生以来，经过研究者们的不断发展，衍生了许多新的版本。所以在你们看一些比较新的Inception算法的论文时，会发现人们使用这些新版本的算法效果也一样很好，比如Inception V2、V3以及V4，还有一个版本引入了跳跃连接的方法，有时也会有特别好的效果。但所有的这些变体都建立在同一种基础的思想上，在之前的视频中你就已经学到过，就是把许多Inception模块通过某种方式连接到一起。通过这个视频，我想你应该能去阅读和理解这些Inception的论文，甚至是一些新版本的论文。 直到现在，你已经了解了许多专用的神经网络结构。在下节视频中，我将会告诉你们如何真正去使用这些算法来构建自己的计算机视觉系统，我们下节视频再见。 2.8 使用开源的实现方案（Using open-source implementations）你现在已经学过几个非常有效的神经网络和ConvNet架构，在接下来的几段视频中我想与你分享几条如何使用它们的实用性建议，首先从使用开放源码的实现开始。 事实证明很多神经网络复杂细致，因而难以复制，因为一些参数调整的细节问题，例如学习率衰减等等，会影响性能。所以我发现有些时候，甚至在顶尖大学学习AI或者深度学习的博士生也很难通过阅读别人的研究论文来复制他人的成果。幸运的是有很多深度学习的研究者都习惯把自己的成果作为开发资源，放在像GitHub之类的网站上。当你自己编写代码时，我鼓励你考虑一下将你的代码贡献给开源社区。如果你看到一篇研究论文想应用它的成果，你应该考虑做一件事，我经常做的就是在网络上寻找一个开源的实现。因为你如果能得到作者的实现，通常要比你从头开始实现要快得多，虽然从零开始实现肯定可以是一个很好的锻炼。 如果你已经熟悉如何使用GitHub，这段视频对你来说可能没什么必要或者没那么重要。但是如果你不习惯从GitHub下载开源代码，让我来演示一下。 （整理者注：ResNets实现的GitHub地址https://github.com/KaimingHe/deep-residual-networks） 假设你对残差网络感兴趣，那就让我们搜索GitHub上的ResNets，那么你可以在GitHub看到很多不同的ResNet的实现。我就打开这里的第一个网址，这是一个ResNets实现的GitHub资源库。在很多GitHub的网页上往下翻，你会看到一些描述，这个实现的文字说明。这个GitHub资源库，实际上是由ResNet论文原作者上传的。这些代码，这里有麻省理工学院的许可，你可以点击查看此许可的含义，MIT许可是比较开放的开源许可之一。我将下载代码，点击这里的链接，它会给你一个URL，通过这个你可以下载这个代码。 我点击这里的按钮（Clone or download），将这个URL复制到我的剪切板里。 （整理者注：NG此处使用的是linux系统的bash命令行，对于win10系统，可以开启linux子系统功能，然后在win10应用商店下载ubuntu安装，运行CMD，输入命令bash即可进入linux的bash命令行） 接着到这里，接下来你要做的就是输入git clone，接着粘贴URL，按下回车，几秒之内就将这个资源库的副本下载到我的本地硬盘里。 让我们进入目录，让我们看一下，比起Windows，我更习惯用Mac，不过没关系，让我们试一下，让我们进入prototxt，我认为这就是存放这些网络文件的地方。让我们看一下这个文件。因为这个文件很长，包含了ResNet里101层的详细配置。我记得，从这个网页上看到这个特殊实现使用了Caffe框架。但如果你想通过其它编程框架来实现这一代码，你也可以尝试寻找一下。 如果你在开发一个计算机视觉应用，一个常见的工作流程是，先选择一个你喜欢的架构，或许是你在这门课中学习到的，或者是你从朋友那听说的，或者是从文献中看到的，接着寻找一个开源实现，从GitHub下载下来，以此基础开始构建。这样做的优点在于，这些网络通常都需要很长的时间来训练，而或许有人已经使用多个GPU，通过庞大的数据集预先训练了这些网络，这样一来你就可以使用这些网络进行迁移学习，我们将在下一节课讨论这些内容。 当然，如果你是一名计算机视觉研究员，从零来实现这些，那么你的工作流程将会不同，如果你自己构建，那么希望你将工作成果贡献出来，放到开源社区。因为已经有如此多计算机视觉研究者为了实现这些架构做了如此之多的工作，我发现从开源项目上开始是一个更好的方法，它也确实是一个更快开展新项目的方法。 2.9 迁移学习（Transfer Learning）如果你要做一个计算机视觉的应用，相比于从头训练权重，或者说从随机初始化权重开始，如果你下载别人已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预训练，然后转换到你感兴趣的任务上。计算机视觉的研究社区非常喜欢把许多数据集上传到网上，如果你听说过，比如ImageNet，或者MS COCO，或者Pascal类型的数据集，这些都是不同数据集的名字，它们都是由大家上传到网络的，并且有大量的计算机视觉研究者已经用这些数据集训练过他们的算法了。有时候这些训练过程需要花费好几周，并且需要很多的GPU，其它人已经做过了，并且经历了非常痛苦的寻最优过程，这就意味着你可以下载花费了别人好几周甚至几个月而做出来的开源的权重参数，把它当作一个很好的初始化用在你自己的神经网络上。用迁移学习把公共的数据集的知识迁移到你自己的问题上，让我们看一下怎么做。 举个例子，假如说你要建立一个猫咪检测器，用来检测你自己的宠物猫。比如网络上的Tigger，是一个常见的猫的名字，Misty也是比较常见的猫名字。假如你的两只猫叫Tigger和Misty，还有一种情况是，两者都不是。所以你现在有一个三分类问题，图片里是Tigger还是Misty，或者都不是，我们忽略两只猫同时出现在一张图片里的情况。现在你可能没有Tigger或者Misty的大量的图片，所以你的训练集会很小，你该怎么办呢？ 我建议你从网上下载一些神经网络开源的实现，不仅把代码下载下来，也把权重下载下来。有许多训练好的网络，你都可以下载。举个例子，ImageNet数据集，它有1000个不同的类别，因此这个网络会有一个Softmax单元，它可以输出1000个可能类别之一。 你可以去掉这个Softmax层，创建你自己的Softmax单元，用来输出Tigger、Misty和neither三个类别。就网络而言，我建议你把所有的层看作是冻结的，你冻结网络中所有层的参数，你只需要训练和你的Softmax层有关的参数。这个Softmax层有三种可能的输出，Tigger、Misty或者都不是。 通过使用其他人预训练的权重，你很可能得到很好的性能，即使只有一个小的数据集。幸运的是，大多数深度学习框架都支持这种操作，事实上，取决于用的框架，它也许会有trainableParameter=0这样的参数，对于这些前面的层，你可能会设置这个参数。为了不训练这些权重，有时也会有freeze=1这样的参数。不同的深度学习编程框架有不同的方式，允许你指定是否训练特定层的权重。在这个例子中，你只需要训练softmax层的权重，把前面这些层的权重都冻结。 另一个技巧，也许对一些情况有用，由于前面的层都冻结了，相当于一个固定的函数，不需要改变。因为你不需要改变它，也不训练它，取输入图像$X$，然后把它映射到这层（softmax的前一层）的激活函数。所以这个能加速训练的技巧就是，如果我们先计算这一层（紫色箭头标记），计算特征或者激活值，然后把它们存到硬盘里。你所做的就是用这个固定的函数，在这个神经网络的前半部分（softmax层之前的所有层视为一个固定映射），取任意输入图像$X$，然后计算它的某个特征向量，这样你训练的就是一个很浅的softmax模型，用这个特征向量来做预测。对你的计算有用的一步就是对你的训练集中所有样本的这一层的激活值进行预计算，然后存储到硬盘里，然后在此之上训练softmax分类器。所以，存储到硬盘或者说预计算方法的优点就是，你不需要每次遍历训练集再重新计算这个激活值了。 因此如果你的任务只有一个很小的数据集，你可以这样做。要有一个更大的训练集怎么办呢？根据经验，如果你有一个更大的标定的数据集，也许你有大量的Tigger和Misty的照片，还有两者都不是的，这种情况，你应该冻结更少的层，比如只把这些层冻结，然后训练后面的层。如果你的输出层的类别不同，那么你需要构建自己的输出单元，Tigger、Misty或者两者都不是三个类别。有很多方式可以实现，你可以取后面几层的权重，用作初始化，然后从这里开始梯度下降。 或者你可以直接去掉这几层，换成你自己的隐藏单元和你自己的softmax输出层，这些方法值得一试。但是有一个规律，如果你有越来越多的数据，你需要冻结的层数越少，你能够训练的层数就越多。这个理念就是，如果你有一个更大的数据集，也许有足够多的数据，那么不要单单训练一个softmax单元，而是考虑训练中等大小的网络，包含你最终要用的网络的后面几层。 最后，如果你有大量数据，你应该做的就是用开源的网络和它的权重，把这、所有的权重当作初始化，然后训练整个网络。再次注意，如果这是一个1000节点的softmax，而你只有三个输出，你需要你自己的softmax输出层来输出你要的标签。 如果你有越多的标定的数据，或者越多的Tigger、Misty或者两者都不是的图片，你可以训练越多的层。极端情况下，你可以用下载的权重只作为初始化，用它们来代替随机初始化，接着你可以用梯度下降训练，更新网络所有层的所有权重。 这就是卷积网络训练中的迁移学习，事实上，网上的公开数据集非常庞大，并且你下载的其他人已经训练好几周的权重，已经从数据中学习了很多了，你会发现，对于很多计算机视觉的应用，如果你下载其他人的开源的权重，并用作你问题的初始化，你会做的更好。在所有不同学科中，在所有深度学习不同的应用中，我认为计算机视觉是一个你经常用到迁移学习的领域，除非你有非常非常大的数据集，你可以从头开始训练所有的东西。总之，迁移学习是非常值得你考虑的，除非你有一个极其大的数据集和非常大的计算量预算来从头训练你的网络。 2.10 数据增强（Data augmentation）大部分的计算机视觉任务使用很多的数据，所以数据扩充是经常使用的一种技巧来提高计算机视觉系统的表现。我认为计算机视觉是一个相当复杂的工作，你需要输入图像的像素值，然后弄清楚图片中有什么，似乎你需要学习一个复杂方程来做这件事。在实践中，更多的数据对大多数计算机视觉任务都有所帮助，不像其他领域，有时候得到充足的数据，但是效果并不怎么样。但是，当下在计算机视觉方面，计算机视觉的主要问题是没有办法得到充足的数据。对大多数机器学习应用，这不是问题，但是对计算机视觉，数据就远远不够。所以这就意味着当你训练计算机视觉模型的时候，数据扩充会有所帮助，这是可行的，无论你是使用迁移学习，使用别人的预训练模型开始，或者从源代码开始训练模型。让我们来看一下计算机视觉中常见的数据扩充的方法。 或许最简单的数据扩充方法就是垂直镜像对称，假如，训练集中有这张图片，然后将其翻转得到右边的图像。对大多数计算机视觉任务，左边的图片是猫，然后镜像对称仍然是猫，如果镜像操作保留了图像中想识别的物体的前提下，这是个很实用的数据扩充技巧。 另一个经常使用的技巧是随机裁剪，给定一个数据集，然后开始随机裁剪，可能修剪这个（编号1），选择裁剪这个（编号2），这个（编号3），可以得到不同的图片放在数据集中，你的训练集中有不同的裁剪。随机裁剪并不是一个完美的数据扩充的方法，如果你随机裁剪的那一部分（红色方框标记部分，编号4），这部分看起来不像猫。但在实践中，这个方法还是很实用的，随机裁剪构成了很大一部分的真实图片。 镜像对称和随机裁剪是经常被使用的。当然，理论上，你也可以使用旋转，剪切（shearing：此处并非裁剪的含义，图像仅水平或垂直坐标发生变化）图像，可以对图像进行这样的扭曲变形，引入很多形式的局部弯曲等等。当然使用这些方法并没有坏处，尽管在实践中，因为太复杂了所以使用的很少。 第二种经常使用的方法是彩色转换，有这样一张图片，然后给R、G和B三个通道上加上不同的失真值。 在这个例子中（编号1），要给红色、蓝色通道加值，给绿色通道减值。红色和蓝色会产生紫色，使整张图片看起来偏紫，这样训练集中就有失真的图片。为了演示效果，我对图片的颜色进行改变比较夸张。在实践中，对R、G和B的变化是基于某些分布的，这样的改变也可能很小。 这么做的目的就是使用不同的R、G和B的值，使用这些值来改变颜色。在第二个例子中（编号2），我们少用了一点红色，更多的绿色和蓝色色调，这就使得图片偏黄一点。 在这（编号3）使用了更多的蓝色，仅仅多了点红色。在实践中，R、G和B的值是根据某种概率分布来决定的。这么做的理由是，可能阳光会有一点偏黄，或者是灯光照明有一点偏黄，这些可以轻易的改变图像的颜色，但是对猫的识别，或者是内容的识别，以及标签$y$，还是保持不变的。所以介绍这些，颜色失真或者是颜色变换方法，这样会使得你的学习算法对照片的颜色更改更具鲁棒性。 这是对更高级的学习者的一些注意提醒，你可以不理解我用红色标出来的内容。对R、G和B有不同的采样方式，其中一种影响颜色失真的算法是PCA，即主成分分析，我在机器学习的mooc中讲过，在Coursera ml-class.Org机器学习这门课中。但具体颜色改变的细节在AlexNet的论文中有时候被称作PCA颜色增强，PCA颜色增强的大概含义是，比如说，如果你的图片呈现紫色，即主要含有红色和蓝色，绿色很少，然后PCA颜色增强算法就会对红色和蓝色增减很多，绿色变化相对少一点，所以使总体的颜色保持一致。如果这些你都不懂，不需要担心，可以在网上搜索你想要了解的东西，如果你愿意的话可以阅读AlexNet论文中的细节，你也能找到PCA颜色增强的开源实现方法，然后直接使用它。 你可能有存储好的数据，你的训练数据存在硬盘上，然后使用符号，这个圆桶来表示你的硬盘。如果你有一个小的训练数据，你可以做任何事情，这些数据集就够了。 但是你有特别大的训练数据，接下来这些就是人么经常使用的方法。你可能会使用CPU线程，然后它不停的从硬盘中读取数据，所以你有一个从硬盘过来的图片数据流。你可以用CPU线程来实现这些失真变形，可以是随机裁剪、颜色变化，或者是镜像。但是对每张图片得到对应的某一种变形失真形式，看这张图片（编号1），对其进行镜像变换，以及使用颜色失真，这张图最后会颜色变化（编号2），从而得到不同颜色的猫。 与此同时，CPU线程持续加载数据，然后实现任意失真变形，从而构成批数据或者最小批数据，这些数据持续的传输给其他线程或者其他的进程，然后开始训练，可以在CPU或者GPU上实现训一个大型网络的训练。 常用的实现数据扩充的方法是使用一个线程或者是多线程，这些可以用来加载数据，实现变形失真，然后传给其他的线程或者其他进程，来训练这个（编号2）和这个（编号1），可以并行实现。 这就是数据扩充，与训练深度神经网络的其他部分类似，在数据扩充过程中也有一些超参数，比如说颜色变化了多少，以及随机裁剪的时候使用的参数。与计算机视觉其他部分类似，一个好的开始可能是使用别人的开源实现，了解他们如何实现数据扩充。当然如果你想获得更多的不变特性，而其他人的开源实现并没有实现这个，你也可以去调整这些参数。因此，我希望你们可以使用数据扩充使你的计算机视觉应用效果更好。 2.11 计算机视觉现状（The state of computer vision）深度学习已经成功地应用于计算机视觉、自然语言处理、语音识别、在线广告、物流还有其他许多问题。在计算机视觉的现状下，深度学习应用于计算机视觉应用有一些独特之处。在这个视频中，我将和你们分享一些我对深度学习在计算机视觉方面应用的认识，希望能帮助你们更好地理解计算机视觉作品（此处指计算机视觉或者数据竞赛中的模型）以及其中的想法，以及如何自己构建这些计算机视觉系统。 你可以认为大部分机器学习问题是介于少量数据和大量数据范围之间的。举个例子，我认为今天我们有相当数量的语音识别数据，至少相对于这个问题的复杂性而言。虽然现在图像识别或图像分类方面有相当大的数据集，因为图像识别是一个复杂的问题，通过分析像素并识别出它是什么，感觉即使在线数据集非常大，如超过一百万张图片，我们仍然希望我们能有更多的数据。还有一些问题，比如物体检测，我们拥有的数据更少。提醒一下，图像识别其实是如何看图片的问题，并且告诉你这张图是不是猫，而对象检测则是看一幅图，你画一个框，告诉你图片里的物体，比如汽车等等。因为获取边框的成本比标记对象的成本更高，所以我们进行对象检测的数据往往比图像识别数据要少，对象检测是我们下周要讨论的内容。 所以，观察一下机器学习数据范围图谱，你会发现当你有很多数据时，人们倾向于使用更简单的算法和更少的手工工程，因为我们不需要为这个问题精心设计特征。当你有大量的数据时，只要有一个大型的神经网络，甚至一个更简单的架构，可以是一个神经网络，就可以去学习它想学习的东西。 相反当你没有那么多的数据时，那时你会看到人们从事更多的是手工工程，低调点说就是你有很多小技巧可用（整理者注：在机器学习或者深度学习中，一般更崇尚更少的人工处理，而手工工程更多依赖人工处理，注意领会Andrew NG的意思）。但我认为每你没有太多数据时，手工工程实际上是获得良好表现的最佳方式。 所以当我看机器学习应用时，我们认为通常我们的学习算法有两种知识来源，一个来源是被标记的数据，就像$(x，y)$应用在监督学习。第二个知识来源是手工工程，有很多方法去建立一个手工工程系统，它可以是源于精心设计的特征，手工精心设计的网络体系结构或者是系统的其他组件。所以当你没有太多标签数据时，你只需要更多地考虑手工工程。 所以我认为计算机视觉是在试图学习一个非常复杂的功能，我们经常感觉我们没有足够的数据，即使获得了更多数据，我们还是经常觉得还是没有足够的数据来满足需求。这就是为什么计算机视觉，从过去甚至到现在都更多地依赖于手工工程。我认为这也是计算机视觉领域发展相当复杂网络架构地原因，因为在缺乏更多数据的情况下，获得良好表现的方式还是花更多时间进行架构设计，或者说在网络架构设计上浪费（贬义褒用，即需要花费更多时间的意思）更多时间。 如果你认为我是在贬低手工工程，那并不是我的意思，当你没有足够的数据时，手工工程是一项非常困难，非常需要技巧的任务，它需要很好的洞察力，那些对手工工程有深刻见解的人将会得到更好的表现。当你没有足够的数据时，手工工程对一个项目来说贡献就很大。当你有很多数据的时候我就不会花时间去做手工工程，我会花时间去建立学习系统。但我认为从历史而言，计算机视觉领域还只是使用了非常小的数据集，因此从历史上来看计算机视觉还是依赖于大量的手工工程。甚至在过去的几年里，计算机视觉任务的数据量急剧增加，我认为这导致了手工工程量大幅减少，但是在计算机视觉上仍然有很多的网络架构使用手工工程，这就是为什么你会在计算机视觉中看到非常复杂的超参数选择，比你在其他领域中要复杂的多。实际上，因为你通常有比图像识别数据集更小的对象检测数据集，当我们谈论对象检测时，其实这是下周的任务，你会看到算法变得更加复杂，而且有更多特殊的组件。 幸运的是，当你有少量的数据时，有一件事对你很有帮助，那就是迁移学习。我想说的是，在之前的幻灯片中，Tigger、Misty或者二者都不是的检测问题中，我们有这么少的数据，迁移学习会有很大帮助。这是另一套技术，当你有相对较少的数据时就可以用很多相似的数据。 如果你看一下计算机视觉方面的作品，看看那里的创意，你会发现人们真的是踌躇满志，他们在基准测试中和竞赛中表现出色。对计算机视觉研究者来说，如果你在基准上做得很好了，那就更容易发表论文了，所以有许多人致力于这些基准上，把它做得很好。积极的一面是，它有助于整个社区找出最有效得算法。但是你在论文上也看到，人们所做的事情让你在数据基准上表现出色，但你不会真正部署在一个实际得应用程序用在生产或一个系统上。 （整理着注：Benchmark 基准测试，Benchmark是一个评价方式，在整个计算机领域有着长期的应用。维基百科上解释：“As computer architecture advanced, it became more difficult to compare the performance of various computer systems simply by looking at their specifications.Therefore, tests were developed that allowed comparison of different architectures.”Benchmark在计算机领域应用最成功的就是性能测试，主要测试负载的执行时间、传输速度、吞吐量、资源占用率等。） 下面是一些有助于在基准测试中表现出色的小技巧，这些都是我自己从来没使用过的东西，如果我把一个系统投入生产，那就是为客户服务。 其中一个是集成，这就意味着在你想好了你想要的神经网络之后，可以独立训练几个神经网络，并平均它们的输出。比如说随机初始化三个、五个或者七个神经网络，然后训练所有这些网络，然后平均它们的输出。另外对他们的输出$\hat y$进行平均计算是很重要的，不要平均他们的权重，这是行不通的。看看你的7个神经网络，它们有7个不同的预测，然后平均他们，这可能会让你在基准上提高1%，2%或者更好。这会让你做得更好，也许有时会达到1%或2%，这真的能帮助你赢得比赛。但因为集成意味着要对每张图片进行测试，你可能需要在从3到15个不同的网络中运行一个图像，这是很典型的，因为这3到15个网络可能会让你的运行时间变慢，甚至更多时间，所以技巧之一的集成是人们在基准测试中表现出色和赢得比赛的利器，但我认为这几乎不用于生产服务于客户的，我想除非你有一个巨大的计算预算而且不介意在每个用户图像数据上花费大量的计算。 你在论文中可以看到在测试时，对进准测试有帮助的另一个技巧就是Multi-crop at test time，我的意思是你已经看到了如何进行数据扩充，Multi-crop是一种将数据扩充应用到你的测试图像中的一种形式。 举个例子，让我们看看猫的图片，然后把它复制四遍，包括它的两个镜像版本。有一种叫作10-crop的技术（crop理解为裁剪的意思），它基本上说，假设你取这个中心区域，裁剪，然后通过你的分类器去运行它，然后取左上角区域，运行你的分类器，右上角用绿色表示，左下方用黄色表示，右下方用橙色表示，通过你的分类器来运行它，然后对镜像图像做同样的事情对吧？所以取中心的crop，然后取四个角落的crop。 这是这里（编号1）和这里（编号3）就是中心crop，这里（编号2）和这里（编号4）就是四个角落的crop。如果把这些加起来，就会有10种不同的图像的crop，因此命名为10-crop。所以你要做的就是，通过你的分类器来运行这十张图片，然后对结果进行平均。如果你有足够的计算预算，你可以这么做，也许他们需要10个crops，你可以使用更多，这可能会让你在生产系统中获得更好的性能。如果是生产的话，我的意思还是实际部署用户的系统。但这是另一种技术，它在基准测试上的应用，要比实际生产系统中好得多。 集成的一个大问题是你需要保持所有这些不同的神经网络，这就占用了更多的计算机内存。对于multi-crop，我想你只保留一个网络，所以它不会占用太多的内存，但它仍然会让你的运行时间变慢。 这些是你看到的小技巧，研究论文也可以参考这些，但我个人并不倾向于在构建生产系统时使用这些方法，尽管它们在基准测试和竞赛上做得很好。 由于计算机视觉问题建立在小数据集之上，其他人已经完成了大量的网络架构的手工工程。一个神经网络在某个计算机视觉问题上很有效，但令人惊讶的是它通常也会解决其他计算机视觉问题。 所以，要想建立一个实用的系统，你最好先从其他人的神经网络架构入手。如果可能的话，你可以使用开源的一些应用，因为开放的源码实现可能已经找到了所有繁琐的细节，比如学习率衰减方式或者超参数。 最后，其他人可能已经在几路GPU上花了几个星期的时间来训练一个模型，训练超过一百万张图片，所以通过使用其他人的预先训练得模型，然后在数据集上进行微调，你可以在应用程序上运行得更快。当然如果你有电脑资源并且有意愿，我不会阻止你从头开始训练你自己的网络。事实上，如果你想发明你自己的计算机视觉算法，这可能是你必须要做的。 这就是本周的学习，我希望看到大量的计算机视觉架构能够帮助你理解什么是有效的。在本周的编程练习中，你实际上会学习另一种编程框架，并使用它来实现ResNets。所以我希望你们喜欢这个编程练习，我期待下周还能见到你们。 目标检测（Object detection）3.1 目标定位（Object localization）大家好，欢迎回来，这一周我们学习的主要内容是对象检测，它是计算机视觉领域中一个新兴的应用方向，相比前两年，它的性能越来越好。在构建对象检测之前，我们先了解一下对象定位，首先我们看看它的定义。 图片分类任务我们已经熟悉了，就是算法遍历图片，判断其中的对象是不是汽车，这就是图片分类。这节课我们要学习构建神经网络的另一个问题，即定位分类问题。这意味着，我们不仅要用算法判断图片中是不是一辆汽车，还要在图片中标记出它的位置，用边框或红色方框把汽车圈起来，这就是定位分类问题。其中“定位”的意思是判断汽车在图片中的具体位置。这周后面几天，我们再讲讲当图片中有多个对象时，应该如何检测它们，并确定出位置。比如，你正在做一个自动驾驶程序，程序不但要检测其它车辆，还要检测其它对象，如行人、摩托车等等，稍后我们再详细讲。 本周我们要研究的分类定位问题，通常只有一个较大的对象位于图片中间位置，我们要对它进行识别和定位。而在对象检测问题中，图片可以含有多个对象，甚至单张图片中会有多个不同分类的对象。因此，图片分类的思路可以帮助学习分类定位，而对象定位的思路又有助于学习对象检测，我们先从分类和定位开始讲起。 图片分类问题你已经并不陌生了，例如，输入一张图片到多层卷积神经网络。这就是卷积神经网络，它会输出一个特征向量，并反馈给softmax单元来预测图片类型。 如果你正在构建汽车自动驾驶系统，那么对象可能包括以下几类：行人、汽车、摩托车和背景，这意味着图片中不含有前三种对象，也就是说图片中没有行人、汽车和摩托车，输出结果会是背景对象，这四个分类就是softmax函数可能输出的结果。 这就是标准的分类过程，如果你还想定位图片中汽车的位置，该怎么做呢？我们可以让神经网络多输出几个单元，输出一个边界框。具体说就是让神经网络再多输出4个数字，标记为$b_{x}$,$b_{y}$,$b_{h}$和$b_{w}$，这四个数字是被检测对象的边界框的参数化表示。 我们先来约定本周课程将使用的符号表示，图片左上角的坐标为$(0,0)$，右下角标记为$(1,1)$。要确定边界框的具体位置，需要指定红色方框的中心点，这个点表示为($b_{x}$,$b_{y}$)，边界框的高度为$b_{h}$，宽度为$b_{w}$。因此训练集不仅包含神经网络要预测的对象分类标签，还要包含表示边界框的这四个数字，接着采用监督学习算法，输出一个分类标签，还有四个参数值，从而给出检测对象的边框位置。此例中，$b_{x}$的理想值是0.5，因为它表示汽车位于图片水平方向的中间位置；$b_{y}$大约是0.7，表示汽车位于距离图片底部$\frac{3}{10}$的位置；$b_{h}$约为0.3，因为红色方框的高度是图片高度的0.3倍；$b_{w}$约为0.4，红色方框的宽度是图片宽度的0.4倍。 下面我再具体讲讲如何为监督学习任务定义目标标签 $y$。 请注意，这有四个分类，神经网络输出的是这四个数字和一个分类标签，或分类标签出现的概率。目标标签$y$的定义如下：$y= \ \begin{bmatrix} p_{c} \\ b_{x} \\ b_{y} \\ b_{h} \\ b_{w} \\ c_{1} \\ c_{2}\\ c_{3} \\\end{bmatrix}$ 它是一个向量，第一个组件$p_{c}$表示是否含有对象，如果对象属于前三类（行人、汽车、摩托车），则$p_{c}= 1$，如果是背景，则图片中没有要检测的对象，则$p_{c} =0$。我们可以这样理解$p_{c}$，它表示被检测对象属于某一分类的概率，背景分类除外。 如果检测到对象，就输出被检测对象的边界框参数$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$。最后，如果存在某个对象，那么$p_{c}=1$，同时输出$c_{1}$、$c_{2}$和$c_{3}$，表示该对象属于1-3类中的哪一类，是行人，汽车还是摩托车。鉴于我们所要处理的问题，我们假设图片中只含有一个对象，所以针对这个分类定位问题，图片最多只会出现其中一个对象。 我们再看几个样本，假如这是一张训练集图片，标记为$x$，即上图的汽车图片。而在$y$当中，第一个元素$p_{c} =1$，因为图中有一辆车，$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$会指明边界框的位置，所以标签训练集需要标签的边界框。图片中是一辆车，所以结果属于分类2，因为定位目标不是行人或摩托车，而是汽车，所以$c_{1}= 0$，$c_{2} = 1$，$c_{3} =0$，$c_{1}$、$c_{2}$和$c_{3}$中最多只有一个等于1。 这是图片中只有一个检测对象的情况，如果图片中没有检测对象呢？如果训练样本是这样一张图片呢？ 这种情况下，$p_{c} =0$，$y$的其它参数将变得毫无意义，这里我全部写成问号，表示“毫无意义”的参数，因为图片中不存在检测对象，所以不用考虑网络输出中边界框的大小，也不用考虑图片中的对象是属于$c_{1}$、$c_{2}$和$c_{3}$中的哪一类。针对给定的被标记的训练样本，不论图片中是否含有定位对象，构建输入图片$x$和分类标签$y$的具体过程都是如此。这些数据最终定义了训练集。 最后，我们介绍一下神经网络的损失函数，其参数为类别$y$和网络输出$\hat{y}$，如果采用平方误差策略，则$L\left(\hat{y},y \right) = \left( \hat{y_1} - y_{1} \right)^{2} + \left(\hat{y_2} - y_{2}\right)^{2} + \ldots\left( \hat{y_8} - y_{8}\right)^{2}$，损失值等于每个元素相应差值的平方和。 如果图片中存在定位对象，那么$y_{1} = 1$，所以$y_{1} =p_{c}$，同样地，如果图片中存在定位对象，$p_{c} =1$，损失值就是不同元素的平方和。 另一种情况是，$y_{1} = 0$，也就是$p_{c} = 0$，损失值是$\left(\hat{y_1} - y_{1}\right)^{2}$，因为对于这种情况，我们不用考虑其它元素，只需要关注神经网络输出$p_{c}$的准确度。 回顾一下，当$y_{1} =1$时，也就是这种情况（编号1），平方误差策略可以减少这8个元素预测值和实际输出结果之间差值的平方。如果$y_{1}=0$，$y$ 矩阵中的后7个元素都不用考虑（编号2），只需要考虑神经网络评估$y_{1}$（即$p_{c}$）的准确度。 为了让大家了解对象定位的细节，这里我用平方误差简化了描述过程。实际应用中，你可以不对$c_{1}$、$c_{2}$、$c_{3}$和softmax激活函数应用对数损失函数，并输出其中一个元素值，通常做法是对边界框坐标应用平方差或类似方法，对$p_{c}$应用逻辑回归函数，甚至采用平方预测误差也是可以的。 以上就是利用神经网络解决对象分类和定位问题的详细过程，结果证明，利用神经网络输出批量实数来识别图片中的对象是个非常有用的算法。下节课，我想和大家分享另一种思路，就是把神经网络输出的实数集作为一个回归任务，这个思想也被应用于计算机视觉的其它领域，也是非常有效的，所以下节课见。 3.2 特征点检测（Landmark detection）上节课，我们讲了如何利用神经网络进行对象定位，即通过输出四个参数值$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$给出图片中对象的边界框。更概括地说，神经网络可以通过输出图片上特征点的$(x,y)$坐标来实现对目标特征的识别，我们看几个例子。 假设你正在构建一个人脸识别应用，出于某种原因，你希望算法可以给出眼角的具体位置。眼角坐标为$(x,y)$，你可以让神经网络的最后一层多输出两个数字$l_{x}$和$l_{y}$，作为眼角的坐标值。如果你想知道两只眼睛的四个眼角的具体位置，那么从左到右，依次用四个特征点来表示这四个眼角。对神经网络稍做些修改，输出第一个特征点（$l_{1x}$，$l_{1y}$），第二个特征点（$l_{2x}$，$l_{2y}$），依此类推，这四个脸部特征点的位置就可以通过神经网络输出了。 也许除了这四个特征点，你还想得到更多的特征点输出值，这些（图中眼眶上的红色特征点）都是眼睛的特征点，你还可以根据嘴部的关键点输出值来确定嘴的形状，从而判断人物是在微笑还是皱眉，也可以提取鼻子周围的关键特征点。为了便于说明，你可以设定特征点的个数，假设脸部有64个特征点，有些点甚至可以帮助你定义脸部轮廓或下颌轮廓。选定特征点个数，并生成包含这些特征点的标签训练集，然后利用神经网络输出脸部关键特征点的位置。 具体做法是，准备一个卷积网络和一些特征集，将人脸图片输入卷积网络，输出1或0，1表示有人脸，0表示没有人脸，然后输出（$l_{1x}$，$l_{1y}$）……直到（$l_{64x}$，$l_{64y}$）。这里我用$l$代表一个特征，这里有129个输出单元，其中1表示图片中有人脸，因为有64个特征，64×2=128，所以最终输出128+1=129个单元，由此实现对图片的人脸检测和定位。这只是一个识别脸部表情的基本构造模块，如果你玩过Snapchat或其它娱乐类应用，你应该对AR（增强现实）过滤器多少有些了解，Snapchat过滤器实现了在脸上画皇冠和其他一些特殊效果。检测脸部特征也是计算机图形效果的一个关键构造模块，比如实现脸部扭曲，头戴皇冠等等。当然为了构建这样的网络，你需要准备一个标签训练集，也就是图片$x$和标签$y$的集合，这些点都是人为辛苦标注的。 最后一个例子，如果你对人体姿态检测感兴趣，你还可以定义一些关键特征点，如胸部的中点，左肩，左肘，腰等等。然后通过神经网络标注人物姿态的关键特征点，再输出这些标注过的特征点，就相当于输出了人物的姿态动作。当然，要实现这个功能，你需要设定这些关键特征点，从胸部中心点($l_{1x}$，$l_{1y}$)一直往下，直到($l_{32x}$，$l_{32y}$)。 一旦了解如何用二维坐标系定义人物姿态，操作起来就相当简单了，批量添加输出单元，用以输出要识别的各个特征点的$(x,y)$坐标值。要明确一点，特征点1的特性在所有图片中必须保持一致，就好比，特征点1始终是右眼的外眼角，特征点2是右眼的内眼角，特征点3是左眼内眼角，特征点4是左眼外眼角等等。所以标签在所有图片中必须保持一致，假如你雇用他人或自己标记了一个足够大的数据集，那么神经网络便可以输出上述所有特征点，你可以利用它们实现其他有趣的效果，比如判断人物的动作姿态，识别图片中的人物表情等等。 以上就是特征点检测的内容，下节课我们将利用这些构造模块来构建对象检测算法。 3.3 目标检测（Object detection）学过了对象定位和特征点检测，今天我们来构建一个对象检测算法。这节课，我们将学习如何通过卷积网络进行对象检测，采用的是基于滑动窗口的目标检测算法。 假如你想构建一个汽车检测算法，步骤是，首先创建一个标签训练集，也就是$x$和$y$表示适当剪切的汽车图片样本，这张图片（编号1）$x$是一个正样本，因为它是一辆汽车图片，这几张图片（编号2、3）也有汽车，但这两张（编号4、5）没有汽车。出于我们对这个训练集的期望，你一开始可以使用适当剪切的图片，就是整张图片$x$几乎都被汽车占据，你可以照张照片，然后剪切，剪掉汽车以外的部分，使汽车居于中间位置，并基本占据整张图片。有了这个标签训练集，你就可以开始训练卷积网络了，输入这些适当剪切过的图片（编号6），卷积网络输出$y$，0或1表示图片中有汽车或没有汽车。训练完这个卷积网络，就可以用它来实现滑动窗口目标检测，具体步骤如下。 假设这是一张测试图片，首先选定一个特定大小的窗口，比如图片下方这个窗口，将这个红色小方块输入卷积神经网络，卷积网络开始进行预测，即判断红色方框内有没有汽车。 滑动窗口目标检测算法接下来会继续处理第二个图像，即红色方框稍向右滑动之后的区域，并输入给卷积网络，因此输入给卷积网络的只有红色方框内的区域，再次运行卷积网络，然后处理第三个图像，依次重复操作，直到这个窗口滑过图像的每一个角落。 为了滑动得更快，我这里选用的步幅比较大，思路是以固定步幅移动窗口，遍历图像的每个区域，把这些剪切后的小图像输入卷积网络，对每个位置按0或1进行分类，这就是所谓的图像滑动窗口操作。 重复上述操作，不过这次我们选择一个更大的窗口，截取更大的区域，并输入给卷积神经网络处理，你可以根据卷积网络对输入大小调整这个区域，然后输入给卷积网络，输出0或1。 再以某个固定步幅滑动窗口，重复以上操作，遍历整个图像，输出结果。 然后第三次重复操作，这次选用更大的窗口。 如果你这样做，不论汽车在图片的什么位置，总有一个窗口可以检测到它。 比如，将这个窗口（编号1）输入卷积网络，希望卷积网络对该输入区域的输出结果为1，说明网络检测到图上有辆车。 这种算法叫作滑动窗口目标检测，因为我们以某个步幅滑动这些方框窗口遍历整张图片，对这些方形区域进行分类，判断里面有没有汽车。 滑动窗口目标检测算法也有很明显的缺点，就是计算成本，因为你在图片中剪切出太多小方块，卷积网络要一个个地处理。如果你选用的步幅很大，显然会减少输入卷积网络的窗口个数，但是粗糙间隔尺寸可能会影响性能。反之，如果采用小粒度或小步幅，传递给卷积网络的小窗口会特别多，这意味着超高的计算成本。 所以在神经网络兴起之前，人们通常采用更简单的分类器进行对象检测，比如通过采用手工处理工程特征的简单的线性分类器来执行对象检测。至于误差，因为每个分类器的计算成本都很低，它只是一个线性函数，所以滑动窗口目标检测算法表现良好，是个不错的算法。然而，卷积网络运行单个分类人物的成本却高得多，像这样滑动窗口太慢。除非采用超细粒度或极小步幅，否则无法准确定位图片中的对象。 不过，庆幸的是，计算成本问题已经有了很好的解决方案，大大提高了卷积层上应用滑动窗口目标检测器的效率，关于它的具体实现，我们下节课再讲。 3.4 滑动窗口的卷积实现（Convolutional implementation of sliding windows）上节课，我们学习了如何通过卷积网络实现滑动窗口对象检测算法，但效率很低。这节课我们讲讲如何在卷积层上应用这个算法。 为了构建滑动窗口的卷积应用，首先要知道如何把神经网络的全连接层转化成卷积层。我们先讲解这部分内容，下一张幻灯片，我们将按照这个思路来演示卷积的应用过程。 假设对象检测算法输入一个14×14×3的图像，图像很小，不过演示起来方便。在这里过滤器大小为5×5，数量是16，14×14×3的图像在过滤器处理之后映射为10×10×16。然后通过参数为2×2的最大池化操作，图像减小到5×5×16。然后添加一个连接400个单元的全连接层，接着再添加一个全连接层，最后通过softmax单元输出$y$。为了跟下图区分开，我先做一点改动，用4个数字来表示$y$，它们分别对应softmax单元所输出的4个分类出现的概率。这4个分类可以是行人、汽车、摩托车和背景或其它对象。 现在我要演示的就是如何把这些全连接层转化为卷积层，画一个这样的卷积网络，它的前几层和之前的一样，而对于下一层，也就是这个全连接层，我们可以用5×5的过滤器来实现，数量是400个（编号1所示），输入图像大小为5×5×16，用5×5的过滤器对它进行卷积操作，过滤器实际上是5×5×16，因为在卷积过程中，过滤器会遍历这16个通道，所以这两处的通道数量必须保持一致，输出结果为1×1。假设应用400个这样的5×5×16过滤器，输出维度就是1×1×400，我们不再把它看作一个含有400个节点的集合，而是一个1×1×400的输出层。从数学角度看，它和全连接层是一样的，因为这400个节点中每个节点都有一个5×5×16维度的过滤器，所以每个值都是上一层这些5×5×16激活值经过某个任意线性函数的输出结果。 我们再添加另外一个卷积层（编号2所示），这里用的是1×1卷积，假设有400个1×1的过滤器，在这400个过滤器的作用下，下一层的维度是1×1×400，它其实就是上个网络中的这一全连接层。最后经由1×1过滤器的处理，得到一个softmax激活值，通过卷积网络，我们最终得到这个1×1×4的输出层，而不是这4个数字（编号3所示）。 以上就是用卷积层代替全连接层的过程，结果这几个单元集变成了1×1×400和1×1×4的维度。 参考论文：Sermanet, Pierre, et al. “OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks.” Eprint Arxiv (2013). 掌握了卷积知识，我们再看看如何通过卷积实现滑动窗口对象检测算法。讲义中的内容借鉴了屏幕下方这篇关于OverFeat的论文，它的作者包括Pierre Sermanet，David Eigen，张翔，Michael Mathieu，Rob Fergus，Yann LeCun。 假设向滑动窗口卷积网络输入14×14×3的图片，为了简化演示和计算过程，这里我们依然用14×14的小图片。和前面一样，神经网络最后的输出层，即softmax单元的输出是1×1×4，我画得比较简单，严格来说，14×14×3应该是一个长方体，第二个10×10×16也是一个长方体，但为了方便，我只画了正面。所以，对于1×1×400的这个输出层，我也只画了它1×1的那一面，所以这里显示的都是平面图，而不是3D图像。 假设输入给卷积网络的图片大小是14×14×3，测试集图片是16×16×3，现在给这个输入图片加上黄色条块，在最初的滑动窗口算法中，你会把这片蓝色区域输入卷积网络（红色笔标记）生成0或1分类。接着滑动窗口，步幅为2个像素，向右滑动2个像素，将这个绿框区域输入给卷积网络，运行整个卷积网络，得到另外一个标签0或1。继续将这个橘色区域输入给卷积网络，卷积后得到另一个标签，最后对右下方的紫色区域进行最后一次卷积操作。我们在这个16×16×3的小图像上滑动窗口，卷积网络运行了4次，于是输出了了4个标签。 结果发现，这4次卷积操作中很多计算都是重复的。所以执行滑动窗口的卷积时使得卷积网络在这4次前向传播过程中共享很多计算，尤其是在这一步操作中（编号1），卷积网络运行同样的参数，使得相同的5×5×16过滤器进行卷积操作，得到12×12×16的输出层。然后执行同样的最大池化（编号2），输出结果6×6×16。照旧应用400个5×5的过滤器（编号3），得到一个2×2×400的输出层，现在输出层为2×2×400，而不是1×1×400。应用1×1过滤器（编号4）得到另一个2×2×400的输出层。再做一次全连接的操作（编号5），最终得到2×2×4的输出层，而不是1×1×4。最终，在输出层这4个子方块中，蓝色的是图像左上部分14×14的输出（红色箭头标识），右上角方块是图像右上部分（绿色箭头标识）的对应输出，左下角方块是输入层左下角（橘色箭头标识），也就是这个14×14区域经过卷积网络处理后的结果，同样，右下角这个方块是卷积网络处理输入层右下角14×14区域(紫色箭头标识)的结果。 如果你想了解具体的计算步骤，以绿色方块为例，假设你剪切出这块区域（编号1），传递给卷积网络，第一层的激活值就是这块区域（编号2），最大池化后的下一层的激活值是这块区域（编号3），这块区域对应着后面几层输出的右上角方块（编号4，5，6）。 所以该卷积操作的原理是我们不需要把输入图像分割成四个子集，分别执行前向传播，而是把它们作为一张图片输入给卷积网络进行计算，其中的公共区域可以共享很多计算，就像这里我们看到的这个4个14×14的方块一样。 下面我们再看一个更大的图片样本，假如对一个28×28×3的图片应用滑动窗口操作，如果以同样的方式运行前向传播，最后得到8×8×4的结果。跟上一个范例一样，以14×14区域滑动窗口，首先在这个区域应用滑动窗口，其结果对应输出层的左上角部分。接着以大小为2的步幅不断地向右移动窗口，直到第8个单元格，得到输出层的第一行。然后向图片下方移动，最终输出这个8×8×4的结果。因为最大池化参数为2，相当于以大小为2的步幅在原始图片上应用神经网络。 总结一下滑动窗口的实现过程，在图片上剪切出一块区域，假设它的大小是14×14，把它输入到卷积网络。继续输入下一块区域，大小同样是14×14，重复操作，直到某个区域识别到汽车。 但是正如在前一页所看到的，我们不能依靠连续的卷积操作来识别图片中的汽车，比如，我们可以对大小为28×28的整张图片进行卷积操作，一次得到所有预测值，如果足够幸运，神经网络便可以识别出汽车的位置。 以上就是在卷积层上应用滑动窗口算法的内容，它提高了整个算法的效率。不过这种算法仍然存在一个缺点，就是边界框的位置可能不够准确。下节课，我们将学习如何解决这个问题。 3.5 Bounding Box预测（Bounding box predictions）在上一个视频中，你们学到了滑动窗口法的卷积实现，这个算法效率更高，但仍然存在问题，不能输出最精准的边界框。在这个视频中，我们看看如何得到更精准的边界框。 在滑动窗口法中，你取这些离散的位置集合，然后在它们上运行分类器，在这种情况下，这些边界框没有一个能完美匹配汽车位置，也许这个框（编号1）是最匹配的了。还有看起来这个真实值，最完美的边界框甚至不是方形，稍微有点长方形（红色方框所示），长宽比有点向水平方向延伸，有没有办法让这个算法输出更精准的边界框呢？ 其中一个能得到更精准边界框的算法是YOLO算法，YOLO(You only look once)意思是你只看一次，这是由Joseph Redmon，Santosh Divvala，Ross Girshick和Ali Farhadi提出的算法。 是这么做的，比如你的输入图像是100×100的，然后在图像上放一个网格。为了介绍起来简单一些，我用3×3网格，实际实现时会用更精细的网格，可能是19×19。基本思路是使用图像分类和定位算法，前几个视频介绍过的，然后将算法应用到9个格子上。（基本思路是，采用图像分类和定位算法，本周第一个视频中介绍过的，逐一应用在图像的9个格子中。）更具体一点，你需要这样定义训练标签，所以对于9个格子中的每一个指定一个标签$y$，$y$是8维的，和你之前看到的一样，$y= \ \begin{bmatrix} p_{c} \\ b_{x} \\ b_{y} \\ b_{h} \\ b_{w} \\ c_{1} \\ c_{2}\\ c_{3} \\\end{bmatrix}$，$p_{c}$等于0或1取决于这个绿色格子中是否有图像。然后$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$作用就是，如果那个格子里有对象，那么就给出边界框坐标。然后$c_{1}$、$c_{2}$和$c_{3}$就是你想要识别的三个类别，背景类别不算，所以你尝试在背景类别中识别行人、汽车和摩托车，那么$c_{1}$、$c_{2}$和$c_{3}$可以是行人、汽车和摩托车类别。这张图里有9个格子，所以对于每个格子都有这么一个向量。 我们看看左上方格子，这里这个（编号1），里面什么也没有，所以左上格子的标签向量$y$是$\begin{bmatrix}0 \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \\\end{bmatrix}$。然后这个格子（编号2）的输出标签$y$也是一样，这个格子（编号3），还有其他什么也没有的格子都一样。 现在这个格子呢？讲的更具体一点，这张图有两个对象，YOLO算法做的就是，取两个对象的中点，然后将这个对象分配给包含对象中点的格子。所以左边的汽车就分配到这个格子上（编号4），然后这辆Condor（车型：神鹰）中点在这里，分配给这个格子（编号6）。所以即使中心格子（编号5）同时有两辆车的一部分，我们就假装中心格子没有任何我们感兴趣的对象，所以对于中心格子，分类标签$y$和这个向量类似，和这个没有对象的向量类似，即$y= \ \begin{bmatrix} 0 \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \\\end{bmatrix}$。而对于这个格子，这个用绿色框起来的格子（编号4），目标标签就是这样的，这里有一个对象，$p_{c}=1$，然后你写出$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$来指定边界框位置，然后还有类别1是行人，那么$c_{1}= 0$，类别2是汽车，所以$c_{2} = 1$，类别3是摩托车，则数值$c_{3} = 0$，即$y= \begin{bmatrix} 1 \\ b_{x} \\ b_{y} \\ b_{h} \\ b_{w} \\ 0 \\ 1 \\0 \\\end{bmatrix}$。右边这个格子（编号6）也是类似的，因为这里确实有一个对象，它的向量应该是这个样子的，$y=\begin{bmatrix} 1 \\ b_{x} \\ b_{y} \\ b_{h} \\ b_{w} \\ 0 \\ 1 \\0 \\ \end{bmatrix}$作为目标向量对应右边的格子。 所以对于这里9个格子中任何一个，你都会得到一个8维输出向量，因为这里是3×3的网格，所以有9个格子，总的输出尺寸是3×3×8，所以目标输出是3×3×8。因为这里有3×3格子，然后对于每个格子，你都有一个8维向量$y$，所以目标输出尺寸是3×3×8。 对于这个例子中，左上格子是1×1×8，对应的是9个格子中左上格子的输出向量。所以对于这3×3中每一个位置而言，对于这9个格子，每个都对应一个8维输出目标向量$y$，其中一些值可以是dont care-s（即？），如果这里没有对象的话。所以总的目标输出，这个图片的输出标签尺寸就是3×3×8。 如果你现在要训练一个输入为100×100×3的神经网络，现在这是输入图像，然后你有一个普通的卷积网络，卷积层，最大池化层等等，最后你会有这个，选择卷积层和最大池化层，这样最后就映射到一个3×3×8输出尺寸。所以你要做的是，有一个输入$x$，就是这样的输入图像，然后你有这些3×3×8的目标标签$y$。当你用反向传播训练神经网络时，将任意输入$x$映射到这类输出向量$y$。 所以这个算法的优点在于神经网络可以输出精确的边界框，所以测试的时候，你做的是喂入输入图像$x$，然后跑正向传播，直到你得到这个输出$y$。然后对于这里3×3位置对应的9个输出，我们在输出中展示过的，你就可以读出1或0（编号1位置），你就知道9个位置之一有个对象。如果那里有个对象，那个对象是什么（编号3位置），还有格子中这个对象的边界框是什么（编号2位置）。只要每个格子中对象数目没有超过1个，这个算法应该是没问题的。一个格子中存在多个对象的问题，我们稍后再讨论。但实践中，我们这里用的是比较小的3×3网格，实践中你可能会使用更精细的19×19网格，所以输出就是19×19×8。这样的网格精细得多，那么多个对象分配到同一个格子得概率就小得多。 重申一下，把对象分配到一个格子的过程是，你观察对象的中点，然后将这个对象分配到其中点所在的格子，所以即使对象可以横跨多个格子，也只会被分配到9个格子其中之一，就是3×3网络的其中一个格子，或者19×19网络的其中一个格子。在19×19网格中，两个对象的中点（图中蓝色点所示）处于同一个格子的概率就会更低。 所以要注意，首先这和图像分类和定位算法非常像，我们在本周第一节课讲过的，就是它显式地输出边界框坐标，所以这能让神经网络输出边界框，可以具有任意宽高比，并且能输出更精确的坐标，不会受到滑动窗口分类器的步长大小限制。其次，这是一个卷积实现，你并没有在3×3网格上跑9次算法，或者，如果你用的是19×19的网格，19平方是361次，所以你不需要让同一个算法跑361次。相反，这是单次卷积实现，但你使用了一个卷积网络，有很多共享计算步骤，在处理这3×3计算中很多计算步骤是共享的，或者你的19×19的网格，所以这个算法效率很高。 事实上YOLO算法有一个好处，也是它受欢迎的原因，因为这是一个卷积实现，实际上它的运行速度非常快，可以达到实时识别。在结束之前我还想给你们分享一个小细节，如何编码这些边界框$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$，我们在下一张幻灯片上讨论。 这里有两辆车，我们有个3×3网格，我们以右边的车为例（编号1），红色格子里有个对象，所以目标标签$y$就是，$p_{c}= 1$，然后$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$，然后$c_{1} =0$，$c_{2} = 1$，$c_{3} = 0$，即$y = \begin{bmatrix} 1 \\ b_{x}\\ b_{y} \\ b_{h} \\ b_{w} \\ 0 \\ 1 \\ 0 \\\end{bmatrix}$。你怎么指定这个边界框呢？ Specify the bounding boxes： 在YOLO算法中，对于这个方框（编号1所示），我们约定左上这个点是$(0,0)$，然后右下这个点是$(1,1)$,要指定橙色中点的位置，$b_{x}$大概是0.4，因为它的位置大概是水平长度的0.4，然后$b_{y}$大概是0.3，然后边界框的高度用格子总体宽度的比例表示，所以这个红框的宽度可能是蓝线（编号2所示的蓝线）的90%，所以$b_{h}$是0.9，它的高度也许是格子总体高度的一半，这样的话$b_{w}$就是0.5。换句话说，$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$单位是相对于格子尺寸的比例，所以$b_{x}$和$b_{y}$必须在0和1之间，因为从定义上看，橙色点位于对象分配到格子的范围内，如果它不在0和1之间，如果它在方块外，那么这个对象就应该分配到另一个格子上。这个值（$b_{h}$和$b_{w}$）可能会大于1，特别是如果有一辆汽车的边界框是这样的（编号3所示），那么边界框的宽度和高度有可能大于1。 指定边界框的方式有很多，但这种约定是比较合理的，如果你去读YOLO的研究论文，YOLO的研究工作有其他参数化的方式，可能效果会更好，我这里就只给出了一个合理的约定，用起来应该没问题。不过还有其他更复杂的参数化方式，涉及到sigmoid函数，确保这个值（$b_{x}$和$b_{y}$）介于0和1之间，然后使用指数参数化来确保这些（$b_{h}$和$b_{w}$）都是非负数，因为0.9和0.5，这个必须大于等于0。还有其他更高级的参数化方式，可能效果要更好一点，但我这里讲的办法应该是管用的。 这就是YOLO算法，你只看一次算法，在接下来的几个视频中，我会告诉你一些其他的思路可以让这个算法做的更好。在此期间，如果你感兴趣，也可以看看YOLO的论文，在前几张幻灯片底部引用的YOLO论文。 Redmon, Joseph, et al. “You Only Look Once: Unified, Real-Time Object Detection.” (2015):779-788. 不过看这些论文之前，先给你们提个醒，YOLO论文是相对难度较高的论文之一，我记得我第一次读这篇论文的时候，我真的很难搞清楚到底是怎么实现的，我最后问了一些我认识的研究员，看看他们能不能给我讲清楚，即使是他们，也很难理解这篇论文的一些细节。所以如果你看论文的时候，发现看不懂，这是没问题的，我希望这种场合出现的概率要更低才好，但实际上，即使是资深研究员也有读不懂研究论文的时候，必须去读源代码，或者联系作者之类的才能弄清楚这些算法的细节。但你们不要被我吓到，你们可以自己看看这些论文，如果你们感兴趣的话，但这篇论文相对较难。现在你们了解了YOLO算法的基础，我们继续讨论别的让这个算法效果更好的研究。 3.6 交并比（Intersection over union）你如何判断对象检测算法运作良好呢？在本视频中，你将了解到并交比函数，可以用来评价对象检测算法。在下一个视频中，我们用它来插入一个分量来进一步改善检测算法，我们开始吧。 在对象检测任务中，你希望能够同时定位对象，所以如果实际边界框是这样的，你的算法给出这个紫色的边界框，那么这个结果是好还是坏？所以交并比（loU）函数做的是计算两个边界框交集和并集之比。两个边界框的并集是这个区域，就是属于包含两个边界框区域（绿色阴影表示区域），而交集就是这个比较小的区域（橙色阴影表示区域），那么交并比就是交集的大小，这个橙色阴影面积，然后除以绿色阴影的并集面积。 一般约定，在计算机检测任务中，如果$loU≥0.5$，就说检测正确，如果预测器和实际边界框完美重叠，loU就是1，因为交集就等于并集。但一般来说只要$loU≥0.5$，那么结果是可以接受的，看起来还可以。一般约定，0.5是阈值，用来判断预测的边界框是否正确。一般是这么约定，但如果你希望更严格一点，你可以将loU定得更高，比如说大于0.6或者更大的数字，但loU越高，边界框越精确。 所以这是衡量定位精确度的一种方式，你只需要统计算法正确检测和定位对象的次数，你就可以用这样的定义判断对象定位是否准确。再次，0.5是人为约定，没有特别深的理论依据，如果你想更严格一点，可以把阈值定为0.6。有时我看到更严格的标准，比如0.6甚至0.7，但很少见到有人将阈值降到0.5以下。 人们定义loU这个概念是为了评价你的对象定位算法是否精准，但更一般地说，loU衡量了两个边界框重叠地相对大小。如果你有两个边界框，你可以计算交集，计算并集，然后求两个数值的比值，所以这也可以判断两个边界框是否相似，我们将在下一个视频中再次用到这个函数，当我们讨论非最大值抑制时再次用到。 好，这就是loU，或者说交并比，不要和借据中提到的我欠你钱的这个概念所混淆，如果你借钱给别人，他们会写给你一个借据，说：“我欠你这么多钱（I own you this much money）。”，这也叫做loU。这是完全不同的概念，这两个概念重名。 现在介绍了loU交并比的定义之后，在下一个视频中，我想讨论非最大值抑制，这个工具可以让YOLO算法输出效果更好，我们下一个视频继续。 3.7 非极大值抑制（Non-max suppression）到目前为止你们学到的对象检测中的一个问题是，你的算法可能对同一个对象做出多次检测，所以算法不是对某个对象检测出一次，而是检测出多次。非极大值抑制这个方法可以确保你的算法对每个对象只检测一次，我们讲一个例子。 假设你需要在这张图片里检测行人和汽车，你可能会在上面放个19×19网格，理论上这辆车只有一个中点，所以它应该只被分配到一个格子里，左边的车子也只有一个中点，所以理论上应该只有一个格子做出有车的预测。 实践中当你运行对象分类和定位算法时，对于每个格子都运行一次，所以这个格子（编号1）可能会认为这辆车中点应该在格子内部，这几个格子（编号2、3）也会这么认为。对于左边的车子也一样，所以不仅仅是这个格子，如果这是你们以前见过的图像，不仅这个格（编号4）子会认为它里面有车，也许这个格子（编号5）和这个格子（编号6）也会，也许其他格子也会这么认为，觉得它们格子内有车。 我们分步介绍一下非极大抑制是怎么起效的，因为你要在361个格子上都运行一次图像检测和定位算法，那么可能很多格子都会举手说我的$p_{c}$，我这个格子里有车的概率很高，而不是361个格子中仅有两个格子会报告它们检测出一个对象。所以当你运行算法的时候，最后可能会对同一个对象做出多次检测，所以非极大值抑制做的就是清理这些检测结果。这样一辆车只检测一次，而不是每辆车都触发多次检测。 所以具体上，这个算法做的是，首先看看每次报告每个检测结果相关的概率$p_{c}$，在本周的编程练习中有更多细节，实际上是$p_{c}$乘以$c_{1}$、$c_{2}$或$c_{3}$。现在我们就说，这个$p_{c}$检测概率，首先看概率最大的那个，这个例子（右边车辆）中是0.9，然后就说这是最可靠的检测，所以我们就用高亮标记，就说我这里找到了一辆车。这么做之后，非极大值抑制就会逐一审视剩下的矩形，所有和这个最大的边框有很高交并比，高度重叠的其他边界框，那么这些输出就会被抑制。所以这两个矩形$p_{c}$分别是0.6和0.7，这两个矩形和淡蓝色矩形重叠程度很高，所以会被抑制，变暗，表示它们被抑制了。 接下来，逐一审视剩下的矩形，找出概率最高，$p_{c}$最高的一个，在这种情况下是0.8，我们就认为这里检测出一辆车（左边车辆），然后非极大值抑制算法就会去掉其他loU值很高的矩形。所以现在每个矩形都会被高亮显示或者变暗，如果你直接抛弃变暗的矩形，那就剩下高亮显示的那些，这就是最后得到的两个预测结果。 所以这就是非极大值抑制，非最大值意味着你只输出概率最大的分类结果，但抑制很接近，但不是最大的其他预测结果，所以这方法叫做非极大值抑制。 我们来看看算法的细节，首先这个19×19网格上执行一下算法，你会得到19×19×8的输出尺寸。不过对于这个例子来说，我们简化一下，就说你只做汽车检测，我们就去掉$c_{1}$、$c_{2}$和$c_{3}$，然后假设这条线对于19×19的每一个输出，对于361个格子的每个输出，你会得到这样的输出预测，就是格子中有对象的概率（$p_{c}$），然后是边界框参数（$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$）。如果你只检测一种对象，那么就没有$c_{1}$、$c_{2}$和$c_{3}$这些预测分量。多个对象处于同一个格子中的情况，我会放到编程练习中，你们可以在本周末之前做做。 现在要实现非极大值抑制，你可以做的第一件事是，去掉所有边界框，我们就将所有的预测值，所有的边界框$p_{c}$小于或等于某个阈值，比如$p_{c}≤0.6$的边界框去掉。 我们就这样说，除非算法认为这里存在对象的概率至少有0.6，否则就抛弃，所以这就抛弃了所有概率比较低的输出边界框。所以思路是对于这361个位置，你输出一个边界框，还有那个最好边界框所对应的概率，所以我们只是抛弃所有低概率的边界框。 接下来剩下的边界框，没有抛弃没有处理过的，你就一直选择概率$p_{c}$最高的边界框，然后把它输出成预测结果，这个过程就是上一张幻灯片，取一个边界框，让它高亮显示，这样你就可以确定输出做出有一辆车的预测。 接下来去掉所有剩下的边界框，任何没有达到输出标准的边界框，之前没有抛弃的边界框，把这些和输出边界框有高重叠面积和上一步输出边界框有很高交并比的边界框全部抛弃。所以while循环的第二步是上一张幻灯片变暗的那些边界框，和高亮标记的边界重叠面积很高的那些边界框抛弃掉。在还有剩下边界框的时候，一直这么做，把没处理的都处理完，直到每个边界框都判断过了，它们有的作为输出结果，剩下的会被抛弃，它们和输出结果重叠面积太高，和输出结果交并比太高，和你刚刚输出这里存在对象结果的重叠程度过高。 在这张幻灯片中，我只介绍了算法检测单个对象的情况，如果你尝试同时检测三个对象，比如说行人、汽车、摩托，那么输出向量就会有三个额外的分量。事实证明，正确的做法是独立进行三次非极大值抑制，对每个输出类别都做一次，但这个细节就留给本周的编程练习吧，其中你可以自己尝试实现，我们可以自己试试在多个对象类别检测时做非极大值抑制。 这就是非极大值抑制，如果你能实现我们说过的对象检测算法，你其实可以得到相当不错的结果。但结束我们对YOLO算法的介绍之前，最后我还有一个细节想给大家分享，可以进一步改善算法效果，就是anchor box的思路，我们下一个视频再介绍。 3.8 Anchor Boxes到目前为止，对象检测中存在的一个问题是每个格子只能检测出一个对象，如果你想让一个格子检测出多个对象，你可以这么做，就是使用anchor box这个概念，我们从一个例子开始讲吧。 假设你有这样一张图片，对于这个例子，我们继续使用3×3网格，注意行人的中点和汽车的中点几乎在同一个地方，两者都落入到同一个格子中。所以对于那个格子，如果 $y$ 输出这个向量$y= \ \begin{bmatrix} p_{c} \\ b_{x} \\ b_{y} \\ b_{h} \\ b_{w} \\ c_{1} \\ c_{2}\\ c_{3} \\\end{bmatrix}$，你可以检测这三个类别，行人、汽车和摩托车，它将无法输出检测结果，所以我必须从两个检测结果中选一个。 而anchor box的思路是，这样子，预先定义两个不同形状的anchor box，或者anchor box形状，你要做的是把预测结果和这两个anchor box关联起来。一般来说，你可能会用更多的anchor box，可能要5个甚至更多，但对于这个视频，我们就用两个anchor box，这样介绍起来简单一些。 你要做的是定义类别标签，用的向量不再是上面这个$\begin{bmatrix} p_{c} & b_{x} &b_{y} & b_{h} & b_{w} & c_{1} & c_{2} & c_{3} \\\end{bmatrix}^{T}$，而是重复两次，$y= \begin{bmatrix} p_{c} & b_{x} & b_{y} &b_{h} & b_{w} & c_{1} & c_{2} & c_{3} & p_{c} & b_{x} & b_{y} & b_{h} & b_{w} &c_{1} & c_{2} & c_{3} \\\end{bmatrix}^{T}$，前面的$p_{c},b_{x},b_{y},b_{h},b_{w},c_{1},c_{2},c_{3}$（绿色方框标记的参数）是和anchor box 1关联的8个参数，后面的8个参数（橙色方框标记的元素）是和anchor box 2相关联。因为行人的形状更类似于anchor box 1的形状，而不是anchor box 2的形状，所以你可以用这8个数值（前8个参数），这么编码$p_{c} =1$，是的，代表有个行人，用$b_{x},b_{y},b_{h}$和$b_{w}$来编码包住行人的边界框，然后用$c_{1},c_{2},c_{3}$($c_{1}= 1,c_{2} = 0,c_{3} = 0$)来说明这个对象是个行人。 然后是车子，因为车子的边界框比起anchor box 1更像anchor box 2的形状，你就可以这么编码，这里第二个对象是汽车，然后有这样的边界框等等，这里所有参数都和检测汽车相关($p_{c}= 1,b_{x},b_{y},b_{h},b_{w},c_{1} = 0,c_{2} = 1,c_{3} = 0$)。 总结一下，用anchor box之前，你做的是这个，对于训练集图像中的每个对象，都根据那个对象中点位置分配到对应的格子中，所以输出$y$就是3×3×8，因为是3×3网格，对于每个网格位置，我们有输出向量，包含$p_{c}$，然后边界框参数$b_{x},b_{y},b_{h}$和$b_{w}$，然后$c_{1},c_{2},c_{3}$。 现在用到anchor box这个概念，是这么做的。现在每个对象都和之前一样分配到同一个格子中，分配到对象中点所在的格子中，以及分配到和对象形状交并比最高的anchor box中。所以这里有两个anchor box，你就取这个对象，如果你的对象形状是这样的（编号1，红色框），你就看看这两个anchor box，anchor box 1形状是这样（编号2，紫色框），anchor box 2形状是这样（编号3，紫色框），然后你观察哪一个anchor box和实际边界框（编号1，红色框）的交并比更高，不管选的是哪一个，这个对象不只分配到一个格子，而是分配到一对，即（grid cell，anchor box）对，这就是对象在目标标签中的编码方式。所以现在输出 $y$ 就是3×3×16，上一张幻灯片中你们看到 $y$ 现在是16维的，或者你也可以看成是3×3×2×8，因为现在这里有2个anchor box，而 $y$ 是8维的。$y$ 维度是8，因为我们有3个对象类别，如果你有更多对象，那么$y$ 的维度会更高。 所以我们来看一个具体的例子，对于这个格子（编号2），我们定义一下$y$: $y =\begin{bmatrix} p_{c} & b_{x} & b_{y} & b_{h} & b_{w} & c_{1} & c_{2} & c_{3} &p_{c} & b_{x} & b_{y} & b_{h} & b_{w} & c_{1} & c_{2} & c_{3} \\\end{bmatrix}^{T}$。 所以行人更类似于anchor box 1的形状，所以对于行人来说，我们将她分配到向量的上半部分。是的，这里存在一个对象，即$p_{c}= 1$，有一个边界框包住行人，如果行人是类别1，那么 $c_{1} = 1,c_{2} = 0,c_{3} =0$（编号1所示的橙色参数）。车子的形状更像anchor box 2，所以这个向量剩下的部分是 $p_{c} = 1$，然后和车相关的边界框，然后$c_{1} = 0,c_{2} = 1,c_{3} =0$（编号1所示的绿色参数）。所以这就是对应中下格子的标签 $y$，这个箭头指向的格子（编号2所示）。 现在其中一个格子有车，没有行人，如果它里面只有一辆车，那么假设车子的边界框形状是这样，更像anchorbox 2，如果这里只有一辆车，行人走开了，那么anchor box 2分量还是一样的，要记住这是向量对应anchor box 2的分量和anchor box 1对应的向量分量，你要填的就是，里面没有任何对象，所以 $p_{c} =0$，然后剩下的就是don’t care-s(即？)（编号3所示）。 现在还有一些额外的细节，如果你有两个anchor box，但在同一个格子中有三个对象，这种情况算法处理不好，你希望这种情况不会发生，但如果真的发生了，这个算法并没有很好的处理办法，对于这种情况，我们就引入一些打破僵局的默认手段。还有这种情况，两个对象都分配到一个格子中，而且它们的anchor box形状也一样，这是算法处理不好的另一种情况，你需要引入一些打破僵局的默认手段，专门处理这种情况，希望你的数据集里不会出现这种情况，其实出现的情况不多，所以对性能的影响应该不会很大。 这就是anchor box的概念，我们建立anchor box这个概念，是为了处理两个对象出现在同一个格子的情况，实践中这种情况很少发生，特别是如果你用的是19×19网格而不是3×3的网格，两个对象中点处于361个格子中同一个格子的概率很低，确实会出现，但出现频率不高。也许设立anchor box的好处在于anchor box能让你的学习算法能够更有征对性，特别是如果你的数据集有一些很高很瘦的对象，比如说行人，还有像汽车这样很宽的对象，这样你的算法就能更有针对性的处理，这样有一些输出单元可以针对检测很宽很胖的对象，比如说车子，然后输出一些单元，可以针对检测很高很瘦的对象，比如说行人。 最后，你应该怎么选择anchor box呢？人们一般手工指定anchor box形状，你可以选择5到10个anchor box形状，覆盖到多种不同的形状，可以涵盖你想要检测的对象的各种形状。还有一个更高级的版本，我就简单说一句，你们如果接触过一些机器学习，可能知道后期YOLO论文中有更好的做法，就是所谓的k-平均算法，可以将两类对象形状聚类，如果我们用它来选择一组anchor box，选择最具有代表性的一组anchor box，可以代表你试图检测的十几个对象类别，但这其实是自动选择anchor box的高级方法。如果你就人工选择一些形状，合理的考虑到所有对象的形状，你预计会检测的很高很瘦或者很宽很胖的对象，这应该也不难做。 所以这就是anchor box，在下一个视频中，我们把学到的所有东西一起融入到YOLO算法中。 3.9 YOLO 算法（Putting it together: YOLO algorithm）你们已经学到对象检测算法的大部分组件了，在这个视频里，我们会把所有组件组装在一起构成YOLO对象检测算法。 我们先看看如何构造你的训练集，假设你要训练一个算法去检测三种对象，行人、汽车和摩托车，你还需要显式指定完整的背景类别。这里有3个类别标签，如果你要用两个anchor box，那么输出 $y$ 就是3×3×2×8，其中3×3表示3×3个网格，2是anchor box的数量，8是向量维度，8实际上先是5（$p_{c},b_{x},b_{y},b_{h},b_{w}$）再加上类别的数量（$c_{1},c_{2},c_{3}$）。你可以将它看成是3×3×2×8，或者3×3×16。要构造训练集，你需要遍历9个格子，然后构成对应的目标向量$y$。 所以先看看第一个格子（编号1），里面没什么有价值的东西，行人、车子和摩托车，三个类别都没有出现在左上格子中，所以对应那个格子目标$y$就是这样的，$y= \begin{bmatrix} 0 & ? & ? & ? & ? & ? & ? & ? & 0 & ? & ? & ? & ? & ? & ? & ?\\ \end{bmatrix}^{T}$，第一个anchor box的 $p_{c}$ 是0，因为没什么和第一个anchor box有关的，第二个anchor box的 $p_{c}$ 也是0，剩下这些值是don’t care-s。 现在网格中大多数格子都是空的，但那里的格子（编号2）会有这个目标向量$y$，$y =\begin{bmatrix} 0 & ? & ? & ? & ? & ? & ? & ? & 1 & b_{x} & b_{y} & b_{h} &b_{w} & 0 & 1 & 0 \\\end{bmatrix}^{T}$，所以假设你的训练集中，对于车子有这样一个边界框（编号3），水平方向更长一点。所以如果这是你的anchor box，这是anchor box 1（编号4），这是anchor box 2（编号5），然后红框和anchor box 2的交并比更高，那么车子就和向量的下半部分相关。要注意，这里和anchor box 1有关的 $p_{c}$ 是0，剩下这些分量都是don’t care-s，然后你的第二个 $p_{c} =1$，然后你要用这些（$b_{x},b_{y},b_{h},b_{w}$）来指定红边界框的位置，然后指定它的正确类别是2($c_{1}= 0 ,c_{2} = 1,c_{3} = 0$)，对吧，这是一辆汽车。 所以你这样遍历9个格子，遍历3×3网格的所有位置，你会得到这样一个向量，得到一个16维向量，所以最终输出尺寸就是3×3×16。和之前一样，简单起见，我在这里用的是3×3网格，实践中用的可能是19×19×16，或者需要用到更多的anchor box，可能是19×19×5×8，即19×19×40，用了5个anchor box。这就是训练集，然后你训练一个卷积网络，输入是图片，可能是100×100×3，然后你的卷积网络最后输出尺寸是，在我们例子中是3×3×16或者3×3×2×8。 接下来我们看看你的算法是怎样做出预测的，输入图像，你的神经网络的输出尺寸是这个3×3×2×8，对于9个格子，每个都有对应的向量。对于左上的格子（编号1），那里没有任何对象，那么我们希望你的神经网络在那里（第一个$p_{c}$）输出的是0，这里（第二个$p_{c}$）是0，然后我们输出一些值，你的神经网络不能输出问号，不能输出don’t care-s，剩下的我输入一些数字，但这些数字基本上会被忽略，因为神经网络告诉你，那里没有任何东西，所以输出是不是对应一个类别的边界框无关紧要，所以基本上是一组数字，多多少少都是噪音（输出 $y$ 如编号3所示）。 和这里的边界框不大一样，希望$y$的值，那个左下格子（编号2）的输出$y$（编号4所示），形式是，对于边界框1来说（$p_{c}$）是0，然后就是一组数字，就是噪音（anchor box 1对应行人，此格子中无行人，$p_{c} = 0,b_{x} = ?,b_{y} = ?,b_{h} = ?,b_{w} = ?,c_{1} = ?c_{2} = ?,c_{3} =?$）。希望你的算法能输出一些数字，可以对车子指定一个相当准确的边界框（anchor box 2对应汽车，此格子中有车，$ p_{c} = 1,b_{x},b_{y},b_{h},b_{w},c_{1} = 0,c_{2}= 1,c_{3} = 0$），这就是神经网络做出预测的过程。 最后你要运行一下这个非极大值抑制，为了让内容更有趣一些，我们看看一张新的测试图像，这就是运行非极大值抑制的过程。如果你使用两个anchor box，那么对于9个格子中任何一个都会有两个预测的边界框，其中一个的概率$p_{c}$很低。但9个格子中，每个都有两个预测的边界框，比如说我们得到的边界框是是这样的，注意有一些边界框可以超出所在格子的高度和宽度（编号1所示）。接下来你抛弃概率很低的预测，去掉这些连神经网络都说，这里很可能什么都没有，所以你需要抛弃这些（编号2所示）。 最后，如果你有三个对象检测类别，你希望检测行人，汽车和摩托车，那么你要做的是，对于每个类别单独运行非极大值抑制，处理预测结果所属类别的边界框，用非极大值抑制来处理行人类别，用非极大值抑制处理车子类别，然后对摩托车类别进行非极大值抑制，运行三次来得到最终的预测结果。所以算法的输出最好能够检测出图像里所有的车子，还有所有的行人（编号3所示）。 这就是YOLO对象检测算法，这实际上是最有效的对象检测算法之一，包含了整个计算机视觉对象检测领域文献中很多最精妙的思路。你可以在本周的编程作业中尝试现实这个算法，所以我希望你喜欢本周的编程练习，这里还有一个可选的视频，你们可以看，也可以不看，总之，我们下周见。 3.10 候选区域（选修）（Region proposals (Optional)）如果你们阅读一下对象检测的文献，可能会看到一组概念，所谓的候选区域，这在计算机视觉领域是非常有影响力的概念。我把这个视频定为可选视频是因为我用到候选区域这一系列算法的频率没有那么高，但当然了，这些工作是很有影响力的，你们在工作中也可能会碰到，我们来看看。 你们还记得滑动窗法吧，你使用训练过的分类器，在这些窗口中全部运行一遍，然后运行一个检测器，看看里面是否有车辆，行人和摩托车。现在你也可以运行一下卷积算法，这个算法的其中一个缺点是，它在显然没有任何对象的区域浪费时间，对吧。 所以这里这个矩形区域（编号1）基本是空的，显然没有什么需要分类的东西。也许算法会在这个矩形上（编号2）运行，而你知道上面没有什么有趣的东西。 [Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2014: 580-587.] 所以Ross Girshick，Jeff Donahue，Trevor Darrell，Jitendra Malik，在本幻灯片底部引用到的论文中提出一种叫做R-CNN的算法，意思是带区域的卷积网络，或者说带区域的CNN。这个算法尝试选出一些区域，在这些区域上运行卷积网络分类器是有意义的，所以这里不再针对每个滑动窗运行检测算法，而是只选择一些窗口，在少数窗口上运行卷积网络分类器。 选出候选区域的方法是运行图像分割算法，分割的结果是下边的图像，为了找出可能存在对象的区域。比如说，分割算法在这里得到一个色块，所以你可能会选择这样的边界框（编号1），然后在这个色块上运行分类器，就像这个绿色的东西（编号2），在这里找到一个色块，接下来我们还会在那个矩形上（编号2）运行一次分类器，看看有没有东西。在这种情况下，如果在蓝色色块上（编号3）运行分类器，希望你能检测出一个行人，如果你在青色色块(编号4)上运行算法，也许你可以发现一辆车，我也不确定。 所以这个细节就是所谓的分割算法，你先找出可能2000多个色块，然后在这2000个色块上放置边界框，然后在这2000个色块上运行分类器，这样需要处理的位置可能要少的多，可以减少卷积网络分类器运行时间，比在图像所有位置运行一遍分类器要快。特别是这种情况，现在不仅是在方形区域（编号5）中运行卷积网络，我们还会在高高瘦瘦（编号6）的区域运行，尝试检测出行人，然后我们在很宽很胖的区域（编号7）运行，尝试检测出车辆，同时在各种尺度运行分类器。 这就是R-CNN或者区域CNN的特色概念，现在看来R-CNN算法还是很慢的。所以有一系列的研究工作去改进这个算法，所以基本的R-CNN算法是使用某种算法求出候选区域，然后对每个候选区域运行一下分类器，每个区域会输出一个标签，有没有车子？有没有行人？有没有摩托车？并输出一个边界框，这样你就能在确实存在对象的区域得到一个精确的边界框。 澄清一下，R-CNN算法不会直接信任输入的边界框，它也会输出一个边界框$b_{x}$，$b_{y}$，$b_{h}$和$b_{w}$，这样得到的边界框比较精确，比单纯使用图像分割算法给出的色块边界要好，所以它可以得到相当精确的边界框。 现在R-CNN算法的一个缺点是太慢了，所以这些年来有一些对R-CNN算法的改进工作，Ross Girshik提出了快速的R-CNN算法，它基本上是R-CNN算法，不过用卷积实现了滑动窗法。最初的算法是逐一对区域分类的，所以快速R-CNN用的是滑动窗法的一个卷积实现，这和你在本周第四个视频（3.4 卷积的滑动窗口实现）中看到的大致相似，这显著提升了R-CNN的速度。 事实证明，Fast R-CNN算法的其中一个问题是得到候选区域的聚类步骤仍然非常缓慢，所以另一个研究组，任少卿（Shaoqing Ren）、何凯明（Kaiming He）、Ross Girshick和孙剑（Jiangxi Sun）提出了更快的R-CNN算法（Faster R-CNN），使用的是卷积神经网络，而不是更传统的分割算法来获得候选区域色块，结果比Fast R-CNN算法快得多。不过我认为大多数更快R-CNN的算法实现还是比YOLO算法慢很多。 候选区域的概念在计算机视觉领域的影响力相当大，所以我希望你们能了解一下这些算法，因为你可以看到还有人在用这些概念。对我个人来说，这是我的个人看法而不是整个计算机视觉研究界的看法，我觉得候选区域是一个有趣的想法，但这个方法需要两步，首先得到候选区域，然后再分类，相比之下，能够一步做完，类似于YOLO或者你只看一次（You only look once）这个算法，在我看来，是长远而言更有希望的方向。但这是我的个人看法，而不是整个计算机视觉研究界的看法，所以你们最好批判接受。但我想这个R-CNN概念，你可能会想到，或者碰到其他人在用，所以这也是值得了解的，这样你可以更好地理解别人的算法。 特殊应用：人脸识别和神经风格转换（Special applications: Face recognition &amp;Neural style transfer）4.1 什么是人脸识别？（What is face recognition?）欢迎来到第四周，即这门课卷积神经网络课程的最后一周。到目前为止，你学了很多卷积神经网络的知识。我这周准备向你展示一些重要的卷积神经网络的特殊应用，我们将从人脸识别开始，之后讲神经风格迁移，你将有机会在编程作业中实现这部分内容，创造自己的艺术作品。 让我们先从人脸识别开始，我这里有一个有意思的演示。我在领导百度AI团队的时候，其中一个小组由林元庆带领的，做过一个人脸识别系统，这个系统非常棒，让我们来看一下。 （以下内容为演示视频内容） 视频开始： 我想演示一个人脸识别系统，我现在在百度的中国总部，很多公司要求进入公司的时候要刷工卡，但是在这里我们并不需要它，使用人脸识别，看看我能做什么。当我走近的时候，它会识别我的脸，然后说欢迎我（Andrew NG），不需要工卡，我就能通过了。 让我们看看另一种情况，在旁边的是林元庆，IDL（百度深度学习实验室）的主管，他领导开发了这个人脸识别系统，我把我的工卡给他，上面有我的头像，他会试着用我的头像照片，而不是真人来通过。 （林元庆语：我将尝试用Andrew的工卡骗过机器，看看发生什么，系统不会识别，系统拒绝识别。现在我要用我自己的脸，（系统语音：“欢迎您”）（林元庆顺利通过）） 类似于这样的人脸识别系统在中国发展很快，我希望这个技术也可以在其他的国家使用。 #视频结束 挺厉害的吧，你刚看到的这个视频展示了人脸识别和活体检测，后一项技术确认你是一个活人。事实上，活体检测可以使用监督学习来实现，去预测是不是一个真人，这个方面我就不多说了。我主要想讲的是，如何构造这个系统中的人脸识别这一部分。 首先，让我们了解一下人脸识别的一些术语。 在人脸识别的相关文献中，人们经常提到人脸验证（face verification）和人脸识别（face recognition）。 这是人脸验证问题，如果你有一张输入图片，以及某人的ID或者是名字，这个系统要做的是，验证输入图片是否是这个人。有时候也被称作1对1问题，只需要弄明白这个人是否和他声称的身份相符。 而人脸识别问题比人脸验证问题难很多（整理者注：1对多问题（$1:K$）），为什么呢？假设你有一个验证系统，准确率是99%，还可以。但是现在，假设在识别系统中，$K=100$，如果你把这个验证系统应用在100个人身上，人脸识别上，你犯错的机会就是100倍了。如果每个人犯错的概率是1%，如果你有一个上百人的数据库，如果你想得到一个可接受的识别误差，你要构造一个验证系统，其准确率为99.9%或者更高，然后才可以在100人的数据库上运行，而保证有很大几率不出错。事实上，如果我们有一个100人的数据库，正确率可能需要远大于99%，才能得到很好的效果。 在之后的几个视频中，我们主要讲构造一个人脸验证，作为基本模块，如果准确率够高，你就可以把它用在识别系统上。 下一个视频中，我们将开始讨论如何构造人脸验证系统，人脸验证之所以难，原因之一在于要解决“一次学”（one-shot learning problem）问题。让我们看下一个视频，什么是一次学习问题。 4.2 One-Shot学习（One-shot learning）人脸识别所面临的一个挑战就是你需要解决一次学习问题，这意味着在大多数人脸识别应用中，你需要通过单单一张图片或者单单一个人脸样例就能去识别这个人。而历史上，当深度学习只有一个训练样例时，它的表现并不好，让我们看一个直观的例子，并讨论如何去解决这个问题。 假设你的数据库里有4张你们公司的员工照片，实际上他们确实是我们deeplearning.ai的员工，分别是Kian，Danielle，Younes和Tian。现在假设有个人（编号1所示）来到办公室，并且她想通过带有人脸识别系统的栅门，现在系统需要做的就是，仅仅通过一张已有的Danielle照片，来识别前面这个人确实是她。相反，如果机器看到一个不在数据库里的人（编号2所示），机器应该能分辨出她不是数据库中四个人之一。 所以在一次学习问题中，只能通过一个样本进行学习，以能够认出同一个人。大多数人脸识别系统都需要解决这个问题，因为在你的数据库中每个雇员或者组员可能都只有一张照片。 有一种办法是，将人的照片放进卷积神经网络中，使用softmax单元来输出4种，或者说5种标签，分别对应这4个人，或者4个都不是，所以softmax里我们会有5种输出。但实际上这样效果并不好，因为如此小的训练集不足以去训练一个稳健的神经网络。 而且，假如有新人加入你的团队，你现在将会有5个组员需要识别，所以输出就变成了6种，这时你要重新训练你的神经网络吗？这听起来实在不像一个好办法。 所以要让人脸识别能够做到一次学习，为了能有更好的效果，你现在要做的应该是学习Similarity函数。详细地说，你想要神经网络学习这样一个用$d$表示的函数，$d(img1,img2) = degree\ of\ difference\ between\ images$，它以两张图片作为输入，然后输出这两张图片的差异值。如果你放进同一个人的两张照片，你希望它能输出一个很小的值，如果放进两个长相差别很大的人的照片，它就输出一个很大的值。所以在识别过程中，如果这两张图片的差异值小于某个阈值$\tau$，它是一个超参数，那么这时就能预测这两张图片是同一个人，如果差异值大于τ，就能预测这是不同的两个人，这就是解决人脸验证问题的一个可行办法。 要将它应用于识别任务，你要做的是拿这张新图片（编号6），然后用$d$函数去比较这两张图片（编号1和编号6），这样可能会输出一个非常大的数字，在该例中，比如说这个数字是10。之后你再让它和数据库中第二张图（编号2）片比较，因为这两张照片是同一个人，所以我们希望会输出一个很小的数。然后你再用它与数据库中的其他图片（编号3、4）进行比较，通过这样的计算，最终你能够知道，这个人确实是Danielle。 对应的，如果某个人（编号7）不在你的数据库中，你通过函数$d$将他们的照片两两进行比较，最后我们希望$d$会对所有的比较都输出一个很大的值，这就证明这个人并不是数据库中4个人的其中一个。 要注意在这过程中你是如何解决一次学习问题的，只要你能学习这个函数$d$，通过输入一对图片，它将会告诉你这两张图片是否是同一个人。如果之后有新人加入了你的团队（编号5），你只需将他的照片加入你的数据库，系统依然能照常工作。 现在你已经知道函数d是如何工作的，通过输入两张照片，它将让你能够解决一次学习问题。那么，下节视频中，我们将会学习如何训练你的神经网络学会这个函数$d$。 4.3 Siamese 网络（Siamese network）上个视频中你学到的函数$d$的作用就是输入两张人脸，然后告诉你它们的相似度。实现这个功能的一个方式就是用Siamese网络，我们看一下。 你经常看到这样的卷积网络，输入图片$x^{(1)}$，然后通过一些列卷积，池化和全连接层，最终得到这样的特征向量（编号1）。有时这个会被送进softmax单元来做分类，但在这个视频里我们不会这么做。我们关注的重点是这个向量（编号1），假如它有128个数，它是由网络深层的全连接层计算出来的，我要给这128个数命个名字，把它叫做$f(x^{(1)})$。你可以把$f(x^{(1)})$看作是输入图像$x^{(1)}$的编码，取这个输入图像（编号2），在这里是Kian的图片，然后表示成128维的向量。 建立一个人脸识别系统的方法就是，如果你要比较两个图片的话，例如这里的第一张（编号1）和第二张图片（编号2），你要做的就是把第二张图片喂给有同样参数的同样的神经网络，然后得到一个不同的128维的向量（编号3），这个向量代表或者编码第二个图片，我要把第二张图片的编码叫做$f(x^{(2)})$。这里我用$x^{(1)}$和$x^{(2)}$仅仅代表两个输入图片，他们没必要非是第一个和第二个训练样本，可以是任意两个图片。 最后如果你相信这些编码很好地代表了这两个图片，你要做的就是定义$d$，将$x^{(1)}$和$x^{(2)}$的距离定义为这两幅图片的编码之差的范数，$d( x^{( 1)},x^{( 2)}) =|| f( x^{( 1)}) - f( x^{( 2)})||_{2}^{2}$。 对于两个不同的输入，运行相同的卷积神经网络，然后比较它们，这一般叫做Siamese网络架构。这里提到的很多观点，都来自于Yaniv Taigman，Ming Yang，Marc’ Aurelio Ranzato，Lior Wolf的这篇论文，他们开发的系统叫做DeepFace。 怎么训练这个Siamese神经网络呢？不要忘了这两个网络有相同的参数，所以你实际要做的就是训练一个网络，它计算得到的编码可以用于函数$d$，它可以告诉你两张图片是否是同一个人。更准确地说，神经网络的参数定义了一个编码函数$f(x^{(i)})$，如果给定输入图像$x^{(i)}$，这个网络会输出$x^{(i)}$的128维的编码。你要做的就是学习参数，使得如果两个图片$x^{( i)}$和$x^{( j)}$是同一个人，那么你得到的两个编码的距离就小。前面几个幻灯片我都用的是$x^{(1)}$和$x^{( 2)}$，其实训练集里任意一对$x^{(i)}$和$x^{(j)}$都可以。相反，如果$x^{(i)}$和$x^{(j)}$是不同的人，那么你会想让它们之间的编码距离大一点。 如果你改变这个网络所有层的参数，你会得到不同的编码结果，你要做的就是用反向传播来改变这些所有的参数，以确保满足这些条件。 你已经了解了Siamese网络架构，并且知道你想要网络输出什么，即什么是好的编码。但是如何定义实际的目标函数，能够让你的神经网络学习并做到我们刚才讨论的内容呢？在下一个视频里，我们会看到如何用三元组损失函数达到这个目的。 4.4 Triplet 损失（Triplet 损失）要想通过学习神经网络的参数来得到优质的人脸图片编码，方法之一就是定义三元组损失函数然后应用梯度下降。 我们看下这是什么意思，为了应用三元组损失函数，你需要比较成对的图像，比如这个图片，为了学习网络的参数，你需要同时看几幅图片，比如这对图片（编号1和编号2），你想要它们的编码相似，因为这是同一个人。然而假如是这对图片（编号3和编号4），你会想要它们的编码差异大一些，因为这是不同的人。 用三元组损失的术语来说，你要做的通常是看一个 Anchor 图片，你想让Anchor图片和Positive图片（Positive意味着是同一个人）的距离很接近。然而，当Anchor图片与Negative图片（Negative意味着是非同一个人）对比时，你会想让他们的距离离得更远一点。 这就是为什么叫做三元组损失，它代表你通常会同时看三张图片，你需要看Anchor图片、Postive图片，还有Negative图片，我要把Anchor图片、Positive图片和Negative图片简写成$A$、$P$、$N$。 把这些写成公式的话，你想要的是网络的参数或者编码能够满足以下特性，也就是说你想要$|| f(A) - f(P) ||^{2}$，你希望这个数值很小，准确地说，你想让它小于等$f(A)$和$f(N)$之间的距离，或者说是它们的范数的平方（即：$|| f(A) - f(P)||^{2} \leq ||f(A) - f(N)||^{2}$）。（$|| f(A) - f(P) ||^{2}$）当然这就是$d(A,P)$，（$|| f(A) - f(N) ||^{2}$）这是$d(A,N)$，你可以把$d$ 看作是距离(distance)函数，这也是为什么我们把它命名为$d$。 现在如果我把方程右边项移到左边，最终就得到： $|| f(A) - f(P)||^{2} \leq ||f(A) - f(N)||^{2}$ 现在我要对这个表达式做一些小的改变，有一种情况满足这个表达式，但是没有用处，就是把所有的东西都学成0，如果$f$总是输出0，即0-0≤0，这就是0减去0还等于0，如果所有图像的$f$都是一个零向量，那么总能满足这个方程。所以为了确保网络对于所有的编码不会总是输出0，也为了确保它不会把所有的编码都设成互相相等的。另一种方法能让网络得到这种没用的输出，就是如果每个图片的编码和其他图片一样，这种情况，你还是得到0-0。 为了阻止网络出现这种情况，我们需要修改这个目标，也就是，这个不能是刚好小于等于0，应该是比0还要小，所以这个应该小于一个$-a$值（即$|| f(A) - f(P)||^{2} -||f(A) - f(N)||^{2} \leq -a$），这里的$a$是另一个超参数，这个就可以阻止网络输出无用的结果。按照惯例，我们习惯写$+a$（即$|| f(A) - f(P)||^{2} -||f(A) - f(N)||^{2} +a\leq0$），而不是把$-a$写在后面，它也叫做间隔(margin)，这个术语你会很熟悉，如果你看过关于支持向量机 (SVM)的文献，没看过也不用担心。我们可以把上面这个方程（$|| f(A) - f(P)||^{2} -||f(A) - f(N)||^{2}$）也修改一下，加上这个间隔参数。haox 举个例子，假如间隔设置成0.2，如果在这个例子中，$d(A,P) =0.5$，如果 Anchor和 Negative图片的$d$，即$d(A,N)$只大一点，比如说0.51，条件就不能满足。虽然0.51也是大于0.5的，但还是不够好，我们想要$d(A,N)$比$d(A,P)$大很多，你会想让这个值（$d(A,N)$）至少是0.7或者更高，或者为了使这个间隔，或者间距至少达到0.2，你可以把这项调大或者这个调小，这样这个间隔$a$，超参数$a$ 至少是0.2，在$d(A,P)$和$d(A,N)$之间至少相差0.2，这就是间隔参数$a$的作用。它拉大了Anchor和Positive 图片对和Anchor与Negative 图片对之间的差距。取下面的这个方框圈起来的方程式，在下个幻灯片里，我们会更公式化表示，然后定义三元组损失函数。 三元组损失函数的定义基于三张图片，假如三张图片$A$、$P$、$N$，即Anchor样本、Positive样本和Negative样本，其中Positive图片和Anchor图片是同一个人，但是Negative图片和Anchor不是同一个人。 接下来我们定义损失函数，这个例子的损失函数，它的定义基于三元图片组，我先从前一张幻灯片复制过来一些式子，就是$|| f( A) - f( P)||^{2} -||f( A) - f( N)||^{2} +a \leq0$。所以为了定义这个损失函数，我们取这个和0的最大值： $L( A,P,N) = max(|| f( A) - f( P)||^{2} -|| f( A) - f( N)||^{2} + a,0)$ 这个$max$函数的作用就是，只要这个$|| f( A) - f( P)||^{2} -|| f( A) - f( N)||^{2} + a\leq0$，那么损失函数就是0。只要你能使画绿色下划线部分小于等于0，只要你能达到这个目标，那么这个例子的损失就是0。 另一方面如果这个$|| f( A) - f( P)||^{2} -|| f( A) - f( N)||^{2} + a\leq0$，然后你取它们的最大值，最终你会得到绿色下划线部分（即$|| f(A) - f( P)||^{2} -|| f( A) - f( N)||^{2} +a$）是最大值，这样你会得到一个正的损失值。通过最小化这个损失函数达到的效果就是使这部分$|| f( A) - f( P)||^{2} -||f( A) - f( N)||^{2} +a$成为0，或者小于等于0。只要这个损失函数小于等于0，网络不会关心它负值有多大。 这是一个三元组定义的损失，整个网络的代价函数应该是训练集中这些单个三元组损失的总和。假如你有一个10000个图片的训练集，里面是1000个不同的人的照片，你要做的就是取这10000个图片，然后生成这样的三元组，然后训练你的学习算法，对这种代价函数用梯度下降，这个代价函数就是定义在你数据集里的这样的三元组图片上。 注意，为了定义三元组的数据集你需要成对的$A$和$P$，即同一个人的成对的图片，为了训练你的系统你确实需要一个数据集，里面有同一个人的多个照片。这是为什么在这个例子中，我说假设你有1000个不同的人的10000张照片，也许是这1000个人平均每个人10张照片，组成了你整个数据集。如果你只有每个人一张照片，那么根本没法训练这个系统。当然，训练完这个系统之后，你可以应用到你的一次学习问题上，对于你的人脸识别系统，可能你只有想要识别的某个人的一张照片。但对于训练集，你需要确保有同一个人的多个图片，至少是你训练集里的一部分人，这样就有成对的Anchor和Positive图片了。 现在我们来看，你如何选择这些三元组来形成训练集。一个问题是如果你从训练集中，随机地选择$A$、$P$和$N$，遵守$A$和$P$是同一个人，而$A$和$N$是不同的人这一原则。有个问题就是，如果随机的选择它们，那么这个约束条件（$d(A,P) + a \leq d(A,N)$）很容易达到，因为随机选择的图片，$A$和$N$比$A$和$P$差别很大的概率很大。我希望你还记得这个符号$d(A,P)$就是前几个幻灯片里写的$|| f(A) - f(P)||^{2}$，$d(A,N)$就是$||f(A) -f(N)||^{2}$，$d(A,P) + a \leq d(A,N)$即$|| f( A) - f( P)||^{2} + a \leq|| f(A) - f( N)||^{2}$。但是如果$A$和$N$是随机选择的不同的人，有很大的可能性$||f(A) - f(N)||^{2}$会比左边这项$||f( A) - f(P)||^{2}$大，而且差距远大于$a$，这样网络并不能从中学到什么。 所以为了构建一个数据集，你要做的就是尽可能选择难训练的三元组$A$、$P$和$N$。具体而言，你想要所有的三元组都满足这个条件（$d(A,P) + a \leq d(A,N)$），难训练的三元组就是，你的$A$、$P$和$N$的选择使得$d(A,P)$很接近$d(A,N)$，即$d(A,P) \approx d(A,N)$，这样你的学习算法会竭尽全力使右边这个式子变大（$d(A,N)$），或者使左边这个式子（$d(A,P)$）变小，这样左右两边至少有一个$a$的间隔。并且选择这样的三元组还可以增加你的学习算法的计算效率，如果随机的选择这些三元组，其中有太多会很简单，梯度算法不会有什么效果，因为网络总是很轻松就能得到正确的结果，只有选择难的三元组梯度下降法才能发挥作用，使得这两边离得尽可能远。 如果你对此感兴趣的话，这篇论文中有更多细节，作者是Florian Schroff, Dmitry Kalenichenko, James Philbin，他们建立了这个叫做FaceNet的系统，我视频里许多的观点都是来自于他们的工作。 • Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). FaceNet: A Unified Embedding forFace Recognition and Clustering 顺便说一下，这有一个有趣的事实，关于在深度学习领域，算法是如何命名的。如果你研究一个特定的领域，假如说“某某”领域，通常会将系统命名为“某某”网络或者深度“某某”，我们一直讨论人脸识别，所以这篇论文叫做FaceNet(人脸网络)，上个视频里你看到过DeepFace(深度人脸)。“某某”网络或者深度“某某”，是深度学习领域流行的命名算法的方式，你可以看一下这篇论文，如果你想要了解更多的关于通过选择最有用的三元组训练来加速算法的细节，这是一个很棒的论文。 总结一下，训练这个三元组损失你需要取你的训练集，然后把它做成很多三元组，这就是一个三元组（编号1），有一个Anchor图片和Positive图片，这两个（Anchor和Positive）是同一个人，还有一张另一个人的Negative图片。这是另一组（编号2），其中Anchor和Positive图片是同一个人，但是Anchor和Negative不是同一个人，等等。 定义了这些包括$A$、$P$和$N$图片的数据集之后，你还需要做的就是用梯度下降最小化我们之前定义的代价函数$J$，这样做的效果就是反向传播到网络中的所有参数来学习到一种编码，使得如果两个图片是同一个人，那么它们的$d$就会很小，如果两个图片不是同一个人，它们的$d$ 就会很大。 这就是三元组损失，并且如何用它来训练网络输出一个好的编码用于人脸识别。现在的人脸识别系统，尤其是大规模的商业人脸识别系统都是在很大的数据集上训练，超过百万图片的数据集并不罕见，一些公司用千万级的图片，还有一些用上亿的图片来训练这些系统。这些是很大的数据集，即使按照现在的标准，这些数据集并不容易获得。幸运的是，一些公司已经训练了这些大型的网络并且上传了模型参数。所以相比于从头训练这些网络，在这一领域，由于这些数据集太大，这一领域的一个实用操作就是下载别人的预训练模型，而不是一切都要从头开始。但是即使你下载了别人的预训练模型，我认为了解怎么训练这些算法也是有用的，以防针对一些应用你需要从头实现这些想法。 这就是三元组损失，下个视频中，我会给你展示Siamese网络的一些其他变体，以及如何训练这些网络，让我们进入下个视频吧。 4.5 人脸验证与二分类（Face verification and binary classification）Triplet loss是一个学习人脸识别卷积网络参数的好方法，还有其他学习参数的方法，让我们看看如何将人脸识别当成一个二分类问题。 另一个训练神经网络的方法是选取一对神经网络，选取Siamese网络，使其同时计算这些嵌入，比如说128维的嵌入（编号1），或者更高维，然后将其输入到逻辑回归单元，然后进行预测，如果是相同的人，那么输出是1，若是不同的人，输出是0。这就把人脸识别问题转换为一个二分类问题，训练这种系统时可以替换Triplet loss的方法。 最后的逻辑回归单元是怎么处理的？输出$\hat y$会变成，比如说sigmoid函数应用到某些特征上，相比起直接放入这些编码（$f(x^{(i)}),f( x^{(j)})$），你可以利用编码之间的不同。 $\hat y = \sigma(\sum_{k = 1}^{128}{w_{i}| f( x^{( i)})_{k} - f( x^{( j)})_{k}| + b})$ 我解释一下，符号$f( x^{( i)})_{k}$代表图片$x^{(i)}$的编码，下标$k$代表选择这个向量中的第$k$个元素，$| f(x^{( i)})_{k} - f( x^{( j)})_{k}|$对这两个编码取元素差的绝对值。你可能想，把这128个元素当作特征，然后把他们放入逻辑回归中，最后的逻辑回归可以增加参数$w_{i}$和$b$，就像普通的逻辑回归一样。你将在这128个单元上训练合适的权重，用来预测两张图片是否是一个人，这是一个很合理的方法来学习预测0或者1，即是否是同一个人。 还有其他不同的形式来计算绿色标记的这部分公式（$| f( x^{( i)})_{k} - f( x^{( j)})_{k}|$），比如说，公式可以是$\frac{(f( x^{( i)})_{k} - f(x^{( j)})_{k})^{2} }{f(x^{( i)})_{k} + f( x^{( j)})_{k} }$，这个公式也被叫做$\chi^{2}$公式，是一个希腊字母$\chi$，也被称为$\chi$平方相似度。 • Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, Lior Wolf (2014). DeepFace:Closing the gap to human-level performance in face verification 这些公式及其变形在这篇DeepFace论文中有讨论，我之前也引用过。 但是在这个学习公式中，输入是一对图片，这是你的训练输入$x$（编号1、2），输出$y$是0或者1，取决于你的输入是相似图片还是非相似图片。与之前类似，你正在训练一个Siamese网络，意味着上面这个神经网络拥有的参数和下面神经网络的相同（编号3和4所示的网络），两组参数是绑定的，这样的系统效果很好。 之前提到一个计算技巧可以帮你显著提高部署效果，如果这是一张新图片（编号1），当员工走进门时，希望门可以自动为他们打开，这个（编号2）是在数据库中的图片，不需要每次都计算这些特征（编号6），不需要每次都计算这个嵌入，你可以提前计算好，那么当一个新员工走近时，你可以使用上方的卷积网络来计算这些编码（编号5），然后使用它，和预先计算好的编码进行比较，然后输出预测值$\hat y$。 因为不需要存储原始图像，如果你有一个很大的员工数据库，你不需要为每个员工每次都计算这些编码。这个预先计算的思想，可以节省大量的计算，这个预训练的工作可以用在Siamese网路结构中，将人脸识别当作一个二分类问题，也可以用在学习和使用Triplet loss函数上，我在之前的视频中描述过。 总结一下，把人脸验证当作一个监督学习，创建一个只有成对图片的训练集，不是三个一组，而是成对的图片，目标标签是1表示一对图片是一个人，目标标签是0表示图片中是不同的人。利用不同的成对图片，使用反向传播算法去训练神经网络，训练Siamese神经网络。 这个你看到的版本，处理人脸验证和人脸识别扩展为二分类问题，这样的效果也很好。我希望你知道，在一次学习时，你需要什么来训练人脸验证，或者人脸识别系统。 4.6 什么是神经风格迁移？（What is neural style transfer?）最近，卷积神经网络最有趣的应用是神经风格迁移，在编程作业中，你将自己实现这部分并创造出你的艺术作品。 什么是神经风格迁移？让我们来看几个例子，比如这张照片，照片是在斯坦福大学拍摄的，离我的办公室不远，你想利用右边照片的风格来重新创造原本的照片，右边的是梵高的星空，神经风格迁移可以帮你生成下面这张照片。 这仍是斯坦福大学的照片，但是用右边图像的风格画出来。 为了描述如何实现神经网络迁移，我将使用$C$来表示内容图像，$S$表示风格图像，$G$表示生成的图像。 另一个例子，比如，这张图片，$C$代表在旧金山的金门大桥，还有这张风格图片，是毕加索的风格，然后把两张照片结合起来，得到G这张毕加索风格的的金门大桥。 这页中展示的例子，是由Justin Johnson制作，在下面几个视频中你将学到如何自己生成这样的图片。 为了实现神经风格迁移，你需要知道卷积网络提取的特征，在不同的神经网络，深层的、浅层的。在深入了解如何实现神经风格迁移之前，我将在下一个视频中直观地介绍卷积神经网络不同层之间的具体运算，让我们来看下一个视频。 4.7 CNN特征可视化（What are deep ConvNets learning?）深度卷积网络到底在学什么？在这个视频中我将展示一些可视化的例子，可以帮助你理解卷积网络中深度较大的层真正在做什么，这样有助于理解如何实现神经风格迁移。 来看一个例子，假如你训练了一个卷积神经网络，是一个Alexnet，轻量级网络，你希望将看到不同层之间隐藏单元的计算结果。 你可以这样做，从第一层的隐藏单元开始，假设你遍历了训练集，然后找到那些使得单元激活最大化的一些图片，或者是图片块。换句话说，将你的训练集经过神经网络，然后弄明白哪一张图片最大限度地激活特定的单元。注意在第一层的隐藏单元，只能看到小部分卷积神经，如果要画出来哪些激活了激活单元，只有一小块图片块是有意义的，因为这就是特定单元所能看到的全部。你选择一个隐藏单元，发现有9个图片最大化了单元激活，你可能找到这样的9个图片块（编号1），似乎是图片浅层区域显示了隐藏单元所看到的，找到了像这样的边缘或者线（编号2），这就是那9个最大化地激活了隐藏单元激活项的图片块。 然后你可以选一个另一个第一层的隐藏单元，重复刚才的步骤，这是另一个隐藏单元，似乎第二个由这9个图片块（编号1）组成。看来这个隐藏单元在输入区域，寻找这样的线条（编号2），我们也称之为接受域。 对其他隐藏单元也进行处理，会发现其他隐藏单元趋向于激活类似于这样的图片。这个似乎对垂直明亮边缘左边有绿色的图片块（编号1）感兴趣，这一个隐藏单元倾向于橘色，这是一个有趣的图片块（编号2），红色和绿色混合成褐色或者棕橙色，但是神经元仍可以激活它。 以此类推，这是9个不同的代表性神经元，每一个不同的图片块都最大化地激活了。你可以这样理解，第一层的隐藏单元通常会找一些简单的特征，比如说边缘或者颜色阴影。 我在这个视频中使用的所有例子来自于Matthew Zener和Rob Fergus的这篇论文，题目是（Zeiler M D, Fergus R.Visualizing and Understanding Convolutional Networks[J]. 2013, 8689:818-833.）《可视化理解卷积神经网络》，我会使用一种更简单的方法来可视化神经网络隐藏单元的计算内容。如果你读过他们的论文，他们提出了一些更复杂的方式来可视化卷积神经网络的计算。 你已经在第一层的9个隐藏单元重复了这个过程好几遍，如果在深层的隐藏单元中进行这样的计算呢？卷积神经网络的深层部分学到了什么？在深层部分，一个隐藏单元会看到一张图片更大的部分，在极端的情况下，可以假设每一个像素都会影响到神经网络更深层的输出，靠后的隐藏单元可以看到更大的图片块，我还会画出和这页中的大小相同的图片块。 但如果我们重复这一过程，这（Layer 1所示图片）是之前第一层得到的，这个（Layer 2所示图片）是可视化的第2层中最大程度激活的9个隐藏单元。我想解释一下这个可视化，这是（编号2所示）使一个隐藏单元最大激活的9个图片块，每一个组合，这是另一组（编号2），使得一个隐藏单元被激活的9个图片块，这个可视化展示了第二层的9个隐藏单元，每一个又有9个图片块使得隐藏单元有较大的输出或是较大的激活。 在更深的层上，你可以重复这个过程。 在这页里很难看清楚，这些微小的浅层图片块，让我们放大一些，这是第一层，这是第一个被高度激活的单元，你能在输入图片的区域看到，大概是这个角度的边缘（编号1）放大第二层的可视化图像。 有意思了，第二层似乎检测到更复杂的形状和模式，比如说这个隐藏单元（编号1），它会找到有很多垂线的垂直图案，这个隐藏单元（编号2）似乎在左侧有圆形图案时会被高度激活，这个的特征（编号3）是很细的垂线，以此类推，第二层检测的特征变得更加复杂。 看看第三层我们将其放大，放得更大一点，看得更清楚一点，这些东西激活了第三层。再放大一点，这又很有趣了，这个隐藏单元（编号1）似乎对图像左下角的圆形很敏感，所以检测到很多车。这一个（编号2）似乎开始检测到人类，这个（编号3）似乎检测特定的图案，蜂窝形状或者方形，类似这样规律的图案。有些很难看出来，需要手动弄明白检测到什么，但是第三层明显，检测到更复杂的模式。 下一层呢？这是第四层，检测到的模式和特征更加复杂，这个（编号1）学习成了一个狗的检测器，但是这些狗看起来都很类似，我并不知道这些狗的种类，但是你知道这些都是狗，他们看起来也类似。第四层中的这个（编号2）隐藏单元它检测什么？水吗？这个（编号3）似乎检测到鸟的脚等等。 第五层检测到更加复杂的事物，注意到这（编号1）也有一个神经元，似乎是一个狗检测器，但是可以检测到的狗似乎更加多样性。这个（编号2）可以检测到键盘，或者是键盘质地的物体，可能是有很多点的物体。我认为这个神经元（编号3）可能检测到文本，但是很难确定，这个（编号4）检测到花。我们已经有了一些进展，从检测简单的事物，比如说，第一层的边缘，第二层的质地，到深层的复杂物体。 我希望这让你可以更直观地了解卷积神经网络的浅层和深层是如何计算的，接下来让我们使用这些知识开始构造神经风格迁移算法。 4.8 代价函数（Cost function）要构建一个神经风格迁移系统，让我们为生成的图像定义一个代价函数，你接下看到的是，通过最小化代价函数，你可以生成你想要的任何图像。 记住我们的问题，给你一个内容图像$C$，给定一个风格图片$S$，而你的目标是生成一个新图片$G$。为了实现神经风格迁移，你要做的是定义一个关于$G$的代价函数$J$用来评判某个生成图像的好坏，我们将使用梯度下降法去最小化$J(G)$，以便于生成这个图像。 怎么判断生成图像的好坏呢？我们把这个代价函数定义为两个部分。 $J_{\text{content} }(C,G)$ 第一部分被称作内容代价，这是一个关于内容图片和生成图片的函数，它是用来度量生成图片$G$的内容与内容图片$C$的内容有多相似。 $J_{\text{style} }(S,G)$ 然后我们会把结果加上一个风格代价函数，也就是关于$S$和$G$的函数，用来度量图片$G$的风格和图片$S$的风格的相似度。 $J( G) = a J_{\text{content} }( C,G) + \beta J_{\text{style} }(S,G)$ 最后我们用两个超参数$a$和$\beta$来来确定内容代价和风格代价，两者之间的权重用两个超参数来确定。两个代价的权重似乎是多余的，我觉得一个超参数似乎就够了，但提出神经风格迁移的原始作者使用了两个不同的超参数，我准备保持一致。 关于神经风格迁移算法我将在接下来几段视频中展示的，是基于Leon Gatys， Alexandra Ecker和Matthias Bethge的这篇论文。这篇论文并不是很难读懂，如果你愿意，看完这些视频，我也非常推荐你去看看他们的论文。 Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). A Neural Algorithm of Artistic Style (https://arxiv.org/abs/1508.06576) 算法的运行是这样的，对于代价函数$J(G)$，为了生成一个新图像，你接下来要做的是随机初始化生成图像$G$，它可能是100×100×3，可能是500×500×3，又或者是任何你想要的尺寸。 然后使用在之前的幻灯片上定义的代价函数$J(G)$，你现在可以做的是使用梯度下降的方法将其最小化，更新$G:= G - \frac{\partial}{\partial G}J(G)$。在这个步骤中，你实际上更新的是图像$G$的像素值，也就是100×100×3，比如RGB通道的图片。 这里有个例子，假设你从这张内容图片（编号1）和风格（编号2）图片开始，这是另一张公开的毕加索画作，当你随机初始化$G$，你随机初始化的生成图像就是这张随机选取像素的白噪声图（编号3）。接下来运行梯度下降算法，最小化代价函数$J(G)$，逐步处理像素，这样慢慢得到一个生成图片（编号4、5、6），越来越像用风格图片的风格画出来的内容图片。 在这段视频中你看到了神经风格迁移算法的概要，定义一个生成图片$G$的代价函数，并将其最小化。接下来我们需要了解怎么去定义内容代价函数和风格代价函数，让我们从下一个视频开始学习这部分内容吧。 4.9 内容代价函数（Content cost function）风格迁移网络的代价函数有一个内容代价部分，还有一个风格代价部分。 $J( G) = \alpha J_{\text{content} }( C,G) + \beta J_{\text{style} }(S,G)$ 我们先定义内容代价部分，不要忘了这就是我们整个风格迁移网络的代价函数，我们看看内容代价函数应该是什么。 假如说，你用隐含层$l$来计算内容代价，如果$l$是个很小的数，比如用隐含层1，这个代价函数就会使你的生成图片像素上非常接近你的内容图片。然而如果你用很深的层，那么那就会问，内容图片里是否有狗，然后它就会确保生成图片里有一个狗。所以在实际中，这个层$l$在网络中既不会选的太浅也不会选的太深。因为你要自己做这周结束的编程练习，我会让你获得一些直觉，在编程练习中的具体例子里通常$l$会选择在网络的中间层，既不太浅也不很深，然后用一个预训练的卷积模型，可以是VGG网络或者其他的网络也可以。 现在你需要衡量假如有一个内容图片和一个生成图片他们在内容上的相似度，我们令这个$a^{[l][C]}$和$a^{[l][G]}$，代表这两个图片$C$和$G$的$l$层的激活函数值。如果这两个激活值相似，那么就意味着两个图片的内容相似。 我们定义这个 $J_{\text{content} }( C,G) = \frac{1}{2}|| a^{[l][C]} - a^{[l][G]}||^{2}$ 为两个激活值不同或者相似的程度，我们取$l$层的隐含单元的激活值，按元素相减，内容图片的激活值与生成图片相比较，然后取平方，也可以在前面加上归一化或者不加，比如$\frac{1}{2}$或者其他的，都影响不大,因为这都可以由这个超参数$a$来调整（$J(G) =a J_{\text{content} }( C,G) + \beta J_{\text{style} }(S,G)$）。 要清楚我这里用的符号都是展成向量形式的，这个就变成了这一项（$a^{[l]\lbrack C\rbrack}$）减这一项（$a^{[l]\lbrack C\rbrack}$）的$L2$范数的平方，在把他们展成向量后。这就是两个激活值间的差值平方和，这就是两个图片之间$l$层激活值差值的平方和。后面如果对$J(G)$做梯度下降来找$G$的值时，整个代价函数会激励这个算法来找到图像$G$，使得隐含层的激活值和你内容图像的相似。 这就是如何定义风格迁移网络的内容代价函数，接下来让我们学习风格代价函数。 4.10 风格代价函数（Style cost function）在上节视频中，我们学习了如何为神经风格迁移定义内容代价函数，这节课我们来了解风格代价函数。那么图片的风格到底是什么意思呢？ 这么说吧，比如你有这样一张图片，你可能已经对这个计算很熟悉了，它能算出这里是否含有不同隐藏层。现在你选择了某一层$l$（编号1），比如这一层去为图片的风格定义一个深度测量，现在我们要做的就是将图片的风格定义为$l$层中各个通道之间激活项的相关系数。 我来详细解释一下，现在你将$l$层的激活项取出，这是个$ n_{H} \times n_{W} \times n_{C}$的激活项，它是一个三维的数据块。现在问题来了，如何知道这些不同通道之间激活项的相关系数呢？ 为了解释这些听起来很含糊不清的词语，现在注意这个激活块，我把它的不同通道渲染成不同的颜色。在这个例子中，假如我们有5个通道为了方便讲解，我将它们染成了五种颜色。一般情况下，我们在神经网络中会有许多通道，但这里只用5个通道，会更方便我们理解。 为了能捕捉图片的风格，你需要进行下面这些操作，首先，先看前两个通道，前两个通道（编号1、2）分别是图中的红色和黄色部分，那我们该如何计算这两个通道间激活项的相关系数呢？ 举个例子，在视频的左下角在第一个通道中含有某个激活项，第二个通道也含有某个激活项，于是它们组成了一对数字（编号1所示）。然后我们再看看这个激活项块中其他位置的激活项，它们也分别组成了很多对数字（编号2，3所示），分别来自第一个通道，也就是红色通道和第二个通道，也就是黄色通道。现在我们得到了很多个数字对，当我们取得这两个$n_{H}\times n_{W}$的通道中所有的数字对后，现在该如何计算它们的相关系数呢？它是如何决定图片风格的呢？ 我们来看一个例子，这是之前视频中的一个可视化例子，它来自一篇论文，作者是Matthew Zeile和Rob Fergus 我之前有提到过。我们知道，这个红色的通道（编号1）对应的是这个神经元，它能找出图片中的特定位置是否含有这些垂直的纹理（编号3），而第二个通道也就是黄色的通道（编号2），对应这个神经元（编号4），它可以粗略地找出橙色的区域。什么时候两个通道拥有高度相关性呢？如果它们有高度相关性，那么这幅图片中出现垂直纹理的地方（编号2），那么这块地方（编号4）很大概率是橙色的。如果说它们是不相关的，又是什么意思呢？显然，这意味着图片中有垂直纹理的地方很大概率不是橙色的。而相关系数描述的就是当图片某处出现这种垂直纹理时，该处又同时是橙色的可能性。 相关系数这个概念为你提供了一种去测量这些不同的特征的方法，比如这些垂直纹理，这些橙色或是其他的特征去测量它们在图片中的各个位置同时出现或不同时出现的频率。 如果我们在通道之间使用相关系数来描述通道的风格，你能做的就是测量你的生成图像中第一个通道（编号1）是否与第二个通道（编号2）相关，通过测量，你能得知在生成的图像中垂直纹理和橙色同时出现或者不同时出现的频率，这样你将能够测量生成的图像的风格与输入的风格图像的相似程度。 现在我们来证实这种说法，对于这两个图像，也就是风格图像与生成图像，你需要计算一个风格矩阵，说得更具体一点就是用$l$层来测量风格。 我们设$a_{i,\ j,\ k}^{[l]}$，设它为隐藏层l中$(i,j,k)$位置的激活项，$i$，$j$，$k$分别代表该位置的高度、宽度以及对应的通道数。现在你要做的就是去计算一个关于$l$层和风格图像的矩阵，即$G^{[l](S)}$（$l$表示层数，$S$表示风格图像），这（$G^{[l]( S)}$）是一个$n_{c} \times n_{c}$的矩阵，同样地，我们也对生成的图像进行这个操作。 但是现在我们先来定义风格图像，设这个关于$l$层和风格图像的，$G$是一个矩阵，这个矩阵的高度和宽度都是$l$层的通道数。在这个矩阵中$k$和$k'$元素被用来描述$k$通道和$k'$通道之间的相关系数。具体地： $G_{kk^{'} }^{[l]( S)} = \sum_{i = 1}^{n_{H}^{[l]} }{\sum_{j = 1}^{n_{W}^{[l]} }{a_{i,\ j,\ k}^{[l](S)}a_{i,\ j,\ k^{'} }^{[l](S)} }}$ 用符号$i$，$j$表示下界，对$i$，$j$，$k$位置的激活项$a_{i,\ j,\ k}^{[l]}$，乘以同样位置的激活项，也就是$i$,$ j$,$k'$位置的激活项，即$a_{i,j,k^{'} }^{[l]}$，将它们两个相乘。然后$i$和$j$分别加到l层的高度和宽度，即$n_{H}^{[l]}$和$n_{W}^{[l]}$，将这些不同位置的激活项都加起来。$(i,j,k)$和$(i,j,k')$中$x$坐标和$y$坐标分别对应高度和宽度，将$k$通道和$k'$通道上这些位置的激活项都进行相乘。我一直以来用的这个公式，严格来说，它是一种非标准的互相关函数，因为我们没有减去平均数，而是将它们直接相乘。 这就是输入的风格图像所构成的风格矩阵，然后，我们再对生成图像做同样的操作。 $G_{kk^{'} }^{[l]( G)} = \sum_{i = 1}^{n_{H}^{[l]} }{\sum_{j = 1}^{n_{W}^{[l]} }{a_{i,\ j,\ k}^{[l](G)}a_{i,\ j,\ k^{'} }^{[l](G)} }}$ $a_{i,\ j,\ k}^{[l](S)}$和$a_{i, j,k}^{[l](G)}$中的上标$(S)$和$(G)$分别表示在风格图像$S$中的激活项和在生成图像$G$的激活项。我们之所以用大写字母$G$来代表这些风格矩阵，是因为在线性代数中这种矩阵有时也叫**Gram**矩阵，但在这里我只把它们叫做风格矩阵。 所以你要做的就是计算出这张图像的风格矩阵，以便能够测量出刚才所说的这些相关系数。更正规地来表示，我们用$a_{i,j,k}^{[l]}$来记录相应位置的激活项，也就是$l$层中的$i,j,k$位置，所以$i$代表高度，$j$代表宽度，$k$代表着$l$中的不同通道。之前说过，我们有5个通道，所以$k$就代表这五个不同的通道。 对于这个风格矩阵，你要做的就是计算这个矩阵也就是$G^{[l]}$矩阵，它是个$n_{c} \times n_{c}$的矩阵，也就是一个方阵。记住，因为这里有$n_{c}$个通道，所以矩阵的大小是$n_{c}\times n_{c}$。以便计算每一对激活项的相关系数，所以$G_{\text{kk}^{'} }^{[l]}$可以用来测量$k$通道与$k'$通道中的激活项之间的相关系数，$k$和$k'$会在1到$n_{c}$之间取值，$n_{c}$就是$l$层中通道的总数量。 当在计算$G^{[l]}$时，我写下的这个符号（下标$kk’$）只代表一种元素，所以我要在右下角标明是$kk'$元素，和之前一样$i$，$j$从一开始往上加，对应$(i,j,k)$位置的激活项与对应$(i, j, k')$位置的激活项相乘。记住，这个$i$和$j$是激活块中对应位置的坐标，也就是该激活项所在的高和宽，所以$i$会从1加到$n_{H}^{[l]}$，$j$会从1加到$n_{W}^{[l]}$，$k$和$k'$则表示对应的通道，所以$k$和$k'$值的范围是从1开始到这个神经网络中该层的通道数量$n_{C}^{[l]}$。这个式子就是把图中各个高度和宽度的激活项都遍历一遍，并将$k$和$k'$通道中对应位置的激活项都进行相乘，这就是$G_{ {kk}^{'} }^{[l]}$的定义。通过对$k$和$k'$通道中所有的数值进行计算就得到了$G$矩阵，也就是风格矩阵。 $G_{kk^{'} }^{[l]} = \sum_{i = 1}^{n_{H}^{[l]} }{\sum_{j = 1}^{n_{W}^{[l]} }{a_{i,\ j,\ k}^{[l]}a_{i,\ j,\ k^{'} }^{[l]} }}$ 要注意，如果两个通道中的激活项数值都很大，那么$G_{ {kk}^{'} }^{[l]}$也会变得很大，对应地，如果他们不相关那么$G_{ {kk}^{'} }^{[l]}$就会很小。严格来讲，我一直使用这个公式来表达直觉想法，但它其实是一种非标准的互协方差，因为我们并没有减去均值而只是把这些元素直接相乘，这就是计算图像风格的方法。 $G_{kk^{'} }^{[l]( S)} = \sum_{i = 1}^{n_{H}^{[l]} }{\sum_{j = 1}^{n_{W}^{[l]} }{a_{i,\ j,\ k}^{[l](S)}a_{i,\ j,\ k^{'} }^{[l](S)} }}$ 你要同时对风格图像$S$和生成图像$G$都进行这个运算，为了区分它们，我们在它的右上角加一个$(S)$，表明它是风格图像$S$，这些都是风格图像S中的激活项，之后你需要对生成图像也做相同的运算。 $G_{kk^{'} }^{[l]( G)} = \sum_{i = 1}^{n_{H}^{[l]} }{\sum_{j = 1}^{n_{W}^{[l]} }{a_{i,\ j,\ k}^{[l](G)}a_{i,\ j,\ k^{'} }^{[l](G)} }}$ 和之前一样，再把公式都写一遍，把这些都加起来，为了区分它是生成图像，在这里放一个$(G)$。 现在，我们有2个矩阵，分别从风格图像$S$和生成图像$G$。 再提醒一下，我们一直使用大写字母$G$来表示矩阵，是因为在线性代数中，这种矩阵被称为Gram矩阵，但在本视频中我把它叫做风格矩阵，我们取了Gram矩阵的首字母$G$来表示这些风格矩阵。 最后，如果我们将$S$和$G$代入到风格代价函数中去计算，这将得到这两个矩阵之间的误差，因为它们是矩阵，所以在这里加一个$F$（Frobenius范数，编号1所示），这实际上是计算两个矩阵对应元素相减的平方的和，我们把这个式子展开，从$k$和$k'$开始作它们的差，把对应的式子写下来，然后把得到的结果都加起来，作者在这里使用了一个归一化常数，也就是$\frac{1}{2n_{H}^{[l]l}n_{W}^{[l]}n_{C}^{[l]} }$，再在外面加一个平方，但是一般情况下你不用写这么多，一般我们只要将它乘以一个超参数$\beta$就行。 最后，这是对$l$层定义的风格代价函数，和之前你见到的一样，这是两个矩阵间一个基本的Frobenius范数，也就是$S$图像和$G$图像之间的范数再乘上一个归一化常数，不过这不是很重要。实际上，如果你对各层都使用风格代价函数，会让结果变得更好。如果要对各层都使用风格代价函数，你可以这么定义代价函数，把各个层的结果（各层的风格代价函数）都加起来，这样就能定义它们全体了。我们还需要对每个层定义权重，也就是一些额外的超参数，我们用$\lambda^{[l]}$来表示，这样将使你能够在神经网络中使用不同的层，包括之前的一些可以测量类似边缘这样的低级特征的层，以及之后的一些能测量高级特征的层，使得我们的神经网络在计算风格时能够同时考虑到这些低级和高级特征的相关系数。这样，在基础的训练中你在定义超参数时，可以尽可能的得到更合理的选择。 为了把这些东西封装起来，你现在可以定义一个全体代价函数： $J(G) = a J_{\text{content}( C,G)} + \beta J_{ {style} }(S,G)$ 之后用梯度下降法，或者更复杂的优化算法来找到一个合适的图像$G$，并计算$J(G)$的最小值，这样的话，你将能够得到非常好看的结果，你将能够得到非常漂亮的结果。 这节神经风格迁移的内容就讲到这里，希望你能愉快地在本周的基础训练中进行实践。在本周结束之前，还有最后一节内容想告诉你们，就是如何对1D和3D的数据进行卷积，之前我们处理的都是2D图片，我们下节视频再见。 4.11 一维到三维推广（1D and 3D generalizations of models）你已经学习了许多关于卷积神经网络（ConvNets）的知识，从卷积神经网络框架，到如何使用它进行图像识别、对象检测、人脸识别与神经网络转换。即使我们大部分讨论的图像数据，某种意义上而言都是2D数据，考虑到图像如此普遍，许多你所掌握的思想不仅局限于2D图像，甚至可以延伸至1D，乃至3D数据。 让我们回头看看在第一周课程中你所学习关于2D卷积，你可能会输入一个14×14的图像，并使用一个5×5的过滤器进行卷积，接下来你看到了14×14图像是如何与5×5的过滤器进行卷积的，通过这个操作你会得到10×10的输出。 如果你使用了多通道，比如14×14×3，那么相匹配的过滤器可能是5×5×3，如果你使用了多重过滤，比如16，最终你得到的是10×10×16。 事实证明早期想法也同样可以用于1维数据，举个例子，左边是一个EKG信号，或者说是心电图，当你在你的胸部放置一个电极，电极透过胸部测量心跳带来的微弱电流，正因为心脏跳动，产生的微弱电波能被一组电极测量，这就是人心跳产生的EKG，每一个峰值都对应着一次心跳。 如果你想使用EKG信号，比如医学诊断，那么你将处理1维数据，因为EKG数据是由时间序列对应的每个瞬间的电压组成，这次不是一个14×14的尺寸输入，你可能只有一个14尺寸输入，在这种情况下你可能需要使用一个1维过滤进行卷积，你只需要一个1×5的过滤器，而不是一个5×5的。 二维数据的卷积是将同一个5×5特征检测器应用于图像中不同的位置（编号1所示），你最后会得到10×10的输出结果。1维过滤器可以取代你的5维过滤器（编号2所示），可在不同的位置中应用类似的方法（编号3，4，5所示）。 当你对这个1维信号使用卷积，你将发现一个14维的数据与5维数据进行卷积，并产生一个10维输出。 再一次如果你使用多通道，在这种场景下可能会获得一个14×1的通道。如果你使用一个EKG，就是5×1的，如果你有16个过滤器，可能你最后会获得一个10×16的数据，这可能会是你卷积网络中的某一层。 对于卷积网络的下一层，如果输入一个10×16数据，你也可以使用一个5维过滤器进行卷积，这需要16个通道进行匹配，如果你有32个过滤器，另一层的输出结果就是6×32，如果你使用了32个过滤器的话。 对于2D数据而言，当你处理10×10×16的数据时也是类似的，你可以使用5×5×16进行卷积，其中两个通道数16要相匹配，你将得到一个6×6的输出，如果你用的是32过滤器，输出结果就是6×6×32，这也是32的来源。 所有这些方法也可以应用于1维数据，你可以在不同的位置使用相同的特征检测器，比如说，为了区分EKG信号中的心跳的差异，你可以在不同的时间轴位置使用同样的特征来检测心跳。 所以卷积网络同样可以被用于1D数据，对于许多1维数据应用，你实际上会使用递归神经网络进行处理，这个网络你会在下一个课程中学到，但是有些人依旧愿意尝试使用卷积网络解决这些问题。 下一门课将讨论序列模型，包括递归神经网络、LCM与其他类似模型。我们将探讨使用1D卷积网络的优缺点，对比于其它专门为序列数据而精心设计的模型。 这也是2D向1D的进化，对于3D数据来说如何呢？什么是3D数据？与1D数列或数字矩阵不同，你现在有了一个3D块，一个3D输入数据。以你做CT扫描为例，这是一种使用X光照射，然后输出身体的3D模型，CT扫描实现的是它可以获取你身体不同片段（图片信息）。 当你进行CT扫描时，与我现在做的事情一样，你可以看到人体躯干的不同切片（整理者注：图中所示为人体躯干中不同层的切片，附CT扫描示意图，图片源于互联网），本质上这个数据是3维的。 一种对这份数据的理解方式是，假设你的数据现在具备一定长度、宽度与高度，其中每一个切片都与躯干的切片对应。 如果你想要在3D扫描或CT扫描中应用卷积网络进行特征识别，你也可以从第一张幻灯片（Convolutions in 2D and 1D）里得到想法，并将其应用到3D卷积中。为了简单起见，如果你有一个3D对象，比如说是14×14×14，这也是输入CT扫描的宽度与深度（后两个14）。再次提醒，正如图像不是必须以矩形呈现，3D对象也不是一定是一个完美立方体，所以长和宽可以不一样，同样CT扫描结果的长宽高也可以是不一致的。为了简化讨论，我仅使用14×14×14为例。 如果你现在使用5×5×5过滤器进行卷积，你的过滤器现在也是3D的，这将会给你一个10×10×10的结果输出，技术上来说你也可以再×1（编号1所示），如果这有一个1的通道。这仅仅是一个3D模块，但是你的数据可以有不同数目的通道，那种情况下也是乘1（编号2所示），因为通道的数目必须与过滤器匹配。如果你使用16过滤器处理5×5×5×1，接下来的输出将是10×10×10×16，这将成为你3D数据卷积网络上的一层。 如果下一层卷积使用5×5×5×16维度的过滤器再次卷积，通道数目也与往常一样匹配，如果你有32个过滤器，操作也与之前相同，最终你得到一个6×6×6×32的输出。 某种程度上3D数据也可以使用3D卷积网络学习，这些过滤器实现的功能正是通过你的3D数据进行特征检测。CT医疗扫描是3D数据的一个实例，另一个数据处理的例子是你可以将电影中随时间变化的不同视频切片看作是3D数据，你可以将这个技术用于检测动作及人物行为。 总而言之这就是1D、2D及3D数据处理，图像数据无处不在，以至于大多数卷积网络都是基于图像上的2D数据，但我希望其他模型同样会对你有帮助。 这是本周最后一次视频，也是最后一次关于卷积神经网络的课程，你已经学习了许多关于卷积网络的知识，我希望你能够在未来工作中发现许多思想对你有所裨益，祝贺你完成了这些视频学习，我希望你能喜欢这周的课后练习，接下来关于顺序模型的课程我们不见不散。]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达深度学习笔记(第二课时)]]></title>
    <url>%2F2019%2F12%2F05%2Fnew_%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E7%AC%AC%E4%BA%8C%E8%AF%BE%E6%97%B6)%2F</url>
    <content type="text"><![CDATA[吴恩达深度学习笔记 改善深层神经网络：超参数调试、正则化以及优化(Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)第一周：深度学习的实践层面(Practical aspects of Deep Learning)1.1 训练，验证，测试集（Train / Dev / Test sets）大家可能已经了解了，那么本周，我们将继续学习如何有效运作神经网络，内容涉及超参数调优，如何构建数据，以及如何确保优化算法快速运行，从而使学习算法在合理时间内完成自我学习。 第一周，我们首先说说神经网络机器学习中的问题，然后是随机神经网络，还会学习一些确保神经网络正确运行的技巧，带着这些问题，我们开始今天的课程。 在配置训练、验证和测试数据集的过程中做出正确决策会在很大程度上帮助大家创建高效的神经网络。训练神经网络时，我们需要做出很多决策，例如： 神经网络分多少层 每层含有多少个隐藏单元 学习速率是多少 各层采用哪些激活函数 创建新应用的过程中，我们不可能从一开始就准确预测出这些信息和其他超级参数。实际上，应用型机器学习是一个高度迭代的过程，通常在项目启动时，我们会先有一个初步想法，比如构建一个含有特定层数，隐藏单元数量或数据集个数等等的神经网络，然后编码，并尝试运行这些代码，通过运行和测试得到该神经网络或这些配置信息的运行结果，你可能会根据输出结果重新完善自己的想法，改变策略，或者为了找到更好的神经网络不断迭代更新自己的方案。 现如今，深度学习已经在自然语言处理，计算机视觉，语音识别以及结构化数据应用等众多领域取得巨大成功。结构化数据无所不包，从广告到网络搜索。其中网络搜索不仅包括网络搜索引擎，还包括购物网站，从所有根据搜索栏词条传输结果的网站。再到计算机安全，物流，比如判断司机去哪接送货，范围之广，不胜枚举。 我发现，可能有自然语言处理方面的人才想踏足计算机视觉领域，或者经验丰富的语音识别专家想投身广告行业，又或者，有的人想从电脑安全领域跳到物流行业，在我看来，从一个领域或者应用领域得来的直觉经验，通常无法转移到其他应用领域，最佳决策取决于你所拥有的数据量，计算机配置中输入特征的数量，用GPU训练还是CPU，GPU和CPU的具体配置以及其他诸多因素。 目前为止，我觉得，对于很多应用系统，即使是经验丰富的深度学习行家也不太可能一开始就预设出最匹配的超级参数，所以说，应用深度学习是一个典型的迭代过程，需要多次循环往复，才能为应用程序找到一个称心的神经网络，因此循环该过程的效率是决定项目进展速度的一个关键因素，而创建高质量的训练数据集，验证集和测试集也有助于提高循环效率。 假设这是训练数据，我用一个长方形表示，我们通常会将这些数据划分成几部分，一部分作为训练集，一部分作为简单交叉验证集，有时也称之为验证集，方便起见，我就叫它验证集（dev set），其实都是同一个概念，最后一部分则作为测试集。 接下来，我们开始对训练集执行算法，通过验证集或简单交叉验证集选择最好的模型，经过充分验证，我们选定了最终模型，然后就可以在测试集上进行评估了，为了无偏评估算法的运行状况。 在机器学习发展的小数据量时代，常见做法是将所有数据三七分，就是人们常说的70%训练集，30%测试集。如果明确设置了验证集，也可以按照60%训练集，20%验证集和20%测试集来划分。这是前几年机器学习领域普遍认可的最好的实践方法。 如果只有100条，1000条或者1万条数据，那么上述比例划分是非常合理的。 但是在大数据时代，我们现在的数据量可能是百万级别，那么验证集和测试集占数据总量的比例会趋向于变得更小。因为验证集的目的就是验证不同的算法，检验哪种算法更有效，因此，验证集只要足够大到能评估不同的算法，比如2个甚至10个不同算法，并迅速判断出哪种算法更有效。我们可能不需要拿出20%的数据作为验证集。 比如我们有100万条数据，那么取1万条数据便足以进行评估，找出其中表现最好的1-2种算法。同样地，根据最终选择的分类器，测试集的主要目的是正确评估分类器的性能，所以，如果拥有百万数据，我们只需要1000条数据，便足以评估单个分类器，并且准确评估该分类器的性能。假设我们有100万条数据，其中1万条作为验证集，1万条作为测试集，100万里取1万，比例是1%，即：训练集占98%，验证集和测试集各占1%。对于数据量过百万的应用，训练集可以占到99.5%，验证和测试集各占0.25%，或者验证集占0.4%，测试集占0.1%。 总结一下，在机器学习中，我们通常将样本分成训练集，验证集和测试集三部分，数据集规模相对较小，适用传统的划分比例，数据集规模较大的，验证集和测试集要小于数据总量的20%或10%。后面我会给出如何划分验证集和测试集的具体指导。 现代深度学习的另一个趋势是越来越多的人在训练和测试集分布不匹配的情况下进行训练，假设你要构建一个用户可以上传大量图片的应用程序，目的是找出并呈现所有猫咪图片，可能你的用户都是爱猫人士，训练集可能是从网上下载的猫咪图片，而验证集和测试集是用户在这个应用上上传的猫的图片，就是说，训练集可能是从网络上抓下来的图片。而验证集和测试集是用户上传的图片。结果许多网页上的猫咪图片分辨率很高，很专业，后期制作精良，而用户上传的照片可能是用手机随意拍摄的，像素低，比较模糊，这两类数据有所不同，针对这种情况，根据经验，我建议大家要确保验证集和测试集的数据来自同一分布，关于这个问题我也会多讲一些。因为你们要用验证集来评估不同的模型，尽可能地优化性能。如果验证集和测试集来自同一个分布就会很好。 但由于深度学习算法需要大量的训练数据，为了获取更大规模的训练数据集，我们可以采用当前流行的各种创意策略，例如，网页抓取，代价就是训练集数据与验证集和测试集数据有可能不是来自同一分布。但只要遵循这个经验法则，你就会发现机器学习算法会变得更快。我会在后面的课程中更加详细地解释这条经验法则。 最后一点，就算没有测试集也不要紧，测试集的目的是对最终所选定的神经网络系统做出无偏估计，如果不需要无偏估计，也可以不设置测试集。所以如果只有验证集，没有测试集，我们要做的就是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估。当然，如果你不需要无偏估计，那就再好不过了。 在机器学习中，如果只有一个训练集和一个验证集，而没有独立的测试集，遇到这种情况，训练集还被人们称为训练集，而验证集则被称为测试集，不过在实际应用中，人们只是把测试集当成简单交叉验证集使用，并没有完全实现该术语的功能，因为他们把验证集数据过度拟合到了测试集中。如果某团队跟你说他们只设置了一个训练集和一个测试集，我会很谨慎，心想他们是不是真的有训练验证集，因为他们把验证集数据过度拟合到了测试集中，让这些团队改变叫法，改称其为“训练验证集”，而不是“训练测试集”，可能不太容易。即便我认为“训练验证集“在专业用词上更准确。实际上，如果你不需要无偏评估算法性能，那么这样是可以的。 所以说，搭建训练验证集和测试集能够加速神经网络的集成，也可以更有效地衡量算法地偏差和方差，从而帮助我们更高效地选择合适方法来优化算法。 1.2 偏差，方差（Bias /Variance）我注意到，几乎所有机器学习从业人员都期望深刻理解偏差和方差，这两个概念易学难精，即使你自己认为已经理解了偏差和方差的基本概念，却总有一些意想不到的新东西出现。关于深度学习的误差问题，另一个趋势是对偏差和方差的权衡研究甚浅，你可能听说过这两个概念，但深度学习的误差很少权衡二者，我们总是分别考虑偏差和方差，却很少谈及偏差和方差的权衡问题，下面我们来一探究竟。 假设这就是数据集，如果给这个数据集拟合一条直线，可能得到一个逻辑回归拟合，但它并不能很好地拟合该数据，这是高偏差（high bias）的情况，我们称为“欠拟合”（underfitting）。 相反的如果我们拟合一个非常复杂的分类器，比如深度神经网络或含有隐藏单元的神经网络，可能就非常适用于这个数据集，但是这看起来也不是一种很好的拟合方式分类器方差较高（high variance），数据过度拟合（overfitting）。 在两者之间，可能还有一些像图中这样的，复杂程度适中，数据拟合适度的分类器，这个数据拟合看起来更加合理，我们称之为“适度拟合”（just right）是介于过度拟合和欠拟合中间的一类。 在这样一个只有$x_1$和$x_2$两个特征的二维数据集中，我们可以绘制数据，将偏差和方差可视化。在多维空间数据中，绘制数据和可视化分割边界无法实现，但我们可以通过几个指标，来研究偏差和方差。 我们沿用猫咪图片分类这个例子，左边一张是猫咪图片，右边一张不是。理解偏差和方差的两个关键数据是训练集误差（Train set error）和验证集误差（Dev set error），为了方便论证，假设我们可以辨别图片中的小猫，我们用肉眼识别几乎是不会出错的。 假定训练集误差是1%，为了方便论证，假定验证集误差是11%，可以看出训练集设置得非常好，而验证集设置相对较差，我们可能过度拟合了训练集，在某种程度上，验证集并没有充分利用交叉验证集的作用，像这种情况，我们称之为“高方差”。 通过查看训练集误差和验证集误差，我们便可以诊断算法是否具有高方差。也就是说衡量训练集和验证集误差就可以得出不同结论。 假设训练集误差是15%，我们把训练集误差写在首行，验证集误差是16%，假设该案例中人的错误率几乎为0%，人们浏览这些图片，分辨出是不是猫。算法并没有在训练集中得到很好训练，如果训练数据的拟合度不高，就是数据欠拟合，就可以说这种算法偏差比较高。相反，它对于验证集产生的结果却是合理的，验证集中的错误率只比训练集的多了1%，所以这种算法偏差高，因为它甚至不能拟合训练集，这与上一张幻灯片最左边的图片相似。 再举一个例子，训练集误差是15%，偏差相当高，但是，验证集的评估结果更糟糕，错误率达到30%，在这种情况下，我会认为这种算法偏差高，因为它在训练集上结果不理想，而且方差也很高，这是方差偏差都很糟糕的情况。 再看最后一个例子，训练集误差是0.5%，验证集误差是1%，用户看到这样的结果会很开心，猫咪分类器只有1%的错误率，偏差和方差都很低。 有一点我先在这个简单提一下，具体的留在后面课程里讲，这些分析都是基于假设预测的，假设人眼辨别的错误率接近0%，一般来说，最优误差也被称为贝叶斯误差，所以，最优误差接近0%，我就不在这里细讲了，如果最优误差或贝叶斯误差非常高，比如15%。我们再看看这个分类器（训练误差15%，验证误差16%），15%的错误率对训练集来说也是非常合理的，偏差不高，方差也非常低。 当所有分类器都不适用时，如何分析偏差和方差呢？比如，图片很模糊，即使是人眼，或者没有系统可以准确无误地识别图片，在这种情况下，最优误差会更高，那么分析过程就要做些改变了，我们暂时先不讨论这些细微差别，重点是通过查看训练集误差，我们可以判断数据拟合情况，至少对于训练数据是这样，可以判断是否有偏差问题，然后查看错误率有多高。当完成训练集训练，开始使用验证集验证时，我们可以判断方差是否过高，从训练集到验证集的这个过程中，我们可以判断方差是否过高。 以上分析的前提都是假设基本误差很小，训练集和验证集数据来自相同分布，如果没有这些假设作为前提，分析过程更加复杂，我们将会在稍后课程里讨论。 上一张幻灯片，我们讲了高偏差和高方差的情况，大家应该对优质分类器有了一定的认识，偏差和方差都高是什么样子呢？这种情况对于两个衡量标准来说都是非常糟糕的。 我们之前讲过，这样的分类器，会产生高偏差，因为它的数据拟合度低，像这种接近线性的分类器，数据拟合度低。 但是如果我们稍微改变一下分类器，我用紫色笔画出，它会过度拟合部分数据，用紫色线画出的分类器具有高偏差和高方差，偏差高是因为它几乎是一条线性分类器，并未拟合数据。 这种二次曲线能够很好地拟合数据。 这条曲线中间部分灵活性非常高，却过度拟合了这两个样本，这类分类器偏差很高，因为它几乎是线性的。 而采用曲线函数或二次元函数会产生高方差，因为它曲线灵活性太高以致拟合了这两个错误样本和中间这些活跃数据。 这看起来有些不自然，从两个维度上看都不太自然，但对于高维数据，有些数据区域偏差高，有些数据区域方差高，所以在高维数据中采用这种分类器看起来就不会那么牵强了。 总结一下，我们讲了如何通过分析在训练集上训练算法产生的误差和验证集上验证算法产生的误差来诊断算法是否存在高偏差和高方差，是否两个值都高，或者两个值都不高，根据算法偏差和方差的具体情况决定接下来你要做的工作，下节课，我会根据算法偏差和方差的高低情况讲解一些机器学习的基本方法，帮助大家更系统地优化算法，我们下节课见。 1.3 机器学习基础（Basic Recipe for Machine Learning）上节课我们讲的是如何通过训练误差和验证集误差判断算法偏差或方差是否偏高，帮助我们更加系统地在机器学习中运用这些方法来优化算法性能。 下图就是我在训练神经网络用到的基本方法：（尝试这些方法，可能有用，可能没用） 这是我在训练神经网络时用到地基本方法，初始模型训练完成后，我首先要知道算法的偏差高不高，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至无法拟合训练集，那么你要做的就是选择一个新的网络，比如含有更多隐藏层或者隐藏单元的网络，或者花费更多时间来训练网络，或者尝试更先进的优化算法，后面我们会讲到这部分内容。你也可以尝试其他方法，可能有用，也可能没用。 一会儿我们会看到许多不同的神经网络架构，或许你能找到一个更合适解决此问题的新的网络架构，加上括号，因为其中一条就是你必须去尝试，可能有用，也可能没用，不过采用规模更大的网络通常都会有所帮助，延长训练时间不一定有用，但也没什么坏处。训练学习算法时，我会不断尝试这些方法，直到解决掉偏差问题，这是最低标准，反复尝试，直到可以拟合数据为止，至少能够拟合训练集。 如果网络足够大，通常可以很好的拟合训练集，只要你能扩大网络规模，如果图片很模糊，算法可能无法拟合该图片，但如果有人可以分辨出图片，如果你觉得基本误差不是很高，那么训练一个更大的网络，你就应该可以……至少可以很好地拟合训练集，至少可以拟合或者过拟合训练集。一旦偏差降低到可以接受的数值，检查一下方差有没有问题，为了评估方差，我们要查看验证集性能，我们能从一个性能理想的训练集推断出验证集的性能是否也理想，如果方差高，最好的解决办法就是采用更多数据，如果你能做到，会有一定的帮助，但有时候，我们无法获得更多数据，我们也可以尝试通过正则化来减少过拟合，这个我们下节课会讲。有时候我们不得不反复尝试，但是，如果能找到更合适的神经网络框架，有时它可能会一箭双雕，同时减少方差和偏差。如何实现呢？想系统地说出做法很难，总之就是不断重复尝试，直到找到一个低偏差，低方差的框架，这时你就成功了。 有两点需要大家注意： 第一点，高偏差和高方差是两种不同的情况，我们后续要尝试的方法也可能完全不同，我通常会用训练验证集来诊断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方法。举个例子，如果算法存在高偏差问题，准备更多训练数据其实也没什么用处，至少这不是更有效的方法，所以大家要清楚存在的问题是偏差还是方差，还是两者都有问题，明确这一点有助于我们选择出最有效的方法。 第二点，在机器学习的初期阶段，关于所谓的偏差方差权衡的讨论屡见不鲜，原因是我们能尝试的方法有很多。可以增加偏差，减少方差，也可以减少偏差，增加方差，但是在深度学习的早期阶段，我们没有太多工具可以做到只减少偏差或方差却不影响到另一方。但在当前的深度学习和大数据时代，只要持续训练一个更大的网络，只要准备了更多数据，那么也并非只有这两种情况，我们假定是这样，那么，只要正则适度，通常构建一个更大的网络便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。这两步实际要做的工作是：训练网络，选择网络或者准备更多数据，现在我们有工具可以做到在减少偏差或方差的同时，不对另一方产生过多不良影响。我觉得这就是深度学习对监督式学习大有裨益的一个重要原因，也是我们不用太过关注如何平衡偏差和方差的一个重要原因，但有时我们有很多选择，减少偏差或方差而不增加另一方。最终，我们会得到一个非常规范化的网络。从下节课开始，我们将讲解正则化，训练一个更大的网络几乎没有任何负面影响，而训练一个大型神经网络的主要代价也只是计算时间，前提是网络是比较规范化的。 今天我们讲了如何通过组织机器学习来诊断偏差和方差的基本方法，然后选择解决问题的正确操作，希望大家有所了解和认识。我在课上不止一次提到了正则化，它是一种非常实用的减少方差的方法，正则化时会出现偏差方差权衡问题，偏差可能略有增加，如果网络足够大，增幅通常不会太高，我们下节课再细讲，以便大家更好理解如何实现神经网络的正则化。 1.4 正则化（Regularization）深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。 如果你怀疑神经网络过度拟合了数据，即存在高方差问题，那么最先想到的方法可能是正则化，另一个解决高方差的方法就是准备更多数据，这也是非常可靠的办法，但你可能无法时时准备足够多的训练数据，或者，获取更多数据的成本很高，但正则化有助于避免过度拟合，或者减少网络误差，下面我们就来讲讲正则化的作用原理。 我们用逻辑回归来实现这些设想，求成本函数$J$的最小值，它是我们定义的成本函数，参数包含一些训练数据和不同数据中个体预测的损失，$w$和$b$是逻辑回归的两个参数，$w$是一个多维度参数矢量，$b$是一个实数。在逻辑回归函数中加入正则化，只需添加参数λ，也就是正则化参数，一会儿再详细讲。 $\frac{\lambda}{2m}$乘以$w$范数的平方，其中$\left\| w \right\|_2^2$是$w$的欧几里德范数的平方，等于$w_{j}$（$j$ 值从1到$n_{x}$）平方的和，也可表示为$w^{T}w$，也就是向量参数$w$ 的欧几里德范数（2范数）的平方，此方法称为$L2$正则化，因为这里用了欧几里德范数，被称为向量参数$w$的$L2$范数。 为什么只正则化参数$w$？为什么不再加上参数 $b$ 呢？你可以这么做，只是我习惯省略不写，因为$w$通常是一个高维参数矢量，已经可以表达高偏差问题，$w$可能包含有很多参数，我们不可能拟合所有参数，而$b$只是单个数字，所以$w$几乎涵盖所有参数，而不是$b$，如果加了参数$b$，其实也没太大影响，因为$b$只是众多参数中的一个，所以我通常省略不计，如果你想加上这个参数，完全没问题。 $L2$正则化是最常见的正则化类型，你们可能听说过$L1$正则化，$L1$正则化，加的不是$L2$范数，而是正则项$\frac{\lambda}{m}$乘以$\sum_{j= 1}^{n_{x} }{|w|}$，$\sum_{j =1}^{n_{x} }{|w|}$也被称为参数$w$向量的$L1$范数，无论分母是$m$还是$2m$，它都是一个比例常量。 如果用的是$L1$正则化，$w$最终会是稀疏的，也就是说$w$向量中有很多0，有人说这样有利于压缩模型，因为集合中参数均为0，存储模型所占用的内存更少。实际上，虽然$L1$正则化使模型变得稀疏，却没有降低太多存储内存，所以我认为这并不是$L1$正则化的目的，至少不是为了压缩模型，人们在训练网络时，越来越倾向于使用$L2$正则化。 我们来看最后一个细节，$\lambda$是正则化参数，我们通常使用验证集或交叉验证集来配置这个参数，尝试各种各样的数据，寻找最好的参数，我们要考虑训练集之间的权衡，把参数设置为较小值，这样可以避免过拟合，所以λ是另外一个需要调整的超级参数，顺便说一下，为了方便写代码，在Python编程语言中，$\lambda$是一个保留字段，编写代码时，我们删掉$a$，写成$lambd$，以免与Python中的保留字段冲突，这就是在逻辑回归函数中实现$L2$正则化的过程，如何在神经网络中实现$L2$正则化呢？ 神经网络含有一个成本函数，该函数包含$W^{[1]}$，$b^{[1]}$到$W^{[l]}$，$b^{[l]}$所有参数，字母$L$是神经网络所含的层数，因此成本函数等于$m$个训练样本损失函数的总和乘以$\frac{1}{m}$，正则项为$\frac{\lambda }{2m}{ {\sum\nolimits_{1}^{L}{| { {W}^{[l]} }|} }^{2} }$，我们称${||W^{\left[l\right]}||}^{2}$为范数平方，这个矩阵范数${||W^{\left[l\right]}||}^{2}$（即平方范数），被定义为矩阵中所有元素的平方求和， 我们看下求和公式的具体参数，第一个求和符号其值$i$从1到$n^{[l - 1]}$，第二个其$J$值从1到$n^{[l]}$，因为$W$是一个$n^{[l]}\times n^{[l-1]}$的多维矩阵，$n^{[l]}$表示$l$ 层单元的数量，$n^{[l-1]}$表示第$l-1$层隐藏单元的数量。 该矩阵范数被称作“弗罗贝尼乌斯范数”，用下标$F$标注”，鉴于线性代数中一些神秘晦涩的原因，我们不称之为“矩阵$L2$范数”，而称它为“弗罗贝尼乌斯范数”，矩阵$L2$范数听起来更自然，但鉴于一些大家无须知道的特殊原因，按照惯例，我们称之为“弗罗贝尼乌斯范数”，它表示一个矩阵中所有元素的平方和。 该如何使用该范数实现梯度下降呢？ 用backprop计算出$dW$的值，backprop会给出$J$对$W$的偏导数，实际上是$ W^{[l]}$，把$W^{[l]}$替换为$W^{[l]}$减去学习率乘以$dW$。 这就是之前我们额外增加的正则化项，既然已经增加了这个正则项，现在我们要做的就是给$dW$加上这一项$\frac {\lambda}{m}W^{[l]}$，然后计算这个更新项，使用新定义的$dW^{[l]}$，它的定义含有相关参数代价函数导数和，以及最后添加的额外正则项，这也是$L2$正则化有时被称为“权重衰减”的原因。 我们用$ dW^{[l]}$的定义替换此处的$dW^{[l]}$，可以看到，$W^{[l]}$的定义被更新为$W^{[l]}$减去学习率$\alpha$ 乘以backprop 再加上$\frac{\lambda}{m}W^{[l]}$。 该正则项说明，不论$W^{[l]}$是什么，我们都试图让它变得更小，实际上，相当于我们给矩阵W乘以$(1 - \alpha\frac{\lambda}{m})$倍的权重，矩阵$W$减去$\alpha\frac{\lambda}{m}$倍的它，也就是用这个系数$(1-\alpha\frac{\lambda}{m})$乘以矩阵$W$，该系数小于1，因此$L2$范数正则化也被称为“权重衰减”，因为它就像一般的梯度下降，$W$被更新为少了$\alpha$乘以backprop输出的最初梯度值，同时$W$也乘以了这个系数，这个系数小于1，因此$L2$正则化也被称为“权重衰减”。 我不打算这么叫它，之所以叫它“权重衰减”是因为这两项相等，权重指标乘以了一个小于1的系数。 以上就是在神经网络中应用$L2$正则化的过程，有人会问我，为什么正则化可以预防过拟合，我们放在下节课讲，同时直观感受一下正则化是如何预防过拟合的。 1.5 为什么正则化有利于预防过拟合呢？（Why regularization reduces overfitting?）为什么正则化有利于预防过拟合呢？为什么它可以减少方差问题？我们通过两个例子来直观体会一下。 左图是高偏差，右图是高方差，中间是Just Right，这几张图我们在前面课程中看到过。 现在我们来看下这个庞大的深度拟合神经网络。我知道这张图不够大，深度也不够，但你可以想象这是一个过拟合的神经网络。这是我们的代价函数$J$，含有参数$W$，$b$。我们添加正则项，它可以避免数据权值矩阵过大，这就是弗罗贝尼乌斯范数，为什么压缩$L2$范数，或者弗罗贝尼乌斯范数或者参数可以减少过拟合？ 直观上理解就是如果正则化$\lambda$设置得足够大，权重矩阵$W$被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。 但是$\lambda$会存在一个中间值，于是会有一个接近“Just Right”的中间状态。 直观理解就是$\lambda$增加到足够大，$W$会接近于0，实际上是不会发生这种情况的，我们尝试消除或至少减少许多隐藏单元的影响，最终这个网络会变得更简单，这个神经网络越来越接近逻辑回归，我们直觉上认为大量隐藏单元被完全消除了，其实不然，实际上是该神经网络的所有隐藏单元依然存在，但是它们的影响变得更小了。神经网络变得更简单了，貌似这样更不容易发生过拟合，因此我不确定这个直觉经验是否有用，不过在编程中执行正则化时，你实际看到一些方差减少的结果。 我们再来直观感受一下，正则化为什么可以预防过拟合，假设我们用的是这样的双曲线激活函数。 用$g(z)$表示$tanh(z)$，我们发现如果 z 非常小，比如 z 只涉及很小范围的参数（图中原点附近的红色区域），这里我们利用了双曲正切函数的线性状态，只要$z$可以扩展为这样的更大值或者更小值，激活函数开始变得非线性。 现在你应该摒弃这个直觉，如果正则化参数λ很大，激活函数的参数会相对较小，因为代价函数中的参数变大了，如果$W$很小， 如果$W$很小，相对来说，$z$也会很小。 特别是，如果$z$的值最终在这个范围内，都是相对较小的值，$g(z)$大致呈线性，每层几乎都是线性的，和线性回归函数一样。 第一节课我们讲过，如果每层都是线性的，那么整个网络就是一个线性网络，即使是一个非常深的深层网络，因具有线性激活函数的特征，最终我们只能计算线性函数，因此，它不适用于非常复杂的决策，以及过度拟合数据集的非线性决策边界，如同我们在幻灯片中看到的过度拟合高方差的情况。 总结一下，如果正则化参数变得很大，参数$W$很小，$z$也会相对变小，此时忽略$b$的影响，$z$会相对变小，实际上，$z$的取值范围很小，这个激活函数，也就是曲线函数$tanh$会相对呈线性，整个神经网络会计算离线性函数近的值，这个线性函数非常简单，并不是一个极复杂的高度非线性函数，不会发生过拟合。 大家在编程作业里实现正则化的时候，会亲眼看到这些结果，总结正则化之前，我给大家一个执行方面的小建议，在增加正则化项时，应用之前定义的代价函数$J$，我们做过修改，增加了一项，目的是预防权重过大。 如果你使用的是梯度下降函数，在调试梯度下降时，其中一步就是把代价函数$J$设计成这样一个函数，在调试梯度下降时，它代表梯度下降的调幅数量。可以看到，代价函数对于梯度下降的每个调幅都单调递减。如果你实施的是正则化函数，请牢记，$J$已经有一个全新的定义。如果你用的是原函数$J$，也就是这第一个项正则化项，你可能看不到单调递减现象，为了调试梯度下降，请务必使用新定义的$J$函数，它包含第二个正则化项，否则函数$J$可能不会在所有调幅范围内都单调递减。 这就是$L2$正则化，它是我在训练深度学习模型时最常用的一种方法。在深度学习中，还有一种方法也用到了正则化，就是dropout正则化，我们下节课再讲。 1.6 dropout 正则化（Dropout Regularization）除了$L2$正则化，还有一个非常实用的正则化方法——“Dropout（随机失活）”，我们来看看它的工作原理。 假设你在训练上图这样的神经网络，它存在过拟合，这就是dropout所要处理的，我们复制这个神经网络，dropout会遍历网络的每一层，并设置消除神经网络中节点的概率。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用backprop方法进行训练。 这是网络节点精简后的一个样本，对于其它样本，我们照旧以抛硬币的方式设置概率，保留一类节点集合，删除其它类型的节点集合。对于每个训练样本，我们都将采用一个精简后神经网络来训练它，这种方法似乎有点怪，单纯遍历节点，编码也是随机的，可它真的有效。不过可想而知，我们针对每个训练样本训练规模小得多的网络，最后你可能会认识到为什么要正则化网络，因为我们在训练规模小得多的网络。 如何实施dropout呢？方法有几种，接下来我要讲的是最常用的方法，即inverted dropout（反向随机失活），出于完整性考虑，我们用一个三层（$l=3$）网络来举例说明。编码中会有很多涉及到3的地方。我只举例说明如何在某一层中实施dropout。 首先要定义向量$d$，$d^{[3]}$表示网络第三层的dropout向量： d3 = np.random.rand(a3.shape[0],a3.shape[1]) 然后看它是否小于某数，我们称之为keep-prob，keep-prob是一个具体数字，上个示例中它是0.5，而本例中它是0.8，它表示保留某个隐藏单元的概率，此处keep-prob等于0.8，它意味着消除任意一个隐藏单元的概率是0.2，它的作用就是生成随机矩阵，如果对$a^{[3]}$进行因子分解，效果也是一样的。$d^{[3]}$是一个矩阵，每个样本和每个隐藏单元，其中$d^{[3]}$中的对应值为1的概率都是0.8，对应为0的概率是0.2，随机数字小于0.8。它等于1的概率是0.8，等于0的概率是0.2。 接下来要做的就是从第三层中获取激活函数，这里我们叫它$a^{[3]}$，$a^{[3]}$含有要计算的激活函数，$a^{[3]}$等于上面的$a^{[3]}$乘以$d^{[3]}$，a3 =np.multiply(a3,d3)，这里是元素相乘，也可写为$a3*=d3$，它的作用就是让$d^{[3]}$中所有等于0的元素（输出），而各个元素等于0的概率只有20%，乘法运算最终把$d^{\left\lbrack3 \right]}$中相应元素输出，即让$d^{[3]}$中0元素与$a^{[3]}$中相对元素归零。 如果用python实现该算法的话，$d^{[3]}$则是一个布尔型数组，值为true和false，而不是1和0，乘法运算依然有效，python会把true和false翻译为1和0，大家可以用python尝试一下。 最后，我们向外扩展$a^{[3]}$，用它除以0.8，或者除以keep-prob参数。 下面我解释一下为什么要这么做，为方便起见，我们假设第三隐藏层上有50个单元或50个神经元，在一维上$a^{[3]}$是50，我们通过因子分解将它拆分成$50×m$维的，保留和删除它们的概率分别为80%和20%，这意味着最后被删除或归零的单元平均有10（50×20%=10）个，现在我们看下$z^{\lbrack4]}$，$z^{[4]} = w^{[4]} a^{[3]} + b^{[4]}$，我们的预期是，$a^{[3]}$减少20%，也就是说$a^{[3]}$中有20%的元素被归零，为了不影响$z^{\lbrack4]}$的期望值，我们需要用$w^{[4]} a^{[3]}/0.8$，它将会修正或弥补我们所需的那20%，$a^{[3]}$的期望值不会变，划线部分就是所谓的dropout方法。 它的功能是，不论keep-prop的值是多少0.8，0.9甚至是1，如果keep-prop设置为1，那么就不存在dropout，因为它会保留所有节点。反向随机失活（inverted dropout）方法通过除以keep-prob，确保$a^{[3]}$的期望值不变。 事实证明，在测试阶段，当我们评估一个神经网络时，也就是用绿线框标注的反向随机失活方法，使测试阶段变得更容易，因为它的数据扩展问题变少，我们将在下节课讨论。 据我了解，目前实施dropout最常用的方法就是Inverted dropout，建议大家动手实践一下。Dropout早期的迭代版本都没有除以keep-prob，所以在测试阶段，平均值会变得越来越复杂，不过那些版本已经不再使用了。 现在你使用的是$d$向量，你会发现，不同的训练样本，清除不同的隐藏单元也不同。实际上，如果你通过相同训练集多次传递数据，每次训练数据的梯度不同，则随机对不同隐藏单元归零，有时却并非如此。比如，需要将相同隐藏单元归零，第一次迭代梯度下降时，把一些隐藏单元归零，第二次迭代梯度下降时，也就是第二次遍历训练集时，对不同类型的隐藏层单元归零。向量$d$或$d^{[3]}$用来决定第三层中哪些单元归零，无论用foreprop还是backprop，这里我们只介绍了foreprob。 如何在测试阶段训练算法，在测试阶段，我们已经给出了$x$，或是想预测的变量，用的是标准计数法。我用$a^{\lbrack0]}$，第0层的激活函数标注为测试样本$x$，我们在测试阶段不使用dropout函数，尤其是像下列情况： $z^{[1]} = w^{[1]} a^{[0]} + b^{[1]}$ $a^{[1]} = g^{[1]}(z^{[1]})$ $z^{[2]} = \ w^{[2]} a^{[1]} + b^{[2]}$ $a^{[2]} = \ldots$ 以此类推直到最后一层，预测值为$\hat{y}$。 显然在测试阶段，我们并未使用dropout，自然也就不用抛硬币来决定失活概率，以及要消除哪些隐藏单元了，因为在测试阶段进行预测时，我们不期望输出结果是随机的，如果测试阶段应用dropout函数，预测会受到干扰。理论上，你只需要多次运行预测处理过程，每一次，不同的隐藏单元会被随机归零，预测处理遍历它们，但计算效率低，得出的结果也几乎相同，与这个不同程序产生的结果极为相似。 Inverted dropout函数在除以keep-prob时可以记住上一步的操作，目的是确保即使在测试阶段不执行dropout来调整数值范围，激活函数的预期结果也不会发生变化，所以没必要在测试阶段额外添加尺度参数，这与训练阶段不同。 $l=keep-prob$ 这就是dropout，大家可以通过本周的编程练习来执行这个函数，亲身实践一下。 为什么dropout会起作用呢？下节课我们将更加直观地了解dropout的具体功能。 1.7 理解 dropout（Understanding Dropout）Dropout可以随机删除网络中的神经单元，他为什么可以通过正则化发挥如此大的作用呢？ 直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的$L2$正则化类似；实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；$L2$对不同权重的衰减是不同的，它取决于激活函数倍增的大小。 总结一下，dropout的功能类似于$L2$正则化，与$L2$正则化不同的是应用方式不同会带来一点点小变化，甚至更适用于不同的输入范围。 第二个直观认识是，我们从单个神经元入手，如图，这个单元的工作就是输入并生成一些有意义的输出。通过dropout，该单元的输入几乎被消除，有时这两个单元会被删除，有时会删除其它单元，就是说，我用紫色圈起来的这个单元，它不能依靠任何特征，因为特征都有可能被随机清除，或者说该单元的输入也都可能被随机清除。我不愿意把所有赌注都放在一个节点上，不愿意给任何一个输入加上太多权重，因为它可能会被删除，因此该单元将通过这种方式积极地传播开，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和我们之前讲过的$L2$正则化类似，实施dropout的结果是它会压缩权重，并完成一些预防过拟合的外层正则化。 事实证明，dropout被正式地作为一种正则化的替代形式，$L2$对不同权重的衰减是不同的，它取决于倍增的激活函数的大小。 总结一下，dropout的功能类似于$L2$正则化，与$L2$正则化不同的是，被应用的方式不同，dropout也会有所不同，甚至更适用于不同的输入范围。 实施dropout的另一个细节是，这是一个拥有三个输入特征的网络，其中一个要选择的参数是keep-prob，它代表每一层上保留单元的概率。所以不同层的keep-prob也可以变化。第一层，矩阵$W^{[1]}$是7×3，第二个权重矩阵$W^{[2]}$是7×7，第三个权重矩阵$W^{[3]}$是3×7，以此类推，$W^{[2]}$是最大的权重矩阵，因为$W^{[2]}$拥有最大参数集，即7×7，为了预防矩阵的过拟合，对于这一层，我认为这是第二层，它的keep-prob值应该相对较低，假设是0.5。对于其它层，过拟合的程度可能没那么严重，它们的keep-prob值可能高一些，可能是0.7，这里是0.7。如果在某一层，我们不必担心其过拟合的问题，那么keep-prob可以为1，为了表达清除，我用紫色线笔把它们圈出来，每层keep-prob的值可能不同。 注意keep-prob的值是1，意味着保留所有单元，并且不在这一层使用dropout，对于有可能出现过拟合，且含有诸多参数的层，我们可以把keep-prob设置成比较小的值，以便应用更强大的dropout，有点像在处理$L2$正则化的正则化参数$\lambda$，我们尝试对某些层施行更多正则化，从技术上讲，我们也可以对输入层应用dropout，我们有机会删除一个或多个输入特征，虽然现实中我们通常不这么做，keep-prob的值为1，是非常常用的输入值，也可以用更大的值，或许是0.9。但是消除一半的输入特征是不太可能的，如果我们遵守这个准则，keep-prob会接近于1，即使你对输入层应用dropout。 总结一下，如果你担心某些层比其它层更容易发生过拟合，可以把某些层的keep-prob值设置得比其它层更低，缺点是为了使用交叉验证，你要搜索更多的超级参数，另一种方案是在一些层上应用dropout，而有些层不用dropout，应用dropout的层只含有一个超级参数，就是keep-prob。 结束前分享两个实施过程中的技巧，实施dropout，在计算机视觉领域有很多成功的第一次。计算视觉中的输入量非常大，输入太多像素，以至于没有足够的数据，所以dropout在计算机视觉中应用得比较频繁，有些计算机视觉研究人员非常喜欢用它，几乎成了默认的选择，但要牢记一点，dropout是一种正则化方法，它有助于预防过拟合，因此除非算法过拟合，不然我是不会使用dropout的，所以它在其它领域应用得比较少，主要存在于计算机视觉领域，因为我们通常没有足够的数据，所以一直存在过拟合，这就是有些计算机视觉研究人员如此钟情于dropout函数的原因。直观上我认为不能概括其它学科。 dropout一大缺点就是代价函数$J$不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。定义明确的代价函数$J$每次迭代后都会下降，因为我们所优化的代价函数$J$实际上并没有明确定义，或者说在某种程度上很难计算，所以我们失去了调试工具来绘制这样的图片。我通常会关闭dropout函数，将keep-prob的值设为1，运行代码，确保J函数单调递减。然后打开dropout函数，希望在dropout过程中，代码并未引入bug。我觉得你也可以尝试其它方法，虽然我们并没有关于这些方法性能的数据统计，但你可以把它们与dropout方法一起使用。 1.8 其他正则化方法（Other regularization methods）除了$L2$正则化和随机失活（dropout）正则化，还有几种方法可以减少神经网络中的过拟合: 一.数据扩增 假设你正在拟合猫咪图片分类器，如果你想通过扩增训练数据来解决过拟合，但扩增数据代价高，而且有时候我们无法扩增数据，但我们可以通过添加这类图片来增加训练集。例如，水平翻转图片，并把它添加到训练集。所以现在训练集中有原图，还有翻转后的这张图片，所以通过水平翻转图片，训练集则可以增大一倍，因为训练集有冗余，这虽然不如我们额外收集一组新图片那么好，但这样做节省了获取更多猫咪图片的花费。 除了水平翻转图片，你也可以随意裁剪图片，这张图是把原图旋转并随意放大后裁剪的，仍能辨别出图片中的猫咪。 通过随意翻转和裁剪图片，我们可以增大数据集，额外生成假训练数据。和全新的，独立的猫咪图片数据相比，这些额外的假的数据无法包含像全新数据那么多的信息，但我们这么做基本没有花费，代价几乎为零，除了一些对抗性代价。以这种方式扩增算法数据，进而正则化数据集，减少过拟合比较廉价。 像这样人工合成数据的话，我们要通过算法验证，图片中的猫经过水平翻转之后依然是猫。大家注意，我并没有垂直翻转，因为我们不想上下颠倒图片，也可以随机选取放大后的部分图片，猫可能还在上面。 对于光学字符识别，我们还可以通过添加数字，随意旋转或扭曲数字来扩增数据，把这些数字添加到训练集，它们仍然是数字。为了方便说明，我对字符做了强变形处理，所以数字4看起来是波形的，其实不用对数字4做这么夸张的扭曲，只要轻微的变形就好，我做成这样是为了让大家看的更清楚。实际操作的时候，我们通常对字符做更轻微的变形处理。因为这几个4看起来有点扭曲。所以，数据扩增可作为正则化方法使用，实际功能上也与正则化相似。 二.early stopping 还有另外一种常用的方法叫作early stopping，运行梯度下降时，我们可以绘制训练误差，或只绘制代价函数$J$的优化过程，在训练集上用0-1记录分类误差次数。呈单调下降趋势，如图。 因为在训练过程中，我们希望训练误差，代价函数$J$都在下降，通过early stopping，我们不但可以绘制上面这些内容，还可以绘制验证集误差，它可以是验证集上的分类误差，或验证集上的代价函数，逻辑损失和对数损失等，你会发现，验证集误差通常会先呈下降趋势，然后在某个节点处开始上升，early stopping的作用是，你会说，神经网络已经在这个迭代过程中表现得很好了，我们在此停止训练吧，得到验证集误差，它是怎么发挥作用的？ 当你还未在神经网络上运行太多迭代过程的时候，参数$w$接近0，因为随机初始化$w$值时，它的值可能都是较小的随机值，所以在你长期训练神经网络之前$w$依然很小，在迭代过程和训练过程中$w$的值会变得越来越大，比如在这儿，神经网络中参数$w$的值已经非常大了，所以early stopping要做就是在中间点停止迭代过程，我们得到一个$w$值中等大小的弗罗贝尼乌斯范数，与$L2$正则化相似，选择参数w范数较小的神经网络，但愿你的神经网络过度拟合不严重。 术语early stopping代表提早停止训练神经网络，训练神经网络时，我有时会用到early stopping，但是它也有一个缺点，我们来了解一下。 我认为机器学习过程包括几个步骤，其中一步是选择一个算法来优化代价函数$J$，我们有很多种工具来解决这个问题，如梯度下降，后面我会介绍其它算法，例如Momentum，RMSprop和Adam等等，但是优化代价函数$J$之后，我也不想发生过拟合，也有一些工具可以解决该问题，比如正则化，扩增数据等等。 在机器学习中，超级参数激增，选出可行的算法也变得越来越复杂。我发现，如果我们用一组工具优化代价函数$J$，机器学习就会变得更简单，在重点优化代价函数$J$时，你只需要留意$w$和$b$，$J(w,b)$的值越小越好，你只需要想办法减小这个值，其它的不用关注。然后，预防过拟合还有其他任务，换句话说就是减少方差，这一步我们用另外一套工具来实现，这个原理有时被称为“正交化”。思路就是在一个时间做一个任务，后面课上我会具体介绍正交化，如果你还不了解这个概念，不用担心。 但对我来说early stopping的主要缺点就是你不能独立地处理这两个问题，因为提早停止梯度下降，也就是停止了优化代价函数$J$，因为现在你不再尝试降低代价函数$J$，所以代价函数$J$的值可能不够小，同时你又希望不出现过拟合，你没有采取不同的方式来解决这两个问题，而是用一种方法同时解决两个问题，这样做的结果是我要考虑的东西变得更复杂。 如果不用early stopping，另一种方法就是$L2$正则化，训练神经网络的时间就可能很长。我发现，这导致超级参数搜索空间更容易分解，也更容易搜索，但是缺点在于，你必须尝试很多正则化参数$\lambda$的值，这也导致搜索大量$\lambda$值的计算代价太高。 Early stopping的优点是，只运行一次梯度下降，你可以找出$w$的较小值，中间值和较大值，而无需尝试$L2$正则化超级参数$\lambda$的很多值。 如果你还不能完全理解这个概念，没关系，下节课我们会详细讲解正交化，这样会更好理解。 虽然$L2$正则化有缺点，可还是有很多人愿意用它。吴恩达老师个人更倾向于使用$L2$正则化，尝试许多不同的$\lambda$值，假设你可以负担大量计算的代价。而使用early stopping也能得到相似结果，还不用尝试这么多$\lambda$值。 这节课我们讲了如何使用数据扩增，以及如何使用early stopping降低神经网络中的方差或预防过拟合。 1.9 归一化输入（Normalizing inputs）训练神经网络，其中一个加速训练的方法就是归一化输入。假设一个训练集有两个特征，输入特征为2维，归一化需要两个步骤： 零均值 归一化方差； 我们希望无论是训练集和测试集都是通过相同的$μ$和$σ^2$定义的数据转换，这两个是由训练集得出来的。 第一步是零均值化，$\mu = \frac{1}{m}\sum_{i =1}^{m}x^{(i)}$，它是一个向量，$x$等于每个训练数据 $x$减去$\mu$，意思是移动训练集，直到它完成零均值化。 第二步是归一化方差，注意特征$x_{1}$的方差比特征$x_{2}$的方差要大得多，我们要做的是给$\sigma$赋值，$\sigma^{2}= \frac{1}{m}\sum_{i =1}^{m}{({x^{(i)})}^{2} }$，这是节点$y$ 的平方，$\sigma^{2}$是一个向量，它的每个特征都有方差，注意，我们已经完成零值均化，$({x^{(i)})}^{2}$元素$y^{2}$就是方差，我们把所有数据除以向量$\sigma^{2}$，最后变成上图形式。 $x_{1}$和$x_{2}$的方差都等于1。提示一下，如果你用它来调整训练数据，那么用相同的 $μ$ 和 $\sigma^{2}$来归一化测试集。尤其是，你不希望训练集和测试集的归一化有所不同，不论$μ$的值是什么，也不论$\sigma^{2}$的值是什么，这两个公式中都会用到它们。所以你要用同样的方法调整测试集，而不是在训练集和测试集上分别预估$μ$ 和 $\sigma^{2}$。因为我们希望不论是训练数据还是测试数据，都是通过相同μ和$\sigma^{2}$定义的相同数据转换，其中$μ$和$\sigma^{2}$是由训练集数据计算得来的。 我们为什么要这么做呢？为什么我们想要归一化输入特征，回想一下右上角所定义的代价函数。 $J(w,b)=\frac{1}{m}\sum\limits_{i=1}^{m}{L({ {{\hat{y} }}^{(i)} },{ {y}^{(i)} })}$ 如果你使用非归一化的输入特征，代价函数会像这样： 这是一个非常细长狭窄的代价函数，你要找的最小值应该在这里。但如果特征值在不同范围，假如$x_{1}$取值范围从1到1000，特征$x_{2}$的取值范围从0到1，结果是参数$w_{1}$和$w_{2}$值的范围或比率将会非常不同，这些数据轴应该是$w_{1}$和$w_{2}$，但直观理解，我标记为$w$和$b$，代价函数就有点像狭长的碗一样，如果你能画出该函数的部分轮廓，它会是这样一个狭长的函数。 然而如果你归一化特征，代价函数平均起来看更对称，如果你在上图这样的代价函数上运行梯度下降法，你必须使用一个非常小的学习率。因为如果是在这个位置，梯度下降法可能需要多次迭代过程，直到最后找到最小值。但如果函数是一个更圆的球形轮廓，那么不论从哪个位置开始，梯度下降法都能够更直接地找到最小值，你可以在梯度下降法中使用较大步长，而不需要像在左图中那样反复执行。 当然，实际上$w$是一个高维向量，因此用二维绘制$w$并不能正确地传达并直观理解，但总地直观理解是代价函数会更圆一些，而且更容易优化，前提是特征都在相似范围内，而不是从1到1000，0到1的范围，而是在-1到1范围内或相似偏差，这使得代价函数$J$优化起来更简单快速。 实际上如果假设特征$x_{1}$范围在0-1之间，$x_{2}$的范围在-1到1之间，$x_{3}$范围在1-2之间，它们是相似范围，所以会表现得很好。 当它们在非常不同的取值范围内，如其中一个从1到1000，另一个从0到1，这对优化算法非常不利。但是仅将它们设置为均化零值，假设方差为1，就像上一张幻灯片里设定的那样，确保所有特征都在相似范围内，通常可以帮助学习算法运行得更快。 所以如果输入特征处于不同范围内，可能有些特征值从0到1，有些从1到1000，那么归一化特征值就非常重要了。如果特征值处于相似范围内，那么归一化就不是很重要了。执行这类归一化并不会产生什么危害，我通常会做归一化处理，虽然我不确定它能否提高训练或算法速度。 这就是归一化特征输入，下节课我们将继续讨论提升神经网络训练速度的方法。 1.10 梯度消失/梯度爆炸（Vanishing / Exploding gradients）训练神经网络，尤其是深度神经所面临的一个问题就是梯度消失或梯度爆炸，也就是你训练神经网络的时候，导数或坡度有时会变得非常大，或者非常小，甚至于以指数方式变小，这加大了训练的难度。 这节课，你将会了解梯度消失或梯度爆炸的真正含义，以及如何更明智地选择随机初始化权重，从而避免这个问题。假设你正在训练这样一个极深的神经网络，为了节约幻灯片上的空间，我画的神经网络每层只有两个隐藏单元，但它可能含有更多，但这个神经网络会有参数$W^{[1]}$，$W^{[2]}$，$W^{[3]}$等等，直到$W^{[l]}$，为了简单起见，假设我们使用激活函数$g(z)=z$，也就是线性激活函数，我们忽略$b$，假设$b^{[l]}$=0，如果那样的话，输出$ y=W^{[l]}W^{[L -1]}W^{[L - 2]}\ldots W^{[3]}W^{[2]}W^{[1]}x$，如果你想考验我的数学水平，$W^{[1]} x = z^{[1]}$，因为$b=0$，所以我想$z^{[1]} =W^{[1]} x$，$a^{[1]} = g(z^{[1]})$，因为我们使用了一个线性激活函数，它等于$z^{[1]}$，所以第一项$W^{[1]} x = a^{[1]}$，通过推理，你会得出$W^{[2]}W^{[1]}x =a^{[2]}$，因为$a^{[2]} = g(z^{[2]})$，还等于$g(W^{[2]}a^{[1]})$，可以用$W^{[1]}x$替换$a^{[1]}$，所以这一项就等于$a^{[2]}$，这个就是$a^{[3]}$($W^{[3]}W^{[2]}W^{[1]}x$)。 所有这些矩阵数据传递的协议将给出$\hat y$而不是$y$的值。 假设每个权重矩阵$W^{[l]} = \begin{bmatrix} 1.5 & 0 \\0 & 1.5 \\\end{bmatrix}$，从技术上来讲，最后一项有不同维度，可能它就是余下的权重矩阵，$y= W^{[1]}\begin{bmatrix} 1.5 & 0 \\ 0 & 1.5 \\\end{bmatrix}^{(L -1)}x$，因为我们假设所有矩阵都等于它，它是1.5倍的单位矩阵，最后的计算结果就是$\hat{y}$，$\hat{y}$也就是等于${1.5}^{(L-1)}x$。如果对于一个深度神经网络来说$L$值较大，那么$\hat{y}$的值也会非常大，实际上它呈指数级增长的，它增长的比率是${1.5}^{L}$，因此对于一个深度神经网络，$y$的值将爆炸式增长。 相反的，如果权重是0.5，$W^{[l]} = \begin{bmatrix} 0.5& 0 \\ 0 & 0.5 \\ \end{bmatrix}$，它比1小，这项也就变成了${0.5}^{L}$，矩阵$y= W^{[1]}\begin{bmatrix} 0.5 & 0 \\ 0 & 0.5 \\\end{bmatrix}^{(L - 1)}x$，再次忽略$W^{[L]}$，因此每个矩阵都小于1，假设$x_{1}$和$x_{2}$都是1，激活函数将变成$\frac{1}{2}$，$\frac{1}{2}$，$\frac{1}{4}$，$\frac{1}{4}$，$\frac{1}{8}$，$\frac{1}{8}$等，直到最后一项变成$\frac{1}{2^{L} }$，所以作为自定义函数，激活函数的值将以指数级下降，它是与网络层数数量$L$相关的函数，在深度网络中，激活函数以指数级递减。 我希望你得到的直观理解是，权重$W$只比1略大一点，或者说只是比单位矩阵大一点，深度神经网络的激活函数将爆炸式增长，如果$W$比1略小一点，可能是$\begin{bmatrix}0.9 & 0 \\ 0 & 0.9 \\ \end{bmatrix}$。 在深度神经网络中，激活函数将以指数级递减，虽然我只是讨论了激活函数以与$L$相关的指数级数增长或下降，它也适用于与层数$L$相关的导数或梯度函数，也是呈指数级增长或呈指数递减。 对于当前的神经网络，假设$L=150$，最近Microsoft对152层神经网络的研究取得了很大进展，在这样一个深度神经网络中，如果激活函数或梯度函数以与$L$相关的指数增长或递减，它们的值将会变得极大或极小，从而导致训练难度上升，尤其是梯度指数小于$L$时，梯度下降算法的步长会非常非常小，梯度下降算法将花费很长时间来学习。 总结一下，我们讲了深度神经网络是如何产生梯度消失或爆炸问题的，实际上，在很长一段时间内，它曾是训练深度神经网络的阻力，虽然有一个不能彻底解决此问题的解决方案，但是已在如何选择初始化权重问题上提供了很多帮助。 1.11 神经网络的权重初始化（Weight Initialization for Deep NetworksVanishing / Exploding gradients）上节课，我们学习了深度神经网络如何产生梯度消失和梯度爆炸问题，最终针对该问题，我们想出了一个不完整的解决方案，虽然不能彻底解决问题，却很有用，有助于我们为神经网络更谨慎地选择随机初始化参数，为了更好地理解它，我们先举一个神经单元初始化地例子，然后再演变到整个深度网络。 我们来看看只有一个神经元的情况，然后才是深度网络。 单个神经元可能有4个输入特征，从$x_{1}$到$x_{4}$，经过$a=g(z)$处理，最终得到$\hat{y}$，稍后讲深度网络时，这些输入表示为$a^{[l]}$，暂时我们用$x$表示。 $z = w_{1}x_{1} + w_{2}x_{2} + \ldots +w_{n}x_{n}$，$b=0$，暂时忽略$b$，为了预防$z$值过大或过小，你可以看到$n$越大，你希望$w_{i}$越小，因为$z$是$w_{i}x_{i}$的和，如果你把很多此类项相加，希望每项值更小，最合理的方法就是设置$w_{i}=\frac{1}{n}$，$n$表示神经元的输入特征数量，实际上，你要做的就是设置某层权重矩阵$w^{[l]} = np.random.randn( \text{shape})*\text{np.}\text{sqrt}(\frac{1}{n^{[l-1]} })$，$n^{[l - 1]}$就是我喂给第$l$层神经单元的数量（即第$l-1$层神经元数量）。 结果，如果你是用的是Relu激活函数，而不是$\frac{1}{n}$，方差设置为$\frac{2}{n}$，效果会更好。你常常发现，初始化时，尤其是使用Relu激活函数时，$g^{[l]}(z) =Relu(z)$,它取决于你对随机变量的熟悉程度，这是高斯随机变量，然后乘以它的平方根，也就是引用这个方差$\frac{2}{n}$。这里，我用的是$n^{[l - 1]}$，因为本例中，逻辑回归的特征是不变的。但一般情况下$l$层上的每个神经元都有$n^{[l - 1]}$个输入。如果激活函数的输入特征被零均值和标准方差化，方差是1，$z$也会调整到相似范围，这就没解决问题（梯度消失和爆炸问题）。但它确实降低了梯度消失和爆炸问题，因为它给权重矩阵$w$设置了合理值，你也知道，它不能比1大很多，也不能比1小很多，所以梯度没有爆炸或消失过快。 我提到了其它变体函数，刚刚提到的函数是Relu激活函数，一篇由Herd等人撰写的论文曾介绍过。对于几个其它变体函数，如tanh激活函数，有篇论文提到，常量1比常量2的效率更高，对于tanh函数来说，它是$\sqrt{\frac{1}{n^{[l-1]} }}$，这里平方根的作用与这个公式作用相同($\text{np.}\text{sqrt}(\frac{1}{n^{[l-1]} })$)，它适用于tanh激活函数，被称为Xavier初始化。Yoshua Bengio和他的同事还提出另一种方法，你可能在一些论文中看到过，它们使用的是公式$\sqrt{\frac{2}{n^{[l-1]} + n^{\left[l\right]} }}$。其它理论已对此证明，但如果你想用Relu激活函数，也就是最常用的激活函数，我会用这个公式$\text{np.}\text{sqrt}(\frac{2}{n^{[l-1]} })$，如果使用tanh函数，可以用公式$\sqrt{\frac{1}{n^{[l-1]} }}$，有些作者也会使用这个函数。 实际上，我认为所有这些公式只是给你一个起点，它们给出初始化权重矩阵的方差的默认值，如果你想添加方差，方差参数则是另一个你需要调整的超级参数，可以给公式$\text{np.}\text{sqrt}(\frac{2}{n^{[l-1]} })$添加一个乘数参数，调优作为超级参数激增一份子的乘子参数。有时调优该超级参数效果一般，这并不是我想调优的首要超级参数，但我发现调优过程中产生的问题，虽然调优该参数能起到一定作用，但考虑到相比调优，其它超级参数的重要性，我通常把它的优先级放得比较低。 希望你现在对梯度消失或爆炸问题以及如何为权重初始化合理值已经有了一个直观认识，希望你设置的权重矩阵既不会增长过快，也不会太快下降到0，从而训练出一个权重或梯度不会增长或消失过快的深度网络。我们在训练深度网络时，这也是一个加快训练速度的技巧。 1.12 梯度的数值逼近（Numerical approximation of gradients）在实施backprop时，有一个测试叫做梯度检验，它的作用是确保backprop正确实施。因为有时候，你虽然写下了这些方程式，却不能100%确定，执行backprop的所有细节都是正确的。为了逐渐实现梯度检验，我们首先说说如何计算梯度的数值逼近，下节课，我们将讨论如何在backprop中执行梯度检验，以确保backprop正确实施。 我们先画出函数$f$，标记为$f\left( \theta \right)$，$f\left( \theta \right)=\theta^{3}$，先看一下$\theta$的值，假设$\theta=1$，不增大$\theta$的值，而是在$\theta$ 右侧，设置一个$\theta +\varepsilon$，在$\theta$左侧，设置$\theta -\varepsilon$。因此$\theta=1$，$\theta +\varepsilon =1.01,\theta -\varepsilon =0.99$,，跟以前一样，$\varepsilon$的值为0.01，看下这个小三角形，计算高和宽的比值，就是更准确的梯度预估，选择$f$函数在$\theta -\varepsilon$上的这个点，用这个较大三角形的高比上宽，技术上的原因我就不详细解释了，较大三角形的高宽比值更接近于$\theta$的导数，把右上角的三角形下移，好像有了两个三角形，右上角有一个，左下角有一个，我们通过这个绿色大三角形同时考虑了这两个小三角形。所以我们得到的不是一个单边公差而是一个双边公差。 我们写一下数据算式，图中绿色三角形上边的点的值是$f( \theta +\varepsilon )$，下边的点是$f( \theta-\varepsilon)$，这个三角形的高度是$f( \theta +\varepsilon)-f(\theta -\varepsilon)$，这两个宽度都是ε，所以三角形的宽度是$2\varepsilon$，高宽比值为$\frac{f(\theta + \varepsilon ) - (\theta -\varepsilon)}{2\varepsilon}$，它的期望值接近$g( \theta)$，$f( \theta)=\theta^{3}$传入参数值，$\frac {f\left( \theta + \varepsilon \right) - f(\theta -\varepsilon)}{2\varepsilon} = \frac{ {(1.01)}^{3} - {(0.99)}^{3} }{2 \times0.01}$，大家可以暂停视频，用计算器算算结果，结果应该是3.0001，而前面一张幻灯片上面是，当$\theta =1$时，$g( \theta)=3\theta^{2} =3$，所以这两个$g(\theta)$值非常接近，逼近误差为0.0001，前一张幻灯片，我们只考虑了单边公差，即从$\theta $到$\theta +\varepsilon$之间的误差，$g( \theta)$的值为3.0301，逼近误差是0.03，不是0.0001，所以使用双边误差的方法更逼近导数，其结果接近于3，现在我们更加确信，$g( \theta)$可能是$f$导数的正确实现，在梯度检验和反向传播中使用该方法时，最终，它与运行两次单边公差的速度一样，实际上，我认为这种方法还是非常值得使用的，因为它的结果更准确。 这是一些你可能比较熟悉的微积分的理论，如果你不太明白我讲的这些理论也没关系，导数的官方定义是针对值很小的$\varepsilon$，导数的官方定义是$f^{'}\theta) = \operatorname{}\frac{f( \theta + \varepsilon) -f(\theta -\varepsilon)}{2\varepsilon}$，如果你上过微积分课，应该学过无穷尽的定义，我就不在这里讲了。 对于一个非零的$\varepsilon$，它的逼近误差可以写成$O(\varepsilon^{2})$，ε值非常小，如果$\varepsilon=0.01$，$\varepsilon^{2}=0.0001$，大写符号$O$的含义是指逼近误差其实是一些常量乘以$\varepsilon^{2}$，但它的确是很准确的逼近误差，所以大写$O$的常量有时是1。然而，如果我们用另外一个公式逼近误差就是$O(\varepsilon)$，当$\varepsilon$小于1时，实际上$\varepsilon$比$\varepsilon^{2}$大很多，所以这个公式近似值远没有左边公式的准确，所以在执行梯度检验时，我们使用双边误差，即$\frac{f\left(\theta + \varepsilon \right) - f(\theta -\varepsilon)}{2\varepsilon}$，而不使用单边公差，因为它不够准确。 如果你不理解上面两条结论，所有公式都在这儿，不用担心，如果你对微积分和数值逼近有所了解，这些信息已经足够多了，重点是要记住，双边误差公式的结果更准确，下节课我们做梯度检验时就会用到这个方法。 今天我们讲了如何使用双边误差来判断别人给你的函数$g( \theta)$，是否正确实现了函数$f$的偏导，现在我们可以使用这个方法来检验反向传播是否得以正确实施，如果不正确，它可能有bug需要你来解决。 1.13 梯度检验（Gradient checking）梯度检验帮我们节省了很多时间，也多次帮我发现backprop实施过程中的bug，接下来，我们看看如何利用它来调试或检验backprop的实施是否正确。 假设你的网络中含有下列参数，$W^{[1]}$和$b^{[1]}$……$W^{[l]}$和$b^{[l]}$，为了执行梯度检验，首先要做的就是，把所有参数转换成一个巨大的向量数据，你要做的就是把矩阵$W$转换成一个向量，把所有$W$矩阵转换成向量之后，做连接运算，得到一个巨型向量$\theta$，该向量表示为参数$\theta$，代价函数$J$是所有$W$和$b$的函数，现在你得到了一个$\theta$的代价函数$J$（即$J(\theta)$）。接着，你得到与$W$和$b$顺序相同的数据，你同样可以把$dW^{[1]}$和${db}^{[1]}$……${dW}^{[l]}$和${db}^{[l]}$转换成一个新的向量，用它们来初始化大向量$d\theta$，它与$\theta$具有相同维度。 同样的，把$dW^{[1]}$转换成矩阵，$db^{[1]}$已经是一个向量了，直到把${dW}^{[l]}$转换成矩阵，这样所有的$dW$都已经是矩阵，注意$dW^{[1]}$与$W^{[1]}$具有相同维度，$db^{[1]}$与$b^{[1]}$具有相同维度。经过相同的转换和连接运算操作之后，你可以把所有导数转换成一个大向量$d\theta$，它与$\theta$具有相同维度，现在的问题是$d\theta$和代价函数$J$的梯度或坡度有什么关系？ 这就是实施梯度检验的过程，英语里通常简称为“grad check”，首先，我们要清楚$J$是超参数$\theta$的一个函数，你也可以将J函数展开为$J(\theta_{1},\theta_{2},\theta_{3},\ldots\ldots)$，不论超级参数向量$\theta$的维度是多少，为了实施梯度检验，你要做的就是循环执行，从而对每个$i$也就是对每个$\theta$组成元素计算$d\theta_{\text{approx} }[i]$的值，我使用双边误差，也就是 $d\theta_{\text{approx} }\left[i \right] = \frac{J\left( \theta_{1},\theta_{2},\ldots\theta_{i} + \varepsilon,\ldots \right) - J\left( \theta_{1},\theta_{2},\ldots\theta_{i} - \varepsilon,\ldots \right)}{2\varepsilon}$ 只对$\theta_{i}$增加$\varepsilon$，其它项保持不变，因为我们使用的是双边误差，对另一边做同样的操作，只不过是减去$\varepsilon$，$\theta$其它项全都保持不变。 从上节课中我们了解到这个值（$d\theta_{\text{approx} }\left[i \right]$）应该逼近$d\theta\left[i \right]$=$\frac{\partial J}{\partial\theta_{i} }$，$d\theta\left[i \right]$是代价函数的偏导数，然后你需要对i的每个值都执行这个运算，最后得到两个向量，得到$d\theta$的逼近值$d\theta_{\text{approx} }$，它与$d\theta$具有相同维度，它们两个与$\theta$具有相同维度，你要做的就是验证这些向量是否彼此接近。 具体来说，如何定义两个向量是否真的接近彼此？我一般做下列运算，计算这两个向量的距离，$d\theta_{\text{approx} }\left[i \right] - d\theta[i]$的欧几里得范数，注意这里（${||d\theta_{\text{approx} } -d\theta||}_{2}$）没有平方，它是误差平方之和，然后求平方根，得到欧式距离，然后用向量长度归一化，使用向量长度的欧几里得范数。分母只是用于预防这些向量太小或太大，分母使得这个方程式变成比率，我们实际执行这个方程式，$\varepsilon$可能为$10^{-7}$，使用这个取值范围内的$\varepsilon$，如果你发现计算方程式得到的值为$10^{-7}$或更小，这就很好，这就意味着导数逼近很有可能是正确的，它的值非常小。 如果它的值在$10^{-5}$范围内，我就要小心了，也许这个值没问题，但我会再次检查这个向量的所有项，确保没有一项误差过大，可能这里有bug。 如果左边这个方程式结果是$10^{-3}$，我就会担心是否存在bug，计算结果应该比$10^{- 3}$小很多，如果比$10^{-3}$大很多，我就会很担心，担心是否存在bug。这时应该仔细检查所有$\theta$项，看是否有一个具体的$i$值，使得$d\theta_{\text{approx} }\left[i \right]$与$ d\theta[i]$大不相同，并用它来追踪一些求导计算是否正确，经过一些调试，最终结果会是这种非常小的值（$10^{-7}$），那么，你的实施可能是正确的。 在实施神经网络时，我经常需要执行foreprop和backprop，然后我可能发现这个梯度检验有一个相对较大的值，我会怀疑存在bug，然后开始调试，调试，调试，调试一段时间后，我得到一个很小的梯度检验值，现在我可以很自信的说，神经网络实施是正确的。 现在你已经了解了梯度检验的工作原理，它帮助我在神经网络实施中发现了很多bug，希望它对你也有所帮助。 1.14 梯度检验应用的注意事项（Gradient Checking Implementation Notes）这节课，分享一些关于如何在神经网络实施梯度检验的实用技巧和注意事项。 首先，不要在训练中使用梯度检验，它只用于调试。我的意思是，计算所有$i$值的$d\theta_{\text{approx} }\left[i\right]$是一个非常漫长的计算过程，为了实施梯度下降，你必须使用$W$和$b$ backprop来计算$d\theta$，并使用backprop来计算导数，只要调试的时候，你才会计算它，来确认数值是否接近$d\theta$。完成后，你会关闭梯度检验，梯度检验的每一个迭代过程都不执行它，因为它太慢了。 第二点，如果算法的梯度检验失败，要检查所有项，检查每一项，并试着找出bug，也就是说，如果$d\theta_{\text{approx} }\left[i\right]$与dθ[i]的值相差很大，我们要做的就是查找不同的i值，看看是哪个导致$d\theta_{\text{approx} }\left[i\right]$与$d\theta\left[i\right]$的值相差这么多。举个例子，如果你发现，相对某些层或某层的$\theta$或$d\theta$的值相差很大，但是$\text{dw}^{[l]}$的各项非常接近，注意$\theta$的各项与$b$和$w$的各项都是一一对应的，这时，你可能会发现，在计算参数$b$的导数$db$的过程中存在bug。反过来也是一样，如果你发现它们的值相差很大，$d\theta_{\text{approx} }\left[i\right]$的值与$d\theta\left[i\right]$的值相差很大，你会发现所有这些项目都来自于$dw$或某层的$dw$，可能帮你定位bug的位置，虽然未必能够帮你准确定位bug的位置，但它可以帮助你估测需要在哪些地方追踪bug。 第三点，在实施梯度检验时，如果使用正则化，请注意正则项。如果代价函数$J(\theta) = \frac{1}{m}\sum_{}^{}{L(\hat y^{(i)},y^{(i)})} + \frac{\lambda}{2m}\sum_{}^{}{||W^{[l]}||}^{2}$，这就是代价函数$J$的定义，$d\theta$等于与$\theta$相关的$J$函数的梯度，包括这个正则项，记住一定要包括这个正则项。 第四点，梯度检验不能与dropout同时使用，因为每次迭代过程中，dropout会随机消除隐藏层单元的不同子集，难以计算dropout在梯度下降上的代价函数$J$。因此dropout可作为优化代价函数$J$的一种方法，但是代价函数J被定义为对所有指数极大的节点子集求和。而在任何迭代过程中，这些节点都有可能被消除，所以很难计算代价函数$J$。你只是对成本函数做抽样，用dropout，每次随机消除不同的子集，所以很难用梯度检验来双重检验dropout的计算，所以我一般不同时使用梯度检验和dropout。如果你想这样做，可以把dropout中的keepprob设置为1.0，然后打开dropout，并寄希望于dropout的实施是正确的，你还可以做点别的，比如修改节点丢失模式确定梯度检验是正确的。实际上，我一般不这么做，我建议关闭dropout，用梯度检验进行双重检查，在没有dropout的情况下，你的算法至少是正确的，然后打开dropout。 最后一点，也是比较微妙的一点，现实中几乎不会出现这种情况。当$w$和$b$接近0时，梯度下降的实施是正确的，在随机初始化过程中……，但是在运行梯度下降时，$w$和$b$变得更大。可能只有在$w$和$b$接近0时，backprop的实施才是正确的。但是当$W$和$b$变大时，它会变得越来越不准确。你需要做一件事，我不经常这么做，就是在随机初始化过程中，运行梯度检验，然后再训练网络，$w$和$b$会有一段时间远离0，如果随机初始化值比较小，反复训练网络之后，再重新运行梯度检验。 这就是梯度检验，恭喜大家，这是本周最后一课了。回顾这一周，我们讲了如何配置训练集，验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差以及高偏差和高方差并存的问题，如何在神经网络中应用不同形式的正则化，如$L2$正则化和dropout，还有加快神经网络训练速度的技巧，最后是梯度检验。这一周我们学习了很多内容，你可以在本周编程作业中多多练习这些概念。祝你好运，期待下周再见。 优化算法 (Optimization algorithms)2.1 Mini-batch 梯度下降（Mini-batch gradient descent）本周将学习优化算法，这能让你的神经网络运行得更快。机器学习的应用是一个高度依赖经验的过程，伴随着大量迭代的过程，你需要训练诸多模型，才能找到合适的那一个，所以，优化算法能够帮助你快速训练模型。 其中一个难点在于，深度学习没有在大数据领域发挥最大的效果，我们可以利用一个巨大的数据集来训练神经网络，而在巨大的数据集基础上进行训练速度很慢。因此，你会发现，使用快速的优化算法，使用好用的优化算法能够大大提高你和团队的效率，那么，我们首先来谈谈mini-batch梯度下降法。 你之前学过，向量化能够让你有效地对所有$m$个样本进行计算，允许你处理整个训练集，而无需某个明确的公式。所以我们要把训练样本放大巨大的矩阵$X$当中去，$X= \lbrack x^{(1)}\ x^{(2)}\ x^{(3)}\ldots\ldots x^{(m)}\rbrack$，$Y$也是如此，$Y= \lbrack y^{(1)}\ y^{(2)}\ y^{(3)}\ldots \ldots y^{(m)}\rbrack$，所以$X$的维数是$(n_{x},m)$，$Y$的维数是$(1,m)$，向量化能够让你相对较快地处理所有$m$个样本。如果$m$很大的话，处理速度仍然缓慢。比如说，如果$m$是500万或5000万或者更大的一个数，在对整个训练集执行梯度下降法时，你要做的是，你必须处理整个训练集，然后才能进行一步梯度下降法，然后你需要再重新处理500万个训练样本，才能进行下一步梯度下降法。所以如果你在处理完整个500万个样本的训练集之前，先让梯度下降法处理一部分，你的算法速度会更快，准确地说，这是你可以做的一些事情。 你可以把训练集分割为小一点的子集训练，这些子集被取名为mini-batch，假设每一个子集中只有1000个样本，那么把其中的$x^{(1)}$到$x^{(1000)}$取出来，将其称为第一个子训练集，也叫做mini-batch，然后你再取出接下来的1000个样本，从$x^{(1001)}$到$x^{(2000)}$，然后再取1000个样本，以此类推。 接下来我要说一个新的符号，把$x^{(1)}$到$x^{(1000)}$称为$X^{\{1\} }$，$x^{(1001)}$到$x^{(2000)}$称为$X^{\{2\} }$，如果你的训练样本一共有500万个，每个mini-batch都有1000个样本，也就是说，你有5000个mini-batch，因为5000乘以1000就是5000万。 你共有5000个mini-batch，所以最后得到是$X^{\left\{ 5000 \right\} }$ 对$Y$也要进行相同处理，你也要相应地拆分$Y$的训练集，所以这是$Y^{\{1\} }$，然后从$y^{(1001)}$到$y^{(2000)}$，这个叫$Y^{\{2\} }$，一直到$Y^{\{ 5000\} }$。 mini-batch的数量$t$组成了$X^{\{ t\} }$和$Y^{\{t\} }$，这就是1000个训练样本，包含相应的输入输出对。 在继续课程之前，先确定一下我的符号，之前我们使用了上角小括号$(i)$表示训练集里的值，所以$x^{(i)}$是第$i$个训练样本。我们用了上角中括号$[l]$来表示神经网络的层数，$z^{\lbrack l\rbrack}$表示神经网络中第$l$层的$z$值，我们现在引入了大括号${t}$来代表不同的mini-batch，所以我们有$X^{\{ t\} }$和$Y^{\{ t\} }$，检查一下自己是否理解无误。 $X^{\{ t\} }$和$Y^{\{ t\} }$的维数：如果$X^{\{1\} }$是一个有1000个样本的训练集，或者说是1000个样本的$x$值，所以维数应该是$(n_{x},1000)$，$X^{\{2\} }$的维数应该是$(n_{x},1000)$，以此类推。因此所有的子集维数都是$(n_{x},1000)$，而这些（$Y^{\{ t\} }$）的维数都是$(1,1000)$。 解释一下这个算法的名称，batch梯度下降法指的是我们之前讲过的梯度下降法算法，就是同时处理整个训练集，这个名字就是来源于能够同时看到整个batch训练集的样本被处理，这个名字不怎么样，但就是这样叫它。 相比之下，mini-batch梯度下降法，指的是我们在下一张幻灯片中会讲到的算法，你每次同时处理的单个的mini-batch $X^{\{t\} }$和$Y^{\{ t\} }$，而不是同时处理全部的$X$和$Y$训练集。 那么究竟mini-batch梯度下降法的原理是什么？在训练集上运行mini-batch梯度下降法，你运行for t=1……5000，因为我们有5000个各有1000个样本的组，在for循环里你要做得基本就是对$X^{\{t\} }$和$Y^{\{t\} }$执行一步梯度下降法。假设你有一个拥有1000个样本的训练集，而且假设你已经很熟悉一次性处理完的方法，你要用向量化去几乎同时处理1000个样本。 首先对输入也就是$X^{\{ t\} }$，执行前向传播，然后执行$z^{\lbrack 1\rbrack} =W^{\lbrack 1\rbrack}X + b^{\lbrack 1\rbrack}$，之前我们这里只有，但是现在你正在处理整个训练集，你在处理第一个mini-batch，在处理mini-batch时它变成了$X^{\{ t\} }$，即$z^{\lbrack 1\rbrack} = W^{\lbrack 1\rbrack}X^{\{ t\} } + b^{\lbrack1\rbrack}$，然后执行$A^{[1]k} =g^{[1]}(Z^{[1]})$，之所以用大写的$Z$是因为这是一个向量内涵，以此类推，直到$A^{\lbrack L\rbrack} = g^{\left\lbrack L \right\rbrack}(Z^{\lbrack L\rbrack})$，这就是你的预测值。注意这里你需要用到一个向量化的执行命令，这个向量化的执行命令，一次性处理1000个而不是500万个样本。接下来你要计算损失成本函数$J$，因为子集规模是1000，$J= \frac{1}{1000}\sum_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})}$，说明一下，这（$L(\hat y^{(i)},y^{(i)})$）指的是来自于mini-batch$X^{\{ t\} }$和$Y^{\{t\} }$中的样本。 如果你用到了正则化，你也可以使用正则化的术语，$J =\frac{1}{1000}\sum_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})} +\frac{\lambda}{2 1000}\sum_{l}^{}{||w^{[l]}||}_{F}^{2}$，因为这是一个mini-batch的损失，所以我将$J$损失记为上角标$t$，放在大括号里（$J^{\{t\} } = \frac{1}{1000}\sum_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})} +\frac{\lambda}{2 1000}\sum_{l}^{}{||w^{[l]}||}_{F}^{2}$）。 你也会注意到，我们做的一切似曾相识，其实跟之前我们执行梯度下降法如出一辙，除了你现在的对象不是$X$，$Y$，而是$X^{\{t\} }$和$Y^{\{ t\} }$。接下来，你执行反向传播来计算$J^{\{t\} }$的梯度，你只是使用$X^{\{ t\} }$和$Y^{\{t\} }$，然后你更新加权值，$W$实际上是$W^{\lbrack l\rbrack}$，更新为$W^{[l]}:= W^{[l]} - adW^{[l]}$，对$b$做相同处理，$b^{[l]}:= b^{[l]} - adb^{[l]}$。这是使用mini-batch梯度下降法训练样本的一步，我写下的代码也可被称为进行“一代”（1 epoch）的训练。一代这个词意味着只是一次遍历了训练集。 使用batch梯度下降法，一次遍历训练集只能让你做一个梯度下降，使用mini-batch梯度下降法，一次遍历训练集，能让你做5000个梯度下降。当然正常来说你想要多次遍历训练集，还需要为另一个while循环设置另一个for循环。所以你可以一直处理遍历训练集，直到最后你能收敛到一个合适的精度。 如果你有一个丢失的训练集，mini-batch梯度下降法比batch梯度下降法运行地更快，所以几乎每个研习深度学习的人在训练巨大的数据集时都会用到，下一个视频中，我们将进一步深度讨论mini-batch梯度下降法，你也会因此更好地理解它的作用和原理。 2.2 理解mini-batch梯度下降法（Understanding mini-batch gradient descent）在上周视频中，你知道了如何利用mini-batch梯度下降法来开始处理训练集和开始梯度下降，即使你只处理了部分训练集，即使你是第一次处理，本视频中，我们将进一步学习如何执行梯度下降法，更好地理解其作用和原理。 使用batch梯度下降法时，每次迭代你都需要历遍整个训练集，可以预期每次迭代成本都会下降，所以如果成本函数$J$是迭代次数的一个函数，它应该会随着每次迭代而减少，如果$J$在某次迭代中增加了，那肯定出了问题，也许你的学习率太大。 使用mini-batch梯度下降法，如果你作出成本函数在整个过程中的图，则并不是每次迭代都是下降的，特别是在每次迭代中，你要处理的是$X^{\{t\} }$和$Y^{\{ t\} }$，如果要作出成本函数$J^{\{ t\} }$的图，而$J^{\{t\} }$只和$X^{\{ t\} }$，$Y^{\{t\} }$有关，也就是每次迭代下你都在训练不同的样本集或者说训练不同的mini-batch，如果你要作出成本函数$J$的图，你很可能会看到这样的结果，走向朝下，但有更多的噪声，所以如果你作出$J^{\{t\} }$的图，因为在训练mini-batch梯度下降法时，会经过多代，你可能会看到这样的曲线。没有每次迭代都下降是不要紧的，但走势应该向下，噪声产生的原因在于也许$X^{\{1\} }$和$Y^{\{1\} }$是比较容易计算的mini-batch，因此成本会低一些。不过也许出于偶然，$X^{\{2\} }$和$Y^{\{2\} }$是比较难运算的mini-batch，或许你需要一些残缺的样本，这样一来，成本会更高一些，所以才会出现这些摆动，因为你是在运行mini-batch梯度下降法作出成本函数图。 你需要决定的变量之一是mini-batch的大小，$m$就是训练集的大小，极端情况下，如果mini-batch的大小等于$m$，其实就是batch梯度下降法，在这种极端情况下，你就有了mini-batch $X^{\{1\} }$和$Y^{\{1\} }$，并且该mini-batch等于整个训练集，所以把mini-batch大小设为$m$可以得到batch梯度下降法。 另一个极端情况，假设mini-batch大小为1，就有了新的算法，叫做随机梯度下降法，每个样本都是独立的mini-batch，当你看第一个mini-batch，也就是$X^{\{1\} }$和$Y^{\{1\} }$，如果mini-batch大小为1，它就是你的第一个训练样本，这就是你的第一个训练样本。接着再看第二个mini-batch，也就是第二个训练样本，采取梯度下降步骤，然后是第三个训练样本，以此类推，一次只处理一个。 看在两种极端下成本函数的优化情况，如果这是你想要最小化的成本函数的轮廓，最小值在那里，batch梯度下降法从某处开始，相对噪声低些，幅度也大一些，你可以继续找最小值。 相反，在随机梯度下降法中，从某一点开始，我们重新选取一个起始点，每次迭代，你只对一个样本进行梯度下降，大部分时候你向着全局最小值靠近，有时候你会远离最小值，因为那个样本恰好给你指的方向不对，因此随机梯度下降法是有很多噪声的，平均来看，它最终会靠近最小值，不过有时候也会方向错误，因为随机梯度下降法永远不会收敛，而是会一直在最小值附近波动，但它并不会在达到最小值并停留在此。 实际上你选择的mini-batch大小在二者之间，大小在1和$m$之间，而1太小了，$m$太大了，原因在于如果使用batch梯度下降法，mini-batch的大小为$m$，每个迭代需要处理大量训练样本，该算法的主要弊端在于特别是在训练样本数量巨大的时候，单次迭代耗时太长。如果训练样本不大，batch梯度下降法运行地很好。 相反，如果使用随机梯度下降法，如果你只要处理一个样本，那这个方法很好，这样做没有问题，通过减小学习率，噪声会被改善或有所减小，但随机梯度下降法的一大缺点是，你会失去所有向量化带给你的加速，因为一次性只处理了一个训练样本，这样效率过于低下，所以实践中最好选择不大不小的mini-batch尺寸，实际上学习率达到最快。你会发现两个好处，一方面，你得到了大量向量化，上个视频中我们用过的例子中，如果mini-batch大小为1000个样本，你就可以对1000个样本向量化，比你一次性处理多个样本快得多。另一方面，你不需要等待整个训练集被处理完就可以开始进行后续工作，再用一下上个视频的数字，每次训练集允许我们采取5000个梯度下降步骤，所以实际上一些位于中间的mini-batch大小效果最好。 用mini-batch梯度下降法，我们从这里开始，一次迭代这样做，两次，三次，四次，它不会总朝向最小值靠近，但它比随机梯度下降要更持续地靠近最小值的方向，它也不一定在很小的范围内收敛或者波动，如果出现这个问题，可以慢慢减少学习率，我们在下个视频会讲到学习率衰减，也就是如何减小学习率。 如果mini-batch大小既不是1也不是$m$，应该取中间值，那应该怎么选择呢？其实是有指导原则的。 首先，如果训练集较小，直接使用batch梯度下降法，样本集较小就没必要使用mini-batch梯度下降法，你可以快速处理整个训练集，所以使用batch梯度下降法也很好，这里的少是说小于2000个样本，这样比较适合使用batch梯度下降法。不然，样本数目较大的话，一般的mini-batch大小为64到512，考虑到电脑内存设置和使用的方式，如果mini-batch大小是2的$n$次方，代码会运行地快一些，64就是2的6次方，以此类推，128是2的7次方，256是2的8次方，512是2的9次方。所以我经常把mini-batch大小设成2的次方。在上一个视频里，我的mini-batch大小设为了1000，建议你可以试一下1024，也就是2的10次方。也有mini-batch的大小为1024，不过比较少见，64到512的mini-batch比较常见。 最后需要注意的是在你的mini-batch中，要确保$X^{\{ t\} }$和$Y^{\{t\} }$要符合CPU/GPU内存，取决于你的应用方向以及训练集的大小。如果你处理的mini-batch和CPU/GPU内存不相符，不管你用什么方法处理数据，你会注意到算法的表现急转直下变得惨不忍睹，所以我希望你对一般人们使用的mini-batch大小有一个直观了解。事实上mini-batch大小是另一个重要的变量，你需要做一个快速尝试，才能找到能够最有效地减少成本函数的那个，我一般会尝试几个不同的值，几个不同的2次方，然后看能否找到一个让梯度下降优化算法最高效的大小。希望这些能够指导你如何开始找到这一数值。 你学会了如何执行mini-batch梯度下降，令算法运行得更快，特别是在训练样本数目较大的情况下。不过还有个更高效的算法，比梯度下降法和mini-batch梯度下降法都要高效的多，我们在接下来的视频中将为大家一一讲解。 2.3 指数加权平均数（Exponentially weighted averages）我想向你展示几个优化算法，它们比梯度下降法快，要理解这些算法，你需要用到指数加权平均，在统计中也叫做指数加权移动平均，我们首先讲这个，然后再来讲更复杂的优化算法。虽然现在我生活在美国，实际上我生于英国伦敦。比如我这儿有去年伦敦的每日温度，所以1月1号，温度是40华氏度，相当于4摄氏度。我知道世界上大部分地区使用摄氏度，但是美国使用华氏度。在1月2号是9摄氏度等等。在年中的时候，一年365天，年中就是说，大概180天的样子，也就是5月末，温度是60华氏度，也就是15摄氏度等等。夏季温度转暖，然后冬季降温。 你用数据作图，可以得到以下结果，起始日在1月份，这里是夏季初，这里是年末，相当于12月末。 这里是1月1号，年中接近夏季的时候，随后就是年末的数据，看起来有些杂乱，如果要计算趋势的话，也就是温度的局部平均值，或者说移动平均值。 你要做的是，首先使$v_{0} =0$，每天，需要使用0.9的加权数之前的数值加上当日温度的0.1倍，即$v_{1} =0.9v_{0} + 0.1\theta_{1}$，所以这里是第一天的温度值。 第二天，又可以获得一个加权平均数，0.9乘以之前的值加上当日的温度0.1倍，即$v_{2}= 0.9v_{1} + 0.1\theta_{2}$，以此类推。 第二天值加上第三日数据的0.1，如此往下。大体公式就是某天的$v$等于前一天$v$值的0.9加上当日温度的0.1。 如此计算，然后用红线作图的话，便得到这样的结果。 你得到了移动平均值，每日温度的指数加权平均值。 看一下上一张幻灯片里的公式，$v_{t} = 0.9v_{t - 1} +0.1\theta_{t}$，我们把0.9这个常数变成$\beta$，将之前的0.1变成$(1 - \beta)$，即$v_{t} = \beta v_{t - 1} + (1 - \beta)\theta_{t}$ 由于以后我们要考虑的原因，在计算时可视$v_{t}$大概是$\frac{1}{(1 -\beta)}$的每日温度，如果$\beta$是0.9，你会想，这是十天的平均值，也就是红线部分。 我们来试试别的，将$\beta$设置为接近1的一个值，比如0.98，计算$\frac{1}{(1 - 0.98)} =50$，这就是粗略平均了一下，过去50天的温度，这时作图可以得到绿线。 这个高值$\beta$要注意几点，你得到的曲线要平坦一些，原因在于你多平均了几天的温度，所以这个曲线，波动更小，更加平坦，缺点是曲线进一步右移，因为现在平均的温度值更多，要平均更多的值，指数加权平均公式在温度变化时，适应地更缓慢一些，所以会出现一定延迟，因为当$\beta=0.98$，相当于给前一天的值加了太多权重，只有0.02的权重给了当日的值，所以温度变化时，温度上下起伏，当$\beta$ 较大时，指数加权平均值适应地更缓慢一些。 我们可以再换一个值试一试，如果$\beta$是另一个极端值，比如说0.5，根据右边的公式（$\frac{1}{(1-\beta)}$），这是平均了两天的温度。 作图运行后得到黄线。 由于仅平均了两天的温度，平均的数据太少，所以得到的曲线有更多的噪声，有可能出现异常值，但是这个曲线能够更快适应温度变化。 所以指数加权平均数经常被使用，再说一次，它在统计学中被称为指数加权移动平均值，我们就简称为指数加权平均数。通过调整这个参数（$\beta$），或者说后面的算法学习，你会发现这是一个很重要的参数，可以取得稍微不同的效果，往往中间有某个值效果最好，$\beta$为中间值时得到的红色曲线，比起绿线和黄线更好地平均了温度。 现在你知道计算指数加权平均数的基本原理，下一个视频中，我们再聊聊它的本质作用。 2.4 理解指数加权平均数（Understanding exponentially weighted averages）上个视频中，我们讲到了指数加权平均数，这是几个优化算法中的关键一环，而这几个优化算法能帮助你训练神经网络。本视频中，我希望进一步探讨算法的本质作用。 回忆一下这个计算指数加权平均数的关键方程。 ${ {v}_{t} }=\beta { {v}_{t-1} }+(1-\beta ){ {\theta }_{t} }$ $\beta=0.9$的时候，得到的结果是红线，如果它更接近于1，比如0.98，结果就是绿线，如果$\beta$小一点，如果是0.5，结果就是黄线。 我们进一步地分析，来理解如何计算出每日温度的平均值。 同样的公式，${ {v}_{t} }=\beta { {v}_{t-1} }+(1-\beta ){ {\theta }_{t} }$ 使$\beta=0.9$，写下相应的几个公式，所以在执行的时候，$t$从0到1到2到3，$t$的值在不断增加，为了更好地分析，我写的时候使得$t$的值不断减小，然后继续往下写。 首先看第一个公式，理解$v_{100}$是什么？我们调换一下这两项（$0.9v_{99}0.1\theta_{100}$），$v_{100}= 0.1\theta_{100} + 0.9v_{99}$。 那么$v_{99}$是什么？我们就代入这个公式（$v_{99} = 0.1\theta_{99} +0.9v_{98}$），所以： $v_{100} = 0.1\theta_{100} + 0.9(0.1\theta_{99} + 0.9v_{98})$。 那么$v_{98}$是什么？你可以用这个公式计算（$v_{98} = 0.1\theta_{98} +0.9v_{97}$），把公式代进去，所以： $v_{100} = 0.1\theta_{100} + 0.9(0.1\theta_{99} + 0.9(0.1\theta_{98} +0.9v_{97}))$。 以此类推，如果你把这些括号都展开， $v_{100} = 0.1\theta_{100} + 0.1 \times 0.9 \theta_{99} + 0.1 \times {(0.9)}^{2}\theta_{98} + 0.1 \times {(0.9)}^{3}\theta_{97} + 0.1 \times {(0.9)}^{4}\theta_{96} + \ldots$ 所以这是一个加和并平均，100号数据，也就是当日温度。我们分析$v_{100}$的组成，也就是在一年第100天计算的数据，但是这个是总和，包括100号数据，99号数据，97号数据等等。画图的一个办法是，假设我们有一些日期的温度，所以这是数据，这是$t$，所以100号数据有个数值，99号数据有个数值，98号数据等等，$t$为100，99，98等等，这就是数日的温度数值。 然后我们构建一个指数衰减函数，从0.1开始，到$0.1 \times 0.9$，到$0.1 \times {(0.9)}^{2}$，以此类推，所以就有了这个指数衰减函数。 计算$v_{100}$是通过，把两个函数对应的元素，然后求和，用这个数值100号数据值乘以0.1，99号数据值乘以0.1乘以${(0.9)}^{2}$，这是第二项，以此类推，所以选取的是每日温度，将其与指数衰减函数相乘，然后求和，就得到了$v_{100}$。 结果是，稍后我们详细讲解，不过所有的这些系数（$0.10.1 \times 0.90.1 \times {(0.9)}^{2}0.1 \times {(0.9)}^{3}\ldots$），相加起来为1或者逼近1，我们称之为偏差修正，下个视频会涉及。 最后也许你会问，到底需要平均多少天的温度。实际上${(0.9)}^{10}$大约为0.35，这大约是$\frac{1}{e}$，e是自然算法的基础之一。大体上说，如果有$1-\varepsilon$，在这个例子中，$\varepsilon=0.1$，所以$1-\varepsilon=0.9$，${(1-\varepsilon)}^{(\frac{1}{\varepsilon})}$约等于$\frac{1}{e}$，大约是0.34，0.35，换句话说，10天后，曲线的高度下降到$\frac{1}{3}$，相当于在峰值的$\frac{1}{e}$。 又因此当$\beta=0.9$的时候，我们说仿佛你在计算一个指数加权平均数，只关注了过去10天的温度，因为10天后，权重下降到不到当日权重的三分之一。 相反，如果，那么0.98需要多少次方才能达到这么小的数值？${(0.98)}^{50}$大约等于$\frac{1}{e}$，所以前50天这个数值比$\frac{1}{e}$大，数值会快速衰减，所以本质上这是一个下降幅度很大的函数，你可以看作平均了50天的温度。因为在例子中，要代入等式的左边，$\varepsilon=0.02$，所以$\frac{1}{\varepsilon}$为50，我们由此得到公式，我们平均了大约$\frac{1}{(1-\beta)}$天的温度，这里$\varepsilon$代替了$1-\beta$，也就是说根据一些常数，你能大概知道能够平均多少日的温度，不过这只是思考的大致方向，并不是正式的数学证明。 最后讲讲如何在实际中执行，还记得吗？我们一开始将$v_{0}$设置为0，然后计算第一天$v_{1}$，然后$v_{2}$，以此类推。 现在解释一下算法，可以将$v_{0}$，$v_{1}$，$v_{2}$等等写成明确的变量，不过在实际中执行的话，你要做的是，一开始将$v$初始化为0，然后在第一天使$v:= \beta v + (1 - \beta)\theta_{1}$，然后第二天，更新$v$值，$v: = \beta v + (1 -\beta)\theta_{2}$，以此类推，有些人会把$v$加下标，来表示$v$是用来计算数据的指数加权平均数。 再说一次，但是换个说法，$v_{\theta} =0$，然后每一天，拿到第$t$天的数据，把$v$更新为$v: = \beta v_{\theta} + (1 -\beta)\theta_{t}$。 指数加权平均数公式的好处之一在于，它占用极少内存，电脑内存中只占用一行数字而已，然后把最新数据代入公式，不断覆盖就可以了，正因为这个原因，其效率，它基本上只占用一行代码，计算指数加权平均数也只占用单行数字的存储和内存，当然它并不是最好的，也不是最精准的计算平均数的方法。如果你要计算移动窗，你直接算出过去10天的总和，过去50天的总和，除以10和50就好，如此往往会得到更好的估测。但缺点是，如果保存所有最近的温度数据，和过去10天的总和，必须占用更多的内存，执行更加复杂，计算成本也更加高昂。 所以在接下来的视频中，我们会计算多个变量的平均值，从计算和内存效率来说，这是一个有效的方法，所以在机器学习中会经常使用，更不用说只要一行代码，这也是一个优势。 现在你学会了计算指数加权平均数，你还需要知道一个专业概念，叫做偏差修正，下一个视频我们会讲到它，接着你就可以用它构建更好的优化算法，而不是简单直接的梯度下降法。 2.5 指数加权平均的偏差修正（Bias correction in exponentially weighted averages）你学过了如何计算指数加权平均数，有一个技术名词叫做偏差修正，可以让平均数运算更加准确，来看看它是怎么运行的。 ${ {v}_{t} }=\beta { {v}_{t-1} }+(1-\beta ){ {\theta }_{t} }$ 在上一个视频中，这个（红色）曲线对应$\beta$的值为0.9，这个（绿色）曲线对应的$\beta$=0.98，如果你执行写在这里的公式，在$\beta$等于0.98的时候，得到的并不是绿色曲线，而是紫色曲线，你可以注意到紫色曲线的起点较低，我们来看看怎么处理。 计算移动平均数的时候，初始化$v_{0} = 0$，$v_{1} = 0.98v_{0} +0.02\theta_{1}$，但是$v_{0} =0$，所以这部分没有了（$0.98v_{0}$），所以$v_{1} =0.02\theta_{1}$，所以如果一天温度是40华氏度，那么$v_{1} = 0.02\theta_{1} =0.02 \times 40 = 8$，因此得到的值会小很多，所以第一天温度的估测不准。 $v_{2} = 0.98v_{1} + 0.02\theta_{2}$，如果代入$v_{1}$，然后相乘，所以$v_{2}= 0.98 \times 0.02\theta_{1} + 0.02\theta_{2} = 0.0196\theta_{1} +0.02\theta_{2}$，假设$\theta_{1}$和$\theta_{2}$都是正数，计算后$v_{2}$要远小于$\theta_{1}$和$\theta_{2}$，所以$v_{2}$不能很好估测出这一年前两天的温度。 有个办法可以修改这一估测，让估测变得更好，更准确，特别是在估测初期，也就是不用$v_{t}$，而是用$\frac{v_{t} }{1- \beta^{t} }$，t就是现在的天数。举个具体例子，当$t=2$时，$1 - \beta^{t} = 1 - {0.98}^{2} = 0.0396$，因此对第二天温度的估测变成了$\frac{v_{2} }{0.0396} =\frac{0.0196\theta_{1} + 0.02\theta_{2} }{0.0396}$，也就是$\theta_{1}$和$\theta_{2}$的加权平均数，并去除了偏差。你会发现随着$t$增加，$\beta^{t}$接近于0，所以当$t$很大的时候，偏差修正几乎没有作用，因此当$t$较大的时候，紫线基本和绿线重合了。不过在开始学习阶段，你才开始预测热身练习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。 在机器学习中，在计算指数加权平均数的大部分时候，大家不在乎执行偏差修正，因为大部分人宁愿熬过初始时期，拿到具有偏差的估测，然后继续计算下去。如果你关心初始时期的偏差，在刚开始计算指数加权移动平均数的时候，偏差修正能帮助你在早期获取更好的估测。 所以你学会了计算指数加权移动平均数，我们接着用它来构建更好的优化算法吧！ 2.6 动量梯度下降法（Gradient descent with Momentum）还有一种算法叫做Momentum，或者叫做动量梯度下降法，运行速度几乎总是快于标准的梯度下降算法，简而言之，基本的想法就是计算梯度的指数加权平均数，并利用该梯度更新你的权重，在本视频中，我们呢要一起拆解单句描述，看看你到底如何计算。 例如，如果你要优化成本函数，函数形状如图，红点代表最小值的位置，假设你从这里（蓝色点）开始梯度下降法，如果进行梯度下降法的一次迭代，无论是batch或mini-batch下降法，也许会指向这里，现在在椭圆的另一边，计算下一步梯度下降，结果或许如此，然后再计算一步，再一步，计算下去，你会发现梯度下降法要很多计算步骤对吧？ 慢慢摆动到最小值，这种上下波动减慢了梯度下降法的速度，你就无法使用更大的学习率，如果你要用较大的学习率（紫色箭头），结果可能会偏离函数的范围，为了避免摆动过大，你要用一个较小的学习率。 另一个看待问题的角度是，在纵轴上，你希望学习慢一点，因为你不想要这些摆动，但是在横轴上，你希望加快学习，你希望快速从左向右移，移向最小值，移向红点。所以使用动量梯度下降法，你需要做的是，在每次迭代中，确切来说在第$t$次迭代的过程中，你会计算微分$dW$，$db$，我会省略上标$[l]$，你用现有的mini-batch计算$dW$，$db$。如果你用batch梯度下降法，现在的mini-batch就是全部的batch，对于batch梯度下降法的效果是一样的。如果现有的mini-batch就是整个训练集，效果也不错，你要做的是计算$v_{ {dW} }= \beta v_{ {dW} } + \left( 1 - \beta \right)dW$，这跟我们之前的计算相似，也就是$v = \beta v + \left( 1 - \beta \right)\theta_{t}$，$dW$的移动平均数，接着同样地计算$v_{db}$，$v_{db} = \beta v_{ {db} } + ( 1 - \beta){db}$，然后重新赋值权重，$W:= W -av_{ {dW} }$，同样$b:= b - a v_{db}$，这样就可以减缓梯度下降的幅度。 例如，在上几个导数中，你会发现这些纵轴上的摆动平均值接近于零，所以在纵轴方向，你希望放慢一点，平均过程中，正负数相互抵消，所以平均值接近于零。但在横轴方向，所有的微分都指向横轴方向，因此横轴方向的平均值仍然较大，因此用算法几次迭代后，你发现动量梯度下降法，最终纵轴方向的摆动变小了，横轴方向运动更快，因此你的算法走了一条更加直接的路径，在抵达最小值的路上减少了摆动。 动量梯度下降法的一个本质，这对有些人而不是所有人有效，就是如果你要最小化碗状函数，这是碗的形状，我画的不太好。 它们能够最小化碗状函数，这些微分项，想象它们为你从山上往下滚的一个球，提供了加速度，Momentum项相当于速度。 想象你有一个碗，你拿一个球，微分项给了这个球一个加速度，此时球正向山下滚，球因为加速度越滚越快，而因为$\beta$ 稍小于1，表现出一些摩擦力，所以球不会无限加速下去，所以不像梯度下降法，每一步都独立于之前的步骤，你的球可以向下滚，获得动量，可以从碗向下加速获得动量。我发现这个球从碗滚下的比喻，物理能力强的人接受得比较好，但不是所有人都能接受，如果球从碗中滚下这个比喻，你理解不了，别担心。 最后我们来看具体如何计算，算法在此。 所以你有两个超参数，学习率$a$以及参数$\beta$，$\beta$控制着指数加权平均数。$\beta$最常用的值是0.9，我们之前平均了过去十天的温度，所以现在平均了前十次迭代的梯度。实际上$\beta$为0.9时，效果不错，你可以尝试不同的值，可以做一些超参数的研究，不过0.9是很棒的鲁棒数。那么关于偏差修正，所以你要拿$v_{dW}$和$v_{db}$除以$1-\beta^{t}$，实际上人们不这么做，因为10次迭代之后，因为你的移动平均已经过了初始阶段。实际中，在使用梯度下降法或动量梯度下降法时，人们不会受到偏差修正的困扰。当然$v_{ {dW} }$初始值是0，要注意到这是和$dW$拥有相同维数的零矩阵，也就是跟$W$拥有相同的维数，$v_{db}$的初始值也是向量零，所以和$db$拥有相同的维数，也就是和$b$是同一维数。 最后要说一点，如果你查阅了动量梯度下降法相关资料，你经常会看到一个被删除了的专业词汇，$1-\beta$被删除了，最后得到的是$v_{dW}= \beta v_{ {dW} } +dW$。用紫色版本的结果就是，所以$v_{ {dW} }$缩小了$1-\beta$倍，相当于乘以$\frac{1}{1- \beta}$，所以你要用梯度下降最新值的话，$a$要根据$\frac{1}{1 -\beta}$相应变化。实际上，二者效果都不错，只会影响到学习率$a$的最佳值。我觉得这个公式用起来没有那么自然，因为有一个影响，如果你最后要调整超参数$\beta$，就会影响到$v_{ {dW} }$和$v_{db}$，你也许还要修改学习率$a$，所以我更喜欢左边的公式，而不是删去了$1-\beta$的这个公式，所以我更倾向于使用左边的公式，也就是有$1-\beta$的这个公式，但是两个公式都将$\beta$设置为0.9，是超参数的常见选择，只是在这两个公式中，学习率$a$的调整会有所不同。 所以这就是动量梯度下降法，这个算法肯定要好于没有Momentum的梯度下降算法，我们还可以做别的事情来加快学习算法，我们将在接下来的视频中探讨这些问题。 2.7 RMSprop你们知道了动量（Momentum）可以加快梯度下降，还有一个叫做RMSprop的算法，全称是root mean square prop算法，它也可以加速梯度下降，我们来看看它是如何运作的。 回忆一下我们之前的例子，如果你执行梯度下降，虽然横轴方向正在推进，但纵轴方向会有大幅度摆动，为了分析这个例子，假设纵轴代表参数$b$，横轴代表参数$W$，可能有$W_{1}$，$W_{2}$或者其它重要的参数，为了便于理解，被称为$b$和$W$。 所以，你想减缓$b$方向的学习，即纵轴方向，同时加快，至少不是减缓横轴方向的学习，RMSprop算法可以实现这一点。 在第$t$次迭代中，该算法会照常计算当下mini-batch的微分$dW$，$db$，所以我会保留这个指数加权平均数，我们用到新符号$S_{dW}$，而不是$v_{dW}$，因此$S_{dW}= \beta S_{dW} + (1 -\beta) {dW}^{2}$，澄清一下，这个平方的操作是针对这一整个符号的，这样做能够保留微分平方的加权平均数，同样$S_{db}= \beta S_{db} + (1 - \beta){db}^{2}$，再说一次，平方是针对整个符号的操作。 接着RMSprop会这样更新参数值，$W:= W -a\frac{dW}{\sqrt{S_{dW} }}$，$b:=b -\alpha\frac{db}{\sqrt{S_{db} }}$，我们来理解一下其原理。记得在横轴方向或者在例子中的$W$方向，我们希望学习速度快，而在垂直方向，也就是例子中的$b$方向，我们希望减缓纵轴上的摆动，所以有了$S_{dW}$和$S_{db}$，我们希望$S_{dW}$会相对较小，所以我们要除以一个较小的数，而希望$S_{db}$又较大，所以这里我们要除以较大的数字，这样就可以减缓纵轴上的变化。你看这些微分，垂直方向的要比水平方向的大得多，所以斜率在$b$方向特别大，所以这些微分中，$db$较大，$dW$较小，因为函数的倾斜程度，在纵轴上，也就是b方向上要大于在横轴上，也就是$W$方向上。$db$的平方较大，所以$S_{db}$也会较大，而相比之下，$dW$会小一些，亦或$dW$平方会小一些，因此$S_{dW}$会小一些，结果就是纵轴上的更新要被一个较大的数相除，就能消除摆动，而水平方向的更新则被较小的数相除。 RMSprop的影响就是你的更新最后会变成这样（绿色线），纵轴方向上摆动较小，而横轴方向继续推进。还有个影响就是，你可以用一个更大学习率$a$，然后加快学习，而无须在纵轴上垂直方向偏离。 要说明一点，我一直把纵轴和横轴方向分别称为$b$和$W$，只是为了方便展示而已。实际中，你会处于参数的高维度空间，所以需要消除摆动的垂直维度，你需要消除摆动，实际上是参数$W_1$，$W_2$等的合集，水平维度可能$W_3$，$W_4$等等，因此把$W$和$b$分开只是方便说明。实际中$dW$是一个高维度的参数向量，$db$也是一个高维度参数向量，但是你的直觉是，在你要消除摆动的维度中，最终你要计算一个更大的和值，这个平方和微分的加权平均值，所以你最后去掉了那些有摆动的方向。所以这就是RMSprop，全称是均方根，因为你将微分进行平方，然后最后使用平方根。 最后再就这个算法说一些细节的东西，然后我们再继续。下一个视频中，我们会将RMSprop和Momentum结合起来，我们在Momentum中采用超参数$\beta$，为了避免混淆，我们现在不用$\beta$，而采用超参数$\beta_{2}$以保证在Momentum和RMSprop中采用同一超参数。要确保你的算法不会除以0，如果$S_{dW}$的平方根趋近于0怎么办？得到的答案就非常大，为了确保数值稳定，在实际操练的时候，你要在分母上加上一个很小很小的$\varepsilon$，$\varepsilon$是多少没关系，$10^{-8}$是个不错的选择，这只是保证数值能稳定一些，无论什么原因，你都不会除以一个很小很小的数。所以RMSprop跟Momentum有很相似的一点，可以消除梯度下降中的摆动，包括mini-batch梯度下降，并允许你使用一个更大的学习率$a$，从而加快你的算法学习速度。 所以你学会了如何运用RMSprop，这是给学习算法加速的另一方法。关于RMSprop的一个有趣的事是，它首次提出并不是在学术研究论文中，而是在多年前Jeff Hinton在Coursera的课程上。我想Coursera并不是故意打算成为一个传播新兴的学术研究的平台，但是却达到了意想不到的效果。就是从Coursera课程开始，RMSprop开始被人们广为熟知，并且发展迅猛。 我们讲过了Momentum，我们讲了RMSprop，如果二者结合起来，你会得到一个更好的优化算法，在下个视频中我们再好好讲一讲为什么。 2.8 Adam 优化算法(Adam optimization algorithm)在深度学习的历史上，包括许多知名研究者在内，提出了优化算法，并很好地解决了一些问题，但随后这些优化算法被指出并不能一般化，并不适用于多种神经网络，时间久了，深度学习圈子里的人开始多少有些质疑全新的优化算法，很多人都觉得动量（Momentum）梯度下降法很好用，很难再想出更好的优化算法。所以RMSprop以及Adam优化算法（Adam优化算法也是本视频的内容），就是少有的经受住人们考验的两种算法，已被证明适用于不同的深度学习结构，这个算法我会毫不犹豫地推荐给你，因为很多人都试过，并且用它很好地解决了许多问题。 Adam优化算法基本上就是将Momentum和RMSprop结合在一起，那么来看看如何使用Adam算法。 使用Adam算法，首先你要初始化，$v_{dW} = 0$，$S_{dW} =0$，$v_{db} = 0$，$S_{db} =0$，在第$t$次迭代中，你要计算微分，用当前的mini-batch计算$dW$，$db$，一般你会用mini-batch梯度下降法。接下来计算Momentum指数加权平均数，所以$v_{dW}= \beta_{1}v_{dW} + ( 1 - \beta_{1})dW$（使用$\beta_{1}$，这样就不会跟超参数$\beta_{2}$混淆，因为后面RMSprop要用到$\beta_{2}$），使用Momentum时我们肯定会用这个公式，但现在不叫它$\beta$，而叫它$\beta_{1}$。同样$v_{db}= \beta_{1}v_{db} + ( 1 -\beta_{1} ){db}$。 接着你用RMSprop进行更新，即用不同的超参数$\beta_{2}$，$S_{dW}=\beta_{2}S_{dW} + ( 1 - \beta_{2}){(dW)}^{2}$，再说一次，这里是对整个微分$dW$进行平方处理，$S_{db} =\beta_{2}S_{db} + \left( 1 - \beta_{2} \right){(db)}^{2}$。 相当于Momentum更新了超参数$\beta_{1}$，RMSprop更新了超参数$\beta_{2}$。一般使用Adam算法的时候，要计算偏差修正，$v_{dW}^{\text{corrected} }$，修正也就是在偏差修正之后， $v_{dW}^{\text{corrected} }= \frac{v_{dW} }{1 - \beta_{1}^{t} }$， 同样$v_{db}^{\text{corrected} } =\frac{v_{db} }{1 -\beta_{1}^{t} }$， $S$也使用偏差修正，也就是$S_{dW}^{\text{corrected} } =\frac{S_{dW} }{1 - \beta_{2}^{t} }$，$S_{db}^{\text{corrected} } =\frac{S_{db} }{1 - \beta_{2}^{t} }$。 最后更新权重，所以$W$更新后是$W:= W - \frac{a v_{dW}^{\text{corrected} }}{\sqrt{S_{dW}^{\text{corrected} }} +\varepsilon}$（如果你只是用Momentum，使用$v_{dW}$或者修正后的$v_{dW}$，但现在我们加入了RMSprop的部分，所以我们要除以修正后$S_{dW}$的平方根加上$\varepsilon$）。 根据类似的公式更新$b$值，$b:=b - \frac{\alpha v_{\text{db} }^{\text{corrected} }}{\sqrt{S_{\text{db} }^{\text{corrected} }} +\varepsilon}$。 所以Adam算法结合了Momentum和RMSprop梯度下降法，并且是一种极其常用的学习算法，被证明能有效适用于不同神经网络，适用于广泛的结构。 本算法中有很多超参数，超参数学习率$a$很重要，也经常需要调试，你可以尝试一系列值，然后看哪个有效。$\beta_{1}$常用的缺省值为0.9，这是dW的移动平均数，也就是$dW$的加权平均数，这是Momentum涉及的项。至于超参数$\beta_{2}$，Adam论文作者，也就是Adam算法的发明者，推荐使用0.999，这是在计算${(dW)}^{2}$以及${(db)}^{2}$的移动加权平均值，关于$\varepsilon$的选择其实没那么重要，Adam论文的作者建议$\varepsilon$为$10^{-8}$，但你并不需要设置它，因为它并不会影响算法表现。但是在使用Adam的时候，人们往往使用缺省值即可，$\beta_{1}$，$\beta_{2}$和$\varepsilon$都是如此，我觉得没人会去调整$\varepsilon$，然后尝试不同的$a$值，看看哪个效果最好。你也可以调整$\beta_{1}$和$\beta_{2}$，但我认识的业内人士很少这么干。 为什么这个算法叫做Adam？Adam代表的是Adaptive Moment Estimation，$\beta_{1}$用于计算这个微分（$dW$），叫做第一矩，$\beta_{2}$用来计算平方数的指数加权平均数（${(dW)}^{2}$），叫做第二矩，所以Adam的名字由此而来，但是大家都简称Adam权威算法。 顺便提一下，我有一个老朋友兼合作伙伴叫做Adam Coates。据我所知，他跟Adam算法没有任何关系，不过我觉得他偶尔会用到这个算法，不过有时有人会问我这个问题，我想你可能也有相同的疑惑。 这就是关于Adam优化算法的全部内容，有了它，你可以更加快速地训练神经网络，在结束本周课程之前，我们还要讲一下超参数调整，以及更好地理解神经网络的优化问题有哪些。下个视频中，我们将讲讲学习率衰减。 2.9 学习率衰减(Learning rate decay)加快学习算法的一个办法就是随时间慢慢减少学习率，我们将之称为学习率衰减，我们来看看如何做到，首先通过一个例子看看，为什么要计算学习率衰减。 假设你要使用mini-batch梯度下降法，mini-batch数量不大，大概64或者128个样本，在迭代过程中会有噪音（蓝色线），下降朝向这里的最小值，但是不会精确地收敛，所以你的算法最后在附近摆动，并不会真正收敛，因为你用的$a$是固定值，不同的mini-batch中有噪音。 但要慢慢减少学习率$a$的话，在初期的时候，$a$学习率还较大，你的学习还是相对较快，但随着$a$变小，你的步伐也会变慢变小，所以最后你的曲线（绿色线）会在最小值附近的一小块区域里摆动，而不是在训练过程中，大幅度在最小值附近摆动。 所以慢慢减少$a$的本质在于，在学习初期，你能承受较大的步伐，但当开始收敛的时候，小一些的学习率能让你步伐小一些。 你可以这样做到学习率衰减，记得一代要遍历一次数据，如果你有以下这样的训练集， 你应该拆分成不同的mini-batch，第一次遍历训练集叫做第一代。第二次就是第二代，依此类推，你可以将$a$学习率设为$a= \frac{1}{1 + decayrate * \text{epoch}\text{-num} }a_{0}$（decay-rate称为衰减率，epoch-num为代数，$\alpha_{0}$为初始学习率），注意这个衰减率是另一个你需要调整的超参数。 这里有一个具体例子，如果你计算了几代，也就是遍历了几次，如果$a_{0}$为0.2，衰减率decay-rate为1，那么在第一代中，$a = \frac{1}{1 + 1}a_{0} = 0.1$，这是在代入这个公式计算（$a= \frac{1}{1 + decayrate * \text{epoch}\text{-num} }a_{0}$），此时衰减率是1而代数是1。在第二代学习率为0.67，第三代变成0.5，第四代为0.4等等，你可以自己多计算几个数据。要理解，作为代数函数，根据上述公式，你的学习率呈递减趋势。如果你想用学习率衰减，要做的是要去尝试不同的值，包括超参数$a_{0}$，以及超参数衰退率，找到合适的值，除了这个学习率衰减的公式，人们还会用其它的公式。 比如，这个叫做指数衰减，其中$a$相当于一个小于1的值，如$a ={0.95}^{\text{epoch-num} } a_{0}$，所以你的学习率呈指数下降。 人们用到的其它公式有$a =\frac{k}{\sqrt{\text{epoch-num} }}a_{0}$或者$a =\frac{k}{\sqrt{t} }a_{0}$（$t$为mini-batch的数字）。 有时人们也会用一个离散下降的学习率，也就是某个步骤有某个学习率，一会之后，学习率减少了一半，一会儿减少一半，一会儿又一半，这就是离散下降（discrete stair cease）的意思。 到现在，我们讲了一些公式，看学习率$a$究竟如何随时间变化。人们有时候还会做一件事，手动衰减。如果你一次只训练一个模型，如果你要花上数小时或数天来训练，有些人的确会这么做，看看自己的模型训练，耗上数日，然后他们觉得，学习速率变慢了，我把$a$调小一点。手动控制$a$当然有用，时复一时，日复一日地手动调整$a$，只有模型数量小的时候有用，但有时候人们也会这么做。 所以现在你有了多个选择来控制学习率$a$。你可能会想，好多超参数，究竟我应该做哪一个选择，我觉得，现在担心为时过早。下一周，我们会讲到，如何系统选择超参数。对我而言，学习率衰减并不是我尝试的要点，设定一个固定的$a$，然后好好调整，会有很大的影响，学习率衰减的确大有裨益，有时候可以加快训练，但它并不是我会率先尝试的内容，但下周我们将涉及超参数调整，你能学到更多系统的办法来管理所有的超参数，以及如何高效搜索超参数。 这就是学习率衰减，最后我还要讲讲神经网络中的局部最优以及鞍点，所以能更好理解在训练神经网络过程中，你的算法正在解决的优化问题，下个视频我们就好好聊聊这些问题。 2.10 局部最优的问题(The problem of local optima)在深度学习研究早期，人们总是担心优化算法会困在极差的局部最优，不过随着深度学习理论不断发展，我们对局部最优的理解也发生了改变。我向你展示一下现在我们怎么看待局部最优以及深度学习中的优化问题。 这是曾经人们在想到局部最优时脑海里会出现的图，也许你想优化一些参数，我们把它们称之为$W_{1}$和$W_{2}$，平面的高度就是损失函数。在图中似乎各处都分布着局部最优。梯度下降法或者某个算法可能困在一个局部最优中，而不会抵达全局最优。如果你要作图计算一个数字，比如说这两个维度，就容易出现有多个不同局部最优的图，而这些低维的图曾经影响了我们的理解，但是这些理解并不正确。事实上，如果你要创建一个神经网络，通常梯度为零的点并不是这个图中的局部最优点，实际上成本函数的零梯度点，通常是鞍点。 也就是在这个点，这里是$W_{1}$和$W_{2}$，高度即成本函数$J$的值。 但是一个具有高维度空间的函数，如果梯度为0，那么在每个方向，它可能是凸函数，也可能是凹函数。如果你在2万维空间中，那么想要得到局部最优，所有的2万个方向都需要是这样，但发生的机率也许很小，也许是$2^{-20000}$，你更有可能遇到有些方向的曲线会这样向上弯曲，另一些方向曲线向下弯，而不是所有的都向上弯曲，因此在高维度空间，你更可能碰到鞍点。 就像下面的这种： 而不会碰到局部最优。至于为什么会把一个曲面叫做鞍点，你想象一下，就像是放在马背上的马鞍一样，如果这是马，这是马的头，这就是马的眼睛，画得不好请多包涵，然后你就是骑马的人，要坐在马鞍上，因此这里的这个点，导数为0的点，这个点叫做鞍点。我想那确实是你坐在马鞍上的那个点，而这里导数为0。 所以我们从深度学习历史中学到的一课就是，我们对低维度空间的大部分直觉，比如你可以画出上面的图，并不能应用到高维度空间中。适用于其它算法，因为如果你有2万个参数，那么$J$函数有2万个维度向量，你更可能遇到鞍点，而不是局部最优点。 如果局部最优不是问题，那么问题是什么？结果是平稳段会减缓学习，平稳段是一块区域，其中导数长时间接近于0，如果你在此处，梯度会从曲面从从上向下下降，因为梯度等于或接近0，曲面很平坦，你得花上很长时间慢慢抵达平稳段的这个点，因为左边或右边的随机扰动，我换个笔墨颜色，大家看得清楚一些，然后你的算法能够走出平稳段（红色笔）。 我们可以沿着这段长坡走，直到这里，然后走出平稳段。 所以此次视频的要点是，首先，你不太可能困在极差的局部最优中，条件是你在训练较大的神经网络，存在大量参数，并且成本函数$J$被定义在较高的维度空间。 第二点，平稳段是一个问题，这样使得学习十分缓慢，这也是像Momentum或是RMSprop，Adam这样的算法，能够加速学习算法的地方。在这些情况下，更成熟的优化算法，如Adam算法，能够加快速度，让你尽早往下走出平稳段。 因为你的网络要解决优化问题，说实话，要面临如此之高的维度空间，我觉得没有人有那么好的直觉，知道这些空间长什么样，而且我们对它们的理解还在不断发展，不过我希望这一点能够让你更好地理解优化算法所面临的问题。 超参数调试、Batch正则化和程序框架（Hyperparameter tuning）3.1 调试处理（Tuning process）大家好，欢迎回来，目前为止，你已经了解到，神经网络的改变会涉及到许多不同超参数的设置。现在，对于超参数而言，你要如何找到一套好的设定呢？在此视频中，我想和你分享一些指导原则，一些关于如何系统地组织超参调试过程的技巧，希望这些能够让你更有效的聚焦到合适的超参设定中。 关于训练深度最难的事情之一是你要处理的参数的数量，从学习速率$a$到Momentum（动量梯度下降法）的参数$\beta$。如果使用Momentum或Adam优化算法的参数，$\beta_{1}$，${\beta}_{2}$和$\varepsilon$，也许你还得选择层数，也许你还得选择不同层中隐藏单元的数量，也许你还想使用学习率衰减。所以，你使用的不是单一的学习率$a$。接着，当然你可能还需要选择mini-batch的大小。 结果证实一些超参数比其它的更为重要，我认为，最为广泛的学习应用是$a$，学习速率是需要调试的最重要的超参数。 除了$a$，还有一些参数需要调试，例如Momentum参数$\beta$，0.9就是个很好的默认值。我还会调试mini-batch的大小，以确保最优算法运行有效。我还会经常调试隐藏单元，我用橙色圈住的这些，这三个是我觉得其次比较重要的，相对于$a$而言。重要性排第三位的是其他因素，层数有时会产生很大的影响，学习率衰减也是如此。当应用Adam算法时，事实上，我从不调试$\beta_{1}$，${\beta}_{2}$和$\varepsilon$，我总是选定其分别为0.9，0.999和$10^{-8}$，如果你想的话也可以调试它们。 但希望你粗略了解到哪些超参数较为重要，$a$无疑是最重要的，接下来是我用橙色圈住的那些，然后是我用紫色圈住的那些，但这不是严格且快速的标准，我认为，其它深度学习的研究者可能会很不同意我的观点或有着不同的直觉。 现在，如果你尝试调整一些超参数，该如何选择调试值呢？在早一代的机器学习算法中，如果你有两个超参数，这里我会称之为超参1，超参2，常见的做法是在网格中取样点，像这样，然后系统的研究这些数值。这里我放置的是5×5的网格，实践证明，网格可以是5×5，也可多可少，但对于这个例子，你可以尝试这所有的25个点，然后选择哪个参数效果最好。当参数的数量相对较少时，这个方法很实用。 在深度学习领域，我们常做的，我推荐你采用下面的做法，随机选择点，所以你可以选择同等数量的点，对吗？25个点，接着，用这些随机取的点试验超参数的效果。之所以这么做是因为，对于你要解决的问题而言，你很难提前知道哪个超参数最重要，正如你之前看到的，一些超参数的确要比其它的更重要。 举个例子，假设超参数1是$a$（学习速率），取一个极端的例子，假设超参数2是Adam算法中，分母中的$\varepsilon$。在这种情况下，$a$的取值很重要，而$\varepsilon$取值则无关紧要。如果你在网格中取点，接着，你试验了$a$的5个取值，那你会发现，无论$\varepsilon$取何值，结果基本上都是一样的。所以，你知道共有25种模型，但进行试验的$a$值只有5个，我认为这是很重要的。 对比而言，如果你随机取值，你会试验25个独立的$a$，似乎你更有可能发现效果做好的那个。 我已经解释了两个参数的情况，实践中，你搜索的超参数可能不止两个。假如，你有三个超参数，这时你搜索的不是一个方格，而是一个立方体，超参数3代表第三维，接着，在三维立方体中取值，你会试验大量的更多的值，三个超参数中每个都是。 实践中，你搜索的可能不止三个超参数有时很难预知，哪个是最重要的超参数，对于你的具体应用而言，随机取值而不是网格取值表明，你探究了更多重要超参数的潜在值，无论结果是什么。 当你给超参数取值时，另一个惯例是采用由粗糙到精细的策略。 比如在二维的那个例子中，你进行了取值，也许你会发现效果最好的某个点，也许这个点周围的其他一些点效果也很好，那在接下来要做的是放大这块小区域（小蓝色方框内），然后在其中更密集得取值或随机取值，聚集更多的资源，在这个蓝色的方格中搜索，如果你怀疑这些超参数在这个区域的最优结果，那在整个的方格中进行粗略搜索后，你会知道接下来应该聚焦到更小的方格中。在更小的方格中，你可以更密集得取点。所以这种从粗到细的搜索也经常使用。 通过试验超参数的不同取值，你可以选择对训练集目标而言的最优值，或对于开发集而言的最优值，或在超参搜索过程中你最想优化的东西。 我希望，这能给你提供一种方法去系统地组织超参数搜索过程。另一个关键点是随机取值和精确搜索，考虑使用由粗糙到精细的搜索过程。但超参数的搜索内容还不止这些，在下一个视频中，我会继续讲解关于如何选择超参数取值的合理范围。 3.2 为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）在上一个视频中，你已经看到了在超参数范围中，随机取值可以提升你的搜索效率。但随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数，这很重要。在这个视频中，我会教你怎么做。 假设你要选取隐藏单元的数量$n^{[l]}$，假设，你选取的取值范围是从50到100中某点，这种情况下，看到这条从50-100的数轴，你可以随机在其取点，这是一个搜索特定超参数的很直观的方式。或者，如果你要选取神经网络的层数，我们称之为字母$L$，你也许会选择层数为2到4中的某个值，接着顺着2，3，4随机均匀取样才比较合理，你还可以应用网格搜索，你会觉得2，3，4，这三个数值是合理的，这是在几个在你考虑范围内随机均匀取值的例子，这些取值还蛮合理的，但对某些超参数而言不适用。 看看这个例子，假设你在搜索超参数$a$（学习速率），假设你怀疑其值最小是0.0001或最大是1。如果你画一条从0.0001到1的数轴，沿其随机均匀取值，那90%的数值将会落在0.1到1之间，结果就是，在0.1到1之间，应用了90%的资源，而在0.0001到0.1之间，只有10%的搜索资源，这看上去不太对。 反而，用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，分别依次取0.0001，0.001，0.01，0.1，1，在对数轴上均匀随机取点，这样，在0.0001到0.001之间，就会有更多的搜索资源可用，还有在0.001到0.01之间等等。 所以在Python中，你可以这样做，使r=-4*np.random.rand()，然后$a$随机取值，$ a =10^{r}$，所以，第一行可以得出$r \in [ 4,0]$，那么$a \in[10^{-4},10^{0}]$，所以最左边的数字是$10^{-4}$，最右边是$10^{0}$。 更常见的情况是，如果你在$10^{a}$和$10^{b}$之间取值，在此例中，这是$10^{a}$（0.0001），你可以通过$\operatorname{}{0.0001}$算出$a$的值，即-4，在右边的值是$10^{b}$，你可以算出$b$的值$\operatorname{}1$，即0。你要做的就是在$[a,b]$区间随机均匀地给$r$取值，这个例子中$r \in \lbrack - 4,0\rbrack$，然后你可以设置$a$的值，基于随机取样的超参数$a =10^{r}$。 所以总结一下，在对数坐标下取值，取最小值的对数就得到$a$的值，取最大值的对数就得到$b$值，所以现在你在对数轴上的$10^{a}$到$10^{b}$区间取值，在$a$，$b$间随意均匀的选取$r$值，将超参数设置为$10^{r}$，这就是在对数轴上取值的过程。 最后，另一个棘手的例子是给$\beta$ 取值，用于计算指数的加权平均值。假设你认为$\beta$是0.9到0.999之间的某个值，也许这就是你想搜索的范围。记住这一点，当计算指数的加权平均值时，取0.9就像在10个值中计算平均值，有点类似于计算10天的温度平均值，而取0.999就是在1000个值中取平均。 所以和上张幻灯片上的内容类似，如果你想在0.9到0.999区间搜索，那就不能用线性轴取值，对吧？不要随机均匀在此区间取值，所以考虑这个问题最好的方法就是，我们要探究的是$1-\beta$，此值在0.1到0.001区间内，所以我们会给$1-\beta$取值，大概是从0.1到0.001，应用之前幻灯片中介绍的方法，这是$10^{-1}$，这是$10^{-3}$，值得注意的是，在之前的幻灯片里，我们把最小值写在左边，最大值写在右边，但在这里，我们颠倒了大小。这里，左边的是最大值，右边的是最小值。所以你要做的就是在$[-3,-1]$里随机均匀的给r取值。你设定了$1- \beta = 10^{r}$，所以$\beta = 1-10^{r}$，然后这就变成了在特定的选择范围内超参数随机取值。希望用这种方式得到想要的结果，你在0.9到0.99区间探究的资源，和在0.99到0.999区间探究的一样多。 所以，如果你想研究更多正式的数学证明，关于为什么我们要这样做，为什么用线性轴取值不是个好办法，这是因为当$\beta$ 接近1时，所得结果的灵敏度会变化，即使$\beta$有微小的变化。所以$\beta$ 在0.9到0.9005之间取值，无关紧要，你的结果几乎不会变化。 但$\beta$值如果在0.999到0.9995之间，这会对你的算法产生巨大影响，对吧？在这两种情况下，是根据大概10个值取平均。但这里，它是指数的加权平均值，基于1000个值，现在是2000个值，因为这个公式$\frac{1}{1- \beta}$，当$\beta$接近1时，$\beta$就会对细微的变化变得很敏感。所以整个取值过程中，你需要更加密集地取值，在$\beta$ 接近1的区间内，或者说，当$1-\beta$ 接近于0时，这样，你就可以更加有效的分布取样点，更有效率的探究可能的结果。 希望能帮助你选择合适的标尺，来给超参数取值。如果你没有在超参数选择中作出正确的标尺决定，别担心，即使你在均匀的标尺上取值，如果数值总量较多的话，你也会得到还不错的结果，尤其是应用从粗到细的搜索方法，在之后的迭代中，你还是会聚焦到有用的超参数取值范围上。 希望这会对你的超参数搜索有帮助，下一个视频中，我们将会分享一些关于如何组建搜索过程的思考，希望它能使你的工作更高效。 3.3 超参数调试的实践：Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）到现在为止，你已经听了许多关于如何搜索最优超参数的内容，在结束我们关于超参数搜索的讨论之前，我想最后和你分享一些建议和技巧，关于如何组织你的超参数搜索过程。 如今的深度学习已经应用到许多不同的领域，某个应用领域的超参数设定，有可能通用于另一领域，不同的应用领域出现相互交融。比如，我曾经看到过计算机视觉领域中涌现的巧妙方法，比如说Confonets或ResNets，这我们会在后续课程中讲到。它还成功应用于语音识别，我还看到过最初起源于语音识别的想法成功应用于NLP等等。 深度学习领域中，发展很好的一点是，不同应用领域的人们会阅读越来越多其它研究领域的文章，跨领域去寻找灵感。 就超参数的设定而言，我见到过有些直觉想法变得很缺乏新意，所以，即使你只研究一个问题，比如说逻辑学，你也许已经找到一组很好的参数设置，并继续发展算法，或许在几个月的过程中，观察到你的数据会逐渐改变，或也许只是在你的数据中心更新了服务器，正因为有了这些变化，你原来的超参数的设定不再好用，所以我建议，或许只是重新测试或评估你的超参数，至少每隔几个月一次，以确保你对数值依然很满意。 最后，关于如何搜索超参数的问题，我见过大概两种重要的思想流派或人们通常采用的两种重要但不同的方式。 一种是你照看一个模型，通常是有庞大的数据组，但没有许多计算资源或足够的CPU和GPU的前提下，基本而言，你只可以一次负担起试验一个模型或一小批模型，在这种情况下，即使当它在试验时，你也可以逐渐改良。比如，第0天，你将随机参数初始化，然后开始试验，然后你逐渐观察自己的学习曲线，也许是损失函数J，或者数据设置误差或其它的东西，在第1天内逐渐减少，那这一天末的时候，你可能会说，看，它学习得真不错。我试着增加一点学习速率，看看它会怎样，也许结果证明它做得更好，那是你第二天的表现。两天后，你会说，它依旧做得不错，也许我现在可以填充下Momentum或减少变量。然后进入第三天，每天，你都会观察它，不断调整你的参数。也许有一天，你会发现你的学习率太大了，所以你可能又回归之前的模型，像这样，但你可以说是在每天花时间照看此模型，即使是它在许多天或许多星期的试验过程中。所以这是一个人们照料一个模型的方法，观察它的表现，耐心地调试学习率，但那通常是因为你没有足够的计算能力，不能在同一时间试验大量模型时才采取的办法。 另一种方法则是同时试验多种模型，你设置了一些超参数，尽管让它自己运行，或者是一天甚至多天，然后你会获得像这样的学习曲线，这可以是损失函数J或实验误差或损失或数据误差的损失，但都是你曲线轨迹的度量。同时你可以开始一个有着不同超参数设定的不同模型，所以，你的第二个模型会生成一个不同的学习曲线，也许是像这样的一条（紫色曲线），我会说这条看起来更好些。与此同时，你可以试验第三种模型，其可能产生一条像这样的学习曲线（红色曲线），还有另一条（绿色曲线），也许这条有所偏离，像这样，等等。或者你可以同时平行试验许多不同的模型，橙色的线就是不同的模型。用这种方式你可以试验许多不同的参数设定，然后只是最后快速选择工作效果最好的那个。在这个例子中，也许这条看起来是最好的（下方绿色曲线）。 打个比方，我把左边的方法称为熊猫方式。当熊猫有了孩子，他们的孩子非常少，一次通常只有一个，然后他们花费很多精力抚养熊猫宝宝以确保其能成活，所以，这的确是一种照料，一种模型类似于一只熊猫宝宝。对比而言，右边的方式更像鱼类的行为，我称之为鱼子酱方式。在交配季节，有些鱼类会产下一亿颗卵，但鱼类繁殖的方式是，它们会产生很多卵，但不对其中任何一个多加照料，只是希望其中一个，或其中一群，能够表现出色。我猜，这就是哺乳动物繁衍和鱼类，很多爬虫类动物繁衍的区别。我将称之为熊猫方式与鱼子酱方式，因为这很有趣，更容易记住。 所以这两种方式的选择，是由你拥有的计算资源决定的，如果你拥有足够的计算机去平行试验许多模型，那绝对采用鱼子酱方式，尝试许多不同的超参数，看效果怎么样。但在一些应用领域，比如在线广告设置和计算机视觉应用领域，那里的数据太多了，你需要试验大量的模型，所以同时试验大量的模型是很困难的，它的确是依赖于应用的过程。但我看到那些应用熊猫方式多一些的组织，那里，你会像对婴儿一样照看一个模型，调试参数，试着让它工作运转。尽管，当然，甚至是在熊猫方式中，试验一个模型，观察它工作与否，也许第二或第三个星期后，也许我应该建立一个不同的模型（绿色曲线），像熊猫那样照料它，我猜，这样一生中可以培育几个孩子，即使它们一次只有一个孩子或孩子的数量很少。 所以希望你能学会如何进行超参数的搜索过程，现在，还有另一种技巧，能使你的神经网络变得更加坚实，它并不是对所有的神经网络都适用，但当适用时，它可以使超参数搜索变得容易许多并加速试验过程，我们在下个视频中再讲解这个技巧。 3.4 归一化网络的激活函数（Normalizing activations in a network）在深度学习兴起后，最重要的一个思想是它的一种算法，叫做Batch归一化，由Sergey loffe和Christian Szegedy两位研究者创造。Batch归一化会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会是你的训练更加容易，甚至是深层网络。让我们来看看Batch归一化是怎么起作用的吧。 当训练一个模型，比如logistic回归时，你也许会记得，归一化输入特征可以加快学习过程。你计算了平均值，从训练集中减去平均值，计算了方差，接着根据方差归一化你的数据集，在之前的视频中我们看到，这是如何把学习问题的轮廓，从很长的东西，变成更圆的东西，更易于算法优化。所以这是有效的，对logistic回归和神经网络的归一化输入特征值而言。 那么更深的模型呢？你不仅输入了特征值$x$，而且这层有激活值$a^{[1]}$，这层有激活值$a^{[2]}$等等。如果你想训练这些参数，比如$w^{[3]}$，$b^{[3]}$，那归一化$a^{[2]}$的平均值和方差岂不是很好？以便使$w^{[3]}$，$b^{[3]}$的训练更有效率。在logistic回归的例子中，我们看到了如何归一化$x_{1}$，$x_{2}$，$x_{3}$，会帮助你更有效的训练$w$和$b$。 所以问题来了，对任何一个隐藏层而言，我们能否归一化$a$值，在此例中，比如说$a^{[2]}$的值，但可以是任何隐藏层的，以更快的速度训练$w^{[3]}$，$b^{[3]}$，因为$a^{[2]}$是下一层的输入值，所以就会影响$w^{[3]}$，$b^{[3]}$的训练。简单来说，这就是Batch归一化的作用。尽管严格来说，我们真正归一化的不是$a^{[2]}$，而是$z^{[2]}$，深度学习文献中有一些争论，关于在激活函数之前是否应该将值$z^{[2]}$归一化，或是否应该在应用激活函数$a^{[2]}$后再规范值。实践中，经常做的是归一化$z^{[2]}$，所以这就是我介绍的版本，我推荐其为默认选择，那下面就是Batch归一化的使用方法。 在神经网络中，已知一些中间值，假设你有一些隐藏单元值，从$z^{(1)}$到$z^{(m)}$，这些来源于隐藏层，所以这样写会更准确，即$z^{[l](i)}$为隐藏层，$i$从1到$m$，但这样书写，我要省略$l$及方括号，以便简化这一行的符号。所以已知这些值，如下，你要计算平均值，强调一下，所有这些都是针对$l$层，但我省略$l$及方括号，然后用正如你常用的那个公式计算方差，接着，你会取每个$z^{(i)}$值，使其规范化，方法如下，减去均值再除以标准偏差，为了使数值稳定，通常将$\varepsilon$作为分母，以防$σ=0$的情况。 所以现在我们已把这些$z$值标准化，化为含平均值0和标准单位方差，所以$z$的每一个分量都含有平均值0和方差1，但我们不想让隐藏单元总是含有平均值0和方差1，也许隐藏单元有了不同的分布会有意义，所以我们所要做的就是计算，我们称之为${\tilde{z} }^{(i)}$，${\tilde{z} }^{(i)}= \gamma z_{\text{norm} }^{(i)} +\beta$，这里$\gamma$和$\beta$是你模型的学习参数，所以我们使用梯度下降或一些其它类似梯度下降的算法，比如Momentum或者Nesterov，Adam，你会更新$\gamma$和$\beta$，正如更新神经网络的权重一样。 请注意$\gamma$和$\beta$的作用是，你可以随意设置${\tilde{z} }^{(i)}$的平均值，事实上，如果$\gamma= \sqrt{\sigma^{2} +\varepsilon}$，如果$\gamma$等于这个分母项（$z_{\text{norm} }^{(i)} = \frac{z^{(i)} -\mu}{\sqrt{\sigma^{2} +\varepsilon} }$中的分母），$\beta$等于$\mu$，这里的这个值是$z_{\text{norm} }^{(i)}= \frac{z^{(i)} - \mu}{\sqrt{\sigma^{2} + \varepsilon} }$中的$\mu$，那么$\gamma z_{\text{norm} }^{(i)} +\beta$的作用在于，它会精确转化这个方程，如果这些成立（$\gamma =\sqrt{\sigma^{2} + \varepsilon},\beta =\mu$），那么${\tilde{z} }^{(i)} = z^{(i)}$。 通过对$\gamma$和$\beta$合理设定，规范化过程，即这四个等式，从根本来说，只是计算恒等函数，通过赋予$\gamma$和$\beta$其它值，可以使你构造含其它平均值和方差的隐藏单元值。 所以，在网络匹配这个单元的方式，之前可能是用$z^{(1)}$，$z^{(2)}$等等，现在则会用${\tilde{z} }^{(i)}$取代$z^{(i)}$，方便神经网络中的后续计算。如果你想放回$[l]$，以清楚的表明它位于哪层，你可以把它放这。 所以我希望你学到的是，归一化输入特征$X$是怎样有助于神经网络中的学习，Batch归一化的作用是它适用的归一化过程，不只是输入层，甚至同样适用于神经网络中的深度隐藏层。你应用Batch归一化了一些隐藏单元值中的平均值和方差，不过训练输入和这些隐藏单元值的一个区别是，你也许不想隐藏单元值必须是平均值0和方差1。 比如，如果你有sigmoid激活函数，你不想让你的值总是全部集中在这里，你想使它们有更大的方差，或不是0的平均值，以便更好的利用非线性的sigmoid函数，而不是使所有的值都集中于这个线性版本中，这就是为什么有了$\gamma$和$\beta$两个参数后，你可以确保所有的$z^{(i)}$值可以是你想赋予的任意值，或者它的作用是保证隐藏的单元已使均值和方差标准化。那里，均值和方差由两参数控制，即$\gamma$和$\beta$，学习算法可以设置为任何值，所以它真正的作用是，使隐藏单元值的均值和方差标准化，即$z^{(i)}$有固定的均值和方差，均值和方差可以是0和1，也可以是其它值，它是由$\gamma$和$\beta$两参数控制的。 我希望你能学会怎样使用Batch归一化，至少就神经网络的单一层而言，在下一个视频中，我会教你如何将Batch归一化与神经网络甚至是深度神经网络相匹配。对于神经网络许多不同层而言，又该如何使它适用，之后，我会告诉你，Batch归一化有助于训练神经网络的原因。所以如果觉得Batch归一化起作用的原因还显得有点神秘，那跟着我走，在接下来的两个视频中，我们会弄清楚。 3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）你已经看到那些等式，它可以在单一隐藏层进行Batch归一化，接下来，让我们看看它是怎样在深度网络训练中拟合的吧。 假设你有一个这样的神经网络，我之前说过，你可以认为每个单元负责计算两件事。第一，它先计算z，然后应用其到激活函数中再计算a，所以我可以认为，每个圆圈代表着两步的计算过程。同样的，对于下一层而言，那就是$z_{1}^{[2]}$和$a_{1}^{[2]}$等。所以如果你没有应用Batch归一化，你会把输入$X$拟合到第一隐藏层，然后首先计算$z^{[1]}$，这是由$w^{[1]}$和$b^{[1]}$两个参数控制的。接着，通常而言，你会把$z^{[1]}$拟合到激活函数以计算$a^{[1]}$。但Batch归一化的做法是将$z^{[1]}$值进行Batch归一化，简称BN，此过程将由${\beta}^{[1]}$和$\gamma^{[1]}$两参数控制，这一操作会给你一个新的规范化的$z^{[1]}$值（${\tilde{z} }^{[1]}$），然后将其输入激活函数中得到$a^{[1]}$，即$a^{[1]} = g^{[1]}({\tilde{z} }^{[ l]})$。 现在，你已在第一层进行了计算，此时Batch归一化发生在z的计算和$a$之间，接下来，你需要应用$a^{[1]}$值来计算$z^{[2]}$，此过程是由$w^{[2]}$和$b^{[2]}$控制的。与你在第一层所做的类似，你会将$z^{[2]}$进行Batch归一化，现在我们简称BN，这是由下一层的Batch归一化参数所管制的，即${\beta}^{[2]}$和$\gamma^{[2]}$，现在你得到${\tilde{z} }^{[2]}$，再通过激活函数计算出$a^{[2]}$等等。 所以需要强调的是Batch归一化是发生在计算$z$和$a$之间的。直觉就是，与其应用没有归一化的$z$值，不如用归一过的$\tilde{z}$，这是第一层（${\tilde{z} }^{[1]}$）。第二层同理，与其应用没有规范过的$z^{[2]}$值，不如用经过方差和均值归一后的${\tilde{z} }^{[2]}$。所以，你网络的参数就会是$w^{[1]}$，$b^{[1]}$，$w^{[2]}$和$b^{[2]}$等等，我们将要去掉这些参数。但现在，想象参数$w^{[1]}$，$b^{[1]}$到$w^{[l]}$，$b^{[l]}$，我们将另一些参数加入到此新网络中${\beta}^{[1]}$，${\beta}^{[2]}$，$\gamma^{[1]}$，$\gamma^{[2]}$等等。对于应用Batch归一化的每一层而言。需要澄清的是，请注意，这里的这些$\beta$（${\beta}^{[1]}$，${\beta}^{[2]}$等等）和超参数$\beta$没有任何关系，下一张幻灯片中会解释原因，后者是用于Momentum或计算各个指数的加权平均值。Adam论文的作者，在论文里用$\beta$代表超参数。Batch归一化论文的作者，则使用$\beta$代表此参数（${\beta}^{[1]}$，${\beta}^{[2]}$等等），但这是两个完全不同的$\beta$。我在两种情况下都决定使用$\beta$，以便你阅读那些原创的论文，但Batch归一化学习参数${\beta}^{[1]}$，${\beta}^{\left\lbrack2 \right\rbrack}$等等和用于Momentum、Adam、RMSprop算法中的$\beta$不同。 所以现在，这是你算法的新参数，接下来你可以使用想用的任何一种优化算法，比如使用梯度下降法来执行它。 举个例子，对于给定层，你会计算$d{\beta}^{[l]}$，接着更新参数$\beta$为${\beta}^{[l]} = {\beta}^{[l]} - \alpha d{\beta}^{[l]}$。你也可以使用Adam或RMSprop或Momentum，以更新参数$\beta$和$\gamma$，并不是只应用梯度下降法。 即使在之前的视频中，我已经解释过Batch归一化是怎么操作的，计算均值和方差，减去均值，再除以方差，如果它们使用的是深度学习编程框架，通常你不必自己把Batch归一化步骤应用于Batch归一化层。因此，探究框架，可写成一行代码，比如说，在TensorFlow框架中，你可以用这个函数（tf.nn.batch_normalization）来实现Batch归一化，我们稍后讲解，但实践中，你不必自己操作所有这些具体的细节，但知道它是如何作用的，你可以更好的理解代码的作用。但在深度学习框架中，Batch归一化的过程，经常是类似一行代码的东西。 所以，到目前为止，我们已经讲了Batch归一化，就像你在整个训练站点上训练一样，或就像你正在使用Batch梯度下降法。 实践中，Batch归一化通常和训练集的mini-batch一起使用。你应用Batch归一化的方式就是，你用第一个mini-batch($X^{\{1\} }$)，然后计算$z^{[1]}$，这和上张幻灯片上我们所做的一样，应用参数$w^{[1]}$和$b^{[1]}$，使用这个mini-batch($X^{\{1\} }$)。接着，继续第二个mini-batch($X^{\{2\} }$)，接着Batch归一化会减去均值，除以标准差，由${\beta}^{[1]}$和$\gamma^{[1]}$重新缩放，这样就得到了${\tilde{z} }^{[1]}$，而所有的这些都是在第一个mini-batch的基础上，你再应用激活函数得到$a^{[1]}$。然后用$w^{[2]}$和$b^{[2]}$计算$z^{[2]}$，等等，所以你做的这一切都是为了在第一个mini-batch($X^{\{1\} }$)上进行一步梯度下降法。 类似的工作，你会在第二个mini-batch（$X^{\left\{2 \right\} }$）上计算$z^{[1]}$，然后用Batch归一化来计算${\tilde{z} }^{[1]}$，所以Batch归一化的此步中，你用第二个mini-batch（$X^{\left\{2 \right\} }$）中的数据使${\tilde{z} }^{[1]}$归一化，这里的Batch归一化步骤也是如此，让我们来看看在第二个mini-batch（$X^{\left\{2 \right\} }$）中的例子，在mini-batch上计算$z^{[1]}$的均值和方差，重新缩放的$\beta$和$\gamma$得到$z^{[1]}$，等等。 然后在第三个mini-batch（$X^{\left\{ 3 \right\} }$）上同样这样做，继续训练。 现在，我想澄清此参数的一个细节。先前我说过每层的参数是$w^{[l]}$和$b^{[l]}$，还有${\beta}^{[l]}$和$\gamma^{[l]}$，请注意计算$z$的方式如下，$z^{[l]} =w^{[l]}a^{\left\lbrack l - 1 \right\rbrack} +b^{[l]}$，但Batch归一化做的是，它要看这个mini-batch，先将$z^{[l]}$归一化，结果为均值0和标准方差，再由$\beta$和$$\gamma$$重缩放，但这意味着，无论$b^{[l]}$的值是多少，都是要被减去的，因为在Batch归一化的过程中，你要计算$z^{[l]}$的均值，再减去平均值，在此例中的mini-batch中增加任何常数，数值都不会改变，因为加上的任何常数都将会被均值减去所抵消。 所以，如果你在使用Batch归一化，其实你可以消除这个参数（$b^{[l]}$），或者你也可以，暂时把它设置为0，那么，参数变成$z^{[l]} = w^{[l]}a^{\left\lbrack l - 1 \right\rbrack}$，然后你计算归一化的$z^{[l]}$，${\tilde{z} }^{[l]} = \gamma^{[l]}z^{[l]} + {\beta}^{[l]}$，你最后会用参数${\beta}^{[l]}$，以便决定${\tilde{z} }^{[l]}$的取值，这就是原因。 所以总结一下，因为Batch归一化超过了此层$z^{[l]}$的均值，$b^{[l]}$这个参数没有意义，所以，你必须去掉它，由${\beta}^{[l]}$代替，这是个控制参数，会影响转移或偏置条件。 最后，请记住$z^{[l]}$的维数，因为在这个例子中，维数会是$(n^{[l]},1)$，$b^{[l]}$的尺寸为$(n^{[l]},1)$，如果是l层隐藏单元的数量，那${\beta}^{[l]}$和$\gamma^{[l]}$的维度也是$(n^{[l]},1)$，因为这是你隐藏层的数量，你有$n^{[l]}$隐藏单元，所以${\beta}^{[l]}$和$\gamma^{[l]}$用来将每个隐藏层的均值和方差缩放为网络想要的值。 让我们总结一下关于如何用Batch归一化来应用梯度下降法，假设你在使用mini-batch梯度下降法，你运行$t=1$到batch数量的for循环，你会在mini-batch $X^{\left\{ t\right\} }$上应用正向prop，每个隐藏层都应用正向prop，用Batch归一化代替$z^{[l]}$为${\tilde{z} }^{[l]}$。接下来，它确保在这个mini-batch中，$z$值有归一化的均值和方差，归一化均值和方差后是${\tilde{z} }^{[l]}$，然后，你用反向prop计算$dw^{[l]}$和$db^{[l]}$，及所有l层所有的参数，$d{\beta}^{[l]}$和$d\gamma^{[l]}$。尽管严格来说，因为你要去掉$b$，这部分其实已经去掉了。最后，你更新这些参数：$w^{[l]} = w^{[l]} -\text{αd}w^{[l]}$，和以前一样，${\beta}^{[l]} = {\beta}^{[l]} - {αd}{\beta}^{[l]}$，对于$\gamma$也是如此$\gamma^{[l]} = \gamma^{[l]} -{αd}\gamma^{[l]}$。 如果你已将梯度计算如下，你就可以使用梯度下降法了，这就是我写到这里的，但也适用于有Momentum、RMSprop、Adam的梯度下降法。与其使用梯度下降法更新mini-batch，你可以使用这些其它算法来更新，我们在之前几个星期中的视频中讨论过的，也可以应用其它的一些优化算法来更新由Batch归一化添加到算法中的$\beta$ 和$\gamma$ 参数。 我希望，你能学会如何从头开始应用Batch归一化，如果你想的话。如果你使用深度学习编程框架之一，我们之后会谈。，希望，你可以直接调用别人的编程框架，这会使Batch归一化的使用变得很容易。 现在，以防Batch归一化仍然看起来有些神秘，尤其是你还不清楚为什么其能如此显著的加速训练，我们进入下一个视频，详细讨论Batch归一化为何效果如此显著，它到底在做什么。 3.6 Batch Norm 为什么奏效？（Why does Batch Norm work?）为什么Batch归一化会起作用呢？ 一个原因是，你已经看到如何归一化输入特征值$x$，使其均值为0，方差1，它又是怎样加速学习的，有一些从0到1而不是从1到1000的特征值，通过归一化所有的输入特征值$x$，以获得类似范围的值，可以加速学习。所以Batch归一化起的作用的原因，直观的一点就是，它在做类似的工作，但不仅仅对于这里的输入值，还有隐藏单元的值，这只是Batch归一化作用的冰山一角，还有些深层的原理，它会有助于你对Batch归一化的作用有更深的理解，让我们一起来看看吧。 Batch归一化有效的第二个原因是，它可以使权重比你的网络更滞后或更深层，比如，第10层的权重更能经受得住变化，相比于神经网络中前层的权重，比如第1层，为了解释我的意思，让我们来看看这个最生动形象的例子。 这是一个网络的训练，也许是个浅层网络，比如logistic回归或是一个神经网络，也许是个浅层网络，像这个回归函数。或一个深层网络，建立在我们著名的猫脸识别检测上，但假设你已经在所有黑猫的图像上训练了数据集，如果现在你要把此网络应用于有色猫，这种情况下，正面的例子不只是左边的黑猫，还有右边其它颜色的猫，那么你的cosfa可能适用的不会很好。 如果图像中，你的训练集是这个样子的，你的正面例子在这儿，反面例子在那儿（左图），但你试图把它们都统一于一个数据集，也许正面例子在这，反面例子在那儿（右图）。你也许无法期待，在左边训练得很好的模块，同样在右边也运行得很好，即使存在运行都很好的同一个函数，但你不会希望你的学习算法去发现绿色的决策边界，如果只看左边数据的话。 所以使你数据改变分布的这个想法，有个有点怪的名字“Covariate shift”，想法是这样的，如果你已经学习了$x$到$y$ 的映射，如果$x$ 的分布改变了，那么你可能需要重新训练你的学习算法。这种做法同样适用于，如果真实函数由$x$ 到$y$ 映射保持不变，正如此例中，因为真实函数是此图片是否是一只猫，训练你的函数的需要变得更加迫切，如果真实函数也改变，情况就更糟了。 “Covariate shift”的问题怎么应用于神经网络呢？试想一个像这样的深度网络，让我们从这层（第三层）来看看学习过程。此网络已经学习了参数$w^{[3]}$和$b^{[3]}$，从第三隐藏层的角度来看，它从前层中取得一些值，接着它需要做些什么，使希望输出值$\hat y$接近真实值$y$。 让我先遮住左边的部分，从第三隐藏层的角度来看，它得到一些值，称为$a_{1}^{[2]}$，$a_{2}^{[2]}$，$a_{3}^{[2]}$，$a_{4}^{[2]}$，但这些值也可以是特征值$x_{1}$，$x_{2}$，$x_{3}$，$x_{4}$，第三层隐藏层的工作是找到一种方式，使这些值映射到$\hat y$，你可以想象做一些截断，所以这些参数$w^{[3]}$和$b^{[3]}$或$w^{[4]}$和$b^{[4]}$或$w^{[5]}$和$b^{[5]}$，也许是学习这些参数，所以网络做的不错，从左边我用黑色笔写的映射到输出值$\hat y$。 现在我们把网络的左边揭开，这个网络还有参数$w^{[2]}$，$b^{[2]}$和$w^{[1]}$，$b^{[1]}$，如果这些参数改变，这些$a^{[2]}$的值也会改变。所以从第三层隐藏层的角度来看，这些隐藏单元的值在不断地改变，所以它就有了“Covariate shift”的问题，上张幻灯片中我们讲过的。 Batch归一化做的，是它减少了这些隐藏值分布变化的数量。如果是绘制这些隐藏的单元值的分布，也许这是重整值$z$，这其实是$z_{1}^{[2]}$，$z_{2}^{[2]}$，我要绘制两个值而不是四个值，以便我们设想为2D，Batch归一化讲的是$z_{1}^{[2]}$，$z_{2}^{[2]}$的值可以改变，它们的确会改变，当神经网络在之前层中更新参数，Batch归一化可以确保无论其怎样变化$z_{1}^{[2]}$，$z_{2}^{[2]}$的均值和方差保持不变，所以即使$z_{1}^{[2]}$，$z_{2}^{[2]}$的值改变，至少他们的均值和方差也会是均值0，方差1，或不一定必须是均值0，方差1，而是由${\beta}^{[2]}$和$\gamma^{[2]}$决定的值。如果神经网络选择的话，可强制其为均值0，方差1，或其他任何均值和方差。但它做的是，它限制了在前层的参数更新，会影响数值分布的程度，第三层看到的这种情况，因此得到学习。 Batch归一化减少了输入值改变的问题，它的确使这些值变得更稳定，神经网络的之后层就会有更坚实的基础。即使使输入分布改变了一些，它会改变得更少。它做的是当前层保持学习，当改变时，迫使后层适应的程度减小了，你可以这样想，它减弱了前层参数的作用与后层参数的作用之间的联系，它使得网络每层都可以自己学习，稍稍独立于其它层，这有助于加速整个网络的学习。 所以，希望这能带给你更好的直觉，重点是Batch归一化的意思是，尤其从神经网络后层之一的角度而言，前层不会左右移动的那么多，因为它们被同样的均值和方差所限制，所以，这会使得后层的学习工作变得更容易些。 Batch归一化还有一个作用，它有轻微的正则化效果，Batch归一化中非直观的一件事是，每个mini-batch，我会说mini-batch$X^{\{ t \} }$的值为$z^{\lbrack t\rbrack}$，$z^{[l]}$，在mini-batch计算中，由均值和方差缩放的，因为在mini-batch上计算的均值和方差，而不是在整个数据集上，均值和方差有一些小的噪声，因为它只在你的mini-batch上计算，比如64或128或256或更大的训练例子。因为均值和方差有一点小噪音，因为它只是由一小部分数据估计得出的。缩放过程从$z^{[l]}$到${\tilde{z} }^{[l]}$，过程也有一些噪音，因为它是用有些噪音的均值和方差计算得出的。 所以和dropout相似，它往每个隐藏层的激活值上增加了噪音，dropout有增加噪音的方式，它使一个隐藏的单元，以一定的概率乘以0，以一定的概率乘以1，所以你的dropout含几重噪音，因为它乘以0或1。 对比而言，Batch归一化含几重噪音，因为标准偏差的缩放和减去均值带来的额外噪音。这里的均值和标准差的估计值也是有噪音的，所以类似于dropout，Batch归一化有轻微的正则化效果，因为给隐藏单元添加了噪音，这迫使后部单元不过分依赖任何一个隐藏单元，类似于dropout，它给隐藏层增加了噪音，因此有轻微的正则化效果。因为添加的噪音很微小，所以并不是巨大的正则化效果，你可以将Batch归一化和dropout一起使用，如果你想得到dropout更强大的正则化效果。 也许另一个轻微非直观的效果是，如果你应用了较大的mini-batch，对，比如说，你用了512而不是64，通过应用较大的min-batch，你减少了噪音，因此减少了正则化效果，这是dropout的一个奇怪的性质，就是应用较大的mini-batch可以减少正则化效果。 说到这儿，我会把Batch归一化当成一种正则化，这确实不是其目的，但有时它会对你的算法有额外的期望效应或非期望效应。但是不要把Batch归一化当作正则化，把它当作将你归一化隐藏单元激活值并加速学习的方式，我认为正则化几乎是一个意想不到的副作用。 所以希望这能让你更理解Batch归一化的工作，在我们结束Batch归一化的讨论之前，我想确保你还知道一个细节。Batch归一化一次只能处理一个mini-batch数据，它在mini-batch上计算均值和方差。所以测试时，你试图做出预测，试着评估神经网络，你也许没有mini-batch的例子，你也许一次只能进行一个简单的例子，所以测试时，你需要做一些不同的东西以确保你的预测有意义。 在下一个也就是最后一个Batch归一化视频中，让我们详细谈谈你需要注意的一些细节，来让你的神经网络应用Batch归一化来做出预测。 3.7 测试时的 Batch Norm（Batch Norm at test time）Batch归一化将你的数据以mini-batch的形式逐一处理，但在测试时，你可能需要对每个样本逐一处理，我们来看一下怎样调整你的网络来做到这一点。 回想一下，在训练时，这些就是用来执行Batch归一化的等式。在一个mini-batch中，你将mini-batch的$z^{(i)}$值求和，计算均值，所以这里你只把一个mini-batch中的样本都加起来，我用m来表示这个mini-batch中的样本数量，而不是整个训练集。然后计算方差，再算$z_{\text{norm} }^{(i)}$，即用均值和标准差来调整，加上$\varepsilon$是为了数值稳定性。$\tilde{z}$是用$\gamma$和$\beta$再次调整$z_{\text{norm} }$得到的。 请注意用于调节计算的$\mu$和$\sigma^{2}$是在整个mini-batch上进行计算，但是在测试时，你可能不能将一个mini-batch中的6428或2056个样本同时处理，因此你需要用其它方式来得到$\mu$和$\sigma^{2}$，而且如果你只有一个样本，一个样本的均值和方差没有意义。那么实际上，为了将你的神经网络运用于测试，就需要单独估算$\mu$和$\sigma^{2}$，在典型的Batch归一化运用中，你需要用一个指数加权平均来估算，这个平均数涵盖了所有mini-batch，接下来我会具体解释。 我们选择$l$层，假设我们有mini-batch，$X^{[1]}$，$X^{[2]}$，$X^{[3]}$……以及对应的$y$值等等，那么在为$l$层训练$X^{\{ 1\} }$时，你就得到了$\mu^{[l]}$，我还是把它写做第一个mini-batch和这一层的$\mu$吧，（$\mu^{[l]} \rightarrow \mu^{\left\{1 \right\}[l]}$）。当你训练第二个mini-batch，在这一层和这个mini-batch中，你就会得到第二个$\mu$（$\mu^{\{2\}[l]}$）值。然后在这一隐藏层的第三个mini-batch，你得到了第三个$\mu$（$\mu^{\left\{3 \right\}[l]}$）值。正如我们之前用的指数加权平均来计算$\theta_{1}$，$\theta_{2}$，$\theta_{3}$的均值，当时是试着计算当前气温的指数加权平均，你会这样来追踪你看到的这个均值向量的最新平均值，于是这个指数加权平均就成了你对这一隐藏层的$z$均值的估值。同样的，你可以用指数加权平均来追踪你在这一层的第一个mini-batch中所见的$\sigma^{2}$的值，以及第二个mini-batch中所见的$\sigma^{2}$的值等等。因此在用不同的mini-batch训练神经网络的同时，能够得到你所查看的每一层的$\mu$和$\sigma^{2}$的平均数的实时数值。 最后在测试时，对应这个等式（$z_{\text{norm} }^{(i)} = \frac{z^{(i)} -\mu}{\sqrt{\sigma^{2} +\varepsilon} }$），你只需要用你的$z$值来计算$z_{\text{norm} }^{(i)}$，用$\mu$和$\sigma^{2}$的指数加权平均，用你手头的最新数值来做调整，然后你可以用左边我们刚算出来的$z_{\text{norm} }$和你在神经网络训练过程中得到的$\beta$和$\gamma$参数来计算你那个测试样本的$\tilde{z}$值。 总结一下就是，在训练时，$\mu$和$\sigma^{2}$是在整个mini-batch上计算出来的包含了像是64或28或其它一定数量的样本，但在测试时，你可能需要逐一处理样本，方法是根据你的训练集估算$\mu$和$\sigma^{2}$，估算的方式有很多种，理论上你可以在最终的网络中运行整个训练集来得到$\mu$和$\sigma^{2}$，但在实际操作中，我们通常运用指数加权平均来追踪在训练过程中你看到的$\mu$和$\sigma^{2}$的值。还可以用指数加权平均，有时也叫做流动平均来粗略估算$\mu$和$\sigma^{2}$，然后在测试中使用$\mu$和$\sigma^{2}$的值来进行你所需要的隐藏单元$z$值的调整。在实践中，不管你用什么方式估算$\mu$和$\sigma^{2}$，这套过程都是比较稳健的，因此我不太会担心你具体的操作方式，而且如果你使用的是某种深度学习框架，通常会有默认的估算$\mu$和$\sigma^{2}$的方式，应该一样会起到比较好的效果。但在实践中，任何合理的估算你的隐藏单元$z$值的均值和方差的方式，在测试中应该都会有效。 Batch归一化就讲到这里，使用Batch归一化，你能够训练更深的网络，让你的学习算法运行速度更快，在结束这周的课程之前，我还想和你们分享一些关于深度学习框架的想法，让我们在下一段视频中一起讨论这个话题。 3.8 Softmax 回归（Softmax regression）到目前为止，我们讲到过的分类的例子都使用了二分分类，这种分类只有两种可能的标记0或1，这是一只猫或者不是一只猫，如果我们有多种可能的类型的话呢？有一种logistic回归的一般形式，叫做Softmax回归，能让你在试图识别某一分类时做出预测，或者说是多种分类中的一个，不只是识别两个分类，我们来一起看一下。 假设你不单需要识别猫，而是想识别猫，狗和小鸡，我把猫加做类1，狗为类2，小鸡是类3，如果不属于以上任何一类，就分到“其它”或者说“以上均不符合”这一类，我把它叫做类0。这里显示的图片及其对应的分类就是一个例子，这幅图片上是一只小鸡，所以是类3，猫是类1，狗是类2，我猜这是一只考拉，所以以上均不符合，那就是类0，下一个类3，以此类推。我们将会用符号表示，我会用大写的$C$来表示你的输入会被分入的类别总个数，在这个例子中，我们有4种可能的类别，包括“其它”或“以上均不符合”这一类。当有4个分类时，指示类别的数字，就是从0到$C-1$，换句话说就是0、1、2、3。 在这个例子中，我们将建立一个神经网络，其输出层有4个，或者说$C$个输出单元，因此$n$，即输出层也就是$L$层的单元数量，等于4，或者一般而言等于$C$。我们想要输出层单元的数字告诉我们这4种类型中每个的概率有多大，所以这里的第一个节点(最后输出的第1个方格+圆圈)输出的应该是或者说我们希望它输出“其它”类的概率。在输入$X$的情况下，这个(最后输出的第2个方格+圆圈)会输出猫的概率。在输入$X$的情况下，这个会输出狗的概率(最后输出的第3个方格+圆圈)。在输入$X$的情况下，输出小鸡的概率（最后输出的第4个方格+圆圈），我把小鸡缩写为bc（baby chick）。因此这里的$\hat y$将是一个$4×1$维向量，因为它必须输出四个数字，给你这四种概率，因为它们加起来应该等于1，输出中的四个数字加起来应该等于1。 让你的网络做到这一点的标准模型要用到Softmax层，以及输出层来生成输出，让我把式子写下来，然后回过头来，就会对Softmax的作用有一点感觉了。 在神经网络的最后一层，你将会像往常一样计算各层的线性部分，$z^{[l]}$这是最后一层的$z$变量，记住这是大写$L$层，和往常一样，计算方法是$z^{[l]} = W^{[l]}a^{[L-1]} + b^{[l]}$，算出了$z$之后，你需要应用Softmax激活函数，这个激活函数对于Softmax层而言有些不同，它的作用是这样的。首先，我们要计算一个临时变量，我们把它叫做t，它等于$e^{z^{[l]} }$，这适用于每个元素，而这里的$z^{[l]}$，在我们的例子中，$z^{[l]}$是4×1的，四维向量$t=e^{z^{[l]} }$，这是对所有元素求幂，$t$也是一个4×1维向量，然后输出的$a^{[l]}$，基本上就是向量$t$，但是会归一化，使和为1。因此$a^{[l]} = \frac{e^{z^{[l]} }}{\sum_{j =1}^{4}t_{i} }$，换句话说，$a^{[l]}$也是一个4×1维向量，而这个四维向量的第$i$个元素，我把它写下来，$a_{i}^{[l]} = \frac{t_{i} }{\sum_{j =1}^{4}t_{i} }$，以防这里的计算不够清晰易懂，我们马上会举个例子来详细解释。 我们来看一个例子，详细解释，假设你算出了$z^{[l]}$，$z^{[l]}$是一个四维向量，假设为$z^{[l]} = \begin{bmatrix} 5 \\ 2 \\ - 1 \\ 3 \\ \end{bmatrix}$，我们要做的就是用这个元素取幂方法来计算$t$，所以$t =\begin{bmatrix} e^{5} \\ e^{2} \\ e^{- 1} \\ e^{3} \\ \end{bmatrix}$，如果你按一下计算器就会得到以下值$t = \begin{bmatrix} 148.4 \\ 7.4 \\ 0.4 \\ 20.1 \\ \end{bmatrix}$，我们从向量$t$得到向量$a^{[l]}$就只需要将这些项目归一化，使总和为1。如果你把$t$的元素都加起来，把这四个数字加起来，得到176.3，最终$a^{[l]} = \frac{t} {176.3}$。 例如这里的第一个节点，它会输出$\frac{e^{5} }{176.3} =0.842$，这样说来，对于这张图片，如果这是你得到的$z$值($\begin{bmatrix} 5 \\ 2 \\ - 1 \\ 3 \\ \end{bmatrix}$)，它是类0的概率就是84.2%。下一个节点输出$\frac{e^{2} }{176.3} =0.042$，也就是4.2%的几率。下一个是$\frac{e^{- 1} }{176.3} =0.002$。最后一个是$\frac{e^{3} }{176.3} =0.114$，也就是11.4%的概率属于类3，也就是小鸡组，对吧？这就是它属于类0，类1，类2，类3的可能性。 神经网络的输出$a^{[l]}$，也就是$\hat y$，是一个4×1维向量，这个4×1向量的元素就是我们算出来的这四个数字($\begin{bmatrix} 0.842 \\ 0.042 \\ 0.002 \\ 0.114 \\ \end{bmatrix}$)，所以这种算法通过向量$z^{[l]}$计算出总和为1的四个概率。 如果我们总结一下从$z^{[l]}$到$a^{[l]}$的计算步骤，整个计算过程，从计算幂到得出临时变量$t$，再归一化，我们可以将此概括为一个Softmax激活函数。设$a^{[l]} = g^{[l]}(z^{[l]})$，这一激活函数的与众不同之处在于，这个激活函数$g$ 需要输入一个4×1维向量，然后输出一个4×1维向量。之前，我们的激活函数都是接受单行数值输入，例如Sigmoid和ReLu激活函数，输入一个实数，输出一个实数。Softmax激活函数的特殊之处在于，因为需要将所有可能的输出归一化，就需要输入一个向量，最后输出一个向量。 那么Softmax分类器还可以代表其它的什么东西么？我来举几个例子，你有两个输入$x_{1}$，$x_{2}$，它们直接输入到Softmax层，它有三四个或者更多的输出节点，输出$\hat y$，我将向你展示一个没有隐藏层的神经网络，它所做的就是计算$z^{[1]} = W^{[1]}x + b^{[1]}$，而输出的出$a^{[l]}$，或者说$\hat y$，$a^{[l]} = y = g(z^{[1]})$，就是$z^{[1]}$的Softmax激活函数，这个没有隐藏层的神经网络应该能让你对Softmax函数能够代表的东西有所了解。 这个例子中（左边图），原始输入只有$x_{1}$和$x_{2}$，一个$C=3$个输出分类的Softmax层能够代表这种类型的决策边界，请注意这是几条线性决策边界，但这使得它能够将数据分到3个类别中，在这张图表中，我们所做的是选择这张图中显示的训练集，用数据的3种输出标签来训练Softmax分类器，图中的颜色显示了Softmax分类器的输出的阈值，输入的着色是基于三种输出中概率最高的那种。因此我们可以看到这是logistic回归的一般形式，有类似线性的决策边界，但有超过两个分类，分类不只有0和1，而是可以是0，1或2。 这是（中间图）另一个Softmax分类器可以代表的决策边界的例子，用有三个分类的数据集来训练，这里（右边图）还有一个。对吧，但是直觉告诉我们，任何两个分类之间的决策边界都是线性的，这就是为什么你看到，比如这里黄色和红色分类之间的决策边界是线性边界，紫色和红色之间的也是线性边界，紫色和黄色之间的也是线性决策边界，但它能用这些不同的线性函数来把空间分成三类。 我们来看一下更多分类的例子，这个例子中（左边图）$C=4$，因此这个绿色分类和Softmax仍旧可以代表多种分类之间的这些类型的线性决策边界。另一个例子（中间图）是$C=5$类，最后一个例子（右边图）是$C=6$，这显示了Softmax分类器在没有隐藏层的情况下能够做到的事情，当然更深的神经网络会有$x$，然后是一些隐藏单元，以及更多隐藏单元等等，你就可以学习更复杂的非线性决策边界，来区分多种不同分类。 我希望你了解了神经网络中的Softmax层或者Softmax激活函数有什么作用，下一个视频中，我们来看一下你该怎样训练一个使用Softmax层的神经网络。 3.9 训练一个 Softmax 分类器（Training a Softmax classifier）上一个视频中我们学习了Softmax层和Softmax激活函数，在这个视频中，你将更深入地了解Softmax分类，并学习如何训练一个使用了Softmax层的模型。 回忆一下我们之前举的的例子，输出层计算出的$z^{[l]}$如下，$z^{[l]} = \begin{bmatrix} 5 \\ 2 \\ - 1 \\ 3 \\ \end{bmatrix}$我们有四个分类$C=4$，$z^{[l]}$可以是4×1维向量，我们计算了临时变量$t$，$t = \begin{bmatrix} e^{5} \\ e^{2} \\ e^{- 1} \\ e^{3} \\ \end{bmatrix}$，对元素进行幂运算，最后，如果你的输出层的激活函数$g^{[L]}()$是Softmax激活函数，那么输出就会是这样的： 简单来说就是用临时变量$t$将它归一化，使总和为1，于是这就变成了$a^{[L]}$，你注意到向量$z$中，最大的元素是5，而最大的概率也就是第一种概率。 Softmax这个名称的来源是与所谓hardmax对比，hardmax会把向量$z$变成这个向量$\begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \\ \end{bmatrix}$，hardmax函数会观察$z$的元素，然后在$z$中最大元素的位置放上1，其它位置放上0，所这是一个hard max，也就是最大的元素的输出为1，其它的输出都为0。与之相反，Softmax所做的从$z$到这些概率的映射更为温和，我不知道这是不是一个好名字，但至少这就是softmax这一名称背后所包含的想法，与hardmax正好相反。 有一点我没有细讲，但之前已经提到过的，就是Softmax回归或Softmax激活函数将logistic激活函数推广到$C$类，而不仅仅是两类，结果就是如果$C=2$，那么$C=2$的Softmax实际上变回了logistic回归，我不会在这个视频中给出证明，但是大致的证明思路是这样的，如果$C=2$，并且你应用了Softmax，那么输出层$a^{[L]}$将会输出两个数字，如果$C=2$的话，也许输出0.842和0.158，对吧？这两个数字加起来要等于1，因为它们的和必须为1，其实它们是冗余的，也许你不需要计算两个，而只需要计算其中一个，结果就是你最终计算那个数字的方式又回到了logistic回归计算单个输出的方式。这算不上是一个证明，但我们可以从中得出结论，Softmax回归将logistic回归推广到了两种分类以上。 接下来我们来看怎样训练带有Softmax输出层的神经网络，具体而言，我们先定义训练神经网络使会用到的损失函数。举个例子，我们来看看训练集中某个样本的目标输出，真实标签是$\begin{bmatrix} 0 \\ 1 \\ 0 \\ 0 \\ \end{bmatrix}$，用上一个视频中讲到过的例子，这表示这是一张猫的图片，因为它属于类1，现在我们假设你的神经网络输出的是$\hat y$，$\hat y$是一个包括总和为1的概率的向量，$y = \begin{bmatrix} 0.3 \\ 0.2 \\ 0.1 \\ 0.4 \\ \end{bmatrix}$，你可以看到总和为1，这就是$a^{[l]}$，$a^{[l]} = y = \begin{bmatrix} 0.3 \\ 0.2 \\ 0.1 \\ 0.4 \\ \end{bmatrix}$。对于这个样本神经网络的表现不佳，这实际上是一只猫，但却只分配到20%是猫的概率，所以在本例中表现不佳。 那么你想用什么损失函数来训练这个神经网络？在Softmax分类中，我们一般用到的损失函数是$L(\hat y,y ) = - \sum_{j = 1}^{4}{y_{j}log\hat y_{j} }$，我们来看上面的单个样本来更好地理解整个过程。注意在这个样本中$y_{1} =y_{3} = y_{4} = 0$，因为这些都是0，只有$y_{2} =1$，如果你看这个求和，所有含有值为0的$y_{j}$的项都等于0，最后只剩下$-y_{2}t{log}\hat y_{2}$，因为当你按照下标$j$全部加起来，所有的项都为0，除了$j=2$时，又因为$y_{2}=1$，所以它就等于$- \ log\hat y_{2}$。 $L\left( \hat y,y \right) = - \sum_{j = 1}^{4}{y_{j}\log \hat y_{j} } = - y_{2}{\ log} \hat y_{2} = - {\ log} \hat y_{2}$ 这就意味着，如果你的学习算法试图将它变小，因为梯度下降法是用来减少训练集的损失的，要使它变小的唯一方式就是使$-{\log}\hat y_{2}$变小，要想做到这一点，就需要使$\hat y_{2}$尽可能大，因为这些是概率，所以不可能比1大，但这的确也讲得通，因为在这个例子中$x$是猫的图片，你就需要这项输出的概率尽可能地大（$y= \begin{bmatrix} 0.3 \\ 0.2 \\ 0.1 \\ 0.4 \\ \end{bmatrix}$中第二个元素）。 概括来讲，损失函数所做的就是它找到你的训练集中的真实类别，然后试图使该类别相应的概率尽可能地高，如果你熟悉统计学中最大似然估计，这其实就是最大似然估计的一种形式。但如果你不知道那是什么意思，也不用担心，用我们刚刚讲过的算法思维也足够了。 这是单个训练样本的损失，整个训练集的损失$J$又如何呢？也就是设定参数的代价之类的，还有各种形式的偏差的代价，它的定义你大致也能猜到，就是整个训练集损失的总和，把你的训练算法对所有训练样本的预测都加起来， $J( w^{[1]},b^{[1]},\ldots\ldots) = \frac{1}{m}\sum_{i = 1}^{m}{L( \hat y^{(i)},y^{(i)})}$ 因此你要做的就是用梯度下降法，使这里的损失最小化。 最后还有一个实现细节，注意因为$C=4$，$y$是一个4×1向量，$y$也是一个4×1向量，如果你实现向量化，矩阵大写$Y$就是$\lbrack y^{(1)}\text{}y^{(2)}\ldots\ldots\ y^{\left( m \right)}\rbrack$，例如如果上面这个样本是你的第一个训练样本，那么矩阵$Y =\begin{bmatrix} 0 & 0 & 1 & \ldots \\ 1 & 0 & 0 & \ldots \\ 0 & 1 & 0 & \ldots \\ 0 & 0 & 0 & \ldots \\ \end{bmatrix}$，那么这个矩阵$Y$最终就是一个$4×m$维矩阵。类似的，$\hat{Y} = \lbrack{\hat{y} }^{(1)}{\hat{y} }^{(2)} \ldots \ldots\ {\hat{y} }^{(m)}\rbrack$，这个其实就是${\hat{y} }^{(1)}$（$a^{[l](1)} = y^{(1)} = \begin{bmatrix} 0.3 \\ 0.2 \\ 0.1 \\ 0.4 \\ \end{bmatrix}$），或是第一个训练样本的输出，那么$\hat{Y} = \begin{bmatrix} 0.3 & \ldots \\ 0.2 & \ldots \\ 0.1 & \ldots \\ 0.4 & \ldots \\ \end{bmatrix}$，$\hat{Y}$本身也是一个$4×m$维矩阵。 最后我们来看一下，在有Softmax输出层时如何实现梯度下降法，这个输出层会计算$z^{[l]}$，它是$C×1$维的，在这个例子中是4×1，然后你用Softmax激活函数来得到$a^{[l]}$或者说$y$，然后又能由此计算出损失。我们已经讲了如何实现神经网络前向传播的步骤，来得到这些输出，并计算损失，那么反向传播步骤或者梯度下降法又如何呢？其实初始化反向传播所需要的关键步骤或者说关键方程是这个表达式$dz^{[l]} = \hat{y} -y$，你可以用$\hat{y}$这个4×1向量减去$y$这个4×1向量，你可以看到这些都会是4×1向量，当你有4个分类时，在一般情况下就是$C×1$，这符合我们对$dz$的一般定义，这是对$z^{[l]}$损失函数的偏导数（$dz^{[l]} = \frac{\partial J}{\partial z^{[l]} }$），如果你精通微积分就可以自己推导，或者说如果你精通微积分，可以试着自己推导，但如果你需要从零开始使用这个公式，它也一样有用。 有了这个，你就可以计算$dz^{[l]}$，然后开始反向传播的过程，计算整个神经网络中所需要的所有导数。 但在这周的初级练习中，我们将开始使用一种深度学习编程框架，对于这些编程框架，通常你只需要专注于把前向传播做对，只要你将它指明为编程框架，前向传播，它自己会弄明白怎样反向传播，会帮你实现反向传播，所以这个表达式值得牢记（$dz^{[l]} = \hat{y} -y$），如果你需要从头开始，实现Softmax回归或者Softmax分类，但其实在这周的初级练习中你不会用到它，因为编程框架会帮你搞定导数计算。 Softmax分类就讲到这里，有了它，你就可以运用学习算法将输入分成不止两类，而是$C$个不同类别。接下来我想向你展示一些深度学习编程框架，可以让你在实现深度学习算法时更加高效，让我们在下一个视频中一起讨论。 3.10 深度学习框架（Deep Learning frameworks）你已经差不多从零开始学习了使用Python和NumPy实现深度学习算法，很高兴你这样做了，因为我希望你理解这些深度学习算法实际上在做什么。但你会发现，除非应用更复杂的模型，例如卷积神经网络，或者循环神经网络，或者当你开始应用很大的模型，否则它就越来越不实用了，至少对大多数人而言，从零开始全部靠自己实现并不现实。 幸运的是，现在有很多好的深度学习软件框架，可以帮助你实现这些模型。类比一下，我猜你知道如何做矩阵乘法，你还应该知道如何编程实现两个矩阵相乘，但是当你在建很大的应用时，你很可能不想用自己的矩阵乘法函数，而是想要访问一个数值线性代数库，它会更高效，但如果你明白两个矩阵相乘是怎么回事还是挺有用的。我认为现在深度学习已经很成熟了，利用一些深度学习框架会更加实用，会使你的工作更加有效，那就让我们来看下有哪些框架。 现在有许多深度学习框架，能让实现神经网络变得更简单，我们来讲主要的几个。每个框架都针对某一用户或开发群体的，我觉得这里的每一个框架都是某类应用的可靠选择，有很多人写文章比较这些深度学习框架，以及这些深度学习框架发展得有多好，而且因为这些框架往往不断进化，每个月都在进步，如果你想看看关于这些框架的优劣之处的讨论，我留给你自己去网上搜索，但我认为很多框架都在很快进步，越来越好，因此我就不做强烈推荐了，而是与你分享推荐一下选择框架的标准。 一个重要的标准就是便于编程，这既包括神经网络的开发和迭代，还包括为产品进行配置，为了成千上百万，甚至上亿用户的实际使用，取决于你想要做什么。 第二个重要的标准是运行速度，特别是训练大数据集时，一些框架能让你更高效地运行和训练神经网络。 还有一个标准人们不常提到，但我觉得很重要，那就是这个框架是否真的开放，要是一个框架真的开放，它不仅需要开源，而且需要良好的管理。不幸的是，在软件行业中，一些公司有开源软件的历史，但是公司保持着对软件的全权控制，当几年时间过去，人们开始使用他们的软件时，一些公司开始逐渐关闭曾经开放的资源，或将功能转移到他们专营的云服务中。因此我会注意的一件事就是你能否相信这个框架能长时间保持开源，而不是在一家公司的控制之下，它未来有可能出于某种原因选择停止开源，即便现在这个软件是以开源的形式发布的。但至少在短期内，取决于你对语言的偏好，看你更喜欢Python，Java还是C++或者其它什么，也取决于你在开发的应用，是计算机视觉，还是自然语言处理或者线上广告，等等，我认为这里的多个框架都是很好的选择。 程序框架就讲到这里，通过提供比数值线性代数库更高程度的抽象化，这里的每一个程序框架都能让你在开发深度机器学习应用时更加高效。 3.11 TensorFlow欢迎来到这周的最后一个视频，有很多很棒的深度学习编程框架，其中一个是TensorFlow，我很期待帮助你开始学习使用TensorFlow，我想在这个视频中向你展示TensorFlow程序的基本结构，然后让你自己练习，学习更多细节，并运用到本周的编程练习中，这周的编程练习需要花些时间来做，所以请务必留出一些空余时间。 先提一个启发性的问题，假设你有一个损失函数$J$需要最小化，在本例中，我将使用这个高度简化的损失函数，$Jw= w^{2}-10w+25$，这就是损失函数，也许你已经注意到该函数其实就是${(w -5)}^{2}$，如果你把这个二次方式子展开就得到了上面的表达式，所以使它最小的$w$值是5，但假设我们不知道这点，你只有这个函数，我们来看一下怎样用TensorFlow将其最小化，因为一个非常类似的程序结构可以用来训练神经网络。其中可以有一些复杂的损失函数$J(w,b)$取决于你的神经网络的所有参数，然后类似的，你就能用TensorFlow自动找到使损失函数最小的$w$和$b$的值。但让我们先从左边这个更简单的例子入手。 我在我的Jupyter notebook中运行Python， import numpy as np import tensorflow as tf #导入TensorFlow w = tf.Variable(0,dtype = tf.float32) #接下来，让我们定义参数w，在TensorFlow中，你要用tf.Variable()来定义参数 #然后我们定义损失函数： cost = tf.add(tf.add(w**2,tf.multiply(- 10.,w)),25) #然后我们定义损失函数J 然后我们再写： train = tf.train.GradientDescentOptimizer(0.01).minimize(cost) #(让我们用0.01的学习率，目标是最小化损失)。 #最后下面的几行是惯用表达式: init = tf.global_variables_initializer() session = tf.Session()#这样就开启了一个TensorFlow session。 session.run(init)#来初始化全局变量。 #然后让TensorFlow评估一个变量，我们要用到: session.run(w) #上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以#上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以session.run(w)评估了w，让我：： print(session.run(w)) 所以如果我们运行这个，它评估$w$等于0，因为我们什么都还没运行。 #现在让我们输入： $session.run(train)，它所做的就是运行一步梯度下降法。 #接下来在运行了一步梯度下降法后，让我们评估一下w的值，再print： print(session.run(w)) #在一步梯度下降法之后，w现在是0.1。现在我们运行梯度下降1000次迭代： 这是运行了梯度下降的1000次迭代，最后$w$变成了4.99999，记不记得我们说${(w -5)}^{2}$最小化，因此$w$的最优值是5，这个结果已经很接近了。 希望这个让你对TensorFlow程序的大致结构有了了解，当你做编程练习，使用更多TensorFlow代码时，我这里用到的一些函数你会熟悉起来，这里有个地方要注意，$w$是我们想要优化的参数，因此将它称为变量，注意我们需要做的就是定义一个损失函数，使用这些add和multiply之类的函数。TensorFlow知道如何对add和mutiply，还有其它函数求导，这就是为什么你只需基本实现前向传播，它能弄明白如何做反向传播和梯度计算，因为它已经内置在add，multiply和平方函数中。 对了，要是觉得这种写法不好看的话，TensorFlow其实还重载了一般的加减运算等等，因此你也可以把$cost$写成更好看的形式，把之前的cost标成注释，重新运行，得到了同样的结果。 一旦$w$被称为TensorFlow变量，平方，乘法和加减运算都重载了，因此你不必使用上面这种不好看的句法。 TensorFlow还有一个特点，我想告诉你，那就是这个例子将$w$的一个固定函数最小化了。如果你想要最小化的函数是训练集函数又如何呢？不管你有什么训练数据$x$，当你训练神经网络时，训练数据$x$会改变，那么如何把训练数据加入TensorFlow程序呢？ 我会定义$x$，把它想做扮演训练数据的角色，事实上训练数据有$x$和$y$，但这个例子中只有$x$，把$x$定义为： x = tf.placeholder(tf.float32,[3,1])，让它成为$[3,1]$数组，我要做的就是，因为$cost$这个二次方程的三项前有固定的系数，它是$w^{2}+10w + 25$，我们可以把这些数字1，-10和25变成数据，我要做的就是把$cost$替换成： cost = x[0][0]*w**2 +x[1][0]*w + x[2][0]，现在$x$变成了控制这个二次函数系数的数据，这个placeholder函数告诉TensorFlow，你稍后会为$x$提供数值。 让我们再定义一个数组，coefficient = np.array([[1.],[-10.],[25.]])，这就是我们要接入$x$的数据。最后我们需要用某种方式把这个系数数组接入变量$x$，做到这一点的句法是，在训练这一步中，要提供给$x$的数值，我在这里设置： feed_dict = {x:coefficients} 好了，希望没有语法错误，我们重新运行它，希望得到和之前一样的结果。 现在如果你想改变这个二次函数的系数，假设你把： coefficient = np.array([[1.],[-10.],[25.]]) 改为：coefficient = np.array([[1.],[-20.],[100.]]) 现在这个函数就变成了${(w -10)}^{2}$，如果我重新运行，希望我得到的使${(w -10)}^{2}$最小化的$w$值为10，让我们看一下，很好，在梯度下降1000次迭代之后，我们得到接近10的$w$。 在你做编程练习时，见到更多的是，TensorFlow中的placeholder是一个你之后会赋值的变量，这种方式便于把训练数据加入损失方程，把数据加入损失方程用的是这个句法，当你运行训练迭代，用feed_dict来让x=coefficients。如果你在做mini-batch梯度下降，在每次迭代时，你需要插入不同的mini-batch，那么每次迭代，你就用feed_dict来喂入训练集的不同子集，把不同的mini-batch喂入损失函数需要数据的地方。 希望这让你了解了TensorFlow能做什么，让它如此强大的是，你只需说明如何计算损失函数，它就能求导，而且用一两行代码就能运用梯度优化器，Adam优化器或者其他优化器。 这还是刚才的代码，我稍微整理了一下，尽管这些函数或变量看上去有点神秘，但你在做编程练习时多练习几次就会熟悉起来了。 还有最后一点我想提一下，这三行（蓝色大括号部分）在TensorFlow里是符合表达习惯的，有些程序员会用这种形式来替代，作用基本上是一样的。 但这个with结构也会在很多TensorFlow程序中用到，它的意思基本上和左边的相同，但是Python中的with命令更方便清理，以防在执行这个内循环时出现错误或例外。所以你也会在编程练习中看到这种写法。那么这个代码到底做了什么呢？让我们看这个等式： cost =x[0][0]*w**2 +x[1][0]*w + x[2][0]#(w-5)**2 TensorFlow程序的核心是计算损失函数，然后TensorFlow自动计算出导数，以及如何最小化损失，因此这个等式或者这行代码所做的就是让TensorFlow建立计算图，计算图所做的就是取$x[0][0]$，取$w$，然后将它平方，然后$x[0][0]$和$w^{2}$相乘，你就得到了$x[0][0]w^{2}$，以此类推，最终整个建立起来计算$cost = [0][0]w*2 + x[1][0]w + x[2][0]$，最后你得到了损失函数。 TensorFlow的优点在于，通过用这个计算损失，计算图基本实现前向传播，TensorFlow已经内置了所有必要的反向函数，回忆一下训练深度神经网络时的一组前向函数和一组反向函数，而像TensorFlow之类的编程框架已经内置了必要的反向函数，这也是为什么通过内置函数来计算前向函数，它也能自动用反向函数来实现反向传播，即便函数非常复杂，再帮你计算导数，这就是为什么你不需要明确实现反向传播，这是编程框架能帮你变得高效的原因之一。 如果你看TensorFlow的使用说明，我只是指出TensorFlow的说明用了一套和我不太一样的符号来画计算图，它用了$x[0][0]$，$w$，然后它不是写出值，想这里的$w^{2}$，TensorFlow使用说明倾向于只写运算符，所以这里就是平方运算，而这两者一起指向乘法运算，以此类推，然后在最后的节点，我猜应该是一个将$x[2][0]$加上去得到最终值的加法运算。 为本课程起见，我认为计算图用第一种方式会更容易理解，但是如果你去看TensorFlow的使用说明，如果你看到说明里的计算图，你会看到另一种表示方式，节点都用运算来标记而不是值，但这两种呈现方式表达的是同样的计算图。 在编程框架中你可以用一行代码做很多事情，例如，你不想用梯度下降法，而是想用Adam优化器，你只要改变这行代码，就能很快换掉它，换成更好的优化算法。所有现代深度学习编程框架都支持这样的功能，让你很容易就能编写复杂的神经网络。 我希望我帮助你了解了TensorFlow程序典型的结构，概括一下这周的内容，你学习了如何系统化地组织超参数搜索过程，我们还讲了Batch归一化，以及如何用它来加速神经网络的训练，最后我们讲了深度学习的编程框架，有很多很棒的编程框架，这最后一个视频我们重点讲了TensorFlow。有了它，我希望你享受这周的编程练习，帮助你更熟悉这些概念。]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达深度学习笔记(第一课时)]]></title>
    <url>%2F2019%2F12%2F04%2Fnew_%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E7%AC%AC%E4%B8%80%E8%AF%BE%E6%97%B6)%2F</url>
    <content type="text"><![CDATA[吴恩达深度学习笔记 神经网络的编程基础(Basics of Neural Network programming)2.1 二分类(Binary Classification)这周我们将学习神经网络的基础知识，其中需要注意的是，当实现一个神经网络的时候，我们需要知道一些非常重要的技术和技巧。例如有一个包含$m$个样本的训练集，你很可能习惯于用一个for循环来遍历训练集中的每个样本，但是当实现一个神经网络的时候，我们通常不直接使用for循环来遍历整个训练集，所以在这周的课程中你将学会如何处理训练集。 另外在神经网络的计算中，通常先有一个叫做前向暂停(forward pause)或叫做前向传播(foward propagation)的步骤，接着有一个叫做反向暂停(backward pause) 或叫做反向传播(backward propagation)的步骤。所以这周我也会向你介绍为什么神经网络的训练过程可以分为前向传播和反向传播两个独立的部分。 在课程中我将使用逻辑回归(logistic regression)来传达这些想法，以使大家能够更加容易地理解这些概念。即使你之前了解过逻辑回归，我认为这里还是有些新的、有趣的东西等着你去发现和了解，所以现在开始进入正题。 逻辑回归是一个用于二分类(binary classification)的算法。首先我们从一个问题开始说起，这里有一个二分类问题的例子，假如你有一张图片作为输入，比如这只猫，如果识别这张图片为猫，则输出标签1作为结果；如果识别出不是猫，那么输出标签0作为结果。现在我们可以用字母 $y$来 表示输出的结果标签，如下图所示： 我们来看看一张图片在计算机中是如何表示的，为了保存一张图片，需要保存三个矩阵，它们分别对应图片中的红、绿、蓝三种颜色通道，如果你的图片大小为64x64像素，那么你就有三个规模为64x64的矩阵，分别对应图片中红、绿、蓝三种像素的强度值。为了便于表示，这里我画了三个很小的矩阵，注意它们的规模为5x4 而不是64x64，如下图所示： 为了把这些像素值放到一个特征向量中，我们需要把这些像素值提取出来，然后放入一个特征向量$x$。为了把这些像素值转换为特征向量 $x$，我们需要像下面这样定义一个特征向量 $x$ 来表示这张图片，我们把所有的像素都取出来，例如255、231等等，直到取完所有的红色像素，接着最后是255、134、…、255、134等等，直到得到一个特征向量，把图片中所有的红、绿、蓝像素值都列出来。如果图片的大小为64x64像素，那么向量 $x$ 的总维度，将是64乘以64乘以3，这是三个像素矩阵中像素的总量。在这个例子中结果为12,288。现在我们用$n_x=12,288$，来表示输入特征向量的维度，有时候为了简洁，我会直接用小写的$n$来表示输入特征向量$x$的维度。所以在二分类问题中，我们的目标就是习得一个分类器，它以图片的特征向量作为输入，然后预测输出结果$y$为1还是0，也就是预测图片中是否有猫： 接下来我们说明一些在余下课程中，需要用到的一些符号。 符号定义 ： $x$：表示一个$n_x$维数据，为输入数据，维度为$(n_x,1)$； $y$：表示输出结果，取值为$(0,1)$； $(x^{(i)},y^{(i)})$：表示第$i$组数据，可能是训练数据，也可能是测试数据，此处默认为训练数据； $X=[x^{(1)},x^{(2)},...,x^{(m)}]$：表示所有的训练数据集的输入值，放在一个 $n_x×m$的矩阵中，其中$m$表示样本数目; $Y=[y^{(1)},y^{(2)},...,y^{(m)}]$：对应表示所有训练数据集的输出值，维度为$1×m$。 用一对$(x,y)$来表示一个单独的样本，$x$代表$n_x$维的特征向量，$y$ 表示标签(输出结果)只能为0或1。而训练集将由$m$个训练样本组成，其中$(x^{(1)},y^{(1)})$表示第一个样本的输入和输出，$(x^{(2)},y^{(2)})$表示第二个样本的输入和输出，直到最后一个样本$(x^{(m)},y^{(m)})$，然后所有的这些一起表示整个训练集。有时候为了强调这是训练样本的个数，会写作$M_{train}$，当涉及到测试集的时候，我们会使用$M_{test}$来表示测试集的样本数，所以这是测试集的样本数： 最后为了能把训练集表示得更紧凑一点，我们会定义一个矩阵用大写$X$的表示，它由输入向量$x^{(1)}$、$x^{(2)}$等组成，如下图放在矩阵的列中，所以现在我们把$x^{(1)}$作为第一列放在矩阵中，$x^{(2)}$作为第二列，$x^{(m)}$放到第$m$列，然后我们就得到了训练集矩阵$X$。所以这个矩阵有$m$列，$m$是训练集的样本数量，然后这个矩阵的高度记为$n_x$，注意有时候可能因为其他某些原因，矩阵$X$会由训练样本按照行堆叠起来而不是列，如下图所示：$x^{(1)}$的转置直到$x^{(m)}$的转置，但是在实现神经网络的时候，使用左边的这种形式，会让整个实现的过程变得更加简单： 现在来简单温习一下:$X$是一个规模为$n_x$乘以$m$的矩阵，当你用Python实现的时候，你会看到X.shape，这是一条Python命令，用于显示矩阵的规模，即X.shape等于$(n_x,m)$，$X$是一个规模为$n_x$乘以$m$的矩阵。所以综上所述，这就是如何将训练样本（输入向量$X$的集合）表示为一个矩阵。 那么输出标签$y$呢？同样的道理，为了能更加容易地实现一个神经网络，将标签$y$放在列中将会使得后续计算非常方便，所以我们定义大写的$Y$等于${ {y}^{\left( 1 \right)} },{ {y}^{\left( m \right)} },...,{ {y}^{\left( m \right)} }$，所以在这里是一个规模为1乘以$m$的矩阵，同样地使用Python将表示为Y.shape等于$(1,m)$，表示这是一个规模为1乘以$m$的矩阵。 当你在后面的课程中实现神经网络的时候，你会发现，一个好的符号约定能够将不同训练样本的数据很好地组织起来。而我所说的数据不仅包括 $x$ 或者 $y$ 还包括之后你会看到的其他的量。将不同的训练样本的数据提取出来，然后就像刚刚我们对 $x$ 或者 $y$ 所做的那样，将他们堆叠在矩阵的列中，形成我们之后会在逻辑回归和神经网络上要用到的符号表示。如果有时候你忘了这些符号的意思，比如什么是 $m$，或者什么是 $n$，或者忘了其他一些东西，我们也会在课程的网站上放上符号说明，然后你可以快速地查阅每个具体的符号代表什么意思，好了，我们接着到下一个视频，在下个视频中，我们将以逻辑回归作为开始。备注：附录里也写了符号说明。 2.2 逻辑回归(Logistic Regression)在这个视频中，我们会重温逻辑回归学习算法，该算法适用于二分类问题，本节将主要介绍逻辑回归的Hypothesis Function（假设函数）。 对于二元分类问题来讲，给定一个输入特征向量$X$，它可能对应一张图片，你想识别这张图片识别看它是否是一只猫或者不是一只猫的图片，你想要一个算法能够输出预测，你只能称之为$\hat{y}$，也就是你对实际值 $y$ 的估计。更正式地来说，你想让 $\hat{y}$ 表示 $y$ 等于1的一种可能性或者是机会，前提条件是给定了输入特征$X$。换句话来说，如果$X$是我们在上个视频看到的图片，你想让 $\hat{y}$ 来告诉你这是一只猫的图片的机率有多大。在之前的视频中所说的，$X$是一个$n_x$维的向量（相当于有$n_x$个特征的特征向量）。我们用$w$来表示逻辑回归的参数，这也是一个$n_x$维向量（因为$w$实际上是特征权重，维度与特征向量相同），参数里面还有$b$，这是一个实数（表示偏差）。所以给出输入$x$以及参数$w$和$b$之后，我们怎样产生输出预测值$\hat{y}$，一件你可以尝试却不可行的事是让$\hat{y}={ {w}^{T} }x+b$。 这时候我们得到的是一个关于输入$x$的线性函数，实际上这是你在做线性回归时所用到的，但是这对于二元分类问题来讲不是一个非常好的算法，因为你想让$\hat{y}$表示实际值$y$等于1的机率的话，$\hat{y}$ 应该在0到1之间。这是一个需要解决的问题，因为${ {w}^{T} }x+b$可能比1要大得多，或者甚至为一个负值。对于你想要的在0和1之间的概率来说它是没有意义的，因此在逻辑回归中，我们的输出应该是$\hat{y}$等于由上面得到的线性函数式子作为自变量的sigmoid函数中，公式如上图最下面所示，将线性函数转换为非线性函数。 下图是sigmoid函数的图像，如果我把水平轴作为$z$轴，那么关于$z$的sigmoid函数是这样的，它是平滑地从0走向1，让我在这里标记纵轴，这是0，曲线与纵轴相交的截距是0.5，这就是关于$z$的sigmoid函数的图像。我们通常都使用$z$来表示${ {w}^{T} }x+b$的值。 关于sigmoid函数的公式是这样的，$\sigma \left( z \right)=\frac{1}{1+{ {e}^{-z} }}$,在这里$z$是一个实数，这里要说明一些要注意的事情，如果$z$非常大那么${ {e}^{-z} }$将会接近于0，关于$z$的sigmoid函数将会近似等于1除以1加上某个非常接近于0的项，因为$e$ 的指数如果是个绝对值很大的负数的话，这项将会接近于0，所以如果$z$很大的话那么关于$z$的sigmoid函数会非常接近1。相反地，如果$z$非常小或者说是一个绝对值很大的负数，那么关于${ {e}^{-z} }$这项会变成一个很大的数，你可以认为这是1除以1加上一个非常非常大的数，所以这个就接近于0。实际上你看到当$z$变成一个绝对值很大的负数，关于$z$的sigmoid函数就会非常接近于0，因此当你实现逻辑回归时，你的工作就是去让机器学习参数$w$以及$b$这样才使得$\hat{y}$成为对$y=1$这一情况的概率的一个很好的估计。 在继续进行下一步之前，介绍一种符号惯例，可以让参数$w$和参数$b$分开。在符号上要注意的一点是当我们对神经网络进行编程时经常会让参数$w$和参数$b$分开，在这里参数$b$对应的是一种偏置。在之前的机器学习课程里，你可能已经见过处理这个问题时的其他符号表示。比如在某些例子里，你定义一个额外的特征称之为${ {x}_{0} }$，并且使它等于1，那么现在$X$就是一个$n_x$加1维的变量，然后你定义$\hat{y}=\sigma \left( { {\theta }^{T} }x \right)$的sigmoid函数。在这个备选的符号惯例里，你有一个参数向量${ {\theta }_{0} },{ {\theta }_{1} },{ {\theta }_{2} },...,{ {\theta }_{ {{n}_{x} }} }$，这样${ {\theta }_{0} }$就充当了$b$，这是一个实数，而剩下的${ {\theta }_{1} }$ 直到${ {\theta }_{ {{n}_{x} }} }$充当了$w$，结果就是当你实现你的神经网络时，有一个比较简单的方法是保持$b$和$w$分开。但是在这节课里我们不会使用任何这类符号惯例，所以不用去担心。现在你已经知道逻辑回归模型是什么样子了，下一步要做的是训练参数$w$和参数$b$，你需要定义一个代价函数，让我们在下节课里对其进行解释。 2.3 逻辑回归的代价函数（Logistic Regression Cost Function）在上个视频中，我们讲了逻辑回归模型，这个视频里，我们讲逻辑回归的代价函数（也翻译作成本函数）。 为什么需要代价函数： 为了训练逻辑回归模型的参数参数$w$和参数$b$我们，需要一个代价函数，通过训练代价函数来得到参数$w$和参数$b$。先看一下逻辑回归的输出函数： 为了让模型通过学习调整参数，你需要给予一个$m$样本的训练集，这会让你在训练集上找到参数$w$和参数$b$,，来得到你的输出。 对训练集的预测值，我们将它写成$\hat{y}$，我们更希望它会接近于训练集中的$y$值，为了对上面的公式更详细的介绍，我们需要说明上面的定义是对一个训练样本来说的，这种形式也使用于每个训练样本，我们使用这些带有圆括号的上标来区分索引和样本，训练样本$i$所对应的预测值是${ {y}^{(i)} }$,是用训练样本的${ {w}^{T} }{ {x}^{(i)} }+b$然后通过sigmoid函数来得到，也可以把$z$定义为${ {z}^{(i)} }={ {w}^{T} }{ {x}^{(i)} }+b$,我们将使用这个符号$(i)$注解，上标$(i)$来指明数据表示$x$或者$y$或者$z$或者其他数据的第$i$个训练样本，这就是上标$(i)$的含义。 损失函数： 损失函数又叫做误差函数，用来衡量算法的运行情况，Loss function:$L\left( \hat{y},y \right)$. 我们通过这个$L$称为的损失函数，来衡量预测输出值和实际值有多接近。一般我们用预测值和实际值的平方差或者它们平方差的一半，但是通常在逻辑回归中我们不这么做，因为当我们在学习逻辑回归参数的时候，会发现我们的优化目标不是凸优化，只能找到多个局部最优值，梯度下降法很可能找不到全局最优值，虽然平方差是一个不错的损失函数，但是我们在逻辑回归模型中会定义另外一个损失函数。 我们在逻辑回归中用到的损失函数是：$L\left( \hat{y},y \right)=-y\log(\hat{y})-(1-y)\log (1-\hat{y})$ 为什么要用这个函数作为逻辑损失函数？当我们使用平方误差作为损失函数的时候，你会想要让这个误差尽可能地小，对于这个逻辑回归损失函数，我们也想让它尽可能地小，为了更好地理解这个损失函数怎么起作用，我们举两个例子： 当$y=1$时损失函数$L=-\log (\hat{y})$，如果想要损失函数$L$尽可能得小，那么$\hat{y}$就要尽可能大，因为sigmoid函数取值$[0,1]$，所以$\hat{y}$会无限接近于1。 当$y=0$时损失函数$L=-\log (1-\hat{y})$，如果想要损失函数$L$尽可能得小，那么$\hat{y}$就要尽可能小，因为sigmoid函数取值$[0,1]$，所以$\hat{y}$会无限接近于0。 在这门课中有很多的函数效果和现在这个类似，就是如果$y$等于1，我们就尽可能让$\hat{y}$变大，如果$y$等于0，我们就尽可能让 $\hat{y}$ 变小。损失函数是在单个训练样本中定义的，它衡量的是算法在单个训练样本中表现如何，为了衡量算法在全部训练样本上的表现如何，我们需要定义一个算法的代价函数，算法的代价函数是对$m$个样本的损失函数求和然后除以$m$: $J\left( w,b \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{L\left( { {{\hat{y} }}^{(i)} },{ {y}^{(i)} } \right)}=\frac{1}{m}\sum\limits_{i=1}^{m}{\left( -{ {y}^{(i)} }\log { {{\hat{y} }}^{(i)} }-(1-{ {y}^{(i)} })\log (1-{ {{\hat{y} }}^{(i)} }) \right)}$ 损失函数只适用于像这样的单个训练样本，而代价函数是参数的总代价，所以在训练逻辑回归模型时候，我们需要找到合适的$w$和$b$，来让代价函数 $J$ 的总代价降到最低。根据我们对逻辑回归算法的推导及对单个样本的损失函数的推导和针对算法所选用参数的总代价函数的推导，结果表明逻辑回归可以看做是一个非常小的神经网络，在下一个视频中，我们会看到神经网络会做什么。 2.4 梯度下降法（Gradient Descent）梯度下降法可以做什么？ 在你测试集上，通过最小化代价函数（成本函数）$J(w,b)$来训练的参数$w$和$b$， 如图，在第二行给出和之前一样的逻辑回归算法的代价函数（成本函数） 梯度下降法的形象化说明 在这个图中，横轴表示你的空间参数$w$和$b$，在实践中，$w$可以是更高的维度，但是为了更好地绘图，我们定义$w$和$b$，都是单一实数，代价函数（成本函数）$J(w,b)$是在水平轴$w$和$b$上的曲面，因此曲面的高度就是$J(w,b)$在某一点的函数值。我们所做的就是找到使得代价函数（成本函数）$J(w,b)$函数值是最小值，对应的参数$w$和$b$。 如图，代价函数（成本函数）$J(w,b)$是一个凸函数(convex function)，像一个大碗一样。 如图，这就与刚才的图有些相反，因为它是非凸的并且有很多不同的局部最小值。由于逻辑回归的代价函数（成本函数）$J(w,b)$特性，我们必须定义代价函数（成本函数）$J(w,b)$为凸函数。初始化$w$和$b$， 可以用如图那个小红点来初始化参数$w$和$b$，也可以采用随机初始化的方法，对于逻辑回归几乎所有的初始化方法都有效，因为函数是凸函数，无论在哪里初始化，应该达到同一点或大致相同的点。 我们以如图的小红点的坐标来初始化参数$w$和$b$。 2. 朝最陡的下坡方向走一步，不断地迭代 我们朝最陡的下坡方向走一步，如图，走到了如图中第二个小红点处。 我们可能停在这里也有可能继续朝最陡的下坡方向再走一步，如图，经过两次迭代走到第三个小红点处。 3.直到走到全局最优解或者接近全局最优解的地方 通过以上的三个步骤我们可以找到全局最优解，也就是代价函数（成本函数）$J(w,b)$这个凸函数的最小值点。 梯度下降法的细节化说明（仅有一个参数） 假定代价函数（成本函数）$J(w)$ 只有一个参数$w$，即用一维曲线代替多维曲线，这样可以更好画出图像。 迭代就是不断重复做如图的公式: $:=$表示更新参数, $a $ 表示学习率（**learning rate**），用来控制步长（**step**），即向下走一步的长度$\frac{dJ(w)}{dw}$ 就是函数$J(w)$对$w$ 求导（**derivative**），在代码中我们会使用$dw$表示这个结果 对于导数更加形象化的理解就是斜率（slope），如图该点的导数就是这个点相切于 $J(w)$的小三角形的高除宽。假设我们以如图点为初始化点，该点处的斜率的符号是正的，即$\frac{dJ(w)}{dw}>0$，所以接下来会向左走一步。 整个梯度下降法的迭代过程就是不断地向左走，直至逼近最小值点。 假设我们以如图点为初始化点，该点处的斜率的符号是负的，即$\frac{dJ(w)}{dw}&lt;0$，所以接下来会向右走一步。 整个梯度下降法的迭代过程就是不断地向右走，即朝着最小值点方向走。 梯度下降法的细节化说明（两个参数） 逻辑回归的代价函数（成本函数）$J(w,b)$是含有两个参数的。 $\partial $ 表示求偏导符号，可以读作**round**， $\frac{\partial J(w,b)}{\partial w}$ 就是函数$J(w,b)$ 对$w$ 求偏导，在代码中我们会使用$dw$ 表示这个结果， $\frac{\partial J(w,b)}{\partial b}$ 就是函数$J(w,b)$对$b$ 求偏导，在代码中我们会使用$db$ 表示这个结果， 小写字母$d$ 用在求导数（derivative），即函数只有一个参数，偏导数符号$\partial $ 用在求偏导（partial derivative），即函数含有两个以上的参数。 2.5 导数（Derivatives）这个视频我主要是想帮你获得对微积分和导数直观的理解。或许你认为自从大学毕以后你再也没有接触微积分。这取决于你什么时候毕业，也许有一段时间了，如果你顾虑这点，请不要担心。为了高效应用神经网络和深度学习，你并不需要非常深入理解微积分。因此如果你观看这个视频或者以后的视频时心想：“哇哦，这些知识、这些运算对我来说很复杂。”我给你的建议是：坚持学习视频，最好下课后做作业，成功的完成编程作业，然后你就可以使用深度学习了。在第四周之后的学习中，你会看到定义的很多种类的函数，通过微积分他们能够帮助你把所有的知识结合起来，其中有的叫做前向函数和反向函数，因此你不需要了解所有你使用的那些微积分中的函数。所以你不用担心他们，除此之外在对深度学习的尝试中，这周我们要进一步深入了解微积分的细节。所有你只需要直观地认识微积分，用来构建和成功的应用这些算法。最后，如果你是精通微积分的那一小部分人群，你对微积分非常熟悉，你可以跳过这部分视频。其他同学让我们开始深入学习导数。 一个函数$f(a)=3a$，它是一条直线。下面我们来简单理解下导数。让我们看看函数中几个点，假定$a=2$，那么$f(a)$是$a$的3倍等于6，也就是说如果$a=2$，那么函数$f(a)=6$。假定稍微改变一点点$a$的值，只增加一点，变为2.001，这时$a$将向右做微小的移动。0.001的差别实在是太小了，不能在图中显示出来，我们把它右移一点，现在$f(a)$等于$a$的3倍是6.003，画在图里，比例不太符合。请看绿色高亮部分的这个小三角形，如果向右移动0.001，那么$f(a)$增加0.003，$f(a)$的值增加3倍于右移的$a$，因此我们说函数$f(a)$在$a=2$，.是这个导数的斜率，或者说，当$a=2$时，斜率是3。导数这个概念意味着斜率，导数听起来是一个很可怕、很令人惊恐的词，但是斜率以一种很友好的方式来描述导数这个概念。所以提到导数，我们把它当作函数的斜率就好了。更正式的斜率定义为在上图这个绿色的小三角形中，高除以宽。即斜率等于0.003除以0.001，等于3。或者说导数等于3，这表示当你将$a$右移0.001，$f(a)$的值增加3倍水平方向的量。 现在让我们从不同的角度理解这个函数。假设$a=5$ ，此时$f(a)=3a=15$。把$a$右移一个很小的幅度，增加到5.001，$f(a)=15.003$。即在$a=5$ 时，斜率是3，这就是表示，当微小改变变量$a$的值，$\frac{df(a)}{da}=3$ 。一个等价的导数表达式可以这样写$\frac{d}{da}f(a)$ ，不管你是否将$f(a)$放在上面或者放在右边都没有关系。在这个视频中，我讲解导数讨论的情况是我们将$a$偏移0.001，如果你想知道导数的数学定义，导数是你右移很小的$a$值（不是0.001，而是一个非常非常小的值）。通常导数的定义是你右移$a$(可度量的值)一个无限小的值，$f(a)$增加3倍（增加了一个非常非常小的值）。也就是这个三角形右边的高度。 那就是导数的正式定义。但是为了直观的认识，我们将探讨右移$a=0.001$ 这个值，即使0.001并不是无穷小的可测数据。导数的一个特性是：这个函数任何地方的斜率总是等于3，不管$a=2$或 $a=5$，这个函数的斜率总等于3，也就是说不管$a$的值如何变化，如果你增加0.001，$f(a)$的值就增加3倍。这个函数在所有地方的斜率都相等。一种证明方式是无论你将小三角形画在哪里，它的高除以宽总是3。 我希望带给你一种感觉：什么是斜率？什么是导函数？对于一条直线，在例子中函数的斜率，在任何地方都是3。在下一个视频让我们看一个更复杂的例子，这个例子中函数在不同点的斜率是可变的。 2.6 更多的导数例子（More Derivative Examples）在这个视频中我将给出一个更加复杂的例子，在这个例子中，函数在不同点处的斜率是不一样的，先来举个例子: 我在这里画一个函数，$f(a)={ {\text{a} }^{\text{2} }}$，如果$a=\text{2}$ 的话，那么$f(a)=4$。让我们稍稍往右推进一点点，现在$a=\text{2}.\text{001}$ ，则$f(a)\approx 4.004$ (如果你用计算器算的话，这个准确的值应该为4.004。0.001 我只是为了简便起见，省略了后面的部分)，如果你在这儿画，一个小三角形，你就会发现，如果把$a$往右移动0.001，那么$f(a)$将增大四倍，即增大0.004。在微积分中我们把这个三角形斜边的斜率，称为$f(a)$在点$a=\text{2}$ 处的导数(即为4)，或者写成微积分的形式，当$a=\text{2}$ 的时候， $\frac{d}{da}f(a)=4$ 由此可知，函数$f(a)={ {a}^{ {2} }}$，在$a$取不同值的时候，它的斜率是不同的，这和上个视频中的例子是不同的。 这里有种直观的方法可以解释，为什么一个点的斜率，在不同位置会不同如果你在曲线上，的不同位置画一些小小的三角形你就会发现，三角形高和宽的比值，在曲线上不同的地方，它们是不同的。所以当$a=2$ 时，斜率为4；而当$a=5$时，斜率为10 。如果你翻看微积分的课本，课本会告诉你，函数$f(a)={ {a}^{ {2} }}$的斜率（即导数）为$2a$。这意味着任意给定一点$a$，如果你稍微将$a$，增大0.001，那么你会看到$f(a)$将增大$2a$，即增大的值为点在$a$处斜率或导数，乘以你向右移动的距离。 现在有个小细节需要注意，导数增大的值，不是刚好等于导数公式算出来的值，而只是根据导数算出来的一个估计值。 为了总结这堂课所学的知识，我们再来看看几个例子： 假设$f(a)={ {a}^{\text{3} }}$ 如果你翻看导数公式表，你会发现这个函数的导数，等于$3{ {a}^{2} }$。所以这是什么意思呢，同样地举一个例子：我们再次令$a=2$，所以${ {a}^{3} }=8$ ，如果我们又将$a$增大一点点，你会发现$f(a)\approx 8.012$， 你可以自己检查一遍，如果我们取8.012，你会发现${ {2.001}^{3} }$ ，和8.012很接近，事实上当$a=2$时，导数值为$3×{ {2}^{2} }$，即$3×4=12$。所以导数公式，表明如果你将$a$向右移动0.001时，$f(a)$ 将会向右移动12倍，即0.012。 来看最后一个例子，假设$f(a)={ {\log }_{e} }a$，有些可能会写作$\ln a$，函数$\log a$ 的斜率应该为$\frac{1}{a}$，所以我们可以解释如下：如果$a$取任何值，比如又取$a=2$，然后又把$a$向右边移动0.001 那么$f(a)$将增大$\frac{\text{1} }{a}\times \text{0}\text{.001}$，如果你借助计算器的话，你会发现当$a=2$时$f(a)\approx \text{0}\text{.69315}$ ；而$a=2.001$时，$f(a)\approx \text{0}\text{.69365}$。所以$f(a)$增大了0.0005，如果你查看导数公式，当$a=2$的时候，导数值$\frac{d}{da}f(a)=\frac{\text{1} }{\text{2} }$。这表明如果你把 增大0.001，$f(a)$将只会增大0.001的二分之一，即0.0005。如果你画个小三角形你就会发现，如果$x$ 轴增加了0.001，那么$y$ 轴上的函数$\log a$，将增大0.001的一半 即0.0005。所以 $\frac{1}{a}$ ，当$a=2$时这里是 ，就是当$a=2$时这条线的斜率。这些就是有关，导数的一些知识。 在这个视频中，你只需要记住两点： 第一点，导数就是斜率，而函数的斜率，在不同的点是不同的。在第一个例子中$f(a)=\text{3}a$ ，这是一条直线，在任何点它的斜率都是相同的，均为3。但是对于函数$f(a)={ {\text{a} }^{\text{2} }}$ ，或者$f(a)=\log a$，它们的斜率是变化的，所以它们的导数或者斜率，在曲线上不同的点处是不同的。 第二点，如果你想知道一个函数的导数，你可参考你的微积分课本或者维基百科，然后你应该就能找到这些函数的导数公式。 最后我希望，你能通过我生动的讲解，掌握这些有关导数和斜率的知识，下一课我们将讲解计算图，以及如何用它来求更加复杂的函数的导数。 2.7 计算图（Computation Graph）可以说，一个神经网络的计算，都是按照前向或反向传播过程组织的。首先我们计算出一个新的网络的输出（前向过程），紧接着进行一个反向传输操作。后者我们用来计算出对应的梯度或导数。计算图解释了为什么我们用这种方式组织这些计算过程。在这个视频中，我们将举一个例子说明计算图是什么。让我们举一个比逻辑回归更加简单的，或者说不那么正式的神经网络的例子。 我们尝试计算函数$J$，$J$是由三个变量$a,b,c$组成的函数，这个函数是$\text{3(a}+\text{bc)}$ 。计算这个函数实际上有三个不同的步骤，首先是计算 $b$ 乘以 $c$，我们把它储存在变量$u$中，因此${u}={bc}$；然后计算$v=a+u$；最后输出$J=3v$，这就是要计算的函数$J$。我们可以把这三步画成如下的计算图，我先在这画三个变量$a,b,c$，第一步就是计算$u=bc$，我在这周围放个矩形框，它的输入是$b,c$，接着第二步$v=a+u$，最后一步$J=3v$。举个例子: $a=5,b=3,c=2$ ，$u=bc$就是6，$v=a+u$ ，就是5+6=11。$J$是3倍的 ，因此。即$3×(5+3×2)$。如果你把它算出来，实际上得到33就是$J$的值。当有不同的或者一些特殊的输出变量时，例如本例中的$J$和逻辑回归中你想优化的代价函数$J$，因此计算图用来处理这些计算会很方便。从这个小例子中我们可以看出，通过一个从左向右的过程，你可以计算出$J$的值。为了计算导数，从右到左（红色箭头，和蓝色箭头的过程相反）的过程是用于计算导数最自然的方式。概括一下：计算图组织计算的形式是用蓝色箭头从左到右的计算，让我们看看下一个视频中如何进行反向红色箭头(也就是从右到左)的导数计算，让我们继续下一个视频的学习。 2.8 使用计算图求导数（Derivatives with a Computation Graph）在上一个视频中，我们看了一个例子使用流程计算图来计算函数J。现在我们清理一下流程图的描述，看看你如何利用它计算出函数$J$的导数。 下面用到的公式： $\frac{dJ}{du}=\frac{dJ}{dv}\frac{dv}{du}$ ， $\frac{dJ}{db}=\frac{dJ}{du}\frac{du}{db}$ ， $\frac{dJ}{da}=\frac{dJ}{du}\frac{du}{da}$ 这是一个流程图： 假设你要计算$\frac{ {dJ} }{ {dv} }$，那要怎么算呢？好，比如说，我们要把这个$v$值拿过来，改变一下，那么$J$的值会怎么变呢？ 所以定义上$J = 3v$，现在$v=11$，所以如果你让$v$增加一点点，比如到11.001，那么$J =3v =33.003$，所以我这里$v$增加了0.001，然后最终结果是$J$上升到原来的3倍，所以$\frac{ {dJ} }{ {dv} }=3$，因为对于任何 $v$ 的增量$J$都会有3倍增量，而且这类似于我们在上一个视频中的例子，我们有$f(a)=3a$，然后我们推导出$\frac{ {df}(a)}{ {da} }= 3$，所以这里我们有$J=3v$，所以$\frac{ {dJ} }{ {dv} } =3$，这里$J$扮演了$f$的角色，在之前的视频里的例子。 在反向传播算法中的术语，我们看到，如果你想计算最后输出变量的导数，使用你最关心的变量对$v$的导数，那么我们就做完了一步反向传播，在这个流程图中是一个反向步骤。 我们来看另一个例子，$\frac{ {dJ} }{da}$是多少呢？换句话说，如果我们提高$a$的数值，对$J$的数值有什么影响？ 好，我们看看这个例子。变量$a=5$，我们让它增加到5.001，那么对v的影响就是$a+u$，之前$v=11$，现在变成11.001，我们从上面看到现在$J$ 就变成33.003了，所以我们看到的是，如果你让$a$增加0.001，$J$增加0.003。那么增加$a$，我是说如果你把这个5换成某个新值，那么$a$的改变量就会传播到流程图的最右，所以$J$最后是33.003。所以J的增量是3乘以$a$的增量，意味着这个导数是3。 要解释这个计算过程，其中一种方式是：如果你改变了$a$，那么也会改变$v$，通过改变$v$，也会改变$J$，所以$J$值的净变化量，当你提升这个值（0.001），当你把$a$值提高一点点，这就是$J$的变化量（0.003）。 首先a增加了，$v$也会增加，$v$增加多少呢？这取决于$\frac{ {dv} }{da}$，然后$v$的变化导致$J$也在增加，所以这在微积分里实际上叫链式法则，如果$a$影响到$v$，$v$影响到$J$，那么当你让$a$变大时，$J$的变化量就是当你改变$a$时，$v$的变化量乘以改变$v$时$J$的变化量，在微积分里这叫链式法则。 我们从这个计算中看到，如果你让$a$增加0.001，$v$也会变化相同的大小，所以$\frac{ {dv} }{da}= 1$。事实上，如果你代入进去，我们之前算过$\frac{ {dJ} }{ {dv} } =3$，$\frac{ {dv} }{da} =1$，所以这个乘积3×1，实际上就给出了正确答案，$\frac{ {dJ} }{da} = 3$。 这张小图表示了如何计算，$\frac{ {dJ} }{ {dv} }$就是$J$对变量$v$的导数，它可以帮助你计算$\frac{ {dJ} }{da}$，所以这是另一步反向传播计算。 现在我想介绍一个新的符号约定，当你编程实现反向传播时，通常会有一个最终输出值是你要关心的，最终的输出变量，你真正想要关心或者说优化的。在这种情况下最终的输出变量是J，就是流程图里最后一个符号，所以有很多计算尝试计算输出变量的导数，所以输出变量对某个变量的导数，我们就用$dvar$命名，所以在很多计算中你需要计算最终输出结果的导数，在这个例子里是$J$，还有各种中间变量，比如$a、b、c、u、v$，当你在软件里实现的时候，变量名叫什么？你可以做的一件事是，在python中，你可以写一个很长的变量名，比如${dFinalOutputvar}\_{dvar}$，但这个变量名有点长，我们就用$dJ\_dvar$，但因为你一直对$dJ$求导，对这个最终输出变量求导。我这里要介绍一个新符号，在程序里，当你编程的时候，在代码里，我们就使用变量名$dvar$，来表示那个量。 好，所以在程序里是$dvar$表示导数，你关心的最终变量$J$的导数，有时最后是$L$，对代码中各种中间量的导数，所以代码里这个东西，你用$dv$表示这个值，所以$dv=3$，你的代码表示就是$da=3$。 好，所以我们通过这个流程图完成部分的后向传播算法。我们在下一张幻灯片看看这个例子剩下的部分。 我们清理出一张新的流程图，我们回顾一下，到目前为止，我们一直在往回传播，并计算$dv=3$，再次，$dv$是代码里的变量名，其真正的定义是$\frac{ {dJ} }{ {dv} }$。我发现$da=3$，再次，$da$是代码里的变量名，其实代表$\frac{ {dJ} }{da}$的值。 大概手算了一下，两条直线怎么计算反向传播。 好，我们继续计算导数，我们看看这个值$u$，那么$\frac{dJ}{du}$是多少呢？通过和之前类似的计算，现在我们从$u=6$出发，如果你令$u$增加到6.001，那么$v$之前是11，现在变成11.001了，$J$ 就从33变成33.003，所以$J$ 增量是3倍，所以$\frac{ {dJ} }{du}= 3$。对$u$的分析很类似对a的分析，实际上这计算起来就是$\frac{ {dJ} }{dv}\cdot \frac{ {dv} }{du}$，有了这个，我们可以算出$\frac{ {dJ} }{dv} =3$，$\frac{ {dv} }{du} = 1$，最终算出结果是$3×1=3$。 所以我们还有一步反向传播，我们最终计算出$du=3$，这里的$du$当然了，就是$\frac{ {dJ} }{du}$。 现在，我们仔细看看最后一个例子，那么$\frac{ {dJ} }{db}$呢？想象一下，如果你改变了$b$的值，你想要然后变化一点，让$J$ 值到达最大或最小，那么导数是什么呢？这个$J$函数的斜率，当你稍微改变$b$值之后。事实上，使用微积分链式法则，这可以写成两者的乘积，就是$\frac{ {dJ} }{du}\cdot \frac{ {du} }{db}$，理由是，如果你改变$b$一点点，所以$b$变化比如说3.001，它影响J的方式是，首先会影响$u$，它对$u$的影响有多大？好，$u$的定义是$b\cdot c$，所以$b=3$时这是6，现在就变成6.002了，对吧，因为在我们的例子中$c=2$，所以这告诉我们$\frac{ {du} }{db}= 2$当你让$b$增加0.001时，$u$就增加两倍。所以$\frac{ {du} }{db} =2$，现在我想$u$的增加量已经是$b$的两倍，那么$\frac{ {dJ} }{du}$是多少呢？我们已经弄清楚了，这等于3，所以让这两部分相乘，我们发现$\frac{ {dJ} }{db}= 6$。 好，这就是第二部分的推导，其中我们想知道 $u$ 增加0.002，会对$J$ 有什么影响。实际上$\frac{ {dJ} }{du}=3$，这告诉我们u增加0.002之后，$J$上升了3倍，那么$J$ 应该上升0.006，对吧。这可以从$\frac{ {dJ} }{du}= 3$推导出来。 如果你仔细看看这些数学内容，你会发现，如果$b$变成3.001，那么$u$就变成6.002，$v$变成11.002，然后$J=3v=33.006$，对吧？这就是如何得到$\frac{ {dJ} }{db}= 6$。 为了填进去，如果我们反向走的话，$db=6$，而$db$其实是Python代码中的变量名，表示$\frac{ {dJ} }{db}$。 我不会很详细地介绍最后一个例子，但事实上，如果你计算$\frac{ {dJ} }{dc} =\frac{ {dJ} }{du}\cdot \frac{ {du} }{dc} = 3 \times 3$，这个结果是9。 我不会详细说明这个例子，在最后一步，我们可以推出$dc=9$。 所以这个视频的要点是，对于那个例子，当计算所有这些导数时，最有效率的办法是从右到左计算，跟着这个红色箭头走。特别是当我们第一次计算对$v$的导数时，之后在计算对$a$导数就可以用到。然后对$u$的导数，比如说这个项和这里这个项： 可以帮助计算对$b$的导数，然后对$c$的导数。 所以这是一个计算流程图，就是正向或者说从左到右的计算来计算成本函数J，你可能需要优化的函数，然后反向从右到左计算导数。如果你不熟悉微积分或链式法则，我知道这里有些细节讲的很快，但如果你没有跟上所有细节，也不用怕。在下一个视频中，我会再过一遍。在逻辑回归的背景下过一遍，并给你介绍需要做什么才能编写代码，实现逻辑回归模型中的导数计算。 2.9 逻辑回归中的梯度下降（Logistic Regression Gradient Descent）本节我们讨论怎样通过计算偏导数来实现逻辑回归的梯度下降算法。它的关键点是几个重要公式，其作用是用来实现逻辑回归中梯度下降算法。但是在本节视频中，我将使用计算图对梯度下降算法进行计算。我必须要承认的是，使用计算图来计算逻辑回归的梯度下降算法有点大材小用了。但是，我认为以这个例子作为开始来讲解，可以使你更好的理解背后的思想。从而在讨论神经网络时，你可以更深刻而全面地理解神经网络。接下来让我们开始学习逻辑回归的梯度下降算法。 假设样本只有两个特征${ {x}_{1} }$和${ {x}_{2} }$，为了计算$z$，我们需要输入参数${ {w}_{1} }$、${ {w}_{2} }$ 和$b$，除此之外还有特征值${ {x}_{1} }$和${ {x}_{2} }$。因此$z$的计算公式为： $z={ {w}_{1} }{ {x}_{1} }+{ {w}_{2} }{ {x}_{2} }+b$ 回想一下逻辑回归的公式定义如下： $\hat{y}=a=\sigma (z)$ 其中$z={ {w}^{T} }x+b$ $\sigma \left( z \right)=\frac{1}{1+{ {e}^{-z} }}$ 损失函数： $L( { {{\hat{y} }}^{(i)} },{ {y}^{(i)} })=-{ {y}^{(i)} }\log { {\hat{y} }^{(i)} }-(1-{ {y}^{(i)} })\log (1-{ {\hat{y} }^{(i)} })$ 代价函数： $J\left( w,b \right)=\frac{1}{m}\sum\nolimits_{i}^{m}{L( { {{\hat{y} }}^{(i)} },{ {y}^{(i)} })}$ 假设现在只考虑单个样本的情况，单个样本的代价函数定义如下： $L(a,y)=-(y\log (a)+(1-y)\log (1-a))$ 其中$a$是逻辑回归的输出，$y$是样本的标签值。现在让我们画出表示这个计算的计算图。这里先复习下梯度下降法，$w$和$b$的修正量可以表达如下： $w:=w-a \frac{\partial J(w,b)}{\partial w}$，$b:=b-a\frac{\partial J(w,b)}{\partial b}$ 如图：在这个公式的外侧画上长方形。然后计算： $\hat{y}=a=\sigma(z)$ 也就是计算图的下一步。最后计算损失函数$L(a,y)$。有了计算图，我就不需要再写出公式了。因此，为了使得逻辑回归中最小化代价函数$L(a,y)$，我们需要做的仅仅是修改参数$w$和$b$的值。前面我们已经讲解了如何在单个训练样本上计算代价函数的前向步骤。现在让我们来讨论通过反向计算出导数。因为我们想要计算出的代价函数$L(a,y)$的导数，首先我们需要反向计算出代价函数$L(a,y)$关于$a$的导数，在编写代码时，你只需要用$da$ 来表示$\frac{dL(a,y)}{da}$ 。通过微积分得到： $\frac{dL(a,y)}{da}=-y/a+(1-y)/(1-a)$ 如果你不熟悉微积分，也不必太担心，我们会列出本课程涉及的所有求导公式。那么如果你非常熟悉微积分，我们鼓励你主动推导前面介绍的代价函数的求导公式，使用微积分直接求出$L(a,y)$关于变量$a$的导数。如果你不太了解微积分，也不用太担心。现在我们已经计算出$da$，也就是最终输出结果的导数。现在可以再反向一步，在编写Python代码时，你只需要用$dz$来表示代价函数$L$关于$z$ 的导数$\frac{dL}{dz}$，也可以写成$\frac{dL(a,y)}{dz}$，这两种写法都是正确的。 $\frac{dL}{dz}=a-y$ 。 因为$\frac{dL(a,y)}{dz}=\frac{dL}{dz}=(\frac{dL}{da})\cdot (\frac{da}{dz})$，并且$\frac{da}{dz}=a\cdot (1-a)$，而 $\frac{dL}{da}=(-\frac{y}{a}+\frac{(1-y)}{(1-a)})$，因此将这两项相乘，得到： ${dz} = \frac{ {dL}(a,y)}{ {dz} } = \frac{ {dL} }{ {dz} } = \left( \frac{ {dL} }{ {da} } \right) \cdot \left(\frac{ {da} }{ {dz} } \right) = ( - \frac{y}{a} + \frac{(1 - y)}{(1 - a)})\cdot a(1 - a) = a - y$ 视频中为了简化推导过程，假设${ {n}_{x} }$ 这个推导的过程就是我之前提到过的链式法则。如果你对微积分熟悉，放心地去推导整个求导过程，如果不熟悉微积分，你只需要知道$dz=(a-y)$已经计算好了。 现在进行最后一步反向推导，也就是计算$w$和$b$变化对代价函数$L$的影响，特别地，可以用: $d{ {w}_{1} }=\frac{1}{m}\sum\limits_{i}^{m}{x_{1}^{(i)} }({ {a}^{(i)} }-{ {y}^{(i)} })$ $d{ {w}_{2} }=\frac{1}{m}\sum\limits_{i}^{m}{x_{2}^{(i)} }({ {a}^{(i)} }-{ {y}^{(i)} })$ $db=\frac{1}{m}\sum\limits_{i}^{m}{({ {a}^{(i)} }-{ {y}^{(i)} })}$ 视频中， $d{ {w}_{1} }$ 表示$\frac{\partial L}{\partial { {w}_{1} }}={ {x}_{1} }\cdot dz$， $d{ {w}_{\text{2} }}$ 表示$\frac{\partial L}{\partial { {w}_{2} }}={ {x}_{2} }\cdot dz$， $db=dz$。 因此，关于单个样本的梯度下降算法，你所需要做的就是如下的事情：使用公式$dz=(a-y)$计算$dz$，使用$d{ {w}_{1} }={ {x}_{1} }\cdot dz$ 计算$d{ {w}_{1} }$， $d{ {w}_{2} }={ {x}_{2} }\cdot dz$计算$d{ {w}_{2} }$， $db=dz$ 来计算$db$， 然后:更新${ {w}_{1} }={ {w}_{1} }-a d{ {w}_{1} }$，更新${ {w}_{2} }={ {w}_{2} }-a d{ {w}_{2} }$，更新$b=b-\alpha db$。这就是关于单个样本实例的梯度下降算法中参数更新一次的步骤。现在你已经知道了怎样计算导数，并且实现针对单个训练样本的逻辑回归的梯度下降算法。但是，训练逻辑回归模型不仅仅只有一个训练样本，而是有$m$个训练样本的整个训练集。因此在下一节视频中，我们将这些思想应用到整个训练样本集中，而不仅仅只是单个样本上。 2.10 m 个样本的梯度下降(Gradient Descent on m Examples)在之前的视频中,你已经看到如何计算导数，以及应用梯度下降在逻辑回归的一个训练样本上。现在我们想要把它应用在$m$个训练样本上。 首先，让我们时刻记住有关于损失函数$J(w,b)$的定义。 $J(w,b)=\frac{1}{m}\sum\limits_{i=1}^{m}{L({ {a}^{(i)} },{ {y}^{(i)} })}$ 当你的算法输出关于样本$y$的${ {a}^{(i)} }$，${ {a}^{(i)} }$是训练样本的预测值，即：$\sigma ( { {z}^{(i)} })=\sigma( { {w}^{T} }{ {x}^{\left( i \right)} }+b)$。所以我们在前面的幻灯中展示的是对于任意单个训练样本，如何计算微分当你只有一个训练样本。因此$d{ {w}_{1} }$，$d{ {w}_{\text{2} }}$和$db$ 添上上标$i$表示你求得的相应的值。如果你面对的是我们在之前的幻灯中演示的那种情况，但只使用了一个训练样本$({ {x}^{(i)} },{ {y}^{(i)} })$。现在你知道带有求和的全局代价函数，实际上是1到$m$项各个损失的平均。 所以它表明全局代价函数对${ {w}_{1} }$的微分，对${ {w}_{1} }$的微分也同样是各项损失对${ {w}_{1} }$微分的平均。 但之前我们已经演示了如何计算这项，即之前幻灯中演示的如何对单个训练样本进行计算。所以你真正需要做的是计算这些微分，如我们在之前的训练样本上做的。并且求平均，这会给你全局梯度值，你能够把它直接应用到梯度下降算法中。 所以这里有很多细节，但让我们把这些装进一个具体的算法。同时你需要一起应用的就是逻辑回归和梯度下降。 我们初始化$J=0,d{ {w}_{1} }=0,d{ {w}_{2} }=0,db=0$ 代码流程： J=0;dw1=0;dw2=0;db=0; for i = 1 to m z(i) = wx(i)+b; a(i) = sigmoid(z(i)); J += -[y(i)log(a(i))+(1-y(i)）log(1-a(i)); dz(i) = a(i)-y(i); dw1 += x1(i)dz(i); dw2 += x2(i)dz(i); db += dz(i); J/= m; dw1/= m; dw2/= m; db/= m; w=w-alpha*dw b=b-alpha*db幻灯片上只应用了一步梯度下降。因此你需要重复以上内容很多次，以应用多次梯度下降。看起来这些细节似乎很复杂，但目前不要担心太多。希望你明白，当你继续尝试并应用这些在编程作业里，所有这些会变的更加清楚。 但这种计算中有两个缺点，也就是说应用此方法在逻辑回归上你需要编写两个for循环。第一个for循环是一个小循环遍历$m$个训练样本，第二个for循环是一个遍历所有特征的for循环。这个例子中我们只有2个特征，所以$n$等于2并且${ {n}_{x} }$ 等于2。 但如果你有更多特征，你开始编写你的因此$d{ {w}_{1} }$，$d{ {w}_{2} }$，你有相似的计算从$d{ {w}_{3} }$一直下去到$d{ {w}_{n} }$。所以看来你需要一个for循环遍历所有$n$个特征。 当你应用深度学习算法，你会发现在代码中显式地使用for循环使你的算法很低效，同时在深度学习领域会有越来越大的数据集。所以能够应用你的算法且没有显式的for循环会是重要的，并且会帮助你适用于更大的数据集。所以这里有一些叫做向量化技术,它可以允许你的代码摆脱这些显式的for循环。 我想在先于深度学习的时代，也就是深度学习兴起之前，向量化是很棒的。可以使你有时候加速你的运算，但有时候也未必能够。但是在深度学习时代向量化，摆脱for循环已经变得相当重要。因为我们越来越多地训练非常大的数据集，因此你真的需要你的代码变得非常高效。所以在接下来的几个视频中，我们会谈到向量化，以及如何应用向量化而连一个for循环都不使用。所以学习了这些，我希望你有关于如何应用逻辑回归，或是用于逻辑回归的梯度下降，事情会变得更加清晰。当你进行编程练习，但在真正做编程练习之前让我们先谈谈向量化。然后你可以应用全部这些东西，应用一个梯度下降的迭代而不使用任何for循环。 2.11 向量化(Vectorization)参考视频: 2.11 向量化 向量化是非常基础的去除代码中for循环的艺术，在深度学习安全领域、深度学习实践中，你会经常发现自己训练大数据集，因为深度学习算法处理大数据集效果很棒，所以你的代码运行速度非常重要，否则如果在大数据集上，你的代码可能花费很长时间去运行，你将要等待非常长的时间去得到结果。所以在深度学习领域，运行向量化是一个关键的技巧，让我们举个栗子说明什么是向量化。 在逻辑回归中你需要去计算$z={ {w}^{T} }x+b$，$w$、$x$都是列向量。如果你有很多的特征那么就会有一个非常大的向量，所以$w\in { {\mathbb{R} }^{ {{n}_{x} }} }$ , $x\in{ {\mathbb{R} }^{ {{n}_{x} }} }$，所以如果你想使用非向量化方法去计算${ {w}^{T} }x$，你需要用如下方式（python） z=0 for i in range(n_x): z += w[i]*x[i] z += b这是一个非向量化的实现，你会发现这真的很慢，作为一个对比，向量化实现将会非常直接计算${ {w}^{T} }x$，代码如下： z=np.dot(w,x)+b 这是向量化计算${ {w}^{T} }x$的方法，你将会发现这个非常快 让我们用一个小例子说明一下，在我的我将会写一些代码（以下为教授在他的Jupyter notebook上写的Python代码，） import numpy as np #导入numpy库 a = np.array([1,2,3,4]) #创建一个数据a print(a) # [1 2 3 4] import time #导入时间库 a = np.random.rand(1000000) b = np.random.rand(1000000) #通过round随机得到两个一百万维度的数组 tic = time.time() #现在测量一下当前时间 #向量化的版本 c = np.dot(a,b) toc = time.time() print(&quot;Vectorized version:&quot; + str(1000*(toc-tic)) +&quot;ms&quot;) #打印一下向量化的版本的时间 #继续增加非向量化的版本 c = 0 tic = time.time() for i in range(1000000): c += a[i]*b[i] toc = time.time() print(c) print(&quot;For loop:&quot; + str(1000*(toc-tic)) + &quot;ms&quot;)#打印for循环的版本的时间返回值见图。 在两个方法中，向量化和非向量化计算了相同的值，如你所见，向量化版本花费了1.5毫秒，非向量化版本的for循环花费了大约几乎500毫秒，非向量化版本多花费了300倍时间。所以在这个例子中，仅仅是向量化你的代码，就会运行300倍快。这意味着如果向量化方法需要花费一分钟去运行的数据，for循环将会花费5个小时去运行。 一句话总结，以上都是再说和for循环相比，向量化可以快速得到结果。 你可能听过很多类似如下的话，“大规模的深度学习使用了GPU或者图像处理单元实现”，但是我做的所有的案例都是在jupyter notebook上面实现，这里只有CPU，CPU和GPU都有并行化的指令，他们有时候会叫做SIMD指令，这个代表了一个单独指令多维数据，这个的基础意义是，如果你使用了built-in函数,像np.function或者并不要求你实现循环的函数，它可以让python的充分利用并行化计算，这是事实在GPU和CPU上面计算，GPU更加擅长SIMD计算，但是CPU事实上也不是太差，可能没有GPU那么擅长吧。接下来的视频中，你将看到向量化怎么能够加速你的代码，经验法则是，无论什么时候，避免使用明确的for循环。 以下代码及运行结果截图： 2.12 向量化的更多例子（More Examples of Vectorization）从上节视频中，你知道了怎样通过numpy内置函数和避开显式的循环(loop)的方式进行向量化，从而有效提高代码速度。 经验提醒我，当我们在写神经网络程序时，或者在写逻辑(logistic)回归，或者其他神经网络模型时，应该避免写循环(loop)语句。虽然有时写循环(loop)是不可避免的，但是我们可以使用比如numpy的内置函数或者其他办法去计算。当你这样使用后，程序效率总是快于循环(loop)。 让我们看另外一个例子。如果你想计算向量$u=Av$，这时矩阵乘法定义为，矩阵乘法的定义就是：$u_{i} =\sum_{j}^{}{A_{\text{ij} }v_{i} }$，这取决于你怎么定义$u_{i}$值。同样使用非向量化实现，$u=np.zeros(n,1)$， 并且通过两层循环$for(i):for(j):$，得到$u[i]=u[i]+A[i][j]*v[j]$ 。现在就有了$i$ 和 $j$ 的两层循环，这就是非向量化。向量化方式就可以用$u=np.dot(A,v)$，右边这种向量化实现方式，消除了两层循环使得代码运行速度更快。 下面通过另一个例子继续了解向量化。如果你已经有一个向量$v$，并且想要对向量$v$的每个元素做指数操作，得到向量$u$等于$e$的$v_1$，$e$的$v_2$，一直到$e$的$v_n$次方。这里是非向量化的实现方式，首先你初始化了向量$u=np.zeros(n,1)$，并且通过循环依次计算每个元素。但事实证明可以通过python的numpy内置函数，帮助你计算这样的单个函数。所以我会引入import numpy as np，执行 $u=np.exp(v)$ 命令。注意到，在之前有循环的代码中，这里仅用了一行代码，向量$v$作为输入，$u$作为输出。你已经知道为什么需要循环，并且通过右边代码实现，效率会明显的快于循环方式。 事实上，numpy库有很多向量函数。比如 u=np.log是计算对数函数($log$)、 np.abs() 计算数据的绝对值、np.maximum(v, 0) 按元素计算$v$中每个元素和和0相比的最大值，v**2 代表获得元素 $v$ 每个值的平方、 1/v 获取 $v$ 中每个元素的倒数等等。所以当你想写循环时候，检查numpy是否存在类似的内置函数，从而避免使用循环(loop)方式。 那么，将刚才所学到的内容，运用在逻辑回归的梯度下降上，看看我们是否能简化两个计算过程中的某一步。这是我们逻辑回归的求导代码，有两层循环。在这例子我们有$n$个特征值。如果你有超过两个特征时，需要循环 $dw_1$ 、$dw_2$ 、$dw_3$ 等等。所以 $j$ 的实际值是1、2 和 $n_x$，就是你想要更新的值。所以我们想要消除第二循环，在这一行，这样我们就不用初始化 $dw_1$ ， $dw_2$ 都等于0。去掉这些，而是定义 $dw$ 为一个向量，设置 $u=np.zeros(n(x),1)$。定义了一个$x$行的一维向量，从而替代循环。我们仅仅使用了一个向量操作 $dw=dw+x^{(i)}dz^{(i)}$ 。最后，我们得到 $dw=dw/m$ 。现在我们通过将两层循环转成一层循环，我们仍然还有这个循环训练样本。 希望这个视频给了你一点向量化感觉，减少一层循环使你代码更快，但事实证明我们能做得更好。所以在下个视频，我们将进一步的讲解逻辑回归，你将会看到更好的监督学习结果。在训练中不需要使用任何 for 循环，你也可以写出代码去运行整个训练集。到此为止一切都好，让我们看下一个视频。 2.13 向量化逻辑回归(Vectorizing Logistic Regression)我们已经讨论过向量化是如何显著加速你的代码，在本次视频中我们将讨论如何实现逻辑回归的向量化计算。这样就能处理整个数据集，甚至不会用一个明确的for循环就能实现对于整个数据集梯度下降算法的优化。我对这项技术感到非常激动，并且当我们后面谈到神经网络时同样也不会用到一个明确的 for 循环。 让我们开始吧，首先我们回顾一下逻辑回归的前向传播步骤。所以，如果你有 $m$ 个训练样本，然后对第一个样本进行预测，你需要这样计算。计算 $z$，我正在使用这个熟悉的公式 $z^{(1)}=w^{T}x^{(1)}+b$ 。然后计算激活函数 $a^{(1)}=\sigma (z^{(1)})$ ，计算第一个样本的预测值 $y$ 。 然后对第二个样本进行预测，你需要计算 $z^{(2)}=w^{T}x^{(2)}+b$ ， $a^{(2)}=\sigma (z^{(2)})$ 。然后对第三个样本进行预测，你需要计算 $z^{(3)}=w^{T}x^{(3)}+b$ ， $a^{(3)}=\sigma (z^{(3)})$ ，依次类推。如果你有 $m$ 个训练样本，你可能需要这样做 $m$ 次，可以看出，为了完成前向传播步骤，即对我们的 $m$ 个样本都计算出预测值。有一个办法可以并且不需要任何一个明确的for循环。让我们来看一下你该怎样做。 首先，回忆一下我们曾经定义了一个矩阵 $X$ 作为你的训练输入，(如下图中蓝色 $X$ )像这样在不同的列中堆积在一起。这是一个 $n_x$ 行 $m$ 列的矩阵。我现在将它写为Python numpy的形式 $$(n_{x},m)$$ ，这只是表示 $X$ 是一个 $n_x$ 乘以 $m$ 的矩阵 $$R^{n_x \times m}$$。 现在我首先想做的是告诉你该如何在一个步骤中计算 $z_1$、 $z_2$ 、$z_3$ 等等。实际上，只用了一行代码。所以，我打算先构建一个 $1\times m$ 的矩阵，实际上它是一个行向量，同时我准备计算 $z^{(1)}$， $z^{(2)}$ ……一直到 $z^{(m)}$ ，所有值都是在同一时间内完成。结果发现它可以表达为 $w$ 的转置乘以大写矩阵 $x$ 然后加上向量 $[b b...b]$ ， $([z^{(1)} z^{(2)}...z^{(m)}]=w^{T}+[bb...b])$ 。$[b b...b]$ 是一个 $1\times m$ 的向量或者 $1\times m$ 的矩阵或者是一个 $m$ 维的行向量。所以希望你熟悉矩阵乘法，你会发现的 $w$ 转置乘以 $x^{(1)}$ ， $x^{(2)}$ 一直到 $x^{(m)}$ 。所以 $w$ 转置可以是一个行向量。所以第一项 $w^{T}X$ 将计算 $w$ 的转置乘以 $x^{(1)}$， $w$ 转置乘以$x^{(2)}$ 等等。然后我们加上第二项 $[b b...b]$ ，你最终将 $b$ 加到了每个元素上。所以你最终得到了另一个 $1\times m$ 的向量， $[z^{(1)} z^{(2)}...z^{(m)}]=w^{T}X+[b b...b]=[w^{T}x^{(1)}+b,w^{T}x^{(2)}+b...w^{T}x^{(m)}+b]$ 。 $w^{T}x^{(1)}+b$ 这是第一个元素，$w^{T}x^{(2)}+b$ 这是第二个元素， $w^{T}x^{(m)}+b$ 这是第 $m$ 个元素。 如果你参照上面的定义，第一个元素恰好是 $z^{(1)}$ 的定义，第二个元素恰好是 $z^{(2)}$ 的定义，等等。所以，因为$X$是一次获得的，当你得到你的训练样本，一个一个横向堆积起来，这里我将 $[z^{(1)} z^{(2)} ... z^{(m)}]$ 定义为大写的 $Z$ ，你用小写 $z$ 表示并将它们横向排在一起。所以当你将不同训练样本对应的小写 $x$ 横向堆积在一起时得到大写变量 $X$ 并且将小写变量也用相同方法处理，将它们横向堆积起来，你就得到大写变量 $Z$ 。结果发现，为了计算 $W^{T}X+[b b ... b]$ ，numpy命令是$Z=np.dot(w.T,X)+b$。这里在Python中有一个巧妙的地方，这里 $b$ 是一个实数，或者你可以说是一个 $1\times 1$ 矩阵，只是一个普通的实数。但是当你将这个向量加上这个实数时，Python自动把这个实数 $b$ 扩展成一个 $1\times m$ 的行向量。所以这种情况下的操作似乎有点不可思议，它在Python中被称作广播(brosdcasting)，目前你不用对此感到顾虑，我们将在下一个视频中进行进一步的讲解。话说回来它只用一行代码，用这一行代码，你可以计算大写的 $Z$，而大写 $Z$ 是一个包含所有小写$z^{(1)}$ 到 $ z^{(m)}$ 的 $1\times m$ 的矩阵。这就是 $Z$ 的内容，关于变量 $a$ 又是如何呢？ 我们接下来要做的就是找到一个同时计算 $[a^{(1)} a^{(2)} ... a^{(m)}]$ 的方法。就像把小写 $x$ 堆积起来得到大写 $X$ 和横向堆积小写 $z$ 得到大写 $Z$ 一样，堆积小写变量 $a$ 将形成一个新的变量，我们将它定义为大写 $A$。在编程作业中，你将看到怎样用一个向量在sigmoid函数中进行计算。所以sigmoid函数中输入大写 $Z$ 作为变量并且非常高效地输出大写 $A$。你将在编程作业中看到它的细节。 总结一下，在这张幻灯片中我们已经看到，不需要for循环，利用 $m$ 个训练样本一次性计算出小写 $z$ 和小写 $a$，用一行代码即可完成。 Z = np.dot(w.T,X) + b 这一行代码：$A=[a^{(1)} a^{(2)} ... a^{(m)}]=\sigma (Z)$ ，通过恰当地运用$\sigma$一次性计算所有 $a$。这就是在同一时间内你如何完成一个所有 $m$ 个训练样本的前向传播向量化计算。 概括一下，你刚刚看到如何利用向量化在同一时间内高效地计算所有的激活函数的所有 $a$值。接下来，可以证明，你也可以利用向量化高效地计算反向传播并以此来计算梯度。让我们在下一个视频中看该如何实现。 2.14 向量化 logistic 回归的梯度输出（Vectorizing Logistic Regression’s Gradient）注：本节中大写字母代表向量，小写字母代表元素 如何向量化计算的同时，对整个训练集预测结果$a$，这是我们之前已经讨论过的内容。在本次视频中我们将学习如何向量化地计算$m$个训练数据的梯度，本次视频的重点是如何同时计算 $m$ 个数据的梯度，并且实现一个非常高效的逻辑回归算法(Logistic Regression)。 之前我们在讲梯度计算的时候，列举过几个例子， $dz^{(1)}=a^{(1)}-y^{(1)}$，$dz^{(2)}=a^{(2)}-y^{(2)}$ ……等等一系列类似公式。现在，对 $m$个训练数据做同样的运算，我们可以定义一个新的变量 $dZ=[dz^{(1)} ,dz^{(2)} ... dz^{(m)}]$，所有的 $dz$ 变量横向排列，因此，$dZ$ 是一个 $1\times m$ 的矩阵，或者说，一个 $m$ 维行向量。在之前的幻灯片中，我们已经知道如何计算$A$，即 $[a^{(1)},a^{(2)} ... a^{(m)}]$,我们需要找到这样的一个行向量 $Y=[y^{(1)} y^{(2)} ... y^{(m)}]$ ，由此，我们可以这样计算 $dZ=A-Y=[a^{(1)}-y^{(1)} a^{(2)}-y^{(2)} ... a^{(m)}-y^{(m)}]$，不难发现第一个元素就是 $dz^{(1)}$，第二个元素就是 $dz^{(2)}$ ……所以我们现在仅需一行代码，就可以同时完成这所有的计算。 在之前的实现中，我们已经去掉了一个for循环，但我们仍有一个遍历训练集的循环，如下所示： $dw=0$ $dw + = x^{(1)}*{dz}^{(1)}$ $dw + = x^{(2)}\ *dz^{(2)}$ …………. $dw + = x^{(m)}*{dz}^{(m)}$ $dw = \frac{ {dw} }{m}$ $db = 0$ $db + = {dz}^{(1)}$ $db + = {dz}^{(2)}$ …………. $db + = dz^{(m)}$ $db = \frac{ {db} }{m}$ 上述（伪）代码就是我们在之前实现中做的，我们已经去掉了一个for循环，但用上述方法计算 $dw$ 仍然需要一个循环遍历训练集，我们现在要做的就是将其向量化！ 首先我们来看 $db$，不难发现 $$db=\frac{1}{m}\sum_{i=1}^{m}dz^{(i)}$$ ，之前的讲解中，我们知道所有的$dz^{i)}$已经组成一个行向量 $dZ$了，所以在Python中，我们很容易地想到$$db=\frac{1}{m}np.sum(dZ)$$；接下来看$dw$，我们先写出它的公式 $$dw=\frac{1}{m}Xdz^{T}$$其中，$X$ 是一个行向量。因此展开后 $$dw=\frac{1}{m}(x^{(1)}dz^{(1)}+x^{(2)}dz^{(2)}+…+x^{m}dz^{m})$$ 。因此我们可以仅用两行代码进行计算：$$db=\frac{1}{m}np.sum(dZ)$$， $$dw=\frac{1}{m}X*dz^{T}$$。这样，我们就避免了在训练集上使用for循环。 现在，让我们回顾一下，看看我们之前怎么实现的逻辑回归，可以发现，没有向量化是非常低效的，如下图所示代码： 我们的目标是不使用for循环，而是向量，我们可以这么做： $Z = w^{T}X + b = np.dot( w.T,X)+b$ $A = \sigma( Z )$ $dZ = A - Y$ ${ {dw} = \frac{1}{m}Xdz^{T}\ }$ $db= \frac{1}{m}*np.sum( dZ)$ $w: = w - a*dw$ $b: = b - a*db$ 现在我们利用前五个公式完成了前向和后向传播，也实现了对所有训练样本进行预测和求导，再利用后两个公式，梯度下降更新参数。我们的目的是不使用for循环，所以我们就通过一次迭代实现一次梯度下降，但如果你希望多次迭代进行梯度下降，那么仍然需要for循环，放在最外层。不过我们还是觉得一次迭代就进行一次梯度下降，避免使用任何循环比较舒服一些。 最后，我们得到了一个高度向量化的、非常高效的逻辑回归的梯度下降算法，我们将在下次视频中讨论Python中的Broadcasting技术。 2.15 Python 中的广播（Broadcasting in Python）这是一个不同食物(每100g)中不同营养成分的卡路里含量表格，表格为3行4列，列表示不同的食物种类，从左至右依次为苹果，牛肉，鸡蛋，土豆。行表示不同的营养成分，从上到下依次为碳水化合物，蛋白质，脂肪。 那么，我们现在想要计算不同食物中不同营养成分中的卡路里百分比。 现在计算苹果中的碳水化合物卡路里百分比含量，首先计算苹果（100g）中三种营养成分卡路里总和56+1.2+1.8= 59，然后用56/59 = 94.9%算出结果。 可以看出苹果中的卡路里大部分来自于碳水化合物，而牛肉则不同。 对于其他食物，计算方法类似。首先，按列求和，计算每种食物中（100g）三种营养成分总和，然后分别用不用营养成分的卡路里数量除以总和，计算百分比。 那么，能否不使用for循环完成这样的一个计算过程呢？ 假设上图的表格是一个4行3列的矩阵$A$，记为 $A_{3\times 4}$，接下来我们要使用Python的numpy库完成这样的计算。我们打算使用两行代码完成，第一行代码对每一列进行求和，第二行代码分别计算每种食物每种营养成分的百分比。 在jupyter notebook中输入如下代码，按shift+Enter运行，输出如下。 下面使用如下代码计算每列的和，可以看到输出是每种食物(100g)的卡路里总和。 其中sum的参数axis=0表示求和运算按列执行，之后会详细解释。 接下来计算百分比，这条指令将 $3\times 4$的矩阵$A$除以一个$1 \times 4$的矩阵，得到了一个 $3 \times 4$的结果矩阵，这个结果矩阵就是我们要求的百分比含量。 下面再来解释一下A.sum(axis = 0)中的参数axis。axis用来指明将要进行的运算是沿着哪个轴执行，在numpy中，0轴是垂直的，也就是列，而1轴是水平的，也就是行。 而第二个A/cal.reshape(1,4)指令则调用了numpy中的广播机制。这里使用 $3 \times 4$的矩阵$A$除以 $1 \times 4$的矩阵$cal$。技术上来讲，其实并不需要再将矩阵$cal$ reshape(重塑)成 $1 \times 4$，因为矩阵$cal$本身已经是 $1 \times 4$了。但是当我们写代码时不确定矩阵维度的时候，通常会对矩阵进行重塑来确保得到我们想要的列向量或行向量。重塑操作reshape是一个常量时间的操作，时间复杂度是$O(1)$，它的调用代价极低。 那么一个 $3 \times 4$ 的矩阵是怎么和 $1 \times 4$的矩阵做除法的呢？让我们来看一些更多的广播的例子。 在numpy中，当一个 $4 \times 1$的列向量与一个常数做加法时，实际上会将常数扩展为一个 $4 \times 1$的列向量，然后两者做逐元素加法。结果就是右边的这个向量。这种广播机制对于行向量和列向量均可以使用。 再看下一个例子。 用一个 $2 \times 3$的矩阵和一个 $1 \times 3$ 的矩阵相加，其泛化形式是 $m \times n$ 的矩阵和 $1 \times n$的矩阵相加。在执行加法操作时，其实是将 $1 \times n$ 的矩阵复制成为 $m \times n$ 的矩阵，然后两者做逐元素加法得到结果。针对这个具体例子，相当于在矩阵的第一列加100，第二列加200，第三列加300。这就是在前一张幻灯片中计算卡路里百分比的广播机制，只不过这里是除法操作（广播机制与执行的运算种类无关）。 下面是最后一个例子 这里相当于是一个 $m \times n$ 的矩阵加上一个 $m \times 1$ 的矩阵。在进行运算时，会先将 $m \times 1$ 矩阵水平复制 $n$ 次，变成一个 $m \times n$ 的矩阵，然后再执行逐元素加法。 广播机制的一般原则如下： 这里我先说一下我本人对numpy广播机制的理解，再解释上面这张PPT。 首先是numpy广播机制 如果两个数组的后缘维度的轴长度相符或其中一方的轴长度为1，则认为它们是广播兼容的。广播会在缺失维度和轴长度为1的维度上进行。 后缘维度的轴长度：A.shape[-1] 即矩阵维度元组中的最后一个位置的值 对于视频中卡路里计算的例子，矩阵 $A_{3,4}$ 后缘维度的轴长度是4，而矩阵 $cal_{1,4}$ 的后缘维度也是4，则他们满足后缘维度轴长度相符，可以进行广播。广播会在轴长度为1的维度进行，轴长度为1的维度对应axis=0，即垂直方向，矩阵 $$\text{cal}_{1,4}$$ 沿`axis=0`(垂直方向)复制成为 $$\text{cal_temp}_{3,4}$$ ，之后两者进行逐元素除法运算。 现在解释上图中的例子 矩阵 $A_{m,n}$ 和矩阵 $B_{1,n}$ 进行四则运算，后缘维度轴长度相符，可以广播，广播沿着轴长度为1的轴进行，即 $B_{1,n}$ 广播成为 ${B_{m,n} }'$ ，之后做逐元素四则运算。 矩阵 $A_{m,n}$ 和矩阵 $B_{m,1}$ 进行四则运算，后缘维度轴长度不相符，但其中一方轴长度为1，可以广播，广播沿着轴长度为1的轴进行，即 $B_{m,1}$ 广播成为 ${B_{m,n} }'$ ，之后做逐元素四则运算。 矩阵 $A_{m,1}$ 和常数$ R$ 进行四则运算，后缘维度轴长度不相符，但其中一方轴长度为1，可以广播，广播沿着缺失维度和轴长度为1的轴进行，缺失维度就是axis=0,轴长度为1的轴是axis=1，即$R$广播成为 ${B_{m,1} }'$ ，之后做逐元素四则运算。 最后，对于Matlab/Octave 有类似功能的函数bsxfun。 总结一下broadcasting，可以看看下面的图： 2.16 关于 python _ numpy 向量的说明（A note on python or numpy vectors）参考视频：本节主要讲Python中的numpy一维数组的特性，以及与行向量或列向量的区别。并介绍了老师在实际应用中的一些小技巧，去避免在coding中由于这些特性而导致的bug。 Python的特性允许你使用广播（broadcasting）功能，这是Python的numpy程序语言库中最灵活的地方。而我认为这是程序语言的优点，也是缺点。优点的原因在于它们创造出语言的表达性，Python语言巨大的灵活性使得你仅仅通过一行代码就能做很多事情。但是这也是缺点，由于广播巨大的灵活性，有时候你对于广播的特点以及广播的工作原理这些细节不熟悉的话，你可能会产生很细微或者看起来很奇怪的bug。例如，如果你将一个列向量添加到一个行向量中，你会以为它报出维度不匹配或类型错误之类的错误，但是实际上你会得到一个行向量和列向量的求和。 在Python的这些奇怪的影响之中，其实是有一个内在的逻辑关系的。但是如果对Python不熟悉的话，我就曾经见过的一些学生非常生硬、非常艰难地去寻找bug。所以我在这里想做的就是分享给你们一些技巧，这些技巧对我非常有用，它们能消除或者简化我的代码中所有看起来很奇怪的bug。同时我也希望通过这些技巧，你也能更容易地写没有bug的Python和numpy代码。 为了演示Python-numpy的一个容易被忽略的效果，特别是怎样在Python-numpy中构造向量，让我来做一个快速示范。首先设置$a=np.random.randn(5)$，这样会生成存储在数组 $a$ 中的5个高斯随机数变量。之后输出 $a$，从屏幕上可以得知，此时 $a$ 的shape（形状）是一个$(5,)$的结构。这在Python中被称作一个一维数组。它既不是一个行向量也不是一个列向量，这也导致它有一些不是很直观的效果。举个例子，如果我输出一个转置阵，最终结果它会和$a$看起来一样，所以$a$和$a$的转置阵最终结果看起来一样。而如果我输出$a$和$a$的转置阵的内积，你可能会想：$a$乘以$a$的转置返回给你的可能会是一个矩阵。但是如果我这样做，你只会得到一个数。 所以建议你编写神经网络时，不要使用shape为 (5,)_、(n,)_ 或者其他一维数组的数据结构。相反，如果你设置 $a$ 为$(5,1)$，那么这就将置于5行1列向量中。在先前的操作里 $a$ 和 $a$ 的转置看起来一样，而现在这样的 $a$ 变成一个新的 $a$ 的转置，并且它是一个行向量。请注意一个细微的差别，在这种数据结构中，当我们输出 $a$ 的转置时有两对方括号，而之前只有一对方括号，所以这就是1行5列的矩阵和一维数组的差别。 如果你输出 $a$ 和 $a$ 的转置的乘积，然后会返回给你一个向量的外积，是吧？所以这两个向量的外积返回给你的是一个矩阵。 就我们刚才看到的，再进一步说明。首先我们刚刚运行的命令是这个 $(a=np.random.randn(5))$，它生成了一个数据结构$a$，其中$a.shape$是$(5,)$。这被称作 $a$ 的一维数组，同时这也是一个非常有趣的数据结构。它不像行向量和列向量那样表现的很一致，这使得它带来一些不直观的影响。所以我建议，当你在编程练习或者在执行逻辑回归和神经网络时，你不需要使用这些一维数组。 相反，如果你每次创建一个数组，你都得让它成为一个列向量，产生一个$(5,1)$向量或者你让它成为一个行向量，那么你的向量的行为可能会更容易被理解。所以在这种情况下，$a.shape$等同于$(5,1)$。这种表现很像 $a$，但是实际上却是一个列向量。同时这也是为什么当它是一个列向量的时候，你能认为这是矩阵$(5,1)$；同时这里 $a.shape$ 将要变成$(1,5)$，这就像行向量一样。所以当你需要一个向量时，我会说用这个或那个(column vector or row vector)，但绝不会是一维数组。 我写代码时还有一件经常做的事，那就是如果我不完全确定一个向量的维度(dimension)，我经常会扔进一个断言语句(assertion statement)。像这样，去确保在这种情况下是一个$(5,1)$向量，或者说是一个列向量。这些断言语句实际上是要去执行的，并且它们也会有助于为你的代码提供信息。所以不论你要做什么，不要犹豫直接插入断言语句。如果你不小心以一维数组来执行，你也能够重新改变数组维数 $a=reshape$，表明一个$(5,1)$数组或者一个$(1,5)$数组，以致于它表现更像列向量或行向量。 我有时候看见学生因为一维数组不直观的影响，难以定位bug而告终。通过在原先的代码里清除一维数组，我的代码变得更加简洁。而且实际上就我在代码中表现的事情而言，我从来不使用一维数组。因此，要去简化你的代码，而且不要使用一维数组。总是使用 $n \times 1$ 维矩阵（基本上是列向量），或者 $1 \times n$ 维矩阵（基本上是行向量），这样你可以减少很多assert语句来节省核矩阵和数组的维数的时间。另外，为了确保你的矩阵或向量所需要的维数时，不要羞于 reshape 操作。 总之，我希望这些建议能帮助你解决一个Python中的bug，从而使你更容易地完成练习。 2.17 Jupyter/iPython Notebooks快速入门（Quick tour of Jupyter/iPython Notebooks）学到现在，你即将要开始处理你的第一个编程作业。但在那之前，让我快速地给你介绍一下在Coursera上的iPython Notebooks工具。 这就是Jupyter iPython Notebooks的界面，你可以通过它连接到Coursera。让我快速地讲解下它的一些特性。关于它的说明已经被写入这个Notebook中。 这里有一些空白区域的代码块，你可以在这里编写代码。有时，你也会看到一些函数块。而关于这些的说明都已经在iPython Notebook的文本中。在iPython Notebook中，在这些较长的灰色的区域就是代码块。 有时，你会看到代码块中有像这样的开始代码和结束代码。在进行编程练习时，请确保你的代码写在开始代码和结束代码之间。 比如，编写打印输出Hello World的代码，然后执行这一代码块（你可以按shift +enter来执行这一代码块）。最终，它就会输出我们想要的Hello World。 在运行一个单元格cell时，你也可以选择运行其中的一块代码区域。通过点击Cell菜单的Run Cells执行这部分代码。 也许，在你的计算机上，运行cell的键盘快捷方式可能并非是shift enter。但是，Mac应该和我的个人电脑一样，可以使用shift + enter来运行cell。 当你正在阅读指南时，如果不小心双击了它，点中的区域就会变成markdown语言形式。如果你不小心使其变成了这样的文本框，只要运行下单元格cell，就可以回到原来的形式。所以，点击cell菜单的Run Cells或者使用shift + enter，就可以使得它变回原样。 这里还有一些其他的小技巧。比如当你执行上面所使用的代码时，它实际上会使用一个内核在服务器上运行这段代码。如果你正在运行超负荷的进程，或者电脑运行了很长一段时间，或者在运行中出了错，又或者网络连接失败，这里依然有机会让Kernel重新工作。你只要点击Kernel，选择Restart，它会重新运行Kernel使程序继续工作。 所以，如果你只是运行相对较小的工作并且才刚刚启动你的ipad或笔记本电脑，这种情况应该是不会发生的。但是，如果你看见错误信息，比如Kernel已经中断或者其他信息,你可以试着重启Kernel。 当我使用iPython Notebook时会有多个代码区域块。尽管我并没有在前面的代码块中添加自己的代码，但还是要确保先执行这块代码。因为在这个例子，它导入了numpy包并另命名为np等，并声明了一些你可能需要的变量。为了能顺利地执行下面的代码，就必须确保先执行上面的代码，即使不要求你去写其他的代码。 最后，当你完成作业后，可以通过点击右上方蓝色的Submit Assignment按钮提交你的作业。 我发现这种交互式的shell命令，在iPython Notebooks是非常有用的，能使你快速地实现代码并且查看输出结果，便于学习。所以我希望这些练习和Jupyter iPython Notebooks会帮助你更快地学习和实践，并且帮助你了解如何去实现这些学习算法。后面一个视频是一个选学视频，它主要是讲解逻辑回归中的代价函数。你可以选择是否观看。不管怎样，都祝愿你能通过这两次编程作业。我会在新一周的课程里等待着你。 2.18 （选修）logistic 损失函数的解释（Explanation of logistic regression cost function）在前面的视频中，我们已经分析了逻辑回归的损失函数表达式，在这节选修视频中，我将给出一个简洁的证明来说明逻辑回归的损失函数为什么是这种形式。 回想一下，在逻辑回归中，需要预测的结果$\hat{y}$,可以表示为$\hat{y}=\sigma(w^{T}x+b)$，$\sigma$是我们熟悉的$S$型函数 $\sigma(z)=\sigma(w^{T}x+b)=\frac{1}{1+e^{-z} }$ 。我们约定 $\hat{y}=p(y=1|x)$ ，即算法的输出$\hat{y}$ 是给定训练样本 $x$ 条件下 $y$ 等于1的概率。换句话说，如果$y=1$，在给定训练样本 $x$ 条件下$y=\hat{y}$；反过来说，如果$y=0$，在给定训练样本$x$条件下 $y$ 等于1减去$\hat{y}(y=1-\hat{y})$，因此，如果 $\hat{y}$ 代表 $y=1$ 的概率，那么$1-\hat{y}$就是 $y=0$的概率。接下来，我们就来分析这两个条件概率公式。 这两个条件概率公式定义形式为 $p(y|x)$并且代表了 $y=0$ 或者 $y=1$ 这两种情况，我们可以将这两个公式合并成一个公式。需要指出的是我们讨论的是二分类问题的损失函数，因此，$y$的取值只能是0或者1。上述的两个条件概率公式可以合并成如下公式： $p(y|x)={\hat{y} }^{y}{(1-\hat{y})}^{(1-y)}$ 接下来我会解释为什么可以合并成这种形式的表达式：$(1-\hat{y})$的$(1-y)$次方这行表达式包含了上面的两个条件概率公式，我来解释一下为什么。 第一种情况，假设 $y=1$，由于$y=1$，那么${(\hat{y})}^{y}=\hat{y}$，因为 $\hat{y}$的1次方等于$\hat{y}$，$1-{(1-\hat{y})}^{(1-y)}$的指数项$(1-y)$等于0，由于任何数的0次方都是1，$\hat{y}$乘以1等于$\hat{y}$。因此当$y=1$时 $p(y|x)=\hat{y}$（图中绿色部分）。 第二种情况，当 $y=0$ 时 $p(y|x)$ 等于多少呢?假设$y=0$，$\hat{y}$的$y$次方就是 $$\hat{y}$$ 的0次方，任何数的0次方都等于1，因此 $p(y|x)=1×{(1-\hat{y})}^{1-y}$ ，前面假设 $y=0$ 因此$(1-y)$就等于1，因此 $p(y|x)=1×(1-\hat{y})$。因此在这里当$y=0$时，$p(y|x)=1-\hat{y}$。这就是这个公式(第二个公式，图中紫色字体部分)的结果。 因此，刚才的推导表明 $p(y|x)={\hat{y} }^{(y)}{(1-\hat{y})}^{(1-y)}$，就是 $p(y|x)$ 的完整定义。由于 log 函数是严格单调递增的函数，最大化 $log(p(y|x))$ 等价于最大化 $p(y|x)$ 并且地计算 $p(y|x)$ 的 log对数，就是计算 $log({\hat{y} }^{(y)}{(1-\hat{y})}^{(1-y)})$ (其实就是将 $p(y|x)$ 代入)，通过对数函数化简为： $ylog\hat{y}+(1-y)log(1-\hat{y})$ 而这就是我们前面提到的损失函数的负数 $(-L(\hat{y},y))$ ，前面有一个负号的原因是当你训练学习算法时需要算法输出值的概率是最大的（以最大的概率预测这个值），然而在逻辑回归中我们需要最小化损失函数，因此最小化损失函数与最大化条件概率的对数 $log(p(y|x))$ 关联起来了，因此这就是单个训练样本的损失函数表达式。 在 $m$个训练样本的整个训练集中又该如何表示呢，让我们一起来探讨一下。 让我们一起来探讨一下，整个训练集中标签的概率，更正式地来写一下。假设所有的训练样本服从同一分布且相互独立，也即独立同分布的，所有这些样本的联合概率就是每个样本概率的乘积: $P\left(\text{labels in training set} \right) = \prod_{i =1}^{m}{P(y^{(i)}|x^{(i)})}$。 如果你想做最大似然估计，需要寻找一组参数，使得给定样本的观测值概率最大，但令这个概率最大化等价于令其对数最大化，在等式两边取对数： $logp\left( \text{labels in training set} \right) = log\prod_{i =1}^{m}{P(y^{(i)}|x^{(i)})} = \sum_{i = 1}^{m}{logP(y^{(i)}|x^{(i)})} = \sum_{i =1}^{m}{- L(\hat y^{(i)},y^{(i)})}$ 在统计学里面，有一个方法叫做最大似然估计，即求出一组参数，使这个式子取最大值，也就是说，使得这个式子取最大值，$\sum_{i= 1}^{m}{- L(\hat y^{(i)},y^{(i)})}$，可以将负号移到求和符号的外面，$- \sum_{i =1}^{m}{L(\hat y^{(i)},y^{(i)})}$，这样我们就推导出了前面给出的logistic回归的成本函数$J(w,b)= \sum_{i = 1}^{m}{L(\hat y^{(i)},y^{\hat( i)})}$。 由于训练模型时，目标是让成本函数最小化，所以我们不是直接用最大似然概率，要去掉这里的负号，最后为了方便，可以对成本函数进行适当的缩放，我们就在前面加一个额外的常数因子$\frac{1}{m}$，即:$J(w,b)= \frac{1}{m}\sum_{i = 1}^{m}{L(\hat y^{(i)},y^{(i)})}$。 总结一下，为了最小化成本函数$J(w,b)$，我们从logistic回归模型的最大似然估计的角度出发，假设训练集中的样本都是独立同分布的条件下。尽管这节课是选修性质的，但还是感谢观看本节视频。我希望通过本节课您能更好地明白逻辑回归的损失函数，为什么是那种形式，明白了损失函数的原理，希望您能继续完成课后的练习，前面课程的练习以及本周的测验，在课后的小测验和编程练习中，祝您好运。 浅层神经网络(Shallow neural networks)3.1 神经网络概述（Neural Network Overview）本周你将学习如何实现一个神经网络。在我们深入学习具体技术之前，我希望快速的带你预览一下本周你将会学到的东西。如果这个视频中的某些细节你没有看懂你也不用担心，我们将在后面的几个视频中深入讨论技术细节。 现在我们开始快速浏览一下如何实现神经网络。上周我们讨论了逻辑回归，我们了解了这个模型(见图3.1.1)如何与下面公式3.1建立联系。图3.1.1 :公式3.1：$$\left.\begin{array}{l}x\w\b\end{array}\right}\implies{z={w}^Tx+b}$$ 如上所示，首先你需要输入特征$x$，参数$w$和$b$，通过这些你就可以计算出$z$，公式3.2：$$\left.\begin{array}{l}x\w\b\end{array}\right}\implies{z={w}^Tx+b}\implies{a = \sigma(z)}\\implies{ {L}(a,y)}$$ 接下来使用$z$就可以计算出$a$。我们将的符号换为表示输出$\hat{y}\implies{a = \sigma(z)}$,然后可以计算出loss function $L(a,y)$ 神经网络看起来是如下这个样子（图3.1.2）。正如我之前已经提到过，你可以把许多sigmoid单元堆叠起来形成一个神经网络。对于图3.1.1中的节点，它包含了之前讲的计算的两个步骤：首先通过公式3.1计算出值$z$，然后通过$\sigma(z)$计算值$a$。 图3.1.2 在这个神经网络（图3.1.2）对应的3个节点，首先计算第一层网络中的各个节点相关的数$z^{[1]}$，接着计算$\alpha^{[1]}$，在计算下一层网络同理；我们会使用符号$^{[m]}$表示第$m$层网络中节点相关的数，这些节点的集合被称为第$m$层网络。这样可以保证$^{[m]}$不会和我们之前用来表示单个的训练样本的$^{(i)}$(即我们使用表示第$i$个训练样本)混淆；整个计算过程，公式如下:公式3.3：$$\left.\begin{array}{r}{x }\{W^{[1]} }\{b^{[1]} }\end{array}\right}\implies{z^{[1]}=W^{[1]}x+b^{[1]} }\implies{a^{[1]} = \sigma(z^{[1]})}$$公式3.4：$$\left.\begin{array}{r}\text{ $a^{[1]} = \sigma(z^{[1]})$ }\\text{ $W^{[2]}$ }\\text{ $b^{[2]}$ }\\end{array}\right}\implies{z^{[2]}=W^{[2]}a^{[1]}+b^{[2]} }\implies{a^{[2]} = \sigma(z^{[2]})}\\implies{ {L}\left(a^{[2]},y \right)}$$ 类似逻辑回归，在计算后需要使用计算，接下来你需要使用另外一个线性方程对应的参数计算$z^{[2]}$，计算$a^{[2]}$，此时$a^{[2]}$就是整个神经网络最终的输出，用 $\hat{y}$表示网络的输出。 公式3.5： $$ \left. \begin{array}{r} {da^{[1]} = {d}\sigma(z^{[1]})}\\ {dW^{[2]} }\\ {db^{[2]} }\\ \end{array} \right\} \impliedby{ {dz}^{[2]}={d}(W^{[2]}\alpha^{[1]}+b^{[2]} }) \impliedby{ {{da}^{[2]} } = {d}\sigma(z^{[2]})}\\ \impliedby{ {dL}\left(a^{[2]},y \right)} $$ 我知道这其中有很多细节，其中有一点非常难以理解，即在逻辑回归中，通过直接计算$z$得到结果$a$。而这个神经网络中，我们反复的计算$z$和$a$，计算$a$和$z$，最后得到了最终的输出loss function。 你应该记得逻辑回归中，有一些从后向前的计算用来计算导数$da$、$dz$。同样，在神经网络中我们也有从后向前的计算，看起来就像这样，最后会计算$da^{[2]}$ 、$dz^{[2]}$，计算出来之后，然后计算计算$dW^{[2]}$、$db^{[2]}$ 等，按公式3.4、3.5箭头表示的那样，从右到左反向计算。 现在你大概了解了一下什么是神经网络，基于逻辑回归重复使用了两次该模型得到上述例子的神经网络。我清楚这里面多了很多新符号和细节，如果没有理解也不用担心，在接下来的视频中我们会仔细讨论具体细节。 那么，下一个视频讲述神经网络的表示。 3.2 神经网络的表示（Neural Network Representation）先回顾一下我在上一个视频画几张神经网络的图片，在这次课中我们将讨论这些图片的具体含义，也就是我们画的这些神经网络到底代表什么。 我们首先关注一个例子，本例中的神经网络只包含一个隐藏层（图3.2.1）。这是一张神经网络的图片，让我们给此图的不同部分取一些名字。 图3.2.1 我们有输入特征$x_1$、$x_2$、$x_3$，它们被竖直地堆叠起来，这叫做神经网络的输入层。它包含了神经网络的输入；然后这里有另外一层我们称之为隐藏层（图3.2.1的四个结点）。待会儿我会回过头来讲解术语”隐藏”的意义；在本例中最后一层只由一个结点构成，而这个只有一个结点的层被称为输出层，它负责产生预测值。解释隐藏层的含义：在一个神经网络中，当你使用监督学习训练它的时候，训练集包含了输入$x$也包含了目标输出$y$，所以术语隐藏层的含义是在训练集中，这些中间结点的准确值我们是不知道到的，也就是说你看不见它们在训练集中应具有的值。你能看见输入的值，你也能看见输出的值，但是隐藏层中的东西，在训练集中你是无法看到的。所以这也解释了词语隐藏层，只是表示你无法在训练集中看到他们。 现在我们再引入几个符号，就像我们之前用向量$x$表示输入特征。这里有个可代替的记号$a^{[0]}$可以用来表示输入特征。$a$表示激活的意思，它意味着网络中不同层的值会传递到它们后面的层中，输入层将$x$传递给隐藏层，所以我们将输入层的激活值称为$a^{[0]}$；下一层即隐藏层也同样会产生一些激活值，那么我将其记作$a^{[1]}$，所以具体地，这里的第一个单元或结点我们将其表示为$a^{[1]}_{1}$，第二个结点的值我们记为$a^{[1]}_{2}$以此类推。所以这里的是一个四维的向量如果写成Python代码，那么它是一个规模为4x1的矩阵或一个大小为4的列向量，如下公式，它是四维的，因为在本例中，我们有四个结点或者单元，或者称为四个隐藏层单元；公式3.7$$a^{[1]} =\left[\begin{array}{ccc}a^{[1]}{1}\a^{[1]}{2}\a^{[1]}{3}\a^{[1]}{4}\end{array}\right]$$ 最后输出层将产生某个数值$a$，它只是一个单独的实数，所以的$\hat{y}$值将取为$a^{[2]}$。这与逻辑回归很相似，在逻辑回归中，我们有$\hat{y}$直接等于$a$，在逻辑回归中我们只有一个输出层，所以我们没有用带方括号的上标。但是在神经网络中，我们将使用这种带上标的形式来明确地指出这些值来自于哪一层，有趣的是在约定俗成的符号传统中，在这里你所看到的这个例子，只能叫做一个两层的神经网络（图3.2.2）。原因是当我们计算网络的层数时，输入层是不算入总层数内，所以隐藏层是第一层，输出层是第二层。第二个惯例是我们将输入层称为第零层，所以在技术上，这仍然是一个三层的神经网络，因为这里有输入层、隐藏层，还有输出层。但是在传统的符号使用中，如果你阅读研究论文或者在这门课中，你会看到人们将这个神经网络称为一个两层的神经网络，因为我们不将输入层看作一个标准的层。 图3.2.2 最后，我们要看到的隐藏层以及最后的输出层是带有参数的，这里的隐藏层将拥有两个参数$W$和$b$，我将给它们加上上标$^{[1]}$($W^{[1]}$,$b^{[1]}$)，表示这些参数是和第一层这个隐藏层有关系的。之后在这个例子中我们会看到$W$是一个4x3的矩阵，而$b$是一个4x1的向量，第一个数字4源自于我们有四个结点或隐藏层单元，然后数字3源自于这里有三个输入特征，我们之后会更加详细地讨论这些矩阵的维数，到那时你可能就更加清楚了。相似的输出层也有一些与之关联的参数$W^{[2]}$以及$b^{[2]}$。从维数上来看，它们的规模分别是1x4以及1x1。1x4是因为隐藏层有四个隐藏层单元而输出层只有一个单元，之后我们会对这些矩阵和向量的维度做出更加深入的解释，所以现在你已经知道一个两层的神经网络什么样的了，即它是一个只有一个隐藏层的神经网络。 在下一个视频中。我们将更深入地了解这个神经网络是如何进行计算的，也就是这个神经网络是怎么输入$x$，然后又是怎么得到$\hat{y}$。 3.3 计算一个神经网络的输出（Computing a Neural Network’s output）在上一节的视频中，我们介绍只有一个隐藏层的神经网络的结构与符号表示。在这节的视频中让我们了解神经网络的输出究竟是如何计算出来的。 首先，回顾下只有一个隐藏层的简单两层神经网络结构： 图3.3.1 其中，$x$表示输入特征，$a$表示每个神经元的输出，$W$表示特征的权重，上标表示神经网络的层数（隐藏层为1），下标表示该层的第几个神经元。这是神经网络的符号惯例，下同。 神经网络的计算 关于神经网络是怎么计算的，从我们之前提及的逻辑回归开始，如下图所示。用圆圈表示神经网络的计算单元，逻辑回归的计算有两个步骤，首先你按步骤计算出$z$，然后在第二步中你以sigmoid函数为激活函数计算$z$（得出$a$），一个神经网络只是这样子做了好多次重复计算。 图3.3.2 回到两层的神经网络，我们从隐藏层的第一个神经元开始计算，如上图第一个最上面的箭头所指。从上图可以看出，输入与逻辑回归相似，这个神经元的计算与逻辑回归一样分为两步，小圆圈代表了计算的两个步骤。 第一步，计算$z^{[1]}_1,z^{[1]}_1 = w^{[1]T}_1x + b^{[1]}_1$。 第二步，通过激活函数计算$a^{[1]}_1,a^{[1]}_1 = \sigma(z^{[1]}_1)$。 隐藏层的第二个以及后面两个神经元的计算过程一样，只是注意符号表示不同，最终分别得到$a^{[1]}_2、a^{[1]}_3、a^{[1]}_4$，详细结果见下: $z^{[1]}_1 = w^{[1]T}_1x + b^{[1]}_1, a^{[1]}_1 = \sigma(z^{[1]}_1)$ $z^{[1]}_2 = w^{[1]T}_2x + b^{[1]}_2, a^{[1]}_2 = \sigma(z^{[1]}_2)$ $z^{[1]}_3 = w^{[1]T}_3x + b^{[1]}_3, a^{[1]}_3 = \sigma(z^{[1]}_3)$ $z^{[1]}_4 = w^{[1]T}_4x + b^{[1]}_4, a^{[1]}_4 = \sigma(z^{[1]}_4)$ 向量化计算如果你执行神经网络的程序，用for循环来做这些看起来真的很低效。所以接下来我们要做的就是把这四个等式向量化。向量化的过程是将神经网络中的一层神经元参数纵向堆积起来，例如隐藏层中的$w$纵向堆积起来变成一个$(4,3)$的矩阵，用符号$W^{[1]}$表示。另一个看待这个的方法是我们有四个逻辑回归单元，且每一个逻辑回归单元都有相对应的参数——向量$w$，把这四个向量堆积在一起，你会得出这4×3的矩阵。因此，公式3.8： $z^{[n]} = w^{[n]}x + b^{[n]}$ 公式3.9： $a^{[n]}=\sigma(z^{[n]})$ 详细过程见下:公式3.10：$$a^{[1]} =\left[\begin{array}{c}a^{[1]}{1}\a^{[1]}{2}\a^{[1]}{3}\a^{[1]}{4}\end{array}\right]= \sigma(z^{[1]})$$公式3.11：$$\left[\begin{array}{c}z^{[1]}{1}\z^{[1]}{2}\z^{[1]}{3}\z^{[1]}{4}\\end{array}\right]=\overbrace{\left[\begin{array}{c}…W^{[1]T}{1}…\…W^{[1]T}{2}…\…W^{[1]T}{3}…\…W^{[1]T}{4}…\end{array}\right]}^{W^{[1]} }*\overbrace{\left[\begin{array}{c}x_1\x_2\x_3\\end{array}\right]}^{input}+\overbrace{\left[\begin{array}{c}b^{[1]}_1\b^{[1]}_2\b^{[1]}_3\b^{[1]}_4\\end{array}\right]}^{b^{[1]} }$$ 对于神经网络的第一层，给予一个输入$x$，得到$a^{[1]}$，$x$可以表示为$a^{[0]}$。通过相似的衍生你会发现，后一层的表示同样可以写成类似的形式，得到$a^{[2]}$，$\hat{y} = a^{[2]}$，具体过程见公式3.8、3.9。 图3.3.3 如上图左半部分所示为神经网络，把网络左边部分盖住先忽略，那么最后的输出单元就相当于一个逻辑回归的计算单元。当你有一个包含一层隐藏层的神经网络，你需要去实现以计算得到输出的是右边的四个等式，并且可以看成是一个向量化的计算过程，计算出隐藏层的四个逻辑回归单元和整个隐藏层的输出结果，如果编程实现需要的也只是这四行代码。 总结通过本视频，你能够根据给出的一个单独的输入特征向量，运用四行代码计算出一个简单神经网络的输出。接下来你将了解的是如何一次能够计算出不止一个样本的神经网络输出，而是能一次性计算整个训练集的输出。 3.4 多样本向量化（Vectorizing across multiple examples）在上一个视频，了解到如何针对于单一的训练样本，在神经网络上计算出预测值。 在这个视频，将会了解到如何向量化多个训练样本，并计算出结果。该过程与你在逻辑回归中所做类似。 逻辑回归是将各个训练样本组合成矩阵，对矩阵的各列进行计算。神经网络是通过对逻辑回归中的等式简单的变形，让神经网络计算出输出值。这种计算是所有的训练样本同时进行的，以下是实现它具体的步骤： 图3.4.1 上一节视频中得到的四个等式。它们给出如何计算出$z^{[1]}$，$a^{[1]}$，$z^{[2]}$，$a^{[2]}$。 对于一个给定的输入特征向量$X$，这四个等式可以计算出$\alpha^{[2]}$等于$\hat{y}$。这是针对于单一的训练样本。如果有$m$个训练样本,那么就需要重复这个过程。 用第一个训练样本$x^{[1]}$来计算出预测值$\hat{y}^{[1]}$，就是第一个训练样本上得出的结果。 然后，用$x^{[2]}$来计算出预测值$\hat{y}^{[2]}$，循环往复，直至用$x^{[m]}$计算出$\hat{y}^{[m]}$。 用激活函数表示法，如上图左下所示，它写成$a^{[2](1)}$、$a^{[2](2)}$和$a^{[2](m)}$。 【注】：$a^{[2](i)}$，$(i)$是指第$i$个训练样本而$[2]$是指第二层。 如果有一个非向量化形式的实现，而且要计算出它的预测值，对于所有训练样本，需要让$i$从1到$m$实现这四个等式： $z^{[1](i)}=W^{[1](i)}x^{(i)}+b^{[1](i)}$ $a^{[1](i)}=\sigma(z^{[1](i)})$ $z^{[2](i)}=W^{[2](i)}a^{[1](i)}+b^{[2](i)}$ $a^{[2](i)}=\sigma(z^{[2](i)})$ 对于上面的这个方程中的$^{(i)}$，是所有依赖于训练样本的变量，即将$(i)$添加到$x$，$z$和$a$。如果想计算$m$个训练样本上的所有输出，就应该向量化整个计算，以简化这列。 本课程需要使用很多线性代数的内容，重要的是能够正确地实现这一点，尤其是在深度学习的错误中。实际上本课程认真地选择了运算符号，这些符号只是针对于这个课程的，并且能使这些向量化容易一些。 所以，希望通过这个细节可以更快地正确实现这些算法。接下来讲讲如何向量化这些：公式3.12：$$x =\left[\begin{array}{c}\vdots &amp; \vdots &amp; \vdots &amp; \vdots\x^{(1)} &amp; x^{(2)} &amp; \cdots &amp; x^{(m)}\\vdots &amp; \vdots &amp; \vdots &amp; \vdots\\end{array}\right]$$公式3.13：$$Z^{[1]} =\left[\begin{array}{c}\vdots &amp; \vdots &amp; \vdots &amp; \vdots\z^{1} &amp; z^{1} &amp; \cdots &amp; z^{1}\\vdots &amp; \vdots &amp; \vdots &amp; \vdots\\end{array}\right]$$公式3.14：$$A^{[1]} =\left[\begin{array}{c}\vdots &amp; \vdots &amp; \vdots &amp; \vdots\\alpha^{1} &amp; \alpha^{1} &amp; \cdots &amp; \alpha^{1}\\vdots &amp; \vdots &amp; \vdots &amp; \vdots\\end{array}\right]$$公式3.15：$$\left.\begin{array}{r}\text{ $z^{[1](i)} = W^{[1](i)}x^{(i)} + b^{[1]}$ }\\text{ $\alpha^{[1](i)} = \sigma(z^{[1](i)})$ }\\text{ $z^{[2](i)} = W^{[2](i)}\alpha^{[1](i)} + b^{[2]}$ }\\text{ $\alpha^{[2](i)} = \sigma(z^{[2](i)})$ }\\end{array}\right}\implies\begin{cases}\text{ $A^{[1]} = \sigma(z^{[1]})$ }\\text{ $z^{[2]} = W^{[2]}A^{[1]} + b^{[2]}$ }\\text{ $A^{[2]} = \sigma(z^{[2]})$ }\\end{cases}$$ 前一张幻灯片中的for循环是来遍历所有个训练样本。定义矩阵$X$等于训练样本，将它们组合成矩阵的各列，形成一个$n$维或$n$乘以$m$维矩阵。接下来计算见公式3.15： 以此类推，从小写的向量$x$到这个大写的矩阵$X$，只是通过组合$x$向量在矩阵的各列中。 同理，$z^{[1](1)}$，$z^{[1](2)}$等等都是$z^{[1](m)}$的列向量，将所有$m$都组合在各列中，就的到矩阵$Z^{[1]}$。 同理，$a^{[1](1)}$，$a^{[1](2)}$，……，$a^{[1](m)}$将其组合在矩阵各列中，如同从向量$x$到矩阵$X$，以及从向量$z$到矩阵$Z$一样，就能得到矩阵$A^{[1]}$。 同样的，对于$Z^{[2]}$和$A^{[2]}$，也是这样得到。 这种符号其中一个作用就是，可以通过训练样本来进行索引。这就是水平索引对应于不同的训练样本的原因，这些训练样本是从左到右扫描训练集而得到的。 在垂直方向，这个垂直索引对应于神经网络中的不同节点。例如，这个节点，该值位于矩阵的最左上角对应于激活单元，它是位于第一个训练样本上的第一个隐藏单元。它的下一个值对应于第二个隐藏单元的激活值。它是位于第一个训练样本上的，以及第一个训练示例中第三个隐藏单元，等等。 当垂直扫描，是索引到隐藏单位的数字。当水平扫描，将从第一个训练示例中从第一个隐藏的单元到第二个训练样本，第三个训练样本……直到节点对应于第一个隐藏单元的激活值，且这个隐藏单元是位于这$m$个训练样本中的最终训练样本。 从水平上看，矩阵$A$代表了各个训练样本。从竖直上看，矩阵$A$的不同的索引对应于不同的隐藏单元。 对于矩阵$Z，X$情况也类似，水平方向上，对应于不同的训练样本；竖直方向上，对应不同的输入特征，而这就是神经网络输入层中各个节点。 神经网络上通过在多样本情况下的向量化来使用这些等式。 在下一个视频中，将证明为什么这是一种正确向量化的实现。这种证明将会与逻辑回归中的证明类似。 3.5 向量化实现的解释（Justification for vectorized implementation）在上一个视频中，我们学习到如何将多个训练样本横向堆叠成一个矩阵$X$，然后就可以推导出神经网络中前向传播（forward propagation）部分的向量化实现。 在这个视频中，我们将会继续了解到，为什么上一节中写下的公式就是将多个样本向量化的正确实现。 我们先手动对几个样本计算一下前向传播，看看有什么规律：公式3.16： $z^{[1](1)} = W^{[1]}x^{(1)} + b^{[1]}$ $z^{[1](2)} = W^{[1]}x^{(2)} + b^{[1]}$ $z^{[1](3)} = W^{[1]}x^{(3)} + b^{[1]}$ 这里，为了描述的简便，我们先忽略掉 $b^{[1]}$后面你将会看到利用Python 的广播机制，可以很容易的将$b^{[1]}$ 加进来。 现在 $W^{[1]}$ 是一个矩阵，$x^{(1)},x^{(2)},x^{(3)}$都是列向量，矩阵乘以列向量得到列向量，下面将它们用图形直观的表示出来:公式3.17：$$W^{[1]} x =\left[\begin{array}{ccc}\cdots \\cdots \\cdots \\end{array}\right] \left[\begin{array}{c}\vdots &amp;\vdots &amp; \vdots &amp; \vdots \x^{(1)} &amp; x^{(2)} &amp; x^{(3)} &amp; \vdots\\vdots &amp;\vdots &amp; \vdots &amp; \vdots \\end{array}\right]=\left[\begin{array}{c}\vdots &amp;\vdots &amp; \vdots &amp; \vdots \w^{(1)}x^{(1)} &amp; w^{(1)}x^{(2)} &amp; w^{(1)}x^{(3)} &amp; \vdots\\vdots &amp;\vdots &amp; \vdots &amp; \vdots \\end{array}\right]=\\left[\begin{array}{c}\vdots &amp;\vdots &amp; \vdots &amp; \vdots \z^{1} &amp; z^{1} &amp; z^{1} &amp; \vdots\\vdots &amp;\vdots &amp; \vdots &amp; \vdots \\end{array}\right]=Z^{[1]}$$ 视频中，吴恩达老师很细心的用不同的颜色表示不同的样本向量，及其对应的输出。所以从图中可以看出，当加入更多样本时，只需向矩阵$X$中加入更多列。 所以从这里我们也可以了解到，为什么之前我们对单个样本的计算要写成 $z^{[1](i)} = W^{[1]}x^{(i)} + b^{[1]}$ 这种形式，因为当有不同的训练样本时，将它们堆到矩阵$X$的各列中，那么它们的输出也就会相应的堆叠到矩阵 $Z^{[1]}$ 的各列中。现在我们就可以直接计算矩阵 $Z^{[1]}$ 加上$b^{[1]}$，因为列向量 $b^{[1]}$ 和矩阵 $Z^{[1]}$的列向量有着相同的尺寸，而Python的广播机制对于这种矩阵与向量直接相加的处理方式是，将向量与矩阵的每一列相加。所以这一节只是说明了为什么公式 $Z^{[1]} =W^{[1]}X + \ b^{[1]}$是前向传播的第一步计算的正确向量化实现，但事实证明，类似的分析可以发现，前向传播的其它步也可以使用非常相似的逻辑，即如果将输入按列向量横向堆叠进矩阵，那么通过公式计算之后，也能得到成列堆叠的输出。 最后，对这一段视频的内容做一个总结: 由公式3.12、公式3.13、公式3.14、公式3.15可以看出，使用向量化的方法，可以不需要显示循环，而直接通过矩阵运算从$X$就可以计算出 $A^{[1]}$，实际上$X$可以记为 $A^{[0]}$，使用同样的方法就可以由神经网络中的每一层的输入 $A^{[i-1]}$ 计算输出 $A^{[i]}$。其实这些方程有一定对称性，其中第一个方程也可以写成$Z^{[1]} = W^{[1]}A^{[0]} + b^{[1]}$，你看这对方程，还有这对方程形式其实很类似，只不过这里所有指标加了1。所以这样就显示出神经网络的不同层次，你知道大概每一步做的都是一样的，或者只不过同样的计算不断重复而已。这里我们有一个双层神经网络，我们在下周视频里会讲深得多的神经网络，你看到随着网络的深度变大，基本上也还是重复这两步运算，只不过是比这里你看到的重复次数更多。在下周的视频中将会讲解更深层次的神经网络，随着层数的加深，基本上也还是重复同样的运算。 以上就是对神经网络向量化实现的正确性的解释，到目前为止，我们仅使用sigmoid函数作为激活函数，事实上这并非最好的选择，在下一个视频中，将会继续深入的讲解如何使用更多不同种类的激活函数。 3.6 激活函数（Activation functions）使用一个神经网络时，需要决定使用哪种激活函数用隐藏层上，哪种用在输出节点上。到目前为止，之前的视频只用过sigmoid激活函数，但是，有时其他的激活函数效果会更好。 在神经网路的前向传播中，的$a^{[1]} = \sigma(z^{[1]})$和$a^{[2]} =\sigma(z^{[2]})$这两步会使用到sigmoid函数。sigmoid函数在这里被称为激活函数。公式3.18： $a = \sigma(z) = \frac{1}{ {1 + e}^{- z} }$ 更通常的情况下，使用不同的函数$g( z^{[1]})$，$g$可以是除了sigmoid函数以外的非线性函数。tanh函数或者双曲正切函数是总体上都优于sigmoid函数的激活函数。 如图，$a = tan(z)$的值域是位于+1和-1之间。公式3.19： $a= tanh(z) = \frac{e^{z} - e^{- z} }{e^{z} + e^{- z} }$ 事实上，tanh函数是sigmoid的向下平移和伸缩后的结果。对它进行了变形后，穿过了$(0,0)$点，并且值域介于+1和-1之间。 结果表明，如果在隐藏层上使用函数公式3.20： $g(z^{[1]}) = tanh(z^{[1]}) $ 效果总是优于sigmoid函数。因为函数值域在-1和+1的激活函数，其均值是更接近零均值的。在训练一个算法模型时，如果使用tanh函数代替sigmoid函数中心化数据，使得数据的平均值更接近0而不是0.5. 这会使下一层学习简单一点，在第二门课中会详细讲解。 在讨论优化算法时，有一点要说明：我基本已经不用sigmoid激活函数了，tanh函数在所有场合都优于sigmoid函数。 但有一个例外：在二分类的问题中，对于输出层，因为$y$的值是0或1，所以想让$\hat{y}$的数值介于0和1之间，而不是在-1和+1之间。所以需要使用sigmoid激活函数。这里的公式3.21： $g(z^{[2]}) = \sigma(z^{[2]})$ 在这个例子里看到的是，对隐藏层使用tanh激活函数，输出层使用sigmoid函数。 所以，在不同的神经网络层中，激活函数可以不同。为了表示不同的激活函数，在不同的层中，使用方括号上标来指出$g$上标为$[1]$的激活函数，可能会跟$g$上标为$[2]$不同。方括号上标$[1]$代表隐藏层，方括号上标$[2]$表示输出层。 sigmoid函数和tanh函数两者共同的缺点是，在$z$特别大或者特别小的情况下，导数的梯度或者函数的斜率会变得特别小，最后就会接近于0，导致降低梯度下降的速度。 在机器学习另一个很流行的函数是：修正线性单元的函数（ReLu），ReLu函数图像是如下图。公式3.22： $ a =max( 0,z) $ 所以，只要$z$是正值的情况下，导数恒等于1，当$z$是负值的时候，导数恒等于0。从实际上来说，当使用$z$的导数时，$z$=0的导数是没有定义的。但是当编程实现的时候，$z$的取值刚好等于0.00000001，这个值相当小，所以，在实践中，不需要担心这个值，$z$是等于0的时候，假设一个导数是1或者0效果都可以。 这有一些选择激活函数的经验法则： 如果输出是0、1值（二分类问题），则输出层选择sigmoid函数，然后其它的所有单元都选择Relu函数。 这是很多激活函数的默认选择，如果在隐藏层上不确定使用哪个激活函数，那么通常会使用Relu激活函数。有时，也会使用tanh激活函数，但Relu的一个优点是：当$z$是负值的时候，导数等于0。 这里也有另一个版本的Relu被称为Leaky Relu。 当$z$是负值时，这个函数的值不是等于0，而是轻微的倾斜，如图。 这个函数通常比Relu激活函数效果要好，尽管在实际中Leaky ReLu使用的并不多。 图3.6.1 两者的优点是： 第一，在$z$的区间变动很大的情况下，激活函数的导数或者激活函数的斜率都会远大于0，在程序实现就是一个if-else语句，而sigmoid函数需要进行浮点四则运算，在实践中，使用ReLu激活函数神经网络通常会比使用sigmoid或者tanh激活函数学习的更快。 第二，sigmoid和tanh函数的导数在正负饱和区的梯度都会接近于0，这会造成梯度弥散，而Relu和Leaky ReLu函数大于0部分都为常数，不会产生梯度弥散现象。(同时应该注意到的是，Relu进入负半区的时候，梯度为0，神经元此时不会训练，产生所谓的稀疏性，而Leaky ReLu不会有这问题) $z$在**ReLu**的梯度一半都是0，但是，有足够的隐藏层使得z值大于0，所以对大多数的训练数据来说学习过程仍然可以很快。 快速概括一下不同激活函数的过程和结论。 sigmoid激活函数：除了输出层是一个二分类问题基本不会用它。 tanh激活函数：tanh是非常优秀的，几乎适合所有场合。 ReLu激活函数：最常用的默认函数，，如果不确定用哪个激活函数，就使用ReLu或者Leaky ReLu。公式3.23： $a = max( 0.01z,z)$ 为什么常数是0.01？当然，可以为学习算法选择不同的参数。 在选择自己神经网络的激活函数时，有一定的直观感受，在深度学习中的经常遇到一个问题：在编写神经网络的时候，会有很多选择：隐藏层单元的个数、激活函数的选择、初始化权值……这些选择想得到一个对比较好的指导原则是挺困难的。 鉴于以上三个原因，以及在工业界的见闻，提供一种直观的感受，哪一种工业界用的多，哪一种用的少。但是，自己的神经网络的应用，以及其特殊性，是很难提前知道选择哪些效果更好。所以通常的建议是：如果不确定哪一个激活函数效果更好，可以把它们都试试，然后在验证集或者发展集上进行评价。然后看哪一种表现的更好，就去使用它。 为自己的神经网络的应用测试这些不同的选择，会在以后检验自己的神经网络或者评估算法的时候，看到不同的效果。如果仅仅遵守使用默认的ReLu激活函数，而不要用其他的激励函数，那就可能在近期或者往后，每次解决问题的时候都使用相同的办法。 3.7 为什么需要非线性激活函数？（why need a nonlinear activation function?）为什么神经网络需要非线性激活函数？事实证明：要让你的神经网络能够计算出有趣的函数，你必须使用非线性激活函数，证明如下： 这是神经网络正向传播的方程，现在我们去掉函数$g$，然后令$a^{[1]} = z^{[1]}$，或者我们也可以令$g(z)=z$，这个有时被叫做线性激活函数（更学术点的名字是恒等激励函数，因为它们就是把输入值输出）。为了说明问题我们把$a^{[2]} = z^{[2]}$，那么这个模型的输出$y$或仅仅只是输入特征$x$的线性组合。 如果我们改变前面的式子，令：(1) $a^{[1]} = z^{[1]} = W^{[1]}x + b^{[1]}$ (2) $a^{[2]} = z^{[2]} = W^{[2]}a^{[1]}+ b^{[2]}$将式子(1)代入式子(2)中，则： $a^{[2]} = z^{[2]} = W^{[2]}(W^{[1]}x + b^{[1]}) + b^{[2]}$ (3) $a^{[2]} = z^{[2]} = W^{[2]}W^{[1]}x + W^{[2]}b^{[1]} + b^{[2]} $简化多项式得 $a^{[2]} = z^{[2]} = W^{'}x + b^{'} $ 如果你是用线性激活函数或者叫恒等激励函数，那么神经网络只是把输入线性组合再输出。 我们稍后会谈到深度网络，有很多层的神经网络，很多隐藏层。事实证明，如果你使用线性激活函数或者没有使用一个激活函数，那么无论你的神经网络有多少层一直在做的只是计算线性函数，所以不如直接去掉全部隐藏层。在我们的简明案例中，事实证明如果你在隐藏层用线性激活函数，在输出层用sigmoid函数，那么这个模型的复杂度和没有任何隐藏层的标准Logistic回归是一样的，如果你愿意的话，可以证明一下。 在这里线性隐层一点用也没有，因为这两个线性函数的组合本身就是线性函数，所以除非你引入非线性，否则你无法计算更有趣的函数，即使你的网络层数再多也不行；只有一个地方可以使用线性激活函数——$g(z)=z$，就是你在做机器学习中的回归问题。$y$ 是一个实数，举个例子，比如你想预测房地产价格，$y$ 就不是二分类任务0或1，而是一个实数，从0到正无穷。如果$y$ 是个实数，那么在输出层用线性激活函数也许可行，你的输出也是一个实数，从负无穷到正无穷。 总而言之，不能在隐藏层用线性激活函数，可以用ReLU或者tanh或者leaky ReLU或者其他的非线性激活函数，唯一可以用线性激活函数的通常就是输出层；除了这种情况，会在隐层用线性函数的，除了一些特殊情况，比如与压缩有关的，那方面在这里将不深入讨论。在这之外，在隐层使用线性激活函数非常少见。因为房价都是非负数，所以我们也可以在输出层使用ReLU函数这样你的$\hat{y}$都大于等于0。 理解为什么使用非线性激活函数对于神经网络十分关键，接下来我们讨论梯度下降，并在下一个视频中开始讨论梯度下降的基础——激活函数的导数。 3.8 激活函数的导数（Derivatives of activation functions）在神经网络中使用反向传播的时候，你真的需要计算激活函数的斜率或者导数。针对以下四种激活，求其导数如下： 1）sigmoid activation function 图3.8.1 其具体的求导如下：公式3.25： $\frac{d}{dz}g(z) = {\frac{1}{1 + e^{-z} } (1-\frac{1}{1 + e^{-z} })}=g(z)(1-g(z))$ 注： 当$z$ = 10或$z= -10$ ; $\frac{d}{dz}g(z)\approx0$ 当$z $= 0 , $\frac{d}{dz}g(z)\text{=g(z)(1-g(z))=}{1}/{4}$ 在神经网络中$a= g(z)$; $g{ {(z)}^{'} }=\frac{d}{dz}g(z)=a(1-a)$ 2) Tanh activation function 图3.8.2 其具体的求导如下：公式3.26： $g(z) = tanh(z) = \frac{e^{z} - e^{-z} }{e^{z} + e^{-z} } $ 公式3.27： $\frac{d}{ {d}z}g(z) = 1 - (tanh(z))^{2}$ 注： 当$z$ = 10或$z= -10$ $\frac{d}{dz}g(z)\approx0$ 当$z$ = 0, $\frac{d}{dz}g(z)\text{=1-(0)=}1$ 在神经网络中; 3）Rectified Linear Unit (ReLU) $g(z) =max (0,z)$ $$g(z)^{‘}=\begin{cases}0&amp; \text{if z &lt; 0}\1&amp; \text{if z &gt; 0}\undefined&amp; \text{if z = 0}\end{cases}$$ 注：通常在$z$= 0的时候给定其导数1,0；当然$z$=0的情况很少 4）Leaky linear unit (Leaky ReLU) 与ReLU类似$$g(z)=\max(0.01z,z) \\\g(z)^{‘}=\begin{cases}0.01&amp; \text{if z &lt; 0}\1&amp; \text{if z &gt; 0}\undefined&amp; \text{if z = 0}\end{cases}$$ 注：通常在$z = 0$的时候给定其导数1,0.01；当然$z=0$的情况很少。 3.9 神经网络的梯度下降（Gradient descent for neural networks）在这个视频中，我会给你实现反向传播或者说梯度下降算法的方程组，在下一个视频我们会介绍为什么这几个特定的方程是针对你的神经网络实现梯度下降的正确方程。 你的单隐层神经网络会有$W^{[1]}$，$b^{[1]}$，$W^{[2]}$，$b^{[2]}$这些参数，还有个$n_x$表示输入特征的个数，$n^{[1]}$表示隐藏单元个数，$n^{[2]}$表示输出单元个数。 在我们的例子中，我们只介绍过的这种情况，那么参数: 矩阵$W^{[1]}$的维度就是($n^{[1]}, n^{[0]}$)，$b^{[1]}$就是$n^{[1]}$维向量，可以写成$(n^{[1]}, 1)$，就是一个的列向量。矩阵$W^{[2]}$的维度就是($n^{[2]}, n^{[1]}$)，$b^{[2]}$的维度就是$(n^{[2]},1)$维度。 你还有一个神经网络的成本函数，假设你在做二分类任务，那么你的成本函数等于： Cost function:公式： $J(W^{[1]},b^{[1]},W^{[2]},b^{[2]}) = {\frac{1}{m} }\sum_{i=1}^mL(\hat{y}, y)$ loss function和之前做logistic回归完全一样。 训练参数需要做梯度下降，在训练神经网络的时候，随机初始化参数很重要，而不是初始化成全零。当你参数初始化成某些值后，每次梯度下降都会循环计算以下预测值： $\hat{y}^{(i)},(i=1,2,…,m)$ 公式3.28： $dW^{[1]} = \frac{dJ}{dW^{[1]} },db^{[1]} = \frac{dJ}{db^{[1]} }$ 公式3.29： ${d}W^{[2]} = \frac{ {dJ} }{dW^{[2]} },{d}b^{[2]} = \frac{dJ}{db^{[2]} }$ 其中 公式3.30： $W^{[1]}\implies{W^{[1]} - adW^{[1]} },b^{[1]}\implies{b^{[1]} -adb^{[1]} }$ 公式3.31： $W^{[2]}\implies{W^{[2]} - \alpha{\rm d}W^{[2]} },b^{[2]}\implies{b^{[2]} - \alpha{\rm d}b^{[2]} }$ 正向传播方程如下（之前讲过）：forward propagation：(1) $z^{[1]} = W^{[1]}x + b^{[1]}$ (2) $a^{[1]} = \sigma(z^{[1]})$ (3) $z^{[2]} = W^{[2]}a^{[1]} + b^{[2]}$ (4) $a^{[2]} = g^{[2]}(z^{[z]}) = \sigma(z^{[2]})$ 反向传播方程如下: back propagation：公式3.32： $ dz^{[2]} = A^{[2]} - Y , Y = \begin{bmatrix}y^{[1]} & y^{[2]} & \cdots & y^{[m]}\\ \end{bmatrix} $ 公式3.33： $ dW^{[2]} = {\frac{1}{m} }dz^{[2]}A^{[1]T} $ 公式3.34： $ {\rm d}b^{[2]} = {\frac{1}{m} }np.sum({d}z^{[2]},axis=1,keepdims=True)$ 公式3.35：$ dz^{[1]} = \underbrace{W^{[2]T}{\rm d}z^{[2]} }{(n^{[1]},m)}\quad*\underbrace{ {g^{[1]} }^{‘} }{activation ; function ; of ; hidden ; layer}*\quad\underbrace{(z^{[1]})}_{(n^{[1]},m)} $公式3.36： $dW^{[1]} = {\frac{1}{m} }dz^{[1]}x^{T}$ 公式3.37： ${\underbrace{db^{[1]} }_{(n^{[1]},1)} } = {\frac{1}{m} }np.sum(dz^{[1]},axis=1,keepdims=True)$ 上述是反向传播的步骤，注：这些都是针对所有样本进行过向量化，$Y$是$1×m$的矩阵；这里np.sum是python的numpy命令，axis=1表示水平相加求和，keepdims是防止python输出那些古怪的秩数$(n,)$，加上这个确保阵矩阵$db^{[2]}$这个向量输出的维度为$(n,1)$这样标准的形式。 目前为止，我们计算的都和Logistic回归十分相似，但当你开始计算反向传播时，你需要计算，是隐藏层函数的导数，输出在使用sigmoid函数进行二元分类。这里是进行逐个元素乘积，因为$W^{[2]T}dz^{[2]}$和$(z^{[1]})$这两个都为$(n^{[1]},m)$矩阵； 还有一种防止python输出奇怪的秩数，需要显式地调用reshape把np.sum输出结果写成矩阵形式。 以上就是正向传播的4个方程和反向传播的6个方程，这里我是直接给出的，在下个视频中，我会讲如何导出反向传播的这6个式子的。如果你要实现这些算法，你必须正确执行正向和反向传播运算，你必须能计算所有需要的导数，用梯度下降来学习神经网络的参数；你也可以许多成功的深度学习从业者一样直接实现这个算法，不去了解其中的知识。 3.10（选修）直观理解反向传播（Backpropagation intuition）这个视频主要是推导反向传播。 下图是逻辑回归的推导： 回想一下逻辑回归的公式(参考公式3.2、公式3.5、公式3.6、公式3.15)公式3.38：$$\left.\begin{array}{l}{x }\{w }\{b }\end{array}\right}\implies{z={w}^Tx+b}\implies{\alpha = \sigma(z)}\implies{ {L}\left(a,y \right)}$$所以回想当时我们讨论逻辑回归的时候，我们有这个正向传播步骤，其中我们计算$z$，然后$a$，然后损失函数$L$。 公式3.39：$$\underbrace{\left.\begin{array}{l}{x }\{w }\{b }\end{array}\right}}{dw={dz}\cdot x, db =dz}\impliedby\underbrace{ {z={w}^Tx+b} }{dz=da\cdot g^{‘}(z),g(z)=\sigma(z),{\frac{ {dL} }{dz} }={\frac{ {dL} }{da} }\cdot{\frac{da}{dz} },{\frac{d}{ dz} }g(z)=g^{‘}(z)}\impliedby\underbrace{ {a = \sigma(z)}\impliedby{L(a,y)} }_{da={\frac{ {d} }{da} }{L}\left(a,y \right)=(-y\log{\alpha} - (1 - y)\log(1 - a))^{‘}={-\frac{y}{a} } + {\frac{1 - y}{1 - a}{} } }$$ 神经网络的计算中，与逻辑回归十分类似，但中间会有多层的计算。下图是一个双层神经网络，有一个输入层，一个隐藏层和一个输出层。 前向传播： 计算$z^{[1]}$，$a^{[1]}$，再计算$z^{[2]}$，$a^{[2]}$，最后得到loss function。 反向传播： 向后推算出$da^{[2]}$，然后推算出$dz^{[2]}$，接着推算出$da^{[1]}$，然后推算出$dz^{[1]}$。我们不需要对$x$求导，因为$x$是固定的，我们也不是想优化$x$。向后推算出$da^{[2]}$，然后推算出$dz^{[2]}$的步骤可以合为一步：公式3.40： $dz^{[2]}=a^{[2]}-y\;，\;dW^{[2]}=dz^{[2]}{a^{[1]} }^{T}$ (注意：逻辑回归中；为什么$a^{[1]T}$多了个转置：$dw$中的$W$(视频里是$W^{[2]}_i$)是一个列向量，而$W^{[2]}$是个行向量，故需要加个转置);公式3.41： $db^{[2]}=dz^{[2]}$ 公式3.42：$dz^{[1]} = W^{[2]T}dz^{[2]}* g[1]^{‘}(z^{[1]})$注意：这里的矩阵：$W^{[2]}$的维度是：$(n^{[2]},n^{[1]})$。 $z^{[2]}$ ， $dz^{[2]}$的维度都是：$(n^{[2]},1)$，如果是二分类，那维度就是$(1,1)$。 $z^{[1]}$，$dz^{[1]}$的维度都是：$(n^{[1]},1)$。 证明过程：见公式3.42，其中$W^{[2]T}dz^{[2]}$维度为：$(n^{[1]},n^{[2]})$、$(n^{[2]},1)$相乘得到$(n^{[1]},1)$，和$z^{[1]}$维度相同， $g[1]^{'}(z^{[1]})$的维度为$(n^{[1]},1)$，这就变成了两个都是$(n^{[1]},1)$向量逐元素乘积。 实现后向传播有个技巧，就是要保证矩阵的维度相互匹配。最后得到$dW^{[1]}$和$db^{[1]}$，公式3.43： $dW^{[1]} =dz^{[1]}x^{T},db^{[1]} = dz^{[1]}$ 可以看出$dW^{[1]}$ 和$dW^{[2]}$ 非常相似，其中$x$扮演了$a^{[0]}$的角色，$x^{T}$ 等同于$a^{[0]T}$。 由： $Z^{[1]} = W^{[1]}x + b^{[1]}\;,\;a^{[1]}=g^{[1]}(Z^{[1]})$ 得到： $Z^{[1]} = W^{[1]}x + b^{[1]}, A^{[1]} = g^{[1]}(Z^{[1]})$ $$Z^{[1]} =\left[\begin{array}{c}\vdots &amp;\vdots &amp; \vdots &amp; \vdots \z^{1} &amp; z^{1} &amp; \vdots &amp; z^{1} \\vdots &amp;\vdots &amp; \vdots &amp; \vdots \\end{array}\right]$$注意：大写的$Z^{[1]}$表示$z^{[1](1)},z^{[1](2)},z^{[1](3)}...z^{[1](m)}$的列向量堆叠成的矩阵，以下类同。 下图写了主要的推导过程：公式3.44： $dZ^{[2]}=A^{[2]}-Y\;，\;dW^{[2]}={\frac{1}{m} }dZ^{[2]}{A^{[1]} }^{T}$ 公式3.45： $L = {\frac{1}{m} }\sum_i^n{L(\hat{y},y)}$ 公式3.46： $db^{[2]} = {\frac{1}{m} }np.sum(dZ^{[2]},axis=1,keepdims=True)$ 公式3.47：$\underbrace{dZ^{[1]} }{(n^{[1]}, m)} = \underbrace{W^{[2]T}dZ^{[2]} }{(n^{[1]}, m)}*\underbrace{g[1]^{‘}(Z^{[1]})}_{(n^{[1]}, m)}$公式3.48： $dW^{[1]} = {\frac{1}{m} }dZ^{[1]}x^{T}$ 公式3.49： $db^{[1]} = {\frac{1}{m} }np.sum(dZ^{[1]},axis=1,keepdims=True) $ 吴恩达老师认为反向传播的推导是机器学习领域最难的数学推导之一，矩阵的导数要用链式法则来求，如果这章内容掌握不了也没大的关系，只要有这种直觉就可以了。还有一点，就是初始化你的神经网络的权重，不要都是0，而是随机初始化，下一章将详细介绍原因。 3.11 随机初始化（Random+Initialization）当你训练神经网络时，权重随机初始化是很重要的。对于逻辑回归，把权重初始化为0当然也是可以的。但是对于一个神经网络，如果你把权重或者参数都初始化为0，那么梯度下降将不会起作用。 让我们看看这是为什么。有两个输入特征，$n^{[0]} = 2$，2个隐藏层单元$n^{[1]}$就等于2。因此与一个隐藏层相关的矩阵，或者说$W^{[1]}$是2*2的矩阵，假设把它初始化为0的2*2矩阵，$b^{[1]}$也等于 $[0\;0]^T$，把偏置项$b$初始化为0是合理的，但是把$w$初始化为0就有问题了。那这个问题如果按照这样初始化的话，你总是会发现$a_{1}^{[1]}$ 和 $a_{2}^{[1]}$相等，这个激活单元和这个激活单元就会一样。因为两个隐含单元计算同样的函数，当你做反向传播计算时，这会导致$\text{dz}_{1}^{[1]}$ 和 $\text{dz}_{2}^{[1]}$也会一样，对称这些隐含单元会初始化得一样，这样输出的权值也会一模一样，由此$W^{[2]}$等于$[0\;0]$； 图3.11.1但是如果你这样初始化这个神经网络，那么这两个隐含单元就会完全一样，因此他们完全对称，也就意味着计算同样的函数，并且肯定的是最终经过每次训练的迭代，这两个隐含单元仍然是同一个函数，令人困惑。$dW$会是一个这样的矩阵，每一行有同样的值因此我们做权重更新把权重$W^{[1]}\implies{W^{[1]}-adW}$每次迭代后的$W^{[1]}$，第一行等于第二行。 由此可以推导，如果你把权重都初始化为0，那么由于隐含单元开始计算同一个函数，所有的隐含单元就会对输出单元有同样的影响。一次迭代后同样的表达式结果仍然是相同的，即隐含单元仍是对称的。通过推导，两次、三次、无论多少次迭代，不管你训练网络多长时间，隐含单元仍然计算的是同样的函数。因此这种情况下超过1个隐含单元也没什么意义，因为他们计算同样的东西。当然更大的网络，比如你有3个特征，还有相当多的隐含单元。 如果你要初始化成0，由于所有的隐含单元都是对称的，无论你运行梯度下降多久，他们一直计算同样的函数。这没有任何帮助，因为你想要两个不同的隐含单元计算不同的函数，这个问题的解决方法就是随机初始化参数。你应该这么做：把$W^{[1]}$设为np.random.randn(2,2)(生成高斯分布)，通常再乘上一个小的数，比如0.01，这样把它初始化为很小的随机数。然后$b$没有这个对称的问题（叫做symmetry breaking problem），所以可以把 $b$ 初始化为0，因为只要随机初始化$W$你就有不同的隐含单元计算不同的东西，因此不会有symmetry breaking问题了。相似的，对于$W^{[2]}$你可以随机初始化，$b^{[2]}$可以初始化为0。 $W^{[1]} = np.random.randn(2,2);;0.01;,;b^{[1]} = np.zeros((2,1))$$W^{[2]} = np.random.randn(2,2);;0.01;,;b^{[2]} = 0$ 你也许会疑惑，这个常数从哪里来，为什么是0.01，而不是100或者1000。我们通常倾向于初始化为很小的随机数。因为如果你用tanh或者sigmoid激活函数，或者说只在输出层有一个Sigmoid，如果（数值）波动太大，当你计算激活值时$z^{[1]} = W^{[1]}x + b^{[1]}\;,\;a^{[1]} = \sigma(z^{[1]})=g^{[1]}(z^{[1]})$如果$W$很大，$z$就会很大或者很小，因此这种情况下你很可能停在tanh/sigmoid函数的平坦的地方(见图3.8.2)，这些地方梯度很小也就意味着梯度下降会很慢，因此学习也就很慢。 回顾一下：如果$w$很大，那么你很可能最终停在（甚至在训练刚刚开始的时候）$z$很大的值，这会造成tanh/Sigmoid激活函数饱和在龟速的学习上，如果你没有sigmoid/tanh激活函数在你整个的神经网络里，就不成问题。但如果你做二分类并且你的输出单元是Sigmoid函数，那么你不会想让初始参数太大，因此这就是为什么乘上0.01或者其他一些小数是合理的尝试。对于$w^{[2]}$一样，就是np.random.randn((1,2))，我猜会是乘以0.01。 事实上有时有比0.01更好的常数，当你训练一个只有一层隐藏层的网络时（这是相对浅的神经网络，没有太多的隐藏层），设为0.01可能也可以。但当你训练一个非常非常深的神经网络，你可能要试试0.01以外的常数。下一节课我们会讨论怎么并且何时去选择一个不同于0.01的常数，但是无论如何它通常都会是个相对小的数。 好了，这就是这周的视频。你现在已经知道如何建立一个一层的神经网络了，初始化参数，用前向传播预测，还有计算导数，结合反向传播用在梯度下降中。 深层神经网络(Deep Neural Networks)4.1 深层神经网络（Deep L-layer neural network）目前为止我们学习了只有一个单独隐藏层的神经网络的正向传播和反向传播，还有逻辑回归，并且你还学到了向量化，这在随机初始化权重时是很重要。 本周所要做的是把这些理念集合起来，就可以执行你自己的深度神经网络。 复习下前三周的课的内容： 1.逻辑回归，结构如下图左边。一个隐藏层的神经网络，结构下图右边： 注意，神经网络的层数是这么定义的：从左到右，由0开始定义，比如上边右图，${x}_{1}$、${x}_{2}$、${x}_{3}$,这层是第0层，这层左边的隐藏层是第1层，由此类推。如下图左边是两个隐藏层的神经网络，右边是5个隐藏层的神经网络。 严格上来说逻辑回归也是一个一层的神经网络，而上边右图一个深得多的模型，浅与深仅仅是指一种程度。记住以下要点： 有一个隐藏层的神经网络，就是一个两层神经网络。记住当我们算神经网络的层数时，我们不算输入层，我们只算隐藏层和输出层。 但是在过去的几年中，DLI（深度学习学院 deep learning institute）已经意识到有一些函数，只有非常深的神经网络能学会，而更浅的模型则办不到。尽管对于任何给定的问题很难去提前预测到底需要多深的神经网络，所以先去尝试逻辑回归，尝试一层然后两层隐含层，然后把隐含层的数量看做是另一个可以自由选择大小的超参数，然后再保留交叉验证数据上评估，或者用你的开发集来评估。 我们再看下深度学习的符号定义： 上图是一个四层的神经网络，有三个隐藏层。我们可以看到，第一层（即左边数过去第二层，因为输入层是第0层）有5个神经元数目，第二层5个，第三层3个。 我们用L表示层数，上图：$L=4$，输入层的索引为“0”，第一个隐藏层${n}^{[1]}=5$,表示有5个隐藏神经元，同理${n}^{[2]}=5$，${n}^{[3]}=3$，${ {n}^{[4]} }$=${ {n}^{[L]} }=1$（输出单元为1）。而输入层，${n}^{[0]}={n}_{x}=3$。 在不同层所拥有的神经元的数目，对于每层l都用${a}^{[l]}$来记作l层激活后结果，我们会在后面看到在正向传播时，最终能你会计算出${ {a}^{[l]} }$。 通过用激活函数 $g$ 计算${z}^{[l]}$，激活函数也被索引为层数$l$，然后我们用${w}^{[l]}$来记作在l层计算${z}^{[l]}$值的权重。类似的，${ {z}^{[l]} }$里的方程${b}^{[l]}$也一样。 最后总结下符号约定： 输入的特征记作$x$，但是$x$同样也是0层的激活函数，所以$x={a}^{[0]}$。 最后一层的激活函数，所以${a}^{[L]}$是等于这个神经网络所预测的输出结果。 4.2 前向传播和反向传播（Forward and backward propagation）之前我们学习了构成深度神经网络的基本模块，比如每一层都有前向传播步骤以及一个相反的反向传播步骤，这次视频我们讲讲如何实现这些步骤。 先讲前向传播，输入${a}^{[l-1]}$，输出是${a}^{[l]}$，缓存为${z}^{[l]}$；从实现的角度来说我们可以缓存下${w}^{[l]}$和${b}^{[l]}$，这样更容易在不同的环节中调用函数。 所以前向传播的步骤可以写成： ${z}^{[l]}={W}^{[l]}\cdot{a}^{[l-1]}+{b}^{[l]}$ ​ ${ {a}^{[l]} }={ {g}^{[l]} }\left( { {z}^{[l]} }\right)$ 向量化实现过程可以写成： ${z}^{[l]}={W}^{[l]}\cdot {A}^{[l-1]}+{b}^{[l]}$ ​ ${A}^{[l]}={g}^{[l]}({Z}^{[l]})$ 前向传播需要喂入${A}^{[0]}$也就是$X$，来初始化；初始化的是第一层的输入值。${a}^{[0]}$对应于一个训练样本的输入特征，而${ {A}^{[0]} }$对应于一整个训练样本的输入特征，所以这就是这条链的第一个前向函数的输入，重复这个步骤就可以从左到右计算前向传播。 下面讲反向传播的步骤： 输入为${ {da}^{[l]} }$，输出为${ {da}^{[l-1]} }$，${ {dw}^{[l]} }$, ${ {db}^{[l]} }$ 所以反向传播的步骤可以写成： （1）$d{ {z}^{[l]} }=d{ {a}^{[l]} }*{ {g}^{[l]} }’( { {z}^{[l]} })$ （2）$d{ {w}^{[l]} }=d{ {z}^{[l]} }\cdot{ {a}^{[l-1]} }~$ （3）$d{ {b}^{[l]} }=d{ {z}^{[l]} }~~$ （4）$d{ {a}^{[l-1]} }={ {w}^{\left[ l \right]T} }\cdot { {dz}^{[l]} }$ （5）$d{ {z}^{[l]} }={ {w}^{[l+1]T} }d{ {z}^{[l+1]} }\cdot \text{ }{ {g}^{[l]} }'( { {z}^{[l]} })~$ 式子（5）由式子（4）带入式子（1）得到，前四个式子就可实现反向函数。 向量化实现过程可以写成： （6）$d{ {Z}^{[l]} }=d{ {A}^{[l]} }*{ {g}^{\left[ l \right]} }’\left({ {Z}^{[l]} } \right)~~$ （7）$d{ {W}^{[l]} }=\frac{1}{m}\text{}d{ {Z}^{[l]} }\cdot { {A}^{\left[ l-1 \right]T} }$ （8）$d{ {b}^{[l]} }=\frac{1}{m}\text{ }np.sum(d{ {z}^{[l]} },axis=1,keepdims=True)$ （9）$d{ {A}^{[l-1]} }={ {W}^{\left[ l \right]T} }.d{ {Z}^{[l]} }$ 总结一下： 第一层你可能有一个ReLU激活函数，第二层为另一个ReLU激活函数，第三层可能是sigmoid函数（如果你做二分类的话），输出值为，用来计算损失；这样你就可以向后迭代进行反向传播求导来求${ {dw}^{[3]} }$，${ {db}^{[3]} }$ ，${ {dw}^{[2]} }$ ，${ {db}^{[2]} }$ ，${ {dw}^{[1]} }$ ，${ {db}^{[1]} }$。在计算的时候，缓存会把${ {z}^{[1]} }$ ${ {z}^{[2]} }$${ {z}^{[3]} }$传递过来，然后回传${ {da}^{[2]} }$，${ {da}^{[1]} }$ ，可以用来计算${ {da}^{[0]} }$，但我们不会使用它，这里讲述了一个三层网络的前向和反向传播，还有一个细节没讲就是前向递归——用输入数据来初始化，那么反向递归（使用Logistic回归做二分类）——对${ {A}^{[l]} }$ 求导。 忠告：补补微积分和线性代数，多推导，多实践。 4.3 深层网络中的前向传播（Forward propagation in a Deep Network）跟往常一样，我们先来看对其中一个训练样本$x$如何应用前向传播，之后讨论向量化的版本。 第一层需要计算${ {z}^{[1]} }={ {w}^{[1]} }x+{ {b}^{[1]} }$，${ {a}^{[1]} }={ {g}^{[1]} } {({z}^{[1]})}$（$x$可以看做${ {a}^{[0]} }$） 第二层需要计算${ {z}^{[2]} }={ {w}^{[2]} }{ {a}^{[1]} }+{ {b}^{[2]} }$，${ {a}^{[2]} }={ {g}^{[2]} } {({z}^{[2]})}$ 以此类推， 第四层为${ {z}^{[4]} }={ {w}^{[4]} }{ {a}^{[3]} }+{ {b}^{[4]} }$，${ {a}^{[4]} }={ {g}^{[4]} } {({z}^{[4]})}$ 前向传播可以归纳为多次迭代${ {z}^{[l]} }={ {w}^{[l]} }{ {a}^{[l-1]} }+{ {b}^{[l]} }$，${ {a}^{[l]} }={ {g}^{[l]} } {({z}^{[l]})}$。 向量化实现过程可以写成： ${ {Z}^{[l]} }={ {W}^{[l]} }{ {a}^{[l-1]} }+{ {b}^{[l]} }$，${ {A}^{[l]} }={ {g}^{[l]} }{({Z}^{[l]})}$ (${ {A}^{[0]} } = X)$ 这里只能用一个显式for循环，$l$从1到$L$，然后一层接着一层去计算。下一节讲的是避免代码产生BUG，我所做的其中一件非常重要的工作。 4.4 核对矩阵的维数（Getting your matrix dimensions right）当实现深度神经网络的时候，其中一个我常用的检查代码是否有错的方法就是拿出一张纸过一遍算法中矩阵的维数。 $w$的维度是（下一层的维数，前一层的维数），即${ {w}^{[l]} }$: (${ {n}^{[l]} }$,${ {n}^{[l-1]} }$)； $b$的维度是（下一层的维数，1），即: ${ {b}^{[l]} }$ : (${ {n}^{[l]} },1)$； ${ {z}^{[l]} }$,${ {a}^{[l]} }$: $({ {n}^{[l]} },1)$; ${ {dw}^{[l]} }$和${ {w}^{[l]} }$维度相同，${ {db}^{[l]} }$和${ {b}^{[l]} }$维度相同，且$w$和$b$向量化维度不变，但$z$,$a$以及$x$的维度会向量化后发生变化。 向量化后： ${Z}^{[l]}$可以看成由每一个单独的${Z}^{[l]}$叠加而得到，${Z}^{[l]}=({ {z}^{[l][1]} }，{ {z}^{[l][2]} }，{ {z}^{[l][3]} }，…，{ {z}^{[l][m]} })$， $m$为训练集大小，所以${Z}^{[l]}$的维度不再是$({ {n}^{[l]} },1)$，而是$({ {n}^{[l]} },m)$。 ${A}^{[l]}$：$({n}^{[l]},m)$，${A}^{[0]} = X =({n}^{[l]},m)$ 在你做深度神经网络的反向传播时，一定要确认所有的矩阵维数是前后一致的，可以大大提高代码通过率。下一节我们讲为什么深层的网络在很多问题上比浅层的好。 4.5 为什么使用深层表示？（Why deep representations?）我们都知道深度神经网络能解决好多问题，其实并不需要很大的神经网络，但是得有深度，得有比较多的隐藏层，这是为什么呢？我们一起来看几个例子来帮助理解，为什么深度神经网络会很好用。 首先，深度网络在计算什么？ 首先，深度网络究竟在计算什么？如果你在建一个人脸识别或是人脸检测系统，深度神经网络所做的事就是，当你输入一张脸部的照片，然后你可以把深度神经网络的第一层，当成一个特征探测器或者边缘探测器。在这个例子里，我会建一个大概有20个隐藏单元的深度神经网络，是怎么针对这张图计算的。隐藏单元就是这些图里这些小方块（第一张大图），举个例子，这个小方块（第一行第一列）就是一个隐藏单元，它会去找这张照片里“|”边缘的方向。那么这个隐藏单元（第四行第四列），可能是在找（“—”）水平向的边缘在哪里。之后的课程里，我们会讲专门做这种识别的卷积神经网络，到时候会细讲，为什么小单元是这么表示的。你可以先把神经网络的第一层当作看图，然后去找这张照片的各个边缘。我们可以把照片里组成边缘的像素们放在一起看，然后它可以把被探测到的边缘组合成面部的不同部分（第二张大图）。比如说，可能有一个神经元会去找眼睛的部分，另外还有别的在找鼻子的部分，然后把这许多的边缘结合在一起，就可以开始检测人脸的不同部分。最后再把这些部分放在一起，比如鼻子眼睛下巴，就可以识别或是探测不同的人脸（第三张大图）。 你可以直觉上把这种神经网络的前几层当作探测简单的函数，比如边缘，之后把它们跟后几层结合在一起，那么总体上就能学习更多复杂的函数。这些图的意义，我们在学习卷积神经网络的时候再深入了解。还有一个技术性的细节需要理解的是，边缘探测器其实相对来说都是针对照片中非常小块的面积。就像这块（第一行第一列），都是很小的区域。面部探测器就会针对于大一些的区域，但是主要的概念是，一般你会从比较小的细节入手，比如边缘，然后再一步步到更大更复杂的区域，比如一只眼睛或是一个鼻子，再把眼睛鼻子装一块组成更复杂的部分。 这种从简单到复杂的金字塔状表示方法或者组成方法，也可以应用在图像或者人脸识别以外的其他数据上。比如当你想要建一个语音识别系统的时候，需要解决的就是如何可视化语音，比如你输入一个音频片段，那么神经网络的第一层可能就会去先开始试着探测比较低层次的音频波形的一些特征，比如音调是变高了还是低了，分辨白噪音，咝咝咝的声音，或者音调，可以选择这些相对程度比较低的波形特征，然后把这些波形组合在一起就能去探测声音的基本单元。在语言学中有个概念叫做音位，比如说单词ca，c的发音，“嗑”就是一个音位，a的发音“啊”是个音位，t的发音“特”也是个音位，有了基本的声音单元以后，组合起来，你就能识别音频当中的单词，单词再组合起来就能识别词组，再到完整的句子。 所以深度神经网络的这许多隐藏层中，较早的前几层能学习一些低层次的简单特征，等到后几层，就能把简单的特征结合起来，去探测更加复杂的东西。比如你录在音频里的单词、词组或是句子，然后就能运行语音识别了。同时我们所计算的之前的几层，也就是相对简单的输入函数，比如图像单元的边缘什么的。到网络中的深层时，你实际上就能做很多复杂的事，比如探测面部或是探测单词、短语或是句子。 有些人喜欢把深度神经网络和人类大脑做类比，这些神经科学家觉得人的大脑也是先探测简单的东西，比如你眼睛看得到的边缘，然后组合起来才能探测复杂的物体，比如脸。这种深度学习和人类大脑的比较，有时候比较危险。但是不可否认的是，我们对大脑运作机制的认识很有价值，有可能大脑就是先从简单的东西，比如边缘着手，再组合成一个完整的复杂物体，这类简单到复杂的过程，同样也是其他一些深度学习的灵感来源，之后的视频我们也会继续聊聊人类或是生物学理解的大脑。 Small：隐藏单元的数量相对较少 Deep：隐藏层数目比较多 深层的网络隐藏单元数量相对较少，隐藏层数目较多，如果浅层的网络想要达到同样的计算结果则需要指数级增长的单元数量才能达到。 另外一个，关于神经网络为何有效的理论，来源于电路理论，它和你能够用电路元件计算哪些函数有着分不开的联系。根据不同的基本逻辑门，譬如与门、或门、非门。在非正式的情况下，这些函数都可以用相对较小，但很深的神经网络来计算，小在这里的意思是隐藏单元的数量相对比较小，但是如果你用浅一些的神经网络计算同样的函数，也就是说在我们不能用很多隐藏层时，你会需要成指数增长的单元数量才能达到同样的计算结果。 我再来举个例子，用没那么正式的语言介绍这个概念。假设你想要对输入特征计算异或或是奇偶性，你可以算$x_{1}XOR x_{2} XOR x_{3} XOR ……x_{n}$，假设你有$n$或者$n_{x}$个特征，如果你画一个异或的树图，先要计算$x_{1}$，$x_{2}$的异或，然后是$x_{3}$和$x_{4}$。技术上来说如果你只用或门，还有非门的话，你可能会需要几层才能计算异或函数，但是用相对小的电路，你应该就可以计算异或了。然后你可以继续建这样的一个异或树图（上图左），那么你最后会得到这样的电路来输出结果$y$，$\hat{y}=y$，也就是输入特征的异或，或是奇偶性，要计算异或关系。这种树图对应网络的深度应该是$O(log(n))$，那么节点的数量和电路部件，或是门的数量并不会很大，你也不需要太多门去计算异或。 但是如果你不能使用多隐层的神经网络的话，在这个例子中隐层数为$O(log(n))$，比如你被迫只能用单隐藏层来计算的话，这里全部都指向从这些隐藏单元到后面这里，再输出$y$，那么要计算奇偶性，或者异或关系函数就需要这一隐层（上图右方框部分）的单元数呈指数增长才行，因为本质上来说你需要列举耗尽$2^{n}$种可能的配置，或是$2^{n}$种输入比特的配置。异或运算的最终结果是1或0，那么你最终就会需要一个隐藏层，其中单元数目随输入比特指数上升。精确的说应该是$2^{n-1}$个隐藏单元数，也就是$O(2^{n})$。 我希望这能让你有点概念，意识到有很多数学函数用深度网络计算比浅网络要容易得多，我个人倒是认为这种电路理论，对训练直觉思维没那么有用，但这个结果人们还是经常提到的，用来解释为什么需要更深层的网络。 除了这些原因，说实话，我认为“深度学习”这个名字挺唬人的，这些概念以前都统称为有很多隐藏层的神经网络，但是深度学习听起来多高大上，太深奥了，对么？这个词流传出去以后，这是神经网络的重新包装或是多隐藏层神经网络的重新包装，激发了大众的想象力。抛开这些公关概念重新包装不谈，深度网络确实效果不错，有时候人们还是会按照字面意思钻牛角尖，非要用很多隐层。但是当我开始解决一个新问题时，我通常会从logistic回归开始，再试试一到两个隐层，把隐藏层数量当作参数、超参数一样去调试，这样去找比较合适的深度。但是近几年以来，有一些人会趋向于使用非常非常深邃的神经网络，比如好几打的层数，某些问题中只有这种网络才是最佳模型。 这就是我想讲的，为什么深度学习效果拔群的直觉解释，现在我们来看看除了正向传播以外，反向传播该怎么具体实现。 4.6 搭建神经网络块（Building blocks of deep neural networks）这周的前几个视频和之前几周的视频里，你已经看到过正向反向传播的基础组成部分了，它们也是深度神经网络的重要组成部分，现在我们来用它们建一个深度神经网络。 这是一个层数较少的神经网络，我们选择其中一层（方框部分），从这一层的计算着手。在第$l$层你有参数$W^{[l]}$和$b^{[l]}$，正向传播里有输入的激活函数，输入是前一层$a^{[l-1]}$，输出是$a^{[l]}$，我们之前讲过$z^{[l]} =W^{[l]}a^{[l-1]} +b^{[l]}$,$a^{[l]} =g^{[l]}(z^{[l]})$，那么这就是你如何从输入$a^{[l-1]}$走到输出的$a^{[l]}$。之后你就可以把$z^{[l]}$的值缓存起来，我在这里也会把这包括在缓存中，因为缓存的$z^{[i]}$对以后的正向反向传播的步骤非常有用。 然后是反向步骤或者说反向传播步骤，同样也是第$l$层的计算，你会需要实现一个函数输入为$da^{[l]}$，输出$da^{[l-1]}$的函数。一个小细节需要注意，输入在这里其实是$da^{[l]}$以及所缓存的$z^{[l]}$值，之前计算好的$z^{[l]}$值，除了输出$da^{[l-1]}$的值以外，也需要输出你需要的梯度$dW^{[l]}$和$db^{[l]}$，这是为了实现梯度下降学习。 这就是基本的正向步骤的结构，我把它成为称为正向函数，类似的在反向步骤中会称为反向函数。总结起来就是，在l层，你会有正向函数，输入$a^{[l-1]}$并且输出$a^{[l]}$，为了计算结果你需要用$W^{[l]}$和$b^{[l]}$，以及输出到缓存的$z^{[l]}$。然后用作反向传播的反向函数，是另一个函数，输入$da^{[l]}$，输出$da^{[l-1]}$，你就会得到对激活函数的导数，也就是希望的导数值$da^{[l]}$。$a^{[l-1]}$是会变的，前一层算出的激活函数导数。在这个方块（第二个）里你需要$W^{[l]}$和$b^{[l]}$，最后你要算的是$dz^{[l]}$。然后这个方块（第三个）中，这个反向函数可以计算输出$dW^{[l]}$和$db^{[l]}$。我会用红色箭头标注标注反向步骤，如果你们喜欢，我可以把这些箭头涂成红色。 然后如果实现了这两个函数（正向和反向），然后神经网络的计算过程会是这样的： 把输入特征$a^{[0]}$，放入第一层并计算第一层的激活函数，用$a^{[1]}$表示，你需要$W^{[1]}$和$b^{[1]}$来计算，之后也缓存$z^{[l]}$值。之后喂到第二层，第二层里，需要用到$W^{[2]}$和$b^{[2]}$，你会需要计算第二层的激活函数$a^{[2]}$。后面几层以此类推，直到最后你算出了$a^{[L]}$，第$L$层的最终输出值$\hat y$。在这些过程里我们缓存了所有的$z$值，这就是正向传播的步骤。 对反向传播的步骤而言，我们需要算一系列的反向迭代，就是这样反向计算梯度，你需要把$da^{[L]}$的值放在这里，然后这个方块会给我们${da}^{[L-1]}$的值，以此类推，直到我们得到${da}^{[2]}$和${da}^{[1]}$，你还可以计算多一个输出值，就是${da}^{[0]}$，但这其实是你的输入特征的导数，并不重要，起码对于训练监督学习的权重不算重要，你可以止步于此。反向传播步骤中也会输出$dW^{[l]}$和$db^{[l]}$，这会输出$dW^{[3]}$和$db^{[3]}$等等。目前为止你算好了所有需要的导数，稍微填一下这个流程图。 神经网络的一步训练包含了，从$a^{[0]}$开始，也就是 $x$ 然后经过一系列正向传播计算得到$\hat y$，之后再用输出值计算这个（第二行最后方块），再实现反向传播。现在你就有所有的导数项了，$W$也会在每一层被更新为$W=W-αdW$，$b$也一样，$b=b-αdb$，反向传播就都计算完毕，我们有所有的导数值，那么这是神经网络一个梯度下降循环。 继续下去之前再补充一个细节，概念上会非常有帮助，那就是把反向函数计算出来的$z$值缓存下来。当你做编程练习的时候去实现它时，你会发现缓存可能很方便，可以迅速得到$W^{[l]}$和$b^{[l]}$的值，非常方便的一个方法，在编程练习中你缓存了$z$，还有$W$和$b$对吧？从实现角度上看，我认为是一个很方便的方法，可以将参数复制到你在计算反向传播时所需要的地方。好，这就是实现过程的细节，做编程练习时会用到。 现在你们见过实现深度神经网络的基本元件，在每一层中有一个正向传播步骤，以及对应的反向传播步骤，以及把信息从一步传递到另一步的缓存。下一个视频我们会讲解这些元件具体实现过程，我们来看下一个视频吧。 4.7 参数VS超参数（Parameters vs Hyperparameters）想要你的深度神经网络起很好的效果，你还需要规划好你的参数以及超参数。 什么是超参数？ 比如算法中的learning rate $a$（学习率）、iterations(梯度下降法循环的数量)、$L$（隐藏层数目）、${ {n}^{[l]} }$（隐藏层单元数目）、choice of activation function（激活函数的选择）都需要你来设置，这些数字实际上控制了最后的参数$W$和$b$的值，所以它们被称作超参数。 实际上深度学习有很多不同的超参数，之后我们也会介绍一些其他的超参数，如momentum、mini batch size、regularization parameters等等。 如何寻找超参数的最优值？ 走Idea—Code—Experiment—Idea这个循环，尝试各种不同的参数，实现模型并观察是否成功，然后再迭代。 今天的深度学习应用领域，还是很经验性的过程，通常你有个想法，比如你可能大致知道一个最好的学习率值，可能说$a=0.01$最好，我会想先试试看，然后你可以实际试一下，训练一下看看效果如何。然后基于尝试的结果你会发现，你觉得学习率设定再提高到0.05会比较好。如果你不确定什么值是最好的，你大可以先试试一个学习率$a$，再看看损失函数J的值有没有下降。然后你可以试一试大一些的值，然后发现损失函数的值增加并发散了。然后可能试试其他数，看结果是否下降的很快或者收敛到在更高的位置。你可能尝试不同的$a$并观察损失函数$J$这么变了，试试一组值，然后可能损失函数变成这样，这个$a$值会加快学习过程，并且收敛在更低的损失函数值上（箭头标识），我就用这个$a$值了。 在前面几页中，还有很多不同的超参数。然而，当你开始开发新应用时，预先很难确切知道，究竟超参数的最优值应该是什么。所以通常，你必须尝试很多不同的值，并走这个循环，试试各种参数。试试看5个隐藏层，这个数目的隐藏单元，实现模型并观察是否成功，然后再迭代。这页的标题是，应用深度学习领域，一个很大程度基于经验的过程，凭经验的过程通俗来说，就是试直到你找到合适的数值。 另一个近来深度学习的影响是它用于解决很多问题，从计算机视觉到语音识别，到自然语言处理，到很多结构化的数据应用，比如网络广告或是网页搜索或产品推荐等等。我所看到过的就有很多其中一个领域的研究员，这些领域中的一个，尝试了不同的设置，有时候这种设置超参数的直觉可以推广，但有时又不会。所以我经常建议人们，特别是刚开始应用于新问题的人们，去试一定范围的值看看结果如何。然后下一门课程，我们会用更系统的方法，用系统性的尝试各种超参数取值。然后其次，甚至是你已经用了很久的模型，可能你在做网络广告应用，在你开发途中，很有可能学习率的最优数值或是其他超参数的最优值是会变的，所以即使你每天都在用当前最优的参数调试你的系统，你还是会发现，最优值过一年就会变化，因为电脑的基础设施，CPU或是GPU可能会变化很大。所以有一条经验规律可能每几个月就会变。如果你所解决的问题需要很多年时间，只要经常试试不同的超参数，勤于检验结果，看看有没有更好的超参数数值，相信你慢慢会得到设定超参数的直觉，知道你的问题最好用什么数值。 这可能的确是深度学习比较让人不满的一部分，也就是你必须尝试很多次不同可能性。但参数设定这个领域，深度学习研究还在进步中，所以可能过段时间就会有更好的方法决定超参数的值，也很有可能由于CPU、GPU、网络和数据都在变化，这样的指南可能只会在一段时间内起作用，只要你不断尝试，并且尝试保留交叉检验或类似的检验方法，然后挑一个对你的问题效果比较好的数值。 近来受深度学习影响，很多领域发生了变化，从计算机视觉到语音识别到自然语言处理到很多结构化的数据应用，比如网络广告、网页搜索、产品推荐等等；有些同一领域设置超参数的直觉可以推广，但有时又不可以，特别是那些刚开始研究新问题的人们应该去尝试一定范围内的结果如何，甚至那些用了很久的模型得学习率或是其他超参数的最优值也有可能会改变。 在下个课程我们会用系统性的方法去尝试各种超参数的取值。有一条经验规律：经常试试不同的超参数，勤于检查结果，看看有没有更好的超参数取值，你将会得到设定超参数的直觉。 4.8 深度学习和大脑的关联性（What does this have to do with the brain?）深度学习和大脑有什么关联性吗？ 关联不大。 那么人们为什么会说深度学习和大脑相关呢？ 当你在实现一个神经网络的时候，那些公式是你在做的东西，你会做前向传播、反向传播、梯度下降法，其实很难表述这些公式具体做了什么，深度学习像大脑这样的类比其实是过度简化了我们的大脑具体在做什么，但因为这种形式很简洁，也能让普通人更愿意公开讨论，也方便新闻报道并且吸引大众眼球，但这个类比是非常不准确的。 一个神经网络的逻辑单元可以看成是对一个生物神经元的过度简化，但迄今为止连神经科学家都很难解释究竟一个神经元能做什么，它可能是极其复杂的；它的一些功能可能真的类似logistic回归的运算，但单个神经元到底在做什么目前还没有人能够真正可以解释。 深度学习的确是个很好的工具来学习各种很灵活很复杂的函数，学习到从$x$到$y$的映射，在监督学习中学到输入到输出的映射。 但这个类比还是很粗略的，这是一个logistic回归单元的sigmoid激活函数，这里是一个大脑中的神经元，图中这个生物神经元，也是你大脑中的一个细胞，它能接受来自其他神经元的电信号，比如$x_1,x_2,x_3$，或可能来自于其他神经元$a_1,a_2,a_3$ 。其中有一个简单的临界计算值，如果这个神经元突然激发了，它会让电脉冲沿着这条长长的轴突，或者说一条导线传到另一个神经元。 所以这是一个过度简化的对比，把一个神经网络的逻辑单元和右边的生物神经元对比。至今为止其实连神经科学家们都很难解释，究竟一个神经元能做什么。一个小小的神经元其实却是极其复杂的，以至于我们无法在神经科学的角度描述清楚，它的一些功能，可能真的是类似logistic回归的运算，但单个神经元到底在做什么，目前还没有人能够真正解释，大脑中的神经元是怎么学习的，至今这仍是一个谜之过程。到底大脑是用类似于后向传播或是梯度下降的算法，或者人类大脑的学习过程用的是完全不同的原理。 所以虽然深度学习的确是个很好的工具，能学习到各种很灵活很复杂的函数来学到从x到y的映射。在监督学习中，学到输入到输出的映射，但这种和人类大脑的类比，在这个领域的早期也许值得一提。但现在这种类比已经逐渐过时了，我自己也在尽量少用这样的说法。 这就是神经网络和大脑的关系，我相信在计算机视觉，或其他的学科都曾受人类大脑启发，还有其他深度学习的领域也曾受人类大脑启发。但是个人来讲我用这个人类大脑类比的次数逐渐减少了。]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习笔记(6-10周)]]></title>
    <url>%2F2019%2F12%2F04%2Fnew_%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(6-10%E5%91%A8)%2F</url>
    <content type="text"><![CDATA[吴恩达机器学习笔记 应用机器学习的建议(Advice for Applying Machine Learning)决定下一步做什么参考视频: 10 - 1 - Deciding What to Try Next (6 min).mkv 到目前为止，我们已经介绍了许多不同的学习算法，如果你一直跟着这些视频的进度学习，你会发现自己已经不知不觉地成为一个了解许多先进机器学习技术的专家了。 然而，在懂机器学习的人当中依然存在着很大的差距，一部分人确实掌握了怎样高效有力地运用这些学习算法。而另一些人他们可能对我马上要讲的东西，就不是那么熟悉了。他们可能没有完全理解怎样运用这些算法。因此总是把时间浪费在毫无意义的尝试上。我想做的是确保你在设计机器学习的系统时，你能够明白怎样选择一条最合适、最正确的道路。因此，在这节视频和之后的几段视频中，我将向你介绍一些实用的建议和指导，帮助你明白怎样进行选择。具体来讲，我将重点关注的问题是假如你在开发一个机器学习系统，或者想试着改进一个机器学习系统的性能，你应如何决定接下来应该选择哪条道路？为了解释这一问题，我想仍然使用预测房价的学习例子，假如你已经完成了正则化线性回归，也就是最小化代价函数$J$的值，假如，在你得到你的学习参数以后，如果你要将你的假设函数放到一组新的房屋样本上进行测试，假如说你发现在预测房价时产生了巨大的误差，现在你的问题是要想改进这个算法，接下来应该怎么办？ 实际上你可以想出很多种方法来改进这个算法的性能，其中一种办法是使用更多的训练样本。具体来讲，也许你能想到通过电话调查或上门调查来获取更多的不同的房屋出售数据。遗憾的是，我看到好多人花费了好多时间想收集更多的训练样本。他们总认为，要是我有两倍甚至十倍数量的训练数据，那就一定会解决问题的是吧？但有时候获得更多的训练数据实际上并没有作用。在接下来的几段视频中，我们将解释原因。 我们也将知道怎样避免把过多的时间浪费在收集更多的训练数据上，这实际上是于事无补的。另一个方法，你也许能想到的是尝试选用更少的特征集。因此如果你有一系列特征比如$x_1,x_2,x_3$等等。也许有很多特征，也许你可以花一点时间从这些特征中仔细挑选一小部分来防止过拟合。或者也许你需要用更多的特征，也许目前的特征集，对你来讲并不是很有帮助。你希望从获取更多特征的角度来收集更多的数据，同样地，你可以把这个问题扩展为一个很大的项目，比如使用电话调查来得到更多的房屋案例，或者再进行土地测量来获得更多有关，这块土地的信息等等，因此这是一个复杂的问题。同样的道理，我们非常希望在花费大量时间完成这些工作之前，我们就能知道其效果如何。我们也可以尝试增加多项式特征的方法，比如$x_1$的平方，$x_2$的平方，$x_1,x_2$的乘积，我们可以花很多时间来考虑这一方法，我们也可以考虑其他方法减小或增大正则化参数$\lambda$的值。我们列出的这个单子，上面的很多方法都可以扩展开来扩展成一个六个月或更长时间的项目。遗憾的是，大多数人用来选择这些方法的标准是凭感觉的，也就是说，大多数人的选择方法是随便从这些方法中选择一种，比如他们会说“噢，我们来多找点数据吧”，然后花上六个月的时间收集了一大堆数据，然后也许另一个人说：“好吧，让我们来从这些房子的数据中多找点特征吧”。我很遗憾不止一次地看到很多人花了至少六个月时间来完成他们随便选择的一种方法，而在六个月或者更长时间后，他们很遗憾地发现自己选择的是一条不归路。幸运的是，有一系列简单的方法能让你事半功倍，排除掉单子上的至少一半的方法，留下那些确实有前途的方法，同时也有一种很简单的方法，只要你使用，就能很轻松地排除掉很多选择，从而为你节省大量不必要花费的时间。最终达到改进机器学习系统性能的目的假设我们需要用一个线性回归模型来预测房价，当我们运用训练好了的模型来预测未知数据的时候发现有较大的误差，我们下一步可以做什么？ 获得更多的训练样本——通常是有效的，但代价较大，下面的方法也可能有效，可考虑先采用下面的几种方法。 尝试减少特征的数量 尝试获得更多的特征 尝试增加多项式特征 尝试减少正则化程度$\lambda$ 尝试增加正则化程度$\lambda$ 我们不应该随机选择上面的某种方法来改进我们的算法，而是运用一些机器学习诊断法来帮助我们知道上面哪些方法对我们的算法是有效的。 在接下来的两段视频中，我首先介绍怎样评估机器学习算法的性能，然后在之后的几段视频中，我将开始讨论这些方法，它们也被称为”机器学习诊断法”。“诊断法”的意思是：这是一种测试法，你通过执行这种测试，能够深入了解某种算法到底是否有用。这通常也能够告诉你，要想改进一种算法的效果，什么样的尝试，才是有意义的。在这一系列的视频中我们将介绍具体的诊断法，但我要提前说明一点的是，这些诊断法的执行和实现，是需要花些时间的，有时候确实需要花很多时间来理解和实现，但这样做的确是把时间用在了刀刃上，因为这些方法让你在开发学习算法时，节省了几个月的时间，因此，在接下来几节课中，我将先来介绍如何评价你的学习算法。在此之后，我将介绍一些诊断法，希望能让你更清楚。在接下来的尝试中，如何选择更有意义的方法。 评估一个假设参考视频: 10 - 2 - Evaluating a Hypothesis (8 min).mkv 在本节视频中我想介绍一下怎样用你学过的算法来评估假设函数。在之后的课程中，我们将以此为基础来讨论如何避免过拟合和欠拟合的问题。 当我们确定学习算法的参数的时候，我们考虑的是选择参量来使训练误差最小化，有人认为得到一个非常小的训练误差一定是一件好事，但我们已经知道，仅仅是因为这个假设具有很小的训练误差，并不能说明它就一定是一个好的假设函数。而且我们也学习了过拟合假设函数的例子，所以这推广到新的训练集上是不适用的。 那么，你该如何判断一个假设函数是过拟合的呢？对于这个简单的例子，我们可以对假设函数$h(x)$进行画图，然后观察图形趋势，但对于特征变量不止一个的这种一般情况，还有像有很多特征变量的问题，想要通过画出假设函数来进行观察，就会变得很难甚至是不可能实现。 因此，我们需要另一种方法来评估我们的假设函数过拟合检验。 为了检验算法是否过拟合，我们将数据分成训练集和测试集，通常用70%的数据作为训练集，用剩下30%的数据作为测试集。很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行“洗牌”，然后再分成训练集和测试集。 测试集评估在通过训练集让我们的模型学习得出其参数后，对测试集运用该模型，我们有两种方式计算误差： 对于线性回归模型，我们利用测试集数据计算代价函数$J$ 对于逻辑回归模型，我们除了可以利用测试数据集来计算代价函数外： $$ J_{test}{(\theta)} = -\frac{1}{ {m}_{test} }\sum_\limits{i=1}^{m_{test} }\log{h_{\theta}(x^{(i)}_{test})}+(1-{y^{(i)}_{test} })\log{h_{\theta}(x^{(i)}_{test})}$$ 误分类的比率，对于每一个测试集样本，计算： 然后对计算结果求平均。 模型选择和交叉验证集参考视频: 10 - 3 - Model Selection and Train_Validation_Test Sets (12 min).mkv 假设我们要在10个不同次数的二项式模型之间进行选择： 显然越高次数的多项式模型越能够适应我们的训练数据集，但是适应训练数据集并不代表着能推广至一般情况，我们应该选择一个更能适应一般情况的模型。我们需要使用交叉验证集来帮助选择模型。 即：使用60%的数据作为训练集，使用 20%的数据作为交叉验证集，使用20%的数据作为测试集 模型选择的方法为： 使用训练集训练出10个模型 用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值） 选取代价函数值最小的模型 用步骤3中选出的模型对测试集计算得出推广误差（代价函数的值） Train/validation/test error Training error: $J_{train}(\theta) = \frac{1}{2m}\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2$ Cross Validation error: $J_{cv}(\theta) = \frac{1}{2m_{cv} }\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)}_{cv})-y^{(i)}_{cv})^2​$ Test error: $J_{test}(\theta)=\frac{1}{2m_{test} }\sum_\limits{i=1}^{m_{test} }(h_{\theta}(x^{(i)}_{cv})-y^{(i)}_{cv})^2$ 诊断偏差和方差参考视频: 10 - 4 - Diagnosing Bias vs. Variance (8 min).mkv 当你运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。那么这两种情况，哪个和偏差有关，哪个和方差有关，或者是不是和两个都有关？搞清楚这一点非常重要，因为能判断出现的情况是这两种情况中的哪一种。其实是一个很有效的指示器，指引着可以改进算法的最有效的方法和途径。在这段视频中，我想更深入地探讨一下有关偏差和方差的问题，希望你能对它们有一个更深入的理解，并且也能弄清楚怎样评价一个学习算法，能够判断一个算法是偏差还是方差有问题，因为这个问题对于弄清如何改进学习算法的效果非常重要，高偏差和高方差的问题基本上来说是欠拟合和过拟合的问题。 我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析： Bias/variance Training error: $J_{train}(\theta) = \frac{1}{2m}\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2$ Cross Validation error: $J_{cv}(\theta) = \frac{1}{2m_{cv} }\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)}_{cv})-y^{(i)}_{cv})^2$ 对于训练集，当 $d$ 较小时，模型拟合程度更低，误差较大；随着 $d$ 的增长，拟合程度提高，误差减小。 对于交叉验证集，当 $d$ 较小时，模型拟合程度低，误差较大；但是随着 $d$ 的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。 如果我们的交叉验证集误差较大，我们如何判断是方差还是偏差呢？根据上面的图表，我们知道: 训练集误差和交叉验证集误差近似时：偏差/欠拟合 交叉验证集误差远大于训练集误差时：方差/过拟合 正则化和偏差/方差参考视频: 10 - 5 - Regularization and Bias_Variance (11 min).mkv 在我们在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。但是我们可能会正则化的程度太高或太小了，即我们在选择λ的值时也需要思考与刚才选择多项式模型次数类似的问题。 我们选择一系列的想要测试的 λ 值，通常是 0-10之间的呈现2倍关系的值（如：$0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10$共12个）。 我们同样把数据分为训练集、交叉验证集和测试集。 选择$\lambda$的方法为： 使用训练集训练出12个不同程度正则化的模型 用12个模型分别对交叉验证集计算的出交叉验证误差 选择得出交叉验证误差最小的模型 运用步骤3中选出模型对测试集计算得出推广误差，我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上： • 当 λ 较小时，训练集误差较小（过拟合）而交叉验证集误差较大 • 随着 λ的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加 学习曲线参考视频: 10 - 6 - Learning Curves (12 min).mkv 学习曲线就是一种很好的工具，我经常使用学习曲线来判断某一个学习算法是否处于偏差、方差问题。学习曲线是学习算法的一个很好的合理检验（sanity check）。学习曲线是将训练集误差和交叉验证集误差作为训练集样本数量（$m$）的函数绘制的图表。 即，如果我们有100行数据，我们从1行数据开始，逐渐学习更多行的数据。思想是：当训练较少行数据的时候，训练的模型将能够非常完美地适应较少的训练数据，但是训练出来的模型却不能很好地适应交叉验证集数据或测试集数据。 如何利用学习曲线识别高偏差/欠拟合：作为例子，我们尝试用一条直线来适应下面的数据，可以看出，无论训练集有多么大误差都不会有太大改观： 也就是说在高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助。 如何利用学习曲线识别高方差/过拟合：假设我们使用一个非常高次的多项式模型，并且正则化非常小，可以看出，当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果。 也就是说在高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果。 决定下一步做什么参考视频: 10 - 7 - Deciding What to Do Next Revisited (7 min).mkv 我们已经介绍了怎样评价一个学习算法，我们讨论了模型选择问题，偏差和方差的问题。那么这些诊断法则怎样帮助我们判断，哪些方法可能有助于改进学习算法的效果，而哪些可能是徒劳的呢？ 让我们再次回到最开始的例子，在那里寻找答案，这就是我们之前的例子。回顾 1.1 中提出的六种可选的下一步，让我们来看一看我们在什么情况下应该怎样选择： 获得更多的训练样本——解决高方差 尝试减少特征的数量——解决高方差 尝试获得更多的特征——解决高偏差 尝试增加多项式特征——解决高偏差 尝试减少正则化程度λ——解决高偏差 尝试增加正则化程度λ——解决高方差 神经网络的方差和偏差： 使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。 通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。 对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络， 然后选择交叉验证集代价最小的神经网络。 好的，以上就是我们介绍的偏差和方差问题，以及诊断该问题的学习曲线方法。在改进学习算法的表现时，你可以充分运用以上这些内容来判断哪些途径可能是有帮助的。而哪些方法可能是无意义的。如果你理解了以上几节视频中介绍的内容，并且懂得如何运用。那么你已经可以使用机器学习方法有效的解决实际问题了。你也能像硅谷的大部分机器学习从业者一样，他们每天的工作就是使用这些学习算法来解决众多实际问题。我希望这几节中提到的一些技巧，关于方差、偏差，以及学习曲线为代表的诊断法能够真正帮助你更有效率地应用机器学习，让它们高效地工作。 机器学习系统的设计(Machine Learning System Design)首先要做什么参考视频: 11 - 1 - Prioritizing What to Work On (10 min).mkv 在接下来的视频中，我将谈到机器学习系统的设计。这些视频将谈及在设计复杂的机器学习系统时，你将遇到的主要问题。同时我们会试着给出一些关于如何巧妙构建一个复杂的机器学习系统的建议。下面的课程的的数学性可能不是那么强，但是我认为我们将要讲到的这些东西是非常有用的，可能在构建大型的机器学习系统时，节省大量的时间。 本周以一个垃圾邮件分类器算法为例进行讨论。 为了解决这样一个问题，我们首先要做的决定是如何选择并表达特征向量$x$。我们可以选择一个由100个最常出现在垃圾邮件中的词所构成的列表，根据这些词是否有在邮件中出现，来获得我们的特征向量（出现为1，不出现为0），尺寸为100×1。 为了构建这个分类器算法，我们可以做很多事，例如： 收集更多的数据，让我们有更多的垃圾邮件和非垃圾邮件的样本 基于邮件的路由信息开发一系列复杂的特征 基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理 为探测刻意的拼写错误（把watch 写成w4tch）开发复杂的算法 在上面这些选项中，非常难决定应该在哪一项上花费时间和精力，作出明智的选择，比随着感觉走要更好。当我们使用机器学习时，总是可以“头脑风暴”一下，想出一堆方法来试试。实际上，当你需要通过头脑风暴来想出不同方法来尝试去提高精度的时候，你可能已经超越了很多人了。大部分人并不尝试着列出可能的方法，他们做的只是某天早上醒来，因为某些原因有了一个突发奇想：”让我们来试试用Honey Pot项目收集大量的数据吧。” 我们将在随后的课程中讲误差分析，我会告诉你怎样用一个更加系统性的方法，从一堆不同的方法中，选取合适的那一个。因此，你更有可能选择一个真正的好方法，能让你花上几天几周，甚至是几个月去进行深入的研究。 误差分析参考视频: 11 - 2 - Error Analysis (13 min).mkv 在本次课程中，我们将会讲到误差分析（Error Analysis）的概念。这会帮助你更系统地做出决定。如果你准备研究机器学习的东西，或者构造机器学习应用程序，最好的实践方法不是建立一个非常复杂的系统，拥有多么复杂的变量；而是构建一个简单的算法，这样你可以很快地实现它。 每当我研究机器学习的问题时，我最多只会花一天的时间，就是字面意义上的24小时，来试图很快的把结果搞出来，即便效果不好。坦白的说，就是根本没有用复杂的系统，但是只是很快的得到的结果。即便运行得不完美，但是也把它运行一遍，最后通过交叉验证来检验数据。一旦做完，你可以画出学习曲线，通过画出学习曲线，以及检验误差，来找出你的算法是否有高偏差和高方差的问题，或者别的问题。在这样分析之后，再来决定用更多的数据训练，或者加入更多的特征变量是否有用。这么做的原因是：这在你刚接触机器学习问题时是一个很好的方法，你并不能提前知道你是否需要复杂的特征变量，或者你是否需要更多的数据，还是别的什么。提前知道你应该做什么，是非常难的，因为你缺少证据，缺少学习曲线。因此，你很难知道你应该把时间花在什么地方来提高算法的表现。但是当你实践一个非常简单即便不完美的方法时，你可以通过画出学习曲线来做出进一步的选择。你可以用这种方式来避免一种电脑编程里的过早优化问题，这种理念是：我们必须用证据来领导我们的决策，怎样分配自己的时间来优化算法，而不是仅仅凭直觉，凭直觉得出的东西一般总是错误的。除了画出学习曲线之外，一件非常有用的事是误差分析，我的意思是说：当我们在构造垃圾邮件分类器时，我会看一看我的交叉验证数据集，然后亲自看一看哪些邮件被算法错误地分类。因此，通过这些被算法错误分类的垃圾邮件与非垃圾邮件，你可以发现某些系统性的规律：什么类型的邮件总是被错误分类。经常地这样做之后，这个过程能启发你构造新的特征变量，或者告诉你：现在这个系统的短处，然后启发你如何去提高它。 构建一个学习算法的推荐方法为： 从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法 2.绘制学习曲线，决定是增加更多数据，或者添加更多特征，还是其他选择 3.进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的样本，看看这些样本是否有某种系统化的趋势 以我们的垃圾邮件过滤器为例，误差分析要做的既是检验交叉验证集中我们的算法产生错误预测的所有邮件，看：是否能将这些邮件按照类分组。例如医药品垃圾邮件，仿冒品垃圾邮件或者密码窃取邮件等。然后看分类器对哪一组邮件的预测误差最大，并着手优化。 思考怎样能改进分类器。例如，发现是否缺少某些特征，记下这些特征出现的次数。 例如记录下错误拼写出现了多少次，异常的邮件路由情况出现了多少次等等，然后从出现次数最多的情况开始着手优化。 误差分析并不总能帮助我们判断应该采取怎样的行动。有时我们需要尝试不同的模型，然后进行比较，在模型比较时，用数值来判断哪一个模型更好更有效，通常我们是看交叉验证集的误差。 在我们的垃圾邮件分类器例子中，对于“我们是否应该将discount/discounts/discounted/discounting处理成同一个词？”如果这样做可以改善我们算法，我们会采用一些截词软件。误差分析不能帮助我们做出这类判断，我们只能尝试采用和不采用截词软件这两种不同方案，然后根据数值检验的结果来判断哪一种更好。 因此，当你在构造学习算法的时候，你总是会去尝试很多新的想法，实现出很多版本的学习算法，如果每一次你实践新想法的时候，你都要手动地检测这些例子，去看看是表现差还是表现好，那么这很难让你做出决定。到底是否使用词干提取，是否区分大小写。但是通过一个量化的数值评估，你可以看看这个数字，误差是变大还是变小了。你可以通过它更快地实践你的新想法，它基本上非常直观地告诉你：你的想法是提高了算法表现，还是让它变得更坏，这会大大提高你实践算法时的速度。所以我强烈推荐在交叉验证集上来实施误差分析，而不是在测试集上。但是，还是有一些人会在测试集上来做误差分析。即使这从数学上讲是不合适的。所以我还是推荐你在交叉验证向量上来做误差分析。 总结一下，当你在研究一个新的机器学习问题时，我总是推荐你实现一个较为简单快速、即便不是那么完美的算法。我几乎从未见过人们这样做。大家经常干的事情是：花费大量的时间在构造算法上，构造他们以为的简单的方法。因此，不要担心你的算法太简单，或者太不完美，而是尽可能快地实现你的算法。当你有了初始的实现之后，它会变成一个非常有力的工具，来帮助你决定下一步的做法。因为我们可以先看看算法造成的错误，通过误差分析，来看看他犯了什么错，然后来决定优化的方式。另一件事是：假设你有了一个快速而不完美的算法实现，又有一个数值的评估数据，这会帮助你尝试新的想法，快速地发现你尝试的这些想法是否能够提高算法的表现，从而你会更快地做出决定，在算法中放弃什么，吸收什么误差分析可以帮助我们系统化地选择该做什么。 类偏斜的误差度量参考视频: 11 - 3 - Error Metrics for Skewed Classes (12 min).mkv 在前面的课程中，我提到了误差分析，以及设定误差度量值的重要性。那就是，设定某个实数来评估你的学习算法，并衡量它的表现，有了算法的评估和误差度量值。有一件重要的事情要注意，就是使用一个合适的误差度量值，这有时会对于你的学习算法造成非常微妙的影响，这件重要的事情就是偏斜类（skewed classes）的问题。类偏斜情况表现为我们的训练集中有非常多的同一种类的样本，只有很少或没有其他类的样本。 例如我们希望用算法来预测癌症是否是恶性的，在我们的训练集中，只有0.5%的实例是恶性肿瘤。假设我们编写一个非学习而来的算法，在所有情况下都预测肿瘤是良性的，那么误差只有0.5%。然而我们通过训练而得到的神经网络算法却有1%的误差。这时，误差的大小是不能视为评判算法效果的依据的。 查准率（Precision）和查全率（Recall） 我们将算法预测的结果分成四种情况： 正确肯定（True Positive,TP）：预测为真，实际为真 2.正确否定（True Negative,TN）：预测为假，实际为假 3.错误肯定（False Positive,FP）：预测为真，实际为假 4.错误否定（False Negative,FN）：预测为假，实际为真 则：查准率=TP/(TP+FP)。例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。 查全率=TP/(TP+FN)。例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。 这样，对于我们刚才那个总是预测病人肿瘤为良性的算法，其查全率是0。 预测值 Positive Negtive 实际值 Positive TP FN Negtive FP TN 查准率和查全率之间的权衡参考视频: 11 - 4 - Trading Off Precision and Recall (14 min).mkv 在之前的课程中，我们谈到查准率和召回率，作为遇到偏斜类问题的评估度量值。在很多应用中，我们希望能够保证查准率和召回率的相对平衡。 在这节课中，我将告诉你应该怎么做，同时也向你展示一些查准率和召回率作为算法评估度量值的更有效的方式。继续沿用刚才预测肿瘤性质的例子。假使，我们的算法输出的结果在0-1 之间，我们使用阀值0.5 来预测真和假。 查准率(Precision)=TP/(TP+FP) 例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。 查全率(Recall)=TP/(TP+FN)例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。 如果我们希望只在非常确信的情况下预测为真（肿瘤为恶性），即我们希望更高的查准率，我们可以使用比0.5更大的阀值，如0.7，0.9。这样做我们会减少错误预测病人为恶性肿瘤的情况，同时却会增加未能成功预测肿瘤为恶性的情况。 如果我们希望提高查全率，尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地检查、诊断，我们可以使用比0.5更小的阀值，如0.3。 我们可以将不同阀值情况下，查全率与查准率的关系绘制成图表，曲线的形状根据数据的不同而不同： 我们希望有一个帮助我们选择这个阀值的方法。一种方法是计算F1 值（F1 Score），其计算公式为： ${ {F}_{1} }Score:2\frac{PR}{P+R}$ 我们选择使得F1值最高的阀值。 机器学习的数据参考视频: 11 - 5 - Data For Machine Learning (11 min).mkv 在之前的视频中，我们讨论了评价指标。在这个视频中，我要稍微转换一下，讨论一下机器学习系统设计中另一个重要的方面，这往往涉及到用来训练的数据有多少。在之前的一些视频中，我曾告诫大家不要盲目地开始，而是花大量的时间来收集大量的数据，因为数据有时是唯一能实际起到作用的。但事实证明，在一定条件下，我会在这个视频里讲到这些条件是什么。得到大量的数据并在某种类型的学习算法中进行训练，可以是一种有效的方法来获得一个具有良好性能的学习算法。而这种情况往往出现在这些条件对于你的问题都成立。 并且你能够得到大量数据的情况下。这可以是一个很好的方式来获得非常高性能的学习算法。因此，在这段视频中，让我们一起讨论一下这个问题。 很多很多年前，我认识的两位研究人员Michele Banko 和Eric Brill进行了一项有趣的研究，他们尝试通过机器学习算法来区分常见的易混淆的单词，他们尝试了许多种不同的算法，并发现数据量非常大时，这些不同类型的算法效果都很好。 比如，在这样的句子中：早餐我吃了__个鸡蛋(to,two,too)，在这个例子中，“早餐我吃了2个鸡蛋”，这是一个易混淆的单词的例子。于是他们把诸如这样的机器学习问题，当做一类监督学习问题，并尝试将其分类，什么样的词，在一个英文句子特定的位置，才是合适的。他们用了几种不同的学习算法，这些算法都是在他们2001年进行研究的时候，都已经被公认是比较领先的。因此他们使用了一个方差，用于逻辑回归上的一个方差，被称作”感知器”(perceptron)。他们也采取了一些过去常用，但是现在比较少用的算法，比如 Winnow算法，很类似于回归问题，但在一些方面又有所不同，过去用得比较多，但现在用得不太多。还有一种基于内存的学习算法，现在也用得比较少了，但是我稍后会讨论一点，而且他们用了一个朴素算法。这些具体算法的细节不那么重要，我们下面希望探讨，什么时候我们会希望获得更多数据，而非修改算法。他们所做的就是改变了训练数据集的大小，并尝试将这些学习算法用于不同大小的训练数据集中，这就是他们得到的结果。 这些趋势非常明显，首先大部分算法，都具有相似的性能，其次，随着训练数据集的增大，在横轴上代表以百万为单位的训练集大小，从0.1个百万到1000百万，也就是到了10亿规模的训练集的样本，这些算法的性能也都对应地增强了。 事实上，如果你选择任意一个算法，可能是选择了一个”劣等的”算法，如果你给这个劣等算法更多的数据，那么从这些例子中看起来的话，它看上去很有可能会其他算法更好，甚至会比”优等算法”更好。由于这项原始的研究非常具有影响力，因此已经有一系列许多不同的研究显示了类似的结果。这些结果表明，许多不同的学习算法有时倾向于表现出非常相似的表现，这还取决于一些细节，但是真正能提高性能的，是你能够给一个算法大量的训练数据。像这样的结果，引起了一种在机器学习中的普遍共识：”取得成功的人不是拥有最好算法的人，而是拥有最多数据的人”。 那么这种说法在什么时候是真，什么时候是假呢？因为如果我们有一个学习算法，并且如果这种说法是真的，那么得到大量的数据通常是保证我们具有一个高性能算法的最佳方式，而不是去争辩应该用什么样的算法。 假如有这样一些假设，在这些假设下有大量我们认为有用的训练集，我们假设在我们的机器学习问题中，特征值$x$包含了足够的信息，这些信息可以帮助我们用来准确地预测$y$，例如，如果我们采用了一些容易混淆的词，如：two、to、too，假如说它能够描述$x$，捕捉到需要填写的空白处周围的词语，那么特征捕捉到之后，我们就希望有对于“早饭我吃了__鸡蛋”，那么这就有大量的信息来告诉我中间我需要填的词是“两个”(two)，而不是单词 to 或too，因此特征捕捉，哪怕是周围词语中的一个词，就能够给我足够的信息来确定出标签 $y$是什么。换句话说，从这三组易混淆的词中，我应该选什么词来填空。 那么让我们来看一看，大量的数据是有帮助的情况。假设特征值有足够的信息来预测$y$值，假设我们使用一种需要大量参数的学习算法，比如有很多特征的逻辑回归或线性回归，或者用带有许多隐藏单元的神经网络，那又是另外一种带有很多参数的学习算法，这些都是非常强大的学习算法，它们有很多参数，这些参数可以拟合非常复杂的函数，因此我要调用这些，我将把这些算法想象成低偏差算法，因为我们能够拟合非常复杂的函数，而且因为我们有非常强大的学习算法，这些学习算法能够拟合非常复杂的函数。很有可能，如果我们用这些数据运行这些算法，这种算法能很好地拟合训练集，因此，训练误差就会很低了。 现在假设我们使用了非常非常大的训练集，在这种情况下，尽管我们希望有很多参数，但是如果训练集比参数的数量还大，甚至是更多，那么这些算法就不太可能会过度拟合。也就是说训练误差有希望接近测试误差。 另一种考虑这个问题的角度是为了有一个高性能的学习算法，我们希望它不要有高的偏差和方差。 因此偏差问题，我么将通过确保有一个具有很多参数的学习算法来解决，以便我们能够得到一个较低偏差的算法，并且通过用非常大的训练集来保证。 我们在此没有方差问题，我们的算法将没有方差，并且通过将这两个值放在一起，我们最终可以得到一个低误差和低方差的学习算法。这使得我们能够很好地测试测试数据集。从根本上来说，这是一个关键的假设：特征值有足够的信息量，且我们有一类很好的函数，这是为什么能保证低误差的关键所在。它有大量的训练数据集，这能保证得到更多的方差值，因此这给我们提出了一些可能的条件，如果你有大量的数据，而且你训练了一种带有很多参数的学习算法，那么这将会是一个很好的方式，来提供一个高性能的学习算法。 我觉得关键的测试：首先，一个人类专家看到了特征值 $x$，能很有信心的预测出$y$值吗？因为这可以证明 $ y$ 可以根据特征值$x$被准确地预测出来。其次，我们实际上能得到一组庞大的训练集，并且在这个训练集中训练一个有很多参数的学习算法吗？如果你不能做到这两者，那么更多时候，你会得到一个性能很好的学习算法。 支持向量机(Support Vector Machines)优化目标参考视频: 12 - 1 - Optimization Objective (15 min).mkv 到目前为止,你已经见过一系列不同的学习算法。在监督学习中，许多学习算法的性能都非常类似，因此，重要的不是你该选择使用学习算法A还是学习算法B，而更重要的是，应用这些算法时，所创建的大量数据在应用这些算法时，表现情况通常依赖于你的水平。比如：你为学习算法所设计的特征量的选择，以及如何选择正则化参数，诸如此类的事。还有一个更加强大的算法广泛的应用于工业界和学术界，它被称为支持向量机(Support Vector Machine)。与逻辑回归和神经网络相比，支持向量机，或者简称SVM，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。因此，在接下来的视频中，我会探讨这一算法。在稍后的课程中，我也会对监督学习算法进行简要的总结。当然，仅仅是作简要描述。但对于支持向量机，鉴于该算法的强大和受欢迎度，在本课中，我会花许多时间来讲解它。它也是我们所介绍的最后一个监督学习算法。 正如我们之前开发的学习算法，我们从优化目标开始。那么，我们开始学习这个算法。为了描述支持向量机，事实上，我将会从逻辑回归开始展示我们如何一点一点修改来得到本质上的支持向量机。 那么，在逻辑回归中我们已经熟悉了这里的假设函数形式，和右边的S型激励函数。然而，为了解释一些数学知识.我将用$z$ 表示$\theta^Tx$。 现在考虑下我们想要逻辑回归做什么：如果有一个 $y=1$的样本，我的意思是不管是在训练集中或是在测试集中，又或者在交叉验证集中，总之是 $y=1$，现在我们希望${ {h}_{\theta } }\left( x \right)$ 趋近1。因为我们想要正确地将此样本分类，这就意味着当 ${ {h}_{\theta } }\left( x \right)$趋近于1时，$\theta^Tx$ 应当远大于0，这里的$>>$意思是远远大于0。这是因为由于 $z$ 表示 $\theta^Tx$，当 $z$远大于0时，即到了该图的右边，你不难发现此时逻辑回归的输出将趋近于1。相反地，如果我们有另一个样本，即$y=0$。我们希望假设函数的输出值将趋近于0，这对应于$\theta^Tx$，或者就是 $z$ 会远小于0，因为对应的假设函数的输出值趋近0。 如果你进一步观察逻辑回归的代价函数，你会发现每个样本 $(x,y)$都会为总代价函数，增加这里的一项，因此，对于总代价函数通常会有对所有的训练样本求和，并且这里还有一个$1/m$项，但是，在逻辑回归中，这里的这一项就是表示一个训练样本所对应的表达式。现在，如果我将完整定义的假设函数代入这里。那么，我们就会得到每一个训练样本都影响这一项。 现在，先忽略 $1/m$ 这一项，但是这一项是影响整个总代价函数中的这一项的。 现在，一起来考虑两种情况： 一种是$y$等于1的情况；另一种是 $y$ 等于0的情况。 在第一种情况中，假设 $y=1$ ，此时在目标函数中只需有第一项起作用，因为$y=1$时，$(1-y)$项将等于0。因此，当在 $y=1$ 的样本中时，即在 $(x, y) $中 ，我们得到 $y=1$ $-\log(1-\frac{1}{1+e^{-z} })$这样一项，这里同上一张幻灯片一致。 我用 $z$ 表示$\theta^Tx$，即： $z= \theta^Tx$。当然，在代价函数中，$y$ 前面有负号。我们只是这样表示，如果 $y=1$ 代价函数中，这一项也等于1。这样做是为了简化此处的表达式。如果画出关于$z$ 的函数，你会看到左下角的这条曲线，我们同样可以看到，当$z$ 增大时，也就是相当于$\theta^Tx$增大时，$z$ 对应的值会变的非常小。对整个代价函数而言，影响也非常小。这也就解释了，为什么逻辑回归在观察到正样本$y=1$时，试图将$\theta^Tx$设置得非常大。因为，在代价函数中的这一项会变的非常小。 现在开始建立支持向量机，我们从这里开始： 我们会从这个代价函数开始，也就是$-\log(1-\frac{1}{1+e^{-z} })$一点一点修改，让我取这里的$z=1$ 点，我先画出将要用的代价函数。 新的代价函数将会水平的从这里到右边(图外)，然后我再画一条同逻辑回归非常相似的直线，但是，在这里是一条直线，也就是我用紫红色画的曲线，就是这条紫红色的曲线。那么，到了这里已经非常接近逻辑回归中使用的代价函数了。只是这里是由两条线段组成，即位于右边的水平部分和位于左边的直线部分，先别过多的考虑左边直线部分的斜率，这并不是很重要。但是，这里我们将使用的新的代价函数，是在$y=1$的前提下的。你也许能想到，这应该能做同逻辑回归中类似的事情，但事实上，在之后的优化问题中，这会变得更坚定，并且为支持向量机，带来计算上的优势。例如，更容易计算股票交易的问题等等。 目前，我们只是讨论了$y=1$的情况，另外一种情况是当$y=0$时，此时如果你仔细观察代价函数只留下了第二项，因为第一项被消除了。如果当$y=0$时，那么这一项也就是0了。所以上述表达式只留下了第二项。因此，这个样本的代价或是代价函数的贡献。将会由这一项表示。并且，如果你将这一项作为$z$的函数，那么，这里就会得到横轴$z$。现在，你完成了支持向量机中的部分内容，同样地，我们要替代这一条蓝色的线，用相似的方法。 如果我们用一个新的代价函数来代替，即这条从0点开始的水平直线，然后是一条斜线，像上图。那么，现在让我给这两个方程命名，左边的函数，我称之为${\cos}t_1{(z)}$，同时，右边函数我称它为${\cos}t_0{(z)}$。这里的下标是指在代价函数中，对应的 $y=1$ 和 $y=0$ 的情况，拥有了这些定义后，现在，我们就开始构建支持向量机。 这是我们在逻辑回归中使用代价函数$J(\theta)$。也许这个方程看起来不是非常熟悉。这是因为之前有个负号在方程外面，但是，这里我所做的是，将负号移到了表达式的里面，这样做使得方程看起来有些不同。对于支持向量机而言，实质上我们要将这替换为${\cos}t_1{(z)}$，也就是${\cos}t_1{(\theta^Tx)}$，同样地，我也将这一项替换为${\cos}t_0{(z)}$，也就是代价${\cos}t_0{(\theta^Tx)}$。这里的代价函数${\cos}t_1$，就是之前所提到的那条线。此外，代价函数${\cos}t_0$，也是上面所介绍过的那条线。因此，对于支持向量机，我们得到了这里的最小化问题，即: 然后，再加上正则化参数。现在，按照支持向量机的惯例，事实上，我们的书写会稍微有些不同，代价函数的参数表示也会稍微有些不同。 首先，我们要除去$1/m$这一项，当然，这仅仅是由于人们使用支持向量机时，对比于逻辑回归而言，不同的习惯所致，但这里我所说的意思是：你知道，我将要做的是仅仅除去$1/m$这一项，但是，这也会得出同样的 ${ {\theta } }$ 最优值，好的，因为$1/m$ 仅是个常量，因此，你知道在这个最小化问题中，无论前面是否有$1/m$ 这一项，最终我所得到的最优值${ {\theta } }$都是一样的。这里我的意思是，先给你举一个样本，假定有一最小化问题：即要求当$(u-5)^2+1$取得最小值时的$u$值，这时最小值为：当$u=5$时取得最小值。 现在，如果我们想要将这个目标函数乘上常数10，这里我的最小化问题就变成了：求使得$10×(u-5)^2+10$最小的值$u$，然而，使得这里最小的$u$值仍为5。因此将一些常数乘以你的最小化项，这并不会改变最小化该方程时得到$u$值。因此，这里我所做的是删去常量$m$。也相同的，我将目标函数乘上一个常量$m$，并不会改变取得最小值时的${ {\theta } }$值。 第二点概念上的变化，我们只是指在使用支持向量机时，一些如下的标准惯例，而不是逻辑回归。因此，对于逻辑回归，在目标函数中，我们有两项：第一个是训练样本的代价，第二个是我们的正则化项，我们不得不去用这一项来平衡。这就相当于我们想要最小化$A$加上正则化参数$\lambda$，然后乘以其他项$B$对吧？这里的$A$表示这里的第一项，同时我用B表示第二项，但不包括$\lambda$，我们不是优化这里的$A+\lambda\times B$。我们所做的是通过设置不同正则参数$\lambda$达到优化目的。这样，我们就能够权衡对应的项，是使得训练样本拟合的更好。即最小化$A$。还是保证正则参数足够小，也即是对于B项而言，但对于支持向量机，按照惯例，我们将使用一个不同的参数替换这里使用的$\lambda$来权衡这两项。你知道，就是第一项和第二项我们依照惯例使用一个不同的参数称为$C$，同时改为优化目标，$C×A+B$。因此，在逻辑回归中，如果给定$\lambda$，一个非常大的值，意味着给予$B$更大的权重。而这里，就对应于将$C$ 设定为非常小的值，那么，相应的将会给$B$比给$A$更大的权重。因此，这只是一种不同的方式来控制这种权衡或者一种不同的方法，即用参数来决定是更关心第一项的优化，还是更关心第二项的优化。当然你也可以把这里的参数$C$ 考虑成$1/\lambda$，同 $1/\lambda$所扮演的角色相同，并且这两个方程或这两个表达式并不相同，因为$C=1/\lambda$，但是也并不全是这样，如果当$C=1/\lambda$时，这两个优化目标应当得到相同的值，相同的最优值 ${ {\theta } }$。因此，就用它们来代替。那么，我现在删掉这里的$\lambda$，并且用常数$C$来代替。因此，这就得到了在支持向量机中我们的整个优化目标函数。然后最小化这个目标函数，得到SVM 学习到的参数$C$。 最后有别于逻辑回归输出的概率。在这里，我们的代价函数，当最小化代价函数，获得参数${ {\theta } }$时，支持向量机所做的是它来直接预测$y$的值等于1，还是等于0。因此，这个假设函数会预测1。当$\theta^Tx$大于或者等于0时，或者等于0时，所以学习参数${ {\theta } }$就是支持向量机假设函数的形式。那么，这就是支持向量机数学上的定义。 在接下来的视频中，让我们再回去从直观的角度看看优化目标，实际上是在做什么，以及SVM的假设函数将会学习什么，同时也会谈谈如何做些许修改，学习更加复杂、非线性的函数。 大边界的直观理解参考视频: 12 - 2 - Large Margin Intuition (11 min).mkv 人们有时将支持向量机看作是大间距分类器。在这一部分，我将介绍其中的含义，这有助于我们直观理解SVM模型的假设是什么样的。 这是我的支持向量机模型的代价函数，在左边这里我画出了关于$z$的代价函数${\cos}t_1{(z)}$，此函数用于正样本，而在右边这里我画出了关于$z$的代价函数${\cos}t_0{(z)}$，横轴表示$z$，现在让我们考虑一下，最小化这些代价函数的必要条件是什么。如果你有一个正样本，$y=1$，则只有在$z>=1$时，代价函数${\cos}t_1{(z)}$才等于0。 换句话说，如果你有一个正样本，我们会希望$\theta^Tx>=1$，反之，如果$y=0$，我们观察一下，函数${\cos}t_0{(z)}$，它只有在$z&lt;=-1$的区间里函数值为0。这是支持向量机的一个有趣性质。事实上，如果你有一个正样本$y=1$，则其实我们仅仅要求$\theta^Tx$大于等于0，就能将该样本恰当分出，这是因为如果$\theta^Tx$&gt;0大的话，我们的模型代价函数值为0，类似地，如果你有一个负样本，则仅需要$\theta^Tx$&amp;lt;=0就会将负例正确分离，但是，支持向量机的要求更高，不仅仅要能正确分开输入的样本，即不仅仅要求$\theta^Tx$&gt;0，我们需要的是比0值大很多，比如大于等于1，我也想这个比0小很多，比如我希望它小于等于-1，这就相当于在支持向量机中嵌入了一个额外的安全因子，或者说安全的间距因子。 当然，逻辑回归做了类似的事情。但是让我们看一下，在支持向量机中，这个因子会导致什么结果。具体而言，我接下来会考虑一个特例。我们将这个常数$C$设置成一个非常大的值。比如我们假设$C$的值为100000或者其它非常大的数，然后来观察支持向量机会给出什么结果？ 如果 $C$非常大，则最小化代价函数的时候，我们将会很希望找到一个使第一项为0的最优解。因此，让我们尝试在代价项的第一项为0的情形下理解该优化问题。比如我们可以把$C$设置成了非常大的常数，这将给我们一些关于支持向量机模型的直观感受。 $\min_\limits{\theta}C\sum_\limits{i=1}^{m}\left[y^{(i)}{\cos}t_{1}\left(\theta^{T}x^{(i)}\right)+\left(1-y^{(i)}\right){\cos}t\left(\theta^{T}x^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{i=1}^{n}\theta^{2}_{j}$ 我们已经看到输入一个训练样本标签为$y=1$，你想令第一项为0，你需要做的是找到一个${ {\theta } }$，使得$\theta^Tx>=1$，类似地，对于一个训练样本，标签为$y=0$，为了使${\cos}t_0{(z)}$ 函数的值为0，我们需要$\theta^Tx&lt;=-1$。因此，现在考虑我们的优化问题。选择参数，使得第一项等于0，就会导致下面的优化问题，因为我们将选择参数使第一项为0，因此这个函数的第一项为0，因此是$C$乘以0加上二分之一乘以第二项。这里第一项是$C$乘以0，因此可以将其删去，因为我知道它是0。 这将遵从以下的约束：$\theta^Tx^{(i)}>=1$，如果 $y^{(i)}$是等于1 的，$\theta^Tx^{(i)}&lt;=-1$，如果样本$i$是一个负样本，这样当你求解这个优化问题的时候，当你最小化这个关于变量${ {\theta } }$的函数的时候，你会得到一个非常有趣的决策边界。 具体而言，如果你考察这样一个数据集，其中有正样本，也有负样本，可以看到这个数据集是线性可分的。我的意思是，存在一条直线把正负样本分开。当然有多条不同的直线，可以把正样本和负样本完全分开。 比如，这就是一个决策边界可以把正样本和负样本分开。但是多多少少这个看起来并不是非常自然是么? 或者我们可以画一条更差的决策界，这是另一条决策边界，可以将正样本和负样本分开，但仅仅是勉强分开，这些决策边界看起来都不是特别好的选择，支持向量机将会选择这个黑色的决策边界，相较于之前我用粉色或者绿色画的决策界。这条黑色的看起来好得多，黑线看起来是更稳健的决策界。在分离正样本和负样本上它显得的更好。数学上来讲，这是什么意思呢？这条黑线有更大的距离，这个距离叫做间距(margin)。 当画出这两条额外的蓝线，我们看到黑色的决策界和训练样本之间有更大的最短距离。然而粉线和蓝线离训练样本就非常近，在分离样本的时候就会比黑线表现差。因此，这个距离叫做支持向量机的间距，而这是支持向量机具有鲁棒性的原因，因为它努力用一个最大间距来分离样本。因此支持向量机有时被称为大间距分类器，而这其实是求解上一页幻灯片上优化问题的结果。 我知道你也许想知道求解上一页幻灯片中的优化问题为什么会产生这个结果？它是如何产生这个大间距分类器的呢？我知道我还没有解释这一点。 我将会从直观上略述为什么这个优化问题会产生大间距分类器。总之这个图示有助于你理解支持向量机模型的做法，即努力将正样本和负样本用最大的间距分开。 在本节课中关于大间距分类器，我想讲最后一点：我们将这个大间距分类器中的正则化因子常数$C$设置的非常大，我记得我将其设置为了100000，因此对这样的一个数据集，也许我们将选择这样的决策界，从而最大间距地分离开正样本和负样本。那么在让代价函数最小化的过程中，我们希望找出在$y=1$和$y=0$两种情况下都使得代价函数中左边的这一项尽量为零的参数。如果我们找到了这样的参数，则我们的最小化问题便转变成： 事实上，支持向量机现在要比这个大间距分类器所体现得更成熟，尤其是当你使用大间距分类器的时候，你的学习算法会受异常点(outlier) 的影响。比如我们加入一个额外的正样本。 在这里，如果你加了这个样本，为了将样本用最大间距分开，也许我最终会得到一条类似这样的决策界，对么？就是这条粉色的线，仅仅基于一个异常值，仅仅基于一个样本，就将我的决策界从这条黑线变到这条粉线，这实在是不明智的。而如果正则化参数$C$，设置的非常大，这事实上正是支持向量机将会做的。它将决策界，从黑线变到了粉线，但是如果$C$ 设置的小一点，如果你将C设置的不要太大，则你最终会得到这条黑线， 当然数据如果不是线性可分的，如果你在这里有一些正样本或者你在这里有一些负样本，则支持向量机也会将它们恰当分开。因此，大间距分类器的描述，仅仅是从直观上给出了正则化参数$C$非常大的情形，同时，要提醒你$C$的作用类似于$1/\lambda$，$\lambda$是我们之前使用过的正则化参数。这只是$C$非常大的情形，或者等价地 $\lambda$ 非常小的情形。你最终会得到类似粉线这样的决策界，但是实际上应用支持向量机的时候，当$C$不是非常非常大的时候，它可以忽略掉一些异常点的影响，得到更好的决策界。 甚至当你的数据不是线性可分的时候，支持向量机也可以给出好的结果。 回顾 $C=1/\lambda$，因此： $C$ 较大时，相当于 $\lambda$ 较小，可能会导致过拟合，高方差。 $C$ 较小时，相当于$\lambda$较大，可能会导致低拟合，高偏差。 我们稍后会介绍支持向量机的偏差和方差，希望在那时候关于如何处理参数的这种平衡会变得更加清晰。我希望，这节课给出了一些关于为什么支持向量机被看做大间距分类器的直观理解。它用最大间距将样本区分开，尽管从技术上讲，这只有当参数$C$是非常大的时候是真的，但是它对于理解支持向量机是有益的。 本节课中我们略去了一步，那就是我们在幻灯片中给出的优化问题。为什么会是这样的？它是如何得出大间距分类器的？我在本节中没有讲解，在下一节课中，我将略述这些问题背后的数学原理，来解释这个优化问题是如何得到一个大间距分类器的。 大边界分类背后的数学（选修）参考视频: 12 - 3 - Mathematics Behind Large Margin Classification (Optional) (20 min).mkv 在本节课中，我将介绍一些大间隔分类背后的数学原理。本节为选修部分，你完全可以跳过它，但是听听这节课可能让你对支持向量机中的优化问题，以及如何得到大间距分类器，产生更好的直观理解。 首先，让我来给大家复习一下关于向量内积的知识。假设我有两个向量，$u$和$v$，我将它们写在这里。两个都是二维向量，我们看一下，$u^T v$的结果。$u^T v$也叫做向量$u$和$v$之间的内积。由于是二维向量，我可以将它们画在这个图上。我们说，这就是向量$u$即在横轴上，取值为某个${ {u}_{1} }$，而在纵轴上，高度是某个${ {u}_{2} }$作为$u$的第二个分量。现在，很容易计算的一个量就是向量$u$的范数。$\left\| u \right\|$表示$u$的范数，即$u$的长度，即向量$u$的欧几里得长度。根据毕达哥拉斯定理，$\left\| u \right\|=\sqrt{u_{1}^{2}+u_{2}^{2} }$，这是向量$u$的长度，它是一个实数。现在你知道了这个的长度是多少了。我刚刚画的这个向量的长度就知道了。 现在让我们回头来看向量$v$ ，因为我们想计算内积。$v$是另一个向量，它的两个分量${ {v}_{1} }$和${ {v}_{2} }$是已知的。向量$v$可以画在这里，现在让我们来看看如何计算$u$和$v$之间的内积。这就是具体做法，我们将向量$v$投影到向量$u$上，我们做一个直角投影，或者说一个90度投影将其投影到$u$上，接下来我度量这条红线的长度。我称这条红线的长度为$p$，因此$p$就是长度，或者说是向量$v$投影到向量$u$上的量，我将它写下来，$p$是$v$投影到向量$u$上的长度，因此可以将${ {u}^{T} }v=p\centerdot \left\| u \right\|$，或者说$u$的长度。这是计算内积的一种方法。如果你从几何上画出$p$的值，同时画出$u$的范数，你也会同样地计算出内积，答案是一样的。另一个计算公式是：$u^T v$就是$\left[ { {u}_{1} }\text{ }{ {u}_{2} } \right]$ 这个一行两列的矩阵乘以$v$。因此可以得到${ {u}_{1} }\times { {v}_{1} }+{ {u}_{2} }\times { {v}_{2} }$。根据线性代数的知识，这两个公式会给出同样的结果。顺便说一句，$u^Tv=v^Tu$。因此如果你将$u$和$v$交换位置，将$u$投影到$v$上，而不是将$v$投影到$u$上，然后做同样地计算，只是把$u$和$v$的位置交换一下，你事实上可以得到同样的结果。申明一点，在这个等式中$u$的范数是一个实数，$p$也是一个实数，因此$u^T v$就是两个实数正常相乘。 最后一点，需要注意的就是$p$值，$p$事实上是有符号的，即它可能是正值，也可能是负值。我的意思是说，如果$u$是一个类似这样的向量，$v$是一个类似这样的向量，$u$和$v$之间的夹角大于90度，则如果将$v$投影到$u$上，会得到这样的一个投影，这是$p$的长度，在这个情形下我们仍然有${ {u}^{T} }v$是等于$p$乘以$u$的范数。唯一一点不同的是$p$在这里是负的。在内积计算中，如果$u$和$v$之间的夹角小于90度，那么那条红线的长度$p$是正值。然而如果这个夹角大于90度，则$p$将会是负的。就是这个小线段的长度是负的。如果它们之间的夹角大于90度，两个向量之间的内积也是负的。这就是关于向量内积的知识。我们接下来将会使用这些关于向量内积的性质试图来理解支持向量机中的目标函数。 这就是我们先前给出的支持向量机模型中的目标函数。为了讲解方便，我做一点简化，仅仅是为了让目标函数更容易被分析。 我接下来忽略掉截距，令${ {\theta }_{0} }=0$，这样更容易画示意图。我将特征数$n$置为2，因此我们仅有两个特征${ {x}_{1} },{ {x}_{2} }$，现在我们来看一下目标函数，支持向量机的优化目标函数。当我们仅有两个特征，即$n=2$时，这个式子可以写作：$\frac{1}{2}\left({\theta_1^2+\theta_2^2}\right)=\frac{1}{2}\left(\sqrt{\theta_1^2+\theta_2^2}\right)^2$，我们只有两个参数${ {\theta }_{1} },{ {\theta }_{2} }$。你可能注意到括号里面的这一项是向量${ {\theta } }$的范数，或者说是向量${ {\theta } }$的长度。我的意思是如果我们将向量${ {\theta } }$写出来，那么我刚刚画红线的这一项就是向量${ {\theta } }$的长度或范数。这里我们用的是之前学过的向量范数的定义，事实上这就等于向量${ {\theta } }$的长度。 当然你可以将其写作${ {\theta }_{0} }\text{,}{ {\theta }_{1} },{ {\theta }_{2} }$，如果${ {\theta }_{0} }=0$，那就是${ {\theta }_{1} },{ {\theta }_{2} }$的长度。在这里我将忽略${ {\theta }_{0} }$，这样来写$\theta$的范数，它仅仅和${ {\theta }_{1} },{ {\theta }_{2} }$有关。但是，数学上不管你是否包含，其实并没有差别，因此在我们接下来的推导中去掉${ {\theta }_{0} }$不会有影响这意味着我们的目标函数是等于$\frac{1}{2}\left\| \theta \right\|^2$。因此支持向量机做的全部事情，就是极小化参数向量${ {\theta } }$范数的平方，或者说长度的平方。 现在我将要看看这些项：$\theta^{T}x$更深入地理解它们的含义。给定参数向量$\theta $给定一个样本$x$，这等于什么呢?在前一页幻灯片上，我们画出了在不同情形下，$u^Tv$的示意图，我们将会使用这些概念，$\theta $和$x^{(i)}$就类似于$u$和$v$ 。 让我们看一下示意图：我们考察一个单一的训练样本，我有一个正样本在这里，用一个叉来表示这个样本$x^{(i)}$，意思是在水平轴上取值为$x_1^{(i)}$，在竖直轴上取值为$x_2^{(i)}$。这就是我画出的训练样本。尽管我没有将其真的看做向量。它事实上就是一个始于原点，终点位置在这个训练样本点的向量。现在，我们有一个参数向量我会将它也画成向量。我将$θ_1$画在横轴这里，将$θ_2$ 画在纵轴这里，那么内积$θ^T x^{(i)}$ 将会是什么呢？ 使用我们之前的方法，我们计算的方式就是我将训练样本投影到参数向量${ {\theta } }$，然后我来看一看这个线段的长度，我将它画成红色。我将它称为$p^{(i)}$用来表示这是第 $i$个训练样本在参数向量${ {\theta } }$上的投影。根据我们之前幻灯片的内容，我们知道的是$θ^Tx^{(i)}$将会等于$p$ 乘以向量 $θ$ 的长度或范数。这就等于$\theta_1\cdot{x_1^{(i)} }+\theta_2\cdot{x_2^{(i)} }$。这两种方式是等价的，都可以用来计算$θ$和$x^{(i)}$之间的内积。 这告诉了我们什么呢？这里表达的意思是：这个$θ^Tx^{(i)}>=1$ 或者$θ^Tx^{(i)}&lt;-1$的,约束是可以被$p^{(i)}\cdot{x}>=1$这个约束所代替的。因为$θ^Tx^{(i)}=p^{(i)}\cdot{\left\| \theta \right\|}$ ，将其写入我们的优化目标。我们将会得到没有了约束，$θ^Tx^{(i)}$而变成了$p^{(i)}\cdot{\left\| \theta \right\|}$。 需要提醒一点，我们之前曾讲过这个优化目标函数可以被写成等于$\frac{1}{2}\left\| \theta \right\|^2$。 现在让我们考虑下面这里的训练样本。现在，继续使用之前的简化，即${ {\theta }_{0} }=0$，我们来看一下支持向量机会选择什么样的决策界。这是一种选择，我们假设支持向量机会选择这个决策边界。这不是一个非常好的选择，因为它的间距很小。这个决策界离训练样本的距离很近。我们来看一下为什么支持向量机不会选择它。 对于这样选择的参数${ {\theta } }$，可以看到参数向量${ {\theta } }$事实上是和决策界是90度正交的，因此这个绿色的决策界对应着一个参数向量${ {\theta } }$这个方向,顺便提一句${ {\theta }_{0} }=0$的简化仅仅意味着决策界必须通过原点$(0,0)$。现在让我们看一下这对于优化目标函数意味着什么。 比如这个样本，我们假设它是我的第一个样本$x^{(1)}$，如果我考察这个样本到参数${ {\theta } }$的投影，投影是这个短的红线段，就等于$p^{(1)}$，它非常短。类似地，这个样本如果它恰好是$x^{(2)}$，我的第二个训练样本，则它到${ {\theta } }$的投影在这里。我将它画成粉色，这个短的粉色线段是$p^{(2)}$，即第二个样本到我的参数向量${ {\theta } }$的投影。因此，这个投影非常短。$p^{(2)}$事实上是一个负值，$p^{(2)}$是在相反的方向，这个向量和参数向量${ {\theta } }$的夹角大于90度，$p^{(2)}$的值小于0。 我们会发现这些$p^{(i)}$将会是非常小的数，因此当我们考察优化目标函数的时候，对于正样本而言，我们需要$p^{(i)}\cdot{\left\| \theta \right\|}>=1$,但是如果 $p^{(i)}$在这里非常小,那就意味着我们需要${ {\theta } }$的范数非常大.因为如果 $p^{(1)}$ 很小,而我们希望$p^{(1)}\cdot{\left\| \theta \right\|}>=1$,令其实现的唯一的办法就是这两个数较大。如果 $p^{(1)}$ 小，我们就希望${ {\theta } }$的范数大。类似地，对于负样本而言我们需要$p^{(2)}\cdot{\left\|\theta \right\|}&lt;=-1$。我们已经在这个样本中看到$p^{(2)}$会是一个非常小的数，因此唯一的办法就是${ {\theta } }$的范数变大。但是我们的目标函数是希望找到一个参数${ {\theta } }$，它的范数是小的。因此，这看起来不像是一个好的参数向量${ {\theta } }$的选择。 相反的，来看一个不同的决策边界。比如说，支持向量机选择了这个决策界，现在状况会有很大不同。如果这是决策界，这就是相对应的参数${ {\theta } }$的方向，因此，在这个决策界之下，垂直线是决策界。使用线性代数的知识，可以说明，这个绿色的决策界有一个垂直于它的向量${ {\theta } }$。现在如果你考察你的数据在横轴$x$上的投影，比如这个我之前提到的样本，我的样本$x^{(1)}$，当我将它投影到横轴$x$上，或说投影到${ {\theta } }$上，就会得到这样$p^{(1)}$。它的长度是$p^{(1)}$，另一个样本，那个样本是$x^{(2)}$。我做同样的投影，我会发现，$p^{(2)}$的长度是负值。你会注意到现在$p^{(1)}$ 和$p^{(2)}$这些投影长度是长多了。如果我们仍然要满足这些约束，$P^{(i)}\cdot{\left\| \theta \right\|}$&gt;1，则因为$p^{(1)}$变大了，${ {\theta } }$的范数就可以变小了。因此这意味着通过选择右边的决策界，而不是左边的那个，支持向量机可以使参数${ {\theta } }$的范数变小很多。因此，如果我们想令${ {\theta } }$的范数变小，从而令${ {\theta } }$范数的平方变小，就能让支持向量机选择右边的决策界。这就是支持向量机如何能有效地产生大间距分类的原因。 看这条绿线，这个绿色的决策界。我们希望正样本和负样本投影到$\theta$的值大。要做到这一点的唯一方式就是选择这条绿线做决策界。这是大间距决策界来区分开正样本和负样本这个间距的值。这个间距的值就是$p^{(1)},p^{(2)},p^{(3)}$等等的值。通过让间距变大，即通过这些$p^{(1)},p^{(2)},p^{(3)}$等等的值，支持向量机最终可以找到一个较小的${ {\theta } }$范数。这正是支持向量机中最小化目标函数的目的。 以上就是为什么支持向量机最终会找到大间距分类器的原因。因为它试图极大化这些$p^{(i)}$的范数，它们是训练样本到决策边界的距离。最后一点，我们的推导自始至终使用了这个简化假设，就是参数$θ_0=0$。 就像我之前提到的。这个的作用是：$θ_0=0$的意思是我们让决策界通过原点。如果你令$θ_0$不是0的话，含义就是你希望决策界不通过原点。我将不会做全部的推导。实际上，支持向量机产生大间距分类器的结论，会被证明同样成立，证明方式是非常类似的，是我们刚刚做的证明的推广。 之前视频中说过，即便$θ_0$不等于0，支持向量机要做的事情都是优化这个目标函数对应着$C$值非常大的情况，但是可以说明的是，即便$θ_0$不等于0，支持向量机仍然会找到正样本和负样本之间的大间距分隔。 总之，我们解释了为什么支持向量机是一个大间距分类器。在下一节我们，将开始讨论如何利用支持向量机的原理，应用它们建立一个复杂的非线性分类器。 核函数1参考视频: 12 - 4 - Kernels I (16 min).mkv 回顾我们之前讨论过可以使用高级数的多项式模型来解决无法用直线进行分隔的分类问题： 为了获得上图所示的判定边界，我们的模型可能是${ {\theta }_{0} }+{ {\theta }_{1} }{ {x}_{1} }+{ {\theta }_{2} }{ {x}_{2} }+{ {\theta }_{3} }{ {x}_{1} }{ {x}_{2} }+{ {\theta }_{4} }x_{1}^{2}+{ {\theta }_{5} }x_{2}^{2}+\cdots $的形式。 我们可以用一系列的新的特征$f$来替换模型中的每一项。例如令： ${ {f}_{1} }={ {x}_{1} },{ {f}_{2} }={ {x}_{2} },{ {f}_{3} }={ {x}_{1} }{ {x}_{2} },{ {f}_{4} }=x_{1}^{2},{ {f}_{5} }=x_{2}^{2}$ …得到$h_θ(x)={ {\theta }_{1} }f_1+{ {\theta }_{2} }f_2+...+{ {\theta }_{n} }f_n$。然而，除了对原有的特征进行组合以外，有没有更好的方法来构造$f_1,f_2,f_3$？我们可以利用核函数来计算出新的特征。 给定一个训练样本$x$，我们利用$x$的各个特征与我们预先选定的地标(landmarks)$l^{(1)},l^{(2)},l^{(3)}$的近似程度来选取新的特征$f_1,f_2,f_3$。 例如：${ {f}_{1} }=similarity(x,{ {l}^{(1)} })=e(-\frac{ {{\left\| x-{ {l}^{(1)} } \right\|}^{2} }}{2{ {\sigma }^{2} }})$ 其中：${ {\left\| x-{ {l}^{(1)} } \right\|}^{2} }=\sum{_{j=1}^{n} }{ {({ {x}_{j} }-l_{j}^{(1)})}^{2} }$，为实例$x$中所有特征与地标$l^{(1)}$之间的距离的和。上例中的$similarity(x,{ {l}^{(1)} })$就是核函数，具体而言，这里是一个高斯核函数(Gaussian Kernel)。 注：这个函数与正态分布没什么实际上的关系，只是看上去像而已。 这些地标的作用是什么？如果一个训练样本$x$与地标$l$之间的距离近似于0，则新特征 $f$近似于$e^{-0}=1$，如果训练样本$x$与地标$l$之间距离较远，则$f$近似于$e^{-(一个较大的数)}=0$。 假设我们的训练样本含有两个特征[$x_{1}$ $x{_2}$]，给定地标$l^{(1)}$与不同的$\sigma$值，见下图： 图中水平面的坐标为 $x_{1}$，$x_{2}$而垂直坐标轴代表$f$。可以看出，只有当$x$与$l^{(1)}$重合时$f$才具有最大值。随着$x$的改变$f$值改变的速率受到$\sigma^2$的控制。 在下图中，当样本处于洋红色的点位置处，因为其离$l^{(1)}$更近，但是离$l^{(2)}$和$l^{(3)}$较远，因此$f_1$接近1，而$f_2$,$f_3$接近0。因此$h_θ(x)=θ_0+θ_1f_1+θ_2f_2+θ_1f_3>0$，因此预测$y=1$。同理可以求出，对于离$l^{(2)}$较近的绿色点，也预测$y=1$，但是对于蓝绿色的点，因为其离三个地标都较远，预测$y=0$。 这样，图中红色的封闭曲线所表示的范围，便是我们依据一个单一的训练样本和我们选取的地标所得出的判定边界，在预测时，我们采用的特征不是训练样本本身的特征，而是通过核函数计算出的新特征$f_1,f_2,f_3$。 核函数2参考视频: 12 - 5 - Kernels II (16 min).mkv 在上一节视频里，我们讨论了核函数这个想法，以及怎样利用它去实现支持向量机的一些新特性。在这一节视频中，我将补充一些缺失的细节，并简单的介绍一下怎么在实际中使用应用这些想法。 如何选择地标？ 我们通常是根据训练集的数量选择地标的数量，即如果训练集中有$m$个样本，则我们选取$m$个地标，并且令:$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},.....,l^{(m)}=x^{(m)}$。这样做的好处在于：现在我们得到的新特征是建立在原有特征与训练集中所有其他特征之间距离的基础之上的，即： 下面我们将核函数运用到支持向量机中，修改我们的支持向量机假设为： • 给定$x$，计算新特征$f$，当$θ^Tf>=0$ 时，预测 $y=1$，否则反之。 相应地修改代价函数为：$\sum{_{j=1}^{n=m} }\theta _{j}^{2}={ {\theta}^{T} }\theta $， $min C\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }cos { {t}_{1} }}( { {\theta }^{T} }{ {f}^{(i)} })+(1-{ {y}^{(i)} })cos { {t}_{0} }( { {\theta }^{T} }{ {f}^{(i)} })]+\frac{1}{2}\sum\limits_{j=1}^{n=m}{\theta _{j}^{2} }$ 在具体实施过程中，我们还需要对最后的正则化项进行些微调整，在计算$\sum{_{j=1}^{n=m} }\theta _{j}^{2}={ {\theta}^{T} }\theta $时，我们用$θ^TMθ$代替$θ^Tθ$，其中$M$是根据我们选择的核函数而不同的一个矩阵。这样做的原因是为了简化计算。 理论上讲，我们也可以在逻辑回归中使用核函数，但是上面使用 $M$来简化计算的方法不适用与逻辑回归，因此计算将非常耗费时间。 在此，我们不介绍最小化支持向量机的代价函数的方法，你可以使用现有的软件包（如liblinear,libsvm等）。在使用这些软件包最小化我们的代价函数之前，我们通常需要编写核函数，并且如果我们使用高斯核函数，那么在使用之前进行特征缩放是非常必要的。 另外，支持向量机也可以不使用核函数，不使用核函数又称为线性核函数(linear kernel)，当我们不采用非常复杂的函数，或者我们的训练集特征非常多而样本非常少的时候，可以采用这种不带核函数的支持向量机。 下面是支持向量机的两个参数$C$和$\sigma$的影响： $C=1/\lambda$ $C$ 较大时，相当于$\lambda$较小，可能会导致过拟合，高方差； $C$ 较小时，相当于$\lambda$较大，可能会导致低拟合，高偏差； $\sigma$较大时，可能会导致低方差，高偏差； $\sigma$较小时，可能会导致低偏差，高方差。 如果你看了本周的编程作业，你就能亲自实现这些想法，并亲眼看到这些效果。这就是利用核函数的支持向量机算法，希望这些关于偏差和方差的讨论，能给你一些对于算法结果预期的直观印象。 使用支持向量机参考视频: 12 - 6 - Using An SVM (21 min).mkv 目前为止，我们已经讨论了SVM比较抽象的层面，在这个视频中我将要讨论到为了运行或者运用SVM。你实际上所需要的一些东西：支持向量机算法，提出了一个特别优化的问题。但是就如在之前的视频中我简单提到的，我真的不建议你自己写软件来求解参数${ {\theta } }$，因此由于今天我们中的很少人，或者其实没有人考虑过自己写代码来转换矩阵，或求一个数的平方根等我们只是知道如何去调用库函数来实现这些功能。同样的，用以解决SVM最优化问题的软件很复杂，且已经有研究者做了很多年数值优化了。因此你提出好的软件库和好的软件包来做这样一些事儿。然后强烈建议使用高优化软件库中的一个，而不是尝试自己落实一些数据。有许多好的软件库，我正好用得最多的两个是liblinear和libsvm，但是真的有很多软件库可以用来做这件事儿。你可以连接许多你可能会用来编写学习算法的主要编程语言。 在高斯核函数之外我们还有其他一些选择，如： 多项式核函数（Polynomial Kernel） 字符串核函数（String kernel） 卡方核函数（ chi-square kernel） 直方图交集核函数（histogram intersection kernel） 等等… 这些核函数的目标也都是根据训练集和地标之间的距离来构建新特征，这些核函数需要满足Mercer’s定理，才能被支持向量机的优化软件正确处理。 多类分类问题 假设我们利用之前介绍的一对多方法来解决一个多类分类问题。如果一共有$k$个类，则我们需要$k$个模型，以及$k$个参数向量${ {\theta } }$。我们同样也可以训练$k$个支持向量机来解决多类分类问题。但是大多数支持向量机软件包都有内置的多类分类功能，我们只要直接使用即可。 尽管你不去写你自己的SVM的优化软件，但是你也需要做几件事： 1、是提出参数$C$的选择。我们在之前的视频中讨论过误差/方差在这方面的性质。 2、你也需要选择内核参数或你想要使用的相似函数，其中一个选择是：我们选择不需要任何内核参数，没有内核参数的理念，也叫线性核函数。因此，如果有人说他使用了线性核的SVM（支持向量机），这就意味这他使用了不带有核函数的SVM（支持向量机）。 从逻辑回归模型，我们得到了支持向量机模型，在两者之间，我们应该如何选择呢？ 下面是一些普遍使用的准则： $n$为特征数，$m$为训练样本数。 (1)如果相较于$m$而言，$n$要大许多，即训练集数据量不够支持我们训练一个复杂的非线性模型，我们选用逻辑回归模型或者不带核函数的支持向量机。 (2)如果$n$较小，而且$m$大小中等，例如$n$在 1-1000 之间，而$m$在10-10000之间，使用高斯核函数的支持向量机。 (3)如果$n$较小，而$m$较大，例如$n$在1-1000之间，而$m$大于50000，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征，然后使用逻辑回归或不带核函数的支持向量机。 值得一提的是，神经网络在以上三种情况下都可能会有较好的表现，但是训练神经网络可能非常慢，选择支持向量机的原因主要在于它的代价函数是凸函数，不存在局部最小值。 今天的SVM包会工作得很好，但是它们仍然会有一些慢。当你有非常非常大的训练集，且用高斯核函数是在这种情况下，我经常会做的是尝试手动地创建，拥有更多的特征变量，然后用逻辑回归或者不带核函数的支持向量机。如果你看到这个幻灯片，看到了逻辑回归，或者不带核函数的支持向量机。在这个两个地方，我把它们放在一起是有原因的。原因是：逻辑回归和不带核函数的支持向量机它们都是非常相似的算法，不管是逻辑回归还是不带核函数的SVM，通常都会做相似的事情，并给出相似的结果。但是根据你实现的情况，其中一个可能会比另一个更加有效。但是在其中一个算法应用的地方，逻辑回归或不带核函数的SVM另一个也很有可能很有效。但是随着SVM的复杂度增加，当你使用不同的内核函数来学习复杂的非线性函数时，这个体系，你知道的，当你有多达1万（10,000）的样本时，也可能是5万（50,000），你的特征变量的数量这是相当大的。那是一个非常常见的体系，也许在这个体系里，不带核函数的支持向量机就会表现得相当突出。你可以做比这困难得多需要逻辑回归的事情。 最后，神经网络使用于什么时候呢？ 对于所有的这些问题，对于所有的这些不同体系一个设计得很好的神经网络也很有可能会非常有效。有一个缺点是，或者说是有时可能不会使用神经网络的原因是：对于许多这样的问题，神经网络训练起来可能会特别慢，但是如果你有一个非常好的SVM实现包，它可能会运行得比较快比神经网络快很多，尽管我们在此之前没有展示，但是事实证明，SVM具有的优化问题，是一种凸优化问题。因此，好的SVM优化软件包总是会找到全局最小值，或者接近它的值。对于SVM你不需要担心局部最优。在实际应用中，局部最优不是神经网络所需要解决的一个重大问题，所以这是你在使用SVM的时候不需要太去担心的一个问题。根据你的问题，神经网络可能会比SVM慢，尤其是在这样一个体系中，至于这里给出的参考，看上去有些模糊，如果你在考虑一些问题，这些参考会有一些模糊，但是我仍然不能完全确定，我是该用这个算法还是改用那个算法，这个没有太大关系，当我遇到机器学习问题的时候，有时它确实不清楚这是否是最好的算法，但是就如在之前的视频中看到的算法确实很重要。但是通常更加重要的是：你有多少数据，你有多熟练是否擅长做误差分析和排除学习算法，指出如何设定新的特征变量和找出其他能决定你学习算法的变量等方面，通常这些方面会比你使用逻辑回归还是SVM这方面更加重要。但是，已经说过了，SVM仍然被广泛认为是一种最强大的学习算法，这是一个体系，包含了什么时候一个有效的方法去学习复杂的非线性函数。因此，实际上与逻辑回归、神经网络、SVM一起使用这些方法来提高学习算法，我认为你会很好地建立很有技术的状态。（编者注：当时GPU计算比较慢，神经网络还不流行。） 机器学习系统对于一个宽泛的应用领域来说，这是另一个在你军械库里非常强大的工具，你可以把它应用到很多地方，如硅谷、在工业、学术等领域建立许多高性能的机器学习系统。 聚类(Clustering)无监督学习：简介参考视频: 13 - 1 - Unsupervised Learning_ Introduction (3 min).mkv 在这个视频中，我将开始介绍聚类算法。这将是一个激动人心的时刻，因为这是我们学习的第一个非监督学习算法。我们将要让计算机学习无标签数据，而不是此前的标签数据。 那么，什么是非监督学习呢？在课程的一开始，我曾简单的介绍过非监督学习，然而，我们还是有必要将其与监督学习做一下比较。 在一个典型的监督学习中，我们有一个有标签的训练集，我们的目标是找到能够区分正样本和负样本的决策边界，在这里的监督学习中，我们有一系列标签，我们需要据此拟合一个假设函数。与此不同的是，在非监督学习中，我们的数据没有附带任何标签，我们拿到的数据就是这样的： 在这里我们有一系列点，却没有标签。因此，我们的训练集可以写成只有$x^{(1)}$,$x^{(2)}$…..一直到$x^{(m)}$。我们没有任何标签$y$。因此，图上画的这些点没有标签信息。也就是说，在非监督学习中，我们需要将一系列无标签的训练数据，输入到一个算法中，然后我们告诉这个算法，快去为我们找找这个数据的内在结构给定数据。我们可能需要某种算法帮助我们寻找一种结构。图上的数据看起来可以分成两个分开的点集（称为簇），一个能够找到我圈出的这些点集的算法，就被称为聚类算法。 这将是我们介绍的第一个非监督学习算法。当然，此后我们还将提到其他类型的非监督学习算法，它们可以为我们找到其他类型的结构或者其他的一些模式，而不只是簇。 我们将先介绍聚类算法。此后，我们将陆续介绍其他算法。那么聚类算法一般用来做什么呢？ 在这门课程的早些时候，我曾经列举过一些应用：比如市场分割。也许你在数据库中存储了许多客户的信息，而你希望将他们分成不同的客户群，这样你可以对不同类型的客户分别销售产品或者分别提供更适合的服务。社交网络分析：事实上有许多研究人员正在研究这样一些内容，他们关注一群人，关注社交网络，例如Facebook，Google+，或者是其他的一些信息，比如说：你经常跟哪些人联系，而这些人又经常给哪些人发邮件，由此找到关系密切的人群。因此，这可能需要另一个聚类算法，你希望用它发现社交网络中关系密切的朋友。我有一个朋友正在研究这个问题，他希望使用聚类算法来更好的组织计算机集群，或者更好的管理数据中心。因为如果你知道数据中心中，那些计算机经常协作工作。那么，你可以重新分配资源，重新布局网络。由此优化数据中心，优化数据通信。 最后，我实际上还在研究如何利用聚类算法了解星系的形成。然后用这个知识，了解一些天文学上的细节问题。好的，这就是聚类算法。这将是我们介绍的第一个非监督学习算法。在下一个视频中，我们将开始介绍一个具体的聚类算法。 K-均值算法参考视频: 13 - 2 - K-Means Algorithm (13 min).mkv K-均值是最普及的聚类算法，算法接受一个未标记的数据集，然后将数据聚类成不同的组。 K-均值是一个迭代算法，假设我们想要将数据聚类成n个组，其方法为: 首先选择$K$个随机的点，称为聚类中心（cluster centroids）； 对于数据集中的每一个数据，按照距离$K$个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。 计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置。 重复步骤2-4直至中心点不再变化。 下面是一个聚类示例： 迭代 1 次 迭代 3 次 迭代 10 次 用$μ^1$,$μ^2$,…,$μ^k$ 来表示聚类中心，用$c^{(1)}$,$c^{(2)}$,…,$c^{(m)}$来存储与第$i$个实例数据最近的聚类中心的索引，K-均值算法的伪代码如下： Repeat { for i = 1 to m c(i) := index (form 1 to K) of cluster centroid closest to x(i) for k = 1 to K μk := average (mean) of points assigned to cluster k }算法分为两个步骤，第一个for循环是赋值步骤，即：对于每一个样例$i$，计算其应该属于的类。第二个for循环是聚类中心的移动，即：对于每一个类$K$，重新计算该类的质心。 K-均值算法也可以很便利地用于将数据分为许多不同组，即使在没有非常明显区分的组群的情况下也可以。下图所示的数据集包含身高和体重两项特征构成的，利用K-均值算法将数据分为三类，用于帮助确定将要生产的T-恤衫的三种尺寸。 优化目标参考视频: 13 - 3 - Optimization Objective (7 min).mkv K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和，因此K-均值的代价函数（又称畸变函数 Distortion function）为： $$J(c^{(1)},...,c^{(m)},μ_1,...,μ_K)=\dfrac {1}{m}\sum^{m}_{i=1}\left\| X^{\left( i\right) }-\mu_{c^{(i)} }\right\| ^{2}$$ 其中${ {\mu }_{ {{c}^{(i)} }} }$代表与${ {x}^{(i)} }$最近的聚类中心点。我们的的优化目标便是找出使得代价函数最小的 $c^{(1)}$,$c^{(2)}$,…,$c^{(m)}$和$μ^1$,$μ^2$,…,$μ^k$： 回顾刚才给出的:K-均值迭代算法，我们知道，第一个循环是用于减小$c^{(i)}$引起的代价，而第二个循环则是用于减小${ {\mu }_{i} }$引起的代价。迭代的过程一定会是每一次迭代都在减小代价函数，不然便是出现了错误。 随机初始化参考视频: 13 - 4 - Random Initialization (8 min).mkv 在运行K-均值算法的之前，我们首先要随机初始化所有的聚类中心点，下面介绍怎样做： 我们应该选择$K&lt;m$，即聚类中心点的个数要小于所有训练集实例的数量 随机选择$K$个训练实例，然后令$K$个聚类中心分别与这$K$个训练实例相等 K-均值的一个问题在于，它有可能会停留在一个局部最小值处，而这取决于初始化的情况。 为了解决这个问题，我们通常需要多次运行K-均值算法，每一次都重新进行随机初始化，最后再比较多次运行K-均值的结果，选择代价函数最小的结果。这种方法在$K$较小的时候（2–10）还是可行的，但是如果$K$较大，这么做也可能不会有明显地改善。 选择聚类数参考视频: 13 - 5 - Choosing the Number of Clusters (8 min).mkv 没有所谓最好的选择聚类数的方法，通常是需要根据不同的问题，人工进行选择的。选择的时候思考我们运用K-均值算法聚类的动机是什么，然后选择能最好服务于该目的标聚类数。 当人们在讨论，选择聚类数目的方法时，有一个可能会谈及的方法叫作“肘部法则”。关于“肘部法则”，我们所需要做的是改变$K$值，也就是聚类类别数目的总数。我们用一个聚类来运行K均值聚类方法。这就意味着，所有的数据都会分到一个聚类里，然后计算成本函数或者计算畸变函数$J$。$K$代表聚类数字。 我们可能会得到一条类似于这样的曲线。像一个人的肘部。这就是“肘部法则”所做的，让我们来看这样一个图，看起来就好像有一个很清楚的肘在那儿。好像人的手臂，如果你伸出你的胳膊，那么这就是你的肩关节、肘关节、手。这就是“肘部法则”。你会发现这种模式，它的畸变值会迅速下降，从1到2，从2到3之后，你会在3的时候达到一个肘点。在此之后，畸变值就下降的非常慢，看起来就像使用3个聚类来进行聚类是正确的，这是因为那个点是曲线的肘点，畸变值下降得很快，$K=3$之后就下降得很慢，那么我们就选$K=3$。当你应用“肘部法则”的时候，如果你得到了一个像上面这样的图，那么这将是一种用来选择聚类个数的合理方法。 例如，我们的 T-恤制造例子中，我们要将用户按照身材聚类，我们可以分成3个尺寸:$S,M,L$，也可以分成5个尺寸$XS,S,M,L,XL$，这样的选择是建立在回答“聚类后我们制造的T-恤是否能较好地适合我们的客户”这个问题的基础上作出的。 聚类参考资料： 1.相似度/距离计算方法总结 (1). 闵可夫斯基距离Minkowski/（其中欧式距离：$p=2$) $dist(X,Y)={ {\left( { {\sum\limits_{i=1}^{n}{\left| { {x}_{i} }-{ {y}_{i} } \right|} }^{p} } \right)}^{\frac{1}{p} }}$ (2). 杰卡德相似系数(Jaccard)： $J(A,B)=\frac{\left| A\cap B \right|}{\left|A\cup B \right|}$ (3). 余弦相似度(cosine similarity)： $n$维向量$x$和$y$的夹角记做$\theta$，根据余弦定理，其余弦值为： $cos (\theta )=\frac{ {{x}^{T} }y}{\left|x \right|\cdot \left| y \right|}=\frac{\sum\limits_{i=1}^{n}{ {{x}_{i} }{ {y}_{i} }} }{\sqrt{\sum\limits_{i=1}^{n}{ {{x}_{i} }^{2} }}\sqrt{\sum\limits_{i=1}^{n}{ {{y}_{i} }^{2} }} }$ (4). Pearson皮尔逊相关系数： ${ {\rho }_{XY} }=\frac{\operatorname{cov}(X,Y)}{ {{\sigma }_{X} }{ {\sigma }_{Y} }}=\frac{E[(X-{ {\mu }_{X} })(Y-{ {\mu }_{Y} })]}{ {{\sigma }_{X} }{ {\sigma }_{Y} }}=\frac{\sum\limits_{i=1}^{n}{(x-{ {\mu }_{X} })(y-{ {\mu }_{Y} })} }{\sqrt{\sum\limits_{i=1}^{n}{ {{(x-{ {\mu }_{X} })}^{2} }} }\sqrt{\sum\limits_{i=1}^{n}{ {{(y-{ {\mu }_{Y} })}^{2} }} }}$ Pearson相关系数即将$x$、$y$坐标向量各自平移到原点后的夹角余弦。 2.聚类的衡量指标 (1). 均一性：$p$ 类似于精确率，一个簇中只包含一个类别的样本，则满足均一性。其实也可以认为就是正确率(每个 聚簇中正确分类的样本数占该聚簇总样本数的比例和) (2). 完整性：$r$ 类似于召回率，同类别样本被归类到相同簇中，则满足完整性;每个聚簇中正确分类的样本数占该类型的总样本数比例的和 (3). V-measure: 均一性和完整性的加权平均 $V = \frac{(1+\beta^2)pr}{\beta^2p+r}$ (4). 轮廓系数 样本$i$的轮廓系数：$s(i)$ 簇内不相似度:计算样本$i$到同簇其它样本的平均距离为$a(i)$，应尽可能小。 簇间不相似度:计算样本$i$到其它簇$C_j$的所有样本的平均距离$b_{ij}$，应尽可能大。 轮廓系数：$s(i)$值越接近1表示样本$i$聚类越合理，越接近-1，表示样本$i$应该分类到 另外的簇中，近似为0，表示样本$i$应该在边界上;所有样本的$s(i)$的均值被成为聚类结果的轮廓系数。 $s(i) = \frac{b(i)-a(i)}{max\{a(i),b(i)\} }$ (5). ARI 数据集$S$共有$N$个元素， 两个聚类结果分别是： $X=\{ {{X}_{1} },{ {X}_{2} },...,{ {X}_{r} }\},Y=\{ {{Y}_{1} },{ {Y}_{2} },...,{ {Y}_{s} }\}$ $X$和$Y$的元素个数为： $a=\{ {{a}_{1} },{ {a}_{2} },...,{ {a}_{r} }\},b=\{ {{b}_{1} },{ {b}_{2} },...,{ {b}_{s} }\}$ 记：${ {n}_{ij} }=\left| { {X}_{i} }\cap { {Y}_{i} } \right|$ $ARI=\frac{\sum\limits_{i,j}{C_{ {{n}_{ij} }}^{2} }-\left[ \left( \sum\limits_{i}{C_{ {{a}_{i} }}^{2} } \right)\cdot \left( \sum\limits_{i}{C_{ {{b}_{i} }}^{2} } \right) \right]/C_{n}^{2} }{\frac{1}{2}\left[ \left( \sum\limits_{i}{C_{ {{a}_{i} }}^{2} } \right)+\left( \sum\limits_{i}{C_{ {{b}_{i} }}^{2} } \right) \right]-\left[ \left( \sum\limits_{i}{C_{ {{a}_{i} }}^{2} } \right)\cdot \left( \sum\limits_{i}{C_{ {{b}_{i} }}^{2} } \right) \right]/C_{n}^{2} }$ 降维(Dimensionality Reduction)动机一：数据压缩参考视频: 14 - 1 - Motivation I_ Data Compression (10 min).mkv 这个视频，我想开始谈论第二种类型的无监督学习问题，称为降维。有几个不同的的原因使你可能想要做降维。一是数据压缩，后面我们会看了一些视频后，数据压缩不仅允许我们压缩数据，因而使用较少的计算机内存或磁盘空间，但它也让我们加快我们的学习算法。 但首先，让我们谈论降维是什么。作为一种生动的例子，我们收集的数据集，有许多，许多特征，我绘制两个在这里。 假设我们未知两个的特征：$x_1$:长度：用厘米表示；$x_2$：是用英寸表示同一物体的长度。 所以，这给了我们高度冗余表示，也许不是两个分开的特征$x_1$和$x_2$，这两个基本的长度度量，也许我们想要做的是减少数据到一维，只有一个数测量这个长度。这个例子似乎有点做作，这里厘米英寸的例子实际上不是那么不切实际的，两者并没有什么不同。 将数据从二维降至一维：假使我们要采用两种不同的仪器来测量一些东西的尺寸，其中一个仪器测量结果的单位是英寸，另一个仪器测量的结果是厘米，我们希望将测量的结果作为我们机器学习的特征。现在的问题的是，两种仪器对同一个东西测量的结果不完全相等（由于误差、精度等），而将两者都作为特征有些重复，因而，我们希望将这个二维的数据降至一维。 从这件事情我看到的东西发生在工业上的事。如果你有几百个或成千上万的特征，它是它这往往容易失去你需要的特征。有时可能有几个不同的工程团队，也许一个工程队给你二百个特征，第二工程队给你另外三百个的特征，第三工程队给你五百个特征，一千多个特征都在一起，它实际上会变得非常困难，去跟踪你知道的那些特征，你从那些工程队得到的。其实不想有高度冗余的特征一样。 多年我一直在研究直升飞机自动驾驶。诸如此类。如果你想测量——如果你想做，你知道，做一个调查或做这些不同飞行员的测试——你可能有一个特征：$x_1$，这也许是他们的技能（直升机飞行员），也许$x_2$可能是飞行员的爱好。这是表示他们是否喜欢飞行，也许这两个特征将高度相关。你真正关心的可能是这条红线的方向，不同的特征，决定飞行员的能力。 将数据从三维降至二维：这个例子中我们要将一个三维的特征向量降至一个二维的特征向量。过程是与上面类似的，我们将三维向量投射到一个二维的平面上，强迫使得所有的数据都在同一个平面上，降至二维的特征向量。 这样的处理过程可以被用于把任何维度的数据降到任何想要的维度，例如将1000维的特征降至100维。 正如我们所看到的，最后，这将使我们能够使我们的一些学习算法运行也较晚，但我们会在以后的视频提到它。 动机二：数据可视化参考视频: 14 - 2 - Motivation II_ Visualization (6 min).mkv 在许多及其学习问题中，如果我们能将数据可视化，我们便能寻找到一个更好的解决方案，降维可以帮助我们。 假使我们有有关于许多不同国家的数据，每一个特征向量都有50个特征（如GDP，人均GDP，平均寿命等）。如果要将这个50维的数据可视化是不可能的。使用降维的方法将其降至2维，我们便可以将其可视化了。 这样做的问题在于，降维的算法只负责减少维数，新产生的特征的意义就必须由我们自己去发现了。 主成分分析问题参考视频: 14 - 3 - Principal Component Analysis Problem Formulation (9 min). mkv 主成分分析(PCA)是最常见的降维算法。 在PCA中，我们要做的是找到一个方向向量（Vector direction），当我们把所有的数据都投射到该向量上时，我们希望投射平均均方误差能尽可能地小。方向向量是一个经过原点的向量，而投射误差是从特征向量向该方向向量作垂线的长度。 下面给出主成分分析问题的描述： 问题是要将$n$维数据降至$k$维，目标是找到向量$u^{(1)}$,$u^{(2)}$,…,$u^{(k)}$使得总的投射误差最小。主成分分析与线性回顾的比较： 主成分分析与线性回归是两种不同的算法。主成分分析最小化的是投射误差（Projected Error），而线性回归尝试的是最小化预测误差。线性回归的目的是预测结果，而主成分分析不作任何预测。 上图中，左边的是线性回归的误差（垂直于横轴投影），右边则是主要成分分析的误差（垂直于红线投影）。 PCA将$n$个特征降维到$k$个，可以用来进行数据压缩，如果100维的向量最后可以用10维来表示，那么压缩率为90%。同样图像处理领域的KL变换使用PCA做图像压缩。但PCA 要保证降维后，还要保证数据的特性损失最小。 PCA技术的一大好处是对数据进行降维的处理。我们可以对新求出的“主元”向量的重要性进行排序，根据需要取前面最重要的部分，将后面的维数省去，可以达到降维从而简化模型或是对数据进行压缩的效果。同时最大程度的保持了原有数据的信息。 PCA技术的一个很大的优点是，它是完全无参数限制的。在PCA的计算过程中完全不需要人为的设定参数或是根据任何经验模型对计算进行干预，最后的结果只与数据相关，与用户是独立的。 但是，这一点同时也可以看作是缺点。如果用户对观测对象有一定的先验知识，掌握了数据的一些特征，却无法通过参数化等方法对处理过程进行干预，可能会得不到预期的效果，效率也不高。 主成分分析算法参考视频: 14 - 4 - Principal Component Analysis Algorithm (15 min).mkv PCA 减少$n$维到$k$维： 第一步是均值归一化。我们需要计算出所有特征的均值，然后令 $x_j= x_j-μ_j$。如果特征是在不同的数量级上，我们还需要将其除以标准差 $σ^2$。 第二步是计算协方差矩阵（covariance matrix）$Σ$： $\sum=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}$ 第三步是计算协方差矩阵$Σ$的特征向量（eigenvectors）: 在 Octave 里我们可以利用奇异值分解（singular value decomposition）来求解，[U, S, V]= svd(sigma)。 $$Sigma=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}$$ 对于一个 $n×n$维度的矩阵，上式中的$U$是一个具有与数据之间最小投射误差的方向向量构成的矩阵。如果我们希望将数据从$n$维降至$k$维，我们只需要从$U$中选取前$k$个向量，获得一个$n×k$维度的矩阵，我们用$U_{reduce}$表示，然后通过如下计算获得要求的新特征向量$z^{(i)}$:$$z^{(i)}=U^{T}_{reduce}*x^{(i)}$$ 其中$x$是$n×1$维的，因此结果为$k×1$维度。注，我们不对方差特征进行处理。 选择主成分的数量参考视频: 14 - 5 - Choosing The Number Of Principal Components (13 min).mkv 主要成分分析是减少投射的平均均方误差： 训练集的方差为：$\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }\right\| ^{2}$ 我们希望在平均均方误差与训练集方差的比例尽可能小的情况下选择尽可能小的$k$值。 如果我们希望这个比例小于1%，就意味着原本数据的偏差有99%都保留下来了，如果我们选择保留95%的偏差，便能非常显著地降低模型中特征的维度了。 我们可以先令$k=1$，然后进行主要成分分析，获得$U_{reduce}$和$z$，然后计算比例是否小于1%。如果不是的话再令$k=2$，如此类推，直到找到可以使得比例小于1%的最小$k$ 值（原因是各个特征之间通常情况存在某种相关性）。 还有一些更好的方式来选择$k$，当我们在Octave中调用“svd”函数的时候，我们获得三个参数：[U, S, V] = svd(sigma)。 其中的$S$是一个$n×n$的矩阵，只有对角线上有值，而其它单元都是0，我们可以使用这个矩阵来计算平均均方误差与训练集方差的比例： $$\dfrac {\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }-x^{\left( i\right) }_{approx}\right\| ^{2} }{\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{(i)}\right\| ^{2} }=1-\dfrac {\Sigma^{k}_{i=1}S_{ii} }{\Sigma^{m}_{i=1}S_{ii} }\leq 1\%$$ 也就是：$$\frac {\Sigma^{k}_{i=1}s_{ii} }{\Sigma^{n}_{i=1}s_{ii} }\geq0.99$$ 在压缩过数据后，我们可以采用如下方法来近似地获得原有的特征：$$x^{\left( i\right) }_{approx}=U_{reduce}z^{(i)}$$ 重建的压缩表示参考视频: 14 - 6 - Reconstruction from Compressed Representation (4 min).mkv 在以前的视频中，我谈论PCA作为压缩算法。在那里你可能需要把1000维的数据压缩100维特征，或具有三维数据压缩到一二维表示。所以，如果这是一个压缩算法，应该能回到这个压缩表示，回到你原有的高维数据的一种近似。 所以，给定的$z^{(i)}$，这可能100维，怎么回到你原来的表示$x^{(i)}$，这可能是1000维的数组？ PCA算法，我们可能有一个这样的样本。如图中样本$x^{(1)}$,$x^{(2)}$。我们做的是，我们把这些样本投射到图中这个一维平面。然后现在我们需要只使用一个实数，比如$z^{(1)}$，指定这些点的位置后他们被投射到这一个三维曲面。给定一个点$z^{(1)}$，我们怎么能回去这个原始的二维空间呢？$x$为2维，$z$为1维，$z=U^{T}_{reduce}x$，相反的方程为：$x_{appox}=U_{reduce}\cdot z$,$x_{appox}\approx x$。如图： 如你所知，这是一个漂亮的与原始数据相当相似。所以，这就是你从低维表示$z$回到未压缩的表示。我们得到的数据的一个之间你的原始数据 $x$，我们也把这个过程称为重建原始数据。 当我们认为试图重建从压缩表示 $x$ 的初始值。所以，给定未标记的数据集，您现在知道如何应用PCA，你的带高维特征$x$和映射到这的低维表示$z$。这个视频，希望你现在也知道如何采取这些低维表示$z$，映射到备份到一个近似你原有的高维数据。 现在你知道如何实施应用PCA，我们将要做的事是谈论一些技术在实际使用PCA很好，特别是，在接下来的视频中，我想谈一谈关于如何选择$k$。 主成分分析法的应用建议参考视频: 14 - 7 - Advice for Applying PCA (13 min).mkv 假使我们正在针对一张 100×100像素的图片进行某个计算机视觉的机器学习，即总共有10000 个特征。 第一步是运用主要成分分析将数据压缩至1000个特征 然后对训练集运行学习算法 在预测时，采用之前学习而来的$U_{reduce}$将输入的特征$x$转换成特征向量$z$，然后再进行预测 注：如果我们有交叉验证集合测试集，也采用对训练集学习而来的$U_{reduce}$。 错误的主要成分分析情况：一个常见错误使用主要成分分析的情况是，将其用于减少过拟合（减少了特征的数量）。这样做非常不好，不如尝试正则化处理。原因在于主要成分分析只是近似地丢弃掉一些特征，它并不考虑任何与结果变量有关的信息，因此可能会丢失非常重要的特征。然而当我们进行正则化处理时，会考虑到结果变量，不会丢掉重要的数据。 另一个常见的错误是，默认地将主要成分分析作为学习过程中的一部分，这虽然很多时候有效果，最好还是从所有原始特征开始，只在有必要的时候（算法运行太慢或者占用太多内存）才考虑采用主要成分分析。 异常检测(Anomaly Detection)问题的动机参考文档: 15 - 1 - Problem Motivation (8 min).mkv 在接下来的一系列视频中，我将向大家介绍异常检测(Anomaly detection)问题。这是机器学习算法的一个常见应用。这种算法的一个有趣之处在于：它虽然主要用于非监督学习问题，但从某些角度看，它又类似于一些监督学习问题。 什么是异常检测呢？为了解释这个概念，让我举一个例子吧： 假想你是一个飞机引擎制造商，当你生产的飞机引擎从生产线上流出时，你需要进行QA(质量控制测试)，而作为这个测试的一部分，你测量了飞机引擎的一些特征变量，比如引擎运转时产生的热量，或者引擎的振动等等。 这样一来，你就有了一个数据集，从$x^{(1)}$到$x^{(m)}$，如果你生产了$m$个引擎的话，你将这些数据绘制成图表，看起来就是这个样子： 这里的每个点、每个叉，都是你的无标签数据。这样，异常检测问题可以定义如下：我们假设后来有一天，你有一个新的飞机引擎从生产线上流出，而你的新飞机引擎有特征变量$x_{test}$。所谓的异常检测问题就是：我们希望知道这个新的飞机引擎是否有某种异常，或者说，我们希望判断这个引擎是否需要进一步测试。因为，如果它看起来像一个正常的引擎，那么我们可以直接将它运送到客户那里，而不需要进一步的测试。 给定数据集 $x^{(1)},x^{(2)},..,x^{(m)}$，我们假使数据集是正常的，我们希望知道新的数据 $x_{test}$ 是不是异常的，即这个测试数据不属于该组数据的几率如何。我们所构建的模型应该能根据该测试数据的位置告诉我们其属于一组数据的可能性 $p(x)$。 上图中，在蓝色圈内的数据属于该组数据的可能性较高，而越是偏远的数据，其属于该组数据的可能性就越低。 这种方法称为密度估计，表达如下： $$if \quad p(x)\begin{cases}&lt; \varepsilon &amp; anomaly \ =\varepsilon &amp; normal\end{cases}$$ 欺诈检测： $x^{(i)} = {用户的第i个活动特征}$ 模型$p(x)$ 为我们其属于一组数据的可能性，通过$p(x) &lt; \varepsilon$检测非正常用户。 异常检测主要用来识别欺骗。例如在线采集而来的有关用户的数据，一个特征向量中可能会包含如：用户多久登录一次，访问过的页面，在论坛发布的帖子数量，甚至是打字速度等。尝试根据这些特征构建一个模型，可以用这个模型来识别那些不符合该模式的用户。 再一个例子是检测一个数据中心，特征可能包含：内存使用情况，被访问的磁盘数量，CPU的负载，网络的通信量等。根据这些特征可以构建一个模型，用来判断某些计算机是不是有可能出错了。 高斯分布参考视频: 15 - 2 - Gaussian Distribution (10 min).mkv 在这个视频中，我将介绍高斯分布，也称为正态分布。回顾高斯分布的基本知识。 通常如果我们认为变量 $x$ 符合高斯分布 $x \sim N(\mu, \sigma^2)$则其概率密度函数为： $p(x,\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$ 我们可以利用已有的数据来预测总体中的$μ$和$σ^2$的计算方法如下： $\mu=\frac{1}{m}\sum\limits_{i=1}^{m}x^{(i)}$ $\sigma^2=\frac{1}{m}\sum\limits_{i=1}^{m}(x^{(i)}-\mu)^2$ 高斯分布样例： 注：机器学习中对于方差我们通常只除以$m$而非统计学中的$(m-1)$。这里顺便提一下，在实际使用中，到底是选择使用$1/m$还是$1/(m-1)$其实区别很小，只要你有一个还算大的训练集，在机器学习领域大部分人更习惯使用$1/m$这个版本的公式。这两个版本的公式在理论特性和数学特性上稍有不同，但是在实际使用中，他们的区别甚小，几乎可以忽略不计。 算法参考视频: 15 - 3 - Algorithm (12 min).mkv 在本节视频中，我将应用高斯分布开发异常检测算法。 异常检测算法： 对于给定的数据集 $x^{(1)},x^{(2)},...,x^{(m)}$，我们要针对每一个特征计算 $\mu$ 和 $\sigma^2$ 的估计值。 $\mu_j=\frac{1}{m}\sum\limits_{i=1}^{m}x_j^{(i)}$ $\sigma_j^2=\frac{1}{m}\sum\limits_{i=1}^m(x_j^{(i)}-\mu_j)^2$ 一旦我们获得了平均值和方差的估计值，给定新的一个训练实例，根据模型计算 $p(x)$： $p(x)=\prod\limits_{j=1}^np(x_j;\mu_j,\sigma_j^2)=\prod\limits_{j=1}^1\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$ 当$p(x) &lt; \varepsilon$时，为异常。 下图是一个由两个特征的训练集，以及特征的分布情况： 下面的三维图表表示的是密度估计函数，$z$轴为根据两个特征的值所估计$p(x)$值： 我们选择一个$\varepsilon$，将$p(x) = \varepsilon$作为我们的判定边界，当$p(x) > \varepsilon$时预测数据为正常数据，否则为异常。 在这段视频中，我们介绍了如何拟合$p(x)$，也就是 $x$的概率值，以开发出一种异常检测算法。同时，在这节课中，我们也给出了通过给出的数据集拟合参数，进行参数估计，得到参数 $\mu$ 和 $\sigma$，然后检测新的样本，确定新样本是否是异常。 在接下来的课程中，我们将深入研究这一算法，同时更深入地介绍，怎样让算法工作地更加有效。 开发和评价一个异常检测系统参考视频: 15 - 4 - Developing and Evaluating an Anomaly Detection System (13 min). mkv 异常检测算法是一个非监督学习算法，意味着我们无法根据结果变量 $ y$ 的值来告诉我们数据是否真的是异常的。我们需要另一种方法来帮助检验算法是否有效。当我们开发一个异常检测系统时，我们从带标记（异常或正常）的数据着手，我们从其中选择一部分正常数据用于构建训练集，然后用剩下的正常数据和异常数据混合的数据构成交叉检验集和测试集。 例如：我们有10000台正常引擎的数据，有20台异常引擎的数据。 我们这样分配数据： 6000台正常引擎的数据作为训练集 2000台正常引擎和10台异常引擎的数据作为交叉检验集 2000台正常引擎和10台异常引擎的数据作为测试集 具体的评价方法如下： 根据测试集数据，我们估计特征的平均值和方差并构建$p(x)$函数 对交叉检验集，我们尝试使用不同的$\varepsilon$值作为阀值，并预测数据是否异常，根据$F1$值或者查准率与查全率的比例来选择 $\varepsilon$ 选出 $\varepsilon$ 后，针对测试集进行预测，计算异常检验系统的$F1$值，或者查准率与查全率之比 异常检测与监督学习对比参考视频: 15 - 5 - Anomaly Detection vs. Supervised Learning (8 min).mkv 之前我们构建的异常检测系统也使用了带标记的数据，与监督学习有些相似，下面的对比有助于选择采用监督学习还是异常检测： 两者比较： 异常检测 监督学习 非常少量的正向类（异常数据 $y=1$）, 大量的负向类（$y=0$） 同时有大量的正向类和负向类 许多不同种类的异常，非常难。根据非常 少量的正向类数据来训练算法。 有足够多的正向类实例，足够用于训练 算法，未来遇到的正向类实例可能与训练集中的非常近似。 未来遇到的异常可能与已掌握的异常、非常的不同。 例如： 欺诈行为检测 生产（例如飞机引擎）检测数据中心的计算机运行状况 例如：邮件过滤器 天气预报 肿瘤分类 希望这节课能让你明白一个学习问题的什么样的特征，能让你把这个问题当做是一个异常检测，或者是一个监督学习的问题。另外，对于很多技术公司可能会遇到的一些问题，通常来说，正样本的数量很少，甚至有时候是0，也就是说，出现了太多没见过的不同的异常类型，那么对于这些问题，通常应该使用的算法就是异常检测算法。 选择特征参考视频: 15 - 6 - Choosing What Features to Use (12 min).mkv 对于异常检测算法，我们使用的特征是至关重要的，下面谈谈如何选择特征： 异常检测假设特征符合高斯分布，如果数据的分布不是高斯分布，异常检测算法也能够工作，但是最好还是将数据转换成高斯分布，例如使用对数函数：$x= log(x+c)$，其中 $c$ 为非负常数； 或者 $x=x^c$，$c$为 0-1 之间的一个分数，等方法。(编者注：在python中，通常用np.log1p()函数，$log1p$就是 $log(x+1)$，可以避免出现负数结果，反向函数就是np.expm1()) 误差分析： 一个常见的问题是一些异常的数据可能也会有较高的$p(x)$值，因而被算法认为是正常的。这种情况下误差分析能够帮助我们，我们可以分析那些被算法错误预测为正常的数据，观察能否找出一些问题。我们可能能从问题中发现我们需要增加一些新的特征，增加这些新特征后获得的新算法能够帮助我们更好地进行异常检测。 异常检测误差分析： 我们通常可以通过将一些相关的特征进行组合，来获得一些新的更好的特征（异常数据的该特征值异常地大或小），例如，在检测数据中心的计算机状况的例子中，我们可以用CPU负载与网络通信量的比例作为一个新的特征，如果该值异常地大，便有可能意味着该服务器是陷入了一些问题中。 在这段视频中，我们介绍了如何选择特征，以及对特征进行一些小小的转换，让数据更像正态分布，然后再把数据输入异常检测算法。同时也介绍了建立特征时，进行的误差分析方法，来捕捉各种异常的可能。希望你通过这些方法，能够了解如何选择好的特征变量，从而帮助你的异常检测算法，捕捉到各种不同的异常情况。 多元高斯分布（选修）参考视频: 15 - 7 - Multivariate Gaussian Distribution (Optional) (14 min).mkv 假使我们有两个相关的特征，而且这两个特征的值域范围比较宽，这种情况下，一般的高斯分布模型可能不能很好地识别异常数据。其原因在于，一般的高斯分布模型尝试的是去同时抓住两个特征的偏差，因此创造出一个比较大的判定边界。 下图中是两个相关特征，洋红色的线（根据ε的不同其范围可大可小）是一般的高斯分布模型获得的判定边界，很明显绿色的X所代表的数据点很可能是异常值，但是其$p(x)$值却仍然在正常范围内。多元高斯分布将创建像图中蓝色曲线所示的判定边界。 在一般的高斯分布模型中，我们计算 $p(x)$ 的方法是：通过分别计算每个特征对应的几率然后将其累乘起来，在多元高斯分布模型中，我们将构建特征的协方差矩阵，用所有的特征一起来计算 $p(x)$。 我们首先计算所有特征的平均值，然后再计算协方差矩阵： $p(x)=\prod_{j=1}^np(x_j;\mu,\sigma_j^2)=\prod_{j=1}^n\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$ $\mu=\frac{1}{m}\sum_{i=1}^mx^{(i)}$ $\Sigma = \frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T=\frac{1}{m}(X-\mu)^T(X-\mu)$ 注:其中$\mu $ 是一个向量，其每一个单元都是原特征矩阵中一行数据的均值。最后我们计算多元高斯分布的$p\left( x \right)$: $p(x)=\frac{1}{(2\pi)^{\frac{n}{2} }|\Sigma|^{\frac{1}{2} }}exp\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right)$ 其中： $|\Sigma|$是定矩阵，在 **Octave** 中用 `det(sigma)`计算 $\Sigma^{-1}$ 是逆矩阵，下面我们来看看协方差矩阵是如何影响模型的： 上图是5个不同的模型，从左往右依次分析： 是一个一般的高斯分布模型 通过协方差矩阵，令特征1拥有较小的偏差，同时保持特征2的偏差 通过协方差矩阵，令特征2拥有较大的偏差，同时保持特征1的偏差 通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的正相关性 通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的负相关性 多元高斯分布模型与原高斯分布模型的关系： 可以证明的是，原本的高斯分布模型是多元高斯分布模型的一个子集，即像上图中的第1、2、3，3个例子所示，如果协方差矩阵只在对角线的单位上有非零的值时，即为原本的高斯分布模型了。 原高斯分布模型和多元高斯分布模型的比较： 原高斯分布模型 多元高斯分布模型 不能捕捉特征之间的相关性 但可以通过将特征进行组合的方法来解决 自动捕捉特征之间的相关性 计算代价低，能适应大规模的特征 计算代价较高 训练集较小时也同样适用 必须要有 $m>n$，不然的话协方差矩阵$\Sigma$不可逆的，通常需要 $m>10n$ 另外特征冗余也会导致协方差矩阵不可逆 原高斯分布模型被广泛使用着，如果特征之间在某种程度上存在相互关联的情况，我们可以通过构造新新特征的方法来捕捉这些相关性。 如果训练集不是太大，并且没有太多的特征，我们可以使用多元高斯分布模型。 使用多元高斯分布进行异常检测（可选）参考视频: 15 - 8 - Anomaly Detection using the Multivariate Gaussian Distribution (Optional) (14 min).mkv 在我们谈到的最后一个视频，关于多元高斯分布，看到的一些建立的各种分布模型，当你改变参数，$\mu$ 和 $\Sigma$。在这段视频中，让我们用这些想法，并应用它们制定一个不同的异常检测算法。 要回顾一下多元高斯分布和多元正态分布： 分布有两个参数， $\mu$ 和 $\Sigma$。其中$\mu$这一个$n$维向量和 $\Sigma$ 的协方差矩阵，是一种$n\times n$的矩阵。而这里的公式$x$的概率，如按 $\mu$ 和参数化 $\Sigma$，和你的变量 $\mu$ 和 $\Sigma$，你可以得到一个范围的不同分布一样，你知道的，这些都是三个样本，那些我们在以前的视频看过了。 因此，让我们谈谈参数拟合或参数估计问题： 我有一组样本${ {{ x^{(1)},x^{(2)},...,x^{(m)} } } }$是一个$n$维向量，我想我的样本来自一个多元高斯分布。我如何尝试估计我的参数 $\mu$ 和 $\Sigma$ 以及标准公式？ 估计他们是你设置 $\mu$ 是你的训练样本的平均值。 $\mu=\frac{1}{m}\sum_{i=1}^{m}x^{(i)}$ 并设置$\Sigma$： $\Sigma=\frac{1}{m}\sum_{i=1}^{m}(x^{(i)}-\mu)(x^{(i)}-\mu)^T$ 这其实只是当我们使用PCA算法时候，有 $\Sigma$ 时写出来。所以你只需插入上述两个公式，这会给你你估计的参数 $\mu$ 和你估计的参数 $\Sigma$。所以，这里给出的数据集是你如何估计 $\mu$ 和 $\Sigma$。让我们以这种方法而只需将其插入到异常检测算法。那么，我们如何把所有这一切共同开发一个异常检测算法？ 首先，我们把我们的训练集，和我们的拟合模型，我们计算$p(x)$，要知道，设定$\mu$和描述的一样$\Sigma$。 如图，该分布在中央最多，越到外面的圈的范围越小。 并在该点是出路这里的概率非常低。 原始模型与多元高斯模型的关系如图： 其中：协方差矩阵$\Sigma$为： 原始模型和多元高斯分布比较如图： 推荐系统(Recommender Systems)问题形式化参考视频: 16 - 1 - Problem Formulation (8 min).mkv 在接下来的视频中，我想讲一下推荐系统。我想讲推荐系统有两个原因： 第一、仅仅因为它是机器学习中的一个重要的应用。在过去几年，我偶尔访问硅谷不同的技术公司，我常和工作在这儿致力于机器学习应用的人们聊天，我常问他们，最重要的机器学习的应用是什么，或者，你最想改进的机器学习应用有哪些。我最常听到的答案是推荐系统。现在，在硅谷有很多团体试图建立很好的推荐系统。因此，如果你考虑网站像亚马逊，或网飞公司或易趣，或iTunes Genius，有很多的网站或系统试图推荐新产品给用户。如，亚马逊推荐新书给你，网飞公司试图推荐新电影给你，等等。这些推荐系统，根据浏览你过去买过什么书，或过去评价过什么电影来判断。这些系统会带来很大一部分收入，比如为亚马逊和像网飞这样的公司。因此，对推荐系统性能的改善，将对这些企业的有实质性和直接的影响。 推荐系统是个有趣的问题，在学术机器学习中因此，我们可以去参加一个学术机器学习会议，推荐系统问题实际上受到很少的关注，或者，至少在学术界它占了很小的份额。但是，如果你看正在发生的事情，许多有能力构建这些系统的科技企业，他们似乎在很多企业中占据很高的优先级。这是我为什么在这节课讨论它的原因之一。 我想讨论推荐系统地第二个原因是：这个班视频的最后几集我想讨论机器学习中的一些大思想，并和大家分享。这节课我们也看到了，对机器学习来说，特征是很重要的，你所选择的特征，将对你学习算法的性能有很大的影响。因此，在机器学习中有一种大思想，它针对一些问题，可能并不是所有的问题，而是一些问题，有算法可以为你自动学习一套好的特征。因此，不要试图手动设计，而手写代码这是目前为止我们常干的。有一些设置，你可以有一个算法，仅仅学习其使用的特征，推荐系统就是类型设置的一个例子。还有很多其它的，但是通过推荐系统，我们将领略一小部分特征学习的思想，至少，你将能够了解到这方面的一个例子，我认为，机器学习中的大思想也是这样。因此，让我们开始讨论推荐系统问题形式化。 我们从一个例子开始定义推荐系统的问题。 假使我们是一个电影供应商，我们有 5 部电影和 4 个用户，我们要求用户为电影打分。 前三部电影是爱情片，后两部则是动作片，我们可以看出Alice和Bob似乎更倾向与爱情片， 而 Carol 和 Dave 似乎更倾向与动作片。并且没有一个用户给所有的电影都打过分。我们希望构建一个算法来预测他们每个人可能会给他们没看过的电影打多少分，并以此作为推荐的依据。 下面引入一些标记： $n_u$ 代表用户的数量 $n_m$ 代表电影的数量 $r(i, j)$ 如果用户j给电影 $i$ 评过分则 $r(i,j)=1$ $y^{(i, j)}$ 代表用户 $j$ 给电影$i$的评分 $m_j$代表用户 $j$ 评过分的电影的总数 基于内容的推荐系统参考视频: 16 - 2 - Content Based Recommendations (15 min).mkv 在一个基于内容的推荐系统算法中，我们假设对于我们希望推荐的东西有一些数据，这些数据是有关这些东西的特征。 在我们的例子中，我们可以假设每部电影都有两个特征，如$x_1$代表电影的浪漫程度，$x_2$ 代表电影的动作程度。 则每部电影都有一个特征向量，如$x^{(1)}$是第一部电影的特征向量为[0.9 0]。 下面我们要基于这些特征来构建一个推荐系统算法。假设我们采用线性回归模型，我们可以针对每一个用户都训练一个线性回归模型，如${ {\theta }^{(1)} }$是第一个用户的模型的参数。于是，我们有： $\theta^{(j)}$用户 $j$ 的参数向量 $x^{(i)}$电影 $i$ 的特征向量 对于用户 $j$ 和电影 $i$，我们预测评分为：$(\theta^{(j)})^T x^{(i)}$ 代价函数 针对用户 $j$，该线性回归模型的代价为预测误差的平方和，加上正则化项：$$\min_{\theta (j)}\frac{1}{2}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\left(\theta_{k}^{(j)}\right)^2$$ 其中 $i:r(i,j)$表示我们只计算那些用户 $j$ 评过分的电影。在一般的线性回归模型中，误差项和正则项应该都是乘以$1/2m$，在这里我们将$m$去掉。并且我们不对方差项$\theta_0$进行正则化处理。 上面的代价函数只是针对一个用户的，为了学习所有用户，我们将所有用户的代价函数求和：$$\min_{\theta^{(1)},…,\theta^{(n_u)} } \frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2$$如果我们要用梯度下降法来求解最优解，我们计算代价函数的偏导数后得到梯度下降的更新公式为： $$\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)} \quad (\text{for} , k = 0)$$ $$\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)}+\lambda\theta_k^{(j)}\right) \quad (\text{for} , k\neq 0)$$ 协同过滤参考视频: 16 - 3 - Collaborative Filtering (10 min).mkv 在之前的基于内容的推荐系统中，对于每一部电影，我们都掌握了可用的特征，使用这些特征训练出了每一个用户的参数。相反地，如果我们拥有用户的参数，我们可以学习得出电影的特征。 $$\mathop{min}\limits_{x^{(1)},…,x^{(n_m)} }\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j{r(i,j)=1} }((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2$$但是如果我们既没有用户的参数，也没有电影的特征，这两种方法都不可行了。协同过滤算法可以同时学习这两者。 我们的优化目标便改为同时针对$x$和$\theta$进行。$$J(x^{(1)},…x^{(n_m)},\theta^{(1)},…,\theta^{(n_u)})=\frac{1}{2}\sum_{(i:j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2$$ 对代价函数求偏导数的结果如下： $$x_k^{(i)}:=x_k^{(i)}-\alpha\left(\sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\theta_k^{j}+\lambda x_k^{(i)}\right)$$ $$\theta_k^{(i)}:=\theta_k^{(i)}-\alpha\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}x_k^{(i)}+\lambda \theta_k^{(j)}\right)$$ 注：在协同过滤从算法中，我们通常不使用方差项，如果需要的话，算法会自动学得。协同过滤算法使用步骤如下： 初始 $x^{(1)},x^{(1)},...x^{(nm)},\ \theta^{(1)},\theta^{(2)},...,\theta^{(n_u)}$为一些随机小值 使用梯度下降算法最小化代价函数 在训练完算法后，我们预测$(\theta^{(j)})^Tx^{(i)}$为用户 $j$ 给电影 $i$ 的评分 通过这个学习过程获得的特征矩阵包含了有关电影的重要数据，这些数据不总是人能读懂的，但是我们可以用这些数据作为给用户推荐电影的依据。 例如，如果一位用户正在观看电影 $x^{(i)}$，我们可以寻找另一部电影$x^{(j)}$，依据两部电影的特征向量之间的距离$\left\| { {x}^{(i)} }-{ {x}^{(j)} } \right\|$的大小。 协同过滤算法参考视频: 16 - 4 - Collaborative Filtering Algorithm (9 min).mkv 协同过滤优化目标： 给定$x^{(1)},...,x^{(n_m)}$，估计$\theta^{(1)},...,\theta^{(n_u)}$：$$\min_{\theta^{(1)},…,\theta^{(n_u)} }\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2$$ 给定$\theta^{(1)},...,\theta^{(n_u)}$，估计$x^{(1)},...,x^{(n_m)}$： 同时最小化$x^{(1)},...,x^{(n_m)}$和$\theta^{(1)},...,\theta^{(n_u)}$：$$J(x^{(1)},…,x^{(n_m)},\theta^{(1)},…,\theta^{(n_u)})=\frac{1}{2}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2$$ $$\min_{x^{(1)},…,x^{(n_m)} \\ \theta^{(1)},…,\theta^{(n_u)} }J(x^{(1)},…,x^{(n_m)},\theta^{(1)},…,\theta^{(n_u)})$$ 向量化：低秩矩阵分解参考视频: 16 - 5 - Vectorization_ Low Rank Matrix Factorization (8 min).mkv 在上几节视频中，我们谈到了协同过滤算法，本节视频中我将会讲到有关该算法的向量化实现，以及说说有关该算法你可以做的其他事情。 举例子： 当给出一件产品时，你能否找到与之相关的其它产品。 一位用户最近看上一件产品，有没有其它相关的产品，你可以推荐给他。 我将要做的是：实现一种选择的方法，写出协同过滤算法的预测情况。 我们有关于五部电影的数据集，我将要做的是，将这些用户的电影评分，进行分组并存到一个矩阵中。 我们有五部电影，以及四位用户，那么 这个矩阵 $Y$ 就是一个5行4列的矩阵，它将这些电影的用户评分数据都存在矩阵里： Movie Alice (1) Bob (2) Carol (3) Dave (4) Love at last 5 5 0 0 Romance forever 5 ? ? 0 Cute puppies of love ? 4 0 ? Nonstop car chases 0 0 5 4 Swords vs. karate 0 0 5 ? 推出评分： 找到相关影片： 现在既然你已经对特征参数向量进行了学习，那么我们就会有一个很方便的方法来度量两部电影之间的相似性。例如说：电影 $i$ 有一个特征向量$x^{(i)}$，你是否能找到一部不同的电影 $j$，保证两部电影的特征向量之间的距离$x^{(i)}$和$x^{(j)}$很小，那就能很有力地表明电影$i$和电影 $j$ 在某种程度上有相似，至少在某种意义上，某些人喜欢电影 $i$，或许更有可能也对电影 $j$ 感兴趣。总结一下，当用户在看某部电影 $i$ 的时候，如果你想找5部与电影非常相似的电影，为了能给用户推荐5部新电影，你需要做的是找出电影 $j$，在这些不同的电影中与我们要找的电影 $i$ 的距离最小，这样你就能给你的用户推荐几部不同的电影了。 通过这个方法，希望你能知道，如何进行一个向量化的计算来对所有的用户和所有的电影进行评分计算。同时希望你也能掌握，通过学习特征参数，来找到相关电影和产品的方法。 推行工作上的细节：均值归一化参考视频: 16 - 6 - Implementational Detail_ Mean Normalization (9 min).mkv 让我们来看下面的用户评分数据： 如果我们新增一个用户 Eve，并且 Eve 没有为任何电影评分，那么我们以什么为依据为Eve推荐电影呢？ 我们首先需要对结果 $Y $矩阵进行均值归一化处理，将每一个用户对某一部电影的评分减去所有用户对该电影评分的平均值： 然后我们利用这个新的 $Y$ 矩阵来训练算法。如果我们要用新训练出的算法来预测评分，则需要将平均值重新加回去，预测$(\theta^{(j)})^T x^{(i)}+\mu_i$，对于Eve，我们的新模型会认为她给每部电影的评分都是该电影的平均分。 大规模机器学习(Large Scale Machine Learning)大型数据集的学习参考视频: 17 - 1 - Learning With Large Datasets (6 min).mkv 如果我们有一个低方差的模型，增加数据集的规模可以帮助你获得更好的结果。我们应该怎样应对一个有100万条记录的训练集？ 以线性回归模型为例，每一次梯度下降迭代，我们都需要计算训练集的误差的平方和，如果我们的学习算法需要有20次迭代，这便已经是非常大的计算代价。 首先应该做的事是去检查一个这么大规模的训练集是否真的必要，也许我们只用1000个训练集也能获得较好的效果，我们可以绘制学习曲线来帮助判断。 随机梯度下降法参考视频: 17 - 2 - Stochastic Gradient Descent (13 min).mkv 如果我们一定需要一个大规模的训练集，我们可以尝试使用随机梯度下降法来代替批量梯度下降法。 在随机梯度下降法中，我们定义代价函数为一个单一训练实例的代价： ​ $$cost\left( \theta, \left( {x}^{(i)} , {y}^{(i)} \right) \right) = \frac{1}{2}\left( {h}_{\theta}\left({x}^{(i)}\right)-{y}^{ {(i)} } \right)^{2}$$ 随机梯度下降算法为：首先对训练集随机“洗牌”，然后：Repeat (usually anywhere between1-10){ for $i = 1:m${ ​ $\theta:={\theta}_{j}-\alpha\left( {h}_{\theta}\left({x}^{(i)}\right)-{y}^{(i)} \right){ {x}_{j} }^{(i)}$ ​ (for $j=0:n$) ​ }} 随机梯度下降算法在每一次计算之后便更新参数 ${ {\theta } }$ ，而不需要首先将所有的训练集求和，在梯度下降算法还没有完成一次迭代时，随机梯度下降算法便已经走出了很远。但是这样的算法存在的问题是，不是每一步都是朝着”正确”的方向迈出的。因此算法虽然会逐渐走向全局最小值的位置，但是可能无法站到那个最小值的那一点，而是在最小值点附近徘徊。 小批量梯度下降参考视频: 17 - 3 - Mini-Batch Gradient Descent (6 min).mkv 小批量梯度下降算法是介于批量梯度下降算法和随机梯度下降算法之间的算法，每计算常数$b$次训练实例，便更新一次参数 ${ {\theta } }$ 。Repeat { for $i = 1:m${ ​ $\theta:={\theta}_{j}-\alpha\frac{1}{b}\sum_\limits{k=i}^{i+b-1}\left( {h}_{\theta}\left({x}^{(k)}\right)-{y}^{(k)} \right){ {x}_{j} }^{(k)}$ ​ (for $j=0:n$) ​ $ i +=10 $ ​ }} 通常我们会令 $b$ 在 2-100 之间。这样做的好处在于，我们可以用向量化的方式来循环 $b$个训练实例，如果我们用的线性代数函数库比较好，能够支持平行处理，那么算法的总体表现将不受影响（与随机梯度下降相同）。 随机梯度下降收敛参考视频: 17 - 4 - Stochastic Gradient Descent Convergence (12 min). mkv 现在我们介绍随机梯度下降算法的调试，以及学习率 $α$ 的选取。 在批量梯度下降中，我们可以令代价函数$J$为迭代次数的函数，绘制图表，根据图表来判断梯度下降是否收敛。但是，在大规模的训练集的情况下，这是不现实的，因为计算代价太大了。 在随机梯度下降中，我们在每一次更新 ${ {\theta } }$ 之前都计算一次代价，然后每$x$次迭代后，求出这$x$次对训练实例计算代价的平均值，然后绘制这些平均值与$x$次迭代的次数之间的函数图表。 当我们绘制这样的图表时，可能会得到一个颠簸不平但是不会明显减少的函数图像（如上面左下图中蓝线所示）。我们可以增加$α$来使得函数更加平缓，也许便能看出下降的趋势了（如上面左下图中红线所示）；或者可能函数图表仍然是颠簸不平且不下降的（如洋红色线所示），那么我们的模型本身可能存在一些错误。 如果我们得到的曲线如上面右下方所示，不断地上升，那么我们可能会需要选择一个较小的学习率$α$。 我们也可以令学习率随着迭代次数的增加而减小，例如令： ​ $$\alpha = \frac{const1}{iterationNumber + const2}$$ 随着我们不断地靠近全局最小值，通过减小学习率，我们迫使算法收敛而非在最小值附近徘徊。但是通常我们不需要这样做便能有非常好的效果了，对$α$进行调整所耗费的计算通常不值得 总结下，这段视频中，我们介绍了一种方法，近似地监测出随机梯度下降算法在最优化代价函数中的表现，这种方法不需要定时地扫描整个训练集，来算出整个样本集的代价函数，而是只需要每次对最后1000个，或者多少个样本，求一下平均值。应用这种方法，你既可以保证随机梯度下降法正在正常运转和收敛，也可以用它来调整学习速率$α$的大小。 在线学习参考视频: 17 - 5 - Online Learning (13 min).mkv 在这个视频中，讨论一种新的大规模的机器学习机制，叫做在线学习机制。在线学习机制让我们可以模型化问题。 今天，许多大型网站或者许多大型网络公司，使用不同版本的在线学习机制算法，从大批的涌入又离开网站的用户身上进行学习。特别要提及的是，如果你有一个由连续的用户流引发的连续的数据流，进入你的网站，你能做的是使用一个在线学习机制，从数据流中学习用户的偏好，然后使用这些信息来优化一些关于网站的决策。 假定你有一个提供运输服务的公司，用户们来向你询问把包裹从A地运到B地的服务，同时假定你有一个网站，让用户们可多次登陆，然后他们告诉你，他们想从哪里寄出包裹，以及包裹要寄到哪里去，也就是出发地与目的地，然后你的网站开出运输包裹的的服务价格。比如，我会收取&lt;!–￼780–&gt;20之类的，然后根据你开给用户的这个价格，用户有时会接受这个运输服务，那么这就是个正样本，有时他们会走掉，然后他们拒绝购买你的运输服务，所以，让我们假定我们想要一个学习算法来帮助我们，优化我们想给用户开出的价格。 一个算法来从中学习的时候来模型化问题在线学习算法指的是对数据流而非离线的静态数据集的学习。许多在线网站都有持续不断的用户流，对于每一个用户，网站希望能在不将数据存储到数据库中便顺利地进行算法学习。 假使我们正在经营一家物流公司，每当一个用户询问从地点A至地点B的快递费用时，我们给用户一个报价，该用户可能选择接受（$y=1$）或不接受（$y=0$）。 现在，我们希望构建一个模型，来预测用户接受报价使用我们的物流服务的可能性。因此报价是我们的一个特征，其他特征为距离，起始地点，目标地点以及特定的用户数据。模型的输出是:$p(y=1)$。 在线学习的算法与随机梯度下降算法有些类似，我们对单一的实例进行学习，而非对一个提前定义的训练集进行循环。Repeat forever (as long as the website is running) {Get $\left(x,y\right)$ corresponding to the current user​ $\theta:={\theta}_{j}-\alpha\left( {h}_{\theta}\left({x}\right)-{y} \right){ {x}_{j} }$​ (for $j=0:n$)} 一旦对一个数据的学习完成了，我们便可以丢弃该数据，不需要再存储它了。这种方式的好处在于，我们的算法可以很好的适应用户的倾向性，算法可以针对用户的当前行为不断地更新模型以适应该用户。 每次交互事件并不只产生一个数据集，例如，我们一次给用户提供3个物流选项，用户选择2项，我们实际上可以获得3个新的训练实例，因而我们的算法可以一次从3个实例中学习并更新模型。 这些问题中的任何一个都可以被归类到标准的，拥有一个固定的样本集的机器学习问题中。或许，你可以运行一个你自己的网站，尝试运行几天，然后保存一个数据集，一个固定的数据集，然后对其运行一个学习算法。但是这些是实际的问题，在这些问题里，你会看到大公司会获取如此多的数据，真的没有必要来保存一个固定的数据集，取而代之的是你可以使用一个在线学习算法来连续的学习，从这些用户不断产生的数据中来学习。这就是在线学习机制，然后就像我们所看到的，我们所使用的这个算法与随机梯度下降算法非常类似，唯一的区别的是，我们不会使用一个固定的数据集，我们会做的是获取一个用户样本，从那个样本中学习，然后丢弃那个样本并继续下去，而且如果你对某一种应用有一个连续的数据流，这样的算法可能会非常值得考虑。当然，在线学习的一个优点就是，如果你有一个变化的用户群，又或者你在尝试预测的事情，在缓慢变化，就像你的用户的品味在缓慢变化，这个在线学习算法，可以慢慢地调试你所学习到的假设，将其调节更新到最新的用户行为。 映射化简和数据并行参考视频: 17 - 6 - Map Reduce and Data Parallelism (14 min).mkv 映射化简和数据并行对于大规模机器学习问题而言是非常重要的概念。之前提到，如果我们用批量梯度下降算法来求解大规模数据集的最优解，我们需要对整个训练集进行循环，计算偏导数和代价，再求和，计算代价非常大。如果我们能够将我们的数据集分配给不多台计算机，让每一台计算机处理数据集的一个子集，然后我们将计所的结果汇总在求和。这样的方法叫做映射简化。 具体而言，如果任何学习算法能够表达为，对训练集的函数的求和，那么便能将这个任务分配给多台计算机（或者同一台计算机的不同CPU 核心），以达到加速处理的目的。 例如，我们有400个训练实例，我们可以将批量梯度下降的求和任务分配给4台计算机进行处理： 很多高级的线性代数函数库已经能够利用多核CPU的多个核心来并行地处理矩阵运算，这也是算法的向量化实现如此重要的缘故（比调用循环快）。 应用实例：图片文字识别(Application Example: Photo OCR)问题描述和流程图参考视频: 18 - 1 - Problem Description and Pipeline (7 min).mkv 图像文字识别应用所作的事是，从一张给定的图片中识别文字。这比从一份扫描文档中识别文字要复杂的多。 为了完成这样的工作，需要采取如下步骤： 文字侦测（Text detection）——将图片上的文字与其他环境对象分离开来 字符切分（Character segmentation）——将文字分割成一个个单一的字符 字符分类（Character classification）——确定每一个字符是什么可以用任务流程图来表达这个问题，每一项任务可以由一个单独的小队来负责解决： 滑动窗口参考视频: 18 - 2 - Sliding Windows (15 min).mkv 滑动窗口是一项用来从图像中抽取对象的技术。假使我们需要在一张图片中识别行人，首先要做的是用许多固定尺寸的图片来训练一个能够准确识别行人的模型。然后我们用之前训练识别行人的模型时所采用的图片尺寸在我们要进行行人识别的图片上进行剪裁，然后将剪裁得到的切片交给模型，让模型判断是否为行人，然后在图片上滑动剪裁区域重新进行剪裁，将新剪裁的切片也交给模型进行判断，如此循环直至将图片全部检测完。 一旦完成后，我们按比例放大剪裁的区域，再以新的尺寸对图片进行剪裁，将新剪裁的切片按比例缩小至模型所采纳的尺寸，交给模型进行判断，如此循环。 滑动窗口技术也被用于文字识别，首先训练模型能够区分字符与非字符，然后，运用滑动窗口技术识别字符，一旦完成了字符的识别，我们将识别得出的区域进行一些扩展，然后将重叠的区域进行合并。接着我们以宽高比作为过滤条件，过滤掉高度比宽度更大的区域（认为单词的长度通常比高度要大）。下图中绿色的区域是经过这些步骤后被认为是文字的区域，而红色的区域是被忽略的。 以上便是文字侦测阶段。下一步是训练一个模型来完成将文字分割成一个个字符的任务，需要的训练集由单个字符的图片和两个相连字符之间的图片来训练模型。 模型训练完后，我们仍然是使用滑动窗口技术来进行字符识别。 以上便是字符切分阶段。最后一个阶段是字符分类阶段，利用神经网络、支持向量机或者逻辑回归算法训练一个分类器即可。 获取大量数据和人工数据参考视频: 18 - 3 - Getting Lots of Data and Artificial Data (16 min).mkv 如果我们的模型是低方差的，那么获得更多的数据用于训练模型，是能够有更好的效果的。问题在于，我们怎样获得数据，数据不总是可以直接获得的，我们有可能需要人工地创造一些数据。 以我们的文字识别应用为例，我们可以字体网站下载各种字体，然后利用这些不同的字体配上各种不同的随机背景图片创造出一些用于训练的实例，这让我们能够获得一个无限大的训练集。这是从零开始创造实例。 另一种方法是，利用已有的数据，然后对其进行修改，例如将已有的字符图片进行一些扭曲、旋转、模糊处理。只要我们认为实际数据有可能和经过这样处理后的数据类似，我们便可以用这样的方法来创造大量的数据。 有关获得更多数据的几种方法： 人工数据合成 手动收集、标记数据 众包 上限分析：哪部分管道的接下去做参考视频: 18 - 4 - Ceiling Analysis_ What Part of the Pipeline to Work on Next(14 min).mkv 在机器学习的应用中，我们通常需要通过几个步骤才能进行最终的预测，我们如何能够知道哪一部分最值得我们花时间和精力去改善呢？这个问题可以通过上限分析来回答。 回到我们的文字识别应用中，我们的流程图如下： 流程图中每一部分的输出都是下一部分的输入，上限分析中，我们选取一部分，手工提供100%正确的输出结果，然后看应用的整体效果提升了多少。假使我们的例子中总体效果为72%的正确率。 如果我们令文字侦测部分输出的结果100%正确，发现系统的总体效果从72%提高到了89%。这意味着我们很可能会希望投入时间精力来提高我们的文字侦测部分。 接着我们手动选择数据，让字符切分输出的结果100%正确，发现系统的总体效果只提升了1%，这意味着，我们的字符切分部分可能已经足够好了。 最后我们手工选择数据，让字符分类输出的结果100%正确，系统的总体效果又提升了10%，这意味着我们可能也会应该投入更多的时间和精力来提高应用的总体表现。]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习笔记(1-5周)]]></title>
    <url>%2F2019%2F12%2F04%2Fnew_%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1-5%E5%91%A8)%2F</url>
    <content type="text"><![CDATA[吴恩达机器学习笔记 引言监督学习参考视频: 1 - 3 - Supervised Learning (12 min).mkv我们用一个例子介绍什么是监督学习把正式的定义放在后面介绍。假如说你想预测房价。 前阵子，一个学生从波特兰俄勒冈州的研究所收集了一些房价的数据。你把这些数据画出来，看起来是这个样子：横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。那基于这组数据，假如你有一个朋友，他有一套750平方英尺房子，现在他希望把房子卖掉，他想知道这房子能卖多少钱。 那么关于这个问题，机器学习算法将会怎么帮助你呢？ 我们应用学习算法，可以在这组数据中画一条直线，或者换句话说，拟合一条直线，根据这条线我们可以推测出，这套房子可能卖$150,000，当然这不是唯一的算法。可能还有更好的，比如我们不用直线拟合这些数据，用二次方程去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近$200,000。稍后我们将讨论如何选择学习算法，如何决定用直线还是二次方程来拟合。两个方案中有一个能让你朋友的房子出售得更合理。这些都是学习算法里面很好的例子。以上就是监督学习的例子。 可以看出，监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成。在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。用术语来讲，这叫做回归问题。我们试着推测出一个连续值的结果，即房子的价格。 一般房子的价格会记到美分，所以房价实际上是一系列离散的值，但是我们通常又把房价看成实数，看成是标量，所以又把它看成一个连续的数值。 回归这个词的意思是，我们在试着推测出这一系列连续值属性。 我再举另外一个监督学习的例子。我和一些朋友之前研究过这个。假设说你想通过查看病历来推测乳腺癌良性与否，假如有人检测出乳腺肿瘤，恶性肿瘤有害并且十分危险，而良性的肿瘤危害就没那么大，所以人们显然会很在意这个问题。 让我们来看一组数据：这个数据集中，横轴表示肿瘤的大小，纵轴上，我标出1和0表示是或者不是恶性肿瘤。我们之前见过的肿瘤，如果是恶性则记为1，不是恶性，或者说良性记为0。 我有5个良性肿瘤样本，在1的位置有5个恶性肿瘤样本。现在我们有一个朋友很不幸检查出乳腺肿瘤。假设说她的肿瘤大概这么大，那么机器学习的问题就在于，你能否估算出肿瘤是恶性的或是良性的概率。用术语来讲，这是一个分类问题。 分类指的是，我们试着推测出离散的输出值：0或1良性或恶性，而事实上在分类问题中，输出可能不止两个值。比如说可能有三种乳腺癌，所以你希望预测离散输出0、1、2、3。0 代表良性，1 表示第1类乳腺癌，2表示第2类癌症，3表示第3类，但这也是分类问题。 因为这几个离散的输出分别对应良性，第一类第二类或者第三类癌症，在分类问题中我们可以用另一种方式绘制这些数据点。 现在我用不同的符号来表示这些数据。既然我们把肿瘤的尺寸看做区分恶性或良性的特征，那么我可以这么画，我用不同的符号来表示良性和恶性肿瘤。或者说是负样本和正样本现在我们不全部画X，良性的肿瘤改成用 O 表示，恶性的继续用 X 表示。来预测肿瘤的恶性与否。 在其它一些机器学习问题中，可能会遇到不止一种特征。举个例子，我们不仅知道肿瘤的尺寸，还知道对应患者的年龄。在其他机器学习问题中，我们通常有更多的特征，我朋友研究这个问题时，通常采用这些特征，比如肿块密度，肿瘤细胞尺寸的一致性和形状的一致性等等，还有一些其他的特征。这就是我们即将学到最有趣的学习算法之一。 那种算法不仅能处理2种3种或5种特征，即使有无限多种特征都可以处理。 上图中，我列举了总共5种不同的特征，坐标轴上的两种和右边的3种，但是在一些学习问题中，你希望不只用3种或5种特征。相反，你想用无限多种特征，好让你的算法可以利用大量的特征，或者说线索来做推测。那你怎么处理无限多个特征，甚至怎么存储这些特征都存在问题，你电脑的内存肯定不够用。我们以后会讲一个算法，叫支持向量机，里面有一个巧妙的数学技巧，能让计算机处理无限多个特征。 想象一下，我没有写下这两种和右边的三种特征，而是在一个无限长的列表里面，一直写一直写不停的写，写下无限多个特征，事实上，我们能用算法来处理它们。 现在来回顾一下，这节课我们介绍了监督学习。其基本思想是，我们数据集中的每个样本都有相应的“正确答案”。再根据这些样本作出预测，就像房子和肿瘤的例子中做的那样。我们还介绍了回归问题，即通过回归来推出一个连续的输出，之后我们介绍了分类问题，其目标是推出一组离散的结果。 现在来个小测验：假设你经营着一家公司，你想开发学习算法来处理这两个问题： 你有一大批同样的货物，想象一下，你有上千件一模一样的货物等待出售，这时你想预测接下来的三个月能卖多少件？ 你有许多客户，这时你想写一个软件来检验每一个用户的账户。对于每一个账户，你要判断它们是否曾经被盗过？ 那这两个问题，它们属于分类问题、还是回归问题? 问题一是一个回归问题，因为你知道，如果我有数千件货物，我会把它看成一个实数，一个连续的值。因此卖出的物品数，也是一个连续的值。 问题二是一个分类问题，因为我会把预测的值，用 0 来表示账户未被盗，用 1 表示账户曾经被盗过。所以我们根据账号是否被盗过，把它们定为0 或 1，然后用算法推测一个账号是 0 还是 1，因为只有少数的离散值，所以我把它归为分类问题。 以上就是监督学习的内容。 无监督学习参考视频: 1 - 4 - Unsupervised Learning (14 min).mkv 上个视频中，已经介绍了监督学习。回想当时的数据集，如图表所示，这个数据集中每条数据都已经标明是阴性或阳性，即是良性或恶性肿瘤。所以，对于监督学习里的每条数据，我们已经清楚地知道，训练集对应的正确答案，是良性或恶性了。 在无监督学习中，我们已知的数据。看上去有点不一样，不同于监督学习的数据的样子，即无监督学习中没有任何的标签或者是有相同的标签或者就是没标签。所以我们已知数据集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集。你能从数据中找到某种结构吗？针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做聚类算法。事实证明，它能被用在很多地方。 聚类应用的一个例子就是在谷歌新闻中。如果你以前从来没见过它，你可以到这个URL网址news.google.com去看看。谷歌新闻每天都在，收集非常多，非常多的网络的新闻内容。它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件，自动地把它们聚类到一起。所以，这些新闻事件全是同一主题的，所以显示到一起。 事实证明，聚类算法和无监督学习算法同样还用在很多其它的问题上。 其中就有基因学的理解应用。一个DNA微观数据的例子。基本思想是输入一组不同个体，对其中的每个个体，你要分析出它们是否有一个特定的基因。技术上，你要分析多少特定基因已经表达。所以这些颜色，红，绿，灰等等颜色，这些颜色展示了相应的程度，即不同的个体是否有着一个特定的基因。你能做的就是运行一个聚类算法，把个体聚类到不同的类或不同类型的组（人）…… 所以这个就是无监督学习，因为我们没有提前告知算法一些信息，比如，这是第一类的人，那些是第二类的人，还有第三类，等等。我们只是说，是的，这是有一堆数据。我不知道数据里面有什么。我不知道谁是什么类型。我甚至不知道人们有哪些不同的类型，这些类型又是什么。但你能自动地找到数据中的结构吗？就是说你要自动地聚类那些个体到各个类，我没法提前知道哪些是哪些。因为我们没有给算法正确答案来回应数据集中的数据，所以这就是无监督学习。 无监督学习或聚集有着大量的应用。它用于组织大型计算机集群。我有些朋友在大数据中心工作，那里有大型的计算机集群，他们想解决什么样的机器易于协同地工作，如果你能够让那些机器协同工作，你就能让你的数据中心工作得更高效。第二种应用就是社交网络的分析。所以已知你朋友的信息，比如你经常发email的，或是你Facebook的朋友、谷歌+ 圈子的朋友，我们能否自动地给出朋友的分组呢？即每组里的人们彼此都熟识，认识组里的所有人？还有市场分割。许多公司有大型的数据库，存储消费者信息。所以，你能检索这些顾客数据集，自动地发现市场分类，并自动地把顾客划分到不同的细分市场中，你才能自动并更有效地销售或不同的细分市场一起进行销售。这也是无监督学习，因为我们拥有所有的顾客数据，但我们没有提前知道是什么的细分市场，以及分别有哪些我们数据集中的顾客。我们不知道谁是在一号细分市场，谁在二号市场，等等。那我们就必须让算法从数据中发现这一切。最后，无监督学习也可用于天文数据分析，这些聚类算法给出了令人惊讶、有趣、有用的理论，解释了星系是如何诞生的。这些都是聚类的例子，聚类只是无监督学习中的一种。 我现在告诉你们另一种。我先来介绍鸡尾酒宴问题。嗯，你参加过鸡尾酒宴吧？你可以想像下，有个宴会房间里满是人，全部坐着，都在聊天，这么多人同时在聊天，声音彼此重叠，因为每个人都在说话，同一时间都在说话，你几乎听不到你面前那人的声音。所以，可能在一个这样的鸡尾酒宴中的两个人，他俩同时都在说话，假设现在是在个有些小的鸡尾酒宴中。我们放两个麦克风在房间中，因为这些麦克风在两个地方，离说话人的距离不同每个麦克风记录下不同的声音，虽然是同样的两个说话人。听起来像是两份录音被叠加到一起，或是被归结到一起，产生了我们现在的这些录音。另外，这个算法还会区分出两个音频资源，这两个可以合成或合并成之前的录音，实际上，鸡尾酒算法的第一个输出结果是： 1，2，3，4，5，6，7，8，9，10, 所以，已经把英语的声音从录音中分离出来了。 第二个输出是这样： 1，2，3，4，5，6，7，8，9，10。 看看这个无监督学习算法，实现这个得要多么的复杂，是吧？它似乎是这样，为了构建这个应用，完成这个音频处理似乎需要你去写大量的代码或链接到一堆的合成器JAVA库，处理音频的库，看上去绝对是个复杂的程序，去完成这个从音频中分离出音频。事实上，这个算法对应你刚才知道的那个问题的算法可以就用一行代码来完成。 就是这里展示的代码：[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x&#39;); 研究人员花费了大量时间才最终实现这行代码。我不是说这个是简单的问题，但它证明了，当你使用正确的编程环境，许多学习算法是相当短的程序。所以，这也是为什么在本课中，我们打算使用Octave编程环境。Octave,是免费的开源软件，使用一个像Octave或Matlab的工具，许多学习算法变得只有几行代码就可实现。 后面，我会教你们一点关于如何使用Octave的知识，你就可以用Octave来实现一些算法了。或者，如果你有Matlab（盗版？），你也可以用Matlab。事实上，在硅谷里，对大量机器学习算法，我们第一步就是建原型，在Octave建软件原型，因为软件在Octave中可以令人难以置信地、快速地实现这些学习算法。这里的这些函数比如SVM（支持向量机）函数，奇异值分解，Octave里已经建好了。如果你试图完成这个工作，但借助C++或JAVA的话，你会需要很多很多行的代码，并链接复杂的C++或Java库。所以，你可以实现这些算法，借助C++或Java或Python，它只是用这些语言来实现会更加复杂。(编者注：这个是当时的情况，现在Python变主流了) 我已经见到，在我教机器学习将近十年后的现在，发现，学习可以更加高速，如果使用Octave作为编程环境，如果使用Octave作为学习工具，以及作为原型工具，它会让你对学习算法的学习和建原型快上许多。 事实上，许多人在大硅谷的公司里做的其实就是，使用一种工具像Octave来做第一步的学习算法的原型搭建，只有在你已经让它工作后，你才移植它到C++ 或Java或别的语言。事实证明，这样做通常可以让你的算法运行得比直接用C++ 实现更快，所以，我知道，作为一名指导者，我必须说“相信我”，但对你们中从未使用过Octave这种编程环境的人，我还是要告诉你们这一点一定要相信我，我想，对你们而言，我认为你们的时间，你们的开发时间是最有价值的资源。我已经见过很多人这样做了，我把你看作是机器学习研究员，或机器学习开发人员，想更加高产的话，你要学会使用这个原型工具，开始使用Octave。 我们介绍了无监督学习，它是学习策略，交给算法大量的数据，并让算法为我们从数据中找出某种结构。 好的，希望你们还记得垃圾邮件问题。如果你有标记好的数据，区别好是垃圾还是非垃圾邮件，我们把这个当作监督学习问题。 新闻事件分类的例子，就是那个谷歌新闻的例子，我们在本视频中有见到了，我们看到，可以用一个聚类算法来聚类这些文章到一起，所以是无监督学习。 细分市场的例子，我在更早一点的时间讲过，你可以当作无监督学习问题，因为我只是拿到算法数据，再让算法去自动地发现细分市场。 最后一个例子，糖尿病，这个其实就像是我们的乳腺癌，上个视频里的。只是替换了好、坏肿瘤，良性、恶性肿瘤，我们改用糖尿病或没病。所以我们把这个当作监督学习，我们能够解决它，作为一个监督学习问题，就像我们在乳腺癌数据中做的一样。 单变量线性回归(Linear Regression with One Variable)模型表示参考视频: 2 - 1 - Model Representation (8 min).mkv 让我们通过一个例子来开始：这个例子是预测住房价格的，我们要使用一个数据集，数据集包含俄勒冈州波特兰市的住房价格。在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子。 它被称作监督学习是因为对于每个数据来说，我们给出了“正确的答案”，即告诉我们：根据我们的数据来说，房子实际的价格是多少，而且，更具体来说，这是一个回归问题。回归一词指的是，我们根据之前的数据预测出一个准确的输出值，对于这个例子就是价格，同时，还有另一种最常见的监督学习方式，叫做分类问题，当我们想要预测离散的输出值，例如，我们正在寻找癌症肿瘤，并想要确定肿瘤是良性的还是恶性的，这就是0/1离散输出的问题。更进一步来说，在监督学习中我们有一个数据集，这个数据集被称训练集。 我将在整个课程中用小写的m来表示训练样本的数目。 以之前的房屋交易问题为例，假使我们回归问题的训练集（Training Set）如下表所示： 我们将要用来描述这个回归问题的标记如下: $m$ 代表训练集中实例的数量 $x$ 代表特征/输入变量 $y$ 代表目标变量/输出变量 $\left( x,y \right)$ 代表训练集中的实例 $({ {x}^{(i)} },{ {y}^{(i)} })$ 代表第$i$ 个观察实例 $h$ 代表学习算法的解决方案或函数也称为假设（**hypothesis**） 这就是一个监督学习算法的工作方式，我们可以看到这里有我们的训练集里房屋价格我们把它喂给我们的学习算法，学习算法的工作了，然后输出一个函数，通常表示为小写 $h$ 表示。$h$ 代表hypothesis(假设)，$h$表示一个函数，输入是房屋尺寸大小，就像你朋友想出售的房屋，因此 $h$ 根据输入的 $x$值来得出 $y$ 值，$y$ 值对应房子的价格 因此，$h$ 是一个从$x$ 到 $y$ 的函数映射。 我将选择最初的使用规则$h$代表hypothesis，因而，要解决房价预测问题，我们实际上是要将训练集“喂”给我们的学习算法，进而学习得到一个假设$h$，然后将我们要预测的房屋的尺寸作为输入变量输入给$h$，预测出该房屋的交易价格作为输出变量输出为结果。那么，对于我们的房价预测问题，我们该如何表达 $h$？ 一种可能的表达方式为：$h_\theta \left( x \right)=\theta_{0} + \theta_{1}x$，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。 代价函数参考视频: 2 - 2 - Cost Function (8 min).mkv 在线性回归中我们有一个像这样的训练集，$m$代表了训练样本的数量，比如 $m = 47$。而我们的假设函数，也就是用来进行预测的函数，是这样的线性函数形式：$h_\theta \left( x \right)=\theta_{0}+\theta_{1}x$。 接下来我们会引入一些术语我们现在要做的便是为我们的模型选择合适的参数（parameters）$\theta_{0}$ 和 $\theta_{1}$，在房价问题这个例子中便是直线的斜率和在$y$ 轴上的截距。 我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error）。 我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。 即使得代价函数 $J \left( \theta_0, \theta_1 \right) = \frac{1}{2m}\sum\limits_{i=1}^m \left( h_{\theta}(x^{(i)})-y^{(i)} \right)^{2}$最小。 我们绘制一个等高线图，三个坐标分别为$\theta_{0}$和$\theta_{1}$ 和$J(\theta_{0}, \theta_{1})$： 则可以看出在三维空间中存在一个使得$J(\theta_{0}, \theta_{1})$最小的点。 代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。 在后续课程中，我们还会谈论其他的代价函数，但我们刚刚讲的选择是对于大多数线性回归问题非常合理的。 也许这个函数$J(\theta_{0}, \theta_{1})$有点抽象，可能你仍然不知道它的内涵，在接下来的几个视频里，我们要更进一步解释代价函数J的工作原理，并尝试更直观地解释它在计算什么，以及我们使用它的目的。 代价函数的直观理解参考视频: 2 - 3 - Cost Function - Intuition I (11 min).mkv在上一个视频中，我们给了代价函数一个数学上的定义。在这个视频里，让我们通过一些例子来获取一些直观的感受，看看代价函数到底是在干什么。 代价函数的样子，等高线图，则可以看出在三维空间中存在一个使得$J(\theta_{0}, \theta_{1})$最小的点。 通过这些图形，我希望你能更好地理解这些代价函数$ J$所表达的值是什么样的，它们对应的假设是什么样的，以及什么样的假设对应的点，更接近于代价函数$J$的最小值。 当然，我们真正需要的是一种有效的算法，能够自动地找出这些使代价函数$J$取最小值的参数$\theta_{0}$和$\theta_{1}$来。 我们也不希望编个程序把这些点画出来，然后人工的方法来读出这些点的数值，这很明显不是一个好办法。我们会遇到更复杂、更高维度、更多参数的情况，而这些情况是很难画出图的，因此更无法将其可视化，因此我们真正需要的是编写程序来找出这些最小化代价函数的$\theta_{0}$和$\theta_{1}$的值，在下一节视频中，我们将介绍一种算法，能够自动地找出能使代价函数$J$最小化的参数$\theta_{0}$和$\theta_{1}$的值。 梯度下降参考视频: 2 - 5 - Gradient Descent (11 min).mkv梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数$J(\theta_{0}, \theta_{1})$ 的最小值。 梯度下降背后的思想是：开始时我们随机选择一个参数的组合$\left( {\theta_{0} },{\theta_{1} },......,{\theta_{n} } \right)$，计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到找到一个局部最小值（local minimum），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），选择不同的初始参数组合，可能会找到不同的局部最小值。 想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。 批量梯度下降（batch gradient descent）算法的公式为： 其中$a$是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。 在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新${\theta_{0} }$和${\theta_{1} }$ ，当 $j=0$ 和$j=1$时，会产生更新，所以你将更新$J\left( {\theta_{0} } \right)$和$J\left( {\theta_{1} } \right)$。实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新${\theta_{0} }$和${\theta_{1} }$，我的意思是在这个等式中，我们要这样更新： ${\theta_{0} }$:= ${\theta_{0} }$ ，并更新${\theta_{1} }$:= ${\theta_{1} }$。 实现方法是：你应该计算公式右边的部分，通过那一部分计算出${\theta_{0} }$和${\theta_{1} }$的值，然后同时更新${\theta_{0} }$和${\theta_{1} }$。 让我进一步阐述这个过程： 在梯度下降算法中，这是正确实现同时更新的方法。我不打算解释为什么你需要同时更新，同时更新是梯度下降中的一种常用方法。我们之后会讲到，同步更新是更自然的实现方法。当人们谈到梯度下降时，他们的意思就是同步更新。 在接下来的视频中，我们要进入这个微分项的细节之中。我已经写了出来但没有真正定义，如果你已经修过微积分课程，如果你熟悉偏导数和导数，这其实就是这个微分项： $\alpha \frac{\partial }{\partial { {\theta }_{0} }}J({ {\theta }_{0} },{ {\theta }_{1} })$，$\alpha \frac{\partial }{\partial { {\theta }_{1} }}J({ {\theta }_{0} },{ {\theta }_{1} })$。 如果你不熟悉微积分，不用担心，即使你之前没有看过微积分，或者没有接触过偏导数，在接下来的视频中，你会得到一切你需要知道，如何计算这个微分项的知识。 梯度下降的直观理解参考视频: 2 - 6 - Gradient Descent Intuition (12 min).mkv在之前的视频中，我们给出了一个数学上关于梯度下降的定义，本次视频我们更深入研究一下，更直观地感受一下这个算法是做什么的，以及梯度下降算法的更新过程有什么意义。梯度下降算法如下： ${\theta_{j} }:={\theta_{j} }-\alpha \frac{\partial }{\partial {\theta_{j} }}J\left(\theta \right)$ 描述：对$\theta $赋值，使得$J\left( \theta \right)$按梯度下降最快方向进行，一直迭代下去，最终得到局部最小值。其中$a$是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大。 对于这个问题，求导的目的，基本上可以说取这个红点的切线，就是这样一条红色的直线，刚好与函数相切于这一点，让我们看看这条红色直线的斜率，就是这条刚好与函数曲线相切的这条直线，这条直线的斜率正好是这个三角形的高度除以这个水平长度，现在，这条线有一个正斜率，也就是说它有正导数，因此，我得到的新的${\theta_{1} }$，${\theta_{1} }$更新后等于${\theta_{1} }$减去一个正数乘以$a$。 这就是我梯度下降法的更新规则：${\theta_{j} }:={\theta_{j} }-\alpha \frac{\partial }{\partial {\theta_{j} }}J\left( \theta \right)$ 让我们来看看如果$a$太小或$a$太大会出现什么情况： 如果$a$太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果$a$太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。 如果$a$太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果$a$太大，它会导致无法收敛，甚至发散。 现在，我还有一个问题，当我第一次学习这个地方时，我花了很长一段时间才理解这个问题，如果我们预先把${\theta_{1} }$放在一个局部的最低点，你认为下一步梯度下降法会怎样工作？ 假设你将${\theta_{1} }$初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得${\theta_{1} }$不再改变，也就是新的${\theta_{1} }$等于原来的${\theta_{1} }$，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率$a$保持不变时，梯度下降也可以收敛到局部最低点。 我们来看一个例子，这是代价函数$J\left( \theta \right)$。 我想找到它的最小值，首先初始化我的梯度下降算法，在那个品红色的点初始化，如果我更新一步梯度下降，也许它会带我到这个点，因为这个点的导数是相当陡的。现在，在这个绿色的点，如果我再更新一步，你会发现我的导数，也即斜率，是没那么陡的。随着我接近最低点，我的导数越来越接近零，所以，梯度下降一步后，新的导数会变小一点点。然后我想再梯度下降一步，在这个绿点，我自然会用一个稍微跟刚才在那个品红点时比，再小一点的一步，到了新的红色点，更接近全局最低点了，因此这点的导数会比在绿点时更小。所以，我再进行一步梯度下降时，我的导数项是更小的，${\theta_{1} }$更新的幅度就会更小。所以随着梯度下降法的运行，你移动的幅度会自动变得越来越小，直到最终移动幅度非常小，你会发现，已经收敛到局部极小值。 回顾一下，在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小$a$。 这就是梯度下降算法，你可以用它来最小化任何代价函数$J$，不只是线性回归中的代价函数$J$。 在接下来的视频中，我们要用代价函数$J$，回到它的本质，线性回归中的代价函数。也就是我们前面得出的平方误差函数，结合梯度下降法，以及平方代价函数，我们会得出第一个机器学习算法，即线性回归算法。 梯度下降的线性回归参考视频: 2 - 7 - GradientDescentForLinearRegression (6 min).mkv在以前的视频中我们谈到关于梯度下降算法，梯度下降是很常用的算法，它不仅被用在线性回归上和线性回归模型、平方误差代价函数。在这段视频中，我们要将梯度下降和代价函数结合。我们将用到此算法，并将其应用于具体的拟合直线的线性回归算法里。 梯度下降算法和线性回归算法比较如图： 对我们之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数，即： $h_\theta \left( x \right)=\theta_{0} + \theta_{1}x$ $\frac{\partial }{\partial { {\theta }_{j} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{\partial }{\partial { {\theta }_{j} }}\frac{1}{2m}{ {\sum\limits_{i=1}^{m}{\left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)} }^{2} }$ $j=0$ 时：$\frac{\partial }{\partial { {\theta }_{0} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{1}{m}{ {\sum\limits_{i=1}^{m}{\left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)} }}$ $j=1$ 时：$\frac{\partial }{\partial { {\theta }_{1} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)\cdot { {x}^{(i)} } \right)}$ 则算法改写成： Repeat { ​ ${\theta_{0} }:={\theta_{0} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{ \left({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)}$ ​ ${\theta_{1} }:={\theta_{1} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)\cdot { {x}^{(i)} } \right)}$ ​ } 我们刚刚使用的算法，有时也称为批量梯度下降。实际上，在机器学习中，通常不太会给算法起名字，但这个名字”批量梯度下降”，指的是在梯度下降的每一步中，我们都用到了所有的训练样本，在梯度下降中，在计算微分求导项时，我们需要进行求和运算，所以，在每一个单独的梯度下降中，我们最终都要计算这样一个东西，这个项需要对所有$m$个训练样本求和。因此，批量梯度下降法这个名字说明了我们需要考虑所有这一”批”训练样本，而事实上，有时也有其他类型的梯度下降法，不是这种”批量”型的，不考虑整个的训练集，而是每次只关注训练集中的一些小的子集。在后面的课程中，我们也将介绍这些方法。 但就目前而言，应用刚刚学到的算法，你应该已经掌握了批量梯度算法，并且能把它应用到线性回归中了，这就是用于线性回归的梯度下降法。 如果你之前学过线性代数，有些同学之前可能已经学过高等线性代数，你应该知道有一种计算代价函数$J$最小值的数值解法，不需要梯度下降这种迭代算法。在后面的课程中，我们也会谈到这个方法，它可以在不需要多步梯度下降的情况下，也能解出代价函数$J$的最小值，这是另一种称为正规方程(normal equations)的方法。实际上在数据量较大的情况下，梯度下降法比正规方程要更适用一些。 现在我们已经掌握了梯度下降，我们可以在不同的环境中使用梯度下降法，我们还将在不同的机器学习问题中大量地使用它。所以，祝贺大家成功学会你的第一个机器学习算法。 在下一段视频中，告诉你泛化的梯度下降算法，这将使梯度下降更加强大。 接下来的内容参考视频: 2 - 8 - What_’s Next (6 min).mkv在接下来的一组视频中，我会对线性代数进行一个快速的复习回顾。如果你从来没有接触过向量和矩阵，那么这课件上所有的一切对你来说都是新知识，或者你之前对线性代数有所了解，但由于隔得久了，对其有所遗忘，那就请学习接下来的一组视频，我会快速地回顾你将用到的线性代数知识。 通过它们，你可以实现和使用更强大的线性回归模型。事实上，线性代数不仅仅在线性回归中应用广泛，它其中的矩阵和向量将有助于帮助我们实现之后更多的机器学习模型，并在计算上更有效率。正是因为这些矩阵和向量提供了一种有效的方式来组织大量的数据，特别是当我们处理巨大的训练集时，如果你不熟悉线性代数，如果你觉得线性代数看上去是一个复杂、可怕的概念，特别是对于之前从未接触过它的人，不必担心，事实上，为了实现机器学习算法，我们只需要一些非常非常基础的线性代数知识。通过接下来几个视频，你可以很快地学会所有你需要了解的线性代数知识。具体来说，为了帮助你判断是否有需要学习接下来的一组视频，我会讨论什么是矩阵和向量，谈谈如何加、减 、乘矩阵和向量，讨论逆矩阵和转置矩阵的概念。 如果你十分熟悉这些概念，那么你完全可以跳过这组关于线性代数的选修视频，但是如果你对这些概念仍有些许的不确定，不确定这些数字或这些矩阵的意思，那么请看一看下一组的视频，它会很快地教你一些你需要知道的线性代数的知识，便于之后编写机器学习算法和处理大量数据。 线性代数回顾(Linear Algebra Review)矩阵和向量参考视频: 3 - 1 - Matrices and Vectors (9 min).mkv如图：这个是4×2矩阵，即4行2列，如$m$为行，$n$为列，那么$m×n$即4×2 矩阵的维数即行数×列数 矩阵元素（矩阵项）：$A=\left[ \begin{matrix} 1402 & 191 \\ 1371 & 821 \\ 949 & 1437 \\ 147 & 1448 \\\end{matrix} \right]$ $A_{ij}$指第$i$行，第$j$列的元素。 向量是一种特殊的矩阵，讲义中的向量一般都是列向量，如： $y=\left[ \begin{matrix} {460} \\ {232} \\ {315} \\ {178} \\\end{matrix} \right]$ 为四维列向量（4×1）。 如下图为1索引向量和0索引向量，左图为1索引向量，右图为0索引向量，一般我们用1索引向量。 $y=\left[ \begin{matrix} { {y}_{1} } \\ { {y}_{2} } \\ { {y}_{3} } \\ { {y}_{4} } \\\end{matrix} \right]$，$y=\left[ \begin{matrix} { {y}_{0} } \\ { {y}_{1} } \\ { {y}_{2} } \\ { {y}_{3} } \\\end{matrix} \right]$ 加法和标量乘法参考视频: 3 - 2 - Addition and Scalar Multiplication (7 min).mkv矩阵的加法：行列数相等的可以加。 例： 矩阵的乘法：每个元素都要乘 组合算法也类似。 矩阵向量乘法参考视频: 3 - 3 - Matrix Vector Multiplication (14 min).mkv 矩阵和向量的乘法如图：$m×n$的矩阵乘以$n×1$的向量，得到的是$m×1$的向量 算法举例： 矩阵乘法参考视频: 3 - 4 - Matrix Matrix Multiplication (11 min).mkv矩阵乘法： $m×n$矩阵乘以$n×o$矩阵，变成$m×o$矩阵。 如果这样说不好理解的话就举一个例子来说明一下，比如说现在有两个矩阵$A$和$B$，那么它们的乘积就可以表示为图中所示的形式。 矩阵乘法的性质参考视频: 3 - 5 - Matrix Multiplication Properties (9 min).mkv矩阵乘法的性质： 矩阵的乘法不满足交换律：$A×B≠B×A$ 矩阵的乘法满足结合律。即：$A×(B×C)=(A×B)×C$ 单位矩阵：在矩阵的乘法中，有一种矩阵起着特殊的作用，如同数的乘法中的1,我们称这种矩阵为单位矩阵．它是个方阵，一般用 $I$ 或者 $E$ 表示，本讲义都用 $I$ 代表单位矩阵，从左上角到右下角的对角线（称为主对角线）上的元素均为1以外全都为0。如： $A{ {A}^{-1} }={ {A}^{-1} }A=I$ 对于单位矩阵，有$AI=IA=A$ 逆、转置参考视频: 3 - 6 - Inverse and Transpose (11 min).mkv矩阵的逆：如矩阵$A$是一个$m×m$矩阵（方阵），如果有逆矩阵，则：$A{ {A}^{-1} }={ {A}^{-1} }A=I$ 我们一般在OCTAVE或者MATLAB中进行计算矩阵的逆矩阵。 矩阵的转置：设$A$为$m×n$阶矩阵（即$m$行$n$列），第$i $行$j $列的元素是$a(i,j)$，即：$A=a(i,j)$ 定义$A$的转置为这样一个$n×m$阶矩阵$B$，满足$B=a(j,i)$，即 $b (i,j)=a(j,i)$（$B$的第$i$行第$j$列元素是$A$的第$j$行第$i$列元素），记${ {A}^{T} }=B$。(有些书记为A’=B） 直观来看，将$A$的所有元素绕着一条从第1行第1列元素出发的右下方45度的射线作镜面反转，即得到$A$的转置。 例： ${ {\left| \begin{matrix} a& b \\ c& d \\ e& f \\\end{matrix} \right|}^{T} }=\left|\begin{matrix} a& c & e \\ b& d & f \\\end{matrix} \right|$ 矩阵的转置基本性质: $ { {\left( A\pm B \right)}^{T} }={ {A}^{T} }\pm { {B}^{T} } $ ${ {\left( A\times B \right)}^{T} }={ {B}^{T} }\times { {A}^{T} }$ ${ {\left( { {A}^{T} } \right)}^{T} }=A $ ${ {\left( KA \right)}^{T} }=K{ {A}^{T} } $ matlab中矩阵转置：直接打一撇，x=y&#39;。 多变量线性回归(Linear Regression with Multiple Variables)多维特征参考视频: 4 - 1 - Multiple Features (8 min).mkv目前为止，我们探讨了单变量/特征的回归模型，现在我们对房价模型增加更多的特征，例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为$\left( {x_{1} },{x_{2} },...,{x_{n} } \right)$。 增添更多特征后，我们引入一系列新的注释： $n$ 代表特征的数量 ${x^{\left( i \right)} }$代表第 $i$ 个训练实例，是特征矩阵中的第$i$行，是一个**向量**（**vector**）。 比方说，上图的 ${x}^{(2)}\text{=}\begin{bmatrix} 1416\\\ 3\\\ 2\\\ 40 \end{bmatrix}$， ${x}_{j}^{\left( i \right)}$代表特征矩阵中第 $i$ 行的第 $j$ 个特征，也就是第 $i$ 个训练实例的第 $j$ 个特征。 如上图的$x_{2}^{\left( 2 \right)}=3,x_{3}^{\left( 2 \right)}=2$， 支持多变量的假设 $h$ 表示为：$h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$， 这个公式中有$n+1$个参数和$n$个变量，为了使得公式能够简化一些，引入$x_{0}=1$，则公式转化为：$h_{\theta} \left( x \right)={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ 此时模型中的参数是一个$n+1$维的向量，任何一个训练实例也都是$n+1$维的向量，特征矩阵$X$的维度是 $m*(n+1)$。 因此公式可以简化为：$h_{\theta} \left( x \right)={\theta^{T} }X$，其中上标$T$代表矩阵转置。 多变量梯度下降参考视频: 4 - 2 - Gradient Descent for Multiple Variables (5 min).mkv与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：$J\left( {\theta_{0} },{\theta_{1} }...{\theta_{n} } \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( h_{\theta} \left({x}^{\left( i \right)} \right)-{y}^{\left( i \right)} \right)}^{2} }}$ ， 其中：$h_{\theta}\left( x \right)=\theta^{T}X={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ ， 我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。多变量线性回归的批量梯度下降算法为： 即： 求导数后得到： 当$n>=1$时， ${ {\theta }_{0} }:={ {\theta }_{0} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{0}^{(i)}$ ${ {\theta }_{1} }:={ {\theta }_{1} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{1}^{(i)}$ ${ {\theta }_{2} }:={ {\theta }_{2} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{2}^{(i)}$ 我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。 代码示例： 计算代价函数 $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( {h_{\theta} }\left( {x^{(i)} } \right)-{y^{(i)} } \right)}^{2} }}$ 其中：${h_{\theta} }\left( x \right)={\theta^{T} }X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ Python 代码： def computeCost(X, y, theta): inner = np.power(((X * theta.T) - y), 2) return np.sum(inner) / (2 * len(X)) 梯度下降法实践1-特征缩放参考视频: 4 - 3 - Gradient Descent in Practice I - Feature Scaling (9 min).mkv 在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。 以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。 解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。如图： 最简单的方法是令：${ {x}_{n} }=\frac{ {{x}_{n} }-{ {\mu}_{n} }}{ {{s}_{n} }}$，其中 ${\mu_{n} }$是平均值，${s_{n} }$是标准差。 梯度下降法实践2-学习率参考视频: 4 - 4 - Gradient Descent in Practice II - Learning Rate (9 min).mkv梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。 也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看上面这样的图表更好。 梯度下降算法的每次迭代受到学习率的影响，如果学习率$a$过小，则达到收敛所需的迭代次数会非常高；如果学习率$a$过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。 通常可以考虑尝试些学习率： $\alpha=0.01，0.03，0.1，0.3，1，3，10$ 特征和多项式回归参考视频: 4 - 5 - Features and Polynomial Regression (8 min).mkv 如房价预测问题， $h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }\times{frontage}+{\theta_{2} }\times{depth}$ ${x_{1} }=frontage$（临街宽度），${x_{2} }=depth$（纵向深度），$x=frontage*depth=area$（面积），则：${h_{\theta} }\left( x \right)={\theta_{0} }+{\theta_{1} }x$。 线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型：$h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}$或者三次方模型： $h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}+{\theta_{3} }{x_{3}^3}$ 通常我们需要先观察数据然后再决定准备尝试怎样的模型。 另外，我们可以令： ${ {x}_{2} }=x_{2}^{2},{ {x}_{3} }=x_{3}^{3}$，从而将模型转化为线性回归模型。 根据函数图形特性，我们还可以使： ${ {{h} }_{\theta} }(x)={ {\theta }_{0} }\text{+}{ {\theta }_{1} }(size)+{ {\theta}_{2} }{ {(size)}^{2} }$ 或者: ${ {{h} }_{\theta} }(x)={ {\theta }_{0} }\text{+}{ {\theta }_{1} }(size)+{ {\theta }_{2} }\sqrt{size}$ 注：如果我们采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要。 正规方程参考视频: 4 - 6 - Normal Equation (16 min).mkv到目前为止，我们都在使用梯度下降算法，但是对于某些线性回归问题，正规方程方法是更好的解决方案。如： 正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：$\frac{\partial}{\partial{\theta_{j} }}J\left( {\theta_{j} } \right)=0$ 。假设我们的训练集特征矩阵为 $X$（包含了 ${ {x}_{0} }=1$）并且我们的训练集结果为向量 $y$，则利用正规方程解出向量 $\theta ={ {\left( {X^T}X \right)}^{-1} }{X^{T} }y$ 。上标 T 代表矩阵转置，上标-1 代表矩阵的逆。设矩阵$A={X^{T} }X$，则：${ {\left( {X^T}X \right)}^{-1} }={A^{-1} }$以下表示数据为例： 即： 运用正规方程方法求解参数： 在 Octave 中，正规方程写作： pinv(X&#39;*X)*X&#39;*y注：对于那些不可逆的矩阵（通常是因为特征之间不独立，如同时包含英尺为单位的尺寸和米为单位的尺寸两个特征，也有可能是特征数量大于训练集的数量），正规方程方法是不能用的。 梯度下降与正规方程的比较： 梯度下降 正规方程 需要选择学习率{% raw %}$\alpha${% endraw %} 不需要 需要多次迭代 一次运算得出 当特征数量{% raw %}$n${% endraw %}大时也能较好适用 需要计算{% raw %}${ {\left( { {X}^{T} }X \right)}^{-1} }${% endraw %} 如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为{% raw %}$O\left( { {n}^{3} } \right)${% endraw %}，通常来说当{% raw %}$n${% endraw %}小于10000 时还是可以接受的 适用于各种类型的模型 只适用于线性模型，不适合逻辑回归模型等其他模型 总结一下，只要特征变量的数目并不大，标准方程是一个很好的计算参数{% raw %}$\theta ${% endraw %}的替代方法。具体地说，只要特征变量数量小于一万，我通常使用标准方程法，而不使用梯度下降法。 随着我们要讲的学习算法越来越复杂，例如，当我们讲到分类算法，像逻辑回归算法，我们会看到，实际上对于那些算法，并不能使用标准方程法。对于那些更复杂的学习算法，我们将不得不仍然使用梯度下降法。因此，梯度下降法是一个非常有用的算法，可以用在有大量特征变量的线性回归问题。或者我们以后在课程中，会讲到的一些其他的算法，因为标准方程法不适合或者不能用在它们上。但对于这个特定的线性回归模型，标准方程法是一个比梯度下降法更快的替代算法。所以，根据具体的问题，以及你的特征变量的数量，这两种算法都是值得学习的。 正规方程的python实现： import numpy as np def normalEqn(X, y): theta = np.linalg.inv(X.T@X)@X.T@y #X.T@X等价于X.T.dot(X) return theta 正规方程及不可逆性（可选）参考视频: 4 - 7 - Normal Equation Noninvertibility (Optional) (6 min).mkv在这段视频中谈谈正规方程 ( normal equation )，以及它们的不可逆性。由于这是一种较为深入的概念，并且总有人问我有关这方面的问题，因此，我想在这里来讨论它，由于概念较为深入，所以对这段可选材料大家放轻松吧，也许你可能会深入地探索下去，并且会觉得理解以后会非常有用。但即使你没有理解正规方程和线性回归的关系，也没有关系。 我们要讲的问题如下：$\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$ 备注：本节最后我把推导过程写下。 有些同学曾经问过我，当计算 $\theta$=inv(X&#39;X ) X&#39;y ，那对于矩阵$X'X$的结果是不可逆的情况咋办呢?如果你懂一点线性代数的知识，你或许会知道，有些矩阵可逆，而有些矩阵不可逆。我们称那些不可逆矩阵为奇异或退化矩阵。问题的重点在于$X'X$的不可逆的问题很少发生，在Octave里，如果你用它来实现$\theta$的计算，你将会得到一个正常的解。在Octave里，有两个函数可以求解矩阵的逆，一个被称为pinv()，另一个是inv()，这两者之间的差异是些许计算过程上的，一个是所谓的伪逆，另一个被称为逆。使用pinv() 函数可以展现数学上的过程，这将计算出$\theta$的值，即便矩阵$X'X$是不可逆的。 在pinv() 和 inv() 之间，又有哪些具体区别呢 ? 其中inv() 引入了先进的数值计算的概念。例如，在预测住房价格时，如果${x_{1} }$是以英尺为尺寸规格计算的房子，${x_{2} }$是以平方米为尺寸规格计算的房子，同时，你也知道1米等于3.28英尺 ( 四舍五入到两位小数 )，这样，你的这两个特征值将始终满足约束：${x_{1} }={x_{2} }*{ {\left( 3.28 \right)}^{2} }$。实际上，你可以用这样的一个线性方程，来展示那两个相关联的特征值，矩阵$X'X$将是不可逆的。 第二个原因是，在你想用大量的特征值，尝试实践你的学习算法的时候，可能会导致矩阵$X'X$的结果是不可逆的。具体地说，在$m$小于或等于n的时候，例如，有$m$等于10个的训练样本也有$n$等于100的特征数量。要找到适合的$(n +1)$ 维参数矢量$\theta$，这将会变成一个101维的矢量，尝试从10个训练样本中找到满足101个参数的值，这工作可能会让你花上一阵子时间，但这并不总是一个好主意。因为，正如我们所看到你只有10个样本，以适应这100或101个参数，数据还是有些少。 稍后我们将看到，如何使用小数据样本以得到这100或101个参数，通常，我们会使用一种叫做正则化的线性代数方法，通过删除某些特征或者是使用某些技术，来解决当$m$比$n$小的时候的问题。即使你有一个相对较小的训练集，也可使用很多的特征来找到很多合适的参数。总之当你发现的矩阵$X'X$的结果是奇异矩阵，或者找到的其它矩阵是不可逆的，我会建议你这么做。 首先，看特征值里是否有一些多余的特征，像这些${x_{1} }$和${x_{2} }$是线性相关的，互为线性函数。同时，当有一些多余的特征时，可以删除这两个重复特征里的其中一个，无须两个特征同时保留，将解决不可逆性的问题。因此，首先应该通过观察所有特征检查是否有多余的特征，如果有多余的就删除掉，直到他们不再是多余的为止，如果特征数量实在太多，我会删除些 用较少的特征来反映尽可能多内容，否则我会考虑使用正规化方法。如果矩阵$X'X$是不可逆的，（通常来说，不会出现这种情况），如果在Octave里，可以用伪逆函数pinv() 来实现。这种使用不同的线性代数库的方法被称为伪逆。即使$X'X$的结果是不可逆的，但算法执行的流程是正确的。总之，出现不可逆矩阵的情况极少发生，所以在大多数实现线性回归中，出现不可逆的问题不应该过多的关注${X^{T} }X$是不可逆的。 增加内容： $\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$ 的推导过程： $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( {h_{\theta} }\left( {x^{(i)} } \right)-{y^{(i)} } \right)}^{2} }}$ 其中：${h_{\theta} }\left( x \right)={\theta^{T} }X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ 将向量表达形式转为矩阵表达形式，则有$J(\theta )=\frac{1}{2}{ {\left( X\theta -y\right)}^{2} }$ ，其中$X$为$m$行$n$列的矩阵（$m$为样本个数，$n$为特征个数），$\theta$为$n$行1列的矩阵，$y$为$m$行1列的矩阵，对$J(\theta )$进行如下变换 $J(\theta )=\frac{1}{2}{ {\left( X\theta -y\right)}^{T} }\left( X\theta -y \right)$ ​ $=\frac{1}{2}\left( { {\theta }^{T} }{ {X}^{T} }-{ {y}^{T} } \right)\left(X\theta -y \right)$ ​ $=\frac{1}{2}\left( { {\theta }^{T} }{ {X}^{T} }X\theta -{ {\theta}^{T} }{ {X}^{T} }y-{ {y}^{T} }X\theta -{ {y}^{T} }y \right)$ 接下来对$J(\theta )$偏导，需要用到以下几个矩阵的求导法则: $\frac{dAB}{dB}={ {A}^{T} }$ $\frac{d{ {X}^{T} }AX}{dX}=2AX$ 所以有: $\frac{\partial J\left( \theta \right)}{\partial \theta }=\frac{1}{2}\left(2{ {X}^{T} }X\theta -{ {X}^{T} }y -{}({ {y}^{T} }X )^{T}-0 \right)$ $=\frac{1}{2}\left(2{ {X}^{T} }X\theta -{ {X}^{T} }y -{ {X}^{T} }y -0 \right)$ ​ $={ {X}^{T} }X\theta -{ {X}^{T} }y$ 令$\frac{\partial J\left( \theta \right)}{\partial \theta }=0$, 则有$\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$ Octave教程(Octave Tutorial)基本操作参考视频: 5 - 1 - Basic Operations (14 min).mkv 在这段视频中，我将教你一种编程语言：Octave语言。你能够用它来非常迅速地实现这门课中我们已经学过的，或者将要学的机器学习算法。 过去我一直尝试用不同的编程语言来教授机器学习，包括C++、Java、Python、Numpy和Octave。我发现当使用像Octave这样的高级语言时，学生能够更快更好地学习并掌握这些算法。事实上，在硅谷，我经常看到进行大规模的机器学习项目的人，通常使用的程序语言就是Octave。(编者注：这是当时的情况，现在主要是用Python) Octave是一种很好的原始语言(prototyping language)，使用Octave你能快速地实现你的算法，剩下的事情，你只需要进行大规模的资源配置，你只用再花时间用C++或Java这些语言把算法重新实现就行了。开发项目的时间是很宝贵的，机器学习的时间也是很宝贵的。所以，如果你能让你的学习算法在Octave上快速的实现，基本的想法实现以后，再用C++或者Java去改写，这样你就能节省出大量的时间。 据我所见，人们使用最多的用于机器学习的原始语言是Octave、MATLAB、Python、NumPy 和R。 Octave很好，因为它是开源的。当然MATLAB也很好，但它不是每个人都买得起的。(貌似国内学生喜欢用收费的matlab，matlab功能要比Octave强大的多，网上有各种D版可以下载)。这次机器学习课的作业也是用matlab的。如果你能够使用matlab，你也可以在这门课里面使用。 如果你会Python、NumPy或者R语言，我也见过有人用 R的，据我所知，这些人不得不中途放弃了，因为这些语言在开发上比较慢，而且，因为这些语言如：Python、NumPy的语法相较于Octave来说，还是更麻烦一点。正因为这样，所以我强烈建议不要用NumPy或者R来完整这门课的作业，我建议在这门课中用Octave来写程序。 本视频将快速地介绍一系列的命令，目标是迅速地展示，通过这一系列Octave的命令，让你知道Octave能用来做什么。 启动Octave： 现在打开Octave，这是Octave命令行。 现在让我示范最基本的Octave代码： 输入5 + 6，然后得到11。 输入3 – 2、5×8、1/2、2^6等等，得到相应答案。 这些都是基本的数学运算。 你也可以做逻辑运算，例如 1==2，计算结果为 false (假)，这里的百分号命令表示注释，1==2 计算结果为假，这里用0表示。 请注意，不等于符号的写法是这个波浪线加上等于符号 ( ~= )，而不是等于感叹号加等号( != )，这是和其他一些编程语言中不太一样的地方。 让我们看看逻辑运算 1 &amp;&amp; 0，使用双&amp;符号表示逻辑与，1 &amp;&amp; 0判断为假，1和0的或运算 1 || 0，其计算结果为真。 还有异或运算 如XOR ( 1, 0 )，其返回值为1 从左向右写着 Octave 324.x版本，是默认的Octave提示，它显示了当前Octave的版本，以及相关的其它信息。 如果你不想看到那个提示，这里有一个隐藏的命令： 输入命令 现在命令提示已经变得简化了。 接下来，我们将谈到Octave的变量。 现在写一个变量，对变量$A$赋值为3，并按下回车键，显示变量$A$等于3。 如果你想分配一个变量，但不希望在屏幕上显示结果，你可以在命令后加一个分号，可以抑制打印输出，敲入回车后，不打印任何东西。 其中这句命令不打印任何东西。 现在举一个字符串的例子：变量$b$等于”hi“。 $c$等于3大于等于1，所以，现在$c$变量的值是真。 如果你想打印出变量，或显示一个变量，你可以像下面这么做： 设置$a$等于圆周率$π$，如果我要打印该值，那么只需键入a像这样 就打印出来了。 对于更复杂的屏幕输出，也可以用DISP命令显示： 这是一种，旧风格的C语言语法，对于之前就学过C语言的同学来说，你可以使用这种基本的语法来将结果打印到屏幕。 例如 ^{T}命令的六个小数：0.6%f ,a，这应该打印$π$的6位小数形式。 也有一些控制输出长短格式的快捷命令： 下面，让我们来看看向量和矩阵： 比方说 建立一个矩阵$A$： 对$A$矩阵进行赋值，考虑到这是一个三行两列的矩阵，你同样可以用向量。 建立向量$V$并赋值1 2 3，$V$是一个行向量，或者说是一个3 ( 列 )×1 ( 行 )的向量，或者说，一行三列的矩阵。 如果我想，分配一个列向量，我可以写“1;2;3”，现在便有了一个3 行 1 列的向量，同时这是一个列向量。 下面是一些更为有用的符号，如： V=1：0.1：2 这个该如何理解呢：这个集合{% raw %}$v${% endraw %}是一组值，从数值1开始，增量或说是步长为0.1，直到增加到2，按照这样的方法对向量{% raw %}$V${% endraw %}操作，可以得到一个行向量，这是一个1行11列的矩阵，其矩阵的元素是11.1 1.2 1.3，依此类推，直到数值2。 我也可以建立一个集合{% raw %}$v${% endraw %}并用命令“1:6”进行赋值，这样{% raw %}$V${% endraw %}就被赋值了1至6的六个整数。 这里还有一些其他的方法来生成矩阵 例如“ones(2, 3)”，也可以用来生成矩阵： 元素都为2，两行三列的矩阵，就可以使用这个命令： 你可以把这个方法当成一个生成矩阵的快速方法。 {% raw %}$w${% endraw %}为一个一行三列的零矩阵，一行三列的{% raw %}$A${% endraw %}矩阵里的元素全部是零： 还有很多的方式来生成矩阵。 如果我对{% raw %}$W${% endraw %}进行赋值，用Rand命令建立一个一行三列的矩阵，因为使用了Rand命令，则其一行三列的元素均为随机值，如“rand(3,3)”命令，这就生成了一个3×3的矩阵，并且其所有元素均为随机。 数值介于0和1之间，所以，正是因为这一点，我们可以得到数值均匀介于0和1之间的元素。 如果，你知道什么是高斯随机变量，或者，你知道什么是正态分布的随机变量，你可以设置集合{% raw %}$W${% endraw %}，使其等于一个一行三列的{% raw %}$N${% endraw %}矩阵，并且，来自三个值，一个平均值为0的高斯分布，方差或者等于1的标准偏差。 还可以设置地更复杂： 并用hist命令绘制直方图。 绘制单位矩阵： 如果对命令不清楚，建议用help命令： 以上讲解的内容都是Octave的基本操作。希望你能通过上面的讲解，自己练习一些矩阵、乘、加等操作，将这些操作在Octave中熟练运用。 在接下来的视频中，将会涉及更多复杂的命令，并使用它们在Octave中对数据进行更多的操作。 移动数据参考视频: 5 - 2 - Moving Data Around (16 min).mkv 在这段关于 Octave的辅导课视频中，我将开始介绍如何在 Octave 中移动数据。 如果你有一个机器学习问题，你怎样把数据加载到 Octave 中？ 怎样把数据存入一个矩阵？ 如何对矩阵进行相乘？ 如何保存计算结果？ 如何移动这些数据并用数据进行操作？ 进入我的 Octave 窗口， 我键入{% raw %}$A${% endraw %}，得到我们之前构建的矩阵 {% raw %}$A${% endraw %}，也就是用这个命令生成的： A = [1 2; 3 4; 5 6] 这是一个3行2列的矩阵，Octave 中的 size() 命令返回矩阵的尺寸。 所以 size(A) 命令返回3 2 实际上，size() 命令返回的是一个 1×2 的矩阵，我们可以用 {% raw %}$sz${% endraw %} 来存放。 设置 sz = size(A) 因此 {% raw %}$sz${% endraw %} 就是一个1×2的矩阵，第一个元素是3，第二个元素是2。 所以如果键入 size(sz) 看看 {% raw %}$sz${% endraw %} 的尺寸，返回的是1 2，表示是一个1×2的矩阵，1 和 2分别表示矩阵{% raw %}$sz${% endraw %}的维度 。 你也可以键入 size(A, 1)，将返回3，这个命令会返回{% raw %}$A${% endraw %}矩阵的第一个元素，{% raw %}$A${% endraw %}矩阵的第一个维度的尺寸，也就是 {% raw %}$A${% endraw %} 矩阵的行数。 同样，命令 size(A, 2)，将返回2，也就是 {% raw %}$A${% endraw %} 矩阵的列数。 如果你有一个向量 {% raw %}$v${% endraw %}，假如 v = [1 2 3 4]，然后键入length(v)，这个命令将返回最大维度的大小，返回4。 你也可以键入length(A)，由于矩阵{% raw %}$A${% endraw %}是一个3×2的矩阵，因此最大的维度应该是3，因此该命令会返回3。 但通常我们还是对向量使用 {% raw %}$length${% endraw %} 命令，而不是对矩阵使用 length 命令，比如length([1;2;3;4;5])，返回5。 如何在系统中加载数据和寻找数据： 当我们打开 Octave 时，我们通常已经在一个默认路径中，这个路径是 Octave的安装位置，pwd 命令可以显示出Octave 当前所处路径。 cd命令，意思是改变路径，我可以把路径改为C:\Users\ang\Desktop，这样当前目录就变为了桌面。 如果键入 ls，ls 来自于一个 Unix 或者 Linux 命令，ls命令将列出我桌面上的所有路径。 事实上，我的桌面上有两个文件：featuresX.dat 和priceY.dat，是两个我想解决的机器学习问题。 featuresX文件如这个窗口所示，是一个含有两列数据的文件，其实就是我的房屋价格数据，数据集中有47行，第一个房子样本，面积是2104平方英尺，有3个卧室，第二套房子面积为1600，有3个卧室等等。 priceY这个文件就是训练集中的价格数据，所以 featuresX 和priceY就是两个存放数据的文档，那么应该怎样把数据读入 Octave 呢？我们只需要键入featuresX.dat，这样我将加载了 featuresX 文件。同样地我可以加载priceY.dat。其实有好多种办法可以完成，如果你把命令写成字符串的形式load(&#39;featureX.dat&#39;)，也是可以的，这跟刚才的命令效果是相同的，只不过是把文件名写成了一个字符串的形式，现在文件名被存在一个字符串中。Octave中使用引号来表示字符串。 另外 who 命令，能显示出 在我的 Octave工作空间中的所有变量 所以我可以键入featuresX 回车，来显示 featuresX 这些就是存在里面的数据。 还可以键入 size(featuresX)，得出的结果是 47 2，代表这是一个47×2的矩阵。 类似地，输入 size(priceY)，结果是 471，表示这是一个47维的向量，是一个列矩阵，存放的是训练集中的所有价格{% raw %}$Y${% endraw %} 的值。 who 函数能让你看到当前工作空间中的所有变量，同样还有另一个 whos命令，能更详细地进行查看。 同样也列出我所有的变量，不仅如此，还列出了变量的维度。 double 意思是双精度浮点型，这也就是说，这些数都是实数，是浮点数。 如果你想删除某个变量，你可以使用 clear 命令，我们键入 clear featuresX，然后再输入 whos 命令，你会发现 featuresX 消失了。 另外，我们怎么储存数据呢？ 我们设变量 V= priceY(1:10) 这表示的是将向量 {% raw %}$Y ${% endraw %}的前10个元素存入 {% raw %}$V${% endraw %}中。 假如我们想把它存入硬盘，那么用 save hello.mat v 命令，这个命令会将变量{% raw %}$V${% endraw %}存成一个叫 hello.mat 的文件，让我们回车，现在我的桌面上就出现了一个新文件，名为hello.mat。 由于我的电脑里同时安装了 MATLAB，所以这个图标上面有 MATLAB的标识，因为操作系统把文件识别为 MATLAB文件。如果在你的电脑上图标显示的不一样的话，也没有关系。 现在我们清除所有变量，直接键入clear，这样将删除工作空间中的所有变量，所以现在工作空间中啥都没了。 但如果我载入 hello.mat 文件，我又重新读取了变量 {% raw %}$v${% endraw %}，因为我之前把变量{% raw %}$v${% endraw %}存入了hello.mat 文件中，所以我们刚才用 save命令做了什么。这个命令把数据按照二进制形式储存，或者说是更压缩的二进制形式，因此，如果{% raw %}$v${% endraw %}是很大的数据，那么压缩幅度也更大，占用空间也更小。如果你想把数据存成一个人能看懂的形式，那么可以键入： save hello.txt v -ascii 这样就会把数据存成一个文本文档，或者将数据的 ascii 码存成文本文档。 我键入了这个命令以后，我的桌面上就有了 hello.txt文件。如果打开它，我们可以发现这个文本文档存放着我们的数据。 这就是读取和储存数据的方法。 接下来我们再来讲讲操作数据的方法： 假如 {% raw %}$A${% endraw %} 还是那个矩阵 跟刚才一样还是那个 3×2 的矩阵，现在我们加上索引值，比如键入 A(3,2) 这将索引到{% raw %}$A${% endraw %} 矩阵的 (3,2) 元素。这就是我们通常书写矩阵的形式，写成 {% raw %}$A${% endraw %} 32，3和2分别表示矩阵的第三行和第二列对应的元素，因此也就对应 6。 我也可以键入A(2,:) 来返回第二行的所有元素，冒号表示该行或该列的所有元素。 类似地，如果我键入 A(:,2)，这将返回 {% raw %}$A${% endraw %} 矩阵第二列的所有元素，这将得到 2 4 6。 这表示返回{% raw %}$A${% endraw %} 矩阵的第二列的所有元素。 你也可以在运算中使用这些较为复杂的索引。 我再给你展示几个例子，可能你也不会经常使用，但我还是输入给你看 A([1 3],:)，这个命令意思是取 {% raw %}$A${% endraw %} 矩阵第一个索引值为1或3的元素，也就是说我取的是A矩阵的第一行和第三行的每一列，冒号表示的是取这两行的每一列元素，即： 可能这些比较复杂一点的索引操作你会经常用到。 我们还能做什么呢？依然是 {% raw %}$A${% endraw %} 矩阵，A(:,2) 命令返回第二列。 你也可以为它赋值，我可以取 {% raw %}$A${% endraw %} 矩阵的第二列，然后将它赋值为10 11 12，我实际上是取出了 {% raw %}$A${% endraw %} 的第二列，然后把一个列向量[10;11;12]赋给了它，因此现在 {% raw %}$A${% endraw %} 矩阵的第一列还是 1 3 5，第二列就被替换为 10 11 12。 接下来一个操作，让我们把 {% raw %}$A ${% endraw %}设为A = [A, [100, 101,102]]，这样做的结果是在原矩阵的右边附加了一个新的列矩阵，就是把 {% raw %}$A${% endraw %}矩阵设置为原来的 {% raw %}$A${% endraw %} 矩阵再在右边附上一个新添加的列矩阵。 最后，还有一个小技巧，如果你就输入 A(:)，这是一个很特别的语法结构，意思是把 {% raw %}$A${% endraw %}中的所有元素放入一个单独的列向量，这样我们就得到了一个 9×1 的向量，这些元素都是{% raw %}$A${% endraw %} 中的元素排列起来的。 再来几个例子： 我还是把 A 重新设为 [1 2; 3 4; 5 6]，我再设一个 {% raw %}$B${% endraw %}为[11 12; 13 14; 15 16]，我可以新建一个矩阵 {% raw %}$C${% endraw %}，C = [A B]，这个意思就是把这两个矩阵直接连在一起，矩阵{% raw %}$A${% endraw %} 在左边，矩阵{% raw %}$B${% endraw %} 在右边，这样组成了 {% raw %}$C${% endraw %}矩阵，就是直接把{% raw %}$A${% endraw %}和 {% raw %}$B${% endraw %} 合起来。 我还可以设C = [A; B]，这里的分号表示把分号后面的东西放到下面。所以，[A;B]的作用依然还是把两个矩阵放在一起，只不过现在是上下排列，所以现在 {% raw %}$A${% endraw %} 在上面 {% raw %}$B${% endraw %}在下面，{% raw %}$C${% endraw %} 就是一个 6×2 矩阵。 简单地说，分号的意思就是换到下一行，所以 C 就包括上面的A，然后换行到下面，然后在下面放上一个 {% raw %}$B${% endraw %}。 另外顺便说一下，这个[A B]命令跟 [A, B] 是一样的，这两种写法的结果是相同的。 通过以上这些操作，希望你现在掌握了怎样构建矩阵，也希望我展示的这些命令能让你很快地学会怎样把矩阵放到一起，怎样取出矩阵，并且把它们放到一起，组成更大的矩阵。 通过几句简单的代码，Octave能够很方便地很快速地帮助我们组合复杂的矩阵以及对数据进行移动。这就是移动数据这一节课。 我认为对你来讲，最好的学习方法是，下课后复习一下我键入的这些代码好好地看一看，从课程的网上把代码的副本下载下来，重新好好看看这些副本，然后自己在Octave 中把这些命令重新输一遍，慢慢开始学会使用这些命令。 当然，没有必要把这些命令都记住，你也不可能记得住。你要做的就是，了解一下你可以用哪些命令，做哪些事。这样在你今后需要编写学习算法时，如果你要找到某个Octave中的命令，你可能回想起你之前在这里学到过，然后你就可以查找课程中提供的程序副本，这样就能很轻松地找到你想使用的命令了。 计算数据参考视频: 5 - 3 - Computing on Data (13 min).mkv 现在，你已经学会了在Octave中如何加载或存储数据，如何把数据存入矩阵等等。在这段视频中，我将介绍如何对数据进行运算，稍后我们将使用这些运算操作来实现我们的学习算法。 这是我的 Octave窗口，我现在快速地初始化一些变量。比如设置{% raw %}$A${% endraw %}为一个3×2的矩阵，设置{% raw %}$B${% endraw %}为一个3 ×2矩阵，设置{% raw %}$C${% endraw %}为2 × 2矩阵。 我想算两个矩阵的乘积，比如说 {% raw %}$A × C${% endraw %}，我只需键入A×C，这是一个 3×2 矩阵乘以 2×2矩阵，得到这样一个3×2矩阵。 你也可以对每一个元素，做运算 方法是做点乘运算A.*B，这么做Octave将矩阵 {% raw %}$A${% endraw %}中的每一个元素与矩阵 {% raw %}$B${% endraw %} 中的对应元素相乘:A.*B 这里第一个元素1乘以11得到11，第二个元素2乘以12得到24，这就是两个矩阵的元素位运算。通常来说，在Octave中点号一般用来表示元素位运算。 这里是一个矩阵{% raw %}$A${% endraw %}，这里我输入A.^2，这将对矩阵{% raw %}$A${% endraw %}中每一个元素平方。 我们设{% raw %}$V${% endraw %}为 [1; 2; 3] 是列向量，你也可以输入1./V，得到每一个元素的倒数，所以这样一来，就会分别算出 1/1 1/2 1/3。 矩阵也可以这样操作，1./A 得到{% raw %}$A${% endraw %}中每一个元素的倒数。 同样地，这里的点号还是表示对每一个元素进行操作。 我们还可以进行求对数运算，也就是对每个元素进行求对数运算。 还有自然数{% raw %}$e${% endraw %}的幂次运算，就是以{% raw %}$e${% endraw %}为底，以这些元素为幂的运算。 我还可以用 abs来对 {% raw %}$v${% endraw %} 的每一个元素求绝对值，当然这里 {% raw %}$v${% endraw %}都是正数。我们换成另一个这样对每个元素求绝对值，得到的结果就是这些非负的元素。还有{% raw %}$–v${% endraw %}，给出{% raw %}$v${% endraw %}中每个元素的相反数，这等价于 -1 乘以 {% raw %}$v${% endraw %}，一般就直接用 {% raw %}$-v${% endraw %}就好了，其实就等于 $-1*v$。 还有一个技巧，比如说我们想对{% raw %}$v${% endraw %}中的每个元素都加1，那么我们可以这么做，首先构造一个3行1列的1向量，然后把这个1向量跟原来的向量相加，因此{% raw %}$v${% endraw %}向量从[1 2 3] 增至 [2 3 4]。我用了一个，length(v)命令，因此这样一来，ones(length(v) ,1) 就相当于ones(3,1)，然后我做的是v +ones(3,1)，也就是将 {% raw %}$v${% endraw %} 的各元素都加上这些1，这样就将{% raw %}$v${% endraw %} 的每个元素增加了1。 另一种更简单的方法是直接用 v+1，v + 1 也就等于把 {% raw %}$v${% endraw %} 中的每一个元素都加上1。 现在，让我们来谈谈更多的操作。 矩阵{% raw %}$A${% endraw %} 如果你想要求它的转置，那么方法是用A’,将得出 A 的转置矩阵。当然，如果我写(A&#39;)&#39;，也就是 {% raw %}$A${% endraw %} 转置两次，那么我又重新得到矩阵 {% raw %}$A${% endraw %}。 还有一些有用的函数，比如： a=[1 15 2 0.5]，这是一个1行4列矩阵，val=max(a)，这将返回{% raw %}$A${% endraw %}矩阵中的最大值15。 我还可以写 [val, ind] =max(a)，这将返回{% raw %}$A${% endraw %}矩阵中的最大值存入{% raw %}$val${% endraw %}，以及该值对应的索引，元素15对应的索引值为2,存入{% raw %}$ind${% endraw %}，所以 {% raw %}$ind =2${% endraw %}。 特别注意一下，如果你用命令 max(A)，{% raw %}$A${% endraw %}是一个矩阵的话，这样做就是对每一列求最大值。 我们还是用这个例子，这个 {% raw %}$a${% endraw %} 矩阵a=[1 15 2 0.5]，如果输入a&amp;lt;3，这将进行逐元素的运算，所以元素小于3的返回1，否则返回0。 因此，返回[1 1 0 1]。也就是说，对{% raw %}$a${% endraw %}矩阵的每一个元素与3进行比较，然后根据每一个元素与3的大小关系，返回1和0表示真与假。 如果我写 find(a&amp;lt;3)，这将告诉我{% raw %}$a${% endraw %} 中的哪些元素是小于3的。 设A = magic(3)，magic 函数将返回一个矩阵，称为魔方阵或幻方 (magic squares)，它们具有以下这样的数学性质：它们所有的行和列和对角线加起来都等于相同的值。 当然据我所知，这在机器学习里基本用不上，但我可以用这个方法很方便地生成一个3行3列的矩阵，而这个魔方矩阵这神奇的方形屏幕。每一行、每一列、每一个对角线三个数字加起来都是等于同一个数。 在其他有用的机器学习应用中，这个矩阵其实没多大作用。 如果我输入 [r,c] = find(A&gt;=7)，这将找出所有{% raw %}$A${% endraw %}矩阵中大于等于7的元素，因此，{% raw %}$r${% endraw %} 和{% raw %}$c${% endraw %}分别表示行和列，这就表示，第一行第一列的元素大于等于7，第三行第二列的元素大于等于7，第二行第三列的元素大于等于7。 顺便说一句，其实我从来都不去刻意记住这个 find 函数，到底是怎么用的，我只需要会用help函数就可以了，每当我在使用这个函数，忘记怎么用的时候，我就可以用 help函数，键入 help find 来找到帮助文档。 最后再讲两个内容，一个是求和函数，这是 {% raw %}$a${% endraw %} 矩阵： 键入 sum(a)，就把 a 中所有元素加起来了。 如果我想把它们都乘起来，键入 prod(a)，prod 意思是product(乘积)，它将返回这四个元素的乘积。 floor(a) 是向下四舍五入，因此对于 {% raw %}$a${% endraw %} 中的元素0.5将被下舍入变成0。 还有 ceil(a)，表示向上四舍五入，所以0.5将上舍入变为最接近的整数，也就是1。 键入 type(3)，这通常得到一个3×3的矩阵，如果键入 max(rand(3),rand(3))，这样做的结果是返回两个3×3的随机矩阵，并且逐元素比较取最大值。 假如我输入max(A,[],1)，这样做会得到每一列的最大值。 所以第一列的最大值就是8，第二列是9，第三列的最大值是7，这里的1表示取A矩阵第一个维度的最大值。 相对地，如果我键入max(A,[],2)，这将得到每一行的最大值，所以，第一行的最大值是等于8，第二行最大值是7，第三行是9。 所以你可以用这个方法来求得每一行或每一列的最值，另外，你要知道，默认情况下max(A)返回的是每一列的最大值，如果你想要找出整个矩阵A的最大值，你可以输入max(max(A))，或者你可以将{% raw %}$A${% endraw %} 矩阵转成一个向量，然后键入 max(A(:))，这样做就是把 {% raw %}$A${% endraw %} 当做一个向量，并返回 {% raw %}$A${% endraw %}向量中的最大值。 最后，让我们把 {% raw %}$A${% endraw %}设为一个9行9列的魔方阵，魔方阵具有的特性是每行每列和对角线的求和都是相等的。 这是一个9×9的魔方阵，我们来求一个 sum(A,1)，这样就得到每一列的总和，这也验证了一个9×9的魔方阵确实每一列加起来都相等，都为369。 现在我们来求每一行的和，键入sum(A,2)，这样就得到了{% raw %}$A${% endraw %} 中每一行的和加起来还是369。 现在我们来算{% raw %}$A ${% endraw %}的对角线元素的和。我们现在构造一个9×9 的单位矩阵，键入 eye(9), 然后我们要用 {% raw %}$A${% endraw %}逐点乘以这个单位矩阵，除了对角线元素外，其他元素都会得到0。 键入sum(sum(A.*eye(9)) 这实际上是求得了，这个矩阵对角线元素的和确实是369。 你也可以求另一条对角线的和也是是369。 flipup/flipud 表示向上/向下翻转。 同样地，如果你想求这个矩阵的逆矩阵，键入pinv(A)，通常称为伪逆矩阵，你就把它看成是矩阵 {% raw %}$A${% endraw %} 求逆，因此这就是 {% raw %}$A${% endraw %}矩阵的逆矩阵。 设 temp = pinv(A)，然后再用{% raw %}$temp${% endraw %} 乘以{% raw %}$A${% endraw %}，这实际上得到的就是单位矩阵，对角线为1，其他元素为0。 如何对矩阵中的数字进行各种操作，在运行完某个学习算法之后，通常一件最有用的事情是看看你的结果，或者说让你的结果可视化，在接下来的视频中，我会非常迅速地告诉你，如何很快地画图，如何只用一两行代码，你就可以快速地可视化你的数据，这样你就能更好地理解你使用的学习算法。 绘图数据参考视频: 5 - 4 - Plotting Data (10 min).mkv 当开发学习算法时，往往几个简单的图，可以让你更好地理解算法的内容，并且可以完整地检查下算法是否正常运行，是否达到了算法的目的。 例如在之前的视频中，我谈到了绘制成本函数{% raw %}$J(\theta)${% endraw %}，可以帮助确认梯度下降算法是否收敛。通常情况下，绘制数据或学习算法所有输出，也会启发你如何改进你的学习算法。幸运的是，Octave有非常简单的工具用来生成大量不同的图。当我用学习算法时，我发现绘制数据、绘制学习算法等，往往是我获得想法来改进算法的重要部分。在这段视频中，我想告诉你一些Octave的工具来绘制和可视化你的数据。 我们先来快速生成一些数据用来绘图。 如果我想绘制正弦函数，这是很容易的，我只需要输入plot(t,y1)，并回车，就出现了这个图： 横轴是{% raw %}$t${% endraw %}变量，纵轴是{% raw %}$y1${% endraw %}，也就是我们刚刚所输出的正弦函数。 让我们设置{% raw %}$y2${% endraw %} Octave将会消除之前的正弦图，并且用这个余弦图来代替它，这里纵轴{% raw %}$cos(x)${% endraw %}从1开始， 如果我要同时表示正弦和余弦曲线。 我要做的就是，输入：plot(t, y1)，得到正弦函数，我使用函数hold on，hold on函数的功能是将新的图像绘制在旧的之上。 我现在绘制{% raw %}$y2${% endraw %}，输入：plot(t, y2)。 我要以不同的颜色绘制余弦函数，所以我在这里输入带引号的r绘制余弦函数，{% raw %}$r${% endraw %}表示所使用的颜色：plot(t,y2,’r’)，再加上命令xlabel(&#39;time&#39;)，来标记X轴即水平轴，输入ylabel(&#39;value&#39;)，来标记垂直轴的值。 同时我也可以来标记我的两条函数曲线，用这个命令 legend(&#39;sin&#39;,&#39;cos&#39;)将这个图例放在右上方，表示这两条曲线表示的内容。最后输入title(&#39;myplot&#39;)，在图像的顶部显示这幅图的标题。 如果你想保存这幅图像，你输入print –dpng &#39;myplot.png&#39;，png是一个图像文件格式，如果你这样做了，它可以让你保存为一个文件。 Octave也可以保存为很多其他的格式，你可以键入help plot。 最后如果你想，删掉这个图像，用命令close会让这个图像关掉。 Octave也可以让你为图像标号 你键入figure(1); plot(t, y1);将显示第一张图，绘制了变量{% raw %}$t${% endraw %} {% raw %}$y1${% endraw %}。 键入figure(2); plot(t, y2); 将显示第一张图，绘制了变量{% raw %}$t${% endraw %} {% raw %}$y2${% endraw %}。 subplot命令，我们要使用subplot(1,2,1)，它将图像分为一个1*2的格子，也就是前两个参数，然后它使用第一个格子，也就是最后一个参数1的意思。 我现在使用第一个格子，如果键入plot(t,y1)，现在这个图显示在第一个格子。如果我键入subplot(1,2,2)，那么我就要使用第二个格子，键入plot(t,y2)；现在y2显示在右边，也就是第二个格子。 最后一个命令，你可以改变轴的刻度，比如改成[0.5 1 -1 1]，输入命令：axis([0.5 1 -1 1])也就是设置了右边图的{% raw %}$x${% endraw %}轴和{% raw %}$y${% endraw %}轴的范围。具体而言，它将右图中的横轴的范围调整至0.5到1，竖轴的范围为-1到1。 你不需要记住所有这些命令，如果你需要改变坐标轴，或者需要知道axis命令，你可以用Octave中用help命令了解细节。 最后，还有几个命令。 Clf（清除一幅图像）。 让我们设置A等于一个5×5的magic方阵： 我有时用一个巧妙的方法来可视化矩阵，也就是imagesc(A)命令，它将会绘制一个5*5的矩阵，一个5*5的彩色格图，不同的颜色对应A矩阵中的不同值。 我还可以使用函数colorbar，让我用一个更复杂的命令 imagesc(A)，colorbar，colormap gray。这实际上是在同一时间运行三个命令：运行imagesc，然后运行，colorbar，然后运行colormap gray。 它生成了一个颜色图像，一个灰度分布图，并在右边也加入一个颜色条。所以这个颜色条显示不同深浅的颜色所对应的值。 你可以看到在不同的方格，它对应于一个不同的灰度。 输入imagesc(magic(15))，colorbar，colormap gray 这将会是一幅15*15的magic方阵值的图。 最后，总结一下这段视频。你看到我所做的是使用逗号连接函数调用。如果我键入{% raw %}$a=1${% endraw %},{% raw %}$b=2${% endraw %},{% raw %}$c=3${% endraw %}然后按Enter键，其实这是将这三个命令同时执行，或者是将三个命令一个接一个执行，它将输出所有这三个结果。 这很像{% raw %}$a=1${% endraw %}; {% raw %}$b=2${% endraw %};{% raw %}$c=3${% endraw %};如果我用分号来代替逗号，则没有输出出任何东西。 这里我们称之为逗号连接的命令或函数调用。 用逗号连接是另一种Octave中更便捷的方式，将多条命令例如imagesc colorbar colormap，将这多条命令写在同一行中。 现在你知道如何绘制Octave中不同的图像，在下面的视频中，我将告诉你怎样在Octave中，写控制语句，比如if while for语句，并且定义和使用函数。 控制语句：for，while，if语句参考视频: 5 - 5 - Control Statements_ for, while, if statements (13 min).mkv 在这段视频中，我想告诉你怎样为你的 Octave 程序写控制语句。诸如：”for“ “while“ “if“ 这些语句，并且如何定义和使用方程。 我先告诉你如何使用 “for” 循环。 首先，我要将 {% raw %}$v${% endraw %} 值设为一个10行1列的零向量。 接着我要写一个 “for“ 循环，让 {% raw %}$i${% endraw %} 等于 1 到 10，写出来就是 i = 1:10。我要设{% raw %}$ v(i)${% endraw %}的值等于 2 的 {% raw %}$i${% endraw %} 次方，循环最后写上“end”。 向量{% raw %}$v${% endraw %} 的值就是这样一个集合 2的一次方、2的二次方，依此类推。这就是我的 {% raw %}$i${% endraw %} 等于 1 到 10的语句结构，让 {% raw %}$i${% endraw %} 遍历 1 到 10的值。 另外，你还可以通过设置你的 indices (索引) 等于 1一直到10，来做到这一点。这时indices 就是一个从1到10的序列。 你也可以写 i = indices，这实际上和我直接把 i 写到 1 到 10 是一样。你可以写 disp(i)，也能得到一样的结果。所以 这就是一个 “for” 循环。 如果你对 “break” 和 “continue” 语句比较熟悉，Octave里也有 “break” 和 “continue”语句，你也可以在 Octave环境里使用那些循环语句。 但是首先让我告诉你一个 while 循环是如何工作的： 这是什么意思呢：我让 {% raw %}$i${% endraw %} 取值从 1 开始，然后我要让 {% raw %}$v(i)${% endraw %} 等于 100，再让 {% raw %}$i${% endraw %} 递增 1，直到{% raw %}$i${% endraw %} 大于 5停止。 现在来看一下结果，我现在已经取出了向量的前五个元素，把他们用100覆盖掉，这就是一个while循环的句法结构。 现在我们来分析另外一个例子： 这里我将向你展示如何使用break语句。比方说 v(i) = 999，然后让 i = i+1，当 {% raw %}$i${% endraw %} 等于6的时候 break (停止循环)，结束 (end)。 当然这也是我们第一次使用一个 if 语句，所以我希望你们可以理解这个逻辑，让 {% raw %}$i${% endraw %} 等于1 然后开始下面的增量循环，while语句重复设置 {% raw %}$v(i)${% endraw %} 等于999，不断让{% raw %}$i${% endraw %}增加，然后当 {% raw %}$i${% endraw %} 达到6，做一个中止循环的命令，尽管有while循环，语句也就此中止。所以最后的结果是取出向量 {% raw %}$v${% endraw %} 的前5个元素，并且把它们设置为999。 所以，这就是if 语句和 while 语句的句法结构。并且要注意要有end，上面的例子里第一个 end 结束的是 if语句，第二个 end 结束的是 while 语句。 现在让我告诉你使用 if-else 语句： 最后，提醒一件事：如果你需要退出 Octave，你可以键入exit命令然后回车就会退出 Octave，或者命令quit也可以。 最后，让我们来说说函数 (functions)，如何定义和调用函数。 我在桌面上存了一个预先定义的文件名为 “squarethisnumber.m”，这就是在 Octave 环境下定义的函数。 让我们打开这个文件。请注意，我使用的是微软的写字板程序来打开这个文件，我只是想建议你，如果你也使用微软的Windows系统，那么可以使用写字板程序，而不是记事本来打开这些文件。如果你有别的什么文本编辑器也可以，记事本有时会把代码的间距弄得很乱。如果你只有记事本程序，那也能用。我建议你用写字板或者其他可以编辑函数的文本编辑器。 现在我们来说如何在 Octave 里定义函数： 这个文件只有三行： 第一行写着 function y = squareThisNumber(x)，这就告诉 Octave，我想返回一个 y值，我想返回一个值，并且返回的这个值将被存放于变量 {% raw %}$y${% endraw %} 里。另外，它告诉了Octave这个函数有一个参数，就是参数 {% raw %}$x${% endraw %}，还有定义的函数体，也就是 {% raw %}$y${% endraw %} 等于 {% raw %}$x${% endraw %} 的平方。 还有一种更高级的功能，这只是对那些知道“search path (搜索路径)”这个术语的人使用的。所以如果你想要修改Octave的搜索路径，你可以把下面这部分作为一个进阶知识，或者选学材料，仅适用于那些熟悉编程语言中搜索路径概念的同学。 你可以使用addpath 命令添加路径，添加路径“C:\Users\ang\desktop”将该目录添加到Octave的搜索路径，这样即使你跑到其他路径底下，Octave依然知道会在 Users\ang\desktop目录下寻找函数。这样，即使我现在在不同的目录下，它仍然知道在哪里可以找到“SquareThisNumber” 这个函数。 但是，如果你不熟悉搜索路径的概念，不用担心，只要确保在执行函数之前，先用 cd命令设置到你函数所在的目录下，实际上也是一样的效果。 Octave还有一个其他许多编程语言都没有的概念，那就是它可以允许你定义一个函数，使得返回值是多个值或多个参数。这里就是一个例子，定义一个函数叫： “SquareAndCubeThisNumber(x)” ({% raw %}$x${% endraw %}的平方以及{% raw %}$x${% endraw %}的立方) 这说的就是函数返回值是两个： {% raw %}$y1${% endraw %} 和 {% raw %}$y2${% endraw %}，接下来就是{% raw %}$y1${% endraw %}是被平方后的结果，{% raw %}$y2${% endraw %}是被立方后的结果，这就是说，函数会真的返回2个值。 有些同学可能会根据你使用的编程语言，比如你们可能熟悉的C或C++，通常情况下，认为作为函数返回值只能是一个值，但Octave 的语法结构就不一样，可以返回多个值。 如果我键入 [a,b] = SquareAndCubeThisNumber(5)，然后，{% raw %}$a${% endraw %}就等于25，{% raw %}$b${% endraw %} 就等于5的立方125。 所以说如果你需要定义一个函数并且返回多个值，这一点常常会带来很多方便。 最后，我来给大家演示一下一个更复杂一点的函数的例子。 比方说，我有一个数据集，像这样，数据点为[1,1], [2,2],[3,3]，我想做的事是定义一个 Octave 函数来计算代价函数 {% raw %}$J(\theta)${% endraw %}，就是计算不同 {% raw %}$\theta${% endraw %}值所对应的代价函数值{% raw %}$J${% endraw %}。 首先让我们把数据放到 Octave 里，我把我的矩阵设置为X = [1 1; 1 2; 1 3]; 请仔细看一下这个函数的定义，确保你明白了定义中的每一步。 现在当我在 Octave 里运行时，我键入 J = costFunctionJ (X, y, theta)，它就计算出 {% raw %}$J${% endraw %}等于0，这是因为如果我的数据集{% raw %}$x${% endraw %} 为 [1;2;3]， {% raw %}$y${% endraw %} 也为 [1;2;3] 然后设置 {% raw %}$\theta_0${% endraw %} 等于0，{% raw %}$\theta_1${% endraw %}等于1，这给了我恰好45度的斜线，这条线是可以完美拟合我的数据集的。 而相反地，如果我设置{% raw %}$\theta${% endraw %} 等于[0;0]，那么这个假设就是0是所有的预测值，和刚才一样，设置{% raw %}$\theta_0${% endraw %} = 0，{% raw %}$\theta_1${% endraw %}也等于0，然后我计算的代价函数，结果是2.333。实际上，他就等于1的平方，也就是第一个样本的平方误差，加上2的平方，加上3的平方，然后除以{% raw %}$2m${% endraw %}，也就是训练样本数的两倍，这就是2.33。 因此这也反过来验证了我们这里的函数，计算出了正确的代价函数。这些就是我们用简单的训练样本尝试的几次试验，这也可以作为我们对定义的代价函数{% raw %}$J${% endraw %}进行了完整性检查。确实是可以计算出正确的代价函数的。至少基于这里的 {% raw %}$x${% endraw %}和 {% raw %}$y${% endraw %}是成立的。也就是我们这几个简单的训练集，至少是成立的。 现在你知道如何在 Octave 环境下写出正确的控制语句，比如 for 循环、while 循环和 if语句，以及如何定义和使用函数。 在接下来的Octave 教程视频里，我会讲解一下向量化，这是一种可以使你的 Octave程序运行非常快的思想。 向量化参考视频: 5 - 6 - Vectorization (14 min).mkv 在这段视频中，我将介绍有关向量化的内容，无论你是用Octave，还是别的语言，比如MATLAB或者你正在用Python、NumPy 或 Java C C++，所有这些语言都具有各种线性代数库，这些库文件都是内置的，容易阅读和获取，他们通常写得很好，已经经过高度优化，通常是数值计算方面的博士或者专业人士开发的。 而当你实现机器学习算法时，如果你能好好利用这些线性代数库，或者数值线性代数库，并联合调用它们，而不是自己去做那些函数库可以做的事情。如果是这样的话，那么通常你会发现：首先，这样更有效，也就是说运行速度更快，并且更好地利用你的计算机里可能有的一些并行硬件系统等等；其次，这也意味着你可以用更少的代码来实现你需要的功能。因此，实现的方式更简单，代码出现问题的有可能性也就越小。 举个具体的例子：与其自己写代码做矩阵乘法。如果你只在Octave中输入{% raw %}$a${% endraw %}乘以{% raw %}$b${% endraw %}就是一个非常有效的两个矩阵相乘的程序。有很多例子可以说明，如果你用合适的向量化方法来实现，你就会有一个简单得多，也有效得多的代码。 让我们来看一些例子：这是一个常见的线性回归假设函数：{% raw %}${ {h}_{\theta } }(x)=\sum\limits_{j=0}^{n}{ {{\theta }_{j} }{ {x}_{j} }}${% endraw %} 如果你想要计算{% raw %}$h_\theta(x)${% endraw %} ，注意到右边是求和，那么你可以自己计算{% raw %}$j = 0${% endraw %} 到{% raw %}$ j = n${% endraw %} 的和。但换另一种方式来想想，把 {% raw %}$h_\theta(x)${% endraw %} 看作{% raw %}$\theta^Tx${% endraw %}，那么你就可以写成两个向量的内积，其中{% raw %}$\theta${% endraw %}就是{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}，如果你有两个特征量，如果 {% raw %}$n = 2${% endraw %}，并且如果你把 {% raw %}$x${% endraw %} 看作{% raw %}$x_0${% endraw %}、{% raw %}$x_1${% endraw %}、{% raw %}$x_2${% endraw %}，这两种思考角度，会给你两种不同的实现方式。 比如说，这是未向量化的代码实现方式： 计算{% raw %}$h_\theta(x)${% endraw %}是未向量化的，我们可能首先要初始化变量 {% raw %}$prediction${% endraw %} 的值为0.0，而这个变量{% raw %}$prediction${% endraw %} 的最终结果就是{% raw %}$h_\theta(x)${% endraw %}，然后我要用一个 for 循环，{% raw %}$j${% endraw %} 取值 0 到{% raw %}$n+1${% endraw %}，变量{% raw %}$prediction${% endraw %} 每次就通过自身加上{% raw %}$ theta(j) ${% endraw %}乘以 {% raw %}$x(j)${% endraw %}更新值，这个就是算法的代码实现。 顺便我要提醒一下，这里的向量我用的下标是0，所以我有{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}，但因为MATLAB的下标从1开始，在 MATLAB 中{% raw %}$\theta_0${% endraw %}，我们可能会用 {% raw %}$theta(1)${% endraw %} 来表示，这第二个元素最后就会变成，{% raw %}$theta(2${% endraw %}) 而第三个元素，最终可能就用{% raw %}$theta(3)${% endraw %}表示，因为MATLAB中的下标从1开始，这就是为什么这里我的 for 循环，{% raw %}$j${% endraw %}取值从 1 直到{% raw %}$n+1${% endraw %}，而不是从 0 到 {% raw %}$n${% endraw %}。这是一个未向量化的代码实现方式，我们用一个 for 循环对 {% raw %}$n${% endraw %} 个元素进行加和。 作为比较，接下来是向量化的代码实现： 你把x和{% raw %}$\theta${% endraw %}看做向量，而你只需要令变量{% raw %}$prediction${% endraw %}等于{% raw %}$theta${% endraw %}转置乘以{% raw %}$x${% endraw %}，你就可以这样计算。与其写所有这些for循环的代码，你只需要一行代码，这行代码就是利用 Octave 的高度优化的数值，线性代数算法来计算两个向量{% raw %}$\theta${% endraw %}以及{% raw %}$x${% endraw %}的内积，这样向量化的实现更简单，它运行起来也将更加高效。这就是 Octave 所做的而向量化的方法，在其他编程语言中同样可以实现。 让我们来看一个C++ 的例子： 与此相反，使用较好的C++ 数值线性代数库，你可以写出像右边这样的代码，因此取决于你的数值线性代数库的内容。你只需要在C++ 中将两个向量相乘，根据你所使用的数值和线性代数库的使用细节的不同，你最终使用的代码表达方式可能会有些许不同，但是通过一个库来做内积，你可以得到一段更简单、更有效的代码。 现在，让我们来看一个更为复杂的例子，这是线性回归算法梯度下降的更新规则： 我们用这条规则对{% raw %}$ j${% endraw %} 等于 0、1、2等等的所有值，更新对象{% raw %}$\theta_j${% endraw %}，我只是用{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}来写方程，假设我们有两个特征量，所以{% raw %}$n${% endraw %}等于2，这些都是我们需要对{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}进行更新，这些都应该是同步更新，我们用一个向量化的代码实现，这里是和之前相同的三个方程，只不过写得小一点而已。 你可以想象实现这三个方程的方式之一，就是用一个 for 循环，就是让 {% raw %}$j${% endraw %}等于0、等于1、等于2，来更新{% raw %}$\theta_j${% endraw %}。但让我们用向量化的方式来实现，看看我们是否能够有一个更简单的方法。基本上用三行代码或者一个for 循环，一次实现这三个方程。让我们来看看怎样能用这三步，并将它们压缩成一行向量化的代码来实现。做法如下： 我打算把{% raw %}$\theta${% endraw %}看做一个向量，然后我用{% raw %}$\theta${% endraw %}-{% raw %}$\alpha${% endraw %} 乘以某个别的向量{% raw %}$\delta${% endraw %} 来更新{% raw %}$\theta${% endraw %}。 这里的 {% raw %}$\delta${% endraw %} 等于 让我解释一下是怎么回事：我要把{% raw %}$\theta${% endraw %}看作一个向量，有一个 {% raw %}$n+1${% endraw %} 维向量，{% raw %}$\alpha${% endraw %} 是一个实数，{% raw %}$\delta${% endraw %}在这里是一个向量。 所以这个减法运算是一个向量减法，因为 {% raw %}$\alpha${% endraw %} 乘以 δ是一个向量，所以{% raw %}$\theta${% endraw %}就是{% raw %}$\theta${% endraw %} - {% raw %}$\alpha \delta${% endraw %}得到的向量。 那么什么是向量 {% raw %}$\delta${% endraw %} 呢 ? {% raw %}$X^{(i)}${% endraw %}是一个向量 你就会得到这些不同的式子，然后作加和。 实际上，在以前的一个小测验，如果你要解这个方程，我们说过为了向量化这段代码，我们会令u = 2v +5w因此，我们说向量{% raw %}$u${% endraw %}等于2乘以向量{% raw %}$v${% endraw %}加上5乘以向量{% raw %}$w${% endraw %}。用这个例子说明，如何对不同的向量进行相加，这里的求和是同样的道理。 这就是为什么我们能够向量化地实现线性回归。 所以，我希望步骤是有逻辑的。请务必看视频，并且保证你确实能理解它。如果你实在不能理解它们数学上等价的原因，你就直接实现这个算法，也是能得到正确答案的。所以即使你没有完全理解为何是等价的，如果只是实现这种算法，你仍然能实现线性回归算法。如果你能弄清楚为什么这两个步骤是等价的，那我希望你可以对向量化有一个更好的理解，如果你在实现线性回归的时候，使用一个或两个以上的特征量。 有时我们使用几十或几百个特征量来计算线性归回，当你使用向量化地实现线性回归，通常运行速度就会比你以前用你的for循环快的多，也就是自己写代码更新{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}。 因此使用向量化实现方式，你应该是能够得到一个高效得多的线性回归算法。而当你向量化我们将在之后的课程里面学到的算法，这会是一个很好的技巧，无论是对于Octave 或者一些其他的语言 如C++、Java 来让你的代码运行得更高效。 逻辑回归(Logistic Regression)分类问题参考文档: 6 - 1 - Classification (8 min).mkv 在这个以及接下来的几个视频中，开始介绍分类问题。 在分类问题中，你要预测的变量 {% raw %}$y${% endraw %} 是离散的值，我们将学习一种叫做逻辑回归 (Logistic Regression) 的算法，这是目前最流行使用最广泛的一种学习算法。 在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；之前我们也谈到了肿瘤分类问题的例子，区别一个肿瘤是恶性的还是良性的。 我们从二元的分类问题开始讨论。 我们将因变量(dependent variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量{% raw %}$y\in { 0,1 \\}${% endraw %} ，其中 0 表示负向类，1 表示正向类。 如果我们要用线性回归算法来解决一个分类问题，对于分类， {% raw %}$y${% endraw %} 取值为 0 或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于 1，或者远小于0，即使所有训练样本的标签 {% raw %}$y${% endraw %} 都等于 0 或 1。尽管我们知道标签应该取值0 或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到 1 之间。 顺便说一下，逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上是一种分类算法，它适用于标签 {% raw %}$y${% endraw %} 取值离散的情况，如：1 0 0 1。 在接下来的视频中，我们将开始学习逻辑回归算法的细节。 假说表示参考视频: 6 - 2 - Hypothesis Representation (7 min).mkv 在这段视频中，我要给你展示假设函数的表达式，也就是说，在分类问题中，要用什么样的函数来表示我们的假设。此前我们说过，希望我们的分类器的输出值在0和1之间，因此，我们希望想出一个满足某个性质的假设函数，这个性质是它的预测值要在0和1之间。 回顾在一开始提到的乳腺癌分类问题，我们可以用线性回归的方法求出适合数据的一条直线： 根据线性回归模型我们只能预测连续的值，然而对于分类问题，我们需要输出0或1，我们可以预测： 当{% raw %}${h_\theta}\left( x \right)>=0.5${% endraw %}时，预测 {% raw %}$y=1${% endraw %}。 当{% raw %}${h_\theta}\left( x \right)&lt;0.5${% endraw %}时，预测 {% raw %}$y=0${% endraw %} 。 对于上图所示的数据，这样的一个线性模型似乎能很好地完成分类任务。假使我们又观测到一个非常大尺寸的恶性肿瘤，将其作为实例加入到我们的训练集中来，这将使得我们获得一条新的直线。 这时，再使用0.5作为阀值来预测肿瘤是良性还是恶性便不合适了。可以看出，线性回归模型，因为其预测的值可以超越[0,1]的范围，并不适合解决这样的问题。 我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在0和1之间。逻辑回归模型的假设是： {% raw %}$h_\theta \left( x \right)=g\left(\theta^{T}X \right)${% endraw %}其中： {% raw %}$X${% endraw %} 代表特征向量 {% raw %}$g${% endraw %} 代表逻辑函数（**logistic function**)是一个常用的逻辑函数为**S**形函数（**Sigmoid function**），公式为： {% raw %}$g\left( z \right)=\frac{1}{1+{ {e}^{-z} }}${% endraw %}。 python代码实现： import numpy as np def sigmoid(z): return 1 / (1 + np.exp(-z)) 该函数的图像为： 合起来，我们得到逻辑回归模型的假设： 对模型的理解： $g\left( z \right)=\frac{1}{1+{ {e}^{-z} }}$。 $h_\theta \left( x \right)$的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性（**estimated probablity**）即$h_\theta \left( x \right)=P\left( y=1|x;\theta \right)$ 例如，如果对于给定的$x$，通过已经确定的参数计算得出$h_\theta \left( x \right)=0.7$，则表示有70%的几率$y$为正向类，相应地$y$为负向类的几率为1-0.7=0.3。 判定边界参考视频: 6 - 3 - Decision Boundary (15 min).mkv 现在讲下决策边界(decision boundary)的概念。这个概念能更好地帮助我们理解逻辑回归的假设函数在计算什么。 在逻辑回归中，我们预测： 当${h_\theta}\left( x \right)>=0.5$时，预测 $y=1$。 当${h_\theta}\left( x \right)&lt;0.5$时，预测 $y=0$ 。 根据上面绘制出的 S 形函数图像，我们知道当 $z=0$ 时 $g(z)=0.5$ $z>0$ 时 $g(z)>0.5$ $z&lt;0$ 时 $g(z)&lt;0.5$ 又 $z={\theta^{T} }x$ ，即： ${\theta^{T} }x>=0$ 时，预测 $y=1$ ${\theta^{T} }x&lt;0$ 时，预测 $y=0$ 现在假设我们有一个模型： 并且参数$\theta$ 是向量[-3 1 1]。 则当$-3+{x_1}+{x_2} \geq 0$，即${x_1}+{x_2} \geq 3$时，模型将预测 $y=1$。我们可以绘制直线${x_1}+{x_2} = 3$，这条线便是我们模型的分界线，将预测为1的区域和预测为 0的区域分隔开。 假使我们的数据呈现这样的分布情况，怎样的模型才能适合呢？ 因为需要用曲线才能分隔 $y=0$ 的区域和 $y=1$ 的区域，我们需要二次方特征：${h_\theta}\left( x \right)=g\left( {\theta_0}+{\theta_1}{x_1}+{\theta_{2} }{x_{2} }+{\theta_{3} }x_{1}^{2}+{\theta_{4} }x_{2}^{2} \right)$是[-1 0 0 1 1]，则我们得到的判定边界恰好是圆点在原点且半径为1的圆形。 我们可以用非常复杂的模型来适应非常复杂形状的判定边界。 代价函数参考视频: 6 - 4 - Cost Function (11 min).mkv 在这段视频中，我们要介绍如何拟合逻辑回归模型的参数$\theta$。具体来说，我要定义用来拟合参数的优化目标或者叫代价函数，这便是监督学习问题中的逻辑回归模型的拟合问题。 对于线性回归模型，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将${h_\theta}\left( x \right)=\frac{1}{1+{e^{-\theta^{T}x} }}$带入到这样定义了的代价函数中时，我们得到的代价函数将是一个非凸函数（non-convexfunction）。 这意味着我们的代价函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。 线性回归的代价函数为：$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{1}{2}{ {\left( {h_\theta}\left({x}^{\left( i \right)} \right)-{y}^{\left( i \right)} \right)}^{2} }}$ 。我们重新定义逻辑回归的代价函数为：$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{ {Cost}\left( {h_\theta}\left( {x}^{\left( i \right)} \right),{y}^{\left( i \right)} \right)}$，其中 ${h_\theta}\left( x \right)$与 $Cost\left( {h_\theta}\left( x \right),y \right)$之间的关系如下图所示： 这样构建的$Cost\left( {h_\theta}\left( x \right),y \right)$函数的特点是：当实际的 $y=1$ 且${h_\theta}\left( x \right)$也为 1 时误差为 0，当 $y=1$ 但${h_\theta}\left( x \right)$不为1时误差随着${h_\theta}\left( x \right)$变小而变大；当实际的 $y=0$ 且${h_\theta}\left( x \right)$也为 0 时代价为 0，当$y=0$ 但${h_\theta}\left( x \right)$不为 0时误差随着 ${h_\theta}\left( x \right)$的变大而变大。将构建的 $Cost\left( {h_\theta}\left( x \right),y \right)$简化如下： $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$ 带入代价函数得到： $J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$ 即：$J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$ Python代码实现： import numpy as np def cost(theta, X, y): theta = np.matrix(theta) X = np.matrix(X) y = np.matrix(y) first = np.multiply(-y, np.log(sigmoid(X* theta.T))) second = np.multiply((1 - y), np.log(1 - sigmoid(X* theta.T))) return np.sum(first - second) / (len(X)) 在得到这样一个代价函数以后，我们便可以用梯度下降算法来求得能使代价函数最小的参数了。算法为： Repeat { $\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j} J(\theta)$ (simultaneously update all )} 求导后得到： Repeat { $\theta_j := \theta_j - \alpha \frac{1}{m}\sum\limits_{i=1}^{m}{ {\left( {h_\theta}\left( \mathop{x}^{\left( i \right)} \right)-\mathop{y}^{\left( i \right)} \right)} }\mathop{x}_{j}^{(i)}$ (simultaneously update all )} 在这个视频中，我们定义了单训练样本的代价函数，凸性分析的内容是超出这门课的范围的，但是可以证明我们所选的代价值函数会给我们一个凸优化问题。代价函数$J(\theta)$会是一个凸函数，并且没有局部最优值。 推导过程： $J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$ 考虑： ${h_\theta}\left( { {x}^{(i)} } \right)=\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }}$ 则： ${ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)$ $={ {y}^{(i)} }\log \left( \frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }} \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }} \right)$ $=-{ {y}^{(i)} }\log \left( 1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} } \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} } \right)$ 所以： $\frac{\partial }{\partial {\theta_{j} }}J\left( \theta \right)=\frac{\partial }{\partial {\theta_{j} }}[-\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( 1+{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} } \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1+{ {e}^{ {\theta^{T} }{ {x}^{(i)} }} } \right)]}]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\frac{-x_{j}^{(i)}{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} }}{1+{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} }}-\left( 1-{ {y}^{(i)} } \right)\frac{x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }} }]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{ {y}^{(i)} }\frac{x_j^{(i)} }{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}-\left( 1-{ {y}^{(i)} } \right)\frac{x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{ {{y}^{(i)} }x_j^{(i)}-x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }+{ {y}^{(i)} }x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{ {{y}^{(i)} }\left( 1\text{+}{ {e}^{ {\theta^T}{ {x}^{(i)} }} } \right)-{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{({ {y}^{(i)} }-\frac{ {{e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }})x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{({ {y}^{(i)} }-\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }})x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }-{h_\theta}\left( { {x}^{(i)} } \right)]x_j^{(i)} }$ $=\frac{1}{m}\sum\limits_{i=1}^{m}{[{h_\theta}\left( { {x}^{(i)} } \right)-{ {y}^{(i)} }]x_j^{(i)} }$ 注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。 一些梯度下降算法之外的选择：除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：共轭梯度（Conjugate Gradient），局部优化法(Broyden fletcher goldfarb shann,BFGS)和有限内存局部优化法(LBFGS) ，fminunc是 matlab和octave 中都带的一个最小值优化函数，使用时我们需要提供代价函数和每个参数的求导，下面是 octave 中使用 fminunc 函数的代码示例： function [jVal, gradient] = costFunction(theta) jVal = [...code to compute J(theta)...]; gradient = [...code to compute derivative of J(theta)...]; end options = optimset(&#39;GradObj&#39;, &#39;on&#39;, &#39;MaxIter&#39;, &#39;100&#39;); initialTheta = zeros(2,1); [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options); 在下一个视频中，我们会把单训练样本的代价函数的这些理念进一步发展，然后给出整个训练集的代价函数的定义，我们还会找到一种比我们目前用的更简单的写法，基于这些推导出的结果，我们将应用梯度下降法得到我们的逻辑回归算法。 简化的成本函数和梯度下降参考视频: 6 - 5 - Simplified Cost Function and Gradient Descent (10 min).mkv 在这段视频中，我们将会找出一种稍微简单一点的方法来写代价函数，来替换我们现在用的方法。同时我们还要弄清楚如何运用梯度下降法，来拟合出逻辑回归的参数。因此，听了这节课，你就应该知道如何实现一个完整的逻辑回归算法。 这就是逻辑回归的代价函数： 这个式子可以合并成： $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$ 即，逻辑回归的代价函数： $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$ 根据这个代价函数，为了拟合出参数，该怎么做呢？我们要试图找尽量让$J\left( \theta \right)$ 取得最小值的参数$\theta $。 $\underset{\theta}{\min }J\left( \theta \right)$ 所以我们想要尽量减小这一项，这将我们将得到某个参数$\theta $。如果我们给出一个新的样本，假如某个特征 $x$，我们可以用拟合训练样本的参数$\theta $，来输出对假设的预测。另外，我们假设的输出，实际上就是这个概率值：$p(y=1|x;\theta)$，就是关于 $x$以$\theta $为参数，$y=1$ 的概率，你可以认为我们的假设就是估计 $y=1$ 的概率，所以，接下来就是弄清楚如何最大限度地最小化代价函数$J\left( \theta \right)$，作为一个关于$\theta $的函数，这样我们才能为训练集拟合出参数$\theta $。 最小化代价函数的方法，是使用梯度下降法(gradient descent)。这是我们的代价函数： $J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$ 如果我们要最小化这个关于$\theta$的函数值，这就是我们通常用的梯度下降法的模板。 我们要反复更新每个参数，用这个式子来更新，就是用它自己减去学习率 $\alpha$乘以后面的微分项。求导后得到： 如果你计算一下的话，你会得到这个等式： ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){x_{j} }^{(i)} }$ 我把它写在这里，将后面这个式子，在 $i=1$ 到 $m$ 上求和，其实就是预测误差乘以$x_j^{(i)}$ ，所以你把这个偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$放回到原来式子这里，我们就可以将梯度下降算法写作如下形式： ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){x_{j} }^{(i)} }$ 所以，如果你有 $n$ 个特征，也就是说：，参数向量$\theta $包括${\theta_{0} }$ ${\theta_{1} }$ ${\theta_{2} }$ 一直到${\theta_{n} }$，那么你就需要用这个式子： ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){ {x}_{j} }^{(i)} }$来同时更新所有$\theta $的值。 现在，如果你把这个更新规则和我们之前用在线性回归上的进行比较的话，你会惊讶地发现，这个式子正是我们用来做线性回归梯度下降的。 那么，线性回归和逻辑回归是同一个算法吗？要回答这个问题，我们要观察逻辑回归看看发生了哪些变化。实际上，假设的定义发生了变化。 对于线性回归假设函数： ${h_\theta}\left( x \right)={\theta^T}X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ 而现在逻辑函数假设函数： ${h_\theta}\left( x \right)=\frac{1}{1+{ {e}^{-{\theta^T}X} }}$ 因此，即使更新参数的规则看起来基本相同，但由于假设的定义发生了变化，所以逻辑函数的梯度下降，跟线性回归的梯度下降实际上是两个完全不同的东西。 在先前的视频中，当我们在谈论线性回归的梯度下降法时，我们谈到了如何监控梯度下降法以确保其收敛，我通常也把同样的方法用在逻辑回归中，来监测梯度下降，以确保它正常收敛。 当使用梯度下降法来实现逻辑回归时，我们有这些不同的参数$\theta $，就是${\theta_{0} }$ ${\theta_{1} }$ ${\theta_{2} }$ 一直到${\theta_{n} }$，我们需要用这个表达式来更新这些参数。我们还可以使用 for循环来更新这些参数值，用 for i=1 to n，或者 for i=1 to n+1。当然，不用 for循环也是可以的，理想情况下，我们更提倡使用向量化的实现，可以把所有这些 $n$个参数同时更新。 最后还有一点，我们之前在谈线性回归时讲到的特征缩放，我们看到了特征缩放是如何提高梯度下降的收敛速度的，这个特征缩放的方法，也适用于逻辑回归。如果你的特征范围差距很大的话，那么应用特征缩放的方法，同样也可以让逻辑回归中，梯度下降收敛更快。 就是这样，现在你知道如何实现逻辑回归，这是一种非常强大，甚至可能世界上使用最广泛的一种分类算法。 高级优化参考视频: 6 - 6 - Advanced Optimization (14 min).mkv 在上一个视频中，我们讨论了用梯度下降的方法最小化逻辑回归中代价函数$J\left( \theta \right)$。在本次视频中，我会教你们一些高级优化算法和一些高级的优化概念，利用这些方法，我们就能够使通过梯度下降，进行逻辑回归的速度大大提高，而这也将使算法更加适合解决大型的机器学习问题，比如，我们有数目庞大的特征量。现在我们换个角度来看什么是梯度下降，我们有个代价函数$J\left( \theta \right)$，而我们想要使其最小化，那么我们需要做的是编写代码，当输入参数 $\theta$ 时，它们会计算出两样东西：$J\left( \theta \right)$ 以及$J$ 等于 0、1直到 $n$ 时的偏导数项。 假设我们已经完成了可以实现这两件事的代码，那么梯度下降所做的就是反复执行这些更新。另一种考虑梯度下降的思路是：我们需要写出代码来计算$J\left( \theta \right)$ 和这些偏导数，然后把这些插入到梯度下降中，然后它就可以为我们最小化这个函数。对于梯度下降来说，我认为从技术上讲，你实际并不需要编写代码来计算代价函数$J\left( \theta \right)$。你只需要编写代码来计算导数项，但是，如果你希望代码还要能够监控这些$J\left( \theta \right)$ 的收敛性，那么我们就需要自己编写代码来计算代价函数$J(\theta)$和偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$。所以，在写完能够计算这两者的代码之后，我们就可以使用梯度下降。然而梯度下降并不是我们可以使用的唯一算法，还有其他一些算法，更高级、更复杂。如果我们能用这些方法来计算代价函数$J\left( \theta \right)$和偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$两个项的话，那么这些算法就是为我们优化代价函数的不同方法，共轭梯度法 BFGS (变尺度法) 和L-BFGS (限制变尺度法) 就是其中一些更高级的优化算法，它们需要有一种方法来计算 $J\left( \theta \right)$，以及需要一种方法计算导数项，然后使用比梯度下降更复杂的算法来最小化代价函数。这三种算法的具体细节超出了本门课程的范畴。实际上你最后通常会花费很多天，或几周时间研究这些算法，你可以专门学一门课来提高数值计算能力，不过让我来告诉你他们的一些特性： 这三种算法有许多优点： 一个是使用这其中任何一个算法，你通常不需要手动选择学习率 $\alpha$，所以对于这些算法的一种思路是，给出计算导数项和代价函数的方法，你可以认为算法有一个智能的内部循环，而且，事实上，他们确实有一个智能的内部循环，称为线性搜索(line search)算法，它可以自动尝试不同的学习速率 $\alpha$，并自动选择一个好的学习速率 $a$，因此它甚至可以为每次迭代选择不同的学习速率，那么你就不需要自己选择。这些算法实际上在做更复杂的事情，不仅仅是选择一个好的学习速率，所以它们往往最终比梯度下降收敛得快多了，不过关于它们到底做什么的详细讨论，已经超过了本门课程的范围。 实际上，我过去使用这些算法已经很长一段时间了，也许超过十年了，使用得相当频繁，而直到几年前我才真正搞清楚共轭梯度法 BFGS 和 L-BFGS的细节。 我们实际上完全有可能成功使用这些算法，并应用于许多不同的学习问题，而不需要真正理解这些算法的内环间在做什么，如果说这些算法有缺点的话，那么我想说主要缺点是它们比梯度下降法复杂多了，特别是你最好不要使用 L-BGFS、BFGS这些算法，除非你是数值计算方面的专家。实际上，我不会建议你们编写自己的代码来计算数据的平方根，或者计算逆矩阵，因为对于这些算法，我还是会建议你直接使用一个软件库，比如说，要求一个平方根，我们所能做的就是调用一些别人已经写好用来计算数字平方根的函数。幸运的是现在我们有Octave 和与它密切相关的 MATLAB 语言可以使用。 Octave 有一个非常理想的库用于实现这些先进的优化算法，所以，如果你直接调用它自带的库，你就能得到不错的结果。我必须指出这些算法实现得好或不好是有区别的，因此，如果你正在你的机器学习程序中使用一种不同的语言，比如如果你正在使用C、C++、Java等等，你可能会想尝试一些不同的库，以确保你找到一个能很好实现这些算法的库。因为在L-BFGS或者等高线梯度的实现上，表现得好与不太好是有差别的，因此现在让我们来说明：如何使用这些算法： 比方说，你有一个含两个参数的问题，这两个参数是${\theta_{0} }$和${\theta_{1} }$，因此，通过这个代价函数，你可以得到${\theta_{1} }$和 ${\theta_{2} }$的值，如果你将$J\left( \theta \right)$ 最小化的话，那么它的最小值将是${\theta_{1} }=5$ ，${\theta_{2} }=5$。代价函数$J\left( \theta \right)$的导数推出来就是这两个表达式： $\frac{\partial }{\partial { {\theta }_{1} }}J(\theta)=2({ {\theta }_{1} }-5)$ $\frac{\partial }{\partial { {\theta }_{2} }}J(\theta)=2({ {\theta }_{2} }-5)$ 如果我们不知道最小值，但你想要代价函数找到这个最小值，是用比如梯度下降这些算法，但最好是用比它更高级的算法，你要做的就是运行一个像这样的Octave 函数： function [jVal, gradient]=costFunction(theta) jVal=(theta(1)-5)^2+(theta(2)-5)^2; gradient=zeros(2,1); gradient(1)=2*(theta(1)-5); gradient(2)=2*(theta(2)-5); end 这样就计算出这个代价函数，函数返回的第二个值是梯度值，梯度值应该是一个2×1的向量，梯度向量的两个元素对应这里的两个偏导数项，运行这个costFunction 函数后，你就可以调用高级的优化函数，这个函数叫fminunc，它表示Octave 里无约束最小化函数。调用它的方式如下： options=optimset(&#39;GradObj&#39;,&#39;on&#39;,&#39;MaxIter&#39;,100); initialTheta=zeros(2,1); [optTheta, functionVal, exitFlag]=fminunc(@costFunction, initialTheta, options); 你要设置几个options，这个 options 变量作为一个数据结构可以存储你想要的options，所以 GradObj 和On，这里设置梯度目标参数为打开(on)，这意味着你现在确实要给这个算法提供一个梯度，然后设置最大迭代次数，比方说100，我们给出一个$\theta$ 的猜测初始值，它是一个2×1的向量，那么这个命令就调用fminunc，这个@符号表示指向我们刚刚定义的costFunction 函数的指针。如果你调用它，它就会使用众多高级优化算法中的一个，当然你也可以把它当成梯度下降，只不过它能自动选择学习速率$\alpha$，你不需要自己来做。然后它会尝试使用这些高级的优化算法，就像加强版的梯度下降法，为你找到最佳的${\theta}$值。 让我告诉你它在 Octave 里什么样： 所以我写了这个关于theta的 costFunction 函数，它计算出代价函数 jval以及梯度gradient，gradient 有两个元素，是代价函数对于theta(1) 和 theta(2)这两个参数的偏导数。 我希望你们从这个幻灯片中学到的主要内容是：写一个函数，它能返回代价函数值、梯度值，因此要把这个应用到逻辑回归，或者甚至线性回归中，你也可以把这些优化算法用于线性回归，你需要做的就是输入合适的代码来计算这里的这些东西。 现在你已经知道如何使用这些高级的优化算法，有了这些算法，你就可以使用一个复杂的优化库，它让算法使用起来更模糊一点。因此也许稍微有点难调试，不过由于这些算法的运行速度通常远远超过梯度下降。 所以当我有一个很大的机器学习问题时，我会选择这些高级算法，而不是梯度下降。有了这些概念，你就应该能将逻辑回归和线性回归应用于更大的问题中，这就是高级优化的概念。 在下一个视频，我想要告诉你如何修改你已经知道的逻辑回归算法，然后使它在多类别分类问题中也能正常运行。 多类别分类：一对多参考视频: 6 - 7 - Multiclass Classification_ One-vs-all (6 min).mkv 在本节视频中，我们将谈到如何使用逻辑回归 (logistic regression)来解决多类别分类问题，具体来说，我想通过一个叫做”一对多” (one-vs-all) 的分类算法。 先看这样一些例子。 第一个例子：假如说你现在需要一个学习算法能自动地将邮件归类到不同的文件夹里，或者说可以自动地加上标签，那么，你也许需要一些不同的文件夹，或者不同的标签来完成这件事，来区分开来自工作的邮件、来自朋友的邮件、来自家人的邮件或者是有关兴趣爱好的邮件，那么，我们就有了这样一个分类问题：其类别有四个，分别用$y=1$、$y=2$、$y=3$、$y=4$ 来代表。 第二个例子是有关药物诊断的，如果一个病人因为鼻塞来到你的诊所，他可能并没有生病，用 $y=1$ 这个类别来代表；或者患了感冒，用 $y=2$ 来代表；或者得了流感用$y=3$来代表。 第三个例子：如果你正在做有关天气的机器学习分类问题，那么你可能想要区分哪些天是晴天、多云、雨天、或者下雪天，对上述所有的例子，$y$ 可以取一个很小的数值，一个相对”谨慎”的数值，比如1 到3、1到4或者其它数值，以上说的都是多类分类问题，顺便一提的是，对于下标是0 1 2 3，还是 1 2 3 4 都不重要，我更喜欢将分类从 1 开始标而不是0，其实怎样标注都不会影响最后的结果。 然而对于之前的一个，二元分类问题，我们的数据看起来可能是像这样： 对于一个多类分类问题，我们的数据集或许看起来像这样： 我用3种不同的符号来代表3个类别，问题就是给出3个类型的数据集，我们如何得到一个学习算法来进行分类呢？ 我们现在已经知道如何进行二元分类，可以使用逻辑回归，对于直线或许你也知道，可以将数据集一分为二为正类和负类。用一对多的分类思想，我们可以将其用在多类分类问题上。 下面将介绍如何进行一对多的分类工作，有时这个方法也被称为”一对余”方法。 现在我们有一个训练集，好比上图表示的有3个类别，我们用三角形表示 $y=1$，方框表示$y=2$，叉叉表示 $y=3$。我们下面要做的就是使用一个训练集，将其分成3个二元分类问题。 我们先从用三角形代表的类别1开始，实际上我们可以创建一个，新的”伪”训练集，类型2和类型3定为负类，类型1设定为正类，我们创建一个新的训练集，如下图所示的那样，我们要拟合出一个合适的分类器。 这里的三角形是正样本，而圆形代表负样本。可以这样想，设置三角形的值为1，圆形的值为0，下面我们来训练一个标准的逻辑回归分类器，这样我们就得到一个正边界。 为了能实现这样的转变，我们将多个类中的一个类标记为正向类（$y=1$），然后将其他所有类都标记为负向类，这个模型记作$h_\theta^{\left( 1 \right)}\left( x \right)$。接着，类似地第我们选择另一个类标记为正向类（$y=2$），再将其它类都标记为负向类，将这个模型记作 $h_\theta^{\left( 2 \right)}\left( x \right)$,依此类推。最后我们得到一系列的模型简记为： $h_\theta^{\left( i \right)}\left( x \right)=p\left( y=i|x;\theta \right)$其中：$i=\left( 1,2,3....k \right)$ 最后，在我们需要做预测时，我们将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。 总之，我们已经把要做的做完了，现在要做的就是训练这个逻辑回归分类器：$h_\theta^{\left( i \right)}\left( x \right)$， 其中 $i$ 对应每一个可能的 $y=i$，最后，为了做出预测，我们给出输入一个新的 $x$ 值，用这个做预测。我们要做的就是在我们三个分类器里面输入 $x$，然后我们选择一个让 $h_\theta^{\left( i \right)}\left( x \right)$ 最大的$ i$，即$\mathop{\max}\limits_i\,h_\theta^{\left( i \right)}\left( x \right)$。 你现在知道了基本的挑选分类器的方法，选择出哪一个分类器是可信度最高效果最好的，那么就可认为得到一个正确的分类，无论$i$值是多少，我们都有最高的概率值，我们预测$y$就是那个值。这就是多类别分类问题，以及一对多的方法，通过这个小方法，你现在也可以将逻辑回归分类器用在多类分类的问题上。 正则化(Regularization)过拟合的问题参考视频: 7 - 1 - The Problem of Overfitting (10 min).mkv 到现在为止，我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到过拟合(over-fitting)的问题，可能会导致它们效果很差。 在这段视频中，我将为你解释什么是过度拟合问题，并且在此之后接下来的几个视频中，我们将谈论一种称为正则化(regularization)的技术，它可以改善或者减少过度拟合问题。 如果我们有非常多的特征，我们通过学习得到的假设可能能够非常好地适应训练集（代价函数可能几乎为0），但是可能会不能推广到新的数据。 下图是一个回归问题的例子： 第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：预测新数据。我们可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎最合适。 分类问题中也存在这样的问题： 就以多项式理解，$x$ 的次数越高，拟合的越好，但相应的预测的能力就可能变差。 问题是，如果我们发现了过拟合问题，应该如何处理？ 丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如PCA） 正则化。 保留所有的特征，但是减少参数的大小（magnitude）。 代价函数参考视频: 7 - 2 - Cost Function (10 min).mkv 上面的回归问题中如果我们的模型是： ${h_\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}+{\theta_{3} }{x_{3}^3}+{\theta_{4} }{x_{4}^4}$ 我们可以从之前的事例中看出，正是那些高次项导致了过拟合的产生，所以如果我们能让这些高次项的系数接近于0的话，我们就能很好的拟合了。所以我们要做的就是在一定程度上减小这些参数$\theta $ 的值，这就是正则化的基本方法。我们决定要减少${\theta_{3} }$和${\theta_{4} }$的大小，我们要做的便是修改代价函数，在其中${\theta_{3} }$和${\theta_{4} }$ 设置一点惩罚。这样做的话，我们在尝试最小化代价时也需要将这个惩罚纳入考虑中，并最终导致选择较小一些的${\theta_{3} }$和${\theta_{4} }$。修改后的代价函数如下：$\underset{\theta }{\mathop{\min } }\,\frac{1}{2m}[\sum\limits_{i=1}^{m}{ {{\left( { {h}_{\theta } }\left( { {x}^{(i)} } \right)-{ {y}^{(i)} } \right)}^{2} }+1000\theta _{3}^{2}+10000\theta _{4}^{2}]}$ 通过这样的代价函数选择出的${\theta_{3} }$和${\theta_{4} }$ 对预测结果的影响就比之前要小许多。假如我们有非常多的特征，我们并不知道其中哪些特征我们要惩罚，我们将对所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设：$J\left( \theta \right)=\frac{1}{2m}[\sum\limits_{i=1}^{m}{ {{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })}^{2} }+\lambda \sum\limits_{j=1}^{n}{\theta_{j}^{2} }]}$ 其中$\lambda $又称为正则化参数（Regularization Parameter）。 注：根据惯例，我们不对${\theta_{0} }$ 进行惩罚。经过正则化处理的模型与原模型的可能对比如下图所示： 如果选择的正则化参数$\lambda$ 过大，则会把所有的参数都最小化了，导致模型变成 ${h_\theta}\left( x \right)={\theta_{0} }$，也就是上图中红色直线所示的情况，造成欠拟合。那为什么增加的一项$\lambda =\sum\limits_{j=1}^{n}{\theta_j^{2} }$ 可以使$\theta $的值减小呢？因为如果我们令 $\lambda$ 的值很大的话，为了使Cost Function 尽可能的小，所有的 $\theta $ 的值（不包括${\theta_{0} }$）都会在一定程度上减小。但若$\lambda$ 的值太大了，那么$\theta $（不包括${\theta_{0} }$）都会趋近于0，这样我们所得到的只能是一条平行于$x$轴的直线。所以对于正则化，我们要取一个合理的 $\lambda$ 的值，这样才能更好的应用正则化。回顾一下代价函数，为了使用正则化，让我们把这些概念应用到到线性回归和逻辑回归中去，那么我们就可以让他们避免过度拟合了。 正则化线性回归参考视频: 7 - 3 - Regularized Linear Regression (11 min).mkv 对于线性回归的求解，我们之前推导了两种学习算法：一种基于梯度下降，一种基于正规方程。 正则化线性回归的代价函数为： $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{[({ {({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })}^{2} }+\lambda \sum\limits_{j=1}^{n}{\theta _{j}^{2} })]}$ 如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对$\theta_0$进行正则化，所以梯度下降算法将分两种情形： $Repeat$ $until$ $convergence${ ​ ${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{0}^{(i)} })$ ​ ${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }+\frac{\lambda }{m}{\theta_j}]$ ​ $for$ $j=1,2,...n$ ​ } 对上面的算法中$ j=1,2,...,n$ 时的更新式子进行调整可得： ${\theta_j}:={\theta_j}(1-a\frac{\lambda }{m})-a\frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }$ 可以看出，正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令$\theta $值减少了一个额外的值。 我们同样也可以利用正规方程来求解正则化线性回归模型，方法如下所示： 图中的矩阵尺寸为 $(n+1)*(n+1)$。 正则化的逻辑回归模型参考视频: 7 - 4 - Regularized Logistic Regression (9 min).mkv 针对逻辑回归问题，我们在之前的课程已经学习过两种优化算法：我们首先学习了使用梯度下降法来优化代价函数$J\left( \theta \right)$，接下来学习了更高级的优化算法，这些高级优化算法需要你自己设计代价函数$J\left( \theta \right)$。 自己计算导数同样对于逻辑回归，我们也给代价函数增加一个正则化的表达式，得到代价函数： $J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}+\frac{\lambda }{2m}\sum\limits_{j=1}^{n}{\theta _{j}^{2} }$ Python代码： import numpy as np def costReg(theta, X, y, learningRate): theta = np.matrix(theta) X = np.matrix(X) y = np.matrix(y) first = np.multiply(-y, np.log(sigmoid(X*theta.T))) second = np.multiply((1 - y), np.log(1 - sigmoid(X*theta.T))) reg = (learningRate / (2 * len(X))* np.sum(np.power(theta[:,1:theta.shape[1]],2)) return np.sum(first - second) / (len(X)) + reg 要最小化该代价函数，通过求导，得出梯度下降算法为： $Repeat$ $until$ $convergence${ ​ ${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{0}^{(i)} })$ ​ ${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }+\frac{\lambda }{m}{\theta_j}]$ ​ $for$ $j=1,2,...n$ ​ } 注：看上去同线性回归一样，但是知道 ${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$，所以与线性回归不同。Octave 中，我们依旧可以用 fminuc 函数来求解代价函数最小化的参数，值得注意的是参数${\theta_{0} }$的更新规则与其他情况不同。注意： 虽然正则化的逻辑回归中的梯度下降和正则化的线性回归中的表达式看起来一样，但由于两者的${h_\theta}\left( x \right)$不同所以还是有很大差别。 ${\theta_{0} }$不参与其中的任何一个正则化。 目前大家对机器学习算法可能还只是略懂，但是一旦你精通了线性回归、高级优化算法和正则化技术，坦率地说，你对机器学习的理解可能已经比许多工程师深入了。现在，你已经有了丰富的机器学习知识，目测比那些硅谷工程师还厉害，或者用机器学习算法来做产品。 接下来的课程中，我们将学习一个非常强大的非线性分类器，无论是线性回归问题，还是逻辑回归问题，都可以构造多项式来解决。你将逐渐发现还有更强大的非线性分类器，可以用来解决多项式回归问题。我们接下来将将学会，比现在解决问题的方法强大N倍的学习算法。 神经网络：表述(Neural Networks: Representation)非线性假设参考视频: 8 - 1 - Non-linear Hypotheses (10 min).mkv 我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。 下面是一个例子： 当我们使用$x_1$, $x_2$ 的多次项式进行预测时，我们可以应用的很好。之前我们已经看到过，使用非线性的多项式项，能够帮助我们建立更好的分类模型。假设我们有非常多的特征，例如大于100个变量，我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合$(x_1x_2+x_1x_3+x_1x_4+...+x_2x_3+x_2x_4+...+x_{99}x_{100})$，我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。 假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车），我们怎样才能这么做呢？一种方法是我们利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。 假如我们只选用灰度图片，每个像素则只有一个值（而非 RGB值），我们可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车： 假使我们采用的都是50x50像素的小图片，并且我们将所有的像素视为特征，则会有 2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约${ {2500}^{2} }/2$个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们需要神经网络。 神经元和大脑参考视频: 8 - 2 - Neurons and the Brain (8 min).mkv 神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。 在这门课中，我将向你们介绍神经网络。因为它能很好地解决不同的机器学习问题。而不只因为它们在逻辑上行得通，在这段视频中，我想告诉你们一些神经网络的背景知识，由此我们能知道可以用它们来做什么。不管是将其应用到现代的机器学习问题上，还是应用到那些你可能会感兴趣的问题中。也许，这一伟大的人工智能梦想在未来能制造出真正的智能机器。另外，我们还将讲解神经网络是怎么涉及这些问题的神经网络产生的原因是人们想尝试设计出模仿大脑的算法，从某种意义上说如果我们想要建立学习系统，那为什么不去模仿我们所认识的最神奇的学习机器——人类的大脑呢？ 神经网络逐渐兴起于二十世纪八九十年代，应用得非常广泛。但由于各种原因，在90年代的后期应用减少了。但是最近，神经网络又东山再起了。其中一个原因是：神经网络是计算量有些偏大的算法。然而大概由于近些年计算机的运行速度变快，才足以真正运行起大规模的神经网络。正是由于这个原因和其他一些我们后面会讨论到的技术因素，如今的神经网络对于许多应用来说是最先进的技术。当你想模拟大脑时，是指想制造出与人类大脑作用效果相同的机器。大脑可以学会去以看而不是听的方式处理图像，学会处理我们的触觉。 我们能学习数学，学着做微积分，而且大脑能处理各种不同的令人惊奇的事情。似乎如果你想要模仿它，你得写很多不同的软件来模拟所有这些五花八门的奇妙的事情。不过能不能假设大脑做所有这些，不同事情的方法，不需要用上千个不同的程序去实现。相反的，大脑处理的方法，只需要一个单一的学习算法就可以了？尽管这只是一个假设，不过让我和你分享，一些这方面的证据。 大脑的这一部分这一小片红色区域是你的听觉皮层，你现在正在理解我的话，这靠的是耳朵。耳朵接收到声音信号，并把声音信号传递给你的听觉皮层，正因如此，你才能明白我的话。 神经系统科学家做了下面这个有趣的实验，把耳朵到听觉皮层的神经切断。在这种情况下，将其重新接到一个动物的大脑上，这样从眼睛到视神经的信号最终将传到听觉皮层。如果这样做了。那么结果表明听觉皮层将会学会“看”。这里的“看”代表了我们所知道的每层含义。所以，如果你对动物这样做，那么动物就可以完成视觉辨别任务，它们可以看图像，并根据图像做出适当的决定。它们正是通过脑组织中的这个部分完成的。下面再举另一个例子，这块红色的脑组织是你的躯体感觉皮层，这是你用来处理触觉的，如果你做一个和刚才类似的重接实验，那么躯体感觉皮层也能学会“看”。这个实验和其它一些类似的实验，被称为神经重接实验，从这个意义上说，如果人体有同一块脑组织可以处理光、声或触觉信号，那么也许存在一种学习算法，可以同时处理视觉、听觉和触觉，而不是需要运行上千个不同的程序，或者上千个不同的算法来做这些大脑所完成的成千上万的美好事情。也许我们需要做的就是找出一些近似的或实际的大脑学习算法，然后实现它大脑通过自学掌握如何处理这些不同类型的数据。在很大的程度上，可以猜想如果我们把几乎任何一种传感器接入到大脑的几乎任何一个部位的话，大脑就会学会处理它。 下面再举几个例子： 这张图是用舌头学会“看”的一个例子。它的原理是：这实际上是一个名为BrainPort的系统，它现在正在FDA(美国食品和药物管理局)的临床试验阶段，它能帮助失明人士看见事物。它的原理是，你在前额上带一个灰度摄像头，面朝前，它就能获取你面前事物的低分辨率的灰度图像。你连一根线到舌头上安装的电极阵列上，那么每个像素都被映射到你舌头的某个位置上，可能电压值高的点对应一个暗像素电压值低的点。对应于亮像素，即使依靠它现在的功能，使用这种系统就能让你我在几十分钟里就学会用我们的舌头“看”东西。 这是第二个例子，关于人体回声定位或者说人体声纳。你有两种方法可以实现：你可以弹响指，或者咂舌头。不过现在有失明人士，确实在学校里接受这样的培训，并学会解读从环境反弹回来的声波模式—这就是声纳。如果你搜索YouTube之后，就会发现有些视频讲述了一个令人称奇的孩子，他因为癌症眼球惨遭移除，虽然失去了眼球，但是通过打响指，他可以四处走动而不撞到任何东西，他能滑滑板，他可以将篮球投入篮框中。注意这是一个没有眼球的孩子。 第三个例子是触觉皮带，如果你把它戴在腰上，蜂鸣器会响，而且总是朝向北时发出嗡嗡声。它可以使人拥有方向感，用类似于鸟类感知方向的方式。 还有一些离奇的例子： 如果你在青蛙身上插入第三只眼，青蛙也能学会使用那只眼睛。因此，这将会非常令人惊奇。如果你能把几乎任何传感器接入到大脑中，大脑的学习算法就能找出学习数据的方法，并处理这些数据。从某种意义上来说，如果我们能找出大脑的学习算法，然后在计算机上执行大脑学习算法或与之相似的算法，也许这将是我们向人工智能迈进做出的最好的尝试。人工智能的梦想就是：有一天能制造出真正的智能机器。 神经网络可能为我们打开一扇进入遥远的人工智能梦的窗户，但我在这节课中讲授神经网络的原因，主要是对于现代机器学习应用。它是最有效的技术方法。因此在接下来的一些课程中，我们将开始深入到神经网络的技术细节。 模型表示1参考视频: 8 - 3 - Model Representation I (12 min).mkv 为了构建神经网络模型，我们需要首先思考大脑中的神经网络是怎样的？每一个神经元都可以被认为是一个处理单元/神经核（processing unit/Nucleus），它含有许多输入/树突（input/Dendrite），并且有一个输出/轴突（output/Axon）。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。 下面是一组神经元的示意图，神经元利用微弱的电流进行沟通。这些弱电流也称作动作电位，其实就是一些微弱的电流。所以如果神经元想要传递一个消息，它就会就通过它的轴突，发送一段微弱电流给其他神经元，这就是轴突。 这里是一条连接到输入神经，或者连接另一个神经元树突的神经，接下来这个神经元接收这条消息，做一些计算，它有可能会反过来将在轴突上的自己的消息传给其他神经元。这就是所有人类思考的模型：我们的神经元把自己的收到的消息进行计算，并向其他神经元传递消息。这也是我们的感觉和肌肉运转的原理。如果你想活动一块肌肉，就会触发一个神经元给你的肌肉发送脉冲，并引起你的肌肉收缩。如果一些感官：比如说眼睛想要给大脑传递一个消息，那么它就像这样发送电脉冲给大脑的。 神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，activation unit）采纳一些特征作为输出，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，参数又可被成为权重（weight）。 我们设计出了类似于神经元的神经网络，效果如下： 其中$x_1$, $x_2$, $x_3$是输入单元（input units），我们将原始数据输入给它们。 $a_1$, $a_2$, $a_3$是中间单元，它们负责将数据进行处理，然后呈递到下一层。 最后是输出单元，它负责计算${h_\theta}\left( x \right)$。 神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个3层的神经网络，第一层成为输入层（Input Layer），最后一层称为输出层（Output Layer），中间一层成为隐藏层（Hidden Layers）。我们为每一层都增加一个偏差单位（bias unit）： 下面引入一些标记法来帮助描述模型： $a_{i}^{\left( j \right)}$ 代表第$j$ 层的第 $i$ 个激活单元。${ {\theta }^{\left( j \right)} }$代表从第 $j$ 层映射到第$ j+1$ 层时的权重的矩阵，例如${ {\theta }^{\left( 1 \right)} }$代表从第一层映射到第二层的权重的矩阵。其尺寸为：以第 $j+1$层的激活单元数量为行数，以第 $j$ 层的激活单元数加一为列数的矩阵。例如：上图所示的神经网络中${ {\theta }^{\left( 1 \right)} }$的尺寸为 3*4。 对于上图所示的模型，激活单元和输出分别表达为： $a_{1}^{(2)}=g(\Theta _{10}^{(1)}{ {x}_{0} }+\Theta _{11}^{(1)}{ {x}_{1} }+\Theta _{12}^{(1)}{ {x}_{2} }+\Theta _{13}^{(1)}{ {x}_{3} })$ $a_{2}^{(2)}=g(\Theta _{20}^{(1)}{ {x}_{0} }+\Theta _{21}^{(1)}{ {x}_{1} }+\Theta _{22}^{(1)}{ {x}_{2} }+\Theta _{23}^{(1)}{ {x}_{3} })$ $a_{3}^{(2)}=g(\Theta _{30}^{(1)}{ {x}_{0} }+\Theta _{31}^{(1)}{ {x}_{1} }+\Theta _{32}^{(1)}{ {x}_{2} }+\Theta _{33}^{(1)}{ {x}_{3} })$ ${ {h}_{\Theta } }(x)=g(\Theta _{10}^{(2)}a_{0}^{(2)}+\Theta _{11}^{(2)}a_{1}^{(2)}+\Theta _{12}^{(2)}a_{2}^{(2)}+\Theta _{13}^{(2)}a_{3}^{(2)})$ 上面进行的讨论中只是将特征矩阵中的一行（一个训练实例）喂给了神经网络，我们需要将整个训练集都喂给我们的神经网络算法来学习模型。 我们可以知道：每一个$a$都是由上一层所有的$x$和每一个$x$所对应的决定的。 （我们把这样从左到右的算法称为前向传播算法( FORWARD PROPAGATION )） 把$x$, $\theta$, $a$ 分别用矩阵表示： 我们可以得到$\theta \cdot X=a$ 。 模型表示2参考视频: 8 - 4 - Model Representation II (12 min).mkv ( FORWARD PROPAGATION )相对于使用循环来编码，利用向量化的方法会使得计算更为简便。以上面的神经网络为例，试着计算第二层的值： 我们令 ${ {z}^{\left( 2 \right)} }={ {\theta }^{\left( 1 \right)} }x$，则 ${ {a}^{\left( 2 \right)} }=g({ {z}^{\left( 2 \right)} })$ ，计算后添加 $a_{0}^{\left( 2 \right)}=1$。 计算输出的值为： 我们令 ${ {z}^{\left( 3 \right)} }={ {\theta }^{\left( 2 \right)} }{ {a}^{\left( 2 \right)} }$，则 $h_\theta(x)={ {a}^{\left( 3 \right)} }=g({ {z}^{\left( 3 \right)} })$。这只是针对训练集中一个训练实例所进行的计算。如果我们要对整个训练集进行计算，我们需要将训练集特征矩阵进行转置，使得同一个实例的特征都在同一列里。即： ${ {z}^{\left( 2 \right)} }={ {\Theta }^{\left( 1 \right)} }\times { {X}^{T} } $ ${ {a}^{\left( 2 \right)} }=g({ {z}^{\left( 2 \right)} })$ 为了更好了了解Neuron Networks的工作原理，我们先把左半部分遮住： 右半部分其实就是以$a_0, a_1, a_2, a_3$, 按照Logistic Regression的方式输出$h_\theta(x)$： 其实神经网络就像是logistic regression，只不过我们把logistic regression中的输入向量$\left[ x_1\sim {x_3} \right]$ 变成了中间层的$\left[ a_1^{(2)}\sim a_3^{(2)} \right]$, 即: $h_\theta(x)=g\left( \Theta_0^{\left( 2 \right)}a_0^{\left( 2 \right)}+\Theta_1^{\left( 2 \right)}a_1^{\left( 2 \right)}+\Theta_{2}^{\left( 2 \right)}a_{2}^{\left( 2 \right)}+\Theta_{3}^{\left( 2 \right)}a_{3}^{\left( 2 \right)} \right)$我们可以把$a_0, a_1, a_2, a_3$看成更为高级的特征值，也就是$x_0, x_1, x_2, x_3$的进化体，并且它们是由 $x$与$\theta$决定的，因为是梯度下降的，所以$a$是变化的，并且变得越来越厉害，所以这些更高级的特征值远比仅仅将 $x$次方厉害，也能更好的预测新数据。这就是神经网络相比于逻辑回归和线性回归的优势。 特征和直观理解1参考视频: 8 - 5 - Examples and Intuitions I (7 min).mkv 从本质上讲，神经网络能够通过学习得出其自身的一系列特征。在普通的逻辑回归中，我们被限制为使用数据中的原始特征$x_1,x_2,...,{ {x}_{n} }$，我们虽然可以使用一些二项式项来组合这些特征，但是我们仍然受到这些原始特征的限制。在神经网络中，原始特征只是输入层，在我们上面三层的神经网络例子中，第三层也就是输出层做出的预测利用的是第二层的特征，而非输入层中的原始特征，我们可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输出变量的新特征。 神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑与(AND)、逻辑或(OR)。 举例说明：逻辑与(AND)；下图中左半部分是神经网络的设计与output层表达式，右边上部分是sigmod函数，下半部分是真值表。 我们可以用这样的一个神经网络表示AND 函数： 其中$\theta_0 = -30, \theta_1 = 20, \theta_2 = 20$我们的输出函数$h_\theta(x)$即为：$h_\Theta(x)=g\left( -30+20x_1+20x_2 \right)$ 我们知道$g(x)$的图像是： 所以我们有：$h_\Theta(x) \approx \text{x}_1 \text{AND} \, \text{x}_2$ 所以我们的：$h_\Theta(x) $ 这就是AND函数。 接下来再介绍一个OR函数： OR与AND整体一样，区别只在于的取值不同。 样本和直观理解II参考视频: 8 - 6 - Examples and Intuitions II (10 min).mkv 二元逻辑运算符（BINARY LOGICAL OPERATORS）当输入特征为布尔值（0或1）时，我们可以用一个单一的激活层可以作为二元逻辑运算符，为了表示不同的运算符，我们只需要选择不同的权重即可。 下图的神经元（三个权重分别为-30，20，20）可以被视为作用同于逻辑与（AND）： 下图的神经元（三个权重分别为-10，20，20）可以被视为作用等同于逻辑或（OR）： 下图的神经元（两个权重分别为 10，-20）可以被视为作用等同于逻辑非（NOT）： 我们可以利用神经元来组合成更为复杂的神经网络以实现更复杂的运算。例如我们要实现XNOR 功能（输入的两个值必须一样，均为1或均为0），即 $\text{XNOR}=( \text{x}_1\, \text{AND}\, \text{x}_2 )\, \text{OR} \left( \left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right) \right)$首先构造一个能表达$\left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right)$部分的神经元： 然后将表示 AND 的神经元和表示$\left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right)$的神经元以及表示 OR 的神经元进行组合： 我们就得到了一个能实现 $\text{XNOR}$ 运算符功能的神经网络。 按这种方法我们可以逐渐构造出越来越复杂的函数，也能得到更加厉害的特征值。 这就是神经网络的厉害之处。 多类分类参考视频: 8 - 7 - Multiclass Classification (4 min).mkv 当我们有不止两种分类时（也就是$y=1,2,3….$），比如以下这种情况，该怎么办？如果我们要训练一个神经网络算法来识别路人、汽车、摩托车和卡车，在输出层我们应该有4个值。例如，第一个值为1或0用于预测是否是行人，第二个值用于判断是否为汽车。 输入向量$x$有三个维度，两个中间层，输出层4个神经元分别用来表示4类，也就是每一个数据在输出层都会出现${ {\left[ a\text{ }b\text{ }c\text{ }d \right]}^{T} }$，且$a,b,c,d$中仅有一个为1，表示当前类。下面是该神经网络的可能结构示例： 神经网络算法的输出结果为四种可能情形之一： 神经网络的学习(Neural Networks: Learning)代价函数参考视频: 9 - 1 - Cost Function (7 min).mkv 首先引入一些便于稍后讨论的新标记方法： 假设神经网络的训练样本有$m$个，每个包含一组输入$x$和一组输出信号$y$，$L$表示神经网络层数，$S_I$表示每层的neuron个数($S_l$表示输出层神经元个数)，$S_L$代表最后一层中处理单元的个数。 将神经网络的分类定义为两种情况：二类分类和多类分类， 二类分类：$S_L=0, y=0\, or\, 1$表示哪一类； $K$类分类：$S_L=k, y_i = 1$表示分到第$i$类；$(k>2)$ 我们回顾逻辑回归问题中我们的代价函数为： $ J\left(\theta \right)=-\frac{1}{m}\left[\sum_\limits{i=1}^{m}{y}^{(i)}\log{h_\theta({x}^{(i)})}+\left(1-{y}^{(i)}\right)log\left(1-h_\theta\left({x}^{(i)}\right)\right)\right]+\frac{\lambda}{2m}\sum_\limits{j=1}^{n}{\theta_j}^{2} $ 在逻辑回归中，我们只有一个输出变量，又称标量（scalar），也只有一个因变量$y$，但是在神经网络中，我们可以有很多输出变量，我们的$h_\theta(x)$是一个维度为$K$的向量，并且我们训练集中的因变量也是同样维度的一个向量，因此我们的代价函数会比逻辑回归更加复杂一些，为：$\newcommand{\subk}[1]{ #1_k }$ $$h_\theta\left(x\right)\in \mathbb{R}^{K}$$ $${\left({h_\theta}\left(x\right)\right)}_{i}={i}^{th} \text{output}$$ $J(\Theta) = -\frac{1}{m} \left[ \sum\limits_{i=1}^{m} \sum\limits_{k=1}^{k} {y_k}^{(i)} \log \subk{(h_\Theta(x^{(i)}))} + \left( 1 - y_k^{(i)} \right) \log \left( 1- \subk{\left( h_\Theta \left( x^{(i)} \right) \right)} \right) \right] + \frac{\lambda}{2m} \sum\limits_{l=1}^{L-1} \sum\limits_{i=1}^{s_l} \sum\limits_{j=1}^{s_{l+1} } \left( \Theta_{ji}^{(l)} \right)^2$ 这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出$K$个预测，基本上我们可以利用循环，对每一行特征都预测$K$个不同结果，然后在利用循环在$K$个预测中选择可能性最高的一个，将其与$y$中的实际数据进行比较。 正则化的那一项只是排除了每一层$\theta_0$后，每一层的$\theta$ 矩阵的和。最里层的循环$j$循环所有的行（由$s_{l+1}$ 层的激活单元数决定），循环$i$则循环所有的列，由该层（$s_l$层）的激活单元数所决定。即：$h_\theta(x)$与真实值之间的距离为每个样本-每个类输出的加和，对参数进行regularization的bias项处理所有参数的平方和。 反向传播算法参考视频: 9 - 2 - Backpropagation Algorithm (12 min).mkv 之前我们在计算神经网络预测结果的时候我们采用了一种正向传播方法，我们从第一层开始正向一层一层进行计算，直到最后一层的$h_{\theta}\left(x\right)$。 现在，为了计算代价函数的偏导数$\frac{\partial}{\partial\Theta^{(l)}_{ij} }J\left(\Theta\right)$，我们需要采用一种反向传播算法，也就是首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。以一个例子来说明反向传播算法。 假设我们的训练集只有一个样本$\left({x}^{(1)},{y}^{(1)}\right)$，我们的神经网络是一个四层的神经网络，其中$K=4，S_{L}=4，L=4$： 前向传播算法： 下面的公式推导过程见：&lt;https://blog.csdn.net/qq_29762941/article/details/80343185&gt; 我们从最后一层的误差开始计算，误差是激活单元的预测（${a^{(4)} }$）与实际值（$y^k$）之间的误差，（$k=1:k$）。我们用$\delta$来表示误差，则：$\delta^{(4)}=a^{(4)}-y$我们利用这个误差值来计算前一层的误差：$\delta^{(3)}=\left({\Theta^{(3)} }\right)^{T}\delta^{(4)}\ast g'\left(z^{(3)}\right)$其中 $g'(z^{(3)})$是 $S$ 形函数的导数，$g'(z^{(3)})=a^{(3)}\ast(1-a^{(3)})$。而$(θ^{(3)})^{T}\delta^{(4)}$则是权重导致的误差的和。下一步是继续计算第二层的误差： $ \delta^{(2)}=(\Theta^{(2)})^{T}\delta^{(3)}\ast g'(z^{(2)})$ 因为第一层是输入变量，不存在误差。我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设$λ=0$，即我们不做任何正则化处理时有： $\frac{\partial}{\partial\Theta_{ij}^{(l)} }J(\Theta)=a_{j}^{(l)} \delta_{i}^{l+1}$ 重要的是清楚地知道上面式子中上下标的含义： $l$ 代表目前所计算的是第几层。 $j$ 代表目前计算层中的激活单元的下标，也将是下一层的第$j$个输入变量的下标。 $i$ 代表下一层中误差单元的下标，是受到权重矩阵中第$i$行影响的下一层中的误差单元的下标。 如果我们考虑正则化处理，并且我们的训练集是一个特征矩阵而非向量。在上面的特殊情况中，我们需要计算每一层的误差单元来计算代价函数的偏导数。在更为一般的情况中，我们同样需要计算每一层的误差单元，但是我们需要为整个训练集计算误差单元，此时的误差单元也是一个矩阵，我们用$\Delta^{(l)}_{ij}$来表示这个误差矩阵。第 $l$ 层的第 $i$ 个激活单元受到第 $j$ 个参数影响而导致的误差。 我们的算法表示为： 即首先用正向传播方法计算出每一层的激活单元，利用训练集的结果与神经网络预测的结果求出最后一层的误差，然后利用该误差运用反向传播法计算出直至第二层的所有误差。 在求出了$\Delta_{ij}^{(l)}$之后，我们便可以计算代价函数的偏导数了，计算方法如下： $ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)}$ ${if}\; j \neq 0$ $ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}$ ${if}\; j = 0$ 在Octave 中，如果我们要使用 fminuc这样的优化算法来求解求出权重矩阵，我们需要将矩阵首先展开成为向量，在利用算法求出最优解后再重新转换回矩阵。 假设我们有三个权重矩阵，Theta1，Theta2 和 Theta3，尺寸分别为 10*11，10*11 和1*11，下面的代码可以实现这样的转换： thetaVec = [Theta1(:) ; Theta2(:) ; Theta3(:)] ...optimization using functions like fminuc... Theta1 = reshape(thetaVec(1:110, 10, 11); Theta2 = reshape(thetaVec(111:220, 10, 11); Theta1 = reshape(thetaVec(221:231, 1, 11);反向传播算法的直观理解参考视频: 9 - 3 - Backpropagation Intuition (13 min).mkv 在上一段视频中，我们介绍了反向传播算法，对很多人来说，当第一次看到这种算法时，第一印象通常是，这个算法需要那么多繁杂的步骤，简直是太复杂了，实在不知道这些步骤，到底应该如何合在一起使用。就好像一个黑箱，里面充满了复杂的步骤。如果你对反向传播算法也有这种感受的话，这其实是正常的，相比于线性回归算法和逻辑回归算法而言，从数学的角度上讲，反向传播算法似乎并不简洁，对于反向传播这种算法，其实我已经使用了很多年了，但即便如此，即使是现在，我也经常感觉自己对反向传播算法的理解并不是十分深入，对于反向传播算法究竟是如何执行的，并没有一个很直观的理解。做过编程练习的同学应该可以感受到这些练习或多或少能帮助你，将这些复杂的步骤梳理了一遍，巩固了反向传播算法具体是如何实现的，这样你才能自己掌握这种算法。 在这段视频中，我想更加深入地讨论一下反向传播算法的这些复杂的步骤，并且希望给你一个更加全面直观的感受，理解这些步骤究竟是在做什么，也希望通过这段视频，你能理解，它至少还是一个合理的算法。但可能你即使看了这段视频，你还是觉得反向传播依然很复杂，依然像一个黑箱，太多复杂的步骤，依然感到有点神奇，这也是没关系的。即使是我接触反向传播这么多年了，有时候仍然觉得这是一个难以理解的算法，但还是希望这段视频能有些许帮助，为了更好地理解反向传播算法，我们再来仔细研究一下前向传播的原理： 前向传播算法： 反向传播算法做的是： 感悟：上图中的 $\delta^{(l)}_{j}="error" \ of cost \ for \ a^{(l)}_{j} \ (unit \ j \ in \ layer \ l)$ 理解如下： $\delta^{(l)}_{j}$ 相当于是第 $l$ 层的第 $j$ 单元中得到的激活项的“误差”，即”正确“的 $a^{(l)}_{j}$ 与计算得到的 $a^{(l)}_{j}$ 的差。 而 $a^{(l)}_{j}=g(z^{(l)})$ ，（g为sigmoid函数）。我们可以想象 $\delta^{(l)}_{j}$ 为函数求导时迈出的那一丁点微分，所以更准确的说 $\delta^{(l)}_{j}=\frac{\partial}{\partial z^{(l)}_{j} }cost(i)$ 实现注意：展开参数参考视频: 9 - 4 - Implementation Note_ Unrolling Parameters (8 min).mkv 在上一段视频中，我们谈到了怎样使用反向传播算法计算代价函数的导数。在这段视频中，我想快速地向你介绍一个细节的实现过程，怎样把你的参数从矩阵展开成向量，以便我们在高级最优化步骤中的使用需要。 梯度检验参考视频: 9 - 5 - Gradient Checking (12 min).mkv 当我们对一个较为复杂的模型（例如神经网络）使用梯度下降算法时，可能会存在一些不容易察觉的错误，意味着，虽然代价看上去在不断减小，但最终的结果可能并不是最优解。 为了避免这样的问题，我们采取一种叫做梯度的数值检验（Numerical Gradient Checking）方法。这种方法的思想是通过估计梯度值来检验我们计算的导数值是否真的是我们要求的。 对梯度的估计采用的方法是在代价函数上沿着切线的方向选择离两个非常近的点然后计算两个点的平均值用以估计梯度。即对于某个特定的 $\theta$，我们计算出在 $\theta$-$\varepsilon $ 处和 $\theta$+$\varepsilon $ 的代价值（$\varepsilon $是一个非常小的值，通常选取 0.001），然后求两个代价的平均，用以估计在 $\theta$ 处的代价值。 Octave 中代码如下： gradApprox = (J(theta + eps) – J(theta - eps)) / (2*eps) 当$\theta$是一个向量时，我们则需要对偏导数进行检验。因为代价函数的偏导数检验只针对一个参数的改变进行检验，下面是一个只针对$\theta_1$进行检验的示例： $$ \frac{\partial}{\partial\theta_1}=\frac{J\left(\theta_1+\varepsilon_1,\theta_2,\theta_3...\theta_n \right)-J \left( \theta_1-\varepsilon_1,\theta_2,\theta_3...\theta_n \right)}{2\varepsilon} $$ 最后我们还需要对通过反向传播方法计算出的偏导数进行检验。 根据上面的算法，计算出的偏导数存储在矩阵 $D_{ij}^{(l)}$ 中。检验时，我们要将该矩阵展开成为向量，同时我们也将 $\theta$ 矩阵展开为向量，我们针对每一个 $\theta$ 都计算一个近似的梯度值，将这些值存储于一个近似梯度矩阵中，最终将得出的这个矩阵同 $D_{ij}^{(l)}$ 进行比较。 随机初始化参考视频: 9 - 6 - Random Initialization (7 min).mkv 任何优化算法都需要一些初始的参数。到目前为止我们都是初始所有参数为0，这样的初始方法对于逻辑回归来说是可行的，但是对于神经网络来说是不可行的。如果我们令所有的初始参数都为0，这将意味着我们第二层的所有激活单元都会有相同的值。同理，如果我们初始所有的参数都为一个非0的数，结果也是一样的。 我们通常初始参数为正负ε之间的随机值，假设我们要随机初始一个尺寸为10×11的参数矩阵，代码如下： Theta1 = rand(10, 11) * (2*eps) – eps 综合起来参考视频: 9 - 7 - Putting It Together (14 min).mkv 小结一下使用神经网络时的步骤： 网络结构：第一件要做的事是选择网络结构，即决定选择多少层以及决定每层分别有多少个单元。 第一层的单元数即我们训练集的特征数量。 最后一层的单元数是我们训练集的结果的类的数量。 如果隐藏层数大于1，确保每个隐藏层的单元个数相同，通常情况下隐藏层单元的个数越多越好。 我们真正要决定的是隐藏层的层数和每个中间层的单元数。 训练神经网络： 参数的随机初始化 利用正向传播方法计算所有的$h_{\theta}(x)$ 编写计算代价函数 $J$ 的代码 利用反向传播方法计算所有偏导数 利用数值检验方法检验这些偏导数 使用优化算法来最小化代价函数 自主驾驶参考视频: 9 - 8 - Autonomous Driving (7 min).mkv 在这段视频中，我想向你介绍一个具有历史意义的神经网络学习的重要例子。那就是使用神经网络来实现自动驾驶，也就是说使汽车通过学习来自己驾驶。接下来我将演示的这段视频是我从 Dean Pomerleau那里拿到的，他是我的同事，任职于美国东海岸的卡耐基梅隆大学。在这部分视频中，你就会明白可视化技术到底是什么？在看这段视频之前，我会告诉你可视化技术是什么。 在下面也就是左下方，就是汽车所看到的前方的路况图像。 在图中你依稀能看出一条道路，朝左延伸了一点，又向右了一点，然后上面的这幅图，你可以看到一条水平的菜单栏显示的是驾驶操作人选择的方向。就是这里的这条白亮的区段显示的就是人类驾驶者选择的方向。比如：最左边的区段，对应的操作就是向左急转，而最右端则对应向右急转的操作。因此，稍微靠左的区段，也就是中心稍微向左一点的位置，则表示在这一点上人类驾驶者的操作是慢慢的向左拐。 这幅图的第二部分对应的就是学习算法选出的行驶方向。并且，类似的，这一条白亮的区段显示的就是神经网络在这里选择的行驶方向，是稍微的左转，并且实际上在神经网络开始学习之前，你会看到网络的输出是一条灰色的区段，就像这样的一条灰色区段覆盖着整个区域这些均称的灰色区域，显示出神经网络已经随机初始化了，并且初始化时，我们并不知道汽车如何行驶，或者说我们并不知道所选行驶方向。只有在学习算法运行了足够长的时间之后，才会有这条白色的区段出现在整条灰色区域之中。显示出一个具体的行驶方向这就表示神经网络算法，在这时候已经选出了一个明确的行驶方向，不像刚开始的时候，输出一段模糊的浅灰色区域，而是输出一条白亮的区段，表示已经选出了明确的行驶方向。 ALVINN (Autonomous Land Vehicle In a Neural Network)是一个基于神经网络的智能系统，通过观察人类的驾驶来学习驾驶，ALVINN能够控制NavLab，装在一辆改装版军用悍马，这辆悍马装载了传感器、计算机和驱动器用来进行自动驾驶的导航试验。实现ALVINN功能的第一步，是对它进行训练，也就是训练一个人驾驶汽车。 然后让ALVINN观看，ALVINN每两秒将前方的路况图生成一张数字化图片，并且记录驾驶者的驾驶方向，得到的训练集图片被压缩为30x32像素，并且作为输入提供给ALVINN的三层神经网络，通过使用反向传播学习算法，ALVINN会训练得到一个与人类驾驶员操纵方向基本相近的结果。一开始，我们的网络选择出的方向是随机的，大约经过两分钟的训练后，我们的神经网络便能够准确地模拟人类驾驶者的驾驶方向，对其他道路类型，也重复进行这个训练过程，当网络被训练完成后，操作者就可按下运行按钮，车辆便开始行驶了。 每秒钟ALVINN生成12次数字化图片，并且将图像传送给神经网络进行训练，多个神经网络同时工作，每一个网络都生成一个行驶方向，以及一个预测自信度的参数，预测自信度最高的那个神经网络得到的行驶方向。比如这里，在这条单行道上训练出的网络将被最终用于控制车辆方向，车辆前方突然出现了一个交叉十字路口，当车辆到达这个十字路口时，我们单行道网络对应的自信度骤减，当它穿过这个十字路口时，前方的双车道将进入其视线，双车道网络的自信度便开始上升，当它的自信度上升时，双车道的网络，将被选择来控制行驶方向，车辆将被安全地引导进入双车道路。 这就是基于神经网络的自动驾驶技术。当然，我们还有很多更加先进的试验来实现自动驾驶技术。在美国，欧洲等一些国家和地区，他们提供了一些比这个方法更加稳定的驾驶控制技术。但我认为，使用这样一个简单的基于反向传播的神经网络，训练出如此强大的自动驾驶汽车，的确是一次令人惊讶的成就。title: 吴恩达机器学习笔记(1-5周)date: 2019-12-04 09:28:03categories: 人工智能tags: nlpcover: https://www.github.com/OneJane/blog/raw/master/小书匠/82a490a419fe375d72125e422ed31adb_hd.jpg 吴恩达机器学习笔记&lt;!–more–&gt; 引言监督学习参考视频: 1 - 3 - Supervised Learning (12 min).mkv我们用一个例子介绍什么是监督学习把正式的定义放在后面介绍。假如说你想预测房价。 前阵子，一个学生从波特兰俄勒冈州的研究所收集了一些房价的数据。你把这些数据画出来，看起来是这个样子：横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。那基于这组数据，假如你有一个朋友，他有一套750平方英尺房子，现在他希望把房子卖掉，他想知道这房子能卖多少钱。 那么关于这个问题，机器学习算法将会怎么帮助你呢？ 我们应用学习算法，可以在这组数据中画一条直线，或者换句话说，拟合一条直线，根据这条线我们可以推测出，这套房子可能卖$150,000，当然这不是唯一的算法。可能还有更好的，比如我们不用直线拟合这些数据，用二次方程去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近$200,000。稍后我们将讨论如何选择学习算法，如何决定用直线还是二次方程来拟合。两个方案中有一个能让你朋友的房子出售得更合理。这些都是学习算法里面很好的例子。以上就是监督学习的例子。 可以看出，监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成。在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。用术语来讲，这叫做回归问题。我们试着推测出一个连续值的结果，即房子的价格。 一般房子的价格会记到美分，所以房价实际上是一系列离散的值，但是我们通常又把房价看成实数，看成是标量，所以又把它看成一个连续的数值。 回归这个词的意思是，我们在试着推测出这一系列连续值属性。 我再举另外一个监督学习的例子。我和一些朋友之前研究过这个。假设说你想通过查看病历来推测乳腺癌良性与否，假如有人检测出乳腺肿瘤，恶性肿瘤有害并且十分危险，而良性的肿瘤危害就没那么大，所以人们显然会很在意这个问题。 让我们来看一组数据：这个数据集中，横轴表示肿瘤的大小，纵轴上，我标出1和0表示是或者不是恶性肿瘤。我们之前见过的肿瘤，如果是恶性则记为1，不是恶性，或者说良性记为0。 我有5个良性肿瘤样本，在1的位置有5个恶性肿瘤样本。现在我们有一个朋友很不幸检查出乳腺肿瘤。假设说她的肿瘤大概这么大，那么机器学习的问题就在于，你能否估算出肿瘤是恶性的或是良性的概率。用术语来讲，这是一个分类问题。 分类指的是，我们试着推测出离散的输出值：0或1良性或恶性，而事实上在分类问题中，输出可能不止两个值。比如说可能有三种乳腺癌，所以你希望预测离散输出0、1、2、3。0 代表良性，1 表示第1类乳腺癌，2表示第2类癌症，3表示第3类，但这也是分类问题。 因为这几个离散的输出分别对应良性，第一类第二类或者第三类癌症，在分类问题中我们可以用另一种方式绘制这些数据点。 现在我用不同的符号来表示这些数据。既然我们把肿瘤的尺寸看做区分恶性或良性的特征，那么我可以这么画，我用不同的符号来表示良性和恶性肿瘤。或者说是负样本和正样本现在我们不全部画X，良性的肿瘤改成用 O 表示，恶性的继续用 X 表示。来预测肿瘤的恶性与否。 在其它一些机器学习问题中，可能会遇到不止一种特征。举个例子，我们不仅知道肿瘤的尺寸，还知道对应患者的年龄。在其他机器学习问题中，我们通常有更多的特征，我朋友研究这个问题时，通常采用这些特征，比如肿块密度，肿瘤细胞尺寸的一致性和形状的一致性等等，还有一些其他的特征。这就是我们即将学到最有趣的学习算法之一。 那种算法不仅能处理2种3种或5种特征，即使有无限多种特征都可以处理。 上图中，我列举了总共5种不同的特征，坐标轴上的两种和右边的3种，但是在一些学习问题中，你希望不只用3种或5种特征。相反，你想用无限多种特征，好让你的算法可以利用大量的特征，或者说线索来做推测。那你怎么处理无限多个特征，甚至怎么存储这些特征都存在问题，你电脑的内存肯定不够用。我们以后会讲一个算法，叫支持向量机，里面有一个巧妙的数学技巧，能让计算机处理无限多个特征。 想象一下，我没有写下这两种和右边的三种特征，而是在一个无限长的列表里面，一直写一直写不停的写，写下无限多个特征，事实上，我们能用算法来处理它们。 现在来回顾一下，这节课我们介绍了监督学习。其基本思想是，我们数据集中的每个样本都有相应的“正确答案”。再根据这些样本作出预测，就像房子和肿瘤的例子中做的那样。我们还介绍了回归问题，即通过回归来推出一个连续的输出，之后我们介绍了分类问题，其目标是推出一组离散的结果。 现在来个小测验：假设你经营着一家公司，你想开发学习算法来处理这两个问题： 你有一大批同样的货物，想象一下，你有上千件一模一样的货物等待出售，这时你想预测接下来的三个月能卖多少件？ 你有许多客户，这时你想写一个软件来检验每一个用户的账户。对于每一个账户，你要判断它们是否曾经被盗过？ 那这两个问题，它们属于分类问题、还是回归问题? 问题一是一个回归问题，因为你知道，如果我有数千件货物，我会把它看成一个实数，一个连续的值。因此卖出的物品数，也是一个连续的值。 问题二是一个分类问题，因为我会把预测的值，用 0 来表示账户未被盗，用 1 表示账户曾经被盗过。所以我们根据账号是否被盗过，把它们定为0 或 1，然后用算法推测一个账号是 0 还是 1，因为只有少数的离散值，所以我把它归为分类问题。 以上就是监督学习的内容。 无监督学习参考视频: 1 - 4 - Unsupervised Learning (14 min).mkv 上个视频中，已经介绍了监督学习。回想当时的数据集，如图表所示，这个数据集中每条数据都已经标明是阴性或阳性，即是良性或恶性肿瘤。所以，对于监督学习里的每条数据，我们已经清楚地知道，训练集对应的正确答案，是良性或恶性了。 在无监督学习中，我们已知的数据。看上去有点不一样，不同于监督学习的数据的样子，即无监督学习中没有任何的标签或者是有相同的标签或者就是没标签。所以我们已知数据集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集。你能从数据中找到某种结构吗？针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做聚类算法。事实证明，它能被用在很多地方。 聚类应用的一个例子就是在谷歌新闻中。如果你以前从来没见过它，你可以到这个URL网址news.google.com去看看。谷歌新闻每天都在，收集非常多，非常多的网络的新闻内容。它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件，自动地把它们聚类到一起。所以，这些新闻事件全是同一主题的，所以显示到一起。 事实证明，聚类算法和无监督学习算法同样还用在很多其它的问题上。 其中就有基因学的理解应用。一个DNA微观数据的例子。基本思想是输入一组不同个体，对其中的每个个体，你要分析出它们是否有一个特定的基因。技术上，你要分析多少特定基因已经表达。所以这些颜色，红，绿，灰等等颜色，这些颜色展示了相应的程度，即不同的个体是否有着一个特定的基因。你能做的就是运行一个聚类算法，把个体聚类到不同的类或不同类型的组（人）…… 所以这个就是无监督学习，因为我们没有提前告知算法一些信息，比如，这是第一类的人，那些是第二类的人，还有第三类，等等。我们只是说，是的，这是有一堆数据。我不知道数据里面有什么。我不知道谁是什么类型。我甚至不知道人们有哪些不同的类型，这些类型又是什么。但你能自动地找到数据中的结构吗？就是说你要自动地聚类那些个体到各个类，我没法提前知道哪些是哪些。因为我们没有给算法正确答案来回应数据集中的数据，所以这就是无监督学习。 无监督学习或聚集有着大量的应用。它用于组织大型计算机集群。我有些朋友在大数据中心工作，那里有大型的计算机集群，他们想解决什么样的机器易于协同地工作，如果你能够让那些机器协同工作，你就能让你的数据中心工作得更高效。第二种应用就是社交网络的分析。所以已知你朋友的信息，比如你经常发email的，或是你Facebook的朋友、谷歌+ 圈子的朋友，我们能否自动地给出朋友的分组呢？即每组里的人们彼此都熟识，认识组里的所有人？还有市场分割。许多公司有大型的数据库，存储消费者信息。所以，你能检索这些顾客数据集，自动地发现市场分类，并自动地把顾客划分到不同的细分市场中，你才能自动并更有效地销售或不同的细分市场一起进行销售。这也是无监督学习，因为我们拥有所有的顾客数据，但我们没有提前知道是什么的细分市场，以及分别有哪些我们数据集中的顾客。我们不知道谁是在一号细分市场，谁在二号市场，等等。那我们就必须让算法从数据中发现这一切。最后，无监督学习也可用于天文数据分析，这些聚类算法给出了令人惊讶、有趣、有用的理论，解释了星系是如何诞生的。这些都是聚类的例子，聚类只是无监督学习中的一种。 我现在告诉你们另一种。我先来介绍鸡尾酒宴问题。嗯，你参加过鸡尾酒宴吧？你可以想像下，有个宴会房间里满是人，全部坐着，都在聊天，这么多人同时在聊天，声音彼此重叠，因为每个人都在说话，同一时间都在说话，你几乎听不到你面前那人的声音。所以，可能在一个这样的鸡尾酒宴中的两个人，他俩同时都在说话，假设现在是在个有些小的鸡尾酒宴中。我们放两个麦克风在房间中，因为这些麦克风在两个地方，离说话人的距离不同每个麦克风记录下不同的声音，虽然是同样的两个说话人。听起来像是两份录音被叠加到一起，或是被归结到一起，产生了我们现在的这些录音。另外，这个算法还会区分出两个音频资源，这两个可以合成或合并成之前的录音，实际上，鸡尾酒算法的第一个输出结果是： 1，2，3，4，5，6，7，8，9，10, 所以，已经把英语的声音从录音中分离出来了。 第二个输出是这样： 1，2，3，4，5，6，7，8，9，10。 看看这个无监督学习算法，实现这个得要多么的复杂，是吧？它似乎是这样，为了构建这个应用，完成这个音频处理似乎需要你去写大量的代码或链接到一堆的合成器JAVA库，处理音频的库，看上去绝对是个复杂的程序，去完成这个从音频中分离出音频。事实上，这个算法对应你刚才知道的那个问题的算法可以就用一行代码来完成。 就是这里展示的代码：[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x&#39;); 研究人员花费了大量时间才最终实现这行代码。我不是说这个是简单的问题，但它证明了，当你使用正确的编程环境，许多学习算法是相当短的程序。所以，这也是为什么在本课中，我们打算使用Octave编程环境。Octave,是免费的开源软件，使用一个像Octave或Matlab的工具，许多学习算法变得只有几行代码就可实现。 后面，我会教你们一点关于如何使用Octave的知识，你就可以用Octave来实现一些算法了。或者，如果你有Matlab（盗版？），你也可以用Matlab。事实上，在硅谷里，对大量机器学习算法，我们第一步就是建原型，在Octave建软件原型，因为软件在Octave中可以令人难以置信地、快速地实现这些学习算法。这里的这些函数比如SVM（支持向量机）函数，奇异值分解，Octave里已经建好了。如果你试图完成这个工作，但借助C++或JAVA的话，你会需要很多很多行的代码，并链接复杂的C++或Java库。所以，你可以实现这些算法，借助C++或Java或Python，它只是用这些语言来实现会更加复杂。(编者注：这个是当时的情况，现在Python变主流了) 我已经见到，在我教机器学习将近十年后的现在，发现，学习可以更加高速，如果使用Octave作为编程环境，如果使用Octave作为学习工具，以及作为原型工具，它会让你对学习算法的学习和建原型快上许多。 事实上，许多人在大硅谷的公司里做的其实就是，使用一种工具像Octave来做第一步的学习算法的原型搭建，只有在你已经让它工作后，你才移植它到C++ 或Java或别的语言。事实证明，这样做通常可以让你的算法运行得比直接用C++ 实现更快，所以，我知道，作为一名指导者，我必须说“相信我”，但对你们中从未使用过Octave这种编程环境的人，我还是要告诉你们这一点一定要相信我，我想，对你们而言，我认为你们的时间，你们的开发时间是最有价值的资源。我已经见过很多人这样做了，我把你看作是机器学习研究员，或机器学习开发人员，想更加高产的话，你要学会使用这个原型工具，开始使用Octave。 我们介绍了无监督学习，它是学习策略，交给算法大量的数据，并让算法为我们从数据中找出某种结构。 好的，希望你们还记得垃圾邮件问题。如果你有标记好的数据，区别好是垃圾还是非垃圾邮件，我们把这个当作监督学习问题。 新闻事件分类的例子，就是那个谷歌新闻的例子，我们在本视频中有见到了，我们看到，可以用一个聚类算法来聚类这些文章到一起，所以是无监督学习。 细分市场的例子，我在更早一点的时间讲过，你可以当作无监督学习问题，因为我只是拿到算法数据，再让算法去自动地发现细分市场。 最后一个例子，糖尿病，这个其实就像是我们的乳腺癌，上个视频里的。只是替换了好、坏肿瘤，良性、恶性肿瘤，我们改用糖尿病或没病。所以我们把这个当作监督学习，我们能够解决它，作为一个监督学习问题，就像我们在乳腺癌数据中做的一样。 单变量线性回归(Linear Regression with One Variable)模型表示参考视频: 2 - 1 - Model Representation (8 min).mkv 让我们通过一个例子来开始：这个例子是预测住房价格的，我们要使用一个数据集，数据集包含俄勒冈州波特兰市的住房价格。在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子。 它被称作监督学习是因为对于每个数据来说，我们给出了“正确的答案”，即告诉我们：根据我们的数据来说，房子实际的价格是多少，而且，更具体来说，这是一个回归问题。回归一词指的是，我们根据之前的数据预测出一个准确的输出值，对于这个例子就是价格，同时，还有另一种最常见的监督学习方式，叫做分类问题，当我们想要预测离散的输出值，例如，我们正在寻找癌症肿瘤，并想要确定肿瘤是良性的还是恶性的，这就是0/1离散输出的问题。更进一步来说，在监督学习中我们有一个数据集，这个数据集被称训练集。 我将在整个课程中用小写的m来表示训练样本的数目。 以之前的房屋交易问题为例，假使我们回归问题的训练集（Training Set）如下表所示： 我们将要用来描述这个回归问题的标记如下: $m$ 代表训练集中实例的数量 $x$ 代表特征/输入变量 $y$ 代表目标变量/输出变量 $\left( x,y \right)$ 代表训练集中的实例 $({ {x}^{(i)} },{ {y}^{(i)} })$ 代表第$i$ 个观察实例 $h$ 代表学习算法的解决方案或函数也称为假设（**hypothesis**） 这就是一个监督学习算法的工作方式，我们可以看到这里有我们的训练集里房屋价格我们把它喂给我们的学习算法，学习算法的工作了，然后输出一个函数，通常表示为小写 $h$ 表示。$h$ 代表hypothesis(假设)，$h$表示一个函数，输入是房屋尺寸大小，就像你朋友想出售的房屋，因此 $h$ 根据输入的 $x$值来得出 $y$ 值，$y$ 值对应房子的价格 因此，$h$ 是一个从$x$ 到 $y$ 的函数映射。 我将选择最初的使用规则$h$代表hypothesis，因而，要解决房价预测问题，我们实际上是要将训练集“喂”给我们的学习算法，进而学习得到一个假设$h$，然后将我们要预测的房屋的尺寸作为输入变量输入给$h$，预测出该房屋的交易价格作为输出变量输出为结果。那么，对于我们的房价预测问题，我们该如何表达 $h$？ 一种可能的表达方式为：$h_\theta \left( x \right)=\theta_{0} + \theta_{1}x$，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。 代价函数参考视频: 2 - 2 - Cost Function (8 min).mkv 在线性回归中我们有一个像这样的训练集，$m$代表了训练样本的数量，比如 $m = 47$。而我们的假设函数，也就是用来进行预测的函数，是这样的线性函数形式：$h_\theta \left( x \right)=\theta_{0}+\theta_{1}x$。 接下来我们会引入一些术语我们现在要做的便是为我们的模型选择合适的参数（parameters）$\theta_{0}$ 和 $\theta_{1}$，在房价问题这个例子中便是直线的斜率和在$y$ 轴上的截距。 我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error）。 我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。 即使得代价函数 $J \left( \theta_0, \theta_1 \right) = \frac{1}{2m}\sum\limits_{i=1}^m \left( h_{\theta}(x^{(i)})-y^{(i)} \right)^{2}$最小。 我们绘制一个等高线图，三个坐标分别为$\theta_{0}$和$\theta_{1}$ 和$J(\theta_{0}, \theta_{1})$： 则可以看出在三维空间中存在一个使得$J(\theta_{0}, \theta_{1})$最小的点。 代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。 在后续课程中，我们还会谈论其他的代价函数，但我们刚刚讲的选择是对于大多数线性回归问题非常合理的。 也许这个函数$J(\theta_{0}, \theta_{1})$有点抽象，可能你仍然不知道它的内涵，在接下来的几个视频里，我们要更进一步解释代价函数J的工作原理，并尝试更直观地解释它在计算什么，以及我们使用它的目的。 代价函数的直观理解参考视频: 2 - 3 - Cost Function - Intuition I (11 min).mkv在上一个视频中，我们给了代价函数一个数学上的定义。在这个视频里，让我们通过一些例子来获取一些直观的感受，看看代价函数到底是在干什么。 代价函数的样子，等高线图，则可以看出在三维空间中存在一个使得$J(\theta_{0}, \theta_{1})$最小的点。 通过这些图形，我希望你能更好地理解这些代价函数$ J$所表达的值是什么样的，它们对应的假设是什么样的，以及什么样的假设对应的点，更接近于代价函数$J$的最小值。 当然，我们真正需要的是一种有效的算法，能够自动地找出这些使代价函数$J$取最小值的参数$\theta_{0}$和$\theta_{1}$来。 我们也不希望编个程序把这些点画出来，然后人工的方法来读出这些点的数值，这很明显不是一个好办法。我们会遇到更复杂、更高维度、更多参数的情况，而这些情况是很难画出图的，因此更无法将其可视化，因此我们真正需要的是编写程序来找出这些最小化代价函数的$\theta_{0}$和$\theta_{1}$的值，在下一节视频中，我们将介绍一种算法，能够自动地找出能使代价函数$J$最小化的参数$\theta_{0}$和$\theta_{1}$的值。 梯度下降参考视频: 2 - 5 - Gradient Descent (11 min).mkv梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数$J(\theta_{0}, \theta_{1})$ 的最小值。 梯度下降背后的思想是：开始时我们随机选择一个参数的组合$\left( {\theta_{0} },{\theta_{1} },......,{\theta_{n} } \right)$，计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到找到一个局部最小值（local minimum），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），选择不同的初始参数组合，可能会找到不同的局部最小值。 想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。 批量梯度下降（batch gradient descent）算法的公式为： 其中$a$是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。 在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新${\theta_{0} }$和${\theta_{1} }$ ，当 $j=0$ 和$j=1$时，会产生更新，所以你将更新$J\left( {\theta_{0} } \right)$和$J\left( {\theta_{1} } \right)$。实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新${\theta_{0} }$和${\theta_{1} }$，我的意思是在这个等式中，我们要这样更新： ${\theta_{0} }$:= ${\theta_{0} }$ ，并更新${\theta_{1} }$:= ${\theta_{1} }$。 实现方法是：你应该计算公式右边的部分，通过那一部分计算出${\theta_{0} }$和${\theta_{1} }$的值，然后同时更新${\theta_{0} }$和${\theta_{1} }$。 让我进一步阐述这个过程： 在梯度下降算法中，这是正确实现同时更新的方法。我不打算解释为什么你需要同时更新，同时更新是梯度下降中的一种常用方法。我们之后会讲到，同步更新是更自然的实现方法。当人们谈到梯度下降时，他们的意思就是同步更新。 在接下来的视频中，我们要进入这个微分项的细节之中。我已经写了出来但没有真正定义，如果你已经修过微积分课程，如果你熟悉偏导数和导数，这其实就是这个微分项： $\alpha \frac{\partial }{\partial { {\theta }_{0} }}J({ {\theta }_{0} },{ {\theta }_{1} })$，$\alpha \frac{\partial }{\partial { {\theta }_{1} }}J({ {\theta }_{0} },{ {\theta }_{1} })$。 如果你不熟悉微积分，不用担心，即使你之前没有看过微积分，或者没有接触过偏导数，在接下来的视频中，你会得到一切你需要知道，如何计算这个微分项的知识。 梯度下降的直观理解参考视频: 2 - 6 - Gradient Descent Intuition (12 min).mkv在之前的视频中，我们给出了一个数学上关于梯度下降的定义，本次视频我们更深入研究一下，更直观地感受一下这个算法是做什么的，以及梯度下降算法的更新过程有什么意义。梯度下降算法如下： ${\theta_{j} }:={\theta_{j} }-\alpha \frac{\partial }{\partial {\theta_{j} }}J\left(\theta \right)$ 描述：对$\theta $赋值，使得$J\left( \theta \right)$按梯度下降最快方向进行，一直迭代下去，最终得到局部最小值。其中$a$是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大。 对于这个问题，求导的目的，基本上可以说取这个红点的切线，就是这样一条红色的直线，刚好与函数相切于这一点，让我们看看这条红色直线的斜率，就是这条刚好与函数曲线相切的这条直线，这条直线的斜率正好是这个三角形的高度除以这个水平长度，现在，这条线有一个正斜率，也就是说它有正导数，因此，我得到的新的${\theta_{1} }$，${\theta_{1} }$更新后等于${\theta_{1} }$减去一个正数乘以$a$。 这就是我梯度下降法的更新规则：${\theta_{j} }:={\theta_{j} }-\alpha \frac{\partial }{\partial {\theta_{j} }}J\left( \theta \right)$ 让我们来看看如果$a$太小或$a$太大会出现什么情况： 如果$a$太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果$a$太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。 如果$a$太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果$a$太大，它会导致无法收敛，甚至发散。 现在，我还有一个问题，当我第一次学习这个地方时，我花了很长一段时间才理解这个问题，如果我们预先把${\theta_{1} }$放在一个局部的最低点，你认为下一步梯度下降法会怎样工作？ 假设你将${\theta_{1} }$初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得${\theta_{1} }$不再改变，也就是新的${\theta_{1} }$等于原来的${\theta_{1} }$，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率$a$保持不变时，梯度下降也可以收敛到局部最低点。 我们来看一个例子，这是代价函数$J\left( \theta \right)$。 我想找到它的最小值，首先初始化我的梯度下降算法，在那个品红色的点初始化，如果我更新一步梯度下降，也许它会带我到这个点，因为这个点的导数是相当陡的。现在，在这个绿色的点，如果我再更新一步，你会发现我的导数，也即斜率，是没那么陡的。随着我接近最低点，我的导数越来越接近零，所以，梯度下降一步后，新的导数会变小一点点。然后我想再梯度下降一步，在这个绿点，我自然会用一个稍微跟刚才在那个品红点时比，再小一点的一步，到了新的红色点，更接近全局最低点了，因此这点的导数会比在绿点时更小。所以，我再进行一步梯度下降时，我的导数项是更小的，${\theta_{1} }$更新的幅度就会更小。所以随着梯度下降法的运行，你移动的幅度会自动变得越来越小，直到最终移动幅度非常小，你会发现，已经收敛到局部极小值。 回顾一下，在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小$a$。 这就是梯度下降算法，你可以用它来最小化任何代价函数$J$，不只是线性回归中的代价函数$J$。 在接下来的视频中，我们要用代价函数$J$，回到它的本质，线性回归中的代价函数。也就是我们前面得出的平方误差函数，结合梯度下降法，以及平方代价函数，我们会得出第一个机器学习算法，即线性回归算法。 梯度下降的线性回归参考视频: 2 - 7 - GradientDescentForLinearRegression (6 min).mkv在以前的视频中我们谈到关于梯度下降算法，梯度下降是很常用的算法，它不仅被用在线性回归上和线性回归模型、平方误差代价函数。在这段视频中，我们要将梯度下降和代价函数结合。我们将用到此算法，并将其应用于具体的拟合直线的线性回归算法里。 梯度下降算法和线性回归算法比较如图： 对我们之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数，即： $h_\theta \left( x \right)=\theta_{0} + \theta_{1}x$ $\frac{\partial }{\partial { {\theta }_{j} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{\partial }{\partial { {\theta }_{j} }}\frac{1}{2m}{ {\sum\limits_{i=1}^{m}{\left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)} }^{2} }$ $j=0$ 时：$\frac{\partial }{\partial { {\theta }_{0} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{1}{m}{ {\sum\limits_{i=1}^{m}{\left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)} }}$ $j=1$ 时：$\frac{\partial }{\partial { {\theta }_{1} }}J({ {\theta }_{0} },{ {\theta }_{1} })=\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left( { {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)\cdot { {x}^{(i)} } \right)}$ 则算法改写成： Repeat { ​ ${\theta_{0} }:={\theta_{0} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{ \left({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)}$ ​ ${\theta_{1} }:={\theta_{1} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} } \right)\cdot { {x}^{(i)} } \right)}$ ​ } 我们刚刚使用的算法，有时也称为批量梯度下降。实际上，在机器学习中，通常不太会给算法起名字，但这个名字”批量梯度下降”，指的是在梯度下降的每一步中，我们都用到了所有的训练样本，在梯度下降中，在计算微分求导项时，我们需要进行求和运算，所以，在每一个单独的梯度下降中，我们最终都要计算这样一个东西，这个项需要对所有$m$个训练样本求和。因此，批量梯度下降法这个名字说明了我们需要考虑所有这一”批”训练样本，而事实上，有时也有其他类型的梯度下降法，不是这种”批量”型的，不考虑整个的训练集，而是每次只关注训练集中的一些小的子集。在后面的课程中，我们也将介绍这些方法。 但就目前而言，应用刚刚学到的算法，你应该已经掌握了批量梯度算法，并且能把它应用到线性回归中了，这就是用于线性回归的梯度下降法。 如果你之前学过线性代数，有些同学之前可能已经学过高等线性代数，你应该知道有一种计算代价函数$J$最小值的数值解法，不需要梯度下降这种迭代算法。在后面的课程中，我们也会谈到这个方法，它可以在不需要多步梯度下降的情况下，也能解出代价函数$J$的最小值，这是另一种称为正规方程(normal equations)的方法。实际上在数据量较大的情况下，梯度下降法比正规方程要更适用一些。 现在我们已经掌握了梯度下降，我们可以在不同的环境中使用梯度下降法，我们还将在不同的机器学习问题中大量地使用它。所以，祝贺大家成功学会你的第一个机器学习算法。 在下一段视频中，告诉你泛化的梯度下降算法，这将使梯度下降更加强大。 接下来的内容参考视频: 2 - 8 - What_’s Next (6 min).mkv在接下来的一组视频中，我会对线性代数进行一个快速的复习回顾。如果你从来没有接触过向量和矩阵，那么这课件上所有的一切对你来说都是新知识，或者你之前对线性代数有所了解，但由于隔得久了，对其有所遗忘，那就请学习接下来的一组视频，我会快速地回顾你将用到的线性代数知识。 通过它们，你可以实现和使用更强大的线性回归模型。事实上，线性代数不仅仅在线性回归中应用广泛，它其中的矩阵和向量将有助于帮助我们实现之后更多的机器学习模型，并在计算上更有效率。正是因为这些矩阵和向量提供了一种有效的方式来组织大量的数据，特别是当我们处理巨大的训练集时，如果你不熟悉线性代数，如果你觉得线性代数看上去是一个复杂、可怕的概念，特别是对于之前从未接触过它的人，不必担心，事实上，为了实现机器学习算法，我们只需要一些非常非常基础的线性代数知识。通过接下来几个视频，你可以很快地学会所有你需要了解的线性代数知识。具体来说，为了帮助你判断是否有需要学习接下来的一组视频，我会讨论什么是矩阵和向量，谈谈如何加、减 、乘矩阵和向量，讨论逆矩阵和转置矩阵的概念。 如果你十分熟悉这些概念，那么你完全可以跳过这组关于线性代数的选修视频，但是如果你对这些概念仍有些许的不确定，不确定这些数字或这些矩阵的意思，那么请看一看下一组的视频，它会很快地教你一些你需要知道的线性代数的知识，便于之后编写机器学习算法和处理大量数据。 线性代数回顾(Linear Algebra Review)矩阵和向量参考视频: 3 - 1 - Matrices and Vectors (9 min).mkv如图：这个是4×2矩阵，即4行2列，如$m$为行，$n$为列，那么$m×n$即4×2 矩阵的维数即行数×列数 矩阵元素（矩阵项）：$A=\left[ \begin{matrix} 1402 & 191 \\ 1371 & 821 \\ 949 & 1437 \\ 147 & 1448 \\\end{matrix} \right]$ $A_{ij}$指第$i$行，第$j$列的元素。 向量是一种特殊的矩阵，讲义中的向量一般都是列向量，如： $y=\left[ \begin{matrix} {460} \\ {232} \\ {315} \\ {178} \\\end{matrix} \right]$ 为四维列向量（4×1）。 如下图为1索引向量和0索引向量，左图为1索引向量，右图为0索引向量，一般我们用1索引向量。 $y=\left[ \begin{matrix} { {y}_{1} } \\ { {y}_{2} } \\ { {y}_{3} } \\ { {y}_{4} } \\\end{matrix} \right]$，$y=\left[ \begin{matrix} { {y}_{0} } \\ { {y}_{1} } \\ { {y}_{2} } \\ { {y}_{3} } \\\end{matrix} \right]$ 加法和标量乘法参考视频: 3 - 2 - Addition and Scalar Multiplication (7 min).mkv矩阵的加法：行列数相等的可以加。 例： 矩阵的乘法：每个元素都要乘 组合算法也类似。 矩阵向量乘法参考视频: 3 - 3 - Matrix Vector Multiplication (14 min).mkv 矩阵和向量的乘法如图：$m×n$的矩阵乘以$n×1$的向量，得到的是$m×1$的向量 算法举例： 矩阵乘法参考视频: 3 - 4 - Matrix Matrix Multiplication (11 min).mkv矩阵乘法： $m×n$矩阵乘以$n×o$矩阵，变成$m×o$矩阵。 如果这样说不好理解的话就举一个例子来说明一下，比如说现在有两个矩阵$A$和$B$，那么它们的乘积就可以表示为图中所示的形式。 矩阵乘法的性质参考视频: 3 - 5 - Matrix Multiplication Properties (9 min).mkv矩阵乘法的性质： 矩阵的乘法不满足交换律：$A×B≠B×A$ 矩阵的乘法满足结合律。即：$A×(B×C)=(A×B)×C$ 单位矩阵：在矩阵的乘法中，有一种矩阵起着特殊的作用，如同数的乘法中的1,我们称这种矩阵为单位矩阵．它是个方阵，一般用 $I$ 或者 $E$ 表示，本讲义都用 $I$ 代表单位矩阵，从左上角到右下角的对角线（称为主对角线）上的元素均为1以外全都为0。如： $A{ {A}^{-1} }={ {A}^{-1} }A=I$ 对于单位矩阵，有$AI=IA=A$ 逆、转置参考视频: 3 - 6 - Inverse and Transpose (11 min).mkv矩阵的逆：如矩阵$A$是一个$m×m$矩阵（方阵），如果有逆矩阵，则：$A{ {A}^{-1} }={ {A}^{-1} }A=I$ 我们一般在OCTAVE或者MATLAB中进行计算矩阵的逆矩阵。 矩阵的转置：设$A$为$m×n$阶矩阵（即$m$行$n$列），第$i $行$j $列的元素是$a(i,j)$，即：$A=a(i,j)$ 定义$A$的转置为这样一个$n×m$阶矩阵$B$，满足$B=a(j,i)$，即 $b (i,j)=a(j,i)$（$B$的第$i$行第$j$列元素是$A$的第$j$行第$i$列元素），记${ {A}^{T} }=B$。(有些书记为A’=B） 直观来看，将$A$的所有元素绕着一条从第1行第1列元素出发的右下方45度的射线作镜面反转，即得到$A$的转置。 例： ${ {\left| \begin{matrix} a& b \\ c& d \\ e& f \\\end{matrix} \right|}^{T} }=\left|\begin{matrix} a& c & e \\ b& d & f \\\end{matrix} \right|$ 矩阵的转置基本性质: $ { {\left( A\pm B \right)}^{T} }={ {A}^{T} }\pm { {B}^{T} } $ ${ {\left( A\times B \right)}^{T} }={ {B}^{T} }\times { {A}^{T} }$ ${ {\left( { {A}^{T} } \right)}^{T} }=A $ ${ {\left( KA \right)}^{T} }=K{ {A}^{T} } $ matlab中矩阵转置：直接打一撇，x=y&#39;。 多变量线性回归(Linear Regression with Multiple Variables)多维特征参考视频: 4 - 1 - Multiple Features (8 min).mkv目前为止，我们探讨了单变量/特征的回归模型，现在我们对房价模型增加更多的特征，例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为$\left( {x_{1} },{x_{2} },...,{x_{n} } \right)$。 增添更多特征后，我们引入一系列新的注释： $n$ 代表特征的数量 ${x^{\left( i \right)} }$代表第 $i$ 个训练实例，是特征矩阵中的第$i$行，是一个**向量**（**vector**）。 比方说，上图的 ${x}^{(2)}\text{=}\begin{bmatrix} 1416\\\ 3\\\ 2\\\ 40 \end{bmatrix}$， ${x}_{j}^{\left( i \right)}$代表特征矩阵中第 $i$ 行的第 $j$ 个特征，也就是第 $i$ 个训练实例的第 $j$ 个特征。 如上图的$x_{2}^{\left( 2 \right)}=3,x_{3}^{\left( 2 \right)}=2$， 支持多变量的假设 $h$ 表示为：$h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$， 这个公式中有$n+1$个参数和$n$个变量，为了使得公式能够简化一些，引入$x_{0}=1$，则公式转化为：$h_{\theta} \left( x \right)={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ 此时模型中的参数是一个$n+1$维的向量，任何一个训练实例也都是$n+1$维的向量，特征矩阵$X$的维度是 $m*(n+1)$。 因此公式可以简化为：$h_{\theta} \left( x \right)={\theta^{T} }X$，其中上标$T$代表矩阵转置。 多变量梯度下降参考视频: 4 - 2 - Gradient Descent for Multiple Variables (5 min).mkv与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：$J\left( {\theta_{0} },{\theta_{1} }...{\theta_{n} } \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( h_{\theta} \left({x}^{\left( i \right)} \right)-{y}^{\left( i \right)} \right)}^{2} }}$ ， 其中：$h_{\theta}\left( x \right)=\theta^{T}X={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ ， 我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。多变量线性回归的批量梯度下降算法为： 即： 求导数后得到： 当$n>=1$时， ${ {\theta }_{0} }:={ {\theta }_{0} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{0}^{(i)}$ ${ {\theta }_{1} }:={ {\theta }_{1} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{1}^{(i)}$ ${ {\theta }_{2} }:={ {\theta }_{2} }-a\frac{1}{m}\sum\limits_{i=1}^{m}{({ {h}_{\theta } }({ {x}^{(i)} })-{ {y}^{(i)} })}x_{2}^{(i)}$ 我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。 代码示例： 计算代价函数 $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( {h_{\theta} }\left( {x^{(i)} } \right)-{y^{(i)} } \right)}^{2} }}$ 其中：${h_{\theta} }\left( x \right)={\theta^{T} }X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ Python 代码： def computeCost(X, y, theta): inner = np.power(((X * theta.T) - y), 2) return np.sum(inner) / (2 * len(X)) 梯度下降法实践1-特征缩放参考视频: 4 - 3 - Gradient Descent in Practice I - Feature Scaling (9 min).mkv 在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。 以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。 解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。如图： 最简单的方法是令：${ {x}_{n} }=\frac{ {{x}_{n} }-{ {\mu}_{n} }}{ {{s}_{n} }}$，其中 ${\mu_{n} }$是平均值，${s_{n} }$是标准差。 梯度下降法实践2-学习率参考视频: 4 - 4 - Gradient Descent in Practice II - Learning Rate (9 min).mkv梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。 也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看上面这样的图表更好。 梯度下降算法的每次迭代受到学习率的影响，如果学习率$a$过小，则达到收敛所需的迭代次数会非常高；如果学习率$a$过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。 通常可以考虑尝试些学习率： $\alpha=0.01，0.03，0.1，0.3，1，3，10$ 特征和多项式回归参考视频: 4 - 5 - Features and Polynomial Regression (8 min).mkv 如房价预测问题， $h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }\times{frontage}+{\theta_{2} }\times{depth}$ ${x_{1} }=frontage$（临街宽度），${x_{2} }=depth$（纵向深度），$x=frontage*depth=area$（面积），则：${h_{\theta} }\left( x \right)={\theta_{0} }+{\theta_{1} }x$。 线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型：$h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}$或者三次方模型： $h_{\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}+{\theta_{3} }{x_{3}^3}$ 通常我们需要先观察数据然后再决定准备尝试怎样的模型。 另外，我们可以令： ${ {x}_{2} }=x_{2}^{2},{ {x}_{3} }=x_{3}^{3}$，从而将模型转化为线性回归模型。 根据函数图形特性，我们还可以使： ${ {{h} }_{\theta} }(x)={ {\theta }_{0} }\text{+}{ {\theta }_{1} }(size)+{ {\theta}_{2} }{ {(size)}^{2} }$ 或者: ${ {{h} }_{\theta} }(x)={ {\theta }_{0} }\text{+}{ {\theta }_{1} }(size)+{ {\theta }_{2} }\sqrt{size}$ 注：如果我们采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要。 正规方程参考视频: 4 - 6 - Normal Equation (16 min).mkv到目前为止，我们都在使用梯度下降算法，但是对于某些线性回归问题，正规方程方法是更好的解决方案。如： 正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：$\frac{\partial}{\partial{\theta_{j} }}J\left( {\theta_{j} } \right)=0$ 。假设我们的训练集特征矩阵为 $X$（包含了 ${ {x}_{0} }=1$）并且我们的训练集结果为向量 $y$，则利用正规方程解出向量 $\theta ={ {\left( {X^T}X \right)}^{-1} }{X^{T} }y$ 。上标 T 代表矩阵转置，上标-1 代表矩阵的逆。设矩阵$A={X^{T} }X$，则：${ {\left( {X^T}X \right)}^{-1} }={A^{-1} }$以下表示数据为例： 即： 运用正规方程方法求解参数： 在 Octave 中，正规方程写作： pinv(X&#39;*X)*X&#39;*y注：对于那些不可逆的矩阵（通常是因为特征之间不独立，如同时包含英尺为单位的尺寸和米为单位的尺寸两个特征，也有可能是特征数量大于训练集的数量），正规方程方法是不能用的。 梯度下降与正规方程的比较： 梯度下降 正规方程 需要选择学习率{% raw %}$\alpha${% endraw %} 不需要 需要多次迭代 一次运算得出 当特征数量{% raw %}$n${% endraw %}大时也能较好适用 需要计算{% raw %}${ {\left( { {X}^{T} }X \right)}^{-1} }${% endraw %} 如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为{% raw %}$O\left( { {n}^{3} } \right)${% endraw %}，通常来说当{% raw %}$n${% endraw %}小于10000 时还是可以接受的 适用于各种类型的模型 只适用于线性模型，不适合逻辑回归模型等其他模型 总结一下，只要特征变量的数目并不大，标准方程是一个很好的计算参数{% raw %}$\theta ${% endraw %}的替代方法。具体地说，只要特征变量数量小于一万，我通常使用标准方程法，而不使用梯度下降法。 随着我们要讲的学习算法越来越复杂，例如，当我们讲到分类算法，像逻辑回归算法，我们会看到，实际上对于那些算法，并不能使用标准方程法。对于那些更复杂的学习算法，我们将不得不仍然使用梯度下降法。因此，梯度下降法是一个非常有用的算法，可以用在有大量特征变量的线性回归问题。或者我们以后在课程中，会讲到的一些其他的算法，因为标准方程法不适合或者不能用在它们上。但对于这个特定的线性回归模型，标准方程法是一个比梯度下降法更快的替代算法。所以，根据具体的问题，以及你的特征变量的数量，这两种算法都是值得学习的。 正规方程的python实现： import numpy as np def normalEqn(X, y): theta = np.linalg.inv(X.T@X)@X.T@y #X.T@X等价于X.T.dot(X) return theta 正规方程及不可逆性（可选）参考视频: 4 - 7 - Normal Equation Noninvertibility (Optional) (6 min).mkv在这段视频中谈谈正规方程 ( normal equation )，以及它们的不可逆性。由于这是一种较为深入的概念，并且总有人问我有关这方面的问题，因此，我想在这里来讨论它，由于概念较为深入，所以对这段可选材料大家放轻松吧，也许你可能会深入地探索下去，并且会觉得理解以后会非常有用。但即使你没有理解正规方程和线性回归的关系，也没有关系。 我们要讲的问题如下：$\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$ 备注：本节最后我把推导过程写下。 有些同学曾经问过我，当计算 $\theta$=inv(X&#39;X ) X&#39;y ，那对于矩阵$X'X$的结果是不可逆的情况咋办呢?如果你懂一点线性代数的知识，你或许会知道，有些矩阵可逆，而有些矩阵不可逆。我们称那些不可逆矩阵为奇异或退化矩阵。问题的重点在于$X'X$的不可逆的问题很少发生，在Octave里，如果你用它来实现$\theta$的计算，你将会得到一个正常的解。在Octave里，有两个函数可以求解矩阵的逆，一个被称为pinv()，另一个是inv()，这两者之间的差异是些许计算过程上的，一个是所谓的伪逆，另一个被称为逆。使用pinv() 函数可以展现数学上的过程，这将计算出$\theta$的值，即便矩阵$X'X$是不可逆的。 在pinv() 和 inv() 之间，又有哪些具体区别呢 ? 其中inv() 引入了先进的数值计算的概念。例如，在预测住房价格时，如果${x_{1} }$是以英尺为尺寸规格计算的房子，${x_{2} }$是以平方米为尺寸规格计算的房子，同时，你也知道1米等于3.28英尺 ( 四舍五入到两位小数 )，这样，你的这两个特征值将始终满足约束：${x_{1} }={x_{2} }*{ {\left( 3.28 \right)}^{2} }$。实际上，你可以用这样的一个线性方程，来展示那两个相关联的特征值，矩阵$X'X$将是不可逆的。 第二个原因是，在你想用大量的特征值，尝试实践你的学习算法的时候，可能会导致矩阵$X'X$的结果是不可逆的。具体地说，在$m$小于或等于n的时候，例如，有$m$等于10个的训练样本也有$n$等于100的特征数量。要找到适合的$(n +1)$ 维参数矢量$\theta$，这将会变成一个101维的矢量，尝试从10个训练样本中找到满足101个参数的值，这工作可能会让你花上一阵子时间，但这并不总是一个好主意。因为，正如我们所看到你只有10个样本，以适应这100或101个参数，数据还是有些少。 稍后我们将看到，如何使用小数据样本以得到这100或101个参数，通常，我们会使用一种叫做正则化的线性代数方法，通过删除某些特征或者是使用某些技术，来解决当$m$比$n$小的时候的问题。即使你有一个相对较小的训练集，也可使用很多的特征来找到很多合适的参数。总之当你发现的矩阵$X'X$的结果是奇异矩阵，或者找到的其它矩阵是不可逆的，我会建议你这么做。 首先，看特征值里是否有一些多余的特征，像这些${x_{1} }$和${x_{2} }$是线性相关的，互为线性函数。同时，当有一些多余的特征时，可以删除这两个重复特征里的其中一个，无须两个特征同时保留，将解决不可逆性的问题。因此，首先应该通过观察所有特征检查是否有多余的特征，如果有多余的就删除掉，直到他们不再是多余的为止，如果特征数量实在太多，我会删除些 用较少的特征来反映尽可能多内容，否则我会考虑使用正规化方法。如果矩阵$X'X$是不可逆的，（通常来说，不会出现这种情况），如果在Octave里，可以用伪逆函数pinv() 来实现。这种使用不同的线性代数库的方法被称为伪逆。即使$X'X$的结果是不可逆的，但算法执行的流程是正确的。总之，出现不可逆矩阵的情况极少发生，所以在大多数实现线性回归中，出现不可逆的问题不应该过多的关注${X^{T} }X$是不可逆的。 增加内容： $\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$ 的推导过程： $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{ {{\left( {h_{\theta} }\left( {x^{(i)} } \right)-{y^{(i)} } \right)}^{2} }}$ 其中：${h_{\theta} }\left( x \right)={\theta^{T} }X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ 将向量表达形式转为矩阵表达形式，则有$J(\theta )=\frac{1}{2}{ {\left( X\theta -y\right)}^{2} }$ ，其中$X$为$m$行$n$列的矩阵（$m$为样本个数，$n$为特征个数），$\theta$为$n$行1列的矩阵，$y$为$m$行1列的矩阵，对$J(\theta )$进行如下变换 $J(\theta )=\frac{1}{2}{ {\left( X\theta -y\right)}^{T} }\left( X\theta -y \right)$ ​ $=\frac{1}{2}\left( { {\theta }^{T} }{ {X}^{T} }-{ {y}^{T} } \right)\left(X\theta -y \right)$ ​ $=\frac{1}{2}\left( { {\theta }^{T} }{ {X}^{T} }X\theta -{ {\theta}^{T} }{ {X}^{T} }y-{ {y}^{T} }X\theta -{ {y}^{T} }y \right)$ 接下来对$J(\theta )$偏导，需要用到以下几个矩阵的求导法则: $\frac{dAB}{dB}={ {A}^{T} }$ $\frac{d{ {X}^{T} }AX}{dX}=2AX$ 所以有: $\frac{\partial J\left( \theta \right)}{\partial \theta }=\frac{1}{2}\left(2{ {X}^{T} }X\theta -{ {X}^{T} }y -{}({ {y}^{T} }X )^{T}-0 \right)$ $=\frac{1}{2}\left(2{ {X}^{T} }X\theta -{ {X}^{T} }y -{ {X}^{T} }y -0 \right)$ ​ $={ {X}^{T} }X\theta -{ {X}^{T} }y$ 令$\frac{\partial J\left( \theta \right)}{\partial \theta }=0$, 则有$\theta ={ {\left( {X^{T} }X \right)}^{-1} }{X^{T} }y$ Octave教程(Octave Tutorial)基本操作参考视频: 5 - 1 - Basic Operations (14 min).mkv 在这段视频中，我将教你一种编程语言：Octave语言。你能够用它来非常迅速地实现这门课中我们已经学过的，或者将要学的机器学习算法。 过去我一直尝试用不同的编程语言来教授机器学习，包括C++、Java、Python、Numpy和Octave。我发现当使用像Octave这样的高级语言时，学生能够更快更好地学习并掌握这些算法。事实上，在硅谷，我经常看到进行大规模的机器学习项目的人，通常使用的程序语言就是Octave。(编者注：这是当时的情况，现在主要是用Python) Octave是一种很好的原始语言(prototyping language)，使用Octave你能快速地实现你的算法，剩下的事情，你只需要进行大规模的资源配置，你只用再花时间用C++或Java这些语言把算法重新实现就行了。开发项目的时间是很宝贵的，机器学习的时间也是很宝贵的。所以，如果你能让你的学习算法在Octave上快速的实现，基本的想法实现以后，再用C++或者Java去改写，这样你就能节省出大量的时间。 据我所见，人们使用最多的用于机器学习的原始语言是Octave、MATLAB、Python、NumPy 和R。 Octave很好，因为它是开源的。当然MATLAB也很好，但它不是每个人都买得起的。(貌似国内学生喜欢用收费的matlab，matlab功能要比Octave强大的多，网上有各种D版可以下载)。这次机器学习课的作业也是用matlab的。如果你能够使用matlab，你也可以在这门课里面使用。 如果你会Python、NumPy或者R语言，我也见过有人用 R的，据我所知，这些人不得不中途放弃了，因为这些语言在开发上比较慢，而且，因为这些语言如：Python、NumPy的语法相较于Octave来说，还是更麻烦一点。正因为这样，所以我强烈建议不要用NumPy或者R来完整这门课的作业，我建议在这门课中用Octave来写程序。 本视频将快速地介绍一系列的命令，目标是迅速地展示，通过这一系列Octave的命令，让你知道Octave能用来做什么。 启动Octave： 现在打开Octave，这是Octave命令行。 现在让我示范最基本的Octave代码： 输入5 + 6，然后得到11。 输入3 – 2、5×8、1/2、2^6等等，得到相应答案。 这些都是基本的数学运算。 你也可以做逻辑运算，例如 1==2，计算结果为 false (假)，这里的百分号命令表示注释，1==2 计算结果为假，这里用0表示。 请注意，不等于符号的写法是这个波浪线加上等于符号 ( ~= )，而不是等于感叹号加等号( != )，这是和其他一些编程语言中不太一样的地方。 让我们看看逻辑运算 1 &amp;&amp; 0，使用双&amp;符号表示逻辑与，1 &amp;&amp; 0判断为假，1和0的或运算 1 || 0，其计算结果为真。 还有异或运算 如XOR ( 1, 0 )，其返回值为1 从左向右写着 Octave 324.x版本，是默认的Octave提示，它显示了当前Octave的版本，以及相关的其它信息。 如果你不想看到那个提示，这里有一个隐藏的命令： 输入命令 现在命令提示已经变得简化了。 接下来，我们将谈到Octave的变量。 现在写一个变量，对变量$A$赋值为3，并按下回车键，显示变量$A$等于3。 如果你想分配一个变量，但不希望在屏幕上显示结果，你可以在命令后加一个分号，可以抑制打印输出，敲入回车后，不打印任何东西。 其中这句命令不打印任何东西。 现在举一个字符串的例子：变量$b$等于”hi“。 $c$等于3大于等于1，所以，现在$c$变量的值是真。 如果你想打印出变量，或显示一个变量，你可以像下面这么做： 设置$a$等于圆周率$π$，如果我要打印该值，那么只需键入a像这样 就打印出来了。 对于更复杂的屏幕输出，也可以用DISP命令显示： 这是一种，旧风格的C语言语法，对于之前就学过C语言的同学来说，你可以使用这种基本的语法来将结果打印到屏幕。 例如 ^{T}命令的六个小数：0.6%f ,a，这应该打印$π$的6位小数形式。 也有一些控制输出长短格式的快捷命令： 下面，让我们来看看向量和矩阵： 比方说 建立一个矩阵$A$： 对$A$矩阵进行赋值，考虑到这是一个三行两列的矩阵，你同样可以用向量。 建立向量$V$并赋值1 2 3，$V$是一个行向量，或者说是一个3 ( 列 )×1 ( 行 )的向量，或者说，一行三列的矩阵。 如果我想，分配一个列向量，我可以写“1;2;3”，现在便有了一个3 行 1 列的向量，同时这是一个列向量。 下面是一些更为有用的符号，如： V=1：0.1：2 这个该如何理解呢：这个集合{% raw %}$v${% endraw %}是一组值，从数值1开始，增量或说是步长为0.1，直到增加到2，按照这样的方法对向量{% raw %}$V${% endraw %}操作，可以得到一个行向量，这是一个1行11列的矩阵，其矩阵的元素是11.1 1.2 1.3，依此类推，直到数值2。 我也可以建立一个集合{% raw %}$v${% endraw %}并用命令“1:6”进行赋值，这样{% raw %}$V${% endraw %}就被赋值了1至6的六个整数。 这里还有一些其他的方法来生成矩阵 例如“ones(2, 3)”，也可以用来生成矩阵： 元素都为2，两行三列的矩阵，就可以使用这个命令： 你可以把这个方法当成一个生成矩阵的快速方法。 {% raw %}$w${% endraw %}为一个一行三列的零矩阵，一行三列的{% raw %}$A${% endraw %}矩阵里的元素全部是零： 还有很多的方式来生成矩阵。 如果我对{% raw %}$W${% endraw %}进行赋值，用Rand命令建立一个一行三列的矩阵，因为使用了Rand命令，则其一行三列的元素均为随机值，如“rand(3,3)”命令，这就生成了一个3×3的矩阵，并且其所有元素均为随机。 数值介于0和1之间，所以，正是因为这一点，我们可以得到数值均匀介于0和1之间的元素。 如果，你知道什么是高斯随机变量，或者，你知道什么是正态分布的随机变量，你可以设置集合{% raw %}$W${% endraw %}，使其等于一个一行三列的{% raw %}$N${% endraw %}矩阵，并且，来自三个值，一个平均值为0的高斯分布，方差或者等于1的标准偏差。 还可以设置地更复杂： 并用hist命令绘制直方图。 绘制单位矩阵： 如果对命令不清楚，建议用help命令： 以上讲解的内容都是Octave的基本操作。希望你能通过上面的讲解，自己练习一些矩阵、乘、加等操作，将这些操作在Octave中熟练运用。 在接下来的视频中，将会涉及更多复杂的命令，并使用它们在Octave中对数据进行更多的操作。 移动数据参考视频: 5 - 2 - Moving Data Around (16 min).mkv 在这段关于 Octave的辅导课视频中，我将开始介绍如何在 Octave 中移动数据。 如果你有一个机器学习问题，你怎样把数据加载到 Octave 中？ 怎样把数据存入一个矩阵？ 如何对矩阵进行相乘？ 如何保存计算结果？ 如何移动这些数据并用数据进行操作？ 进入我的 Octave 窗口， 我键入{% raw %}$A${% endraw %}，得到我们之前构建的矩阵 {% raw %}$A${% endraw %}，也就是用这个命令生成的： A = [1 2; 3 4; 5 6] 这是一个3行2列的矩阵，Octave 中的 size() 命令返回矩阵的尺寸。 所以 size(A) 命令返回3 2 实际上，size() 命令返回的是一个 1×2 的矩阵，我们可以用 {% raw %}$sz${% endraw %} 来存放。 设置 sz = size(A) 因此 {% raw %}$sz${% endraw %} 就是一个1×2的矩阵，第一个元素是3，第二个元素是2。 所以如果键入 size(sz) 看看 {% raw %}$sz${% endraw %} 的尺寸，返回的是1 2，表示是一个1×2的矩阵，1 和 2分别表示矩阵{% raw %}$sz${% endraw %}的维度 。 你也可以键入 size(A, 1)，将返回3，这个命令会返回{% raw %}$A${% endraw %}矩阵的第一个元素，{% raw %}$A${% endraw %}矩阵的第一个维度的尺寸，也就是 {% raw %}$A${% endraw %} 矩阵的行数。 同样，命令 size(A, 2)，将返回2，也就是 {% raw %}$A${% endraw %} 矩阵的列数。 如果你有一个向量 {% raw %}$v${% endraw %}，假如 v = [1 2 3 4]，然后键入length(v)，这个命令将返回最大维度的大小，返回4。 你也可以键入length(A)，由于矩阵{% raw %}$A${% endraw %}是一个3×2的矩阵，因此最大的维度应该是3，因此该命令会返回3。 但通常我们还是对向量使用 {% raw %}$length${% endraw %} 命令，而不是对矩阵使用 length 命令，比如length([1;2;3;4;5])，返回5。 如何在系统中加载数据和寻找数据： 当我们打开 Octave 时，我们通常已经在一个默认路径中，这个路径是 Octave的安装位置，pwd 命令可以显示出Octave 当前所处路径。 cd命令，意思是改变路径，我可以把路径改为C:\Users\ang\Desktop，这样当前目录就变为了桌面。 如果键入 ls，ls 来自于一个 Unix 或者 Linux 命令，ls命令将列出我桌面上的所有路径。 事实上，我的桌面上有两个文件：featuresX.dat 和priceY.dat，是两个我想解决的机器学习问题。 featuresX文件如这个窗口所示，是一个含有两列数据的文件，其实就是我的房屋价格数据，数据集中有47行，第一个房子样本，面积是2104平方英尺，有3个卧室，第二套房子面积为1600，有3个卧室等等。 priceY这个文件就是训练集中的价格数据，所以 featuresX 和priceY就是两个存放数据的文档，那么应该怎样把数据读入 Octave 呢？我们只需要键入featuresX.dat，这样我将加载了 featuresX 文件。同样地我可以加载priceY.dat。其实有好多种办法可以完成，如果你把命令写成字符串的形式load(&#39;featureX.dat&#39;)，也是可以的，这跟刚才的命令效果是相同的，只不过是把文件名写成了一个字符串的形式，现在文件名被存在一个字符串中。Octave中使用引号来表示字符串。 另外 who 命令，能显示出 在我的 Octave工作空间中的所有变量 所以我可以键入featuresX 回车，来显示 featuresX 这些就是存在里面的数据。 还可以键入 size(featuresX)，得出的结果是 47 2，代表这是一个47×2的矩阵。 类似地，输入 size(priceY)，结果是 471，表示这是一个47维的向量，是一个列矩阵，存放的是训练集中的所有价格{% raw %}$Y${% endraw %} 的值。 who 函数能让你看到当前工作空间中的所有变量，同样还有另一个 whos命令，能更详细地进行查看。 同样也列出我所有的变量，不仅如此，还列出了变量的维度。 double 意思是双精度浮点型，这也就是说，这些数都是实数，是浮点数。 如果你想删除某个变量，你可以使用 clear 命令，我们键入 clear featuresX，然后再输入 whos 命令，你会发现 featuresX 消失了。 另外，我们怎么储存数据呢？ 我们设变量 V= priceY(1:10) 这表示的是将向量 {% raw %}$Y ${% endraw %}的前10个元素存入 {% raw %}$V${% endraw %}中。 假如我们想把它存入硬盘，那么用 save hello.mat v 命令，这个命令会将变量{% raw %}$V${% endraw %}存成一个叫 hello.mat 的文件，让我们回车，现在我的桌面上就出现了一个新文件，名为hello.mat。 由于我的电脑里同时安装了 MATLAB，所以这个图标上面有 MATLAB的标识，因为操作系统把文件识别为 MATLAB文件。如果在你的电脑上图标显示的不一样的话，也没有关系。 现在我们清除所有变量，直接键入clear，这样将删除工作空间中的所有变量，所以现在工作空间中啥都没了。 但如果我载入 hello.mat 文件，我又重新读取了变量 {% raw %}$v${% endraw %}，因为我之前把变量{% raw %}$v${% endraw %}存入了hello.mat 文件中，所以我们刚才用 save命令做了什么。这个命令把数据按照二进制形式储存，或者说是更压缩的二进制形式，因此，如果{% raw %}$v${% endraw %}是很大的数据，那么压缩幅度也更大，占用空间也更小。如果你想把数据存成一个人能看懂的形式，那么可以键入： save hello.txt v -ascii 这样就会把数据存成一个文本文档，或者将数据的 ascii 码存成文本文档。 我键入了这个命令以后，我的桌面上就有了 hello.txt文件。如果打开它，我们可以发现这个文本文档存放着我们的数据。 这就是读取和储存数据的方法。 接下来我们再来讲讲操作数据的方法： 假如 {% raw %}$A${% endraw %} 还是那个矩阵 跟刚才一样还是那个 3×2 的矩阵，现在我们加上索引值，比如键入 A(3,2) 这将索引到{% raw %}$A${% endraw %} 矩阵的 (3,2) 元素。这就是我们通常书写矩阵的形式，写成 {% raw %}$A${% endraw %} 32，3和2分别表示矩阵的第三行和第二列对应的元素，因此也就对应 6。 我也可以键入A(2,:) 来返回第二行的所有元素，冒号表示该行或该列的所有元素。 类似地，如果我键入 A(:,2)，这将返回 {% raw %}$A${% endraw %} 矩阵第二列的所有元素，这将得到 2 4 6。 这表示返回{% raw %}$A${% endraw %} 矩阵的第二列的所有元素。 你也可以在运算中使用这些较为复杂的索引。 我再给你展示几个例子，可能你也不会经常使用，但我还是输入给你看 A([1 3],:)，这个命令意思是取 {% raw %}$A${% endraw %} 矩阵第一个索引值为1或3的元素，也就是说我取的是A矩阵的第一行和第三行的每一列，冒号表示的是取这两行的每一列元素，即： 可能这些比较复杂一点的索引操作你会经常用到。 我们还能做什么呢？依然是 {% raw %}$A${% endraw %} 矩阵，A(:,2) 命令返回第二列。 你也可以为它赋值，我可以取 {% raw %}$A${% endraw %} 矩阵的第二列，然后将它赋值为10 11 12，我实际上是取出了 {% raw %}$A${% endraw %} 的第二列，然后把一个列向量[10;11;12]赋给了它，因此现在 {% raw %}$A${% endraw %} 矩阵的第一列还是 1 3 5，第二列就被替换为 10 11 12。 接下来一个操作，让我们把 {% raw %}$A ${% endraw %}设为A = [A, [100, 101,102]]，这样做的结果是在原矩阵的右边附加了一个新的列矩阵，就是把 {% raw %}$A${% endraw %}矩阵设置为原来的 {% raw %}$A${% endraw %} 矩阵再在右边附上一个新添加的列矩阵。 最后，还有一个小技巧，如果你就输入 A(:)，这是一个很特别的语法结构，意思是把 {% raw %}$A${% endraw %}中的所有元素放入一个单独的列向量，这样我们就得到了一个 9×1 的向量，这些元素都是{% raw %}$A${% endraw %} 中的元素排列起来的。 再来几个例子： 我还是把 A 重新设为 [1 2; 3 4; 5 6]，我再设一个 {% raw %}$B${% endraw %}为[11 12; 13 14; 15 16]，我可以新建一个矩阵 {% raw %}$C${% endraw %}，C = [A B]，这个意思就是把这两个矩阵直接连在一起，矩阵{% raw %}$A${% endraw %} 在左边，矩阵{% raw %}$B${% endraw %} 在右边，这样组成了 {% raw %}$C${% endraw %}矩阵，就是直接把{% raw %}$A${% endraw %}和 {% raw %}$B${% endraw %} 合起来。 我还可以设C = [A; B]，这里的分号表示把分号后面的东西放到下面。所以，[A;B]的作用依然还是把两个矩阵放在一起，只不过现在是上下排列，所以现在 {% raw %}$A${% endraw %} 在上面 {% raw %}$B${% endraw %}在下面，{% raw %}$C${% endraw %} 就是一个 6×2 矩阵。 简单地说，分号的意思就是换到下一行，所以 C 就包括上面的A，然后换行到下面，然后在下面放上一个 {% raw %}$B${% endraw %}。 另外顺便说一下，这个[A B]命令跟 [A, B] 是一样的，这两种写法的结果是相同的。 通过以上这些操作，希望你现在掌握了怎样构建矩阵，也希望我展示的这些命令能让你很快地学会怎样把矩阵放到一起，怎样取出矩阵，并且把它们放到一起，组成更大的矩阵。 通过几句简单的代码，Octave能够很方便地很快速地帮助我们组合复杂的矩阵以及对数据进行移动。这就是移动数据这一节课。 我认为对你来讲，最好的学习方法是，下课后复习一下我键入的这些代码好好地看一看，从课程的网上把代码的副本下载下来，重新好好看看这些副本，然后自己在Octave 中把这些命令重新输一遍，慢慢开始学会使用这些命令。 当然，没有必要把这些命令都记住，你也不可能记得住。你要做的就是，了解一下你可以用哪些命令，做哪些事。这样在你今后需要编写学习算法时，如果你要找到某个Octave中的命令，你可能回想起你之前在这里学到过，然后你就可以查找课程中提供的程序副本，这样就能很轻松地找到你想使用的命令了。 计算数据参考视频: 5 - 3 - Computing on Data (13 min).mkv 现在，你已经学会了在Octave中如何加载或存储数据，如何把数据存入矩阵等等。在这段视频中，我将介绍如何对数据进行运算，稍后我们将使用这些运算操作来实现我们的学习算法。 这是我的 Octave窗口，我现在快速地初始化一些变量。比如设置{% raw %}$A${% endraw %}为一个3×2的矩阵，设置{% raw %}$B${% endraw %}为一个3 ×2矩阵，设置{% raw %}$C${% endraw %}为2 × 2矩阵。 我想算两个矩阵的乘积，比如说 {% raw %}$A × C${% endraw %}，我只需键入A×C，这是一个 3×2 矩阵乘以 2×2矩阵，得到这样一个3×2矩阵。 你也可以对每一个元素，做运算 方法是做点乘运算A.*B，这么做Octave将矩阵 {% raw %}$A${% endraw %}中的每一个元素与矩阵 {% raw %}$B${% endraw %} 中的对应元素相乘:A.*B 这里第一个元素1乘以11得到11，第二个元素2乘以12得到24，这就是两个矩阵的元素位运算。通常来说，在Octave中点号一般用来表示元素位运算。 这里是一个矩阵{% raw %}$A${% endraw %}，这里我输入A.^2，这将对矩阵{% raw %}$A${% endraw %}中每一个元素平方。 我们设{% raw %}$V${% endraw %}为 [1; 2; 3] 是列向量，你也可以输入1./V，得到每一个元素的倒数，所以这样一来，就会分别算出 1/1 1/2 1/3。 矩阵也可以这样操作，1./A 得到{% raw %}$A${% endraw %}中每一个元素的倒数。 同样地，这里的点号还是表示对每一个元素进行操作。 我们还可以进行求对数运算，也就是对每个元素进行求对数运算。 还有自然数{% raw %}$e${% endraw %}的幂次运算，就是以{% raw %}$e${% endraw %}为底，以这些元素为幂的运算。 我还可以用 abs来对 {% raw %}$v${% endraw %} 的每一个元素求绝对值，当然这里 {% raw %}$v${% endraw %}都是正数。我们换成另一个这样对每个元素求绝对值，得到的结果就是这些非负的元素。还有{% raw %}$–v${% endraw %}，给出{% raw %}$v${% endraw %}中每个元素的相反数，这等价于 -1 乘以 {% raw %}$v${% endraw %}，一般就直接用 {% raw %}$-v${% endraw %}就好了，其实就等于 $-1*v$。 还有一个技巧，比如说我们想对{% raw %}$v${% endraw %}中的每个元素都加1，那么我们可以这么做，首先构造一个3行1列的1向量，然后把这个1向量跟原来的向量相加，因此{% raw %}$v${% endraw %}向量从[1 2 3] 增至 [2 3 4]。我用了一个，length(v)命令，因此这样一来，ones(length(v) ,1) 就相当于ones(3,1)，然后我做的是v +ones(3,1)，也就是将 {% raw %}$v${% endraw %} 的各元素都加上这些1，这样就将{% raw %}$v${% endraw %} 的每个元素增加了1。 另一种更简单的方法是直接用 v+1，v + 1 也就等于把 {% raw %}$v${% endraw %} 中的每一个元素都加上1。 现在，让我们来谈谈更多的操作。 矩阵{% raw %}$A${% endraw %} 如果你想要求它的转置，那么方法是用A’,将得出 A 的转置矩阵。当然，如果我写(A&#39;)&#39;，也就是 {% raw %}$A${% endraw %} 转置两次，那么我又重新得到矩阵 {% raw %}$A${% endraw %}。 还有一些有用的函数，比如： a=[1 15 2 0.5]，这是一个1行4列矩阵，val=max(a)，这将返回{% raw %}$A${% endraw %}矩阵中的最大值15。 我还可以写 [val, ind] =max(a)，这将返回{% raw %}$A${% endraw %}矩阵中的最大值存入{% raw %}$val${% endraw %}，以及该值对应的索引，元素15对应的索引值为2,存入{% raw %}$ind${% endraw %}，所以 {% raw %}$ind =2${% endraw %}。 特别注意一下，如果你用命令 max(A)，{% raw %}$A${% endraw %}是一个矩阵的话，这样做就是对每一列求最大值。 我们还是用这个例子，这个 {% raw %}$a${% endraw %} 矩阵a=[1 15 2 0.5]，如果输入a&amp;lt;3，这将进行逐元素的运算，所以元素小于3的返回1，否则返回0。 因此，返回[1 1 0 1]。也就是说，对{% raw %}$a${% endraw %}矩阵的每一个元素与3进行比较，然后根据每一个元素与3的大小关系，返回1和0表示真与假。 如果我写 find(a&amp;lt;3)，这将告诉我{% raw %}$a${% endraw %} 中的哪些元素是小于3的。 设A = magic(3)，magic 函数将返回一个矩阵，称为魔方阵或幻方 (magic squares)，它们具有以下这样的数学性质：它们所有的行和列和对角线加起来都等于相同的值。 当然据我所知，这在机器学习里基本用不上，但我可以用这个方法很方便地生成一个3行3列的矩阵，而这个魔方矩阵这神奇的方形屏幕。每一行、每一列、每一个对角线三个数字加起来都是等于同一个数。 在其他有用的机器学习应用中，这个矩阵其实没多大作用。 如果我输入 [r,c] = find(A&gt;=7)，这将找出所有{% raw %}$A${% endraw %}矩阵中大于等于7的元素，因此，{% raw %}$r${% endraw %} 和{% raw %}$c${% endraw %}分别表示行和列，这就表示，第一行第一列的元素大于等于7，第三行第二列的元素大于等于7，第二行第三列的元素大于等于7。 顺便说一句，其实我从来都不去刻意记住这个 find 函数，到底是怎么用的，我只需要会用help函数就可以了，每当我在使用这个函数，忘记怎么用的时候，我就可以用 help函数，键入 help find 来找到帮助文档。 最后再讲两个内容，一个是求和函数，这是 {% raw %}$a${% endraw %} 矩阵： 键入 sum(a)，就把 a 中所有元素加起来了。 如果我想把它们都乘起来，键入 prod(a)，prod 意思是product(乘积)，它将返回这四个元素的乘积。 floor(a) 是向下四舍五入，因此对于 {% raw %}$a${% endraw %} 中的元素0.5将被下舍入变成0。 还有 ceil(a)，表示向上四舍五入，所以0.5将上舍入变为最接近的整数，也就是1。 键入 type(3)，这通常得到一个3×3的矩阵，如果键入 max(rand(3),rand(3))，这样做的结果是返回两个3×3的随机矩阵，并且逐元素比较取最大值。 假如我输入max(A,[],1)，这样做会得到每一列的最大值。 所以第一列的最大值就是8，第二列是9，第三列的最大值是7，这里的1表示取A矩阵第一个维度的最大值。 相对地，如果我键入max(A,[],2)，这将得到每一行的最大值，所以，第一行的最大值是等于8，第二行最大值是7，第三行是9。 所以你可以用这个方法来求得每一行或每一列的最值，另外，你要知道，默认情况下max(A)返回的是每一列的最大值，如果你想要找出整个矩阵A的最大值，你可以输入max(max(A))，或者你可以将{% raw %}$A${% endraw %} 矩阵转成一个向量，然后键入 max(A(:))，这样做就是把 {% raw %}$A${% endraw %} 当做一个向量，并返回 {% raw %}$A${% endraw %}向量中的最大值。 最后，让我们把 {% raw %}$A${% endraw %}设为一个9行9列的魔方阵，魔方阵具有的特性是每行每列和对角线的求和都是相等的。 这是一个9×9的魔方阵，我们来求一个 sum(A,1)，这样就得到每一列的总和，这也验证了一个9×9的魔方阵确实每一列加起来都相等，都为369。 现在我们来求每一行的和，键入sum(A,2)，这样就得到了{% raw %}$A${% endraw %} 中每一行的和加起来还是369。 现在我们来算{% raw %}$A ${% endraw %}的对角线元素的和。我们现在构造一个9×9 的单位矩阵，键入 eye(9), 然后我们要用 {% raw %}$A${% endraw %}逐点乘以这个单位矩阵，除了对角线元素外，其他元素都会得到0。 键入sum(sum(A.*eye(9)) 这实际上是求得了，这个矩阵对角线元素的和确实是369。 你也可以求另一条对角线的和也是是369。 flipup/flipud 表示向上/向下翻转。 同样地，如果你想求这个矩阵的逆矩阵，键入pinv(A)，通常称为伪逆矩阵，你就把它看成是矩阵 {% raw %}$A${% endraw %} 求逆，因此这就是 {% raw %}$A${% endraw %}矩阵的逆矩阵。 设 temp = pinv(A)，然后再用{% raw %}$temp${% endraw %} 乘以{% raw %}$A${% endraw %}，这实际上得到的就是单位矩阵，对角线为1，其他元素为0。 如何对矩阵中的数字进行各种操作，在运行完某个学习算法之后，通常一件最有用的事情是看看你的结果，或者说让你的结果可视化，在接下来的视频中，我会非常迅速地告诉你，如何很快地画图，如何只用一两行代码，你就可以快速地可视化你的数据，这样你就能更好地理解你使用的学习算法。 绘图数据参考视频: 5 - 4 - Plotting Data (10 min).mkv 当开发学习算法时，往往几个简单的图，可以让你更好地理解算法的内容，并且可以完整地检查下算法是否正常运行，是否达到了算法的目的。 例如在之前的视频中，我谈到了绘制成本函数{% raw %}$J(\theta)${% endraw %}，可以帮助确认梯度下降算法是否收敛。通常情况下，绘制数据或学习算法所有输出，也会启发你如何改进你的学习算法。幸运的是，Octave有非常简单的工具用来生成大量不同的图。当我用学习算法时，我发现绘制数据、绘制学习算法等，往往是我获得想法来改进算法的重要部分。在这段视频中，我想告诉你一些Octave的工具来绘制和可视化你的数据。 我们先来快速生成一些数据用来绘图。 如果我想绘制正弦函数，这是很容易的，我只需要输入plot(t,y1)，并回车，就出现了这个图： 横轴是{% raw %}$t${% endraw %}变量，纵轴是{% raw %}$y1${% endraw %}，也就是我们刚刚所输出的正弦函数。 让我们设置{% raw %}$y2${% endraw %} Octave将会消除之前的正弦图，并且用这个余弦图来代替它，这里纵轴{% raw %}$cos(x)${% endraw %}从1开始， 如果我要同时表示正弦和余弦曲线。 我要做的就是，输入：plot(t, y1)，得到正弦函数，我使用函数hold on，hold on函数的功能是将新的图像绘制在旧的之上。 我现在绘制{% raw %}$y2${% endraw %}，输入：plot(t, y2)。 我要以不同的颜色绘制余弦函数，所以我在这里输入带引号的r绘制余弦函数，{% raw %}$r${% endraw %}表示所使用的颜色：plot(t,y2,’r’)，再加上命令xlabel(&#39;time&#39;)，来标记X轴即水平轴，输入ylabel(&#39;value&#39;)，来标记垂直轴的值。 同时我也可以来标记我的两条函数曲线，用这个命令 legend(&#39;sin&#39;,&#39;cos&#39;)将这个图例放在右上方，表示这两条曲线表示的内容。最后输入title(&#39;myplot&#39;)，在图像的顶部显示这幅图的标题。 如果你想保存这幅图像，你输入print –dpng &#39;myplot.png&#39;，png是一个图像文件格式，如果你这样做了，它可以让你保存为一个文件。 Octave也可以保存为很多其他的格式，你可以键入help plot。 最后如果你想，删掉这个图像，用命令close会让这个图像关掉。 Octave也可以让你为图像标号 你键入figure(1); plot(t, y1);将显示第一张图，绘制了变量{% raw %}$t${% endraw %} {% raw %}$y1${% endraw %}。 键入figure(2); plot(t, y2); 将显示第一张图，绘制了变量{% raw %}$t${% endraw %} {% raw %}$y2${% endraw %}。 subplot命令，我们要使用subplot(1,2,1)，它将图像分为一个1*2的格子，也就是前两个参数，然后它使用第一个格子，也就是最后一个参数1的意思。 我现在使用第一个格子，如果键入plot(t,y1)，现在这个图显示在第一个格子。如果我键入subplot(1,2,2)，那么我就要使用第二个格子，键入plot(t,y2)；现在y2显示在右边，也就是第二个格子。 最后一个命令，你可以改变轴的刻度，比如改成[0.5 1 -1 1]，输入命令：axis([0.5 1 -1 1])也就是设置了右边图的{% raw %}$x${% endraw %}轴和{% raw %}$y${% endraw %}轴的范围。具体而言，它将右图中的横轴的范围调整至0.5到1，竖轴的范围为-1到1。 你不需要记住所有这些命令，如果你需要改变坐标轴，或者需要知道axis命令，你可以用Octave中用help命令了解细节。 最后，还有几个命令。 Clf（清除一幅图像）。 让我们设置A等于一个5×5的magic方阵： 我有时用一个巧妙的方法来可视化矩阵，也就是imagesc(A)命令，它将会绘制一个5*5的矩阵，一个5*5的彩色格图，不同的颜色对应A矩阵中的不同值。 我还可以使用函数colorbar，让我用一个更复杂的命令 imagesc(A)，colorbar，colormap gray。这实际上是在同一时间运行三个命令：运行imagesc，然后运行，colorbar，然后运行colormap gray。 它生成了一个颜色图像，一个灰度分布图，并在右边也加入一个颜色条。所以这个颜色条显示不同深浅的颜色所对应的值。 你可以看到在不同的方格，它对应于一个不同的灰度。 输入imagesc(magic(15))，colorbar，colormap gray 这将会是一幅15*15的magic方阵值的图。 最后，总结一下这段视频。你看到我所做的是使用逗号连接函数调用。如果我键入{% raw %}$a=1${% endraw %},{% raw %}$b=2${% endraw %},{% raw %}$c=3${% endraw %}然后按Enter键，其实这是将这三个命令同时执行，或者是将三个命令一个接一个执行，它将输出所有这三个结果。 这很像{% raw %}$a=1${% endraw %}; {% raw %}$b=2${% endraw %};{% raw %}$c=3${% endraw %};如果我用分号来代替逗号，则没有输出出任何东西。 这里我们称之为逗号连接的命令或函数调用。 用逗号连接是另一种Octave中更便捷的方式，将多条命令例如imagesc colorbar colormap，将这多条命令写在同一行中。 现在你知道如何绘制Octave中不同的图像，在下面的视频中，我将告诉你怎样在Octave中，写控制语句，比如if while for语句，并且定义和使用函数。 控制语句：for，while，if语句参考视频: 5 - 5 - Control Statements_ for, while, if statements (13 min).mkv 在这段视频中，我想告诉你怎样为你的 Octave 程序写控制语句。诸如：”for“ “while“ “if“ 这些语句，并且如何定义和使用方程。 我先告诉你如何使用 “for” 循环。 首先，我要将 {% raw %}$v${% endraw %} 值设为一个10行1列的零向量。 接着我要写一个 “for“ 循环，让 {% raw %}$i${% endraw %} 等于 1 到 10，写出来就是 i = 1:10。我要设{% raw %}$ v(i)${% endraw %}的值等于 2 的 {% raw %}$i${% endraw %} 次方，循环最后写上“end”。 向量{% raw %}$v${% endraw %} 的值就是这样一个集合 2的一次方、2的二次方，依此类推。这就是我的 {% raw %}$i${% endraw %} 等于 1 到 10的语句结构，让 {% raw %}$i${% endraw %} 遍历 1 到 10的值。 另外，你还可以通过设置你的 indices (索引) 等于 1一直到10，来做到这一点。这时indices 就是一个从1到10的序列。 你也可以写 i = indices，这实际上和我直接把 i 写到 1 到 10 是一样。你可以写 disp(i)，也能得到一样的结果。所以 这就是一个 “for” 循环。 如果你对 “break” 和 “continue” 语句比较熟悉，Octave里也有 “break” 和 “continue”语句，你也可以在 Octave环境里使用那些循环语句。 但是首先让我告诉你一个 while 循环是如何工作的： 这是什么意思呢：我让 {% raw %}$i${% endraw %} 取值从 1 开始，然后我要让 {% raw %}$v(i)${% endraw %} 等于 100，再让 {% raw %}$i${% endraw %} 递增 1，直到{% raw %}$i${% endraw %} 大于 5停止。 现在来看一下结果，我现在已经取出了向量的前五个元素，把他们用100覆盖掉，这就是一个while循环的句法结构。 现在我们来分析另外一个例子： 这里我将向你展示如何使用break语句。比方说 v(i) = 999，然后让 i = i+1，当 {% raw %}$i${% endraw %} 等于6的时候 break (停止循环)，结束 (end)。 当然这也是我们第一次使用一个 if 语句，所以我希望你们可以理解这个逻辑，让 {% raw %}$i${% endraw %} 等于1 然后开始下面的增量循环，while语句重复设置 {% raw %}$v(i)${% endraw %} 等于999，不断让{% raw %}$i${% endraw %}增加，然后当 {% raw %}$i${% endraw %} 达到6，做一个中止循环的命令，尽管有while循环，语句也就此中止。所以最后的结果是取出向量 {% raw %}$v${% endraw %} 的前5个元素，并且把它们设置为999。 所以，这就是if 语句和 while 语句的句法结构。并且要注意要有end，上面的例子里第一个 end 结束的是 if语句，第二个 end 结束的是 while 语句。 现在让我告诉你使用 if-else 语句： 最后，提醒一件事：如果你需要退出 Octave，你可以键入exit命令然后回车就会退出 Octave，或者命令quit也可以。 最后，让我们来说说函数 (functions)，如何定义和调用函数。 我在桌面上存了一个预先定义的文件名为 “squarethisnumber.m”，这就是在 Octave 环境下定义的函数。 让我们打开这个文件。请注意，我使用的是微软的写字板程序来打开这个文件，我只是想建议你，如果你也使用微软的Windows系统，那么可以使用写字板程序，而不是记事本来打开这些文件。如果你有别的什么文本编辑器也可以，记事本有时会把代码的间距弄得很乱。如果你只有记事本程序，那也能用。我建议你用写字板或者其他可以编辑函数的文本编辑器。 现在我们来说如何在 Octave 里定义函数： 这个文件只有三行： 第一行写着 function y = squareThisNumber(x)，这就告诉 Octave，我想返回一个 y值，我想返回一个值，并且返回的这个值将被存放于变量 {% raw %}$y${% endraw %} 里。另外，它告诉了Octave这个函数有一个参数，就是参数 {% raw %}$x${% endraw %}，还有定义的函数体，也就是 {% raw %}$y${% endraw %} 等于 {% raw %}$x${% endraw %} 的平方。 还有一种更高级的功能，这只是对那些知道“search path (搜索路径)”这个术语的人使用的。所以如果你想要修改Octave的搜索路径，你可以把下面这部分作为一个进阶知识，或者选学材料，仅适用于那些熟悉编程语言中搜索路径概念的同学。 你可以使用addpath 命令添加路径，添加路径“C:\Users\ang\desktop”将该目录添加到Octave的搜索路径，这样即使你跑到其他路径底下，Octave依然知道会在 Users\ang\desktop目录下寻找函数。这样，即使我现在在不同的目录下，它仍然知道在哪里可以找到“SquareThisNumber” 这个函数。 但是，如果你不熟悉搜索路径的概念，不用担心，只要确保在执行函数之前，先用 cd命令设置到你函数所在的目录下，实际上也是一样的效果。 Octave还有一个其他许多编程语言都没有的概念，那就是它可以允许你定义一个函数，使得返回值是多个值或多个参数。这里就是一个例子，定义一个函数叫： “SquareAndCubeThisNumber(x)” ({% raw %}$x${% endraw %}的平方以及{% raw %}$x${% endraw %}的立方) 这说的就是函数返回值是两个： {% raw %}$y1${% endraw %} 和 {% raw %}$y2${% endraw %}，接下来就是{% raw %}$y1${% endraw %}是被平方后的结果，{% raw %}$y2${% endraw %}是被立方后的结果，这就是说，函数会真的返回2个值。 有些同学可能会根据你使用的编程语言，比如你们可能熟悉的C或C++，通常情况下，认为作为函数返回值只能是一个值，但Octave 的语法结构就不一样，可以返回多个值。 如果我键入 [a,b] = SquareAndCubeThisNumber(5)，然后，{% raw %}$a${% endraw %}就等于25，{% raw %}$b${% endraw %} 就等于5的立方125。 所以说如果你需要定义一个函数并且返回多个值，这一点常常会带来很多方便。 最后，我来给大家演示一下一个更复杂一点的函数的例子。 比方说，我有一个数据集，像这样，数据点为[1,1], [2,2],[3,3]，我想做的事是定义一个 Octave 函数来计算代价函数 {% raw %}$J(\theta)${% endraw %}，就是计算不同 {% raw %}$\theta${% endraw %}值所对应的代价函数值{% raw %}$J${% endraw %}。 首先让我们把数据放到 Octave 里，我把我的矩阵设置为X = [1 1; 1 2; 1 3]; 请仔细看一下这个函数的定义，确保你明白了定义中的每一步。 现在当我在 Octave 里运行时，我键入 J = costFunctionJ (X, y, theta)，它就计算出 {% raw %}$J${% endraw %}等于0，这是因为如果我的数据集{% raw %}$x${% endraw %} 为 [1;2;3]， {% raw %}$y${% endraw %} 也为 [1;2;3] 然后设置 {% raw %}$\theta_0${% endraw %} 等于0，{% raw %}$\theta_1${% endraw %}等于1，这给了我恰好45度的斜线，这条线是可以完美拟合我的数据集的。 而相反地，如果我设置{% raw %}$\theta${% endraw %} 等于[0;0]，那么这个假设就是0是所有的预测值，和刚才一样，设置{% raw %}$\theta_0${% endraw %} = 0，{% raw %}$\theta_1${% endraw %}也等于0，然后我计算的代价函数，结果是2.333。实际上，他就等于1的平方，也就是第一个样本的平方误差，加上2的平方，加上3的平方，然后除以{% raw %}$2m${% endraw %}，也就是训练样本数的两倍，这就是2.33。 因此这也反过来验证了我们这里的函数，计算出了正确的代价函数。这些就是我们用简单的训练样本尝试的几次试验，这也可以作为我们对定义的代价函数{% raw %}$J${% endraw %}进行了完整性检查。确实是可以计算出正确的代价函数的。至少基于这里的 {% raw %}$x${% endraw %}和 {% raw %}$y${% endraw %}是成立的。也就是我们这几个简单的训练集，至少是成立的。 现在你知道如何在 Octave 环境下写出正确的控制语句，比如 for 循环、while 循环和 if语句，以及如何定义和使用函数。 在接下来的Octave 教程视频里，我会讲解一下向量化，这是一种可以使你的 Octave程序运行非常快的思想。 向量化参考视频: 5 - 6 - Vectorization (14 min).mkv 在这段视频中，我将介绍有关向量化的内容，无论你是用Octave，还是别的语言，比如MATLAB或者你正在用Python、NumPy 或 Java C C++，所有这些语言都具有各种线性代数库，这些库文件都是内置的，容易阅读和获取，他们通常写得很好，已经经过高度优化，通常是数值计算方面的博士或者专业人士开发的。 而当你实现机器学习算法时，如果你能好好利用这些线性代数库，或者数值线性代数库，并联合调用它们，而不是自己去做那些函数库可以做的事情。如果是这样的话，那么通常你会发现：首先，这样更有效，也就是说运行速度更快，并且更好地利用你的计算机里可能有的一些并行硬件系统等等；其次，这也意味着你可以用更少的代码来实现你需要的功能。因此，实现的方式更简单，代码出现问题的有可能性也就越小。 举个具体的例子：与其自己写代码做矩阵乘法。如果你只在Octave中输入{% raw %}$a${% endraw %}乘以{% raw %}$b${% endraw %}就是一个非常有效的两个矩阵相乘的程序。有很多例子可以说明，如果你用合适的向量化方法来实现，你就会有一个简单得多，也有效得多的代码。 让我们来看一些例子：这是一个常见的线性回归假设函数：{% raw %}${ {h}_{\theta } }(x)=\sum\limits_{j=0}^{n}{ {{\theta }_{j} }{ {x}_{j} }}${% endraw %} 如果你想要计算{% raw %}$h_\theta(x)${% endraw %} ，注意到右边是求和，那么你可以自己计算{% raw %}$j = 0${% endraw %} 到{% raw %}$ j = n${% endraw %} 的和。但换另一种方式来想想，把 {% raw %}$h_\theta(x)${% endraw %} 看作{% raw %}$\theta^Tx${% endraw %}，那么你就可以写成两个向量的内积，其中{% raw %}$\theta${% endraw %}就是{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}，如果你有两个特征量，如果 {% raw %}$n = 2${% endraw %}，并且如果你把 {% raw %}$x${% endraw %} 看作{% raw %}$x_0${% endraw %}、{% raw %}$x_1${% endraw %}、{% raw %}$x_2${% endraw %}，这两种思考角度，会给你两种不同的实现方式。 比如说，这是未向量化的代码实现方式： 计算{% raw %}$h_\theta(x)${% endraw %}是未向量化的，我们可能首先要初始化变量 {% raw %}$prediction${% endraw %} 的值为0.0，而这个变量{% raw %}$prediction${% endraw %} 的最终结果就是{% raw %}$h_\theta(x)${% endraw %}，然后我要用一个 for 循环，{% raw %}$j${% endraw %} 取值 0 到{% raw %}$n+1${% endraw %}，变量{% raw %}$prediction${% endraw %} 每次就通过自身加上{% raw %}$ theta(j) ${% endraw %}乘以 {% raw %}$x(j)${% endraw %}更新值，这个就是算法的代码实现。 顺便我要提醒一下，这里的向量我用的下标是0，所以我有{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}，但因为MATLAB的下标从1开始，在 MATLAB 中{% raw %}$\theta_0${% endraw %}，我们可能会用 {% raw %}$theta(1)${% endraw %} 来表示，这第二个元素最后就会变成，{% raw %}$theta(2${% endraw %}) 而第三个元素，最终可能就用{% raw %}$theta(3)${% endraw %}表示，因为MATLAB中的下标从1开始，这就是为什么这里我的 for 循环，{% raw %}$j${% endraw %}取值从 1 直到{% raw %}$n+1${% endraw %}，而不是从 0 到 {% raw %}$n${% endraw %}。这是一个未向量化的代码实现方式，我们用一个 for 循环对 {% raw %}$n${% endraw %} 个元素进行加和。 作为比较，接下来是向量化的代码实现： 你把x和{% raw %}$\theta${% endraw %}看做向量，而你只需要令变量{% raw %}$prediction${% endraw %}等于{% raw %}$theta${% endraw %}转置乘以{% raw %}$x${% endraw %}，你就可以这样计算。与其写所有这些for循环的代码，你只需要一行代码，这行代码就是利用 Octave 的高度优化的数值，线性代数算法来计算两个向量{% raw %}$\theta${% endraw %}以及{% raw %}$x${% endraw %}的内积，这样向量化的实现更简单，它运行起来也将更加高效。这就是 Octave 所做的而向量化的方法，在其他编程语言中同样可以实现。 让我们来看一个C++ 的例子： 与此相反，使用较好的C++ 数值线性代数库，你可以写出像右边这样的代码，因此取决于你的数值线性代数库的内容。你只需要在C++ 中将两个向量相乘，根据你所使用的数值和线性代数库的使用细节的不同，你最终使用的代码表达方式可能会有些许不同，但是通过一个库来做内积，你可以得到一段更简单、更有效的代码。 现在，让我们来看一个更为复杂的例子，这是线性回归算法梯度下降的更新规则： 我们用这条规则对{% raw %}$ j${% endraw %} 等于 0、1、2等等的所有值，更新对象{% raw %}$\theta_j${% endraw %}，我只是用{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}来写方程，假设我们有两个特征量，所以{% raw %}$n${% endraw %}等于2，这些都是我们需要对{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}进行更新，这些都应该是同步更新，我们用一个向量化的代码实现，这里是和之前相同的三个方程，只不过写得小一点而已。 你可以想象实现这三个方程的方式之一，就是用一个 for 循环，就是让 {% raw %}$j${% endraw %}等于0、等于1、等于2，来更新{% raw %}$\theta_j${% endraw %}。但让我们用向量化的方式来实现，看看我们是否能够有一个更简单的方法。基本上用三行代码或者一个for 循环，一次实现这三个方程。让我们来看看怎样能用这三步，并将它们压缩成一行向量化的代码来实现。做法如下： 我打算把{% raw %}$\theta${% endraw %}看做一个向量，然后我用{% raw %}$\theta${% endraw %}-{% raw %}$\alpha${% endraw %} 乘以某个别的向量{% raw %}$\delta${% endraw %} 来更新{% raw %}$\theta${% endraw %}。 这里的 {% raw %}$\delta${% endraw %} 等于 让我解释一下是怎么回事：我要把{% raw %}$\theta${% endraw %}看作一个向量，有一个 {% raw %}$n+1${% endraw %} 维向量，{% raw %}$\alpha${% endraw %} 是一个实数，{% raw %}$\delta${% endraw %}在这里是一个向量。 所以这个减法运算是一个向量减法，因为 {% raw %}$\alpha${% endraw %} 乘以 δ是一个向量，所以{% raw %}$\theta${% endraw %}就是{% raw %}$\theta${% endraw %} - {% raw %}$\alpha \delta${% endraw %}得到的向量。 那么什么是向量 {% raw %}$\delta${% endraw %} 呢 ? {% raw %}$X^{(i)}${% endraw %}是一个向量 你就会得到这些不同的式子，然后作加和。 实际上，在以前的一个小测验，如果你要解这个方程，我们说过为了向量化这段代码，我们会令u = 2v +5w因此，我们说向量{% raw %}$u${% endraw %}等于2乘以向量{% raw %}$v${% endraw %}加上5乘以向量{% raw %}$w${% endraw %}。用这个例子说明，如何对不同的向量进行相加，这里的求和是同样的道理。 这就是为什么我们能够向量化地实现线性回归。 所以，我希望步骤是有逻辑的。请务必看视频，并且保证你确实能理解它。如果你实在不能理解它们数学上等价的原因，你就直接实现这个算法，也是能得到正确答案的。所以即使你没有完全理解为何是等价的，如果只是实现这种算法，你仍然能实现线性回归算法。如果你能弄清楚为什么这两个步骤是等价的，那我希望你可以对向量化有一个更好的理解，如果你在实现线性回归的时候，使用一个或两个以上的特征量。 有时我们使用几十或几百个特征量来计算线性归回，当你使用向量化地实现线性回归，通常运行速度就会比你以前用你的for循环快的多，也就是自己写代码更新{% raw %}$\theta_0${% endraw %}、{% raw %}$\theta_1${% endraw %}、{% raw %}$\theta_2${% endraw %}。 因此使用向量化实现方式，你应该是能够得到一个高效得多的线性回归算法。而当你向量化我们将在之后的课程里面学到的算法，这会是一个很好的技巧，无论是对于Octave 或者一些其他的语言 如C++、Java 来让你的代码运行得更高效。 逻辑回归(Logistic Regression)分类问题参考文档: 6 - 1 - Classification (8 min).mkv 在这个以及接下来的几个视频中，开始介绍分类问题。 在分类问题中，你要预测的变量 {% raw %}$y${% endraw %} 是离散的值，我们将学习一种叫做逻辑回归 (Logistic Regression) 的算法，这是目前最流行使用最广泛的一种学习算法。 在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；之前我们也谈到了肿瘤分类问题的例子，区别一个肿瘤是恶性的还是良性的。 我们从二元的分类问题开始讨论。 我们将因变量(dependent variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量{% raw %}$y\in { 0,1 \\}${% endraw %} ，其中 0 表示负向类，1 表示正向类。 如果我们要用线性回归算法来解决一个分类问题，对于分类， {% raw %}$y${% endraw %} 取值为 0 或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于 1，或者远小于0，即使所有训练样本的标签 {% raw %}$y${% endraw %} 都等于 0 或 1。尽管我们知道标签应该取值0 或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到 1 之间。 顺便说一下，逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上是一种分类算法，它适用于标签 {% raw %}$y${% endraw %} 取值离散的情况，如：1 0 0 1。 在接下来的视频中，我们将开始学习逻辑回归算法的细节。 假说表示参考视频: 6 - 2 - Hypothesis Representation (7 min).mkv 在这段视频中，我要给你展示假设函数的表达式，也就是说，在分类问题中，要用什么样的函数来表示我们的假设。此前我们说过，希望我们的分类器的输出值在0和1之间，因此，我们希望想出一个满足某个性质的假设函数，这个性质是它的预测值要在0和1之间。 回顾在一开始提到的乳腺癌分类问题，我们可以用线性回归的方法求出适合数据的一条直线： 根据线性回归模型我们只能预测连续的值，然而对于分类问题，我们需要输出0或1，我们可以预测： 当{% raw %}${h_\theta}\left( x \right)>=0.5${% endraw %}时，预测 {% raw %}$y=1${% endraw %}。 当{% raw %}${h_\theta}\left( x \right)&lt;0.5${% endraw %}时，预测 {% raw %}$y=0${% endraw %} 。 对于上图所示的数据，这样的一个线性模型似乎能很好地完成分类任务。假使我们又观测到一个非常大尺寸的恶性肿瘤，将其作为实例加入到我们的训练集中来，这将使得我们获得一条新的直线。 这时，再使用0.5作为阀值来预测肿瘤是良性还是恶性便不合适了。可以看出，线性回归模型，因为其预测的值可以超越[0,1]的范围，并不适合解决这样的问题。 我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在0和1之间。逻辑回归模型的假设是： {% raw %}$h_\theta \left( x \right)=g\left(\theta^{T}X \right)${% endraw %}其中： {% raw %}$X${% endraw %} 代表特征向量 {% raw %}$g${% endraw %} 代表逻辑函数（**logistic function**)是一个常用的逻辑函数为**S**形函数（**Sigmoid function**），公式为： {% raw %}$g\left( z \right)=\frac{1}{1+{ {e}^{-z} }}${% endraw %}。 python代码实现： import numpy as np def sigmoid(z): return 1 / (1 + np.exp(-z)) 该函数的图像为： 合起来，我们得到逻辑回归模型的假设： 对模型的理解： $g\left( z \right)=\frac{1}{1+{ {e}^{-z} }}$。 $h_\theta \left( x \right)$的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性（**estimated probablity**）即$h_\theta \left( x \right)=P\left( y=1|x;\theta \right)$ 例如，如果对于给定的$x$，通过已经确定的参数计算得出$h_\theta \left( x \right)=0.7$，则表示有70%的几率$y$为正向类，相应地$y$为负向类的几率为1-0.7=0.3。 判定边界参考视频: 6 - 3 - Decision Boundary (15 min).mkv 现在讲下决策边界(decision boundary)的概念。这个概念能更好地帮助我们理解逻辑回归的假设函数在计算什么。 在逻辑回归中，我们预测： 当${h_\theta}\left( x \right)>=0.5$时，预测 $y=1$。 当${h_\theta}\left( x \right)&lt;0.5$时，预测 $y=0$ 。 根据上面绘制出的 S 形函数图像，我们知道当 $z=0$ 时 $g(z)=0.5$ $z>0$ 时 $g(z)>0.5$ $z&lt;0$ 时 $g(z)&lt;0.5$ 又 $z={\theta^{T} }x$ ，即： ${\theta^{T} }x>=0$ 时，预测 $y=1$ ${\theta^{T} }x&lt;0$ 时，预测 $y=0$ 现在假设我们有一个模型： 并且参数$\theta$ 是向量[-3 1 1]。 则当$-3+{x_1}+{x_2} \geq 0$，即${x_1}+{x_2} \geq 3$时，模型将预测 $y=1$。我们可以绘制直线${x_1}+{x_2} = 3$，这条线便是我们模型的分界线，将预测为1的区域和预测为 0的区域分隔开。 假使我们的数据呈现这样的分布情况，怎样的模型才能适合呢？ 因为需要用曲线才能分隔 $y=0$ 的区域和 $y=1$ 的区域，我们需要二次方特征：${h_\theta}\left( x \right)=g\left( {\theta_0}+{\theta_1}{x_1}+{\theta_{2} }{x_{2} }+{\theta_{3} }x_{1}^{2}+{\theta_{4} }x_{2}^{2} \right)$是[-1 0 0 1 1]，则我们得到的判定边界恰好是圆点在原点且半径为1的圆形。 我们可以用非常复杂的模型来适应非常复杂形状的判定边界。 代价函数参考视频: 6 - 4 - Cost Function (11 min).mkv 在这段视频中，我们要介绍如何拟合逻辑回归模型的参数$\theta$。具体来说，我要定义用来拟合参数的优化目标或者叫代价函数，这便是监督学习问题中的逻辑回归模型的拟合问题。 对于线性回归模型，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将${h_\theta}\left( x \right)=\frac{1}{1+{e^{-\theta^{T}x} }}$带入到这样定义了的代价函数中时，我们得到的代价函数将是一个非凸函数（non-convexfunction）。 这意味着我们的代价函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。 线性回归的代价函数为：$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{1}{2}{ {\left( {h_\theta}\left({x}^{\left( i \right)} \right)-{y}^{\left( i \right)} \right)}^{2} }}$ 。我们重新定义逻辑回归的代价函数为：$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{ {Cost}\left( {h_\theta}\left( {x}^{\left( i \right)} \right),{y}^{\left( i \right)} \right)}$，其中 ${h_\theta}\left( x \right)$与 $Cost\left( {h_\theta}\left( x \right),y \right)$之间的关系如下图所示： 这样构建的$Cost\left( {h_\theta}\left( x \right),y \right)$函数的特点是：当实际的 $y=1$ 且${h_\theta}\left( x \right)$也为 1 时误差为 0，当 $y=1$ 但${h_\theta}\left( x \right)$不为1时误差随着${h_\theta}\left( x \right)$变小而变大；当实际的 $y=0$ 且${h_\theta}\left( x \right)$也为 0 时代价为 0，当$y=0$ 但${h_\theta}\left( x \right)$不为 0时误差随着 ${h_\theta}\left( x \right)$的变大而变大。将构建的 $Cost\left( {h_\theta}\left( x \right),y \right)$简化如下： $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$ 带入代价函数得到： $J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$ 即：$J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$ Python代码实现： import numpy as np def cost(theta, X, y): theta = np.matrix(theta) X = np.matrix(X) y = np.matrix(y) first = np.multiply(-y, np.log(sigmoid(X* theta.T))) second = np.multiply((1 - y), np.log(1 - sigmoid(X* theta.T))) return np.sum(first - second) / (len(X)) 在得到这样一个代价函数以后，我们便可以用梯度下降算法来求得能使代价函数最小的参数了。算法为： Repeat { $\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j} J(\theta)$ (simultaneously update all )} 求导后得到： Repeat { $\theta_j := \theta_j - \alpha \frac{1}{m}\sum\limits_{i=1}^{m}{ {\left( {h_\theta}\left( \mathop{x}^{\left( i \right)} \right)-\mathop{y}^{\left( i \right)} \right)} }\mathop{x}_{j}^{(i)}$ (simultaneously update all )} 在这个视频中，我们定义了单训练样本的代价函数，凸性分析的内容是超出这门课的范围的，但是可以证明我们所选的代价值函数会给我们一个凸优化问题。代价函数$J(\theta)$会是一个凸函数，并且没有局部最优值。 推导过程： $J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$ 考虑： ${h_\theta}\left( { {x}^{(i)} } \right)=\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }}$ 则： ${ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)$ $={ {y}^{(i)} }\log \left( \frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }} \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }} \right)$ $=-{ {y}^{(i)} }\log \left( 1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} } \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} } \right)$ 所以： $\frac{\partial }{\partial {\theta_{j} }}J\left( \theta \right)=\frac{\partial }{\partial {\theta_{j} }}[-\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( 1+{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} } \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1+{ {e}^{ {\theta^{T} }{ {x}^{(i)} }} } \right)]}]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\frac{-x_{j}^{(i)}{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} }}{1+{ {e}^{-{\theta^{T} }{ {x}^{(i)} }} }}-\left( 1-{ {y}^{(i)} } \right)\frac{x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }} }]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{ {y}^{(i)} }\frac{x_j^{(i)} }{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}-\left( 1-{ {y}^{(i)} } \right)\frac{x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}]$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{ {{y}^{(i)} }x_j^{(i)}-x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }+{ {y}^{(i)} }x_j^{(i)}{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{ {{y}^{(i)} }\left( 1\text{+}{ {e}^{ {\theta^T}{ {x}^{(i)} }} } \right)-{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }}x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{({ {y}^{(i)} }-\frac{ {{e}^{ {\theta^T}{ {x}^{(i)} }} }}{1+{ {e}^{ {\theta^T}{ {x}^{(i)} }} }})x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{({ {y}^{(i)} }-\frac{1}{1+{ {e}^{-{\theta^T}{ {x}^{(i)} }} }})x_j^{(i)} }$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }-{h_\theta}\left( { {x}^{(i)} } \right)]x_j^{(i)} }$ $=\frac{1}{m}\sum\limits_{i=1}^{m}{[{h_\theta}\left( { {x}^{(i)} } \right)-{ {y}^{(i)} }]x_j^{(i)} }$ 注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。 一些梯度下降算法之外的选择：除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：共轭梯度（Conjugate Gradient），局部优化法(Broyden fletcher goldfarb shann,BFGS)和有限内存局部优化法(LBFGS) ，fminunc是 matlab和octave 中都带的一个最小值优化函数，使用时我们需要提供代价函数和每个参数的求导，下面是 octave 中使用 fminunc 函数的代码示例： function [jVal, gradient] = costFunction(theta) jVal = [...code to compute J(theta)...]; gradient = [...code to compute derivative of J(theta)...]; end options = optimset(&#39;GradObj&#39;, &#39;on&#39;, &#39;MaxIter&#39;, &#39;100&#39;); initialTheta = zeros(2,1); [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options); 在下一个视频中，我们会把单训练样本的代价函数的这些理念进一步发展，然后给出整个训练集的代价函数的定义，我们还会找到一种比我们目前用的更简单的写法，基于这些推导出的结果，我们将应用梯度下降法得到我们的逻辑回归算法。 简化的成本函数和梯度下降参考视频: 6 - 5 - Simplified Cost Function and Gradient Descent (10 min).mkv 在这段视频中，我们将会找出一种稍微简单一点的方法来写代价函数，来替换我们现在用的方法。同时我们还要弄清楚如何运用梯度下降法，来拟合出逻辑回归的参数。因此，听了这节课，你就应该知道如何实现一个完整的逻辑回归算法。 这就是逻辑回归的代价函数： 这个式子可以合并成： $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$ 即，逻辑回归的代价函数： $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$ $=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$ 根据这个代价函数，为了拟合出参数，该怎么做呢？我们要试图找尽量让$J\left( \theta \right)$ 取得最小值的参数$\theta $。 $\underset{\theta}{\min }J\left( \theta \right)$ 所以我们想要尽量减小这一项，这将我们将得到某个参数$\theta $。如果我们给出一个新的样本，假如某个特征 $x$，我们可以用拟合训练样本的参数$\theta $，来输出对假设的预测。另外，我们假设的输出，实际上就是这个概率值：$p(y=1|x;\theta)$，就是关于 $x$以$\theta $为参数，$y=1$ 的概率，你可以认为我们的假设就是估计 $y=1$ 的概率，所以，接下来就是弄清楚如何最大限度地最小化代价函数$J\left( \theta \right)$，作为一个关于$\theta $的函数，这样我们才能为训练集拟合出参数$\theta $。 最小化代价函数的方法，是使用梯度下降法(gradient descent)。这是我们的代价函数： $J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)+\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}$ 如果我们要最小化这个关于$\theta$的函数值，这就是我们通常用的梯度下降法的模板。 我们要反复更新每个参数，用这个式子来更新，就是用它自己减去学习率 $\alpha$乘以后面的微分项。求导后得到： 如果你计算一下的话，你会得到这个等式： ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){x_{j} }^{(i)} }$ 我把它写在这里，将后面这个式子，在 $i=1$ 到 $m$ 上求和，其实就是预测误差乘以$x_j^{(i)}$ ，所以你把这个偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$放回到原来式子这里，我们就可以将梯度下降算法写作如下形式： ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){x_{j} }^{(i)} }$ 所以，如果你有 $n$ 个特征，也就是说：，参数向量$\theta $包括${\theta_{0} }$ ${\theta_{1} }$ ${\theta_{2} }$ 一直到${\theta_{n} }$，那么你就需要用这个式子： ${\theta_j}:={\theta_j}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} }){ {x}_{j} }^{(i)} }$来同时更新所有$\theta $的值。 现在，如果你把这个更新规则和我们之前用在线性回归上的进行比较的话，你会惊讶地发现，这个式子正是我们用来做线性回归梯度下降的。 那么，线性回归和逻辑回归是同一个算法吗？要回答这个问题，我们要观察逻辑回归看看发生了哪些变化。实际上，假设的定义发生了变化。 对于线性回归假设函数： ${h_\theta}\left( x \right)={\theta^T}X={\theta_{0} }{x_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2} }+...+{\theta_{n} }{x_{n} }$ 而现在逻辑函数假设函数： ${h_\theta}\left( x \right)=\frac{1}{1+{ {e}^{-{\theta^T}X} }}$ 因此，即使更新参数的规则看起来基本相同，但由于假设的定义发生了变化，所以逻辑函数的梯度下降，跟线性回归的梯度下降实际上是两个完全不同的东西。 在先前的视频中，当我们在谈论线性回归的梯度下降法时，我们谈到了如何监控梯度下降法以确保其收敛，我通常也把同样的方法用在逻辑回归中，来监测梯度下降，以确保它正常收敛。 当使用梯度下降法来实现逻辑回归时，我们有这些不同的参数$\theta $，就是${\theta_{0} }$ ${\theta_{1} }$ ${\theta_{2} }$ 一直到${\theta_{n} }$，我们需要用这个表达式来更新这些参数。我们还可以使用 for循环来更新这些参数值，用 for i=1 to n，或者 for i=1 to n+1。当然，不用 for循环也是可以的，理想情况下，我们更提倡使用向量化的实现，可以把所有这些 $n$个参数同时更新。 最后还有一点，我们之前在谈线性回归时讲到的特征缩放，我们看到了特征缩放是如何提高梯度下降的收敛速度的，这个特征缩放的方法，也适用于逻辑回归。如果你的特征范围差距很大的话，那么应用特征缩放的方法，同样也可以让逻辑回归中，梯度下降收敛更快。 就是这样，现在你知道如何实现逻辑回归，这是一种非常强大，甚至可能世界上使用最广泛的一种分类算法。 高级优化参考视频: 6 - 6 - Advanced Optimization (14 min).mkv 在上一个视频中，我们讨论了用梯度下降的方法最小化逻辑回归中代价函数$J\left( \theta \right)$。在本次视频中，我会教你们一些高级优化算法和一些高级的优化概念，利用这些方法，我们就能够使通过梯度下降，进行逻辑回归的速度大大提高，而这也将使算法更加适合解决大型的机器学习问题，比如，我们有数目庞大的特征量。现在我们换个角度来看什么是梯度下降，我们有个代价函数$J\left( \theta \right)$，而我们想要使其最小化，那么我们需要做的是编写代码，当输入参数 $\theta$ 时，它们会计算出两样东西：$J\left( \theta \right)$ 以及$J$ 等于 0、1直到 $n$ 时的偏导数项。 假设我们已经完成了可以实现这两件事的代码，那么梯度下降所做的就是反复执行这些更新。另一种考虑梯度下降的思路是：我们需要写出代码来计算$J\left( \theta \right)$ 和这些偏导数，然后把这些插入到梯度下降中，然后它就可以为我们最小化这个函数。对于梯度下降来说，我认为从技术上讲，你实际并不需要编写代码来计算代价函数$J\left( \theta \right)$。你只需要编写代码来计算导数项，但是，如果你希望代码还要能够监控这些$J\left( \theta \right)$ 的收敛性，那么我们就需要自己编写代码来计算代价函数$J(\theta)$和偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$。所以，在写完能够计算这两者的代码之后，我们就可以使用梯度下降。然而梯度下降并不是我们可以使用的唯一算法，还有其他一些算法，更高级、更复杂。如果我们能用这些方法来计算代价函数$J\left( \theta \right)$和偏导数项$\frac{\partial }{\partial {\theta_j} }J\left( \theta \right)$两个项的话，那么这些算法就是为我们优化代价函数的不同方法，共轭梯度法 BFGS (变尺度法) 和L-BFGS (限制变尺度法) 就是其中一些更高级的优化算法，它们需要有一种方法来计算 $J\left( \theta \right)$，以及需要一种方法计算导数项，然后使用比梯度下降更复杂的算法来最小化代价函数。这三种算法的具体细节超出了本门课程的范畴。实际上你最后通常会花费很多天，或几周时间研究这些算法，你可以专门学一门课来提高数值计算能力，不过让我来告诉你他们的一些特性： 这三种算法有许多优点： 一个是使用这其中任何一个算法，你通常不需要手动选择学习率 $\alpha$，所以对于这些算法的一种思路是，给出计算导数项和代价函数的方法，你可以认为算法有一个智能的内部循环，而且，事实上，他们确实有一个智能的内部循环，称为线性搜索(line search)算法，它可以自动尝试不同的学习速率 $\alpha$，并自动选择一个好的学习速率 $a$，因此它甚至可以为每次迭代选择不同的学习速率，那么你就不需要自己选择。这些算法实际上在做更复杂的事情，不仅仅是选择一个好的学习速率，所以它们往往最终比梯度下降收敛得快多了，不过关于它们到底做什么的详细讨论，已经超过了本门课程的范围。 实际上，我过去使用这些算法已经很长一段时间了，也许超过十年了，使用得相当频繁，而直到几年前我才真正搞清楚共轭梯度法 BFGS 和 L-BFGS的细节。 我们实际上完全有可能成功使用这些算法，并应用于许多不同的学习问题，而不需要真正理解这些算法的内环间在做什么，如果说这些算法有缺点的话，那么我想说主要缺点是它们比梯度下降法复杂多了，特别是你最好不要使用 L-BGFS、BFGS这些算法，除非你是数值计算方面的专家。实际上，我不会建议你们编写自己的代码来计算数据的平方根，或者计算逆矩阵，因为对于这些算法，我还是会建议你直接使用一个软件库，比如说，要求一个平方根，我们所能做的就是调用一些别人已经写好用来计算数字平方根的函数。幸运的是现在我们有Octave 和与它密切相关的 MATLAB 语言可以使用。 Octave 有一个非常理想的库用于实现这些先进的优化算法，所以，如果你直接调用它自带的库，你就能得到不错的结果。我必须指出这些算法实现得好或不好是有区别的，因此，如果你正在你的机器学习程序中使用一种不同的语言，比如如果你正在使用C、C++、Java等等，你可能会想尝试一些不同的库，以确保你找到一个能很好实现这些算法的库。因为在L-BFGS或者等高线梯度的实现上，表现得好与不太好是有差别的，因此现在让我们来说明：如何使用这些算法： 比方说，你有一个含两个参数的问题，这两个参数是${\theta_{0} }$和${\theta_{1} }$，因此，通过这个代价函数，你可以得到${\theta_{1} }$和 ${\theta_{2} }$的值，如果你将$J\left( \theta \right)$ 最小化的话，那么它的最小值将是${\theta_{1} }=5$ ，${\theta_{2} }=5$。代价函数$J\left( \theta \right)$的导数推出来就是这两个表达式： $\frac{\partial }{\partial { {\theta }_{1} }}J(\theta)=2({ {\theta }_{1} }-5)$ $\frac{\partial }{\partial { {\theta }_{2} }}J(\theta)=2({ {\theta }_{2} }-5)$ 如果我们不知道最小值，但你想要代价函数找到这个最小值，是用比如梯度下降这些算法，但最好是用比它更高级的算法，你要做的就是运行一个像这样的Octave 函数： function [jVal, gradient]=costFunction(theta) jVal=(theta(1)-5)^2+(theta(2)-5)^2; gradient=zeros(2,1); gradient(1)=2*(theta(1)-5); gradient(2)=2*(theta(2)-5); end 这样就计算出这个代价函数，函数返回的第二个值是梯度值，梯度值应该是一个2×1的向量，梯度向量的两个元素对应这里的两个偏导数项，运行这个costFunction 函数后，你就可以调用高级的优化函数，这个函数叫fminunc，它表示Octave 里无约束最小化函数。调用它的方式如下： options=optimset(&#39;GradObj&#39;,&#39;on&#39;,&#39;MaxIter&#39;,100); initialTheta=zeros(2,1); [optTheta, functionVal, exitFlag]=fminunc(@costFunction, initialTheta, options); 你要设置几个options，这个 options 变量作为一个数据结构可以存储你想要的options，所以 GradObj 和On，这里设置梯度目标参数为打开(on)，这意味着你现在确实要给这个算法提供一个梯度，然后设置最大迭代次数，比方说100，我们给出一个$\theta$ 的猜测初始值，它是一个2×1的向量，那么这个命令就调用fminunc，这个@符号表示指向我们刚刚定义的costFunction 函数的指针。如果你调用它，它就会使用众多高级优化算法中的一个，当然你也可以把它当成梯度下降，只不过它能自动选择学习速率$\alpha$，你不需要自己来做。然后它会尝试使用这些高级的优化算法，就像加强版的梯度下降法，为你找到最佳的${\theta}$值。 让我告诉你它在 Octave 里什么样： 所以我写了这个关于theta的 costFunction 函数，它计算出代价函数 jval以及梯度gradient，gradient 有两个元素，是代价函数对于theta(1) 和 theta(2)这两个参数的偏导数。 我希望你们从这个幻灯片中学到的主要内容是：写一个函数，它能返回代价函数值、梯度值，因此要把这个应用到逻辑回归，或者甚至线性回归中，你也可以把这些优化算法用于线性回归，你需要做的就是输入合适的代码来计算这里的这些东西。 现在你已经知道如何使用这些高级的优化算法，有了这些算法，你就可以使用一个复杂的优化库，它让算法使用起来更模糊一点。因此也许稍微有点难调试，不过由于这些算法的运行速度通常远远超过梯度下降。 所以当我有一个很大的机器学习问题时，我会选择这些高级算法，而不是梯度下降。有了这些概念，你就应该能将逻辑回归和线性回归应用于更大的问题中，这就是高级优化的概念。 在下一个视频，我想要告诉你如何修改你已经知道的逻辑回归算法，然后使它在多类别分类问题中也能正常运行。 多类别分类：一对多参考视频: 6 - 7 - Multiclass Classification_ One-vs-all (6 min).mkv 在本节视频中，我们将谈到如何使用逻辑回归 (logistic regression)来解决多类别分类问题，具体来说，我想通过一个叫做”一对多” (one-vs-all) 的分类算法。 先看这样一些例子。 第一个例子：假如说你现在需要一个学习算法能自动地将邮件归类到不同的文件夹里，或者说可以自动地加上标签，那么，你也许需要一些不同的文件夹，或者不同的标签来完成这件事，来区分开来自工作的邮件、来自朋友的邮件、来自家人的邮件或者是有关兴趣爱好的邮件，那么，我们就有了这样一个分类问题：其类别有四个，分别用$y=1$、$y=2$、$y=3$、$y=4$ 来代表。 第二个例子是有关药物诊断的，如果一个病人因为鼻塞来到你的诊所，他可能并没有生病，用 $y=1$ 这个类别来代表；或者患了感冒，用 $y=2$ 来代表；或者得了流感用$y=3$来代表。 第三个例子：如果你正在做有关天气的机器学习分类问题，那么你可能想要区分哪些天是晴天、多云、雨天、或者下雪天，对上述所有的例子，$y$ 可以取一个很小的数值，一个相对”谨慎”的数值，比如1 到3、1到4或者其它数值，以上说的都是多类分类问题，顺便一提的是，对于下标是0 1 2 3，还是 1 2 3 4 都不重要，我更喜欢将分类从 1 开始标而不是0，其实怎样标注都不会影响最后的结果。 然而对于之前的一个，二元分类问题，我们的数据看起来可能是像这样： 对于一个多类分类问题，我们的数据集或许看起来像这样： 我用3种不同的符号来代表3个类别，问题就是给出3个类型的数据集，我们如何得到一个学习算法来进行分类呢？ 我们现在已经知道如何进行二元分类，可以使用逻辑回归，对于直线或许你也知道，可以将数据集一分为二为正类和负类。用一对多的分类思想，我们可以将其用在多类分类问题上。 下面将介绍如何进行一对多的分类工作，有时这个方法也被称为”一对余”方法。 现在我们有一个训练集，好比上图表示的有3个类别，我们用三角形表示 $y=1$，方框表示$y=2$，叉叉表示 $y=3$。我们下面要做的就是使用一个训练集，将其分成3个二元分类问题。 我们先从用三角形代表的类别1开始，实际上我们可以创建一个，新的”伪”训练集，类型2和类型3定为负类，类型1设定为正类，我们创建一个新的训练集，如下图所示的那样，我们要拟合出一个合适的分类器。 这里的三角形是正样本，而圆形代表负样本。可以这样想，设置三角形的值为1，圆形的值为0，下面我们来训练一个标准的逻辑回归分类器，这样我们就得到一个正边界。 为了能实现这样的转变，我们将多个类中的一个类标记为正向类（$y=1$），然后将其他所有类都标记为负向类，这个模型记作$h_\theta^{\left( 1 \right)}\left( x \right)$。接着，类似地第我们选择另一个类标记为正向类（$y=2$），再将其它类都标记为负向类，将这个模型记作 $h_\theta^{\left( 2 \right)}\left( x \right)$,依此类推。最后我们得到一系列的模型简记为： $h_\theta^{\left( i \right)}\left( x \right)=p\left( y=i|x;\theta \right)$其中：$i=\left( 1,2,3....k \right)$ 最后，在我们需要做预测时，我们将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。 总之，我们已经把要做的做完了，现在要做的就是训练这个逻辑回归分类器：$h_\theta^{\left( i \right)}\left( x \right)$， 其中 $i$ 对应每一个可能的 $y=i$，最后，为了做出预测，我们给出输入一个新的 $x$ 值，用这个做预测。我们要做的就是在我们三个分类器里面输入 $x$，然后我们选择一个让 $h_\theta^{\left( i \right)}\left( x \right)$ 最大的$ i$，即$\mathop{\max}\limits_i\,h_\theta^{\left( i \right)}\left( x \right)$。 你现在知道了基本的挑选分类器的方法，选择出哪一个分类器是可信度最高效果最好的，那么就可认为得到一个正确的分类，无论$i$值是多少，我们都有最高的概率值，我们预测$y$就是那个值。这就是多类别分类问题，以及一对多的方法，通过这个小方法，你现在也可以将逻辑回归分类器用在多类分类的问题上。 正则化(Regularization)过拟合的问题参考视频: 7 - 1 - The Problem of Overfitting (10 min).mkv 到现在为止，我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到过拟合(over-fitting)的问题，可能会导致它们效果很差。 在这段视频中，我将为你解释什么是过度拟合问题，并且在此之后接下来的几个视频中，我们将谈论一种称为正则化(regularization)的技术，它可以改善或者减少过度拟合问题。 如果我们有非常多的特征，我们通过学习得到的假设可能能够非常好地适应训练集（代价函数可能几乎为0），但是可能会不能推广到新的数据。 下图是一个回归问题的例子： 第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：预测新数据。我们可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎最合适。 分类问题中也存在这样的问题： 就以多项式理解，$x$ 的次数越高，拟合的越好，但相应的预测的能力就可能变差。 问题是，如果我们发现了过拟合问题，应该如何处理？ 丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如PCA） 正则化。 保留所有的特征，但是减少参数的大小（magnitude）。 代价函数参考视频: 7 - 2 - Cost Function (10 min).mkv 上面的回归问题中如果我们的模型是： ${h_\theta}\left( x \right)={\theta_{0} }+{\theta_{1} }{x_{1} }+{\theta_{2} }{x_{2}^2}+{\theta_{3} }{x_{3}^3}+{\theta_{4} }{x_{4}^4}$ 我们可以从之前的事例中看出，正是那些高次项导致了过拟合的产生，所以如果我们能让这些高次项的系数接近于0的话，我们就能很好的拟合了。所以我们要做的就是在一定程度上减小这些参数$\theta $ 的值，这就是正则化的基本方法。我们决定要减少${\theta_{3} }$和${\theta_{4} }$的大小，我们要做的便是修改代价函数，在其中${\theta_{3} }$和${\theta_{4} }$ 设置一点惩罚。这样做的话，我们在尝试最小化代价时也需要将这个惩罚纳入考虑中，并最终导致选择较小一些的${\theta_{3} }$和${\theta_{4} }$。修改后的代价函数如下：$\underset{\theta }{\mathop{\min } }\,\frac{1}{2m}[\sum\limits_{i=1}^{m}{ {{\left( { {h}_{\theta } }\left( { {x}^{(i)} } \right)-{ {y}^{(i)} } \right)}^{2} }+1000\theta _{3}^{2}+10000\theta _{4}^{2}]}$ 通过这样的代价函数选择出的${\theta_{3} }$和${\theta_{4} }$ 对预测结果的影响就比之前要小许多。假如我们有非常多的特征，我们并不知道其中哪些特征我们要惩罚，我们将对所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设：$J\left( \theta \right)=\frac{1}{2m}[\sum\limits_{i=1}^{m}{ {{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })}^{2} }+\lambda \sum\limits_{j=1}^{n}{\theta_{j}^{2} }]}$ 其中$\lambda $又称为正则化参数（Regularization Parameter）。 注：根据惯例，我们不对${\theta_{0} }$ 进行惩罚。经过正则化处理的模型与原模型的可能对比如下图所示： 如果选择的正则化参数$\lambda$ 过大，则会把所有的参数都最小化了，导致模型变成 ${h_\theta}\left( x \right)={\theta_{0} }$，也就是上图中红色直线所示的情况，造成欠拟合。那为什么增加的一项$\lambda =\sum\limits_{j=1}^{n}{\theta_j^{2} }$ 可以使$\theta $的值减小呢？因为如果我们令 $\lambda$ 的值很大的话，为了使Cost Function 尽可能的小，所有的 $\theta $ 的值（不包括${\theta_{0} }$）都会在一定程度上减小。但若$\lambda$ 的值太大了，那么$\theta $（不包括${\theta_{0} }$）都会趋近于0，这样我们所得到的只能是一条平行于$x$轴的直线。所以对于正则化，我们要取一个合理的 $\lambda$ 的值，这样才能更好的应用正则化。回顾一下代价函数，为了使用正则化，让我们把这些概念应用到到线性回归和逻辑回归中去，那么我们就可以让他们避免过度拟合了。 正则化线性回归参考视频: 7 - 3 - Regularized Linear Regression (11 min).mkv 对于线性回归的求解，我们之前推导了两种学习算法：一种基于梯度下降，一种基于正规方程。 正则化线性回归的代价函数为： $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{[({ {({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })}^{2} }+\lambda \sum\limits_{j=1}^{n}{\theta _{j}^{2} })]}$ 如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对$\theta_0$进行正则化，所以梯度下降算法将分两种情形： $Repeat$ $until$ $convergence${ ​ ${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{0}^{(i)} })$ ​ ${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }+\frac{\lambda }{m}{\theta_j}]$ ​ $for$ $j=1,2,...n$ ​ } 对上面的算法中$ j=1,2,...,n$ 时的更新式子进行调整可得： ${\theta_j}:={\theta_j}(1-a\frac{\lambda }{m})-a\frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }$ 可以看出，正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令$\theta $值减少了一个额外的值。 我们同样也可以利用正规方程来求解正则化线性回归模型，方法如下所示： 图中的矩阵尺寸为 $(n+1)*(n+1)$。 正则化的逻辑回归模型参考视频: 7 - 4 - Regularized Logistic Regression (9 min).mkv 针对逻辑回归问题，我们在之前的课程已经学习过两种优化算法：我们首先学习了使用梯度下降法来优化代价函数$J\left( \theta \right)$，接下来学习了更高级的优化算法，这些高级优化算法需要你自己设计代价函数$J\left( \theta \right)$。 自己计算导数同样对于逻辑回归，我们也给代价函数增加一个正则化的表达式，得到代价函数： $J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{ {y}^{(i)} }\log \left( {h_\theta}\left( { {x}^{(i)} } \right) \right)-\left( 1-{ {y}^{(i)} } \right)\log \left( 1-{h_\theta}\left( { {x}^{(i)} } \right) \right)]}+\frac{\lambda }{2m}\sum\limits_{j=1}^{n}{\theta _{j}^{2} }$ Python代码： import numpy as np def costReg(theta, X, y, learningRate): theta = np.matrix(theta) X = np.matrix(X) y = np.matrix(y) first = np.multiply(-y, np.log(sigmoid(X*theta.T))) second = np.multiply((1 - y), np.log(1 - sigmoid(X*theta.T))) reg = (learningRate / (2 * len(X))* np.sum(np.power(theta[:,1:theta.shape[1]],2)) return np.sum(first - second) / (len(X)) + reg 要最小化该代价函数，通过求导，得出梯度下降算法为： $Repeat$ $until$ $convergence${ ​ ${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{0}^{(i)} })$ ​ ${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({ {x}^{(i)} })-{ {y}^{(i)} })x_{j}^{\left( i \right)} }+\frac{\lambda }{m}{\theta_j}]$ ​ $for$ $j=1,2,...n$ ​ } 注：看上去同线性回归一样，但是知道 ${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$，所以与线性回归不同。Octave 中，我们依旧可以用 fminuc 函数来求解代价函数最小化的参数，值得注意的是参数${\theta_{0} }$的更新规则与其他情况不同。注意： 虽然正则化的逻辑回归中的梯度下降和正则化的线性回归中的表达式看起来一样，但由于两者的${h_\theta}\left( x \right)$不同所以还是有很大差别。 ${\theta_{0} }$不参与其中的任何一个正则化。 目前大家对机器学习算法可能还只是略懂，但是一旦你精通了线性回归、高级优化算法和正则化技术，坦率地说，你对机器学习的理解可能已经比许多工程师深入了。现在，你已经有了丰富的机器学习知识，目测比那些硅谷工程师还厉害，或者用机器学习算法来做产品。 接下来的课程中，我们将学习一个非常强大的非线性分类器，无论是线性回归问题，还是逻辑回归问题，都可以构造多项式来解决。你将逐渐发现还有更强大的非线性分类器，可以用来解决多项式回归问题。我们接下来将将学会，比现在解决问题的方法强大N倍的学习算法。 神经网络：表述(Neural Networks: Representation)非线性假设参考视频: 8 - 1 - Non-linear Hypotheses (10 min).mkv 我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。 下面是一个例子： 当我们使用$x_1$, $x_2$ 的多次项式进行预测时，我们可以应用的很好。之前我们已经看到过，使用非线性的多项式项，能够帮助我们建立更好的分类模型。假设我们有非常多的特征，例如大于100个变量，我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合$(x_1x_2+x_1x_3+x_1x_4+...+x_2x_3+x_2x_4+...+x_{99}x_{100})$，我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。 假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车），我们怎样才能这么做呢？一种方法是我们利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。 假如我们只选用灰度图片，每个像素则只有一个值（而非 RGB值），我们可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车： 假使我们采用的都是50x50像素的小图片，并且我们将所有的像素视为特征，则会有 2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约${ {2500}^{2} }/2$个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们需要神经网络。 神经元和大脑参考视频: 8 - 2 - Neurons and the Brain (8 min).mkv 神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。 在这门课中，我将向你们介绍神经网络。因为它能很好地解决不同的机器学习问题。而不只因为它们在逻辑上行得通，在这段视频中，我想告诉你们一些神经网络的背景知识，由此我们能知道可以用它们来做什么。不管是将其应用到现代的机器学习问题上，还是应用到那些你可能会感兴趣的问题中。也许，这一伟大的人工智能梦想在未来能制造出真正的智能机器。另外，我们还将讲解神经网络是怎么涉及这些问题的神经网络产生的原因是人们想尝试设计出模仿大脑的算法，从某种意义上说如果我们想要建立学习系统，那为什么不去模仿我们所认识的最神奇的学习机器——人类的大脑呢？ 神经网络逐渐兴起于二十世纪八九十年代，应用得非常广泛。但由于各种原因，在90年代的后期应用减少了。但是最近，神经网络又东山再起了。其中一个原因是：神经网络是计算量有些偏大的算法。然而大概由于近些年计算机的运行速度变快，才足以真正运行起大规模的神经网络。正是由于这个原因和其他一些我们后面会讨论到的技术因素，如今的神经网络对于许多应用来说是最先进的技术。当你想模拟大脑时，是指想制造出与人类大脑作用效果相同的机器。大脑可以学会去以看而不是听的方式处理图像，学会处理我们的触觉。 我们能学习数学，学着做微积分，而且大脑能处理各种不同的令人惊奇的事情。似乎如果你想要模仿它，你得写很多不同的软件来模拟所有这些五花八门的奇妙的事情。不过能不能假设大脑做所有这些，不同事情的方法，不需要用上千个不同的程序去实现。相反的，大脑处理的方法，只需要一个单一的学习算法就可以了？尽管这只是一个假设，不过让我和你分享，一些这方面的证据。 大脑的这一部分这一小片红色区域是你的听觉皮层，你现在正在理解我的话，这靠的是耳朵。耳朵接收到声音信号，并把声音信号传递给你的听觉皮层，正因如此，你才能明白我的话。 神经系统科学家做了下面这个有趣的实验，把耳朵到听觉皮层的神经切断。在这种情况下，将其重新接到一个动物的大脑上，这样从眼睛到视神经的信号最终将传到听觉皮层。如果这样做了。那么结果表明听觉皮层将会学会“看”。这里的“看”代表了我们所知道的每层含义。所以，如果你对动物这样做，那么动物就可以完成视觉辨别任务，它们可以看图像，并根据图像做出适当的决定。它们正是通过脑组织中的这个部分完成的。下面再举另一个例子，这块红色的脑组织是你的躯体感觉皮层，这是你用来处理触觉的，如果你做一个和刚才类似的重接实验，那么躯体感觉皮层也能学会“看”。这个实验和其它一些类似的实验，被称为神经重接实验，从这个意义上说，如果人体有同一块脑组织可以处理光、声或触觉信号，那么也许存在一种学习算法，可以同时处理视觉、听觉和触觉，而不是需要运行上千个不同的程序，或者上千个不同的算法来做这些大脑所完成的成千上万的美好事情。也许我们需要做的就是找出一些近似的或实际的大脑学习算法，然后实现它大脑通过自学掌握如何处理这些不同类型的数据。在很大的程度上，可以猜想如果我们把几乎任何一种传感器接入到大脑的几乎任何一个部位的话，大脑就会学会处理它。 下面再举几个例子： 这张图是用舌头学会“看”的一个例子。它的原理是：这实际上是一个名为BrainPort的系统，它现在正在FDA(美国食品和药物管理局)的临床试验阶段，它能帮助失明人士看见事物。它的原理是，你在前额上带一个灰度摄像头，面朝前，它就能获取你面前事物的低分辨率的灰度图像。你连一根线到舌头上安装的电极阵列上，那么每个像素都被映射到你舌头的某个位置上，可能电压值高的点对应一个暗像素电压值低的点。对应于亮像素，即使依靠它现在的功能，使用这种系统就能让你我在几十分钟里就学会用我们的舌头“看”东西。 这是第二个例子，关于人体回声定位或者说人体声纳。你有两种方法可以实现：你可以弹响指，或者咂舌头。不过现在有失明人士，确实在学校里接受这样的培训，并学会解读从环境反弹回来的声波模式—这就是声纳。如果你搜索YouTube之后，就会发现有些视频讲述了一个令人称奇的孩子，他因为癌症眼球惨遭移除，虽然失去了眼球，但是通过打响指，他可以四处走动而不撞到任何东西，他能滑滑板，他可以将篮球投入篮框中。注意这是一个没有眼球的孩子。 第三个例子是触觉皮带，如果你把它戴在腰上，蜂鸣器会响，而且总是朝向北时发出嗡嗡声。它可以使人拥有方向感，用类似于鸟类感知方向的方式。 还有一些离奇的例子： 如果你在青蛙身上插入第三只眼，青蛙也能学会使用那只眼睛。因此，这将会非常令人惊奇。如果你能把几乎任何传感器接入到大脑中，大脑的学习算法就能找出学习数据的方法，并处理这些数据。从某种意义上来说，如果我们能找出大脑的学习算法，然后在计算机上执行大脑学习算法或与之相似的算法，也许这将是我们向人工智能迈进做出的最好的尝试。人工智能的梦想就是：有一天能制造出真正的智能机器。 神经网络可能为我们打开一扇进入遥远的人工智能梦的窗户，但我在这节课中讲授神经网络的原因，主要是对于现代机器学习应用。它是最有效的技术方法。因此在接下来的一些课程中，我们将开始深入到神经网络的技术细节。 模型表示1参考视频: 8 - 3 - Model Representation I (12 min).mkv 为了构建神经网络模型，我们需要首先思考大脑中的神经网络是怎样的？每一个神经元都可以被认为是一个处理单元/神经核（processing unit/Nucleus），它含有许多输入/树突（input/Dendrite），并且有一个输出/轴突（output/Axon）。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。 下面是一组神经元的示意图，神经元利用微弱的电流进行沟通。这些弱电流也称作动作电位，其实就是一些微弱的电流。所以如果神经元想要传递一个消息，它就会就通过它的轴突，发送一段微弱电流给其他神经元，这就是轴突。 这里是一条连接到输入神经，或者连接另一个神经元树突的神经，接下来这个神经元接收这条消息，做一些计算，它有可能会反过来将在轴突上的自己的消息传给其他神经元。这就是所有人类思考的模型：我们的神经元把自己的收到的消息进行计算，并向其他神经元传递消息。这也是我们的感觉和肌肉运转的原理。如果你想活动一块肌肉，就会触发一个神经元给你的肌肉发送脉冲，并引起你的肌肉收缩。如果一些感官：比如说眼睛想要给大脑传递一个消息，那么它就像这样发送电脉冲给大脑的。 神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，activation unit）采纳一些特征作为输出，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，参数又可被成为权重（weight）。 我们设计出了类似于神经元的神经网络，效果如下： 其中$x_1$, $x_2$, $x_3$是输入单元（input units），我们将原始数据输入给它们。 $a_1$, $a_2$, $a_3$是中间单元，它们负责将数据进行处理，然后呈递到下一层。 最后是输出单元，它负责计算${h_\theta}\left( x \right)$。 神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个3层的神经网络，第一层成为输入层（Input Layer），最后一层称为输出层（Output Layer），中间一层成为隐藏层（Hidden Layers）。我们为每一层都增加一个偏差单位（bias unit）： 下面引入一些标记法来帮助描述模型： $a_{i}^{\left( j \right)}$ 代表第$j$ 层的第 $i$ 个激活单元。${ {\theta }^{\left( j \right)} }$代表从第 $j$ 层映射到第$ j+1$ 层时的权重的矩阵，例如${ {\theta }^{\left( 1 \right)} }$代表从第一层映射到第二层的权重的矩阵。其尺寸为：以第 $j+1$层的激活单元数量为行数，以第 $j$ 层的激活单元数加一为列数的矩阵。例如：上图所示的神经网络中${ {\theta }^{\left( 1 \right)} }$的尺寸为 3*4。 对于上图所示的模型，激活单元和输出分别表达为： $a_{1}^{(2)}=g(\Theta _{10}^{(1)}{ {x}_{0} }+\Theta _{11}^{(1)}{ {x}_{1} }+\Theta _{12}^{(1)}{ {x}_{2} }+\Theta _{13}^{(1)}{ {x}_{3} })$ $a_{2}^{(2)}=g(\Theta _{20}^{(1)}{ {x}_{0} }+\Theta _{21}^{(1)}{ {x}_{1} }+\Theta _{22}^{(1)}{ {x}_{2} }+\Theta _{23}^{(1)}{ {x}_{3} })$ $a_{3}^{(2)}=g(\Theta _{30}^{(1)}{ {x}_{0} }+\Theta _{31}^{(1)}{ {x}_{1} }+\Theta _{32}^{(1)}{ {x}_{2} }+\Theta _{33}^{(1)}{ {x}_{3} })$ ${ {h}_{\Theta } }(x)=g(\Theta _{10}^{(2)}a_{0}^{(2)}+\Theta _{11}^{(2)}a_{1}^{(2)}+\Theta _{12}^{(2)}a_{2}^{(2)}+\Theta _{13}^{(2)}a_{3}^{(2)})$ 上面进行的讨论中只是将特征矩阵中的一行（一个训练实例）喂给了神经网络，我们需要将整个训练集都喂给我们的神经网络算法来学习模型。 我们可以知道：每一个$a$都是由上一层所有的$x$和每一个$x$所对应的决定的。 （我们把这样从左到右的算法称为前向传播算法( FORWARD PROPAGATION )） 把$x$, $\theta$, $a$ 分别用矩阵表示： 我们可以得到$\theta \cdot X=a$ 。 模型表示2参考视频: 8 - 4 - Model Representation II (12 min).mkv ( FORWARD PROPAGATION )相对于使用循环来编码，利用向量化的方法会使得计算更为简便。以上面的神经网络为例，试着计算第二层的值： 我们令 ${ {z}^{\left( 2 \right)} }={ {\theta }^{\left( 1 \right)} }x$，则 ${ {a}^{\left( 2 \right)} }=g({ {z}^{\left( 2 \right)} })$ ，计算后添加 $a_{0}^{\left( 2 \right)}=1$。 计算输出的值为： 我们令 ${ {z}^{\left( 3 \right)} }={ {\theta }^{\left( 2 \right)} }{ {a}^{\left( 2 \right)} }$，则 $h_\theta(x)={ {a}^{\left( 3 \right)} }=g({ {z}^{\left( 3 \right)} })$。这只是针对训练集中一个训练实例所进行的计算。如果我们要对整个训练集进行计算，我们需要将训练集特征矩阵进行转置，使得同一个实例的特征都在同一列里。即： ${ {z}^{\left( 2 \right)} }={ {\Theta }^{\left( 1 \right)} }\times { {X}^{T} } $ ${ {a}^{\left( 2 \right)} }=g({ {z}^{\left( 2 \right)} })$ 为了更好了了解Neuron Networks的工作原理，我们先把左半部分遮住： 右半部分其实就是以$a_0, a_1, a_2, a_3$, 按照Logistic Regression的方式输出$h_\theta(x)$： 其实神经网络就像是logistic regression，只不过我们把logistic regression中的输入向量$\left[ x_1\sim {x_3} \right]$ 变成了中间层的$\left[ a_1^{(2)}\sim a_3^{(2)} \right]$, 即: $h_\theta(x)=g\left( \Theta_0^{\left( 2 \right)}a_0^{\left( 2 \right)}+\Theta_1^{\left( 2 \right)}a_1^{\left( 2 \right)}+\Theta_{2}^{\left( 2 \right)}a_{2}^{\left( 2 \right)}+\Theta_{3}^{\left( 2 \right)}a_{3}^{\left( 2 \right)} \right)$我们可以把$a_0, a_1, a_2, a_3$看成更为高级的特征值，也就是$x_0, x_1, x_2, x_3$的进化体，并且它们是由 $x$与$\theta$决定的，因为是梯度下降的，所以$a$是变化的，并且变得越来越厉害，所以这些更高级的特征值远比仅仅将 $x$次方厉害，也能更好的预测新数据。这就是神经网络相比于逻辑回归和线性回归的优势。 特征和直观理解1参考视频: 8 - 5 - Examples and Intuitions I (7 min).mkv 从本质上讲，神经网络能够通过学习得出其自身的一系列特征。在普通的逻辑回归中，我们被限制为使用数据中的原始特征$x_1,x_2,...,{ {x}_{n} }$，我们虽然可以使用一些二项式项来组合这些特征，但是我们仍然受到这些原始特征的限制。在神经网络中，原始特征只是输入层，在我们上面三层的神经网络例子中，第三层也就是输出层做出的预测利用的是第二层的特征，而非输入层中的原始特征，我们可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输出变量的新特征。 神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑与(AND)、逻辑或(OR)。 举例说明：逻辑与(AND)；下图中左半部分是神经网络的设计与output层表达式，右边上部分是sigmod函数，下半部分是真值表。 我们可以用这样的一个神经网络表示AND 函数： 其中$\theta_0 = -30, \theta_1 = 20, \theta_2 = 20$我们的输出函数$h_\theta(x)$即为：$h_\Theta(x)=g\left( -30+20x_1+20x_2 \right)$ 我们知道$g(x)$的图像是： 所以我们有：$h_\Theta(x) \approx \text{x}_1 \text{AND} \, \text{x}_2$ 所以我们的：$h_\Theta(x) $ 这就是AND函数。 接下来再介绍一个OR函数： OR与AND整体一样，区别只在于的取值不同。 样本和直观理解II参考视频: 8 - 6 - Examples and Intuitions II (10 min).mkv 二元逻辑运算符（BINARY LOGICAL OPERATORS）当输入特征为布尔值（0或1）时，我们可以用一个单一的激活层可以作为二元逻辑运算符，为了表示不同的运算符，我们只需要选择不同的权重即可。 下图的神经元（三个权重分别为-30，20，20）可以被视为作用同于逻辑与（AND）： 下图的神经元（三个权重分别为-10，20，20）可以被视为作用等同于逻辑或（OR）： 下图的神经元（两个权重分别为 10，-20）可以被视为作用等同于逻辑非（NOT）： 我们可以利用神经元来组合成更为复杂的神经网络以实现更复杂的运算。例如我们要实现XNOR 功能（输入的两个值必须一样，均为1或均为0），即 $\text{XNOR}=( \text{x}_1\, \text{AND}\, \text{x}_2 )\, \text{OR} \left( \left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right) \right)$首先构造一个能表达$\left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right)$部分的神经元： 然后将表示 AND 的神经元和表示$\left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right)$的神经元以及表示 OR 的神经元进行组合： 我们就得到了一个能实现 $\text{XNOR}$ 运算符功能的神经网络。 按这种方法我们可以逐渐构造出越来越复杂的函数，也能得到更加厉害的特征值。 这就是神经网络的厉害之处。 多类分类参考视频: 8 - 7 - Multiclass Classification (4 min).mkv 当我们有不止两种分类时（也就是$y=1,2,3….$），比如以下这种情况，该怎么办？如果我们要训练一个神经网络算法来识别路人、汽车、摩托车和卡车，在输出层我们应该有4个值。例如，第一个值为1或0用于预测是否是行人，第二个值用于判断是否为汽车。 输入向量$x$有三个维度，两个中间层，输出层4个神经元分别用来表示4类，也就是每一个数据在输出层都会出现${ {\left[ a\text{ }b\text{ }c\text{ }d \right]}^{T} }$，且$a,b,c,d$中仅有一个为1，表示当前类。下面是该神经网络的可能结构示例： 神经网络算法的输出结果为四种可能情形之一： 神经网络的学习(Neural Networks: Learning)代价函数参考视频: 9 - 1 - Cost Function (7 min).mkv 首先引入一些便于稍后讨论的新标记方法： 假设神经网络的训练样本有$m$个，每个包含一组输入$x$和一组输出信号$y$，$L$表示神经网络层数，$S_I$表示每层的neuron个数($S_l$表示输出层神经元个数)，$S_L$代表最后一层中处理单元的个数。 将神经网络的分类定义为两种情况：二类分类和多类分类， 二类分类：$S_L=0, y=0\, or\, 1$表示哪一类； $K$类分类：$S_L=k, y_i = 1$表示分到第$i$类；$(k>2)$ 我们回顾逻辑回归问题中我们的代价函数为： $ J\left(\theta \right)=-\frac{1}{m}\left[\sum_\limits{i=1}^{m}{y}^{(i)}\log{h_\theta({x}^{(i)})}+\left(1-{y}^{(i)}\right)log\left(1-h_\theta\left({x}^{(i)}\right)\right)\right]+\frac{\lambda}{2m}\sum_\limits{j=1}^{n}{\theta_j}^{2} $ 在逻辑回归中，我们只有一个输出变量，又称标量（scalar），也只有一个因变量$y$，但是在神经网络中，我们可以有很多输出变量，我们的$h_\theta(x)$是一个维度为$K$的向量，并且我们训练集中的因变量也是同样维度的一个向量，因此我们的代价函数会比逻辑回归更加复杂一些，为：$\newcommand{\subk}[1]{ #1_k }$ $$h_\theta\left(x\right)\in \mathbb{R}^{K}$$ $${\left({h_\theta}\left(x\right)\right)}_{i}={i}^{th} \text{output}$$ $J(\Theta) = -\frac{1}{m} \left[ \sum\limits_{i=1}^{m} \sum\limits_{k=1}^{k} {y_k}^{(i)} \log \subk{(h_\Theta(x^{(i)}))} + \left( 1 - y_k^{(i)} \right) \log \left( 1- \subk{\left( h_\Theta \left( x^{(i)} \right) \right)} \right) \right] + \frac{\lambda}{2m} \sum\limits_{l=1}^{L-1} \sum\limits_{i=1}^{s_l} \sum\limits_{j=1}^{s_{l+1} } \left( \Theta_{ji}^{(l)} \right)^2$ 这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出$K$个预测，基本上我们可以利用循环，对每一行特征都预测$K$个不同结果，然后在利用循环在$K$个预测中选择可能性最高的一个，将其与$y$中的实际数据进行比较。 正则化的那一项只是排除了每一层$\theta_0$后，每一层的$\theta$ 矩阵的和。最里层的循环$j$循环所有的行（由$s_{l+1}$ 层的激活单元数决定），循环$i$则循环所有的列，由该层（$s_l$层）的激活单元数所决定。即：$h_\theta(x)$与真实值之间的距离为每个样本-每个类输出的加和，对参数进行regularization的bias项处理所有参数的平方和。 反向传播算法参考视频: 9 - 2 - Backpropagation Algorithm (12 min).mkv 之前我们在计算神经网络预测结果的时候我们采用了一种正向传播方法，我们从第一层开始正向一层一层进行计算，直到最后一层的$h_{\theta}\left(x\right)$。 现在，为了计算代价函数的偏导数$\frac{\partial}{\partial\Theta^{(l)}_{ij} }J\left(\Theta\right)$，我们需要采用一种反向传播算法，也就是首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。以一个例子来说明反向传播算法。 假设我们的训练集只有一个样本$\left({x}^{(1)},{y}^{(1)}\right)$，我们的神经网络是一个四层的神经网络，其中$K=4，S_{L}=4，L=4$： 前向传播算法： 下面的公式推导过程见：&lt;https://blog.csdn.net/qq_29762941/article/details/80343185&gt; 我们从最后一层的误差开始计算，误差是激活单元的预测（${a^{(4)} }$）与实际值（$y^k$）之间的误差，（$k=1:k$）。我们用$\delta$来表示误差，则：$\delta^{(4)}=a^{(4)}-y$我们利用这个误差值来计算前一层的误差：$\delta^{(3)}=\left({\Theta^{(3)} }\right)^{T}\delta^{(4)}\ast g'\left(z^{(3)}\right)$其中 $g'(z^{(3)})$是 $S$ 形函数的导数，$g'(z^{(3)})=a^{(3)}\ast(1-a^{(3)})$。而$(θ^{(3)})^{T}\delta^{(4)}$则是权重导致的误差的和。下一步是继续计算第二层的误差： $ \delta^{(2)}=(\Theta^{(2)})^{T}\delta^{(3)}\ast g'(z^{(2)})$ 因为第一层是输入变量，不存在误差。我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设$λ=0$，即我们不做任何正则化处理时有： $\frac{\partial}{\partial\Theta_{ij}^{(l)} }J(\Theta)=a_{j}^{(l)} \delta_{i}^{l+1}$ 重要的是清楚地知道上面式子中上下标的含义： $l$ 代表目前所计算的是第几层。 $j$ 代表目前计算层中的激活单元的下标，也将是下一层的第$j$个输入变量的下标。 $i$ 代表下一层中误差单元的下标，是受到权重矩阵中第$i$行影响的下一层中的误差单元的下标。 如果我们考虑正则化处理，并且我们的训练集是一个特征矩阵而非向量。在上面的特殊情况中，我们需要计算每一层的误差单元来计算代价函数的偏导数。在更为一般的情况中，我们同样需要计算每一层的误差单元，但是我们需要为整个训练集计算误差单元，此时的误差单元也是一个矩阵，我们用$\Delta^{(l)}_{ij}$来表示这个误差矩阵。第 $l$ 层的第 $i$ 个激活单元受到第 $j$ 个参数影响而导致的误差。 我们的算法表示为： 即首先用正向传播方法计算出每一层的激活单元，利用训练集的结果与神经网络预测的结果求出最后一层的误差，然后利用该误差运用反向传播法计算出直至第二层的所有误差。 在求出了$\Delta_{ij}^{(l)}$之后，我们便可以计算代价函数的偏导数了，计算方法如下： $ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)}$ ${if}\; j \neq 0$ $ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}$ ${if}\; j = 0$ 在Octave 中，如果我们要使用 fminuc这样的优化算法来求解求出权重矩阵，我们需要将矩阵首先展开成为向量，在利用算法求出最优解后再重新转换回矩阵。 假设我们有三个权重矩阵，Theta1，Theta2 和 Theta3，尺寸分别为 10*11，10*11 和1*11，下面的代码可以实现这样的转换： thetaVec = [Theta1(:) ; Theta2(:) ; Theta3(:)] ...optimization using functions like fminuc... Theta1 = reshape(thetaVec(1:110, 10, 11); Theta2 = reshape(thetaVec(111:220, 10, 11); Theta1 = reshape(thetaVec(221:231, 1, 11);反向传播算法的直观理解参考视频: 9 - 3 - Backpropagation Intuition (13 min).mkv 在上一段视频中，我们介绍了反向传播算法，对很多人来说，当第一次看到这种算法时，第一印象通常是，这个算法需要那么多繁杂的步骤，简直是太复杂了，实在不知道这些步骤，到底应该如何合在一起使用。就好像一个黑箱，里面充满了复杂的步骤。如果你对反向传播算法也有这种感受的话，这其实是正常的，相比于线性回归算法和逻辑回归算法而言，从数学的角度上讲，反向传播算法似乎并不简洁，对于反向传播这种算法，其实我已经使用了很多年了，但即便如此，即使是现在，我也经常感觉自己对反向传播算法的理解并不是十分深入，对于反向传播算法究竟是如何执行的，并没有一个很直观的理解。做过编程练习的同学应该可以感受到这些练习或多或少能帮助你，将这些复杂的步骤梳理了一遍，巩固了反向传播算法具体是如何实现的，这样你才能自己掌握这种算法。 在这段视频中，我想更加深入地讨论一下反向传播算法的这些复杂的步骤，并且希望给你一个更加全面直观的感受，理解这些步骤究竟是在做什么，也希望通过这段视频，你能理解，它至少还是一个合理的算法。但可能你即使看了这段视频，你还是觉得反向传播依然很复杂，依然像一个黑箱，太多复杂的步骤，依然感到有点神奇，这也是没关系的。即使是我接触反向传播这么多年了，有时候仍然觉得这是一个难以理解的算法，但还是希望这段视频能有些许帮助，为了更好地理解反向传播算法，我们再来仔细研究一下前向传播的原理： 前向传播算法： 反向传播算法做的是： 感悟：上图中的 $\delta^{(l)}_{j}="error" \ of cost \ for \ a^{(l)}_{j} \ (unit \ j \ in \ layer \ l)$ 理解如下： $\delta^{(l)}_{j}$ 相当于是第 $l$ 层的第 $j$ 单元中得到的激活项的“误差”，即”正确“的 $a^{(l)}_{j}$ 与计算得到的 $a^{(l)}_{j}$ 的差。 而 $a^{(l)}_{j}=g(z^{(l)})$ ，（g为sigmoid函数）。我们可以想象 $\delta^{(l)}_{j}$ 为函数求导时迈出的那一丁点微分，所以更准确的说 $\delta^{(l)}_{j}=\frac{\partial}{\partial z^{(l)}_{j} }cost(i)$ 实现注意：展开参数参考视频: 9 - 4 - Implementation Note_ Unrolling Parameters (8 min).mkv 在上一段视频中，我们谈到了怎样使用反向传播算法计算代价函数的导数。在这段视频中，我想快速地向你介绍一个细节的实现过程，怎样把你的参数从矩阵展开成向量，以便我们在高级最优化步骤中的使用需要。 梯度检验参考视频: 9 - 5 - Gradient Checking (12 min).mkv 当我们对一个较为复杂的模型（例如神经网络）使用梯度下降算法时，可能会存在一些不容易察觉的错误，意味着，虽然代价看上去在不断减小，但最终的结果可能并不是最优解。 为了避免这样的问题，我们采取一种叫做梯度的数值检验（Numerical Gradient Checking）方法。这种方法的思想是通过估计梯度值来检验我们计算的导数值是否真的是我们要求的。 对梯度的估计采用的方法是在代价函数上沿着切线的方向选择离两个非常近的点然后计算两个点的平均值用以估计梯度。即对于某个特定的 $\theta$，我们计算出在 $\theta$-$\varepsilon $ 处和 $\theta$+$\varepsilon $ 的代价值（$\varepsilon $是一个非常小的值，通常选取 0.001），然后求两个代价的平均，用以估计在 $\theta$ 处的代价值。 Octave 中代码如下： gradApprox = (J(theta + eps) – J(theta - eps)) / (2*eps) 当$\theta$是一个向量时，我们则需要对偏导数进行检验。因为代价函数的偏导数检验只针对一个参数的改变进行检验，下面是一个只针对$\theta_1$进行检验的示例： $$ \frac{\partial}{\partial\theta_1}=\frac{J\left(\theta_1+\varepsilon_1,\theta_2,\theta_3...\theta_n \right)-J \left( \theta_1-\varepsilon_1,\theta_2,\theta_3...\theta_n \right)}{2\varepsilon} $$ 最后我们还需要对通过反向传播方法计算出的偏导数进行检验。 根据上面的算法，计算出的偏导数存储在矩阵 $D_{ij}^{(l)}$ 中。检验时，我们要将该矩阵展开成为向量，同时我们也将 $\theta$ 矩阵展开为向量，我们针对每一个 $\theta$ 都计算一个近似的梯度值，将这些值存储于一个近似梯度矩阵中，最终将得出的这个矩阵同 $D_{ij}^{(l)}$ 进行比较。 随机初始化参考视频: 9 - 6 - Random Initialization (7 min).mkv 任何优化算法都需要一些初始的参数。到目前为止我们都是初始所有参数为0，这样的初始方法对于逻辑回归来说是可行的，但是对于神经网络来说是不可行的。如果我们令所有的初始参数都为0，这将意味着我们第二层的所有激活单元都会有相同的值。同理，如果我们初始所有的参数都为一个非0的数，结果也是一样的。 我们通常初始参数为正负ε之间的随机值，假设我们要随机初始一个尺寸为10×11的参数矩阵，代码如下： Theta1 = rand(10, 11) * (2*eps) – eps 综合起来参考视频: 9 - 7 - Putting It Together (14 min).mkv 小结一下使用神经网络时的步骤： 网络结构：第一件要做的事是选择网络结构，即决定选择多少层以及决定每层分别有多少个单元。 第一层的单元数即我们训练集的特征数量。 最后一层的单元数是我们训练集的结果的类的数量。 如果隐藏层数大于1，确保每个隐藏层的单元个数相同，通常情况下隐藏层单元的个数越多越好。 我们真正要决定的是隐藏层的层数和每个中间层的单元数。 训练神经网络： 参数的随机初始化 利用正向传播方法计算所有的$h_{\theta}(x)$ 编写计算代价函数 $J$ 的代码 利用反向传播方法计算所有偏导数 利用数值检验方法检验这些偏导数 使用优化算法来最小化代价函数 自主驾驶参考视频: 9 - 8 - Autonomous Driving (7 min).mkv 在这段视频中，我想向你介绍一个具有历史意义的神经网络学习的重要例子。那就是使用神经网络来实现自动驾驶，也就是说使汽车通过学习来自己驾驶。接下来我将演示的这段视频是我从 Dean Pomerleau那里拿到的，他是我的同事，任职于美国东海岸的卡耐基梅隆大学。在这部分视频中，你就会明白可视化技术到底是什么？在看这段视频之前，我会告诉你可视化技术是什么。 在下面也就是左下方，就是汽车所看到的前方的路况图像。 在图中你依稀能看出一条道路，朝左延伸了一点，又向右了一点，然后上面的这幅图，你可以看到一条水平的菜单栏显示的是驾驶操作人选择的方向。就是这里的这条白亮的区段显示的就是人类驾驶者选择的方向。比如：最左边的区段，对应的操作就是向左急转，而最右端则对应向右急转的操作。因此，稍微靠左的区段，也就是中心稍微向左一点的位置，则表示在这一点上人类驾驶者的操作是慢慢的向左拐。 这幅图的第二部分对应的就是学习算法选出的行驶方向。并且，类似的，这一条白亮的区段显示的就是神经网络在这里选择的行驶方向，是稍微的左转，并且实际上在神经网络开始学习之前，你会看到网络的输出是一条灰色的区段，就像这样的一条灰色区段覆盖着整个区域这些均称的灰色区域，显示出神经网络已经随机初始化了，并且初始化时，我们并不知道汽车如何行驶，或者说我们并不知道所选行驶方向。只有在学习算法运行了足够长的时间之后，才会有这条白色的区段出现在整条灰色区域之中。显示出一个具体的行驶方向这就表示神经网络算法，在这时候已经选出了一个明确的行驶方向，不像刚开始的时候，输出一段模糊的浅灰色区域，而是输出一条白亮的区段，表示已经选出了明确的行驶方向。 ALVINN (Autonomous Land Vehicle In a Neural Network)是一个基于神经网络的智能系统，通过观察人类的驾驶来学习驾驶，ALVINN能够控制NavLab，装在一辆改装版军用悍马，这辆悍马装载了传感器、计算机和驱动器用来进行自动驾驶的导航试验。实现ALVINN功能的第一步，是对它进行训练，也就是训练一个人驾驶汽车。 然后让ALVINN观看，ALVINN每两秒将前方的路况图生成一张数字化图片，并且记录驾驶者的驾驶方向，得到的训练集图片被压缩为30x32像素，并且作为输入提供给ALVINN的三层神经网络，通过使用反向传播学习算法，ALVINN会训练得到一个与人类驾驶员操纵方向基本相近的结果。一开始，我们的网络选择出的方向是随机的，大约经过两分钟的训练后，我们的神经网络便能够准确地模拟人类驾驶者的驾驶方向，对其他道路类型，也重复进行这个训练过程，当网络被训练完成后，操作者就可按下运行按钮，车辆便开始行驶了。 每秒钟ALVINN生成12次数字化图片，并且将图像传送给神经网络进行训练，多个神经网络同时工作，每一个网络都生成一个行驶方向，以及一个预测自信度的参数，预测自信度最高的那个神经网络得到的行驶方向。比如这里，在这条单行道上训练出的网络将被最终用于控制车辆方向，车辆前方突然出现了一个交叉十字路口，当车辆到达这个十字路口时，我们单行道网络对应的自信度骤减，当它穿过这个十字路口时，前方的双车道将进入其视线，双车道网络的自信度便开始上升，当它的自信度上升时，双车道的网络，将被选择来控制行驶方向，车辆将被安全地引导进入双车道路。 这就是基于神经网络的自动驾驶技术。当然，我们还有很多更加先进的试验来实现自动驾驶技术。在美国，欧洲等一些国家和地区，他们提供了一些比这个方法更加稳定的驾驶控制技术。但我认为，使用这样一个简单的基于反向传播的神经网络，训练出如此强大的自动驾驶汽车，的确是一次令人惊讶的成就。]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nlp基本概念及算法]]></title>
    <url>%2F2019%2F11%2F25%2Fnlp%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[整理的一些基本算法及概念 算法复杂度 分词最大前向匹配 最大后向匹配 依赖于词典，不能做词细分 局部最优（属于贪心算法） 效率不高（取决于max_length） 有歧义（不能考虑语义）unigram lmViterbi算法(DP算法)输入句子-&gt;生成所有可能的分割-&gt;利用语言模型，选择其中最好的，分词方法分两步进行（分割-&gt;计算unigram概率），时间复杂度很高编辑距离拼写纠错距离相似度欧式距离：d = |s1-s2|余弦相似度：d=s1s2/(∣s1∣∣s2∣) d(s1,s2)=0缺点: 只从出现频率来表示单词/句子，距离计算时，频次高的单词对结果影响较大，实际的语义分析时，并不是出现频率越高就越重要 BOW词袋模型假设我们不考虑文本中词与词之间的上下文关系，仅仅只考虑所有词的权重。而权重与词在文本中出现的频率有关。 one-hot表示单词 词典：[我们，去，爬山，今天，你们，昨天，跑步]按照单词在词典库中的顺序我们：(1,0,0,0,0,0,0)-&gt;7维=|词典|爬山：(0,0,1,0,0,0,0)跑步：(0,0,0,0,0,0,1)昨天：(0,0,0,0,0,1,0) boolean represention(不关心单词频率)表达句子 词典：[我们，又，去，爬山，今天，你们，昨天，跑步]按照单词在词典库中的顺序我们|今天|去|爬山：(1,0,1,1,1,0,0,0)-&gt;8维=|词典|你们|昨天|跑步：(0,0,0,0,0,1,1,1)你们|又|去|爬山|又|去|跑步：(0,1,1,1,0,1,0,1) count based represention(记录单词频率)表达句子 词典：[我们，又，去，爬山，今天，你们，昨天，跑步]按照单词在词典库中的顺序我们|今天|去|爬山：(1,0,1,1,1,0,0,0)-&gt;8维=|词典|你们|昨天|跑步：(0,0,0,0,0,1,1,1)你们|又|去|爬山|又|去|跑步：(0,2,2,1,0,1,0,1) tf-idf tf为词频，即一个词语在文档中的出现频率，假设一个词语在整个文档中出现了i次，而整个文档有N个词语，则tf的值为i/N.idf为逆向文件频率，假设整个文档有n篇文章，而一个词语在k篇文章中出现，则idf值为log(n/k)1.所有文档分词得到词典向量2.词典向量每个词对于当前句子进行词频统计，该词在句中出现n次，即tf3.所有文档总数m,词典向量中当前词出现在k个文档中，log(m/k)为idf4.针对词典向量生成tf-idf为m*log(m/k) 词典：[今天,上,NLP,课程,的,有,意思,数据,也]s1:今天|上|NLP|课程-&gt;[1log(3\2),1log(3\1),1log(3\1),1log(3\3),0,0,0,0,0]s2:今天|的|课程|有|意思-&gt;[1log(3\2),0,0,1log(3/3),1log(3\1),1log(3\2),1log(3\2),0,0]s3:数据|课程|也|有|意思-&gt;[0,0,0,1log(3\3),0,1log(3\2),1log(3\2),1log(3\1),1log(3\1)] distributed word 表示单词 我们:[0.4,0.6,0.8,0.1]爬山:[0.4,0.6,0.2,0.6]运动:[0.2,0.3,0.7,0.6]昨天:[0.5,0.9,0.1,0.3] 缺点：首先，它是一个词袋模型，不考虑词与词之间的顺序（文本中词的顺序信息也是很重要的）；其次，它假设词与词相互独立（在大多数情况下，词与词是相互影响的）；最后，它得到的特征是离散稀疏的。 文本语料库-&gt;预处理-&gt;文本处理集-&gt;one-hot向量输入word2vec-&gt;词向量（模型：CBOW和Skip-gram;；方法：负采样与层次softmax方法） Language Model语言模型：判断一句话是否通顺。 unigram bigram n-gram SmoothingLaplace Good-Turning]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>tf-idf</tag>
        <tag>hanlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动手实战中文句法依存分析（16）]]></title>
    <url>%2F2019%2F11%2F22%2F16.%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%88%98%E4%B8%AD%E6%96%87%E5%8F%A5%E6%B3%95%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[句法分析被用在很多场景中，比如搜索引擎用户日志分析和关键词识别，比如信息抽取、自动问答、机器翻译等其他自然语言处理相关的任务。 语法体系句法分析需要遵循某一语法体系，根据该体系的语法确定语法树的表示形式，我们看下面这个句子： 西门子将努力参与中国的三峡工程建设。 用可视化的工具 Stanford Parser来看看句法分析的整个过程： 短语结构树由终节点、非终结点以及短语标记三部分组成。句子分裂的语法规则为若干终结点构成一个短语，作为非终结点参与下一次规约，直至结束。如下图： 句法分析技术依存句法分析依存句法依存句法（Dependency Parsing， DP）通过分析语言单位内成分之间的依存关系揭示其句法结构。 直观来讲，依存句法的目的在于分析识别句子中的“主谓宾”、“定状补”这些语法成分，并分析各成分之间的关系。 依存句法的结构没有非终结点，词与词之间直接发生依存关系，构成一个依存对，其中一个是核心词，也叫支配词，另一个叫修饰词，也叫从属词。 依存关系用一个有向弧表示，叫做依存弧。依存弧的方向为由从属词指向支配词，当然反过来也是可以的，按个人习惯统一表示即可。 例如，下面这个句子： 国务院总理李克强调研上海外高桥时提出，支持上海积极探索新机制。 依存句法的分析结果见下（利用哈工大 LTP）： 从分析结果中我们可以看到，句子的核心谓词为“提出”，主语是“李克强”，提出的宾语是“支持上海……”，“调研……时”是“提出”的（时间）状语，“李克强”的修饰语是“国务院总理”，“支持”的宾语是“探索新机制”。 有了上面的依存句法分析结果，我们就可以比较容易的看到，“提出者”是“李克强”，而不是“上海”或“外高桥”，即使它们都是名词，而且距离“提出”更近。 依存关系依存句法通过分析语言单位内成分之前的依存关系解释其句法结构，主张句子中核心动词是支配其他成分的中心成分。而它本身却不受其他任何成分的支配，所有受支配成分都以某种关系从属于支配者。 在20世纪70年代，Robinson 提出依存句法中关于依存关系的四条公理，在处理中文信息的研究中，中国学者提出了依存关系的第五条公理，分别如下： 一个句子中只有一个成分是独立的； 句子的其他成分都从属于某一成分； 任何一个成分都不能依存于两个或两个以上的成分； 如果成分 A 直接从属成分 B，而成分 C 在句子中位于 A 和 B 之间，那么，成分 C 或者从属于 A，或者从属于 B，或者从属于 A 和 B 之间的某一成分； 中心成分左右两边的其他成分相互不发生关系。 句子成分之间相互支配与被支配、依存与被依存的现象，普遍存在于汉语的词汇（合成语）、短语、单句、段落、篇章等能够独立运用和表达的语言之中，这一特点体现了依存关系的普遍性。依存句法分析可以反映出句子各成分之间的语义修饰关系，它可以获得长距离的搭配信息，并与句子成分的物理位置无关。 依存句法分析标注关系（共14种）及含义如下表所示： 语义依存分析语义依存分析（Semantic Dependency Parsing，SDP），分析句子各个语言单位之间的语义关联，并将语义关联以依存结构呈现。使用语义依存刻画句子语义，好处在于不需要去抽象词汇本身，而是通过词汇所承受的语义框架来描述该词汇，而论元的数目相对词汇来说数量总是少了很多。 语义依存分析目标是跨越句子表层句法结构的束缚，直接获取深层的语义信息。例如以下三个句子，用不同的表达方式表达了同一个语义信息，即张三实施了一个吃的动作，吃的动作是对苹果实施的。 语义依存分析不受句法结构的影响，将具有直接语义关联的语言单元直接连接依存弧并标记上相应的语义关系。这也是语义依存分析与依存句法分析的重要区别。 语义依存关系分为三类，分别是主要语义角色，每一种语义角色对应存在一个嵌套关系和反关系；事件关系，描述两个事件间的关系；语义依附标记，标记说话者语气等依附性信息。 Pyhanlp 实战依存句法最后，我们通过 Pyhanlp 库实现依存句法的实战练习。这个过程中，我们选用 Dependency Viewer 工具进行可视化展示。可视化时， txt文档需要采用 UTF-8 编码。 首先，引入包，然后可直接进行分析： from pyhanlp import * sentence = &quot;徐先生还具体帮助他确定了把画雄鹰、松鼠和麻雀作为主攻目标。&quot; print(HanLP.parseDependency(sentence)) 得到的结果： 然后，我们将结果保存在 txt 文件中： f = open(&quot;D://result.txt&quot;,&#39;a+&#39;) print((HanLP.parseDependency(sentence )),file = f) 最后，通过 Dependency Viewer 工具进行可视化，如果出现乱码，记得把 txt 文档保存为 UTF-8 式即可，得到的可视化结果如下图所示： 总结本文，首先为大家介绍了语法体系，以及如何根据语法体系确定一个句子的语法树，为后面的句法分析奠定基础。 接着，介绍了依存句法，它的目的是通过分析语言单位内成分之间的依存关系揭示其句法结构，随之讲解了依存句法中的五大依存关系。 最后，进一步介绍了区别于依存句法的语义依存，其目的是分析句子各个语言单位之间的语义关联，并将语义关联以依存结构呈现。 文章结尾，通过 Pyhanlp 实战以及可视化，带大家进一步加深对中文依存句法的了解。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[中文短文本分类（22）]]></title>
    <url>%2F2019%2F11%2F22%2F22.%E4%B8%AD%E6%96%87%E7%9F%AD%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[目前，随着大数据、云计算对关系型数据处理技术趋向稳定成熟，各大互联网公司对关系数据的整合也已经落地成熟，笔者预测未来数据领域的挑战将主要集中在半结构化和非结构化数据的整合，NLP 技术对个人发展越来越重要，尤其在中文文本上挑战更大。 由于是第一讲，笔者在本次 Chat 并没有提及较深入的 NLP 处理技术，通过 WordCloud 制作词云、用 LDA 主题模型获取文本关键词、以及用朴素贝叶斯算法和 SVM 分别对文本分类，目的是让大家对中文文本处理有一个直观了解，为后续实战提供基础保障。 WordCloud 制作词云最近中美贸易战炒的沸沸扬扬，笔者用网上摘取了一些文本（自己线下可以继续添加语料），下面来制作一个中美贸易战相关的词云。 jieba 分词安装jieba 俗称中文分词利器，作用是来对文本语料进行分词。 全自动安装：easy_install jieba 或者 pip install jieba / pip3 install jieba 半自动安装：先下载 https://pypi.python.org/pypi/jieba/ ，解压后运行 python setup.py install 手动安装：将 jieba 目录放置于当前目录或者 site-packages 目录。 安装完通过 import jieba 验证安装成功与否。 WordCloud 安装 下载：https://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud 安装（window 环境安装）找的下载文件的路径：pip install wordcloud-1.3.2-cp36-cp36m-win_amd64.whl 安装完通过 from wordcloud import WordCloud 验证安装成功与否。 开始编码实现整个过程分为几个步骤： 文件加载 分词 统计词频 去停用词 构建词云 #引入所需要的包 import jieba import pandas as pd import numpy as np from scipy.misc import imread from wordcloud import WordCloud,ImageColorGenerator import matplotlib.pyplot as plt #定义文件路径 dir = &quot;D://ProgramData//PythonWorkSpace//study//&quot; #定义语料文件路径 file = &quot;&quot;.join([dir,&quot;z_m.csv&quot;]) #定义停用词文件路径 stop_words = &quot;&quot;.join([dir,&quot;stopwords.txt&quot;]) #定义wordcloud中字体文件的路径 simhei = &quot;&quot;.join([dir,&quot;simhei.ttf&quot;]) #读取语料 df = pd.read_csv(file, encoding=&#39;utf-8&#39;) df.head() #如果存在nan，删除 df.dropna(inplace=True) #将content一列转为list content=df.content.values.tolist() #用jieba进行分词操作 segment=[] for line in content: try: segs=jieba.cut_for_search(line) segs = [v for v in segs if not str(v).isdigit()]#去数字 segs = list(filter(lambda x:x.strip(), segs)) #去左右空格 #segs = list(filter(lambda x:len(x)&gt;1, segs)) #长度为1的字符 for seg in segs: if len(seg)&gt;1 and seg!=&#39;\r\n&#39;: segment.append(seg) except: print(line) continue #分词后加入一个新的DataFrame words_df=pd.DataFrame({&#39;segment&#39;:segment}) #加载停用词 stopwords=pd.read_csv(stop_words,index_col=False,quoting=3,sep=&quot;\t&quot;,names=[&#39;stopword&#39;], encoding=&#39;utf-8&#39;) #安装关键字groupby分组统计词频，并按照计数降序排序 words_stat=words_df.groupby(by=[&#39;segment&#39;])[&#39;segment&#39;].agg({&quot;计数&quot;:np.size}) words_stat=words_stat.reset_index().sort_values(by=[&quot;计数&quot;],ascending=False) #分组之后去掉停用词 words_stat=words_stat[~words_stat.segment.isin(stopwords.stopword)] #下面是重点，绘制wordcloud词云，这一提供2种方式 #第一种是默认的样式 wordcloud=WordCloud(font_path=simhei,background_color=&quot;white&quot;,max_font_size=80) word_frequence = {x[0]:x[1] for x in words_stat.head(1000).values} wordcloud=wordcloud.fit_words(word_frequence) plt.imshow(wordcloud) wordcloud.to_file(r&#39;wordcloud_1.jpg&#39;) #保存结果 #第二种是自定义图片 text = &quot; &quot;.join(words_stat[&#39;segment&#39;].head(100).astype(str)) abel_mask = imread(r&quot;china.jpg&quot;) #这里设置了一张中国地图 wordcloud2 = WordCloud(background_color=&#39;white&#39;, # 设置背景颜色 mask = abel_mask, # 设置背景图片 max_words = 3000, # 设置最大现实的字数 font_path = simhei, # 设置字体格式 width=2048, height=1024, scale=4.0, max_font_size= 300, # 字体最大值 random_state=42).generate(text) # 根据图片生成词云颜色 image_colors = ImageColorGenerator(abel_mask) wordcloud2.recolor(color_func=image_colors) # 以下代码显示图片 plt.imshow(wordcloud2) plt.axis(&quot;off&quot;) plt.show() wordcloud2.to_file(r&#39;wordcloud_2.jpg&#39;) #保存结果 这里只给出默认生产的图，自定义的图保存在 wordcloud_2.jpg，回头自己看。 LDA 提取关键字Gensim 安装Gensim 除了具备基本的语料处理功能外，Gensim 还提供了 LSI、LDA、HDP、DTM、DIM 等主题模型、TF-IDF 计算以及当前流行的深度神经网络语言模型 word2vec、paragraph2vec 等算法，可谓是方便之至。 Gensim 安装：pip install gensim 安装完通过 import gensim 验证安装成功与否。 LDA 提取关键字编码实现语料是一个关于汽车的短文本，传统的关键字提取有基于 TF-IDF 算法的关键词抽取；基于 TextRank 算法的关键词抽取等方式。下面通过 Gensim 库完成基于 LDA 的关键字提取。 整个过程步骤： 文件加载 分词 去停用词 构建词袋模型 LDA 模型训练 结果可视化 #引入库文件 import jieba.analyse as analyse import jieba import pandas as pd from gensim import corpora, models, similarities import gensim import numpy as np import matplotlib.pyplot as plt %matplotlib inline #设置文件路径 dir = &quot;D://ProgramData//PythonWorkSpace//study//&quot; file_desc = &quot;&quot;.join([dir,&#39;car.csv&#39;]) stop_words = &quot;&quot;.join([dir,&#39;stopwords.txt&#39;]) #定义停用词 stopwords=pd.read_csv(stop_words,index_col=False,quoting=3,sep=&quot;\t&quot;,names=[&#39;stopword&#39;], encoding=&#39;utf-8&#39;) stopwords=stopwords[&#39;stopword&#39;].values #加载语料 df = pd.read_csv(file_desc, encoding=&#39;gbk&#39;) #删除nan行 df.dropna(inplace=True) lines=df.content.values.tolist() #开始分词 sentences=[] for line in lines: try: segs=jieba.lcut(line) segs = [v for v in segs if not str(v).isdigit()]#去数字 segs = list(filter(lambda x:x.strip(), segs)) #去左右空格 segs = list(filter(lambda x:x not in stopwords, segs)) #去掉停用词 sentences.append(segs) except Exception: print(line) continue #构建词袋模型 dictionary = corpora.Dictionary(sentences) corpus = [dictionary.doc2bow(sentence) for sentence in sentences] #lda模型，num_topics是主题的个数，这里定义了5个 lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=10) #我们查一下第1号分类，其中最常出现的5个词是： print(lda.print_topic(1, topn=5)) #我们打印所有5个主题，每个主题显示8个词 for topic in lda.print_topics(num_topics=10, num_words=8): print(topic[1]) #显示中文matplotlib plt.rcParams[&#39;font.sans-serif&#39;] = [u&#39;SimHei&#39;] plt.rcParams[&#39;axes.unicode_minus&#39;] = False # 在可视化部分，我们首先画出了九个主题的7个词的概率分布图 num_show_term = 8 # 每个主题下显示几个词 num_topics = 10 for i, k in enumerate(range(num_topics)): ax = plt.subplot(2, 5, i+1) item_dis_all = lda.get_topic_terms(topicid=k) item_dis = np.array(item_dis_all[:num_show_term]) ax.plot(range(num_show_term), item_dis[:, 1], &#39;b*&#39;) item_word_id = item_dis[:, 0].astype(np.int) word = [dictionary.id2token[i] for i in item_word_id] ax.set_ylabel(u&quot;概率&quot;) for j in range(num_show_term): ax.text(j, item_dis[j, 1], word[j], bbox=dict(facecolor=&#39;green&#39;,alpha=0.1)) plt.suptitle(u&#39;9个主题及其7个主要词的概率&#39;, fontsize=18) plt.show() 朴素贝叶斯和 SVM 文本分类最后一部分，我们通过带标签的数据： 数据是笔者曾经做过的一份司法数据，其中需求是对每一条输入数据，判断事情的主体是谁，比如报警人被老公打，报警人被老婆打，报警人被儿子打，报警人被女儿打等来进行文本有监督的分类操作。 本次主要选这 4 类标签，基本操作过程步骤： 文件加载 分词 去停用词 抽取词向量特征 分别进行朴素贝叶斯和 SVM 分类算法建模 评估打分 #引入包 import random import jieba import pandas as pd #指定文件目录 dir = &quot;D://ProgramData//PythonWorkSpace//chat//chat1//NB_SVM//&quot; #指定语料 stop_words = &quot;&quot;.join([dir,&#39;stopwords.txt&#39;]) laogong = &quot;&quot;.join([dir,&#39;beilaogongda.csv&#39;]) #被老公打 laopo = &quot;&quot;.join([dir,&#39;beilaopoda.csv&#39;]) #被老婆打 erzi = &quot;&quot;.join([dir,&#39;beierzida.csv&#39;]) #被儿子打 nver = &quot;&quot;.join([dir,&#39;beinverda.csv&#39;]) #被女儿打 #加载停用词 stopwords=pd.read_csv(stop_words,index_col=False,quoting=3,sep=&quot;\t&quot;,names=[&#39;stopword&#39;], encoding=&#39;utf-8&#39;) stopwords=stopwords[&#39;stopword&#39;].values #加载语料 laogong_df = pd.read_csv(laogong, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) laopo_df = pd.read_csv(laopo, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) erzi_df = pd.read_csv(erzi, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) nver_df = pd.read_csv(nver, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) #删除语料的nan行 laogong_df.dropna(inplace=True) laopo_df.dropna(inplace=True) erzi_df.dropna(inplace=True) nver_df.dropna(inplace=True) #转换 laogong = laogong_df.segment.values.tolist() laopo = laopo_df.segment.values.tolist() erzi = erzi_df.segment.values.tolist() nver = nver_df.segment.values.tolist() #定义分词和打标签函数preprocess_text #参数content_lines即为上面转换的list #参数sentences是定义的空list，用来储存打标签之后的数据 #参数category 是类型标签 def preprocess_text(content_lines, sentences, category): for line in content_lines: try: segs=jieba.lcut(line) segs = [v for v in segs if not str(v).isdigit()]#去数字 segs = list(filter(lambda x:x.strip(), segs)) #去左右空格 segs = list(filter(lambda x:len(x)&gt;1, segs)) #长度为1的字符 segs = list(filter(lambda x:x not in stopwords, segs)) #去掉停用词 sentences.append((&quot; &quot;.join(segs), category))# 打标签 except Exception: print(line) continue #调用函数、生成训练数据 sentences = [] preprocess_text(laogong, sentences, &#39;laogong&#39;) preprocess_text(laopo, sentences, &#39;laopo&#39;) preprocess_text(erzi, sentences, &#39;erzi&#39;) preprocess_text(nver, sentences, &#39;nver&#39;) #打散数据，生成更可靠的训练集 random.shuffle(sentences) #控制台输出前10条数据，观察一下 for sentence in sentences[:10]: print(sentence[0], sentence[1]) #用sk-learn对数据切分，分成训练集和测试集 from sklearn.model_selection import train_test_split x, y = zip(*sentences) x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1234) #抽取特征，我们对文本抽取词袋模型特征 from sklearn.feature_extraction.text import CountVectorizer vec = CountVectorizer( analyzer=&#39;word&#39;, # tokenise by character ngrams max_features=4000, # keep the most common 1000 ngrams ) vec.fit(x_train) #用朴素贝叶斯算法进行模型训练 from sklearn.naive_bayes import MultinomialNB classifier = MultinomialNB() classifier.fit(vec.transform(x_train), y_train) #对结果进行评分 print(classifier.score(vec.transform(x_test), y_test)) 这时输出结果为：0.99284009546539376。 我们看到，这个时候的结果评分已经很高了，当然我们的训练数据集中，噪声都已经提前处理完了，使得数据集在很少数据量下，模型得分就可以很高。 下面我们继续进行优化： #可以把特征做得更棒一点，试试加入抽取2-gram和3-gram的统计特征，比如可以把词库的量放大一点。 from sklearn.feature_extraction.text import CountVectorizer vec = CountVectorizer( analyzer=&#39;word&#39;, # tokenise by character ngrams ngram_range=(1,4), # use ngrams of size 1 and 2 max_features=20000, # keep the most common 1000 ngrams ) vec.fit(x_train) #用朴素贝叶斯算法进行模型训练 from sklearn.naive_bayes import MultinomialNB classifier = MultinomialNB() classifier.fit(vec.transform(x_train), y_train) #对结果进行评分 print(classifier.score(vec.transform(x_test), y_test)) 这时输出结果为：0.97852028639618138。 我们看到，这个时候的结果稍微有点下降，这与我们语料本身有关系，但是如果随着数据量更多，语料文本长点，我认为或许第二种方式应该比第一种方式效果更好。 可见使用 scikit-learn 包，算法模型开发非常简单，下面看看 SVM 的应用： from sklearn.svm import SVC svm = SVC(kernel=&#39;linear&#39;) svm.fit(vec.transform(x_train), y_train) print(svm.score(vec.transform(x_test), y_test)) 这时输出结果为：0.997613365155，比朴素贝叶斯效果更好。 语料数据下载地址：https://github.com/sujeek/chat_list 数据科学比赛大杀器 XGBoost 实战文本分类在说 XGBoost 之前，我们先简单从树模型说起，典型的决策树模型。决策树的学习过程主要包括： 特征选择： 从训练数据的特征中选择一个特征作为当前节点的分裂标准（特征选择的标准不同产生了不同的特征决策树算法，如根据信息增益、信息增益率和gini等）。 决策树生成： 根据所选特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树生长。 剪枝： 决策树容易过拟合，需通过剪枝来预防过拟合（包括预剪枝和后剪枝）。 常见的决策树算法有 ID3、C4.5、CART 等。 在 sklearn 中决策树分类模型如下，可以看到默认通过 gini 计算实现。 sklearn.tree.DecisionTreeClassifier(criterion=’gini’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False) 尽管决策树分类算法模型在应用中能够得到很好的结果，并通过剪枝操作提高模型泛化能力，但一棵树的生成肯定不如多棵树，因此就有了随机森林，并成功解决了决策树泛化能力弱的缺点，随机森林就是集成学习的一种方式。 在西瓜书中对集成学习的描述：集成学习通过将多个学习器进行结合，可获得比单一学习器显著优越的泛化性能，对“弱学习器” 尤为明显。弱学习器常指泛化性能略优于随机猜测的学习器。集成学习的结果通过投票法产生，即“少数服从多数”。个体学习不能太坏，并且要有“多样性”，即学习器间具有差异，即集成个体应“好而不同”。 假设基分类器的错误率相互独立，则由 Hoeffding 不等式可知，随着集成中个体分类器数目 T 的增大，集成的错误率将指数级下降，最终趋向于零。 但是这里有一个关键假设：基学习器的误差相互独立，而现实中个体学习器是为解决同一个问题训练出来的，所以不可能相互独立。因此，如何产生并结合“好而不同”的个体学习器是集成学习研究的核心。 集成学习大致分为两大类： Boosting：个体学习器间存在强依赖关系，必须串行生成的序列化方法。代表：AdaBoost、GBDT、XGBoost Bagging：个体学习器间不存在强依赖关系，可同时生成的并行化方法。代表：随机森林（Random Forest） 在 sklearn 中，对于 Random Forest、AdaBoost、GBDT 都有实现，下面我们重点说说在 kaggle、阿里天池等数据科学比赛经常会用到的大杀器 XGBoost，来实战文本分类 。 关于分类数据，还是延用《NLP 中文短文本分类项目实践（上）》中朴素贝叶斯算法的数据，这里对数据的标签做个修改，标签由 str 换成 int 类型，并从 0 开始，0、1、2、3 代表四类，所以是一个多分类问题： preprocess_text(laogong, sentences,0) #laogong 分类0 preprocess_text(laopo, sentences, 1) #laopo 分类1 preprocess_text(erzi, sentences, 2) #erzi 分类2 preprocess_text(nver, sentences,3) #nver 分类3 接着我们引入 XGBoost 的库（默认你已经安装好 XGBoost），整个代码加了注释，可以当做模板来用，每次使用只需微调即可使用。 import xgboost as xgb from sklearn.model_selection import StratifiedKFold import numpy as np # xgb矩阵赋值 xgb_train = xgb.DMatrix(vec.transform(x_train), label=y_train) xgb_test = xgb.DMatrix(vec.transform(x_test)) 上面在引入库和构建完 DMatrix 矩阵之后，下面主要是调参指标，可以根据参数进行调参： params = { &#39;booster&#39;: &#39;gbtree&#39;, #使用gbtree &#39;objective&#39;: &#39;multi:softmax&#39;, # 多分类的问题、 # &#39;objective&#39;: &#39;multi:softprob&#39;, # 多分类概率 #&#39;objective&#39;: &#39;binary:logistic&#39;, #二分类 &#39;eval_metric&#39;: &#39;merror&#39;, #logloss &#39;num_class&#39;: 4, # 类别数，与 multisoftmax 并用 &#39;gamma&#39;: 0.1, # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。 &#39;max_depth&#39;: 8, # 构建树的深度，越大越容易过拟合 &#39;alpha&#39;: 0, # L1正则化系数 &#39;lambda&#39;: 10, # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。 &#39;subsample&#39;: 0.7, # 随机采样训练样本 &#39;colsample_bytree&#39;: 0.5, # 生成树时进行的列采样 &#39;min_child_weight&#39;: 3, # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言 # 假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。 # 这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 &#39;silent&#39;: 0, # 设置成1则没有运行信息输出，最好是设置为0. &#39;eta&#39;: 0.03, # 如同学习率 &#39;seed&#39;: 1000, &#39;nthread&#39;: -1, # cpu 线程数 &#39;missing&#39;: 1 #&#39;scale_pos_weight&#39;: (np.sum(y==0)/np.sum(y==1)) # 用来处理正负样本不均衡的问题,通常取：sum(negative cases) / sum(positive cases) } 这里进行迭代次数设置和 k 折交叉验证，训练模型，并进行模型保存和预测结果。 plst = list(params.items()) num_rounds = 200 # 迭代次数 watchlist = [(xgb_train, &#39;train&#39;)] # 交叉验证 result = xgb.cv(plst, xgb_train, num_boost_round=200, nfold=4, early_stopping_rounds=200, verbose_eval=True, folds=StratifiedKFold(n_splits=4).split(vec.transform(x_train), y_train)) # 训练模型并保存 # early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练 model = xgb.train(plst, xgb_train, num_rounds, watchlist, early_stopping_rounds=200) #model.save_model(&#39;../data/model/xgb.model&#39;) # 用于存储训练出的模型 #predicts = model.predict(xgb_test) #预测 词向量 Word2Vec 和 FastText 实战深度学习带给自然语言处理最令人兴奋的突破是词向量（Word Embedding）技术。词向量技术是将词语转化成为稠密向量。在自然语言处理应用中，词向量作为机器学习、深度学习模型的特征进行输入。因此，最终模型的效果很大程度上取决于词向量的效果。 Word2Vec 词向量在 Word2Vec 出现之前，自然语言处理经常把字词进行独热编码，也就是 One-Hot Encoder。 大数据 [0,0,0,0,0,0,0,1,0,……，0,0,0,0,0,0,0] 云计算[0,0,0,0,1,0,0,0,0,……，0,0,0,0,0,0,0] 机器学习[0,0,0,1,0,0,0,0,0,……，0,0,0,0,0,0,0] 人工智能[0,0,0,0,0,0,0,0,0,……，1,0,0,0,0,0,0] 比如上面的例子中，大数据 、云计算、机器学习和人工智能各对应一个向量，向量中只有一个值为 1，其余都为 0。所以使用 One-Hot Encoder 有以下问题：第一，词语编码是随机的，向量之间相互独立，看不出词语之间可能存在的关联关系。第二，向量维度的大小取决于语料库中词语的多少，如果语料包含的所有词语对应的向量合为一个矩阵的话，那这个矩阵过于稀疏，并且会造成维度灾难。 而解决这个问题的手段，就是使用向量表示（Vector Representations）。 Word2Vec 是 Google 团队 2013 年推出的，自提出后被广泛应用在自然语言处理任务中，并且受到它的启发，后续出现了更多形式的词向量模型。Word2Vec 主要包含两种模型：Skip-Gram 和 CBOW，值得一提的是，Word2Vec 词向量可以较好地表达不同词之间的相似和类比关系。 下面我们通过代码实战来体验一下 Word2Vec，pip install gensim 安装好库后，即可导入使用： 训练模型定义 from gensim.models import Word2Vec model = Word2Vec(sentences, sg=1, size=100, window=5, min_count=5, negative=3, sample=0.001, hs=1, workers=4) 参数解释： sg=1 是 skip-gram 算法，对低频词敏感；默认 sg=0 为 CBOW 算法。 size 是输出词向量的维数，值太小会导致词映射因为冲突而影响结果，值太大则会耗内存并使算法计算变慢，一般值取为 100 到 200 之间。 window 是句子中当前词与目标词之间的最大距离，3 表示在目标词前看 3-b 个词，后面看 b 个词（b 在 0-3 之间随机）。 min_count 是对词进行过滤，频率小于 min-count 的单词则会被忽视，默认值为 5。 negative 和 sample 可根据训练结果进行微调，sample 表示更高频率的词被随机下采样到所设置的阈值，默认值为 1e-3。 hs=1 表示层级 softmax 将会被使用，默认 hs=0 且 negative 不为 0，则负采样将会被选择使用。 详细参数说明可查看 Word2Vec 源代码。训练后的模型保存与加载，可以用来计算相似性，最大匹配程度等。 model.save(model) #保存模型 model = Word2Vec.load(model) #加载模型 model.most_similar(positive=[&#39;女人&#39;, &#39;女王&#39;], negative=[&#39;男人&#39;]) #输出[(&#39;女王&#39;, 0.50882536), ...] model.similarity(&#39;女人&#39;, &#39;男人&#39;) #输出0.73723527 FastText词向量FastText 是 facebook 开源的一个词向量与文本分类工具，模型简单，训练速度非常快。FastText 做的事情，就是把文档中所有词通过 lookup table 变成向量，取平均后直接用线性分类器得到分类结果。 FastText python 包的安装： pip install fasttext FastText 做文本分类要求文本是如下的存储形式： __label__1 ，内容。 __label__2，内容。 __label__3 ，内容。 __label__4，内容。 其中前面的 label 是前缀，也可以自己定义，label 后接的为类别，之后接的就是我是我们的文本内容。 调用 fastText 训练生成模型，对模型效果进行评估。 import fasttext classifier = fasttext.supervised(&#39;train_data.txt&#39;, &#39;classifier.model&#39;, label_prefix=&#39;__label__&#39;) result = classifier.test(&#39;train_data.txt&#39;) print(result.precision) print(result.recall) 实际预测过程： label_to_cate = {1:&#39;科技&#39;, 2:&#39;财经&#39;, 3:&#39;体育&#39;, 4:&#39;生活&#39;, 5:&#39;美食&#39;} texts = [&#39;现如今 机器 学习 和 深度 学习 带动 人工智能 飞速 的 发展 并 在 图片 处理 语音 识别 领域 取得 巨大成功&#39;] labels = classifier.predict(texts) print(labels) print(label_to_cate[int(labels[0][0])]) [[u&#39;1&#39;]] 科技 文本分类之神经网络 CNN 和 LSTM 实战CNN 做文本分类实战CNN 在图像上的巨大成功，使得大家都有在文本上试一把的冲动。CNN 的原理这里就不赘述了，关键看看怎样用于文本分类的，下图是一个 TextCNN 的结构（来源：网络）： 具体结构介绍： 输入层可以把输入层理解成把一句话转化成了一个二维的图像：每一排是一个词的 Word2Vec 向量，纵向是这句话的每个词按序排列。输入数据的 size，也就是图像的 size，n×k，n 代表训练数据中最长的句子的词个数，k 是 embbeding 的维度。从输入层还可以看出 kernel 的 size。很明显 kernel 的高 (h) 会有不同的值，有的是 2，有的是 3。这很容易理解，不同的 kernel 想获取不同范围内词的关系；和图像不同的是，NLP 中的 CNN 的 kernel 的宽 (w) 一般都是图像的宽，也就是 Word2Vec 的维度，这也可以理解，因为我们需要获得的是纵向的差异信息，也就是不同范围的词出现会带来什么信息。 卷积层由于 kernel 的特殊形状，因此卷积后的 feature map 是一个宽度是 1 的长条。 池化层这里使用 MaxPooling，并且一个 feature map 只选一个最大值留下。这被认为是按照这个 kernel 卷积后的最重要的特征。 全连接层这里的全连接层是带 dropout 的全连接层和 softmax。 下面我们看看自己用 Tensorflow 如何实现一个文本分类器： 超参数定义： #文档最长长度 MAX_DOCUMENT_LENGTH = 100 #最小词频数 MIN_WORD_FREQUENCE = 2 #词嵌入的维度 EMBEDDING_SIZE = 20 #filter个数 N_FILTERS = 10 #感知野大小 WINDOW_SIZE = 20 #filter的形状 FILTER_SHAPE1 = [WINDOW_SIZE, EMBEDDING_SIZE] FILTER_SHAPE2 = [WINDOW_SIZE, N_FILTERS] #池化 POOLING_WINDOW = 4 POOLING_STRIDE = 2 n_words = 0 网络结构定义，2 层的卷积神经网络，用于短文本分类： def cnn_model(features, target): # 先把词转成词嵌入 # 我们得到一个形状为[n_words, EMBEDDING_SIZE]的词表映射矩阵 # 接着我们可以把一批文本映射成[batch_size, sequence_length, EMBEDDING_SIZE]的矩阵形式 target = tf.one_hot(target, 15, 1, 0) word_vectors = tf.contrib.layers.embed_sequence( features, vocab_size=n_words, embed_dim=EMBEDDING_SIZE, scope=&#39;words&#39;) word_vectors = tf.expand_dims(word_vectors, 3) with tf.variable_scope(&#39;CNN_Layer1&#39;): # 添加卷积层做滤波 conv1 = tf.contrib.layers.convolution2d( word_vectors, N_FILTERS, FILTER_SHAPE1, padding=&#39;VALID&#39;) # 添加RELU非线性 conv1 = tf.nn.relu(conv1) # 最大池化 pool1 = tf.nn.max_pool( conv1, ksize=[1, POOLING_WINDOW, 1, 1], strides=[1, POOLING_STRIDE, 1, 1], padding=&#39;SAME&#39;) # 对矩阵进行转置，以满足形状 pool1 = tf.transpose(pool1, [0, 1, 3, 2]) with tf.variable_scope(&#39;CNN_Layer2&#39;): # 第2个卷积层 conv2 = tf.contrib.layers.convolution2d( pool1, N_FILTERS, FILTER_SHAPE2, padding=&#39;VALID&#39;) # 抽取特征 pool2 = tf.squeeze(tf.reduce_max(conv2, 1), squeeze_dims=[1]) # 全连接层 logits = tf.contrib.layers.fully_connected(pool2, 15, activation_fn=None) loss = tf.losses.softmax_cross_entropy(target, logits) train_op = tf.contrib.layers.optimize_loss( loss, tf.contrib.framework.get_global_step(), optimizer=&#39;Adam&#39;, learning_rate=0.01) return ({ &#39;class&#39;: tf.argmax(logits, 1), &#39;prob&#39;: tf.nn.softmax(logits) }, loss, train_op) LSTM 做文本分类实战上面实现了基于 CNN 的文本分类器之后，再来做一个基于 LSTM 分类器，会觉得非常容易，因为变化的部分只偶遇中间把 CNN 换成了 LSTM 模型。关于 RNN 和 LSTM 的理论知识，请自行解决，这里主要给出思路和代码实现。 具体结构，参照下面这幅图（来源：网络）： 上面我们用的 Tensorflow 实现的，这次我们用 Keras 更简单方便的实现其核心代码： #超参数定义 MAX_SEQUENCE_LENGTH = 100 EMBEDDING_DIM = 200 VALIDATION_SPLIT = 0.16 TEST_SPLIT = 0.2 epochs = 10 batch_size = 128 #模型网络定义 model = Sequential() model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)) model.add(LSTM(200, dropout=0.2, recurrent_dropout=0.2)) model.add(Dropout(0.2)) model.add(Dense(labels.shape[1], activation=&#39;softmax&#39;)) model.summary() 可见，基于 Keras 实现神经网络比 Tensorflow 要简单和容易很多，Keras 搭建神经网络俗称“堆积木”，这里有所体现。所以笔者也推荐，如果想快速实现一个神经网络，建议先用 Keras 快速搭建验证，之后再尝试用 Tensorflow 去实现。 总结，本次 Chat 就将分享到这里，从 XGBoost 到词向量以及神经网络，内容非常多也非常重要，笔者并没有过多的讲述理论并不代表不重要，相反理论很重要，但笔者希望能够先通过代码实战进行体验，然后静下心来完成理论部分的学习，最后代码和理论相结合，效率更高。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>jieba</tag>
        <tag>lstm</tag>
        <tag>lda</tag>
        <tag>cnn</tag>
        <tag>svm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HMM和CRF（8）]]></title>
    <url>%2F2019%2F11%2F22%2F8.HMM%E5%92%8CCRF%2F</url>
    <content type="text"><![CDATA[HMM（隐马尔可夫模型）和 CRF（条件随机场）算法常常被用于分词、句法分析、命名实体识别、词性标注等。由于两者之间有很大的共同点，所以在很多应用上往往是重叠的，但在命名实体、句法分析等领域 CRF 似乎更胜一筹。 在机器学习中，生成式模型和判别式模型都用于有监督学习，有监督学习的任务就是从数据中学习一个模型（也叫分类器），应用这一模型，对给定的输入 X 预测相应的输出 Y。这个模型的一般形式为：决策函数 Y=f(X) 或者条件概率分布 P(Y|X)。 首先，简单从贝叶斯定理说起，若记 P(A)、P(B) 分别表示事件 A 和事件 B 发生的概率，则 P(A|B) 表示事件 B 发生的情况下事件 A 发生的概率；P(AB)表示事件 A 和事件 B 同时发生的概率。 生成式模型：估计的是联合概率分布，P(Y, X)=P(Y|X)*P(X)，由联合概率密度分布 P(X,Y)，然后求出条件概率分布 P(Y|X) 作为预测的模型，即生成模型公式为：P(Y|X)= P(X,Y)/ P(X)。基本思想是首先建立样本的联合概率密度模型 P(X,Y)，然后再得到后验概率 P(Y|X)，再利用它进行分类，其主要关心的是给定输入 X 产生输出 Y 的生成关系。 判别式模型：估计的是条件概率分布， P(Y|X)，是给定观测变量 X 和目标变量 Y 的条件模型。由数据直接学习决策函数 Y=f(X) 或者条件概率分布 P(Y|X) 作为预测的模型，其主要关心的是对于给定的输入 X，应该预测什么样的输出 Y。 HMM 使用隐含变量生成可观测状态，其生成概率有标注集统计得到，是一个生成模型。其他常见的生成式模型有：Gaussian、 Naive Bayes、Mixtures of multinomials 等。 CRF 就像一个反向的隐马尔可夫模型（HMM），通过可观测状态判别隐含变量，其概率亦通过标注集统计得来，是一个判别模型。其他常见的判别式模型有：K 近邻法、感知机、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、提升方法等。 基于 HMM 训练自己的 Python 中文分词器HMM 模型是由一个“五元组”组成的集合： StatusSet：状态值集合，状态值集合为 (B, M, E, S)，其中 B 为词的首个字，M 为词中间的字，E 为词语中最后一个字，S 为单个字，B、M、E、S 每个状态代表的是该字在词语中的位置。 举个例子，对“中国的人工智能发展进入高潮阶段”，分词可以标注为：“中B国E的S人B工E智B能E发B展E进B入E高B潮E阶B段E”，最后的分词结果为：[‘中国’, ‘的’, ‘人工’, ‘智能’, ‘发展’, ‘进入’, ‘高潮’, ‘阶段’]。 ObservedSet：观察值集合，观察值集合就是所有语料的汉字，甚至包括标点符号所组成的集合。 TransProbMatrix：转移概率矩阵，状态转移概率矩阵的含义就是从状态 X 转移到状态 Y 的概率，是一个4×4的矩阵，即 {B,E,M,S}×{B,E,M,S}。 EmitProbMatrix：发射概率矩阵，发射概率矩阵的每个元素都是一个条件概率，代表 P(Observed[i]|Status[j]) 概率。 InitStatus：初始状态分布，初始状态概率分布表示句子的第一个字属于 {B,E,M,S} 这四种状态的概率。 将 HMM 应用在分词上，要解决的问题是：参数（ObservedSet、TransProbMatrix、EmitRobMatrix、InitStatus）已知的情况下，求解状态值序列。解决这个问题的最有名的方法是 Viterbi 算法。 本次训练使用的预料 syj_trainCorpus_utf8.txt ,整个语料大小 264M，包含1116903条数据，UTF-8 编码，词与词之间用空格隔开，用来训练分词模型。语料格式，用空格隔开的： 如果 继续 听任 资产阶级 自由化 的 思潮 泛滥 ， 党 就 失去 了 凝聚力 和 战斗力 ， 怎么 能 成为 全国 人民 的 领导 核心 ？ 中国 又 会 成为 一盘散沙 ， 那 还有 什么 希望 ？预定义# 用来模型保存 import pickle import json # 定义 HMM 中的状态，初始化概率，以及中文停顿词 STATES = {&#39;B&#39;, &#39;M&#39;, &#39;E&#39;, &#39;S&#39;} EPS = 0.0001 #定义停顿标点 seg_stop_words = {&quot; &quot;,&quot;，&quot;,&quot;。&quot;,&quot;“&quot;,&quot;”&quot;,&#39;“&#39;, &quot;？&quot;, &quot;！&quot;, &quot;：&quot;, &quot;《&quot;, &quot;》&quot;, &quot;、&quot;, &quot;；&quot;, &quot;·&quot;, &quot;‘ &quot;, &quot;’&quot;, &quot;──&quot;, &quot;,&quot;, &quot;.&quot;, &quot;?&quot;, &quot;!&quot;, &quot;`&quot;, &quot;~&quot;, &quot;@&quot;, &quot;#&quot;, &quot;$&quot;, &quot;%&quot;, &quot;^&quot;, &quot;&amp;&quot;, &quot;*&quot;, &quot;(&quot;, &quot;)&quot;, &quot;-&quot;, &quot;_&quot;, &quot;+&quot;, &quot;=&quot;, &quot;[&quot;, &quot;]&quot;, &quot;{&quot;, &quot;}&quot;, &#39;&quot;&#39;, &quot;&#39;&quot;, &quot;&lt;&quot;, &quot;&gt;&quot;, &quot;\\&quot;, &quot;|&quot; &quot;\r&quot;, &quot;\n&quot;,&quot;\t&quot;} 编码实现将 HMM 模型封装为独立的类 HMM_Model class HMM_Model: def __init__(self): pass #初始化 def setup(self): pass #模型保存 def save(self, filename, code): pass #模型加载 def load(self, filename, code): pass #模型训练 def do_train(self, observes, states): pass #HMM计算 def get_prob(self): pass #模型预测 def do_predict(self, sequence): pass 第一个方法 __init__()是一种特殊的方法，被称为类的构造函数或初始化方法，当创建了这个类的实例时就会调用该方法，其中定义了数据结构和初始变量，实现如下： def __init__(self): self.trans_mat = {} self.emit_mat = {} self.init_vec = {} self.state_count = {} self.states = {} self.inited = False 其中的数据结构定义： trans_mat：状态转移矩阵，trans_mat[state1][state2] 表示训练集中由 state1 转移到 state2 的次数。 emit_mat：观测矩阵，emit_mat[state][char] 表示训练集中单字 char 被标注为 state 的次数。 init_vec：初始状态分布向量，init_vec[state] 表示状态 state 在训练集中出现的次数。 state_count：状态统计向量，state_count[state]表示状态 state 出现的次数。 word_set：词集合，包含所有单词。第二个方法 setup()，初始化第一个方法中的数据结构，具体实现如下：#初始化数据结构 def setup(self): for state in self.states: # build trans_mat self.trans_mat[state] = {} for target in self.states: self.trans_mat[state][target] = 0.0 self.emit_mat[state] = {} self.init_vec[state] = 0 self.state_count[state] = 0 self.inited = True 第三个方法 save()，用来保存训练好的模型，filename 指定模型名称，默认模型名称为 hmm.json，这里提供两种格式的保存类型，JSON 或者pickle 格式，通过参数 code 来决定，code 的值为 code=&#39;json&#39; 或者 code = &#39;pickle&#39;，默认为code=&#39;json&#39;，具体实现如下：#模型保存 def save(self, filename=&quot;hmm.json&quot;, code=&#39;json&#39;): fw = open(filename, &#39;w&#39;, encoding=&#39;utf-8&#39;) data = { &quot;trans_mat&quot;: self.trans_mat, &quot;emit_mat&quot;: self.emit_mat, &quot;init_vec&quot;: self.init_vec, &quot;state_count&quot;: self.state_count } if code == &quot;json&quot;: txt = json.dumps(data) txt = txt.encode(&#39;utf-8&#39;).decode(&#39;unicode-escape&#39;) fw.write(txt) elif code == &quot;pickle&quot;: pickle.dump(data, fw) fw.close() 第四个方法 load()，与第三个 save() 方法对应，用来加载模型，filename 指定模型名称，默认模型名称为hmm.json，这里提供两种格式的保存类型，JSON 或者 pickle 格式，通过参数 code 来决定，code 的值为 code=&#39;json&#39;或者 code = &#39;pickle&#39;，默认为 code=&#39;json&#39;，具体实现如下： #模型加载 def load(self, filename=&quot;hmm.json&quot;, code=&quot;json&quot;): fr = open(filename, &#39;r&#39;, encoding=&#39;utf-8&#39;) if code == &quot;json&quot;: txt = fr.read() model = json.loads(txt) elif code == &quot;pickle&quot;: model = pickle.load(fr) self.trans_mat = model[&quot;trans_mat&quot;] self.emit_mat = model[&quot;emit_mat&quot;] self.init_vec = model[&quot;init_vec&quot;] self.state_count = model[&quot;state_count&quot;] self.inited = True fr.close() 第五个方法 do_train()，用来训练模型，因为使用的标注数据集， 因此可以使用更简单的监督学习算法，训练函数输入观测序列和状态序列进行训练，依次更新各矩阵数据。类中维护的模型参数均为频数而非频率，这样的设计使得模型可以进行在线训练，使得模型随时都可以接受新的训练数据继续训练，不会丢失前次训练的结果。具体实现如下： #模型训练 def do_train(self, observes, states): if not self.inited: self.setup() for i in range(len(states)): if i == 0: self.init_vec[states[0]] += 1 self.state_count[states[0]] += 1 else: self.trans_mat[states[i - 1]][states[i]] += 1 self.state_count[states[i]] += 1 if observes[i] not in self.emit_mat[states[i]]: self.emit_mat[states[i]][observes[i]] = 1 else: self.emit_mat[states[i]][observes[i]] += 1 第六个方法 get_prob()，在进行预测前，需将数据结构的频数转换为频率，具体实现如下： #频数转频率 def get_prob(self): init_vec = {} trans_mat = {} emit_mat = {} default = max(self.state_count.values()) for key in self.init_vec: if self.state_count[key] != 0: init_vec[key] = float(self.init_vec[key]) / self.state_count[key] else: init_vec[key] = float(self.init_vec[key]) / default for key1 in self.trans_mat: trans_mat[key1] = {} for key2 in self.trans_mat[key1]: if self.state_count[key1] != 0: trans_mat[key1][key2] = float(self.trans_mat[key1][key2]) / self.state_count[key1] else: trans_mat[key1][key2] = float(self.trans_mat[key1][key2]) / default for key1 in self.emit_mat: emit_mat[key1] = {} for key2 in self.emit_mat[key1]: if self.state_count[key1] != 0: emit_mat[key1][key2] = float(self.emit_mat[key1][key2]) / self.state_count[key1] else: emit_mat[key1][key2] = float(self.emit_mat[key1][key2]) / default return init_vec, trans_mat, emit_mat 第七个方法 do_predict()，预测采用 Viterbi 算法求得最优路径， 具体实现如下： #模型预测 def do_predict(self, sequence): tab = [{}] path = {} init_vec, trans_mat, emit_mat = self.get_prob() # 初始化 for state in self.states: tab[0][state] = init_vec[state] * emit_mat[state].get(sequence[0], EPS) path[state] = [state] # 创建动态搜索表 for t in range(1, len(sequence)): tab.append({}) new_path = {} for state1 in self.states: items = [] for state2 in self.states: if tab[t - 1][state2] == 0: continue prob = tab[t - 1][state2] * trans_mat[state2].get(state1, EPS) * emit_mat[state1].get(sequence[t], EPS) items.append((prob, state2)) best = max(items) tab[t][state1] = best[0] new_path[state1] = path[best[1]] + [state1] path = new_path # 搜索最有路径 prob, state = max([(tab[len(sequence) - 1][state], state) for state in self.states]) return path[state] 上面实现了类 HMM_Model 的7个方法，接下来我们来实现分词器，这里先定义两个函数，这两个函数是独立的，不在类中。 定义一个工具函数，对输入的训练语料中的每个词进行标注，因为训练数据是空格隔开的，可以进行转态标注，该方法用在训练数据的标注，具体实现如下： def get_tags(src): tags = [] if len(src) == 1: tags = [&#39;S&#39;] elif len(src) == 2: tags = [&#39;B&#39;, &#39;E&#39;] else: m_num = len(src) - 2 tags.append(&#39;B&#39;) tags.extend([&#39;M&#39;] * m_num) tags.append(&#39;E&#39;) return tags 定义一个工具函数,根据预测得到的标注序列将输入的句子分割为词语列表，也就是预测得到的状态序列，解析成一个 list 列表进行返回，具体实现如下： def cut_sent(src, tags): word_list = [] start = -1 started = False if len(tags) != len(src): return None if tags[-1] not in {&#39;S&#39;, &#39;E&#39;}: if tags[-2] in {&#39;S&#39;, &#39;E&#39;}: tags[-1] = &#39;S&#39; else: tags[-1] = &#39;E&#39; for i in range(len(tags)): if tags[i] == &#39;S&#39;: if started: started = False word_list.append(src[start:i]) word_list.append(src[i]) elif tags[i] == &#39;B&#39;: if started: word_list.append(src[start:i]) start = i started = True elif tags[i] == &#39;E&#39;: started = False word = src[start:i+1] word_list.append(word) elif tags[i] == &#39;M&#39;: continue return word_list 最后，我们来定义分词器类 HMMSoyoger，继承 HMM_Model 类并实现中文分词器训练、分词功能，先给出 HMMSoyoger 类的结构定义： class HMMSoyoger(HMM_Model): def __init__(self, *args, **kwargs): pass #加载训练数据 def read_txt(self, filename): pass #模型训练函数 def train(self): pass #模型分词预测 def lcut(self, sentence): pass 第一个方法 init()，构造函数，定义了初始化变量，具体实现如下： def __init__(self, *args, **kwargs): super(HMMSoyoger, self).__init__(*args, **kwargs) self.states = STATES self.data = None 第二个方法 read_txt()，加载训练语料，读入文件为 txt，并且 UTF-8 编码，防止中文出现乱码，具体实现如下： #加载语料 def read_txt(self, filename): self.data = open(filename, &#39;r&#39;, encoding=&quot;utf-8&quot;) 第三个方法 train()，根据单词生成观测序列和状态序列，并通过父类的 do_train() 方法进行训练，具体实现如下： def train(self): if not self.inited: self.setup() for line in self.data: line = line.strip() if not line: continue #观测序列 observes = [] for i in range(len(line)): if line[i] == &quot; &quot;: continue observes.append(line[i]) #状态序列 words = line.split(&quot; &quot;) states = [] for word in words: if word in seg_stop_words: continue states.extend(get_tags(word)) #开始训练 if(len(observes) &gt;= len(states)): self.do_train(observes, states) else: pass 第四个方法 lcut()，模型训练好之后，通过该方法进行分词测试，具体实现如下： def lcut(self, sentence): try: tags = self.do_predict(sentence) return cut_sent(sentence, tags) except: return sentence 通过上面两个类和两个方法，就完成了基于 HMM 的中文分词器编码，下面我们来进行模型训练和测试。 训练模型首先实例化 HMMSoyoger 类，然后通过 read_txt() 方法加载语料，再通过 train()进行在线训练，如果训练语料比较大，可能需要等待一点时间，具体实现如下： soyoger = HMMSoyoger() soyoger.read_txt(&quot;syj_trainCorpus_utf8.txt&quot;) soyoger.train() 模型测试模型训练完成之后，我们就可以进行测试： soyoger.lcut(&quot;中国的人工智能发展进入高潮阶段。&quot;) 得到结果为： [‘中国’, ‘的’, ‘人工’, ‘智能’, ‘发展’, ‘进入’, ‘高潮’, ‘阶段’, ‘。’] soyoger.lcut(&quot;中文自然语言处理是人工智能技术的一个重要分支。&quot;) 得到结果为： [‘中文’, ‘自然’, ‘语言’, ‘处理’, ‘是人’, ‘工智’, ‘能技’, ‘术的’, ‘一个’, ‘重要’, ‘分支’, ‘。’] 可见，最后的结果还是不错的，如果想取得更好的结果，可自行制备更大更丰富的训练数据集。 基于 CRF 的开源中文分词工具 Genius 实践Genius 是一个基于 CRF 的开源中文分词工具，采用了 Wapiti 做训练与序列标注，支持 Python 2.x、Python 3.x。 安装（1）下载源码 在 Github 上下载源码地址，解压源码，然后通过 python setup.py install 安装。 （2）Pypi 安装 通过执行命令：easy_install genius 或者 pip install genius 安装。 分词首先引入 Genius，然后对 text 文本进行分词。 import genius text = u&quot;&quot;&quot;中文自然语言处理是人工智能技术的一个重要分支。&quot;&quot;&quot; seg_list = genius.seg_text( text, use_combine=True, use_pinyin_segment=True, use_tagging=True, use_break=True ) print(&#39; &#39;.join([word.text for word in seg_list]) 其中，genius.seg_text 函数接受5个参数，其中 text 是必填参数： text 第一个参数为需要分词的字。 use_break 代表对分词结构进行打断处理，默认值 True。 use_combine 代表是否使用字典进行词合并，默认值 False。 use_tagging 代表是否进行词性标注，默认值 True。 use_pinyin_segment 代表是否对拼音进行分词处理，默认值 True。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>crf</tag>
        <tag>hmm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于ML的中文短文本分类（6）]]></title>
    <url>%2F2019%2F11%2F22%2F6.%E5%9F%BA%E4%BA%8EML%E7%9A%84%E4%B8%AD%E6%96%87%E7%9F%AD%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[对每一条输入数据，判断事情的主体是谁 语料加载 分词 去停用词 抽取词向量特征 分别进行算法建模和模型训练 评估、计算 AUC 值 模型对比语料加载 import random import jieba import pandas as pd #加载停用词 stopwords=pd.read_csv(&#39;stopwords.txt&#39;,index_col=False,quoting=3,sep=&quot;\t&quot;,names=[&#39;stopword&#39;], encoding=&#39;utf-8&#39;) stopwords=stopwords[&#39;stopword&#39;].values #加载语料 laogong_df = pd.read_csv(&#39;beilaogongda.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) laopo_df = pd.read_csv(&#39;beilaogongda.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) erzi_df = pd.read_csv(&#39;beierzida.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) nver_df = pd.read_csv(&#39;beinverda.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) #删除语料的nan行 laogong_df.dropna(inplace=True) laopo_df.dropna(inplace=True) erzi_df.dropna(inplace=True) nver_df.dropna(inplace=True) #提取要分词的 content 列转换为 list 列表 laogong = laogong_df.segment.values.tolist() laopo = laopo_df.segment.values.tolist() erzi = erzi_df.segment.values.tolist() nver = nver_df.segment.values.tolist() 分词和去停用词#定义分词、去停用词和批量打标签的函数 #参数content_lines即为语料列表 上面转换的list #参数sentences是先定义的 list，用来存储分词并打标签后的结果 #参数category 是类型标签 def preprocess_text(content_lines, sentences, category): for line in content_lines: try: segs=jieba.lcut(line) segs = [v for v in segs if not str(v).isdigit()]#去数字 segs = list(filter(lambda x:x.strip(), segs)) #去左右空格 segs = list(filter(lambda x:len(x)&gt;1, segs)) #长度为1的字符 segs = list(filter(lambda x:x not in stopwords, segs)) #去掉停用词 sentences.append((&quot; &quot;.join(segs), category))# 打标签 except Exception: print(line) continue # 调用函数、生成训练数据，根据我提供的司法语料数据，分为报警人被老公打，报警人被老婆打，报警人被儿子打，报警人被女儿打，标签分别为0、1、2、3 sentences = [] preprocess_text(laogong, sentences,0) preprocess_text(laopo, sentences, 1) preprocess_text(erzi, sentences, 2) preprocess_text(nver, sentences, 3) # 将得到的数据集打散，生成更可靠的训练集分布，避免同类数据分布不均匀 random.shuffle(sentences) # 控制台输出前10条数据 for sentence in sentences[:10]: print(sentence[0], sentence[1]) #下标0是词列表，1是标签 抽取词向量特征# 抽取特征，我们定义文本抽取词袋模型特征 from sklearn.feature_extraction.text import CountVectorizer vec = CountVectorizer( analyzer=&#39;word&#39;, # tokenise by character ngrams max_features=4000, # keep the most common 1000 ngrams ) # 把语料数据切分，用 sk-learn 对数据切分，分成训练集和测试集 from sklearn.model_selection import train_test_split x, y = zip(*sentences) x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1256) # 把训练数据转换为词袋模型 vec.fit(x_train) 分别进行算法建模和模型训练# 定义朴素贝叶斯模型，然后对训练集进行模型训练，直接使用 sklearn 中的 MultinomialNB from sklearn.naive_bayes import MultinomialNB classifier = MultinomialNB() classifier.fit(vec.transform(x_train), y_train)评估、计算 AUC 值# 评分为 0.647331786543。 print(classifier.score(vec.transform(x_test), y_test)) # 测试集的预测 pre = classifier.predict(vec.transform(x_test)) 模型对比改变特征向量模型和训练模型对结果有什么变化。 ## 改变特征向量模型:把特征做得更强一点，尝试加入抽取 2-gram 和 3-gram 的统计特征，把词库的量放大一点 from sklearn.feature_extraction.text import CountVectorizer vec = CountVectorizer( analyzer=&#39;word&#39;, # tokenise by character ngrams ngram_range=(1,4), # use ngrams of size 1 and 2 max_features=20000, # keep the most common 1000 ngrams ) vec.fit(x_train) #用朴素贝叶斯算法进行模型训练 classifier = MultinomialNB() classifier.fit(vec.transform(x_train), y_train) #对结果进行评分 结果评分为：0.649651972158 print(classifier.score(vec.transform(x_test), y_test)) ## SVM 训练 from sklearn.svm import SVC svm = SVC(kernel=&#39;linear&#39;) svm.fit(vec.transform(x_train), y_train) print(svm.score(vec.transform(x_test), y_test)) ## 使用决策树、随机森林、XGBoost、神经网络 import xgboost as xgb from sklearn.model_selection import StratifiedKFold import numpy as np # xgb矩阵赋值 xgb_train = xgb.DMatrix(vec.transform(x_train), label=y_train) xgb_test = xgb.DMatrix(vec.transform(x_test)) 在 XGBoost 中，下面主要是调参指标，可以根据参数进行调参 params = { &#39;booster&#39;: &#39;gbtree&#39;, #使用gbtree &#39;objective&#39;: &#39;multi:softmax&#39;, # 多分类的问题、 # &#39;objective&#39;: &#39;multi:softprob&#39;, # 多分类概率 #&#39;objective&#39;: &#39;binary:logistic&#39;, #二分类 &#39;eval_metric&#39;: &#39;merror&#39;, #logloss &#39;num_class&#39;: 4, # 类别数，与 multisoftmax 并用 &#39;gamma&#39;: 0.1, # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。 &#39;max_depth&#39;: 8, # 构建树的深度，越大越容易过拟合 &#39;alpha&#39;: 0, # L1正则化系数 &#39;lambda&#39;: 10, # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。 &#39;subsample&#39;: 0.7, # 随机采样训练样本 &#39;colsample_bytree&#39;: 0.5, # 生成树时进行的列采样 &#39;min_child_weight&#39;: 3, # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言 # 假设 h 在 0.01 附近，min_child_weight 为 1 叶子节点中最少需要包含 100 个样本。 &#39;silent&#39;: 0, # 设置成1则没有运行信息输出，最好是设置为0. &#39;eta&#39;: 0.03, # 如同学习率 &#39;seed&#39;: 1000, &#39;nthread&#39;: -1, # cpu 线程数 &#39;missing&#39;: 1 }]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>jieba</tag>
        <tag>auc</tag>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neo4j从入门到构建一个简单知识图谱（20）]]></title>
    <url>%2F2019%2F11%2F22%2F20.Neo4j%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%2F</url>
    <content type="text"><![CDATA[Neo4j 对于大多数人来说，可能是比较陌生的。其实，Neo4j 是一个图形数据库，就像传统的关系数据库中的 Oracel 和MySQL一样，用来持久化数据。Neo4j 是最近几年发展起来的新技术，属于 NoSQL 数据库中的一种。 本文主要从 Neo4j 为什么被用来做知识图谱，Neo4j 的简单安装，在 Neo4j 浏览器中创建节点和关系，Neo4j 的 Python 接口操作以及用Neo4j 构建一个简单的农业知识图谱五个方面来讲。 Neo4j 为什么被用来做知识图谱从第19课《知识挖掘与知识图谱概述》中，我们已经明白，知识图谱是一种基于图的数据结构，由节点和边组成。其中节点即实体，由一个全局唯一的 ID标示，关系（也称属性）用于连接两个节点。通俗地讲，知识图谱就是把所有不同种类的信息连接在一起而得到一个关系网络，提供了从“关系”的角度去分析问题的能力。 而 Neo4j 作为一种经过特别优化的图形数据库，有以下优势： 数据存储 ：不像传统数据库整条记录来存储数据，Neo4j 以图的结构存储，可以存储图的节点、属性和边。属性、节点都是分开存储的，属性与节点的关系构成边，这将大大有助于提高数据库的性能。 数据读写 ：在 Neo4j 中，存储节点时使用了 Index-free Adjacency 技术，即每个节点都有指向其邻居节点的指针，可以让我们在时间复杂度为 O(1) 的情况下找到邻居节点。另外，按照官方的说法，在 Neo4j 中边是最重要的，是 First-class Entities，所以单独存储，更有利于在图遍历时提高速度，也可以很方便地以任何方向进行遍历。 资源丰富 ：Neo4j 作为较早的一批图形数据库之一，其文档和各种技术博客较多。 同类对比 ：Flockdb 安装过程中依赖太多，安装复杂；Orientdb，Arangodb 与 Neo4j 做对比，从易用性来说都差不多，但是从稳定性来说，neo4j 是最好的。 综合上述以及因素，我认为 Neo4j 是做知识图谱比较简单、灵活、易用的图形数据库。 Neo4j 的简单安装Neo4j 是基于 Java 的图形数据库，运行 Neo4j 需要启动 JVM 进程，因此必须安装 Java SE 的 JDK。从 Oracle官方网站下载 Java SEJDK，选择版本JDK8 以上版本即可。 下面简单介绍下 Neo4j 在 Linux 和 Windows的安装过程。首先去官网下载对应版本。解压之后，Neo4j 应用程序有如下主要的目录结构： bin 目录：用于存储 Neo4j 的可执行程序； conf 目录：用于控制 Neo4j 启动的配置文件； data 目录：用于存储核心数据库文件； plugins 目录：用于存储 Neo4j 的插件。 Linux 系统下的安装通过 tar 解压命令解压到一个目录下： tar -xzvf neo4j-community-3.3.1-unix.tar.gz 然后进入 Neo4j 解压目录： cd /usr/local/neo4j/neo4j-community-3.1.0 通过启动命令，可以实现启动、控制台、停止服务： bin/neo4j start/console/stop（启动/控制台/停止） 通过 cypher-shell 命令，可以进入命令行： bin/cypher-shell Windows 系统下的安装启动 DOS 命令行窗口，切换到解压目录 bin 下，以管理员身份运行命令，分别为启动服务、停止服务、重启服务和查询服务的状态： bin\neo4j start bin\neo4j stop bin\neo4j restart bin\neo4j status 把 Neo4j 安装为服务（Windows Services），可通过以下命令： bin\neo4j install-service bin\neo4j uninstall-service Neo4j 的配置文档存储在 conf 目录下，Neo4j 通过配置文件 neo4j.conf控制服务器的工作。默认情况下，不需要进行任意配置，就可以启动服务器。 下面我们在 Windows 环境下启动 Neo4j： Neo4j 服务器具有一个集成的浏览器，在一个运行的服务器实例上访问： http://localhost:7474/，打开浏览器，显示启动页面： 默认的 Host 是 bolt://localhost:7687，默认的用户是 neo4j，其默认的密码是 neo4j，第一次成功登录到 Neo4j服务器之后，需要重置密码。访问 Graph Database 需要输入身份验证，Host 是 Bolt 协议标识的主机。登录成功后界面： 到此为止，我们就完成了 Neo4j 的基本安装过程，更详细的参数配置，可以参考官方文档。 在 Neo4j 浏览器中创建节点和关系下面，我们简单编写 Cypher 命令，Cypher 命令可以通过 Neo4j教程学习，在浏览器中通过 Neo4j 创建两个节点和两个关系。 在 $ 命令行中，编写 Cypher 脚本代码，点击 Play 按钮完成创建，依次执行下面的语句： CREATE (n:Person { name: &#39;Andres&#39;, title: &#39;Developer&#39; }) return n; 作用是创建一个 Person，并包含属性名字和职称。 下面这条语句也创建了一个 Person 对象，属性中只是名字和职称不一样。 CREATE (n:Person { name: &#39;Vic&#39;, title: &#39;Developer&#39; }) return n; 紧接着，通过下面两行命令进行两个 Person 的关系匹配： match(n:Person{name:&quot;Vic&quot;}),(m:Person{name:&quot;Andres&quot;}) create (n)-[r:Friend]-&gt;(m) return r; match(n:Person{name:&quot;Vic&quot;}),(m:Person{name:&quot;Andres&quot;}) create (n)&lt;-[r:Friend]-(m) return r; 最后，在创建完两个节点和关系之后，查看数据库中的图形： match(n) return n; 如下图，返回两个 Person 节点，以及其关系网，两个 Person 之间组成 Friend 关系： Neo4j 的 Python 操作既然 Neo4j 作为一个图库数据库，那我们在项目中使用的时候，必然不能通过上面那种方式完成任务，一般都要通过代码来完成数据的持久化操作。其中，对于Java 编程者来说，可通过 Spring Data Neo4j 达到这一目的。 而对于 Python 开发者来说，Py2neo 库也可以完成对 Neo4j 的操作，操作过程如下。 首先 安装 Py2neo。Py2neo 的安装过程非常简单，在命令行通过下面命令即可安装成功。 pip install py2neo 安装好之后，我们来看一下简单的图关系构建，看下面代码： from py2neo.data import Node, Relationship a = Node(&quot;Person&quot;, name=&quot;Alice&quot;) b = Node(&quot;Person&quot;, name=&quot;Bob&quot;) ab = Relationship(a, &quot;KNOWS&quot;, b) 第一行代码，首先引入 Node 和 Relationship 对象，紧接着，创建 a 和 b 节点对象，最后一行匹配 a 和 b之间的工作雇佣关系。接着来看看 ab 对象的内容是什么： print(ab) 通过 print 打印出 ab 的内容： (Alice)-[:KNOWS {}]-&gt;(Bob) 通过这样，就完成了 Alice 和 Bob 之间的工作关系，如果有多组关系将构建成 Person 之间的一个关系网。 了解更多 Py2neo 的使用方法，建议查看官方文档。 用 Neo4j 构建一个简单的农业知识图谱我们来看一个基于开源语料的简单农业知识图谱，由于过程比较繁杂，数据和知识图谱数据预处理过程这里不再赘述，下面，我们重点看基于 Neo4j来创建知识图谱的过程。 整个过程主要包含以下步骤： 环境准备 语料准备 语料加载 知识图谱查询展示 Neo4j 环境准备。根据上面对 Neo4j 环境的介绍，这里默认你已经搭建好 Neo4j 的环境，并能正常访问，如果没有环境，请自行搭建好 Neo4j 的可用环境。 数据语料介绍。本次提供的语料是已经处理好的数据，包含6个 csv 文件，文件内容和描述如下。 attributes.csv：文件大小 2M，内容是通过互动百科页面得到的部分实体的属性，包含字段：Entity、AttributeName、Attribute，分别表示实体、属性名称、属性值。文件前5行结构如下： Entity,AttributeName,Attribute 密度板,别名,纤维板 葡萄蔓枯病,主要为害部位,枝蔓 坎德拉,性别,男 坎德拉,国籍,法国 坎德拉,场上位置,后卫 hudong_pedia.csv：文件大小 94.6M，内容是已经爬好的农业实体的百科页面的结构化数据，包含字段：title、url、image、openTypeList、detail、baseInfoKeyList、baseInfoValueList，分别表示名称、百科 URL 地址、图片、分类类型、详情、关键字、依据来源。文件前2行结构如下： &quot;title&quot;,&quot;url&quot;,&quot;image&quot;,&quot;openTypeList&quot;,&quot;detail&quot;,&quot;baseInfoKeyList&quot;,&quot;baseInfoValueList&quot; &quot;菊糖&quot;,&quot;http://www.baike.com/wiki/菊糖&quot;,&quot;http://a0.att.hudong.com/72/85/20200000013920144736851207227_s.jpg&quot;,&quot;健康科学##分子生物学##化学品##有机物##科学##自然科学##药品##药学名词##药物中文名称列表&quot;,&quot;[药理作用] 诊断试剂 人体内不含菊糖，静注后，不被机体分解、结合、利用和破坏，经肾小球滤过，通过测定血中和尿中的菊糖含量，可以准确计算肾小球的滤过率。菊糖广泛存在于植物组织中,约有3.6万种植物中含有菊糖,尤其是菊芋、菊苣块根中含有丰富的菊糖[6,8]。菊芋(Jerusalem artichoke)又名洋姜,多年生草本植物,在我国栽种广泛,其适应性广、耐贫瘠、产量高、易种植,一般亩产菊芋块茎为2 000～4 000 kg,菊芋块茎除水分外,还含有15%～20%的菊糖,是加工生产菊糖及其制品的良好原料。&quot;,&quot;中文名：&quot;,&quot;菊糖&quot; &quot;密度板&quot;,&quot;http://www.baike.com/wiki/密度板&quot;,&quot;http://a0.att.hudong.com/64/31/20200000013920144728317993941_s.jpg&quot;,&quot;居家##巧克力包装##应用科学##建筑材料##珠宝盒##礼品盒##科学##糖果盒##红酒盒##装修##装饰材料##隔断##首饰盒&quot;,&quot;密度板（英文：Medium Density Fiberboard (MDF)）也称纤维板，是以木质纤维或其他植物纤维为原料，施加脲醛树脂或其他适用的胶粘剂制成的人造板材。按其密度的不同，分为高密度板、中密度板、低密度板。密度板由于质软耐冲击，也容易再加工，在国外是制作家私的一种良好材料，但由于国家关于高密度板的标准比国际标准低数倍，所以，密度板在中国的使用质量还有待提高。&quot;,&quot;中文名：##全称：##别名：##主要材料：##分类：##优点：&quot;,&quot;密度板##中密度板纤维板##纤维板##以木质纤维或其他植物纤维##高密度板、中密度板、低密度板##表面光滑平整、材质细密性能稳定&quot; hudong_pedia2.csv：文件大小 41M，内容结构和 hudong_pedia.csv 文件保持一致，只是增加数据量，作为 hudong_pedia.csv 数据的补充。 new_node.csv：文件大小 2.28M，内容是节点名称和标签，包含字段：title、lable，分别表示节点名称、标签，文件前5行结构如下： title,lable 药物治疗,newNode 膳食纤维,newNode Boven Merwede,newNode 亚美尼亚苏维埃百科全书,newNode wikidata_relation.csv：文件大小 1.83M，内容是实体和关系，包含字段 HudongItem1、relation、HudongItem2，分别表示实体1、关系、实体2，文件前5行结构如下： HudongItem1,relation,HudongItem2 菊糖,instance of,化合物 菊糖,instance of,多糖 瓦尔,instance of,河流 菊糖,subclass of,食物 瓦尔,origin of the watercourse,莱茵河 wikidata_relation2.csv：大小 7.18M，内容结构和 wikidata_relation.csv 一致，作为 wikidata_relation.csv 数据的补充。 语料加载。语料加载，利用 Neo4j 的 LOAD CSV WITH HEADERS FROM... 功能进行加载，具体操作过程如下。 首先，依次执行以下命令： // 将hudong_pedia.csv 导入 LOAD CSV WITH HEADERS FROM &quot;file:///hudong_pedia.csv&quot; AS line CREATE (p:HudongItem{title:line.title,image:line.image,detail:line.detail,url:line.url,openTypeList:line.openTypeList,baseInfoKeyList:line.baseInfoKeyList,baseInfoValueList:line.baseInfoValueList}) 执行成功之后，控制台显示成功： 上面这张图，表示数据加载成功，并显示加载的数据条数和耗费的时间。 // 新增了hudong_pedia2.csv LOAD CSV WITH HEADERS FROM &quot;file:///hudong_pedia2.csv&quot; AS line CREATE (p:HudongItem{title:line.title,image:line.image,detail:line.detail,url:line.url,openTypeList:line.openTypeList,baseInfoKeyList:line.baseInfoKeyList,baseInfoValueList:line.baseInfoValueList}) // 创建索引 CREATE CONSTRAINT ON (c:HudongItem) ASSERT c.title IS UNIQUE 以上命令的意思是，将 hudong_pedia.csv 和 hudong_pedia2.csv 导入 Neo4j 作为结点，然后对 titile属性添加 UNIQUE（唯一约束/索引）。 注意： 如果导入的时候出现 Neo4j JVM 内存溢出错误，可以在导入前，先把 Neo4j 下的 conf/neo4j.conf 中的dbms.memory.heap.initial_size 和 dbms.memory.heap.max_size调大点。导入完成后再把值改回去即可。 下面继续执行数据导入命令： // 导入新的节点 LOAD CSV WITH HEADERS FROM &quot;file:///new_node.csv&quot; AS line CREATE (:NewNode { title: line.title }) //添加索引 CREATE CONSTRAINT ON (c:NewNode) ASSERT c.title IS UNIQUE //导入hudongItem和新加入节点之间的关系 LOAD CSV WITH HEADERS FROM &quot;file:///wikidata_relation2.csv&quot; AS line MATCH (entity1:HudongItem{title:line.HudongItem}) , (entity2:NewNode{title:line.NewNode}) CREATE (entity1)-[:RELATION { type: line.relation }]-&gt;(entity2) LOAD CSV WITH HEADERS FROM &quot;file:///wikidata_relation.csv&quot; AS line MATCH (entity1:HudongItem{title:line.HudongItem1}) , (entity2:HudongItem{title:line.HudongItem2}) CREATE (entity1)-[:RELATION { type: line.relation }]-&gt;(entity2) 执行完这些命令后，我们导入 new_node.csv 新节点，并对 titile 属性添加 UNIQUE（唯一约束/索引），导入wikidata_relation.csv 和 wikidata_relation2.csv，并给节点之间创建关系。 紧接着，继续导入实体属性，并创建实体之间的关系： LOAD CSV WITH HEADERS FROM &quot;file:///attributes.csv&quot; AS line MATCH (entity1:HudongItem{title:line.Entity}), (entity2:HudongItem{title:line.Attribute}) CREATE (entity1)-[:RELATION { type: line.AttributeName }]-&gt;(entity2); LOAD CSV WITH HEADERS FROM &quot;file:///attributes.csv&quot; AS line MATCH (entity1:HudongItem{title:line.Entity}), (entity2:NewNode{title:line.Attribute}) CREATE (entity1)-[:RELATION { type: line.AttributeName }]-&gt;(entity2); LOAD CSV WITH HEADERS FROM &quot;file:///attributes.csv&quot; AS line MATCH (entity1:NewNode{title:line.Entity}), (entity2:NewNode{title:line.Attribute}) CREATE (entity1)-[:RELATION { type: line.AttributeName }]-&gt;(entity2); LOAD CSV WITH HEADERS FROM &quot;file:///attributes.csv&quot; AS line MATCH (entity1:NewNode{title:line.Entity}), (entity2:HudongItem{title:line.Attribute}) CREATE (entity1)-[:RELATION { type: line.AttributeName }]-&gt;(entity2) 这里注意，建索引的时候带了 label，因此只有使用 label 时才会使用索引，这里我们的实体有两个 label，所以一共做 2*2=4次。当然也可以建立全局索引，即对于不同的 label 使用同一个索引。 以上过程，我们就完成了语料加载，并创建了实体之间的关系和属性匹配，下面我们来看看 Neo4j 图谱关系展示。 知识图谱查询展示最后通过 cypher 语句查询来看看农业图谱展示。 首先，展示 HudongItem 实体，执行如下命令： MATCH (n:HudongItem) RETURN n LIMIT 25 对 HudongItem 实体进行查询，返回结果的25条数据，结果如下图： 接着，展示 NewNode 实体，执行如下命令： MATCH (n:NewNode) RETURN n LIMIT 25 对 NewNode 实体进行查询，返回结果的25条数据，结果如下图： 之后，展示 RELATION 直接的关系，执行如下命令： MATCH p=()-[r:RELATION]-&gt;() RETURN p LIMIT 25 展示实体属性关系，结果如下图： 总结本节内容到此结束，回顾下整篇文章，主要讲了以下内容： 解释了 Neo4j 被用来做知识图谱的原因； Neo4j 的简单安装以及在 Neo4j 浏览器中创建节点和关系； Neo4j 的 Python 接口操作及使用； 从五个方面讲解了如何使用 Neo4j 构建一个简单的农业知识图谱。 最后，强调一句，知识图谱未来会通过自然语言处理技术和搜索技术结合应用会越来越广，工业界所出的地位也会越来越重要。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于情感词典的文本情感分析（12）]]></title>
    <url>%2F2019%2F11%2F22%2F12.%E5%9F%BA%E4%BA%8E%E6%83%85%E6%84%9F%E8%AF%8D%E5%85%B8%E7%9A%84%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[目前情感分析在中文自然语言处理中比较火热，很多场景下，我们都需要用到情感分析。比如，做金融产品量化交易，需要根据爬取的舆论数据来分析政策和舆论对股市或者基金期货的态度；电商交易，根据买家的评论数据，来分析商品的预售率等等。 下面我们通过以下几点来介绍中文自然语言处理情感分析： 中文情感分析方法简介； SnowNLP 快速进行评论数据情感分析； 基于标注好的情感词典来计算情感值； pytreebank 绘制情感树； 股吧数据情感分类。 中文情感分析方法简介情感倾向可认为是主体对某一客体主观存在的内心喜恶，内在评价的一种倾向。它由两个方面来衡量：一个情感倾向方向，一个是情感倾向度。 目前，情感倾向分析的方法主要分为两类：一种是基于情感词典的方法；一种是基于机器学习的方法，如基于大规模语料库的机器学习。前者需要用到标注好的情感词典；后者则需要大量的人工标注的语料作为训练集，通过提取文本特征，构建分类器来实现情感的分类。 文本情感分析的分析粒度可以是词语、句子、段落或篇章。 段落篇章级情感分析主要是针对某个主题或事件进行情感倾向判断，一般需要构建对应事件的情感词典，如电影评论的分析，需要构建电影行业自己的情感词典，这样效果会比通用情感词典更好；也可以通过人工标注大量电影评论来构建分类器。句子级的情感分析大多通过计算句子里包含的所有情感词的值来得到。 篇章级的情感分析，也可以通过聚合篇章中所有的句子的情感倾向来计算得出。因此，针对句子级的情感倾向分析，既能解决短文本的情感分析，同时也是篇章级文本情感分析的基础。 中文情感分析的一些难点，比如句子是由词语根据一定的语言规则构成的，应该把句子中词语的依存关系纳入到句子情感的计算过程中去，不同的依存关系，进行情感倾向计算是不一样的。文档的情感，根据句子对文档的重要程度赋予不同权重，调整其对文档情感的贡献程度等。 SnowNLP 快速进行评论数据情感分析如果有人问，有没有比较快速简单的方法能判断一句话的情感倾向，那么 SnowNLP 库就是答案。 SnowNLP 主要可以进行中文分词、词性标注、情感分析、文本分类、转换拼音、繁体转简体、提取文本关键词、提取摘要、分割句子、文本相似等。 需要注意的是，用 SnowNLP进行情感分析，官网指出进行电商评论的准确率较高，其实是因为它的语料库主要是电商评论数据，但是可以自己构建相关领域语料库，替换单一的电商评论语料，准确率也挺不错的。 1. SnowNLP 安装。 （1） 使用 pip 安装： pip install snownlp==0.11.1 （2）使用 Github 源码安装。 首先，下载 SnowNLP 的 Github源码并解压，在解压目录，通过下面命令安装： python setup.py install 以上方式，二选一安装完成之后，就可以引入 SnowNLP 库使用了。 from snownlp import SnowNLP 2. 评论语料获取情感值。 首先，SnowNLP 对情感的测试值为0到1，值越大，说明情感倾向越积极。下面我们通过 SnowNLP 测试在京东上找的好评、中评、差评的结果。 首先，引入 SnowNLP 库： from snownlp import SnowNLP （1） 测试一条京东的好评数据： SnowNLP(u&#39;本本已收到，体验还是很好，功能方面我不了解，只看外观还是很不错很薄，很轻，也有质感。&#39;).sentiments 得到的情感值很高，说明买家对商品比较认可，情感值为： 0.999950702449061 （2）测试一条京东的中评数据： SnowNLP(u&#39;屏幕分辨率一般，送了个极丑的鼠标。&#39;).sentiments 得到的情感值一般，说明买家对商品看法一般，甚至不喜欢，情感值为： 0.03251402883400323 （3）测试一条京东的差评数据： SnowNLP(u&#39;很差的一次购物体验，细节做得极差了，还有发热有点严重啊，散热不行，用起来就是烫得厉害，很垃圾！！！&#39;).sentiments 得到的情感值一般，说明买家对商品不认可，存在退货嫌疑，情感值为： 0.0036849517156107847 以上就完成了简单快速的情感值计算，对评论数据是不是很好用呀！！！ 使用 SnowNLP 来计算情感值，官方推荐的是电商评论数据计算准确度比较高，难道非评论数据就不能使用 SnowNLP 来计算情感值了吗？当然不是，虽然SnowNLP 默认提供的模型是用评论数据训练的，但是它还支持我们根据现有数据训练自己的模型。 首先我们来看看自定义训练模型的 源码 Sentiment 类 ，代码定义如下： class Sentiment(object): def __init__(self): self.classifier = Bayes() def save(self, fname, iszip=True): self.classifier.save(fname, iszip) def load(self, fname=data_path, iszip=True): self.classifier.load(fname, iszip) def handle(self, doc): words = seg.seg(doc) words = normal.filter_stop(words) return words def train(self, neg_docs, pos_docs): data = [] for sent in neg_docs: data.append([self.handle(sent), &#39;neg&#39;]) for sent in pos_docs: data.append([self.handle(sent), &#39;pos&#39;]) self.classifier.train(data) def classify(self, sent): ret, prob = self.classifier.classify(self.handle(sent)) if ret == &#39;pos&#39;: return prob return 1-prob 通过源代码，我们可以看到，可以使用 train方法训练数据，并使用 save 方法和 load 方法保存与加载模型。下面训练自己的模型，训练集pos.txt 和 neg.txt 分别表示积极和消极情感语句，两个 TXT 文本中每行表示一句语料。 下面代码进行自定义模型训练和保存： from snownlp import sentiment sentiment.train(&#39;neg.txt&#39;, &#39;pos.txt&#39;) sentiment.save(&#39;sentiment.marshal&#39;) 基于标注好的情感词典来计算情感值这里我们使用一个行业标准的情感词典——玻森情感词典，来自定义计算一句话、或者一段文字的情感值。 整个过程如下： 加载玻森情感词典； jieba 分词； 获取句子得分。 首先引入包： import pandas as pd import jieba 接下来加载情感词典： df = pd.read_table(&quot;bosonnlp//BosonNLP_sentiment_score.txt&quot;,sep= &quot; &quot;,names=[&#39;key&#39;,&#39;score&#39;]) 查看一下情感词典前5行： 将词 key 和对应得分 score 转成2个 list 列表，目的是找到词 key 的时候，能对应获取到 score 值： key = df[&#39;key&#39;].values.tolist() score = df[&#39;score&#39;].values.tolist() 定义分词和统计得分函数： def getscore(line): segs = jieba.lcut(line) #分词 score_list = [score[key.index(x)] for x in segs if(x in key)] return sum(score_list) #计算得分 最后来进行结果测试： line = &quot;今天天气很好，我很开心&quot; print(round(getscore(line),2)) line = &quot;今天下雨，心情也受到影响。&quot; print(round(getscore(line),2)) 获得的情感得分保留2位小数： 5.26 -0.96 pytreebank 绘制情感树1. 安装 pytreebank。 在 Github 上下载 pytreebank源码，解压之后，进入解压目录命令行，执行命令： python setup.py install 最后通过引入命令，判断是否安装成功： import pytreebank 提示，如果在 Windows 下安装之后，报错误： UnicodeDecodeError: &#39;gbk&#39; codec can&#39;t decode byte 0x92 in position 24783: illegal multibyte sequence 这是由于编码问题引起的，可以在安装目录下报错的文件中报错的代码地方加个 encoding=&#39;utf-8&#39; 编码： import_tag( &quot;script&quot;, contents=format_replacements(open(scriptname,encoding=&#39;utf-8&#39;).read(), replacements), type=&quot;text/javascript&quot; ) 2. 绘制情感树。首先引入 pytreebank 包： import pytreebank 然后，加载用来可视化的 JavaScript 和 CSS 脚本： pytreebank.LabeledTree.inject_visualization_javascript() 绘制情感树，把句子首先进行组合再绘制图形： line = &#39;(4 (0 你) (3 (2 是) (3 (3 (3 谁) (2 的)) (2 谁))))&#39; pytreebank.create_tree_from_string(line).display() 得到的情感树如下： 股吧数据情感分类但在7月15日之前，随着中美贸易战不断升级，中兴股价又上演了一场“跌跌不休”的惨状，我以中美贸易战背景下中兴通讯在股吧解禁前一段时间的评论数据，来进行情感数据人工打标签和分类。其中，把消极、中性 、积极分别用0、1、2来表示。 整个文本分类流程主要包括以下6个步骤： 中文语料； 分词； 复杂规则； 特征向量； 算法建模； 情感分析。 本次分类算法采用 CNN，首先引入需要的包： import pandas as pd import numpy as np import jieba import random import keras from keras.preprocessing import sequence from keras.models import Sequential from keras.layers import Dense, Dropout, Activation from keras.layers import Embedding from keras.layers import Conv1D, GlobalMaxPooling1D from keras.datasets import imdb from keras.models import model_from_json from keras.utils import np_utils import matplotlib.pyplot as plt 继续引入停用词和语料文件： dir = &quot;D://ProgramData//PythonWorkSpace//chat//chat8//&quot; stopwords=pd.read_csv(dir +&quot;stopwords.txt&quot;,index_col=False,quoting=3,sep=&quot;\t&quot;,names=[&#39;stopword&#39;], encoding=&#39;utf-8&#39;) stopwords=stopwords[&#39;stopword&#39;].values df_data1 = pd.read_csv(dir+&quot;data1.csv&quot;,encoding=&#39;utf-8&#39;) df_data1.head() 下图展示数据的前5行：接着进行数据预处理，把消极、中性、积极分别为0、1、2的预料分别拿出来： #把内容有缺失值的删除 df_data1.dropna(inplace=True) #抽取文本数据和标签 data_1 = df_data1.loc[:,[&#39;content&#39;,&#39;label&#39;]] #把消极 中性 积极分别为0、1、2的预料分别拿出来 data_label_0 = data_1.loc[data_1[&#39;label&#39;] ==0,:] data_label_1 = data_1.loc[data_1[&#39;label&#39;] ==1,:] data_label_2 = data_1.loc[data_1[&#39;label&#39;] ==2,:] 接下来，定义中文分词函数： #定义分词函数 def preprocess_text(content_lines, sentences, category): for line in content_lines: try: segs=jieba.lcut(line) segs = filter(lambda x:len(x)&gt;1, segs) segs = [v for v in segs if not str(v).isdigit()]#去数字 segs = list(filter(lambda x:x.strip(), segs)) #去左右空格 segs = filter(lambda x:x not in stopwords, segs) temp = &quot; &quot;.join(segs) if(len(temp)&gt;1): sentences.append((temp, category)) except Exception: print(line) continue 生成训练的分词数据，并进行打散，使其分布均匀： #获取数据 data_label_0_content = data_label_0[&#39;content&#39;].values.tolist() data_label_1_content = data_label_1[&#39;content&#39;].values.tolist() data_label_2_content = data_label_2[&#39;content&#39;].values.tolist() #生成训练数据 sentences = [] preprocess_text(data_label_0_content, sentences, 0) preprocess_text(data_label_1_content, sentences, 1) preprocess_text(data_label_2_content, sentences,2) #我们打乱一下顺序，生成更可靠的训练集 random.shuffle(sentences) 对数据集进行切分，按照训练集合测试集7:3的比例： #所以把原数据集分成训练集的测试集，咱们用sklearn自带的分割函数。 from sklearn.model_selection import train_test_split x, y = zip(*sentences) x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=1234) 然后，对特征构造词向量： #抽取特征，我们对文本抽取词袋模型特征 from sklearn.feature_extraction.text import CountVectorizer vec = CountVectorizer( analyzer=&#39;word&#39;, #tokenise by character ngrams max_features=4000, #keep the most common 1000 ngrams ) vec.fit(x_train) 定义模型参数： # 设置参数 max_features = 5001 maxlen = 100 batch_size = 32 embedding_dims = 50 filters = 250 kernel_size = 3 hidden_dims = 250 epochs = 10 nclasses = 3 输入特征转成 Array 和标签处理，打印训练集和测试集的 shape： x_train = vec.transform(x_train) x_test = vec.transform(x_test) x_train = x_train.toarray() x_test = x_test.toarray() y_train = np_utils.to_categorical(y_train,nclasses) y_test = np_utils.to_categorical(y_test,nclasses) x_train = sequence.pad_sequences(x_train, maxlen=maxlen) x_test = sequence.pad_sequences(x_test, maxlen=maxlen) print(&#39;x_train shape:&#39;, x_train.shape) print(&#39;x_test shape:&#39;, x_test.shape) 定义一个绘制 Loss 曲线的类： class LossHistory(keras.callbacks.Callback): def on_train_begin(self, logs={}): self.losses = {&#39;batch&#39;:[], &#39;epoch&#39;:[]} self.accuracy = {&#39;batch&#39;:[], &#39;epoch&#39;:[]} self.val_loss = {&#39;batch&#39;:[], &#39;epoch&#39;:[]} self.val_acc = {&#39;batch&#39;:[], &#39;epoch&#39;:[]} def on_batch_end(self, batch, logs={}): self.losses[&#39;batch&#39;].append(logs.get(&#39;loss&#39;)) self.accuracy[&#39;batch&#39;].append(logs.get(&#39;acc&#39;)) self.val_loss[&#39;batch&#39;].append(logs.get(&#39;val_loss&#39;)) self.val_acc[&#39;batch&#39;].append(logs.get(&#39;val_acc&#39;)) def on_epoch_end(self, batch, logs={}): self.losses[&#39;epoch&#39;].append(logs.get(&#39;loss&#39;)) self.accuracy[&#39;epoch&#39;].append(logs.get(&#39;acc&#39;)) self.val_loss[&#39;epoch&#39;].append(logs.get(&#39;val_loss&#39;)) self.val_acc[&#39;epoch&#39;].append(logs.get(&#39;val_acc&#39;)) def loss_plot(self, loss_type): iters = range(len(self.losses[loss_type])) plt.figure() # acc plt.plot(iters, self.accuracy[loss_type], &#39;r&#39;, label=&#39;train acc&#39;) # loss plt.plot(iters, self.losses[loss_type], &#39;g&#39;, label=&#39;train loss&#39;) if loss_type == &#39;epoch&#39;: # val_acc plt.plot(iters, self.val_acc[loss_type], &#39;b&#39;, label=&#39;val acc&#39;) # val_loss plt.plot(iters, self.val_loss[loss_type], &#39;k&#39;, label=&#39;val loss&#39;) plt.grid(True) plt.xlabel(loss_type) plt.ylabel(&#39;acc-loss&#39;) plt.legend(loc=&quot;upper right&quot;) plt.show() 然后，初始化上面类的对象，并作为模型的回调函数输入，训练模型： history = LossHistory() print(&#39;Build model...&#39;) model = Sequential() model.add(Embedding(max_features, embedding_dims, input_length=maxlen)) model.add(Dropout(0.5)) model.add(Conv1D(filters, kernel_size, padding=&#39;valid&#39;, activation=&#39;relu&#39;, strides=1)) model.add(GlobalMaxPooling1D()) model.add(Dense(hidden_dims)) model.add(Dropout(0.5)) model.add(Activation(&#39;relu&#39;)) model.add(Dense(nclasses)) model.add(Activation(&#39;softmax&#39;)) model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test),callbacks=[history]) 得到的模型迭代次数为10轮的训练过程： 最后绘制 Loss 图像： 关于本次分类，这里重点讨论的一个知识点就是数据分布不均匀的情况，我们都知道，本次贸易战中兴公司受影响很大，导致整个股票价格处于下跌趋势，所以整个舆论上，大多数评论都是消极的态度，导致数据分布极不均匀。 那数据分布不均匀一般怎么处理呢？从以下几个方面考虑： 数据采样，包括上采样、下采样和综合采样； 改变分类算法，在传统分类算法的基础上对不同类别采取不同的加权方式，使得模型更看重少数类； 采用合理的性能评价指标； 代价敏感。 总结，本文通过第三方、基于词典等方式计算中文文本情感值，以及通过情感树来进行可视化，然而这些内容只是情感分析的入门知识，情感分析还涉及句法依存等，最后通过一个CNN 分类模型，提供一种有监督的情感分类思路。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>cnn</tag>
        <tag>snownlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于CNN的电影推荐系统（10）]]></title>
    <url>%2F2019%2F11%2F22%2F10.%E5%9F%BA%E4%BA%8ECNN%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[本文从深度学习卷积神经网络入手，基于 Github 的开源项目来完成 MovieLens 数据集的电影推荐系统。 什么是推荐系统呢？什么是推荐系统呢？首先我们来看看几个常见的推荐场景。 如果你经常通过豆瓣电影评分来找电影，你会发现下图所示的推荐： 如果你喜欢购物，根据你的选择和购物行为，平台会给你推荐相似商品： 在互联网的很多场景下都可以看到推荐的影子。因为推荐可以帮助用户和商家满足不同的需求： 对用户而言：找到感兴趣的东西，帮助发现新鲜、有趣的事物。 对商家而言：提供个性化服务，提高信任度和粘性，增加营收。 常见的推荐系统主要包含两个方面的内容，基于用户的推荐系统（UserCF）和基于物品的推荐系统（ItemCF）。两者的区别在于，UserCF给用户推荐那些和他有共同兴趣爱好的用户喜欢的商品，而 ItemCF 给用户推荐那些和他之前喜欢的商品类似的商品。这两种方式都会遭遇冷启动问题。 下面是 UserCF 和 ItemCF 的对比： CNN 是如何应用在文本处理上的？提到卷积神经网络（CNN），相信大部分人首先想到的是图像分类，比如 MNIST 手写体识别，CAFRI10 图像分类。CNN已经在图像识别方面取得了较大的成果，随着近几年的不断发展，在文本处理领域，基于文本挖掘的文本卷积神经网络被证明是有效的。 首先，来看看 CNN 是如何应用到 NLP 中的，下面是一个简单的过程图： 和图像像素处理不一样，自然语言通常是一段文字，那么在特征矩阵中，矩阵的每一个行向量（比如 word2vec 或者 doc2vec）代表一个Token，包括词或者字符。如果一段文字包含有 n 个词，每个词有 m 维的词向量，那么我们可以构造出一个 n*m 的词向量矩阵，在 NLP处理过程中，让过滤器宽度和矩阵宽度保持一致整行滑动。 动手实战基于 CNN 的电影推荐系统将 CNN 的技术应用到自然语言处理中并与电影推荐相结合，来训练一个基于文本的卷积神经网络，实现电影个性化推荐系统。 首先感谢作者 chengstone 的分享，源码请访问下面网址： Github 在验证了 CNN 应用在自然语言处理上是有效的之后，从推荐系统的个性化推荐入手，在文本上，把 CNN成果应用到电影的个性化推荐上。并在特征工程中，对训练集和测试集做了相应的特征处理，其中有部分字段是类型性变量，特征工程上可以采用 one-hot编码，但是对于 UserID、MovieID 这样非常稀疏的变量，如果使用 one-hot，那么数据的维度会急剧膨胀，对于这份数据集来说是不合适的。 具体算法设计如下： 1. 定义用户嵌入矩阵。 用户的特征矩阵主要是通过用户信息嵌入网络来生成的，在预处理数据的时候，我们将UserID、MovieID、性别、年龄、职业特征全部转成了数字类型，然后把这个数字当作嵌入矩阵的索引，在网络的第一层就使用嵌入层，这样数据输入的维度保持在（N，32）和（N，16）。然后进行全连接层，转成（N，128）的大小，再进行全连接层，转成（N，200）的大小，这样最后输出的用户特征维度相对比较高，也保证了能把每个用户所带有的特征充分携带并通过特征表达。 具体流程如下： 2. 生成用户特征。 生成用户特征是在用户嵌入矩阵网络输出结果的基础上，通过2层全连接层实现的。第一个全连接层把特征矩阵转成（N，128）的大小，再进行第二次全连接层，转成（N，200）的大小，这样最后输出的用户特征维度相对比较高，也保证了能把每个用户所带有的特征充分携带并通过特征表达。 具体流程如下： 3. 定义电影 ID 嵌入矩阵。 通过电影 ID 和电影类型分别生成电影 ID 和电影类型特征，电影类型的多个嵌入向量做加和输出。电影 ID的实现过程和上面一样，但是对于电影类型的处理相较于上面，稍微复杂一点。因为电影类型有重叠性，一个电影可以属于多个类别，当把电影类型从嵌入矩阵索引出来之后是一个（N，32）形状的矩阵，因为有多个类别，这里采用的处理方式是矩阵求和，把类别加上去，变成（1，32）形状，这样使得电影的类别信息不会丢失。 具体流程如下： 4. 文本卷积神经网络设计。 文本卷积神经网络和单纯的 CNN网络结构有点不同，因为自然语言通常是一段文字与图片像素组成的矩阵是不一样的。在电影文本特征矩阵中，矩阵的每一个行构成的行向量代表一个Token，包括词或者字符。如果一段文字有 n 个词，每个词有 m 维的词向量，那么我们可以构造出一个 n*m 的矩阵。而且 NLP处理过程中，会有多个不同大小的过滤器串行执行，且过滤器宽度和矩阵宽度保持一致，是整行滑动。在执行完卷积操作之后采用了 ReLU激活函数，然后采用最大池化操作，最后通过全连接并 Dropout 操作和 Softmax输出。这里电影名称的处理比较特殊，并没有采用循环神经网络，而采用的是文本在 CNN 网络上的应用。 对于电影数据集，我们对电影名称做 CNN处理，其大致流程，从嵌入矩阵中得到电影名对应的各个单词的嵌入向量，由于电影名称比较特殊一点，名称长度有一定限制，这里过滤器大小使用时，就选择2、3、4、5长度。然后对文本嵌入层使用滑动2、3、4、5个单词尺寸的卷积核做卷积和最大池化，然后Dropout 操作，全连接层输出。 具体流程如下： 具体过程描述： （1）首先输入一个 32*32 的矩阵； （2）第一次卷积核大小为 2*2，得到 31*31 的矩阵，然后通过 [1,14,1,1] 的 max-pooling 操作，得到的矩阵为18*31； （3）第二次卷积核大小为 3*3，得到 16*29的矩阵，然后通过[1,13,1,1] 的 max-pooling 操作，得到的矩阵为4*29； （4）第三次卷积核大小 4*4，得到 1*26 的矩阵，然后通过 [1,12,1,1] 的 max-pooling 操作，得到的矩阵为1*26； （5）第四次卷积核大小 5*5，得到 1*22 的矩阵，然后通过 [1,11,1,1] 的 max-pooling 操作，得到的矩阵为1*22； （6）最后通过 Dropout 和全连接层，len(window_sizes) * filter_num =32，得到 1*32的矩阵。 5. 电影各层做一个全连接层。 将上面几步生成的特征向量，通过2个全连接层连接在一起，第一个全连接层是电影 ID 特征和电影类型特征先全连接，之后再和 CNN生成的电影名称特征全连接，生成最后的特征集。 具体流程如下： 6. 完整的基于 CNN 的电影推荐流程。 把以上实现的模块组合成整个算法，将网络模型作为回归问题进行训练，得到训练好的用户特征矩阵和电影特征矩阵进行推荐。 基于 CNN 的电影推荐系统代码调参过程在训练过程中，我们需要对算法预先设置一些超参数，这里给出的最终的设置结果： # 设置迭代次数 num_epochs = 5 # 设置BatchSize大小 batch_size = 256 #设置dropout保留比例 dropout_keep = 0.5 # 设置学习率 learning_rate = 0.0001 # 设置每轮显示的batches大小 show_every_n_batches = 20 首先对数据集进行划分，按照 4:1 的比例划分为训练集和测试集，下面给出的是算法模型最终训练集合测试集使用的划分结果： #将数据集分成训练集和测试集，随机种子不固定 train_X,test_X, train_y, test_y = train_test_split(features, targets_values, test_size = 0.3, random_state = 0) 接下来是具体模型训练过程。训练过程，要不断调参，根据经验调参粒度可以选择从粗到细分阶段进行。 调参过程对比： （1）第一步，先固定，learning_rate=0.01 和 num_epochs=10，测试 batch_size=128 对迭代时间和Loss 的影响； （2）第二步，先固定，learning_rate=0.01 和 num_epochs=10，测试 batch_size=256 对迭代时间和Loss 的影响； （3）第三步，先固定，learning_rate=0.01 和 num_epochs=10，测试 batch_size=512 对迭代时间和Loss 的影响； （4）第四步，先固定，learning_rate=0.01 和 num_epochs=5，测试 batch_size=128 对迭代时间和Loss 的影响； （5）第五步，先固定，learning_rate=0.01 和 num_epochs=5，测试 batch_size=256 对迭代时间和Loss 的影响； （6）第六步，先固定，learning_rate=0.01 和 num_epochs=5，测试 batch_size=512 对迭代时间和Loss 的影响； （7）第七步，先固定，batch_size=256 和 num_epochs=5，测试 learning_rate=0.001 对 Loss的影响； （8）第八步，先固定，batch_size=256 和 num_epochs=5，测试 learning_rate=0.0005 对 Loss的影响； （9）第九步，先固定，batch_size=256 和 num_epochs=5，测试 learning_rate=0.0001 对 Loss的影响； （10）第十步，先固定，batch_size=256 和 num_epochs=5，测试 learning_rate=0.00005 对Loss 的影响。 得到的调参结果对比表如下： 通过上面（1）-（6）步调参比较，在 learning_rate、batch_size 相同的情况下，num_epochs对于训练时间影响较大；而在 learning_rate、num_epochs 相同情况下，batch_size 对 Loss的影响较大，batch_size 选择512，Loss 有抖动情况，权衡之下，最终确定后续调参固定采用batch_size=256、num_epochs=5 的超参数值，后续（7）-（10）步，随着 learning_rate 逐渐减小，发现Loss 是先逐渐减小，而在 learning_rate=0.00005 时反而增大，最终选择出学习率为 learning_rate=0.0001的超参数值。 基于 CNN 的电影推荐系统电影推荐在上面，完成模型训练验证之后，实际来进行推荐电影，这里使用生产的用户特征矩阵和电影特征矩阵做电影推荐，主要有三种方式的推荐。 1. 推荐同类型的电影。 思路是：计算当前看的电影特征向量与整个电影特征矩阵的余弦相似度，取相似度最大的 top_k 个，这里加了些随机选择在里面，保证每次的推荐稍稍有些不同。 def recommend_same_type_movie(movie_id_val, top_k = 20): loaded_graph = tf.Graph() # with tf.Session(graph=loaded_graph) as sess: # # Load saved model loader = tf.train.import_meta_graph(load_dir + &#39;.meta&#39;) loader.restore(sess, load_dir) norm_movie_matrics = tf.sqrt(tf.reduce_sum(tf.square(movie_matrics), 1, keep_dims=True)) normalized_movie_matrics = movie_matrics / norm_movie_matrics #推荐同类型的电影 probs_embeddings = (movie_matrics[movieid2idx[movie_id_val]]).reshape([1, 200]) probs_similarity = tf.matmul(probs_embeddings, tf.transpose(normalized_movie_matrics)) sim = (probs_similarity.eval()) print(&quot;您看的电影是：{}&quot;.format(movies_orig[movieid2idx[movie_id_val]])) print(&quot;以下是给您的推荐：&quot;) p = np.squeeze(sim) p[np.argsort(p)[:-top_k]] = 0 p = p / np.sum(p) results = set() while len(results) != 5: c = np.random.choice(3883, 1, p=p)[0] results.add(c) for val in (results): print(val) print(movies_orig[val]) return result 2. 推荐您喜欢的电影。 思路是：使用用户特征向量与电影特征矩阵计算所有电影的评分，取评分最高的 top_k 个，同样加了些随机选择部分。 def recommend_your_favorite_movie(user_id_val, top_k = 10): loaded_graph = tf.Graph() # with tf.Session(graph=loaded_graph) as sess: # # Load saved model loader = tf.train.import_meta_graph(load_dir + &#39;.meta&#39;) loader.restore(sess, load_dir) #推荐您喜欢的电影 probs_embeddings = (users_matrics[user_id_val-1]).reshape([1, 200]) probs_similarity = tf.matmul(probs_embeddings, tf.transpose(movie_matrics)) sim = (probs_similarity.eval()) print(&quot;以下是给您的推荐：&quot;) p = np.squeeze(sim) p[np.argsort(p)[:-top_k]] = 0 p = p / np.sum(p) results = set() while len(results) != 5: c = np.random.choice(3883, 1, p=p)[0] results.add(c) for val in (results): print(val) print(movies_orig[val]) return results 3. 看过这个电影的人还看了（喜欢）哪些电影。 （1）首先选出喜欢某个电影的 top_k 个人，得到这几个人的用户特征向量； （2）然后计算这几个人对所有电影的评分 ； （3）选择每个人评分最高的电影作为推荐； （4）同样加入了随机选择。 def recommend_other_favorite_movie(movie_id_val, top_k = 20): loaded_graph = tf.Graph() # with tf.Session(graph=loaded_graph) as sess: # # Load saved model loader = tf.train.import_meta_graph(load_dir + &#39;.meta&#39;) loader.restore(sess, load_dir) probs_movie_embeddings = (movie_matrics[movieid2idx[movie_id_val]]).reshape([1, 200]) probs_user_favorite_similarity = tf.matmul(probs_movie_embeddings, tf.transpose(users_matrics)) favorite_user_id = np.argsort(probs_user_favorite_similarity.eval())[0][-top_k:] print(&quot;您看的电影是：{}&quot;.format(movies_orig[movieid2idx[movie_id_val]])) print(&quot;喜欢看这个电影的人是：{}&quot;.format(users_orig[favorite_user_id-1])) probs_users_embeddings = (users_matrics[favorite_user_id-1]).reshape([-1, 200]) probs_similarity = tf.matmul(probs_users_embeddings, tf.transpose(movie_matrics)) sim = (probs_similarity.eval()) p = np.argmax(sim, 1) print(&quot;喜欢看这个电影的人还喜欢看：&quot;) results = set() while len(results) != 5: c = p[random.randrange(top_k)] results.add(c) for val in (results): print(val) print(movies_orig[val]) return results 基于 CNN 的电影推荐系统不足这里讨论一下基于上述方法所带来的不足： 由于一个新的用户在刚开始的时候并没有任何行为记录，所以系统会出现冷启动的问题； 由于神经网络是一个黑盒子过程，我们并不清楚在反向传播的过程中的具体细节，也不知道每一个卷积层抽取的特征细节，所以此算法缺乏一定的可解释性； 一般来说，在工业界，用户的数据量是海量的，而卷积神经网络又要耗费大量的计算资源，所以进行集群计算是非常重要的。但是由于本课程所做实验环境有限，还是在单机上运行，所以后期可以考虑在服务器集群上全量跑数据，这样获得的结果也更准确。 总结上面通过 Github 上一个开源的项目，梳理了CNN 在文本推荐上的应用，并通过模型训练调参，给出一般的模型调参思路，最后建议大家自己把源码下载下来跑跑模型，效果更好。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>cnn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于LSTM轻松生成各种古诗（11）]]></title>
    <url>%2F2019%2F11%2F22%2F11.%E5%9F%BA%E4%BA%8ELSTM%E8%BD%BB%E6%9D%BE%E7%94%9F%E6%88%90%E5%90%84%E7%A7%8D%E5%8F%A4%E8%AF%97%2F</url>
    <content type="text"><![CDATA[目前循环神经网络（RNN）已经广泛用于自然语言处理中，可以处理大量的序列数据，可以说是最强大的神经网络模型之一。人们已经给 RNN找到了越来越多的事情做，比如画画和写诗，微软的小冰都已经出版了一本诗集了。 而其实训练一个能写诗的神经网络并不难，下面我们就介绍如何简单快捷地建立一个会写诗的网络模型。 本次开发环境如下： Python 3.6 Keras 环境 Jupyter Notebook 整个过程分为以下步骤完成： 语料准备 语料预处理 模型参数配置 构建模型 训练模型 模型作诗 绘制模型网络结构图 下面一步步来构建和训练一个会写诗的模型。 第一 ，语料准备。一共四万多首古诗，每行一首诗，标题在预处理的时候已经去掉了。 第二 ，文件预处理。首先，机器并不懂每个中文汉字代表的是什么，所以要将文字转换为机器能理解的形式，这里我们采用 One-Hot的形式，这样诗句中的每个字都能用向量来表示，下面定义函数 preprocess_file() 来处理。 puncs = [&#39;]&#39;, &#39;[&#39;, &#39;（&#39;, &#39;）&#39;, &#39;{&#39;, &#39;}&#39;, &#39;：&#39;, &#39;《&#39;, &#39;》&#39;] def preprocess_file(Config): # 语料文本内容 files_content = &#39;&#39; with open(Config.poetry_file, &#39;r&#39;, encoding=&#39;utf-8&#39;) as f: for line in f: # 每行的末尾加上&quot;]&quot;符号代表一首诗结束 for char in puncs: line = line.replace(char, &quot;&quot;) files_content += line.strip() + &quot;]&quot; words = sorted(list(files_content)) words.remove(&#39;]&#39;) counted_words = {} for word in words: if word in counted_words: counted_words[word] += 1 else: counted_words[word] = 1 # 去掉低频的字 erase = [] for key in counted_words: if counted_words[key] &lt;= 2: erase.append(key) for key in erase: del counted_words[key] del counted_words[&#39;]&#39;] wordPairs = sorted(counted_words.items(), key=lambda x: -x[1]) words, _ = zip(*wordPairs) # word到id的映射 word2num = dict((c, i + 1) for i, c in enumerate(words)) num2word = dict((i, c) for i, c in enumerate(words)) word2numF = lambda x: word2num.get(x, 0) return word2numF, num2word, words, files_content 在每行末尾加上 ]符号是为了标识这首诗已经结束了。我们给模型学习的方法是，给定前六个字，生成第七个字，所以在后面生成训练数据的时候，会以6的跨度，1的步长截取文字，生成语料。如果出现了] 符号，说明 ] 符号之前的语句和之后的语句是两首诗里面的内容，两首诗之间是没有关联关系的，所以我们后面会舍弃掉包含 ] 符号的训练数据。 第三 ，模型参数配置。预先定义模型参数和加载语料以及模型保存名称，通过类 Config 实现。 class Config(object): poetry_file = &#39;poetry.txt&#39; weight_file = &#39;poetry_model.h5&#39; # 根据前六个字预测第七个字 max_len = 6 batch_size = 512 learning_rate = 0.001 第四 ，构建模型，通过 PoetryModel 类实现，类的代码结构如下： class PoetryModel(object): def __init__(self, config): pass def build_model(self): pass def sample(self, preds, temperature=1.0): pass def generate_sample_result(self, epoch, logs): pass def predict(self, text): pass def data_generator(self): pass def train(self): pass 类中定义的方法具体实现功能如下： （1）init 函数定义，通过加载 Config 配置信息，进行语料预处理和模型加载，如果模型文件存在则直接加载模型，否则开始训练。 def __init__(self, config): self.model = None self.do_train = True self.loaded_model = False self.config = config # 文件预处理 self.word2numF, self.num2word, self.words, self.files_content = preprocess_file(self.config) if os.path.exists(self.config.weight_file): self.model = load_model(self.config.weight_file) self.model.summary() else: self.train() self.do_train = False self.loaded_model = True （2）build_model 函数主要用 Keras 来构建网络模型，这里使用 LSTM 的 GRU 来实现，当然直接使用 LSTM 也没问题。 def build_model(self): &#39;&#39;&#39;建立模型&#39;&#39;&#39; input_tensor = Input(shape=(self.config.max_len,)) embedd = Embedding(len(self.num2word)+1, 300, input_length=self.config.max_len)(input_tensor) lstm = Bidirectional(GRU(128, return_sequences=True))(embedd) dropout = Dropout(0.6)(lstm) lstm = Bidirectional(GRU(128, return_sequences=True))(embedd) dropout = Dropout(0.6)(lstm) flatten = Flatten()(lstm) dense = Dense(len(self.words), activation=&#39;softmax&#39;)(flatten) self.model = Model(inputs=input_tensor, outputs=dense) optimizer = Adam(lr=self.config.learning_rate) self.model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=optimizer, metrics=[&#39;accuracy&#39;]) （3）sample 函数，在训练过程的每个 epoch 迭代中采样。 def sample(self, preds, temperature=1.0): &#39;&#39;&#39; 当temperature=1.0时，模型输出正常 当temperature=0.5时，模型输出比较open 当temperature=1.5时，模型输出比较保守 在训练的过程中可以看到temperature不同，结果也不同 &#39;&#39;&#39; preds = np.asarray(preds).astype(&#39;float64&#39;) preds = np.log(preds) / temperature exp_preds = np.exp(preds) preds = exp_preds / np.sum(exp_preds) probas = np.random.multinomial(1, preds, 1) return np.argmax(probas) （4）训练过程中，每个 epoch 打印出当前的学习情况。 def generate_sample_result(self, epoch, logs): print(&quot;\n==================Epoch {}=====================&quot;.format(epoch)) for diversity in [0.5, 1.0, 1.5]: print(&quot;------------Diversity {}--------------&quot;.format(diversity)) start_index = random.randint(0, len(self.files_content) - self.config.max_len - 1) generated = &#39;&#39; sentence = self.files_content[start_index: start_index + self.config.max_len] generated += sentence for i in range(20): x_pred = np.zeros((1, self.config.max_len)) for t, char in enumerate(sentence[-6:]): x_pred[0, t] = self.word2numF(char) preds = self.model.predict(x_pred, verbose=0)[0] next_index = self.sample(preds, diversity) next_char = self.num2word[next_index] generated += next_char sentence = sentence + next_char print(sentence) （5）predict 函数，用于根据给定的提示，来进行预测。 根据给出的文字，生成诗句，如果给的 text 不到四个字，则随机补全。 def predict(self, text): if not self.loaded_model: return with open(self.config.poetry_file, &#39;r&#39;, encoding=&#39;utf-8&#39;) as f: file_list = f.readlines() random_line = random.choice(file_list) # 如果给的text不到四个字，则随机补全 if not text or len(text) != 4: for _ in range(4 - len(text)): random_str_index = random.randrange(0, len(self.words)) text += self.num2word.get(random_str_index) if self.num2word.get(random_str_index) not in [&#39;,&#39;, &#39;。&#39;, &#39;，&#39;] else self.num2word.get( random_str_index + 1) seed = random_line[-(self.config.max_len):-1] res = &#39;&#39; seed = &#39;c&#39; + seed for c in text: seed = seed[1:] + c for j in range(5): x_pred = np.zeros((1, self.config.max_len)) for t, char in enumerate(seed): x_pred[0, t] = self.word2numF(char) preds = self.model.predict(x_pred, verbose=0)[0] next_index = self.sample(preds, 1.0) next_char = self.num2word[next_index] seed = seed[1:] + next_char res += seed return res （6） data_generator 函数，用于生成数据，提供给模型训练时使用。 def data_generator(self): i = 0 while 1: x = self.files_content[i: i + self.config.max_len] y = self.files_content[i + self.config.max_len] puncs = [&#39;]&#39;, &#39;[&#39;, &#39;（&#39;, &#39;）&#39;, &#39;{&#39;, &#39;}&#39;, &#39;：&#39;, &#39;《&#39;, &#39;》&#39;, &#39;:&#39;] if len([i for i in puncs if i in x]) != 0: i += 1 continue if len([i for i in puncs if i in y]) != 0: i += 1 continue y_vec = np.zeros( shape=(1, len(self.words)), dtype=np.bool ) y_vec[0, self.word2numF(y)] = 1.0 x_vec = np.zeros( shape=(1, self.config.max_len), dtype=np.int32 ) for t, char in enumerate(x): x_vec[0, t] = self.word2numF(char) yield x_vec, y_vec i += 1 （7）train 函数，用来进行模型训练，其中迭代次数 number_of_epoch ，是根据训练语料长度除以 batch_size计算的，如果在调试中，想用更小一点的 number_of_epoch ，可以自定义大小，把 train 函数的第一行代码注释即可。 def train(self): #number_of_epoch = len(self.files_content) // self.config.batch_size number_of_epoch = 10 if not self.model: self.build_model() self.model.summary() self.model.fit_generator( generator=self.data_generator(), verbose=True, steps_per_epoch=self.config.batch_size, epochs=number_of_epoch, callbacks=[ keras.callbacks.ModelCheckpoint(self.config.weight_file, save_weights_only=False), LambdaCallback(on_epoch_end=self.generate_sample_result) ] ) 第五 ，整个模型构建好以后，接下来进行模型训练。 model = PoetryModel(Config) 训练过程中的第1-2轮迭代： 训练过程中的第9-10轮迭代： 虽然训练过程写出的诗句不怎么能看得懂，但是可以看到模型从一开始标点符号都不会用 ，到最后写出了有一点点模样的诗句，能看到模型变得越来越聪明了。 第六 ，模型作诗，模型迭代10次之后的测试，首先输入几个字，模型根据输入的提示，做出诗句。 text = input(&quot;text:&quot;) sentence = model.predict(text) print(sentence) 比如输入：小雨，模型做出的诗句为： 输入：text：小雨 结果：小妃侯里守。雨封即客寥。俘剪舟过槽。傲老槟冬绛。 第七 ，绘制网络结构图。 模型结构绘图，采用 Keras自带的功能实现： plot_model(model.model, to_file=&#39;model.png&#39;) 得到的模型结构图如下： 本节使用 LSTM 的变形 GRU 训练出一个能作诗的模型，当然大家可以替换训练语料为歌词或者小说，让机器人自动创作不同风格的歌曲或者小说。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>gru</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中文命名实体提取（14）]]></title>
    <url>%2F2019%2F11%2F22%2F14.%E4%B8%AD%E6%96%87%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E6%8F%90%E5%8F%96%2F</url>
    <content type="text"><![CDATA[命名实体识别（NamedEntitiesRecognition，NER）是自然语言处理的一个基础任务。其目的是识别语料中人名、地名、组织机构名等命名实体，比如，[2015年中国国家海洋局对124个国际海底地理实体的命名]https://baike.baidu.com/item/2015%E5%B9%B4%E4%B8%AD%E5%9B%BD%E5%91%BD%E5%90%8D%E7%9A%84124%E4%B8%AA%E5%9B%BD%E9%99%85%E6%B5%B7%E5%BA%95%E5%9C%B0%E7%90%86%E5%AE%9E%E4%BD%93%E5%90%8D%E7%A7%B0%E4%BF%A1%E6%81%AF/18705238)。 由于命名实体数量不断增加，通常不可能在词典中穷尽列出，且其构成方法具有各自的一些规律性，因而，通常把对这些词的识别从词汇形态处理（如汉语切分）任务中独立处理，称为命名实体识别。 命名实体识别技术是信息抽取、信息检索、机器翻译、问答系统等多种自然语言处理技术必不可少的组成部分。 常见的命名实体识别方法综述命名实体是命名实体识别的研究主体，一般包括三大类（实体类、时间类和数字类）和七小类（人名、地名、机构名、时间、日期、货币和百分比）命名实体。评判一个命名实体是否被正确识别包括两个方面：实体的边界是否正确和实体的类型是否标注正确。 命名实体识别的主要技术方法分为：基于规则和词典的方法、基于统计的方法、二者混合的方法等。 1.基于规则和词典的方法。 基于规则的方法多采用语言学专家手工构造规则模板，选用特征包括统计信息、标点符号、关键字、指示词和方向词、位置词（如尾字）、中心词等方法，以模式和字符串相匹配为主要手段，这类系统大多依赖于知识库和词典的建立。基于规则和词典的方法是命名实体识别中最早使用的方法，一般而言，当提取的规则能比较精确地反映语言现象时，基于规则的方法性能要优于基于统计的方法。但是这些规则往往依赖于具体语言、领域和文本风格，编制过程耗时且难以涵盖所有的语言现象，特别容易产生错误，系统可移植性不好，对于不同的系统需要语言学专家重新书写规则。基于规则的方法的另外一个缺点是代价太大，存在系统建设周期长、移植性差而且需要建立不同领域知识库作为辅助以提高系统识别能力等问题。 2.基于统计的方法。 基于统计机器学习的方法主要包括隐马尔可夫模型（HiddenMarkovMode，HMM）、最大熵（MaxmiumEntropy，ME）、支持向量机（SupportVectorMachine，SVM）、条件随机场（ConditionalRandom Fields，CRF）等。 在基于统计的这四种学习方法中，最大熵模型结构紧凑，具有较好的通用性，主要缺点是训练时间长复杂性高，有时甚至导致训练代价难以承受，另外由于需要明确的归一化计算，导致开销比较大。而条件随机场为命名实体识别提供了一个特征灵活、全局最优的标注框架，但同时存在收敛速度慢、训练时间长的问题。一般说来，最大熵和支持向量机在正确率上要比隐马尔可夫模型高一些，但隐马尔可夫模型在训练和识别时的速度要快一些，主要是由于在利用Viterbi算法求解命名实体类别序列时的效率较高。隐马尔可夫模型更适用于一些对实时性有要求以及像信息检索这样需要处理大量文本的应用，如短文本命名实体识别。 基于统计的方法对特征选取的要求较高，需要从文本中选择对该项任务有影响的各种特征，并将这些特征加入到特征向量中。依据特定命名实体识别所面临的主要困难和所表现出的特性，考虑选择能有效反映该类实体特性的特征集合。主要做法是通过对训练语料所包含的语言信息进行统计和分析，从训练语料中挖掘出特征。有关特征可以分为具体的单词特征、上下文特征、词典及词性特征、停用词特征、核心词特征以及语义特征等。 基于统计的方法对语料库的依赖也比较大，而可以用来建设和评估命名实体识别系统的大规模通用语料库又比较少。 3.混合方法。 自然语言处理并不完全是一个随机过程，单独使用基于统计的方法使状态搜索空间非常庞大，必须借助规则知识提前进行过滤修剪处理。目前几乎没有单纯使用统计模型而不使用规则知识的命名实体识别系统，在很多情况下是使用混合方法： 统计学习方法之间或内部层叠融合。 规则、词典和机器学习方法之间的融合，其核心是融合方法技术。在基于统计的学习方法中引入部分规则，将机器学习和人工知识结合起来。 将各类模型、算法结合起来，将前一级模型的结果作为下一级的训练数据，并用这些训练数据对模型进行训练，得到下一级模型。 命名实体识别的一般流程如下图所示，一般的命名实体流程主要分为四个步骤： 对需要进行提取的文本语料进行分词； 获取需要识别的领域标签，并对分词结果进行标签标注； 对标签标注的分词进行抽取； 将抽取的分词组成需要的领域的命名实体。 动手实战命名实体识别下面通过jieba 分词包和 pyhanlp 来实战命名实体识别和提取。 1.jieba 进行命名实体识别和提取。 第一步，引入 jieba 包： import jieba import jieba.analyse import jieba.posseg as posg 第二步，使用 jieba 进行词性切分，allowPOS 指定允许的词性，这里选择名词 n 和地名 ns： sentence=u&#39;&#39;&#39;上线三年就成功上市,拼多多上演了互联网企业的上市奇迹,却也放大平台上存在的诸多问题，拼多多在美国上市。&#39;&#39;&#39; kw=jieba.analyse.extract_tags(sentence,topK=10,withWeight=True,allowPOS=(&#39;n&#39;,&#39;ns&#39;)) for item in kw: print(item[0],item[1]) 在这里，我们可以得到打印出来的结果： 上市 1.437080435586 上线 0.820694551317 奇迹 0.775434839431 互联网 0.712189275429 平台 0.6244340485550001 企业 0.422177218495 美国 0.415659623166 问题 0.39635135730800003 可以看得出，上市和上线应该是动词，这里给出的结果不是很准确。接下来，我们使用 textrank 算法来试试： kw=jieba.analyse.textrank(sentence,topK=20,withWeight=True,allowPOS=(&#39;ns&#39;,&#39;n&#39;)) for item in kw: print(item[0],item[1]) 这次得到的结果如下，可见，两次给出的结果还是不一样的。 上市 1.0 奇迹 0.572687398431635 企业 0.5710407272273452 互联网 0.5692560484441649 上线 0.23481844682115297 美国 0.23481844682115297 2.pyhanlp 进行命名实体识别和提取。 第一步，引入pyhanlp包： from pyhanlp import * 第二步，进行词性切分： sentence=u&#39;&#39;&#39;上线三年就成功上市,拼多多上演了互联网企业的上市奇迹,却也放大平台上存在的诸多问题，拼多多在美国上市。&#39;&#39;&#39; analyzer = PerceptronLexicalAnalyzer() segs = analyzer.analyze(sentence) arr = str(segs).split(&quot; &quot;) 第三步，定义一个函数，从得到的结果中，根据词性获取指定词性的词： def get_result(arr): re_list = [] ner = [&#39;n&#39;,&#39;ns&#39;] for x in arr: temp = x.split(&quot;/&quot;) if(temp[1] in ner): re_list.append(temp[0]) return re_list 第四步，我们获取结果： result = get_result(arr) print(result) 得到的结果如下，可见比 jieba 更准确： [&#39;互联网&#39;, &#39;企业&#39;, &#39;奇迹&#39;, &#39;平台&#39;, &#39;问题&#39;, &#39;美国&#39;] 总结本文对命名实体识别的方法进行了总结，并给出一般的处理流程，最后通过简单的 jieba 分词和 pyhanlp分词根据词性获取实体对象，后续大家也可以尝试通过哈工大和斯坦福的包来处理，下篇我们通过条件随机场 CRF 来训练一个命名实体识别模型。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>jieba</tag>
        <tag>pyhanlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊天机器人（13）]]></title>
    <url>%2F2019%2F11%2F22%2F13.%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%2F</url>
    <content type="text"><![CDATA[自动聊天机器人，也称为自动问答系统，由于所使用的场景不同，叫法也不一样。自动问答（Question Answering，QA）是指利用计算机自动回答用户所提出的问题以满足用户知识需求的任务。不同于现有搜索引擎，问答系统是信息服务的一种高级形式，系统返回用户的不再是基于关键词匹配排序的文档列表，而是精准的自然语言答案。近年来，随着人工智能的飞速发展，自动问答已经成为倍受关注且发展前景广泛的研究方向。 自动问答简介自动问答主要研究的内容和关键科学问题如下： 问句理解 ：给定用户问题，自动问答首先需要理解用户所提问题。用户问句的语义理解包含词法分析、句法分析、语义分析等多项关键技术，需要从文本的多个维度理解其中包含的语义内容。 文本信息抽取 ：自动问答系统需要在已有语料库、知识库或问答库中匹配相关的信息，并抽取出相应的答案。 知识推理 ：自动问答中，由于语料库、知识库和问答库本身的覆盖度有限，并不是所有问题都能直接找到答案。这就需要在已有的知识体系中，通过知识推理的手段获取这些隐含的答案。 纵观自动问答研究的发展态势和技术现状，以下研究方向或问题将可能成为未来整个领域和行业重点关注的方向：基于深度学习的端到端自动问答，多领域、多语言的自动问答，面向问答的深度推理，篇章阅读理解、对话等。 基于 Chatterbot 制作中文聊天机器人ChatterBot 是一个构建在 Python 上，基于一系列规则和机器学习算法完成的聊天机器人，具有结构清晰，可扩展性好，简单实用的特点。 Chatterbot 安装有两种方式： 使用 pip install chatterbot 安装； 直接在 Github Chatterbot 下载这个项目，通过 python setup.py install 安装，其中 examples 文件夹中包含几个例子，可以根据例子加深自己的理解。 安装过程如果出现错误，主要是需要安装这些依赖库： chatterbot-corpus&gt;=1.1,&lt;1.2 mathparse&gt;=0.1,&lt;0.2 nltk&gt;=3.2,&lt;4.0 pymongo&gt;=3.3,&lt;4.0 python-dateutil&gt;=2.6,&lt;2.7 python-twitter&gt;=3.0,&lt;4.0 sqlalchemy&gt;=1.2,&lt;1.3 pint&gt;=0.8.1 1. 手动设置一点语料，体验基于规则的聊天机器人回答。 from chatterbot import ChatBot from chatterbot.trainers import ListTrainer Chinese_bot = ChatBot(&quot;Training demo&quot;) #创建一个新的实例 Chinese_bot.set_trainer(ListTrainer) Chinese_bot.train([ &#39;亲，在吗？&#39;, &#39;亲，在呢&#39;, &#39;这件衣服的号码大小标准吗？&#39;, &#39;亲，标准呢，请放心下单吧。&#39;, &#39;有红色的吗？&#39;, &#39;有呢，目前有白红蓝3种色调。&#39;, ]) 下面进行测试： # 测试一下 question = &#39;亲，在吗&#39; print(question) response = Chinese_bot.get_response(question) print(response) print(&quot;\n&quot;) question = &#39;有红色的吗？&#39; print(question) response = Chinese_bot.get_response(question) print(response) 从得到的结果可以看出，这应该完全是基于规则的判断： 亲，在吗 亲，在呢 有红色的吗？ 有呢，目前有白红蓝3种色调。 2. 训练自己的语料。 本次使用的语料来自 QQ 群的聊天记录，导出的 QQ 聊天记录稍微处理一下即可使用，整个过程如下。 （1）首先载入语料，第二行代码主要是想把每句话后面的换行 \n 去掉。 lines = open(&quot;QQ.txt&quot;,&quot;r&quot;,encoding=&#39;gbk&#39;).readlines() sec = [ line.strip() for line in lines] （2）接下来就可以训练模型了，由于整个语料比较大，训练过程也比较耗时。 from chatterbot import ChatBot from chatterbot.trainers import ListTrainer Chinese_bot = ChatBot(&quot;Training&quot;) Chinese_bot.set_trainer(ListTrainer) Chinese_bot.train(sec) 这里需要注意，如果训练过程很慢，可以在第一步中加入如下代码，即只取前1000条进行训练： sec = sec[0:1000] （3）最后，对训练好的模型进行测试，可见训练数据是 QQ 群技术对话，也看得出程序员们都很努力，整体想的都是学习。 以上只是简单的 Chatterbot 演示，如果想看更好的应用，推荐看官方文档。 基于 Seq2Seq 制作中文聊天机器人序列数据处理模型，从N-gram 语言模型到 RNN 及其变种。这里我们讲另外一个基于深度学习的 Seq2Seq 模型。 从 RNN 结构说起，根据输出和输入序列不同数量 RNN ，可以有多种不同的结构，不同结构自然就有不同的引用场合。 One To One 结构，仅仅只是简单的给一个输入得到一个输出，此处并未体现序列的特征，例如图像分类场景。 One To Many 结构，给一个输入得到一系列输出，这种结构可用于生产图片描述的场景。 Many To One 结构，给一系列输入得到一个输出，这种结构可用于文本情感分析，对一些列的文本输入进行分类，看是消极还是积极情感。 Many To Many 结构，给一系列输入得到一系列输出，这种结构可用于翻译或聊天对话场景，将输入的文本转换成另外一系列文本。 同步 Many To Many 结构，它是经典的 RNN 结构，前一输入的状态会带到下一个状态中，而且每个输入都会对应一个输出，我们最熟悉的应用场景是字符预测，同样也可以用于视频分类，对视频的帧打标签。 在 Many To Many 的两种模型中，第四和第五种是有差异的，经典 RNN结构的输入和输出序列必须要等长，它的应用场景也比较有限。而第四种，输入和输出序列可以不等长，这种模型便是 Seq2Seq 模型，即 Sequence toSequence。它实现了从一个序列到另外一个序列的转换，比如 Google 曾用 Seq2Seq 模型加 Attention模型实现了翻译功能，类似的还可以实现聊天机器人对话模型。经典的 RNN 模型固定了输入序列和输出序列的大小，而 Seq2Seq 模型则突破了该限制。 Seq2Seq 属于 Encoder-Decoder 结构，这里看看常见的 Encoder-Decoder 结构。基本思想就是利用两个 RNN，一个RNN 作为 Encoder，另一个 RNN 作为 Decoder。Encoder负责将输入序列压缩成指定长度的向量，这个向量就可以看成是这个序列的语义，这个过程称为编码，如下图，获取语义向量最简单的方式就是直接将最后一个输入的隐状态作为语义向量。也可以对最后一个隐含状态做一个变换得到语义向量，还可以将输入序列的所有隐含状态做一个变换得到语义变量。 具体理论知识这里不再赘述，下面重点看看，如何通过 Keras 实现一个 LSTM_Seq2Seq 自动问答机器人。 1. 语料准备。 语料我们使用 Tab 键 \t 把问题和答案区分，每一对为一行。其中，语料为爬虫爬取的工程机械网站的问答。 2. 模型构建和训练。 第一步，引入需要的包： from keras.models import Model from keras.layers import Input, LSTM, Dense import numpy as np import pandas as pd 第二步，定义模型超参数、迭代次数、语料路径： #Batch size 的大小 batch_size = 32 # 迭代次数epochs epochs = 100 # 编码空间的维度Latent dimensionality latent_dim = 256 # 要训练的样本数 num_samples = 5000 #设置语料的路径 data_path = &#39;D://nlp//ch13//files.txt&#39; 第三步，把语料向量化： #把数据向量话 input_texts = [] target_texts = [] input_characters = set() target_characters = set() with open(data_path, &#39;r&#39;, encoding=&#39;utf-8&#39;) as f: lines = f.read().split(&#39;\n&#39;) for line in lines[: min(num_samples, len(lines) - 1)]: #print(line) input_text, target_text = line.split(&#39;\t&#39;) # We use &quot;tab&quot; as the &quot;start sequence&quot; character # for the targets, and &quot;\n&quot; as &quot;end sequence&quot; character. target_text = target_text[0:100] target_text = &#39;\t&#39; + target_text + &#39;\n&#39; input_texts.append(input_text) target_texts.append(target_text) for char in input_text: if char not in input_characters: input_characters.add(char) for char in target_text: if char not in target_characters: target_characters.add(char) input_characters = sorted(list(input_characters)) target_characters = sorted(list(target_characters)) num_encoder_tokens = len(input_characters) num_decoder_tokens = len(target_characters) max_encoder_seq_length = max([len(txt) for txt in input_texts]) max_decoder_seq_length = max([len(txt) for txt in target_texts]) print(&#39;Number of samples:&#39;, len(input_texts)) print(&#39;Number of unique input tokens:&#39;, num_encoder_tokens) print(&#39;Number of unique output tokens:&#39;, num_decoder_tokens) print(&#39;Max sequence length for inputs:&#39;, max_encoder_seq_length) print(&#39;Max sequence length for outputs:&#39;, max_decoder_seq_length) input_token_index = dict( [(char, i) for i, char in enumerate(input_characters)]) target_token_index = dict( [(char, i) for i, char in enumerate(target_characters)]) encoder_input_data = np.zeros( (len(input_texts), max_encoder_seq_length, num_encoder_tokens),dtype=&#39;float32&#39;) decoder_input_data = np.zeros( (len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype=&#39;float32&#39;) decoder_target_data = np.zeros( (len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype=&#39;float32&#39;) for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)): for t, char in enumerate(input_text): encoder_input_data[i, t, input_token_index[char]] = 1. for t, char in enumerate(target_text): # decoder_target_data is ahead of decoder_input_data by one timestep decoder_input_data[i, t, target_token_index[char]] = 1. if t &gt; 0: # decoder_target_data will be ahead by one timestep # and will not include the start character. decoder_target_data[i, t - 1, target_token_index[char]] = 1. 第四步，LSTM_Seq2Seq 模型定义、训练和保存： encoder_inputs = Input(shape=(None, num_encoder_tokens)) encoder = LSTM(latent_dim, return_state=True) encoder_outputs, state_h, state_c = encoder(encoder_inputs) # 输出 `encoder_outputs` encoder_states = [state_h, state_c] # 状态 `encoder_states` decoder_inputs = Input(shape=(None, num_decoder_tokens)) decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states) decoder_dense = Dense(num_decoder_tokens, activation=&#39;softmax&#39;) decoder_outputs = decoder_dense(decoder_outputs) # 定义模型 model = Model([encoder_inputs, decoder_inputs], decoder_outputs) # 训练 model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;categorical_crossentropy&#39;) model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs, validation_split=0.2) # 保存模型 model.save(&#39;s2s.h5&#39;) 第五步，Seq2Seq 的 Encoder 操作： encoder_model = Model(encoder_inputs, encoder_states) decoder_state_input_h = Input(shape=(latent_dim,)) decoder_state_input_c = Input(shape=(latent_dim,)) decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] decoder_outputs, state_h, state_c = decoder_lstm( decoder_inputs, initial_state=decoder_states_inputs) decoder_states = [state_h, state_c] decoder_outputs = decoder_dense(decoder_outputs) decoder_model = Model( [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states) 第六步，把索引和分词转成序列： reverse_input_char_index = dict( (i, char) for char, i in input_token_index.items()) reverse_target_char_index = dict( (i, char) for char, i in target_token_index.items()) 第七步，定义预测函数，先使用预模型预测，然后编码成汉字结果： def decode_sequence(input_seq): # Encode the input as state vectors. states_value = encoder_model.predict(input_seq) #print(states_value) # Generate empty target sequence of length 1. target_seq = np.zeros((1, 1, num_decoder_tokens)) # Populate the first character of target sequence with the start character. target_seq[0, 0, target_token_index[&#39;\t&#39;]] = 1. # Sampling loop for a batch of sequences # (to simplify, here we assume a batch of size 1). stop_condition = False decoded_sentence = &#39;&#39; while not stop_condition: output_tokens, h, c = decoder_model.predict( [target_seq] + states_value) # Sample a token sampled_token_index = np.argmax(output_tokens[0, -1, :]) sampled_char = reverse_target_char_index[sampled_token_index] decoded_sentence += sampled_char if (sampled_char == &#39;\n&#39; or len(decoded_sentence) &gt; max_decoder_seq_length): stop_condition = True # Update the target sequence (of length 1). target_seq = np.zeros((1, 1, num_decoder_tokens)) target_seq[0, 0, sampled_token_index] = 1. # 更新状态 states_value = [h, c] return decoded_sentence 3. 模型预测。首先，定义一个预测函数： def predict_ans(question): inseq = np.zeros((len(question), max_encoder_seq_length, num_encoder_tokens),dtype=&#39;float16&#39;) decoded_sentence = decode_sequence(inseq) return decoded_sentence 然后就可以预测了： print(&#39;Decoded sentence:&#39;, predict_ans(&quot;挖机履带掉了怎么装上去&quot;)) 总结本文我们首先基于 Chatterbot 制作了中文聊天机器人，并用 QQ 群对话语料自己尝试训练。然后通过 LSTM 和 Seq2Seq模型，根据爬取的语料，训练了一个自动问答的模型，通过以上两种方式，我们们对自动问答有了一个简单的入门。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>chatterbot</tag>
        <tag>seq2seq</tag>
        <tag>lstm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于CRF的中文命名实体识别模型实现（15）]]></title>
    <url>%2F2019%2F11%2F22%2F15.%E5%9F%BA%E4%BA%8ECRF%E7%9A%84%E4%B8%AD%E6%96%87%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[命名实体识别在越来越多的场景下被应用，如自动问答、知识图谱等。非结构化的文本内容有很多丰富的信息，但找到相关的知识始终是一个具有挑战性的任务，命名实体识别也不例外。 前面我们用隐马尔可夫模型（HMM）自己尝试训练过一个分词器，其实 HMM也可以用来训练命名实体识别器，但在本文，我们讲另外一个算法——条件随机场（CRF），来训练一个命名实体识别器。 浅析条件随机场（CRF）条件随机场（Conditional Random Fields，简称CRF）是给定一组输入序列条件下另一组输出序列的条件概率分布模型，在自然语言处理中得到了广泛应用。 首先，我们来看看什么是随机场。“随机场”的名字取的很玄乎，其实理解起来不难。随机场是由若干个位置组成的整体，当按照某种分布给每一个位置随机赋予一个值之后，其全体就叫做随机场。 还是举词性标注的例子。假如我们有一个十个词形成的句子需要做词性标注。这十个词每个词的词性可以在我们已知的词性集合（名词，动词……)中去选择。当我们为每个词选择完词性后，这就形成了一个随机场。 了解了随机场，我们再来看看马尔科夫随机场。马尔科夫随机场是随机场的特例，它假设随机场中某一个位置的赋值仅仅与和它相邻的位置的赋值有关，和与其不相邻的位置的赋值无关。 继续举十个词的句子词性标注的例子。如果我们假设所有词的词性只和它相邻的词的词性有关时，这个随机场就特化成一个马尔科夫随机场。比如第三个词的词性除了与自己本身的位置有关外，还只与第二个词和第四个词的词性有关。 理解了马尔科夫随机场，再理解 CRF 就容易了。CRF 是马尔科夫随机场的特例，它假设马尔科夫随机场中只有 X 和 Y 两种变量，X 一般是给定的，而 Y一般是在给定 X 的条件下我们的输出。这样马尔科夫随机场就特化成了条件随机场。 在我们十个词的句子词性标注的例子中，X 是词，Y 是词性。因此，如果我们假设它是一个马尔科夫随机场，那么它也就是一个 CRF。 对于 CRF，我们给出准确的数学语言描述：设 X 与 Y 是随机变量，P(Y|X) 是给定 X 时 Y 的条件概率分布，若随机变量 Y构成的是一个马尔科夫随机场，则称条件概率分布 P(Y|X) 是条件随机场。 基于 CRF 的中文命名实体识别模型实现在常规的命名实体识别中，通用场景下最常提取的是时间、人物、地点及组织机构名，因此本模型也将提取以上四种实体。 1.开发环境。 本次开发所选用的环境为： Sklearn_crfsuite Python 3.6 Jupyter Notebook 2.数据预处理。 本模型使用人民日报1998年标注数据，进行预处理。语料库词性标记中，对应的实体词依次为 t、nr、ns、nt。对语料需要做以下处理： 将语料全角字符统一转为半角； 合并语料库分开标注的姓和名，例如：温/nr 家宝/nr； 合并语料库中括号中的大粒度词，例如：[国家/n 环保局/n]nt； 合并语料库分开标注的时间，例如：（/w 一九九七年/t 十二月/t 三十一日/t ）/w。 首先引入需要用到的库： import re import sklearn_crfsuite from sklearn_crfsuite import metrics from sklearn.externals import joblib 数据预处理，定义 CorpusProcess 类，我们还是先给出类实现框架： class CorpusProcess(object): def __init__(self): &quot;&quot;&quot;初始化&quot;&quot;&quot; pass def read_corpus_from_file(self, file_path): &quot;&quot;&quot;读取语料&quot;&quot;&quot; pass def write_corpus_to_file(self, data, file_path): &quot;&quot;&quot;写语料&quot;&quot;&quot; pass def q_to_b(self,q_str): &quot;&quot;&quot;全角转半角&quot;&quot;&quot; pass def b_to_q(self,b_str): &quot;&quot;&quot;半角转全角&quot;&quot;&quot; pass def pre_process(self): &quot;&quot;&quot;语料预处理 &quot;&quot;&quot; pass def process_k(self, words): &quot;&quot;&quot;处理大粒度分词,合并语料库中括号中的大粒度分词,类似：[国家/n 环保局/n]nt &quot;&quot;&quot; pass def process_nr(self, words): &quot;&quot;&quot; 处理姓名，合并语料库分开标注的姓和名，类似：温/nr 家宝/nr&quot;&quot;&quot; pass def process_t(self, words): &quot;&quot;&quot;处理时间,合并语料库分开标注的时间词，类似： （/w 一九九七年/t 十二月/t 三十一日/t ）/w &quot;&quot;&quot; pass def pos_to_tag(self, p): &quot;&quot;&quot;由词性提取标签&quot;&quot;&quot; pass def tag_perform(self, tag, index): &quot;&quot;&quot;标签使用BIO模式&quot;&quot;&quot; pass def pos_perform(self, pos): &quot;&quot;&quot;去除词性携带的标签先验知识&quot;&quot;&quot; pass def initialize(self): &quot;&quot;&quot;初始化 &quot;&quot;&quot; pass def init_sequence(self, words_list): &quot;&quot;&quot;初始化字序列、词性序列、标记序列 &quot;&quot;&quot; pass def extract_feature(self, word_grams): &quot;&quot;&quot;特征选取&quot;&quot;&quot; pass def segment_by_window(self, words_list=None, window=3): &quot;&quot;&quot;窗口切分&quot;&quot;&quot; pass def generator(self): &quot;&quot;&quot;训练数据&quot;&quot;&quot; pass 由于整个代码实现过程较长，我这里给出重点步骤，最后会在 Github 上连同语料代码一同给出 ，下面是关键过程实现。 对语料中的句子、词性，实体分类标记进行区分。标签采用“BIO”体系，即实体的第一个字为 B_*，其余字为 I_*，非实体字统一标记为O。大部分情况下，标签体系越复杂，准确度也越高，但这里采用简单的 BIO 体系也能达到相当不错的效果。这里模型采用 tri-gram形式，所以在字符列中，要在句子前后加上占位符。 def init_sequence(self, words_list): &quot;&quot;&quot;初始化字序列、词性序列、标记序列 &quot;&quot;&quot; words_seq = [[word.split(u&#39;/&#39;)[0] for word in words] for words in words_list] pos_seq = [[word.split(u&#39;/&#39;)[1] for word in words] for words in words_list] tag_seq = [[self.pos_to_tag(p) for p in pos] for pos in pos_seq] self.pos_seq = [[[pos_seq[index][i] for _ in range(len(words_seq[index][i]))] for i in range(len(pos_seq[index]))] for index in range(len(pos_seq))] self.tag_seq = [[[self.tag_perform(tag_seq[index][i], w) for w in range(len(words_seq[index][i]))] for i in range(len(tag_seq[index]))] for index in range(len(tag_seq))] self.pos_seq = [[u&#39;un&#39;]+[self.pos_perform(p) for pos in pos_seq for p in pos]+[u&#39;un&#39;] for pos_seq in self.pos_seq] self.tag_seq = [[t for tag in tag_seq for t in tag] for tag_seq in self.tag_seq] self.word_seq = [[u&#39;&lt;BOS&gt;&#39;]+[w for word in word_seq for w in word]+[u&#39;&lt;EOS&gt;&#39;] for word_seq in words_seq] 处理好语料之后，紧接着进行模型定义和训练，定义 CRF_NER 类，我们还是采用先给出类实现框架，再具体讲解其实现： class CRF_NER(object): def __init__(self): &quot;&quot;&quot;初始化参数&quot;&quot;&quot; pass def initialize_model(self): &quot;&quot;&quot;初始化&quot;&quot;&quot; pass def train(self): &quot;&quot;&quot;训练&quot;&quot;&quot; pass def predict(self, sentence): &quot;&quot;&quot;预测&quot;&quot;&quot; pass def load_model(self): &quot;&quot;&quot;加载模型 &quot;&quot;&quot; pass def save_model(self): &quot;&quot;&quot;保存模型&quot;&quot;&quot; pass 在 CRF_NER 类中，分别完成了语料预处理和模型训练、保存、预测功能，具体实现如下。 第一步，init 函数实现了模型参数定义和 CorpusProcess 的实例化和语料预处理： def __init__(self): &quot;&quot;&quot;初始化参数&quot;&quot;&quot; self.algorithm = &quot;lbfgs&quot; self.c1 =&quot;0.1&quot; self.c2 = &quot;0.1&quot; self.max_iterations = 100 #迭代次数 self.model_path = dir + &quot;model.pkl&quot; self.corpus = CorpusProcess() #Corpus 实例 self.corpus.pre_process() #语料预处理 self.corpus.initialize() #初始化语料 self.model = None 第二步，给出模型定义，了解 sklearn_crfsuite.CRF 详情可查该[文档](https://sklearn-crfsuite.readthedocs.io/en/latest/api.html#sklearn_crfsuite.CRF)。 def initialize_model(self): &quot;&quot;&quot;初始化&quot;&quot;&quot; algorithm = self.algorithm c1 = float(self.c1) c2 = float(self.c2) max_iterations = int(self.max_iterations) self.model = sklearn_crfsuite.CRF(algorithm=algorithm, c1=c1, c2=c2, max_iterations=max_iterations, all_possible_transitions=True) 第三步，模型训练和保存，分为训练集和测试集： def train(self): &quot;&quot;&quot;训练&quot;&quot;&quot; self.initialize_model() x, y = self.corpus.generator() x_train, y_train = x[500:], y[500:] x_test, y_test = x[:500], y[:500] self.model.fit(x_train, y_train) labels = list(self.model.classes_) labels.remove(&#39;O&#39;) y_predict = self.model.predict(x_test) metrics.flat_f1_score(y_test, y_predict, average=&#39;weighted&#39;, labels=labels) sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0])) print(metrics.flat_classification_report(y_test, y_predict, labels=sorted_labels, digits=3)) self.save_model() 第四至第六步中 predict、load_model、save_model 方法的实现，大家可以在文末给出的地址中查看源码，这里就不堆代码了。 最后，我们来看看模型训练和预测的过程和结果： ner = CRF_NER() model = ner.train() 经过模型训练，得到的准确率和召回率如下： 进行模型预测，其结果还不错，如下： 基于 CRF的中文命名实体识别模型实现先讲到这儿，项目源码和涉及到的语料，大家可以到：Github上查看。 总结本文浅析了条件随机场，并使用 sklearn_crfsuite.CRF模型，对人民日报1998年标注数据进行了模型训练和预测，以帮助大家加强对条件随机场的理解。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>crf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模型部署上线的几种服务发布方式（18）]]></title>
    <url>%2F2019%2F11%2F22%2F18.%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%E7%9A%84%E5%87%A0%E7%A7%8D%E6%9C%8D%E5%8A%A1%E5%8F%91%E5%B8%83%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在前面所有的模型训练和预测中，我们训练好的模型都是直接通过控制台或者 Jupyter Notebook来进行预测和交互的，在一个系统或者项目中使用这种方式显然不可能，那在 Web 应用中如何使用我们训练好的模型呢？ 本文将通过以下四个方面对该问题进行讲解： 微服务架构简介； 模型的持久化与加载方式； Flask 和 Bottle 微服务框架； Tensorflow Serving 模型部署和服务。 微服务架构简介微服务是指开发一个单个小型的但有业务功能的服务，每个服务都有自己的处理和轻量通讯机制，可以部署在单个或多个服务器上。微服务也指一种松耦合的、有一定的有界上下文的面向服务架构。也就是说，如果每个服务都要同时修改，那么它们就不是微服务，因为它们紧耦合在一起；如果你需要掌握一个服务太多的上下文场景使用条件，那么它就是一个有上下文边界的服务，这个定义来自DDD 领域驱动设计。 相对于单体架构和 SOA，它的主要特点是组件化、松耦合、自治、去中心化，体现在以下几个方面： 一组小的服务：服务粒度要小，而每个服务是针对一个单一职责的业务能力的封装，专注做好一件事情； 独立部署运行和扩展：每个服务能够独立被部署并运行在一个进程内。这种运行和部署方式能够赋予系统灵活的代码组织方式和发布节奏，使得快速交付和应对变化成为可能。 独立开发和演化：技术选型灵活，不受遗留系统技术约束。合适的业务问题选择合适的技术可以独立演化。服务与服务之间采取与语言无关的 API 进行集成。相对单体架构，微服务架构是更面向业务创新的一种架构模式。 独立团队和自治：团队对服务的整个生命周期负责，工作在独立的上下文中，自己决策自己治理，而不需要统一的指挥中心。团队和团队之间通过松散的社区部落进行衔接。 由此，我们可以看到整个微服务的思想，与我们现在面对信息爆炸、知识爆炸做事情的思路是相通的：通过解耦我们所做的事情，分而治之以减少不必要的损耗，使得整个复杂的系统和组织能够快速地应对变化。 我们为什么采用微服务呢？ “让我们的系统尽可能快地响应变化” ——Rebecca Parson 下面是一个简单的微服务模型架构设计： 模型的持久化与加载方式开发过 J2EE应用的人应该对持久化的概念很清楚。通俗得讲，就是临时数据（比如内存中的数据，是不能永久保存的）持久化为持久数据（比如持久化至数据库中，能够长久保存）。 那我们训练好的模型一般都是存储在内存中，这个时候就需要用到持久化方式，在 Python 中，常用的模型持久化方式有三种，并且都是以文件的方式持久化。 1.JSON（JavaScript Object Notation）格式。 JSON 是一种轻量级的数据交换格式，易于人们阅读和编写。使用 JSON 函数需要导入 JSON 库： import json 它拥有两个格式处理函数： json.dumps：将 Python 对象编码成 JSON 字符串； json.loads：将已编码的 JSON 字符串解码为 Python 对象。 下面看一个例子。 首先我们创建一个 List 对象 data，然后把 data 编码成 JSON 字符串保存在 data.json 文件中，之后再读取 data.json文件中的字符串解码成 Python 对象，代码如下： 2. pickle 模块 pickle 提供了一个简单的持久化功能。可以将对象以文件的形式存放在磁盘上。pickle 模块只能在 Python 中使用，Python中几乎所有的数据类型（列表、字典、集合、类等）都可以用 pickle 来序列化。pickle 序列化后的数据，可读性差，人一般无法识别。 使用的时候需要引入库： import pickle 它有以下两个方法： pickle.dump(obj, file[, protocol])：序列化对象，并将结果数据流写入到文件对象中。参数 protocol 是序列化模式，默认值为0，表示以文本的形式序列化。protocol 的值还可以是1或2，表示以二进制的形式序列化。 pickle.load(file)：反序列化对象。将文件中的数据解析为一个 Python 对象。 我们继续延用上面的例子。实现的不同点在于，这次文件打开时用了 with...as... 语法，使用 pickle 保存结果，文件保存为data.pkl，代码如下。3. sklearn 中的 joblib 模块。使用 joblib，首先需要引入包： from sklearn.externals import joblib 使用方法如下，基本和 JSON、pickle一样，这里不再详细讲解。第17课中，进行模型保存时使用的就是这种方式，可以看代码，回顾一下。 joblib.dump(model, model_path) #模型保存 joblib.load(model_path) #模型加载 Flask 和 Bottle 微服务框架通过上面，我们对微服务和 Python 中三种模型持久化和加载方式有了基本了解。下面我们看看，Python 中如何把模型发布成一个微服务的。 这里给出两个微服务框架 Bottle 和Flask。 Bottle 是一个非常小巧但高效的微型 Python Web 框架，它被设计为仅仅只有一个文件的 Python 模块，并且除 Python标准库外，它不依赖于任何第三方模块。 Bottle 本身主要包含以下四个模块，依靠它们便可快速开发微 Web 服务： 路由（Routing）：将请求映射到函数，可以创建十分优雅的 URL； 模板（Templates）：可以快速构建 Python 内置模板引擎，同时还支持 Mako、Jinja2、Cheetah 等第三方模板引擎； 工具集（Utilites）：用于快速读取 form 数据，上传文件，访问 Cookies，Headers 或者其它 HTTP 相关的 metadata； 服务器（Server）：内置 HTTP 开发服务器，并且支持 paste、fapws3、 bjoern、Google App Engine、Cherrypy 或者其它任何 WSGI HTTP 服务器。 Flask 也是一个 Python 编写的 Web 微框架，可以让我们使用 Python 语言快速实现一个网站或 Web 服务。并使用方式和 Bottle相似，Flask 依赖 Jinja2 模板和 Werkzeug WSGI 服务。Werkzeug 本质是 Socket 服务端，其用于接收 HTTP请求并对请求进行预处理，然后触发 Flask 框架，开发人员基于 Flask框架提供的功能对请求进行相应的处理，并返回给用户，如果返回给用户的内容比较复杂时，需要借助 Jinja2模板来实现对模板的处理，即将模板和数据进行渲染，将渲染后的字符串返回给用户浏览器。 Bottle 和 Flask 在使用上相似，而且 Flask 的文档资料更全，发布的服务更稳定，因此下面重点以 Flask为例，来说明模型的微服务发布过程。 如果大家想进一步了解这两个框架，可以参考说明文档。 1.安装。 对 Bottle 和 Flask 进行安装，分别执行如下命令即可安装成功： pip install bottle pip install Flask 安装好之后，分别进入需要的包就可以写微服务程序了。这两个框架在使用时，用法、语法结构都差不多，网上 Flask 的中文资料相对多一些，所以这里用 Flask来举例。 2. 第一个最小的 Flask 应用。 第一个最小的 Flask 应用看起来会是这样: from flask import Flask app = Flask(__name__) @app.route(&#39;/&#39;) def hello_world(): return &#39;Hello World!&#39; if __name__ == &#39;__main__&#39;: app.run() 把它保存为 hello.py（或是类似的），然后用 Python 解释器来运行： python hello.py 或者直接在 Jupyter Notebook 里面执行，都没有问题。服务启动将在控制台打印如下消息： Running on http://127.0.0.1:5000/ 意思就是，可以通过 localhost 和 5000 端口，在浏览器访问： 这时我们就得到了服务在浏览器上的返回结果，于是也成功构建了与浏览器交互的服务。 如果要修改服务对应的 IP 地址和端口怎么办？只需要修改这行代码，即可修改 IP 地址和端口： app.run(host=&#39;192.168.31.19&#39;,port=8088) 3. Flask 发布一个预测模型。 首先，我们这里使用第17课保存的模型“model.pkl”。如果不使用浏览器，常规的控制台交互，我们这样就可以实现： from sklearn.externals import joblib model_path = &quot;D://达人课//中文自然语言处理入门实战课程//ch18//model.pkl&quot; model = joblib.load(model_path) sen =[[[&#39;坚决&#39;, &#39;a&#39;, &#39;ad&#39;, &#39;1_v&#39;], [&#39;惩治&#39;, &#39;v&#39;, &#39;v&#39;, &#39;0_Root&#39;], [&#39;贪污&#39;, &#39;v&#39;, &#39;v&#39;, &#39;1_v&#39;], [&#39;贿赂&#39;, &#39;n&#39;, &#39;n&#39;, &#39;-1_v&#39;], [&#39;等&#39;, &#39;u&#39;, &#39;udeng&#39;, &#39;-1_v&#39;], [&#39;经济&#39;, &#39;n&#39;, &#39;n&#39;, &#39;1_v&#39;], [&#39;犯罪&#39;, &#39;v&#39;, &#39;vn&#39;, &#39;-2_v&#39;]]] print(model.predict(sen)) 如果你现在有个需求，要求你的模型和浏览器进行交互，那 Flask 就可以实现。在第一个最小的 Flask 应用基础上，我们增加模型预测接口，这里注意： 启动之前把 IP 地址修改为自己本机的地址或者服务器工作站所在的 IP地址。 完整的代码如下，首先在启动之前先把模型预加载到内存中，然后重新定义 predict 函数，接受一个参数 sen： from sklearn.externals import joblib from flask import Flask,request app = Flask(__name__) @app.route(&#39;/&#39;) def hello_world(): return &#39;Hello World!&#39; @app.route(&#39;/predict/&lt;sen&gt;&#39;) def predict(sen): result = model.predict(sen) return str(result) if __name__ == &#39;__main__&#39;: model_path = &quot;D://ch18//model.pkl&quot; model = joblib.load(model_path) app.run(host=&#39;192.168.31.19&#39;) 启动 Flask 服务之后，在浏览器地址中输入： http://192.168.31.19:5000/predict/[[[&#39;坚决&#39;, ‘a’, ‘ad’, ‘1 v’], [‘惩治’, ‘v’,’v’, ‘0 Root’], [‘贪污’, ‘v’, ‘v’, ‘1 v’], [‘贿赂’, ‘n’, ‘n’, ‘-1 v’], [‘等’,’u’, ‘udeng’, ‘-1 v’], [‘经济’, ‘n’, ‘n’, ‘1 v’], [‘犯罪’, ‘v’, ‘vn’, ‘-2_v’]]] 得到预测结果，这样就完成了微服务的发布，并实现了模型和前端浏览器的交互。 Tensorflow Serving 模型部署和服务TensorFlow Serving 是一个用于机器学习模型 Serving 的高性能开源库。它可以将训练好的机器学习模型部署到线上，使用 gRPC作为接口接受外部调用。更加让人眼前一亮的是，它支持模型热更新与自动模型版本管理。这意味着一旦部署 TensorFlow Serving后，你再也不需要为线上服务操心，只需要关心你的线下模型训练。 同样，TensorFlow Serving 可以将模型部署在移动端，如安卓或者 iOS 系统的 App 应用上。关于 Tensorflow Serving模型部署和服务，这里不在列举示例，直接参考文末的推荐阅读。 总结本节对微服务架构做了简单介绍，并介绍了三种机器学习模型持久化和加载的方式，接着介绍了 Python 的两个轻量级微服务框架 Bottle 和Flask。随后，我们通过 Flask 制作了一个简单的微服务预测接口，实现模型的预测和浏览器交互功能，最后简单介绍了 TensorFlow Servin模型的部署和服务功能。 学完上述内容，读者可轻易实现自己训练的模型和 Web 应用的结合，提供微服务接口，实现模型上线应用。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>bottle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于CRF的中文句法依存分析模型实现（17）]]></title>
    <url>%2F2019%2F11%2F22%2F17.%E5%9F%BA%E4%BA%8ECRF%E7%9A%84%E4%B8%AD%E6%96%87%E5%8F%A5%E6%B3%95%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[句法分析是自然语言处理中的关键技术之一，其基本任务是确定句子的句法结构或者句子中词汇之间的依存关系。主要包括两方面的内容，一是确定语言的语法体系，即对语言中合法句子的语法结构给予形式化的定义；另一方面是句法分析技术，即根据给定的语法体系，自动推导出句子的句法结构，分析句子所包含的句法单位和这些句法单位之间的关系。 依存关系本身是一个树结构，每一个词看成一个节点，依存关系就是一条有向边。本文主要通过清华大学的句法标注语料库，来实现基于 CRF 的中文句法依存分析模型。 清华大学句法标注语料库清华大学的句法标注语料，包括训练集（train.conll）和开发集合文件（dev.conll）。训练集大小 5.41M，共185541条数据。测试集大小为578kb，共19302条数据。 语料本身格式如下图所示： 通过上图，我们可以看出，每行语料包括有8个标签，分别是ID、FROM、lEMMA、CPOSTAG、POSTAG、FEATS、HEAD、DEPREL。详细介绍如下图： 模型的实现通过上面对句法依存关键技术的定义，我们明白了，句法依存的基本任务是确定句子的句法结构或者句子中词汇之间的依存关系。同时，我们也对此次模型实现的语料有了基本了解。 有了这些基础内容，我们便可以开始着手开发了。 本模型的实现过程，我们将主要分为训练集和测试集数据预处理、语料特征生成、模型训练及预测三大部分来实现，最终将通过模型预测得到正确的预测结果。 本次实战演练，我们选择以下模型和软件： Sklearn_crfsuite Python3.6 Jupyter Notebook 训练集和测试集数据预处理由于上述给定的语料，在模型中，我们不能直接使用，必须先经过预处理，把上述语料格式重新组织成具有词性、方向和距离的格式。 首先，我们通过一个 Python 脚本 get_parser_train_test_input.py，生成所需要的训练集和测试集，执行如下命令即可： cat train.conll | python get_parser_train_test_input.py &gt; train.data cat dev.conll | python get_parser_train_test_input.py &gt; dev.data 上面的脚本通过 cat 命令和管道符把内容传递给脚本进行处理。这里需要注意的是，脚本需要在 Linux 环境下执行，且语料和脚本应放在同一目录下。 get_parser_train_test_input.py 这一脚本的目的，就是重新组织语料，组织成可以使用 CRF算法的格式，具有词性、方向和距离的格式。我们认为，如果词 A 依赖词 B，A 就是孩子，B就是父亲。按照这种假设得到父亲节点的粗词性和详细词性，以及和依赖次之间的距离。 我们打开该脚本，看看它的代码，如下所示，重要的代码给出了注释。 #coding=utf-8 &#39;&#39;&#39;词A依赖词B，A就是孩子，B就是父亲&#39;&#39;&#39; import sys sentence = [&quot;Root&quot;] def do_parse(sentence): if len(sentence) == 1:return for line in sentence[1:]: line_arr = line.strip().split(&quot;\t&quot;) c_id = int(line_arr[0]) f_id = int(line_arr[6]) if f_id == 0: print(&quot;\t&quot;.join(line_arr[2:5])+&quot;\t&quot; + &quot;0_Root&quot;) continue f_post,f_detail_post = sentence[f_id].strip().split(&quot;\t&quot;)[3:5] #得到父亲节点的粗词性和详细词性 c_edge_post = f_post #默认是依赖词的粗粒度词性，但是名词除外；名词取细粒度词性 if f_post == &quot;n&quot;: c_edge_post = f_detail_post #计算是第几个出现这种词行 diff = f_id - c_id #确定要走几步 step = 1 if f_id &gt; c_id else -1 #确定每一步方向 same_post_num = 0 #中间每一步统计多少个一样的词性 cmp_idx = 4 if f_post == &quot;n&quot; else 3 #根据是否是名词决定取的是粗or详细词性 for i in range(0, abs(diff)): idx = c_id + (i+1)*step if sentence[idx].strip().split(&quot;\t&quot;)[cmp_idx] == c_edge_post: same_post_num += step print(&quot;\t&quot;.join(line_arr[2:5])+&quot;\t&quot; + &quot;%d_%s&quot;%(same_post_num, c_edge_post)) print(&quot;&quot;) for line in sys.stdin: line = line.strip() line_arr = line.split(&quot;\t&quot;) if line == &quot;&quot; or line_arr[0] == &quot;1&quot;: do_parse(sentence) sentence = [&quot;Root&quot;] if line ==&quot;&quot;:continue sentence.append(line) 整个脚本按行读入，每行按 Tab 键分割，首先得到父亲节点的词性，然后根据词性是否是名词 n 进行判断，默认是依赖词的粗粒度词性，如果是名词取细粒度词性。 脚本处理完，数据集的格式如下： 根据依存文法，决定两个词之间依存关系的主要有两个因素：方向和距离。正如上图中第四列类别标签所示，该列可以定义为以下形式： [+|-]dPOS 其中，[+|-] 表示中心词在句子中相对坐标轴的方向；POS 代表中心词具有的词性类别；d 表示与中心词词性相同的词的数量，即距离。 语料特征生成语料特征提取，主要采用 N-gram 模型来完成。这里我们使用 3-gram完成提取，将词性与词语两两进行匹配，分别返回特征集合和标签集合，需要注意整个语料采用的是 UTF-8 编码格式。 整个编码过程中，我们首先需要引入需要的库，然后对语料进行读文件操作。语料采用 UTF-8 编码格式，以句子为单位，按 Tab 键作分割处理，从而实现句子3-gram 模型的特征提取。具体实现如下。 import sklearn_crfsuite from sklearn_crfsuite import metrics from sklearn.externals import joblib 首先引入需要用到的库，如上面代码所示。其目的是使用模型 sklearn_crfsuite .CRF，metrics 用来进行模型性能测试，joblib用来保存和加载训练好的模型。 接着，定义包含特征处理方法的类，命名为 CorpusProcess，类结构定义如下： class CorpusProcess(object): def __init__(self): &quot;&quot;&quot;初始化&quot;&quot;&quot; pass def read_corpus_from_file(self, file_path): &quot;&quot;&quot;读取语料&quot;&quot;&quot; pass def write_corpus_to_file(self, data, file_path): &quot;&quot;&quot;写语料&quot;&quot;&quot; pass def process_sentence(self,lines): &quot;&quot;&quot;处理句子&quot;&quot;&quot; pass def initialize(self): &quot;&quot;&quot;语料初始化&quot;&quot;&quot; pass def generator(self, train=True): &quot;&quot;&quot;特征生成器&quot;&quot;&quot; pass def extract_feature(self, sentences): &quot;&quot;&quot;提取特征&quot;&quot;&quot; pass 下面介绍下 CorpusProcess 类中各个方法的具体实现。 第1步， 实现 init 构造函数，目的初始化预处理好的语料的路径： def __init__(self): &quot;&quot;&quot;初始化&quot;&quot;&quot; self.train_process_path = dir + &quot;data//train.data&quot; #预处理之后的训练集 self.test_process_path = dir + &quot;data//dev.data&quot; #预处理之后的测试集 这里的路径可以自定义，这里的语料之前已经完成了预处理过程。第2-3步，read_corpus_from_file 方法和 write_corpus_to_file 方法，分别定义了语料文件的读和写操作： def read_corpus_from_file(self, file_path): &quot;&quot;&quot;读取语料&quot;&quot;&quot; f = open(file_path, &#39;r&#39;,encoding=&#39;utf-8&#39;) lines = f.readlines() f.close() return lines def write_corpus_to_file(self, data, file_path): &quot;&quot;&quot;写语料&quot;&quot;&quot; f = open(file_path, &#39;w&#39;) f.write(str(data)) f.close() 这一步，主要用 open 函数来实现语料文件的读和写。 第4-5步，process_sentence 方法和 initialize 方法，用来处理句子和初始化语料，把语料按句子结构用 list存储起来，存储到内存中： def process_sentence(self,lines): &quot;&quot;&quot;处理句子&quot;&quot;&quot; sentence = [] for line in lines: if not line.strip(): yield sentence sentence = [] else: lines = line.strip().split(u&#39;\t&#39;) result = [line for line in lines] sentence.append(result) def initialize(self): &quot;&quot;&quot;语料初始化&quot;&quot;&quot; train_lines = self.read_corpus_from_file(self.train_process_path) test_lines = self.read_corpus_from_file(self.test_process_path) self.train_sentences = [sentence for sentence in self.process_sentence(train_lines)] self.test_sentences = [sentence for sentence in self.process_sentence(test_lines)] 这一步，通过 process_sentence 把句子收尾的空格去掉，然后通过 initialize 函数调用上面read_corpus_from_file 方法读取语料，分别加载训练集和测试集。 第6步，特征生成器，分别用来指定生成训练集或者测试集的特征集： def generator(self, train=True): &quot;&quot;&quot;特征生成器&quot;&quot;&quot; if train: sentences = self.train_sentences else: sentences = self.test_sentences return self.extract_feature(sentences) 这一步，对训练集和测试集分别处理，如果参数 train 为 True，则表示处理训练集，如果是 False，则表示处理测试集。第7步，特征提取，简单的进行 3-gram 的抽取，将词性与词语两两进行匹配，分别返回特征集合和标签集合： def extract_feature(self, sentences): &quot;&quot;&quot;提取特征&quot;&quot;&quot; features, tags = [], [] for index in range(len(sentences)): feature_list, tag_list = [], [] for i in range(len(sentences[index])): feature = {&quot;w0&quot;: sentences[index][i][0], &quot;p0&quot;: sentences[index][i][1], &quot;w-1&quot;: sentences[index][i-1][0] if i != 0 else &quot;BOS&quot;, &quot;w+1&quot;: sentences[index][i+1][0] if i != len(sentences[index])-1 else &quot;EOS&quot;, &quot;p-1&quot;: sentences[index][i-1][1] if i != 0 else &quot;un&quot;, &quot;p+1&quot;: sentences[index][i+1][1] if i != len(sentences[index])-1 else &quot;un&quot;} feature[&quot;w-1:w0&quot;] = feature[&quot;w-1&quot;]+feature[&quot;w0&quot;] feature[&quot;w0:w+1&quot;] = feature[&quot;w0&quot;]+feature[&quot;w+1&quot;] feature[&quot;p-1:p0&quot;] = feature[&quot;p-1&quot;]+feature[&quot;p0&quot;] feature[&quot;p0:p+1&quot;] = feature[&quot;p0&quot;]+feature[&quot;p+1&quot;] feature[&quot;p-1:w0&quot;] = feature[&quot;p-1&quot;]+feature[&quot;w0&quot;] feature[&quot;w0:p+1&quot;] = feature[&quot;w0&quot;]+feature[&quot;p+1&quot;] feature_list.append(feature) tag_list.append(sentences[index][i][-1]) features.append(feature_list) tags.append(tag_list) return features, tags 经过第6步，确定处理的是训练集还是测试集之后，通过 extract_feature 对句子进行特征抽取，使用 3-gram模型，得到特征集合和标签集合的对应关系。 模型训练及预测在完成特征工程和特征提取之后，接下来，我们要进行模型训练和预测，要预定义模型需要的一些参数，并初始化模型对象，进而完成模型训练和预测，以及模型的保存与加载。 首先，我们定义模型 ModelParser 类，进行初始化参数、模型初始化，以及模型训练、预测、保存和加载，类的结构定义如下： class ModelParser(object): def __init__(self): &quot;&quot;&quot;初始化参数&quot;&quot;&quot; pass def initialize_model(self): &quot;&quot;&quot;模型初始化&quot;&quot;&quot; pass def train(self): &quot;&quot;&quot;训练&quot;&quot;&quot; pass def predict(self, sentences): &quot;&quot;&quot;模型预测&quot;&quot;&quot; pass def load_model(self, name=&#39;model&#39;): &quot;&quot;&quot;加载模型 &quot;&quot;&quot; pass def save_model(self, name=&#39;model&#39;): &quot;&quot;&quot;保存模型&quot;&quot;&quot; pass 接下来，我们分析 ModelParser 类中方法的具体实现。第1步，init 方法实现算法模型参数和语料预处理 CorpusProcess 类的实例化和初始化： def __init__(self): &quot;&quot;&quot;初始化参数&quot;&quot;&quot; self.algorithm = &quot;lbfgs&quot; self.c1 = 0.1 self.c2 = 0.1 self.max_iterations = 100 self.model_path = &quot;model.pkl&quot; self.corpus = CorpusProcess() #初始化CorpusProcess类 self.corpus.initialize() #语料预处理 self.model = None 这一步，init 方法初始化参数以及 CRF 模型的参数，算法选用 LBFGS，c1 和 c2分别为0.1，最大迭代次数100次。然后定义模型保存的文件名称，以及完成对 CorpusProcess 类 的初始化。 第2-3步，initialize_model 方法和 train 实现模型定义和训练： def initialize_model(self): &quot;&quot;&quot;模型初始化&quot;&quot;&quot; algorithm = self.algorithm c1 = float(self.c1) c2 = float(self.c2) max_iterations = int(self.max_iterations) self.model = sklearn_crfsuite.CRF(algorithm=algorithm, c1=c1, c2=c2, max_iterations=max_iterations, all_possible_transitions=True) def train(self): &quot;&quot;&quot;训练&quot;&quot;&quot; self.initialize_model() x_train, y_train = self.corpus.generator() self.model.fit(x_train, y_train) labels = list(self.model.classes_) x_test, y_test = self.corpus.generator(train=False) y_predict = self.model.predict(x_test) metrics.flat_f1_score(y_test, y_predict, average=&#39;weighted&#39;, labels=labels) sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0])) print(metrics.flat_classification_report(y_test, y_predict, labels=sorted_labels, digits=3)) self.save_model() 这一步，initialize_model 方法实现 了 sklearn_crfsuite.CRF 模型的初始化。然后在 train 方法中，先通过fit 方法训练模型，再通过 metrics.flat_f1_score 对测试集进行 F1 性能测试，最后将模型保存。 第4-6步，分别实现模型预测、保存和加载方法 最后，实例化类，并进行模型训练： model = ModelParser() model.train() 对模型进行预测，预测数据输入格式为三维，表示完整的一句话： [[[‘坚决’, ‘a’, ‘ad’, ‘1_v’], [&#39;惩治&#39;, &#39;v&#39;, &#39;v&#39;, &#39;0_Root&#39;], [&#39;贪污&#39;, &#39;v&#39;, &#39;v&#39;, &#39;1_v&#39;], [&#39;贿赂&#39;, &#39;n&#39;, &#39;n&#39;, &#39;-1_v&#39;], [&#39;等&#39;, &#39;u&#39;, &#39;udeng&#39;, &#39;-1_v&#39;], [&#39;经济&#39;, &#39;n&#39;, &#39;n&#39;, &#39;1_v&#39;], [&#39;犯罪&#39;, &#39;v&#39;, &#39;vn&#39;, &#39;-2_v&#39;]]] 模型预测的结果如下图所示： 预测的结果，和原始语料预处理得到的标签格式保持一致。 总结本文通过清华大学的句法标注语料库，实现了基于 CRF 的中文句法依存分析模型。借此实例，相信大家对句法依存已有了一个完整客观的认识。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>crf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中文自然语言处理的应用、现状和未来（21）]]></title>
    <url>%2F2019%2F11%2F22%2F21.%E4%B8%AD%E6%96%87%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%9A%84%E5%BA%94%E7%94%A8%E3%80%81%E7%8E%B0%E7%8A%B6%E5%92%8C%E6%9C%AA%E6%9D%A5%2F</url>
    <content type="text"><![CDATA[自然语言理解和自然语言生成是自然语言处理的两大内核，机器翻译是自然语言理解方面最早的研究工作。自然语言处理的主要任务是：研究表示语言能力和语言应用的模型，建立和实现计算框架并提出相应的方法不断地完善模型，根据这样的语言模型设计有效地实现自然语言通信的计算机系统，并研讨关于系统的评测技术，最终实现用自然语言与计算机进行通信。目前，具有一定自然语言处理能力的典型应用包括计算机信息检索系统、多语种翻译系统等。 微软创始人比尔·盖茨曾经表示，“语言理解是人工智能领域皇冠上的明珠”。 语言是逻辑思维和交流的工具，宇宙万物中，只有人类才具有这种高级功能。要实现人与计算机间采用自然语言通信，必须使计算机同时具备自然语言理解和自然语言生成两大功能。 因此，NLP作为人工智能的一个子领域，其主要目的就包括两个方面：自然语言理解，让计算机理解自然语言文本的意义；自然语言生成，让计算机能以自然语言文本来表达给定的意图、思想等。自然语言是人类智慧的结晶，自然语言处理是人工智能中最为困难的问题之一，而对自然语言处理的研究也是充满魅力和挑战的。 NLP 领域发展现状如何？近年来，自然语言处理处于快速发展阶段。各种词表、语义语法词典、语料库等数据资源的日益丰富，词语切分、词性标注、句法分析等技术的快速进步，各种新理论、新方法、新模型的出现推动了自然语言处理研究的繁荣。互联网与移动互联网和世界经济社会一体化的潮流对自然语言处理技术的迫切需求，为自然语言处理研究发展提供了强大的市场动力。 我国直到上世纪80年代中期才开始较大规模和较系统的自然语言处理研究，尽管较国际水平尚有较大差距，但已经有了比较稳定的研究内容，包括语料库、知识库等数据资源建设，词语切分、句法分析等基础技术，以及信息检索、机器翻译等应用技术。 当前国内外出现了一批基于 NLP 技术的应用系统，例如 IBM 的 Watson 在电视问答节目中战胜人类冠军；苹果公司的 Siri个人助理被大众广为测试；谷歌、微软、百度等公司纷纷发布个人智能助理；科大讯飞牵头研发高考机器人……但相比于性能趋于饱和的计算机视觉和语音识别技术，自然语言处理因技术难度太大、应用场景太复杂，研究成果还未达到足够的高度。 自然语言处理中句子级分析技术目前，自然语言处理的对象有词、句子、篇章和段落、文本等，但是大多归根到底在句子的处理上，自然语言处理中的自然语言句子级分析技术，可以大致分为词法分析、句法分析、语义分析三个层面。 第一层面的词法分析包括汉语分词和词性标注两部分。和大部分西方语言不同，汉语书面语词语之间没有明显的空格标记，文本中的句子以字串的形式出现。因此汉语自然语言处理的首要工作就是要将输入的字串切分为单独的词语，然后在此基础上进行其他更高级的分析，这一步骤称为分词。 除了分词，词性标注也通常认为是词法分析的一部分。给定一个切好词的句子，词性标注的目的是为每一个词赋予一个类别，这个类别称为词性标记，比如，名词（Noun）、动词（Verb）、形容词（Adjective）等。一般来说，属于相同词性的词，在句法中承担类似的角色。 第二个层面的句法分析是对输入的文本句子进行分析以得到句子的句法结构的处理过程。对句法结构进行分析，一方面是语言理解的自身需求，句法分析是语言理解的重要一环，另一方面也为其它自然语言处理任务提供支持。例如句法驱动的统计机器翻译需要对源语言或目标语言（或者同时两种语言）进行句法分析；语义分析通常以句法分析的输出结果作为输入以便获得更多的指示信息。 根据句法结构表示形式的不同，最常见的句法分析任务可以分为以下三种： 短语结构句法分析，该任务也被称作成分句法分析，作用是识别出句子中的短语结构以及短语之间的层次句法关系； 依存句法分析，作用是识别句子中词汇与词汇之间的相互依存关系； 深层文法句法分析，即利用深层文法，例如词汇化树邻接文法、词汇功能文法、组合范畴文法等，对句子进行深层的句法以及语义分析。 上述几种句法分析任务比较而言，依存句法分析属于浅层句法分析。其实现过程相对简单，比较适合在多语言环境下的应用，但是依存句法分析所能提供的信息也相对较少。深层文法句法分析可以提供丰富的句法和语义信息，但是采用的文法相对复杂，分析器的运行复杂度也较高，这使得深层句法分析当前不适合处理大规模数据。短语结构句法分析介于依存句法分析和深层文法句法分析之间。 第三个层面是语义分析。语义分析的最终目的是理解句子表达的真实语义。但是，语义应该采用什么表示形式一直困扰着研究者们，至今这个问题也没有一个统一的答案。 语义角色标注是目前比较成熟的浅层语义分析技术。基于逻辑表达的语义分析也得到学术界的长期关注。出于机器学习模型复杂度、效率的考虑，自然语言处理系统通常采用级联的方式，即分词、词性标注、句法分析、语义分析分别训练模型。实际使用时，给定输入句子，逐一使用各个模块进行分析，最终得到所有结果。 深度学习背景下的自然语言处理近年来，随着研究工作的深入，研究者们开始从传统机器学习转向深度学习。2006年开始，有人利用深层神经网络在大规模无标注语料上无监督的为每个词学到了一个分布式表示，形式上把每个单词表示成一个固定维数的向量，当作词的底层特征。在此特征基础上，完成了词性标注、命名实体识别和语义角色标注等多个任务，后来有人利用递归神经网络完成了句法分析、情感分析和句子表示等多个任务，这也为语言表示提供了新的思路。 面向自然语言处理的深度学习研究工作，目前尚处于起步阶段，尽管已有的深度学习算法模型如循环神经网络、递归神经网络和卷积神经网络等已经有较为显著的应用，但还没有重大突破。围绕适合自然语言处理领域的深度学习模型构建等研究应该有着非常广阔的空间。 在当前已有的深度学习模型研究中，难点是在模型构建过程中参数的优化调整方面。主要有深度网络层数、正则化问题及网络学习速率等，可能的解决方案比如有采用多核机提升网络训练速度，针对不同应用场合，选择合适的优化算法等。 自然语言处理未来的研究方向纵观自然语言处理技术研究发展的态势和现状，以下研究方向或问题将可能成为自然语言处理未来研究必须攻克的堡垒： 词法和句法分析方面：包括多粒度分词、新词发现、词性标注等； 语义分析方面：包括词义消歧、非规范文本的语义分析。其中，非规范划化文本主要指社交平台上比较口语化、弱规范甚至不规范的短文本，因其数据量巨大和实时性而具有研究和应用价值，被广泛用于舆情监控、情感分析和突发事件发现等任务； 语言认知模型方面：比如使用深度神经网络处理自然语言，建立更有效、可解释的语言计算模型，例如，词嵌入的发现。还有目前词的表示是通过大量的语料库学习得到的，如何通过基于少量样本来发现新词、低频词也急需探索； 知识图谱方面：如何构建能够融合符号逻辑和表示学习的大规模高精度的知识图谱； 文本分类与聚类方面：通过有监督、半监督和无监督学习，能够准确进行分类和聚类。当下大多数语料都是没有标签的，未来在无监督或者半监督方面更有需求； 信息抽取方面：对于多源异构信息，如何准确进行关系、事件的抽取等。信息抽取主要从面向开放域的可扩展信息抽取技术、自学习与自适应和自演化的信息抽取系统以及面向多源异构数据的信息融合技术方向发展； 情感分析方面：包括基于上下文感知的情感分析、跨领域跨语言情感分析、基于深度学习的端到端情感分析、情感解释、反讽分析、立场分析等； 自动文摘方面：如何表达要点信息？如何评估信息单元的重要性？这些都要随着语义分析、篇章理解、深度学习等技术快速发展； 信息检索方面：包括意图搜索、语义搜索等，都将有可能出现在各种场景的垂直领域，将以知识化推理为检索运行方式，以自然语言多媒体交互为手段的智能化搜索与推荐技术； 自动问答方面：包括深度推理问答、多轮问答等各种形式的自动问答系统； 机器翻译方面：包括面向小数据的机器翻译、非规范文本的机器翻译和篇章级机器翻译等。 总结本文，从 NLP 的概念出发，首先指出了自然语言处理的两大内核：自然语言理解和自然语言生成；然后简单介绍了国内外 NLP研究发展现状；紧接着重点介绍了最常用、应用最广的自然语言处理中句子级分析技术，最后在深度学习背景下，指出了自然语言处理未来可能遇到的挑战和重点研究方向，为后期的学习提供指导和帮助。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[知识挖掘与知识图谱概述（19）]]></title>
    <url>%2F2019%2F11%2F22%2F19.%E7%9F%A5%E8%AF%86%E6%8C%96%E6%8E%98%E4%B8%8E%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[搜索技术日新月异，如今它不再是搜索框中输入几个单词那么简单了。不仅输入方式多样化，并且还要在非常短的时间内给出一个精准而又全面的答案。目前，谷歌给出的解决方案就是——知识图谱（KnowledgeGraph）。 知识图谱能做什么？知识图谱想做的，就是在不同数据（来自现实世界）之间建立联系，从而带给我们更有意义的搜索结果。 比如，在上图中，用 Google搜索自然语言处理，右侧会显示研究领域和相关概念。点击这些知识点，又可以深入了解；再比如，搜索一个人名时，右侧会给出此人的生平、背景、居住位置、作品等信息。 这就是知识图谱，它不再是单一的信息，而是一个多元的信息网络。 知识图谱的源头知识图谱的雏形好几年前就已出现，一家名为 Metaweb的小公司，将现实世界中实体（人或事）的各种数据信息存储在系统中，并在数据之间建立起联系，从而发展出有别于传统关键词搜索的技术。 谷歌认为这一系统很有发展潜力，于2010年收购了 Metaweb。那时 Metawab 已经存储了1200万个节点（ReferencePoint，相当于一个词条或者一个页面），谷歌收购后的两年中，大大加速这一进程，现已有超过5.7亿个节点并在它们之间建了180亿个有效连接（这可是一个相当大的数字，维基百科英文版也才有大约400万个节点）。 知识图谱的通用表示方法本质上，知识图谱是一种揭示实体之间关系的语义网络 ，可以对现实世界的事物及其相互关系进行形式化地描述 。现在的知识图谱己被用来泛指各种大规模的知识库 。 三元组是知识图谱的一种通用表示方式，即 ${G=(E，R，S)}$，其中 $E={e_1，e_2，…，e_{|E|}}$ 是知识库中的实体集合，共包含$|E|$ 种不同实体，$R={r_1，r_2，…,r_{|E|}}$ 是知识库中的关系集合，共包含 $|R|$ 种不同关系，$S \subseteqE×R×E$ 代表知识库中的三元组集合。 三元组的基本形式主要包括实体 A、关系、实体 B和概念、属性、属性值等，实体是知识图谱中的最基本元素，不同的实体间存在不同的关系。概念主要指集合、类别、对象类型、事物的种类，例如人物、地理等；属性主要指对象可能具有的属性、特征、特性、特点以及参数，例如国籍、生日等；属性值主要指对象指定属性的值，例如中国、1988—09—08等。每个实体（概念的外延）可用一个全局唯一确定的ID 来标识，每个属性—属性值对可用来刻画实体的内在特性，而关系可用来连接两个实体，刻画它们之间的关联。 如下图是实体 A 与实体 B 组成的一个简单三元组形式。 知识图谱的架构知识图谱的架构主要包括自身的逻辑结构以及体系架构，分别说明如下。 1. 知识图谱的逻辑结构。 知识图谱在逻辑上可分为模式层与数据层两个层次，数据层主要是由一系列的事实组成，而知识将以事实为单位进行存储。如果用（实体 A，关系，实体B）、（实体、属性，属性值）这样的三元组来表达事实，可选择图数据库作为存储介质，例如开源的 Neo4j、Twitter 的 FlockDB、Sones 的GraphDB等。模式层构建在数据层之上，主要是通过本体库来规范数据层的一系列事实表达。本体是结构化知识库的概念模板，通过本体库而形成的知识库不仅层次结构较强，并且冗余程度较小。 2. 知识图谱的体系架构。 知识图谱的体系架构是指其构建模式结构，如图下图所示。 知识图谱主要有自顶向下与自底向上两种构建方式。自顶向下指的是先为知识图谱定义好本体与数据模式，再将实体加入到知识库。该构建方式需要利用一些现有的结构化知识库作为其基础知识库，例如Freebase项目就是采用这种方式，它的绝大部分数据是从维基百科中得到的。自底向上指的是从一些开放链接数据中提取出实体，选择其中置信度较高的加入到知识库，再构建顶层的本体模式。目前，大多数知识图谱都采用自底向上的方式进行构建，其中最典型就是Google 的 Knowledge Vault。 知识图谱的关键技术大规模知识库的构建与应用需要多种智能信息处理技术的支持。这就涉及到当下异常火爆的人工智能中的自然语言处理（NLP）技术。 所谓自然语言，就是我们平时所说的话（包括语音或文字），但这些话计算机如何能“理解”？过程很复杂，下面是其中的几个关键步骤。 1. 知识抽取。 知识抽取技术，可以从一些公开的半结构化、非结构化的数据中提取出实体、关系、属性等知识要素。 知识抽取主要包含实体抽取、关系抽取、属性抽取等，涉及到的 NLP 技术有命名实体识别、句法依存、实体关系识别等。 2. 知识表示。 知识表示形成的综合向量对知识库的构建、推理、融合以及应用均具有重要的意义。 基于三元组的知识表示形式受到了人们广泛的认可，但是其在计算效率、数据稀疏性等方面却面临着诸多问题。近年来，以深度学习为代表的表示学习技术取得了重要的进展，可以将实体的语义信息表示为稠密低维实值向量，进而在低维空间中高效计算实体、关系及其之间的复杂语义关联。 知识表示学习主要包含的 NLP 技术有语义相似度计算、复杂关系模型，知识代表模型如距离模型、双线性模型、神经张量模型、矩阵分解模型、翻译模型等。 3.知识融合。 由于知识图谱中的知识来源广泛，存在知识质量良莠不齐、来自不同数据源的知识重复、知识间的关联不够明确等问题，所以必须要进行知识的融合。知识融合是高层次的知识组织，使来自不同知识源的知识在同一框架规范下进行异构数据整合、消歧、加工、推理验证、更新等步骤，达到数据、信息、方法、经验以及人的思想的融合，形成高质量的知识库。 在知识融合过程中，实体对齐、知识加工是两个重要的过程。 4.知识推理。 知识推理则是在已有的知识库基础上进一步挖掘隐含的知识，从而丰富、扩展知识库。在推理的过程中，往往需要关联规则的支持。由于实体、实体属性以及关系的多样性，人们很难穷举所有的推理规则，一些较为复杂的推理规则往往是手动总结的。对于推理规则的挖掘，主要还是依赖于实体以及关系间的丰富情况。知识推理的对象可以是实体、实体的属性、实体间的关系、本体库中概念的层次结构等。 知识推理方法主要可分为基于逻辑的推理与基于图的推理两种类别。 大规模开放知识库互联网的发展为知识工程提供了新的机遇。从一定程度上看，是互联网的出现帮助突破了传统知识工程在知识获取方面的瓶颈。从1998年 Tim Berners Lee提出语义网至今，涌现出大量以互联网资源为基础的新一代知识库。这类知识库的构建方法可以分为三类：互联网众包、专家协作和互联网挖掘，如下图所示： 下面介绍几个知名的中文知识图谱资源： OpenKG.CN：中文开放知识图谱联盟旨在通过建设开放的社区来促进中文知识图谱数据的开放与互联，促进中文知识图谱工具的标准化和技术普及。 Zhishi.me ：Zhishi.me 是中文常识知识图谱。主要通过从开放的百科数据中抽取结构化数据，已融合了百度百科，互动百科以及维基百科中的中文数据。 CN-DBPeidia：CN-DBpedia 是由复旦大学知识工场实验室研发并维护的大规模通用领域结构化百科。 cnSchema.org: cnSchema.org 是一个基于社区维护的开放的知识图谱 Schema 标准。cnSchema 的词汇集包括了上千种概念分类、数据类型、属性和关系等常用概念定义，以支持知识图谱数据的通用性、复用性和流动性。 知识图谱的典型应用知识图谱为互联网上海量、异构、动态的大数据表达、组织、管理以及利用提供了一种更为有效的方式，使得网络的智能化水平更高，更加接近于人类的认知思维。 基于大规模开放知识库或知识图谱的应用，目前尚处在持续不断的发展与探索的阶段。下面列出了一些国内外比较出色的应用。 1. 语义检索。 谷歌公司通过建立 Google KnowledgeGraph，实现了对知识的体系化组织与展示，试图从用户搜索意图感知、以及查询扩展的角度，直接提供给用户想要的知识。 2. 智能问答。 IBM 公司通过搭建知识图谱，并通过自然语言处理和机器学习等技术，开发出了 Watson系统。在2011年2月的美国问答节目《Jeopardy!》上，Watson 战胜了这一节目的两位冠军选手，可与1996年同样来自 IBM的“深蓝”战胜国际象棋大师卡斯帕罗夫产生的影响相提并论，被认为是人工智能历史上的一个里程碑。 3. 领域专家快速生成。 构建面向特定领域、特定主题的大规模知识库是实现对某一领域深度分析和计算的重要基础，OpenKN通过实现端到端的开放知识库构建工具集，实现了在给定部分种子（Seed）的情况下，从无到有的生成领域知识库，进而形成领域专家。 4. 行业生态深度分析与预测。 利用开放大数据可以帮助企业发现潜伏在数据中的威胁，将结构化网络日志、文本数据、开源和第三方数据整合进一个单一的环境，屏蔽可疑的信号与噪声，有效保护用户网络，可在信用卡欺诈行为识别、医疗行业疾病预测、电商商品推荐、强化组织数据安全、不一致性验证、异常分析、金融量化交易、法律分析服务等多方面提供有价值的服务。 知识图谱的前景与挑战在关注到知识图谱在自然语言处理、人工智能等领域展现巨大潜力的同时，也不难发现知识图谱中的知识获取、知识表示、知识推理等技术依然面临着一些困难与挑战，在未来的一段时间内，知识图谱将是大数据智能的前沿研究问题，有很多重要的开放性问题亟待学术界和产业界协力解决。我们认为，未来知识图谱研究有以下几个重要挑战： 知识类型与表示。知识图谱主要采用（实体1、关系、实体2）三元组的形式来表示知识，这种方法可以较好地表示很多事实性知识。然而，人类知识类型多样，面对很多复杂知识，三元组就束手无策了。例如，人们的购物记录信息、新闻事件等，包含大量实体及其之间的复杂关系，更不用说人类大量的涉及主观感受、主观情感和模糊的知识了。 知识获取。如何从互联网大数据萃取知识，是构建知识图谱的重要问题。目前已经提出各种知识获取方案，并已成功抽取大量有用的知识。但在抽取知识的准确率、覆盖率和效率等方面，都仍不如人意，有极大的提升空间。 知识融合。来自不同数据的抽取知识可能存在大量噪音和冗余，或者使用了不同的语言。如何将这些知识有机融合起来，建立更大规模的知识图谱，是实现大数据智能的必由之路。 知识应用。目前大规模知识图谱的应用场景和方式还比较有限，如何有效实现知识图谱的应用，利用知识图谱实现深度知识推理，提高大规模知识图谱计算效率，需要人们不断锐意发掘用户需求，探索更重要的应用场景，提出新的应用算法。 总结本文对知识图谱的起源、定义、架构、大规模知识库、应用以及未来挑战等内容，进行了全面阐述。 知识抽取、知识表示、知识融合以及知识推理为构建知识图谱的四大核心技术，本文就当前产业界的需求介绍了它在智能搜索、深度问答、社交网络以及一些垂直行业中的实际应用。此外，还总结了目前知识图谱面临的主要挑战，并对其未来的研究方向进行了展望。 知识图谱的重要性不仅在于它是一个拥有强大语义处理能力与开放互联能力的知识库，并且还是一把开启智能机器大脑的钥匙，能够打开 Web3.0时代的知识宝库，为相关学科领域开启新的发展方向。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关键字提取（3）]]></title>
    <url>%2F2019%2F11%2F22%2F3.%E5%85%B3%E9%94%AE%E5%AD%97%E6%8F%90%E5%8F%96%2F</url>
    <content type="text"><![CDATA[关键词提取就是从文本里面把跟这篇文章意义最相关的一些词语抽取出来。关键词在文献检索、自动文摘、文本聚类/分类等方面有着重要的应用，它不仅是进行这些工作不可或缺的基础和前提，也是互联网上信息建库的一项重要工作。 简介关键词抽取从方法来说主要有两种： 第一种是关键词分配：就是给定一个已有的关键词库，对于新来的文档从该词库里面匹配几个词语作为这篇文档的关键词。 第二种是关键词提取：针对新文档，通过算法分析，提取文档中一些词语作为该文档的关键词。 目前大多数应用领域的关键词抽取算法都是基于后者实现的，从逻辑上说，后者比前者在实际应用中更准确。 下面介绍一些关于关键词抽取的常用和经典的算法实现。 基于 TF-IDF 算法进行关键词提取在信息检索理论中，TF-IDF 是 Term Frequency - Inverse Document Frequency 的简写。TF-IDF 是一种数值统计，用于反映一个词对于语料中某篇文档的重要性。在信息检索和文本挖掘领域，它经常用于因子加权。TF-IDF 的主要思想就是：如果某个词在一篇文档中出现的频率高，也即 TF 高；并且在语料库中其他文档中很少出现，即 DF 低，也即 IDF 高，则认为这个词具有很好的类别区分能力。 TF 为词频（Term Frequency），表示词 t 在文档 d 中出现的频率，计算公式：IDF 为逆文档频率（Inverse Document Frequency），表示语料库中包含词 t 的文档的数目的倒数，计算公式：TF-IDF 在实际中主要是将二者相乘，也即 TF * IDF， 计算公式：因此，TF-IDF 倾向于过滤掉常见的词语，保留重要的词语。例如，某一特定文件内的高频率词语，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的 TF-IDF。好在 jieba 已经实现了基于 TF-IDF 算法的关键词抽取，通过命令 import jieba.analyse 引入，函数参数解释如下： jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=()) sentence：待提取的文本语料； topK：返回 TF/IDF 权重最大的关键词个数，默认值为 20； withWeight：是否需要返回关键词权重值，默认值为 False； allowPOS：仅包括指定词性的词，默认值为空，即不筛选 import jieba.analyse sentence = &quot;人工智能（Artificial Intelligence），英文缩写为AI。它是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。人工智能是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器，该领域的研究包括机器人、语言识别、图像识别、自然语言处理和专家系统等。人工智能从诞生以来，理论和技术日益成熟，应用领域也不断扩大，可以设想，未来人工智能带来的科技产品，将会是人类智慧的“容器”。人工智能可以对人的意识、思维的信息过程的模拟。人工智能不是人的智能，但能像人那样思考、也可能超过人的智能。人工智能是一门极富挑战性的科学，从事这项工作的人必须懂得计算机知识，心理学和哲学。人工智能是包括十分广泛的科学，它由不同的领域组成，如机器学习，计算机视觉等等，总的说来，人工智能研究的一个主要目标是使机器能够胜任一些通常需要人类智能才能完成的复杂工作。但不同的时代、不同的人对这种“复杂工作”的理解是不同的。2017年12月，人工智能入选“2017年度中国媒体十大流行语”。&quot; keywords = &quot; &quot;.join(jieba.analyse.extract_tags(sentence , topK=20, withWeight=False, allowPOS=())) print(keywords) 输出：人工智能 智能 2017 机器 不同 人类 科学 模拟 一门 技术 计算机 研究 工作 Artificial Intelligence AI 图像识别 12 复杂 流行语 keywords =(jieba.analyse.extract_tags(sentence , topK=10, withWeight=True, allowPOS=([&#39;n&#39;,&#39;v&#39;]))) print(keywords) 输出：[(‘人工智能’, 0.9750542675762887), (‘智能’, 0.5167124540885567), (‘机器’, 0.20540911929525774), (‘人类’, 0.17414426566082475), (‘科学’, 0.17250169374402063), (‘模拟’, 0.15723537382948452), (‘技术’, 0.14596259315164947), (‘计算机’, 0.14030483362639176), (‘图像识别’, 0.12324502580309278), (‘流行语’, 0.11242211730309279)] 基于 TextRank 算法进行关键词提取TextRank 是由 PageRank 改进而来，核心思想将文本中的词看作图中的节点，通过边相互连接，不同的节点会有不同的权重，权重高的节点可以作为关键词。这里给出 TextRank 的公式：节点 i 的权重取决于节点 i 的邻居节点中 i-j 这条边的权重 / j 的所有出度的边的权重 * 节点 j 的权重，将这些邻居节点计算的权重相加，再乘上一定的阻尼系数，就是节点 i 的权重，阻尼系数 d 一般取 0.85。 TextRank 用于关键词提取的算法如下： （1）把给定的文本 T 按照完整句子进行分割，即:（2）对于每个句子，进行分词和词性标注处理，并过滤掉停用词，只保留指定词性的单词，如名词、动词、形容词，其中 ti,j 是保留后的候选关键词。（3）构建候选关键词图 G = (V,E)，其中 V 为节点集，由（2）生成的候选关键词组成，然后采用共现关系（Co-Occurrence）构造任两点之间的边，两个节点之间存在边仅当它们对应的词汇在长度为 K 的窗口中共现，K 表示窗口大小，即最多共现 K 个单词。 （4）根据 TextRank 的公式，迭代传播各节点的权重，直至收敛。 （5）对节点权重进行倒序排序，从而得到最重要的 T 个单词，作为候选关键词。 （6）由（5）得到最重要的 T 个单词，在原始文本中进行标记，若形成相邻词组，则组合成多词关键词。 同样 jieba 已经实现了基于 TextRank 算法的关键词抽取，通过命令 import jieba.analyse 引用，函数参数解释如下： jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=(&#39;ns&#39;, &#39;n&#39;, &#39;vn&#39;, &#39;v&#39;)) 直接使用，接口参数同 TF-IDF 相同，注意默认过滤词性。接下来，我们继续看例子，语料继续使用上例中的句子。 result = &quot; &quot;.join(jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=(&#39;ns&#39;, &#39;n&#39;, &#39;vn&#39;, &#39;v&#39;))) print(result) 输出：智能 人工智能 机器 人类 研究 技术 模拟 包括 科学 工作 领域 理论 计算机 年度 需要 语言 相似 方式 做出 心理学 修改词性 result = &quot; &quot;.join(jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=(&#39;n&#39;,&#39;v&#39;))) print(result) 输出： 智能 人工智能 机器 人类 技术 模拟 包括 科学 理论 计算机 领域 年度 需要 心理学 信息 语言 识别 带来 过程 延伸 基于 LDA 主题模型进行关键词提取通过 Gensim 库完成基于 LDA 的关键字提取。整个过程的步骤为：文件加载 -&gt; jieba 分词 -&gt; 去停用词 -&gt; 构建词袋模型 -&gt; LDA 模型训练 -&gt; 结果可视化。 数据处理训练#引入库文件 import jieba.analyse as analyse import jieba import pandas as pd from gensim import corpora, models, similarities import gensim import numpy as np import matplotlib.pyplot as plt %matplotlib inline #设置文件路径 dir = &quot;./&quot; file_desc = &quot;&quot;.join([dir,&#39;car.csv&#39;]) stop_words = &quot;&quot;.join([dir,&#39;stopwords.txt&#39;]) #定义停用词 stopwords=pd.read_csv(stop_words,index_col=False,quoting=3,sep=&quot;\t&quot;,names=[&#39;stopword&#39;], encoding=&#39;utf-8&#39;) stopwords=stopwords[&#39;stopword&#39;].values #加载语料 df = pd.read_csv(file_desc, encoding=&#39;gbk&#39;) #删除nan行 df.dropna(inplace=True) lines=df.content.values.tolist() #开始分词 sentences=[] for line in lines: try: segs=jieba.lcut(line) segs = [v for v in segs if not str(v).isdigit()]#去数字 segs = list(filter(lambda x:x.strip(), segs)) #去左右空格 segs = list(filter(lambda x:x not in stopwords, segs)) #去掉停用词 sentences.append(segs) except Exception: print(line) continue #构建词袋模型 dictionary = corpora.Dictionary(sentences) corpus = [dictionary.doc2bow(sentence) for sentence in sentences] #lda模型，num_topics是主题的个数，这里定义了5个 lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=10) #我们查一下第1号分类，其中最常出现的5个词是： print(lda.print_topic(1, topn=5)) #我们打印所有5个主题，每个主题显示8个词 for topic in lda.print_topics(num_topics=10, num_words=8): print(topic[1]) 结果可视化#显示中文matplotlib plt.rcParams[&#39;font.sans-serif&#39;] = [u&#39;SimHei&#39;] plt.rcParams[&#39;axes.unicode_minus&#39;] = False # 在可视化部分，我们首先画出了九个主题的7个词的概率分布图 num_show_term = 8 # 每个主题下显示几个词 num_topics = 10 for i, k in enumerate(range(num_topics)): ax = plt.subplot(2, 5, i+1) item_dis_all = lda.get_topic_terms(topicid=k) item_dis = np.array(item_dis_all[:num_show_term]) ax.plot(range(num_show_term), item_dis[:, 1], &#39;b*&#39;) item_word_id = item_dis[:, 0].astype(np.int) word = [dictionary.id2token[i] for i in item_word_id] ax.set_ylabel(u&quot;概率&quot;) for j in range(num_show_term): ax.text(j, item_dis[j, 1], word[j], bbox=dict(facecolor=&#39;green&#39;,alpha=0.1)) plt.suptitle(u&#39;9个主题及其7个主要词的概率&#39;, fontsize=18) plt.show() 基于 pyhanlp 进行关键词提取 HanLP 来完成关键字提取，内部采用 TextRankKeyword 实现 from pyhanlp import * result = HanLP.extractKeyword(sentence, 20) print(result) 输出：[人工智能, 智能, 领域, 人类, 研究, 不同, 工作, 包括, 模拟, 新的, 机器, 计算机, 门, 科学, 应用, 系统, 理论, 技术, 入选, 复杂]]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>tf-idf</tag>
        <tag>pyhanlp</tag>
        <tag>textrank</tag>
        <tag>lda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[词袋与词向量（5）]]></title>
    <url>%2F2019%2F11%2F22%2F5.%E8%AF%8D%E8%A2%8B%E4%B8%8E%E8%AF%8D%E5%90%91%E9%87%8F%2F</url>
    <content type="text"><![CDATA[词袋和词向量模型可以将文本数据如转换成计算机能够计算的数据。 词袋模型（Bag of Words Model）词袋模型把文本（段落或者文档）被看作是无序的词汇集合，忽略语法甚至是单词的顺序，把每一个单词都进行统计，同时计算每个单词出现的次数，常常被用在文本分类中，如贝叶斯算法、LDA 和 LSA 等。 实战词袋模型import jieba #定义停用词、标点符号 punctuation = [&quot;，&quot;,&quot;。&quot;, &quot;：&quot;, &quot;；&quot;, &quot;？&quot;] #定义语料 content = [&quot;机器学习带动人工智能飞速的发展。&quot;, &quot;深度学习带动人工智能飞速的发展。&quot;, &quot;机器学习和深度学习带动人工智能飞速的发展。&quot; ] #分词 segs_1 = [jieba.lcut(con) for con in content] print(segs_1) 输出： [[‘机器’, ‘学习’, ‘带动’, ‘人工智能’, ‘飞速’, ‘的’, ‘发展’, ‘。’], [‘深度’, ‘学习’, ‘带动’, ‘人工智能’, ‘飞速’, ‘的’, ‘发展’, ‘。’], [‘机器’, ‘学习’, ‘和’, ‘深度’, ‘学习’, ‘带动’, ‘人工智能’, ‘飞速’, ‘的’, ‘发展’, ‘。’]] # 去标点符号 tokenized = [] for sentence in segs_1: words = [] for word in sentence: if word not in punctuation: words.append(word) tokenized.append(words) print(tokenized) 输出：[[‘机器’, ‘学习’, ‘带动’, ‘人工智能’, ‘飞速’, ‘的’, ‘发展’], [‘深度’, ‘学习’, ‘带动’, ‘人工智能’, ‘飞速’, ‘的’, ‘发展’], [‘机器’, ‘学习’, ‘和’, ‘深度’, ‘学习’, ‘带动’, ‘人工智能’, ‘飞速’, ‘的’, ‘发展’]] # 把所有的分词结果放到一个袋子（List）里面，也就是取并集，再去重，获取对应的特征词。 #求并集 bag_of_words = [ x for item in segs_1 for x in item if x not in punctuation] #去重 bag_of_words = list(set(bag_of_words)) print(bag_of_words) 输出： [‘飞速’, ‘的’, ‘深度’, ‘人工智能’, ‘发展’, ‘和’, ‘机器’, ‘学习’, ‘带动’] # 以上面特征词的顺序，完成词袋化，得到词袋向量 bag_of_word2vec = [] for sentence in tokenized: tokens = [1 if token in sentence else 0 for token in bag_of_words ] bag_of_word2vec.append(tokens) 输出：[[1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 1, 1, 1, 1, 0, 0, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]] Gensim 构建词袋模型from gensim import corpora import gensim #tokenized是去标点之后的 dictionary = corpora.Dictionary(tokenized) #保存词典 dictionary.save(&#39;deerwester.dict&#39;) print(dictionary) 输出： Dictionary(9 unique tokens: [‘人工智能’, ‘发展’, ‘学习’, ‘带动’, ‘机器’]…) #查看词典和下标 id 的映射 print(dictionary.token2id) 输出： {‘人工智能’: 0, ‘发展’: 1, ‘学习’: 2, ‘带动’: 3, ‘机器’: 4, ‘的’: 5, ‘飞速’: 6, ‘深度’: 7, ‘和’: 8} # doc2bow()，作用只是计算每个不同单词的出现次数，将单词转换为其整数单词 id 并将结果作为稀疏向量返回。 corpus = [dictionary.doc2bow(sentence) for sentence in segs_1] print(corpus ) 输出： [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(0, 1), (1, 1), (2, 1), (3, 1), (5, 1), (6, 1), (7, 1)], [(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]] 词向量 （Word Embedding）词向量技术是将词语转化成为稠密向量。在自然语言处理应用中，词向量作为机器学习、深度学习模型的特征进行输入。因此，最终模型的效果很大程度上取决于词向量的效果。在 Word2Vec 出现之前，自然语言处理经常把字词进行独热编码，也就是 One-Hot Encoder。 大数据 [0,0,0,0,0,0,0,1,0,……，0,0,0,0,0,0,0] 云计算[0,0,0,0,1,0,0,0,0,……，0,0,0,0,0,0,0] 机器学习[0,0,0,1,0,0,0,0,0,……，0,0,0,0,0,0,0] 人工智能[0,0,0,0,0,0,0,0,0,……，1,0,0,0,0,0,0] 比如上面的例子中，大数据 、云计算、机器学习和人工智能各对应一个向量，向量中只有一个值为1，其余都为0。所以使用 One-Hot Encoder有以下问题： 第一，词语编码是随机的，向量之间相互独立，看不出词语之间可能存在的关联关系。第二，向量维度的大小取决于语料库中词语的多少，如果语料包含的所有词语对应的向量合为一个矩阵的话，那这个矩阵过于稀疏，并且会造成维度灾难。而解决这个问题的手段，就是使用向量表示（Vector Representations）。比如 Word2Vec 可以将 One-Hot Encoder 转化为低维度的连续值，也就是稠密向量，并且其中意思相近的词也将被映射到向量空间中相近的位置。经过降维，在二维空间中，相似的单词在空间中的距离也很接近。 这里简单给词向量一个定义，词向量就是要用某个固定维度的向量去表示单词。也就是说要把单词变成固定维度的向量，作为机器学习（Machine Learning）或深度学习模型的特征向量输入。 词向量实战Word2VecWord2Vec 主要包含两种模型：Skip-Gram 和 CBOW，值得一提的是，Word2Vec 词向量可以较好地表达不同词之间的相似和类比关系。 pip install gensim from gensim.models import Word2Vec import jieba #定义停用词、标点符号 punctuation = [&quot;,&quot;,&quot;。&quot;, &quot;:&quot;, &quot;;&quot;, &quot;.&quot;, &quot;&#39;&quot;, &#39;&quot;&#39;, &quot;’&quot;, &quot;?&quot;, &quot;/&quot;, &quot;-&quot;, &quot;+&quot;, &quot;&amp;&quot;, &quot;(&quot;, &quot;)&quot;] sentences = [ &quot;长江是中国第一大河，干流全长6397公里（以沱沱河为源），一般称6300公里。流域总面积一百八十余万平方公里，年平均入海水量约九千六百余亿立方米。以干流长度和入海水量论，长江均居世界第三位。&quot;, &quot;黄河，中国古代也称河，发源于中华人民共和国青海省巴颜喀拉山脉，流经青海、四川、甘肃、宁夏、内蒙古、陕西、山西、河南、山东9个省区，最后于山东省东营垦利县注入渤海。干流河道全长5464千米，仅次于长江，为中国第二长河。黄河还是世界第五长河。&quot;, &quot;黄河,是中华民族的母亲河。作为中华文明的发祥地,维系炎黄子孙的血脉.是中华民族民族精神与民族情感的象征。&quot;, &quot;黄河被称为中华文明的母亲河。公元前2000多年华夏族在黄河领域的中原地区形成、繁衍。&quot;, &quot;在兰州的“黄河第一桥”内蒙古托克托县河口镇以上的黄河河段为黄河上游。&quot;, &quot;黄河上游根据河道特性的不同，又可分为河源段、峡谷段和冲积平原三部分。 &quot;, &quot;黄河,是中华民族的母亲河。&quot; ] # 定义好语料，接下来进行分词，去标点符号 sentences = [jieba.lcut(sen) for sen in sentences] tokenized = [] for sentence in sentences: words = [] for word in sentence: if word not in punctuation: words.append(word) tokenized.append(words) # 模型训练 model = Word2Vec(tokenized, sg=1, size=100, window=5, min_count=2, negative=1, sample=0.001, hs=1, workers=4) sg=1 是 skip-gram 算法，对低频词敏感；默认 sg=0 为 CBOW 算法。 size 是输出词向量的维数，值太小会导致词映射因为冲突而影响结果，值太大则会耗内存并使算法计算变慢，一般值取为100到200之间。 window 是句子中当前词与目标词之间的最大距离，3表示在目标词前看3-b 个词，后面看 b 个词（b 在0-3之间随机）。 min_count 是对词进行过滤，频率小于 min-count 的单词则会被忽视，默认值为5。 negative 和 sample 可根据训练结果进行微调，sample 表示更高频率的词被随机下采样到所设置的阈值，默认值为 1e-3。 hs=1 表示层级 softmax 将会被使用，默认 hs=0 且 negative 不为0，则负采样将会被选择使用。 # 训练后的模型可以保存与加载 model.save(&#39;model&#39;) #保存模型 model = Word2Vec.load(&#39;model&#39;) #加载模型 # 模型训练好之后，接下来就可以使用模型，可以用来计算句子或者词的相似性、最大匹配程度等。 # 计算相似度 print(model.similarity(&#39;黄河&#39;, &#39;长江&#39;)) # 预测最接近的词，预测与黄河和母亲河最接近，而与长江不接近的词 print(model.most_similar(positive=[&#39;黄河&#39;, &#39;母亲河&#39;], negative=[&#39;长江&#39;])) 输出： [(‘是’, 0.14632007479667664), (‘以’, 0.14630728960037231), (‘长河’, 0.13878652453422546), (‘河道’, 0.13716217875480652), (‘在’, 0.11577725410461426), (‘全长’, 0.10969121754169464), (‘内蒙古’, 0.07590540498495102), (‘入海’, 0.06970417499542236), (‘民族’, 0.06064444035291672), (‘中华文明’, 0.057667165994644165)] Word2Vec 是一种将词变成词向量的工具。通俗点说，只有这样文本预料才转化为计算机能够计算的矩阵向量。 Doc2Vec在 Gensim 库中，Doc2Vec 与 Word2Vec 都极为相似。但两者在对输入数据的预处理上稍有不同，Doc2vec 接收一个由 LabeledSentence 对象组成的迭代器作为其构造函数的输入参数。其中，LabeledSentence 是 Gensim 内建的一个类，它接收两个 List 作为其初始化的参数：word list 和 label list。 Doc2Vec 也包括两种实现方式：DBOW（Distributed Bag of Words）和 DM （Distributed Memory）。DBOW 和 DM 的实现，二者在 gensim 库中的实现用的是同一个方法，该方法中参数 dm = 0 或者 dm=1 决定调用 DBOW 还是 DM。Doc2Vec 将文档语料通过一个固定长度的向量表达。 下面是 Gensim 中 Doc2Vec 模型的实战，我们把上述语料每一句话当做一个文本，添加上对应的标签。接下来，定义数据预处理类，作用是给每个文章添加对应的标签： #定义数据预处理类，作用是给每个文章添加对应的标签 from gensim.models.doc2vec import Doc2Vec,LabeledSentence doc_labels = [&quot;长江&quot;,&quot;黄河&quot;,&quot;黄河&quot;,&quot;黄河&quot;,&quot;黄河&quot;,&quot;黄河&quot;,&quot;黄河&quot;] class LabeledLineSentence(object): def __init__(self, doc_list, labels_list): self.labels_list = labels_list self.doc_list = doc_list def __iter__(self): for idx, doc in enumerate(self.doc_list): yield LabeledSentence(words=doc,tags=[self.labels_list[idx]]) model = Doc2Vec(documents,dm=1, size=100, window=8, min_count=5, workers=4) model.save(&#39;model&#39;) model = Doc2Vec.load(&#39;model&#39;) # 定义好了数据预处理函数，我们将 Word2Vec 中分词去标点后的数据，进行转换 iter_data = LabeledLineSentence(tokenized, doc_labels) # 开始定义模型参数，这里 dm=1，采用了 Gensim 中的 DM 实现 model = Doc2Vec(dm=1, size=100, window=8, min_count=5, workers=4) model.build_vocab(iter_data) # 训练模型， 设置迭代次数1000次，start_alpha 为开始学习率，end_alpha 与 start_alpha 线性递减。 model.train(iter_data,total_examples=model.corpus_count,epochs=1000,start_alpha=0.01,end_alpha =0.001) # 进行一些预测 根据标签找最相似的，这里只有黄河和长江，所以结果为长江，并计算出了相似度 print(model.docvecs.most_similar(&#39;黄河&#39;)) 输出： [(‘长江’, 0.25543850660324097)] print(model.docvecs.similarity(&#39;黄河&#39;,&#39;长江&#39;)) 输出： 0.25543848271351405 最终影响模型准确率的因素有：文档的数量越多，文档的相似性越好，也就是基于大数据量的模型训练。在工业界，Word2Vec 和 Doc2Vec 常见的应用有：做相似词计算；相关词挖掘，在推荐系统中用在品牌、用户、商品挖掘中；上下文预测句子；机器翻译；作为特征输入其他模型等。 总结，本文只是简单的介绍了词袋和词向量模型的典型应用，对于两者的理论和其他词向量模型，比如 TextRank 、FastText 和 GloVe 等。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>doc2vec</tag>
        <tag>word2vec</tag>
        <tag>gensim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于ML的中文短文本聚类（7）]]></title>
    <url>%2F2019%2F11%2F22%2F7.%E5%9F%BA%E4%BA%8EML%E7%9A%84%E4%B8%AD%E6%96%87%E7%9F%AD%E6%96%87%E6%9C%AC%E8%81%9A%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[文本聚类是将一个个文档由原有的自然语言文字信息转化成数学信息，以高维空间点的形式展现出来，通过计算哪些点距离比较近，从而将那些点聚成一个簇，簇的中心叫做簇心。一个好的聚类要保证簇内点的距离尽量的近，但簇与簇之间的点要尽量的远。 文本聚类如下图，以 K、M、N 三个点分别为聚类的簇心，将结果聚为三类，使得簇内点的距离尽量的近，但簇与簇之间的点尽量的远。 文本无监督聚类步骤： 语料加载 分词 去停用词 抽取词向量特征 实战 TF-IDF 的中文文本 K-means 聚类 实战 word2Vec 的中文文本 K-means 聚类 语料加载进行语料加载，在这之前，引入所需要的 Python 依赖包，并将全部语料和停用词字典读入内存中 #依赖库，有随机数库、jieba 分词、pandas 库 import random import jieba import pandas as pd import numpy as np from sklearn.feature_extraction.text import TfidfTransformer from sklearn.feature_extraction.text import TfidfVectorizer import matplotlib.pyplot as plt from sklearn.decomposition import PCA from sklearn.cluster import KMeans import gensim from gensim.models import Word2Vec from sklearn.preprocessing import scale import multiprocessing #加载停用词 stopwords.txt topwords=pd.read_csv(&#39;stopwords.txt&#39;,index_col=False,quoting=3,sep=&quot;\t&quot;,names=[&#39;stopword&#39;], encoding=&#39;utf-8&#39;) topwords=stopwords[&#39;stopword&#39;].values # 加载语料，语料是4个已经分好类的 csv 文件，直接用 pandas 加载即可，加载之后可以首先删除 nan 行，并提取要分词的 content 列转换为 list 列表 #加载语料 laogong_df = pd.read_csv(&#39;beilaogongda.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) laopo_df = pd.read_csv(&#39;beilaogongda.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) erzi_df = pd.read_csv(&#39;beierzida.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) nver_df = pd.read_csv(&#39;beinverda.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) #删除语料的nan行 laogong_df.dropna(inplace=True) laopo_df.dropna(inplace=True) erzi_df.dropna(inplace=True) nver_df.dropna(inplace=True) #转换 laogong = laogong_df.segment.values.tolist() laopo = laopo_df.segment.values.tolist() erzi = erzi_df.segment.values.tolist() nver = nver_df.segment.values.tolist() 分词和去停用词定义分词、去停用词的函数，函数包含两个参数：content_lines 参数为语料列表；sentences 参数为预先定义的 list，用来存储分词后的结果 def preprocess_text(content_lines, sentences): for line in content_lines: try: segs=jieba.lcut(line) segs = [v for v in segs if not str(v).isdigit()]#去数字 segs = list(filter(lambda x:x.strip(), segs)) #去左右空格 segs = list(filter(lambda x:len(x)&gt;1, segs)) #长度为1的字符 segs = list(filter(lambda x:x not in stopwords, segs)) #去掉停用词 sentences.append(&quot; &quot;.join(segs)) except Exception: print(line) continue # 调用函数、生成训练数据，根据我提供的司法语料数据，分为报警人被老公打，报警人被老婆打，报警人被儿子打，报警人被女儿打 sentences = [] preprocess_text(laogong, sentences) preprocess_text(laopo, sentences) preprocess_text(erzi, sentences) preprocess_text(nver, sentences) # 将得到的数据集打散，生成更可靠的训练集分布，避免同类数据分布不均匀 random.shuffle(sentences) # 我们控制台输出前10条数据，观察一下（因为上面进行了随机打散，你看到的前10条可能不一样） for sentence in sentences[:10]: print(sentenc) 得到的结果聚类和分类是不同的，这里没有标签 抽取词向量特征抽取特征，将文本中的词语转换为词频矩阵，统计每个词语的 tf-idf 权值，获得词在对应文本中的 tf-idf 权重 #将文本中的词语转换为词频矩阵 矩阵元素a[i][j] 表示j词在i类文本下的词频 vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5) #统计每个词语的tf-idf权值 transformer = TfidfTransformer() # 第一个fit_transform是计算tf-idf 第二个fit_transform是将文本转为词频矩阵 tfidf = transformer.fit_transform(vectorizer.fit_transform(sentences)) # 获取词袋模型中的所有词语 word = vectorizer.get_feature_names() # 将tf-idf矩阵抽取出来，元素w[i][j]表示j词在i类文本中的tf-idf权重 weight = tfidf.toarray() #查看特征大小 print (&#39;Features length: &#39; + str(len(word)))TF-IDF 的中文文本 K-means 聚类使用 k-means++ 来初始化模型，当然也可以选择随机初始化，即 init=”random”，然后通过 PCA 降维把上面的权重 weight 降到10维，进行聚类模型训练 numClass=4 #聚类分几簇 clf = KMeans(n_clusters=numClass, max_iter=10000, init=&quot;k-means++&quot;, tol=1e-6) #这里也可以选择随机初始化init=&quot;random&quot; pca = PCA(n_components=10) # 降维 TnewData = pca.fit_transform(weight) # 载入N维 s = clf.fit(TnewData)第二步，定义聚类结果可视化函数 plot_cluster(result,newData,numClass)，该函数包含3个参数，其中 result 表示聚类拟合的结果集；newData 表示权重 weight 降维的结果，这里需要降维到2维，即平面可视化；numClass 表示聚类分为几簇，绘制代码第一部分绘制结果 newData，第二部分绘制聚类的中心点 def plot_cluster(result,newData,numClass): plt.figure(2) Lab = [[] for i in range(numClass)] index = 0 for labi in result: Lab[labi].append(index) index += 1 color = [&#39;oy&#39;, &#39;ob&#39;, &#39;og&#39;, &#39;cs&#39;, &#39;ms&#39;, &#39;bs&#39;, &#39;ks&#39;, &#39;ys&#39;, &#39;yv&#39;, &#39;mv&#39;, &#39;bv&#39;, &#39;kv&#39;, &#39;gv&#39;, &#39;y^&#39;, &#39;m^&#39;, &#39;b^&#39;, &#39;k^&#39;, &#39;g^&#39;] * 3 for i in range(numClass): x1 = [] y1 = [] for ind1 in newData[Lab[i]]: # print ind1 try: y1.append(ind1[1]) x1.append(ind1[0]) except: pass plt.plot(x1, y1, color[i]) #绘制初始中心点 x1 = [] y1 = [] for ind1 in clf.cluster_centers_: try: y1.append(ind1[1]) x1.append(ind1[0]) except: pass plt.plot(x1, y1, &quot;rv&quot;) #绘制中心 plt.show() 对数据降维到2维，然后获得结果，最后绘制聚类结果图 pca = PCA(n_components=2) # 输出两维 newData = pca.fit_transform(weight) # 载入N维 result = list(clf.predict(TnewData)) plot_cluster(result,newData,numClass) 得到的聚类结果图，4个中心点和4个簇，我们看到结果还比较好，簇的边界很清楚上面演示的可视化过程，降维使用了 PCA，我们还可以试试 TSNE，两者同为降维工具，主要区别在于，所在的包不同因为原理不同，导致 TSNE 保留下的属性信息，更具代表性，也即最能体现样本间的差异，但是 TSNE 运行极慢，PCA 则相对较快，下面看看 TSNE 运行的可视化结果 from sklearn.decomposition import PCA from sklearn.manifold import TSNE ts =TSNE(2) newData = ts.fit_transform(weight) result = list(clf.predict(TnewData)) plot_cluster(result,newData,numClass) 得到的可视化结果，为一个中心点，不同簇落在围绕中心点的不同半径之内，得到的可视化结果，为一个中心点，不同簇落在围绕中心点的不同半径之内，我们看到在这里结果并不是很好为了更好的表达和获取更具有代表性的信息，在展示（可视化）高维数据时，更为一般的处理，常常先用 PCA 进行降维，再使用 TSNE from sklearn.manifold import TSNE newData = PCA(n_components=4).fit_transform(weight) # 载入N维 newData =TSNE(2).fit_transform(newData) result = list(clf.predict(TnewData)) plot_cluster(result,newData,numClass) 得到的可视化结果，不同簇落在围绕中心点的不同半径之内从优化和提高模型准确率来说，主要有两方面可以尝试： 特征向量的构建，除了词袋模型，可以考虑使用 word2vec 和 doc2vec 等； 模型上可以采用基于密度的 DBSCAN、层次聚类等算法。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>jieba</tag>
        <tag>tf-idf</tag>
        <tag>gensim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RNN-GRU-LSTM（9）]]></title>
    <url>%2F2019%2F11%2F22%2F9.RNN-GRU-LSTM%2F</url>
    <content type="text"><![CDATA[序列数据的处理，我们从语言模型 N-gram 模型说起，然后着重谈谈 RNN，并通过 RNN 的变种 LSTM 和 GRU 来实战文本分类。 首先，我们来思考下，当人工神经网络从浅层发展到深层；从全连接到卷积神经网络。在此过程中，人类在图片分类、语音识别等方面都取得了非常好的结果，那么我们为什么还需要循环神经网络呢？ 因为，上面提到的这些网络结构的层与层之间是全连接或部分连接的，但在每层之间的节点是无连接的，这样的网络结构并不能很好的处理序列数据。 语言模型 N-gram 模型通过前面的课程，我们了解到一般自然语言处理的传统方法是将句子处理为一个词袋模型（Bag-of-Words，BoW），而不考虑每个词的顺序，比如用朴素贝叶斯算法进行垃圾邮件识别或者文本分类。在中文里有时候这种方式没有问题，因为有些句子即使把词的顺序打乱，还是可以看懂这句话在说什么，比如： T：研究表明，汉字的顺序并不一定能影响阅读，比如当你看完这句话后。F：研表究明，汉字的序顺并不定一能影阅响读，比如当你看完这句话后。 但有时候不行，词的顺序打乱，句子意思就变得让人不可思议了，例如： T：我喜欢吃烧烤。F：烧烤喜欢吃我。 那么，有没有模型是考虑句子中词与词之间的顺序的呢？有，语言模型中的 N-gram 就是一种。 N-gram 模型是一种语言模型（Language Model，LM），是一个基于概率的判别模型，它的输入是一句话（词的顺序序列），输出是这句话的概率，即这些词的联合概率（JointProbability）。使用 N-gram语言模型思想，一般是需要知道当前词以及前面的词，因为一个句子中每个词的出现并不是独立的。比如，如果第一个词是“空气”，接下来的词是“很”，那么下一个词很大概率会是“新鲜”。类似于我们人的联想，N-gram模型知道的信息越多，得到的结果也越准确。 在前面课程中讲解的文本分类中，我们曾用到基于 sklearn 的词袋模型，尝试加入抽取 2-gram 和 3-gram的统计特征，把词库的量放大，获得更强的特征。 通过 ngram_range 参数来控制，代码如下： from sklearn.feature_extraction.text import CountVectorizer vec = CountVectorizer( analyzer=&#39;word&#39;, # tokenise by character ngrams ngram_range=(1,4), # use ngrams of size 1 and 2 max_features=20000, # keep the most common 1000 ngrams ) 因此，N-gram 模型，在自然语言处理中主要应用在如词性标注、垃圾短信分类、分词器、机器翻译和语音识别、语音识别等领域。 然而 N-gram 模型并不是完美的，它存在如下优缺点： 优点：包含了前 N-1 个词所能提供的全部信息，这些词对于当前词的出现概率具有很强的约束力； 缺点：需要很大规模的训练文本来确定模型的参数，当 N 很大时，模型的参数空间过大。所以常见的 N 值一般为1，2，3等。还有因数据稀疏而导致的数据平滑问题，解决方法主要是拉普拉斯平滑和内插与回溯。 所以，根据 N-gram 的优缺点，它的进化版 NNLM（Neural Network based Language Model）诞生了。 NNLM 由 Bengio 在2003年提出，它是一个很简单的模型，由四层组成，输入层、嵌入层、隐层和输出层，模型结构如下图（来自百度图片）： NNLM 接收的输入是长度为 N 的词序列，输出是下一个词的类别。首先，输入是词序列的 index 序列，例如词“我”在字典（大小为|V|）中的 index是10，词“是”的 index 是23， “小明”的 index 是65，则句子“我是小明”的 index 序列就是 10、23、65。嵌入层（Embedding）是一个大小为 |V|×K 的矩阵，从中取出第10、23、65行向量拼成 3×K 的矩阵就是 Embedding层的输出了。隐层接受拼接后的 Embedding 层输出作为输入，以 tanh 为激活函数，最后送入带 softmax 的输出层，输出概率。 NNLM 最大的缺点就是参数多，训练慢，要求输入定长 N 这一点很不灵活，同时不能利用完整的历史信息。 因此，针对 NNLM 存在的问题，Mikolov 在2010年提出了RNNLM，有兴趣可以阅读相关论文，其结构实际上是用RNN 代替 NNLM 里的隐层，这样做的好处，包括减少模型参数、提高训练速度、接受任意长度输入、利用完整的历史信息。同时，RNN 的引入意味着可以使用RNN 的其他变体，像 LSTM、BLSTM、GRU 等等，从而在序列建模上进行更多更丰富的优化。 以上，从词袋模型说起，引出语言模型 N-gram 以及其优化模型 NNLM 和 RNNLM，后续内容从 RNN 说起，来看看其变种 LSTM 和 GRU模型如何处理类似序列数据。 RNN 以及变种 LSTM 和 GRU 原理RNN 为序列数据而生RNN 称为循环神经网路，因为这种网络有“记忆性”，主要应用在自然语言处理（NLP）和语音领域。RNN具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。 理论上，RNN 能够对任何长度的序列数据进行处理，但由于该网络结构存在“梯度消失”问题，所以在实际应用中，解决梯度消失的方法有：梯度裁剪（ClippingGradient）和 LSTM（Long Short-Term Memory）。 下图是一个简单的 RNN 经典结构： RNN 包含输入单元（Input Units），输入集标记为{x0,x1,…,xt,xt…}\{x_0,x_1,…,x_t,x_t…\}{x0​,x1​,…,xt​,xt​…}；输出单元（Output Units）的输出集则被标记为{y0,y1,…,yt,…}\{y_0,y_1,…,y_t,…\}{y0​,y1​,…,yt​,…}；RNN还包含隐藏单元（Hidden Units），我们将其输出集标记为{h0,h1,…,ht,…}\{h_0,h_1,…,h_t,…\}{h0​,h1​,…,ht​,…}，这些隐藏单元完成了最为主要的工作。 LSTM 结构LSTM 在1997年由“Hochreiter &amp; Schmidhuber”提出，目前已经成为 RNN 中的标准形式，用来解决上面提到的 RNN模型存在“长期依赖”的问题。 LSTM 通过三个“门”结构来控制不同时刻的状态和输出。所谓的“门”结构就是使用了 Sigmoid激活函数的全连接神经网络和一个按位做乘法的操作，Sigmoid激活函数会输出一个0~1之间的数值，这个数值代表当前有多少信息能通过“门”，0表示任何信息都无法通过，1表示全部信息都可以通过。其中，“遗忘门”和“输入门”是LSTM 单元结构的核心。下面我们来详细分析下三种“门”结构。 遗忘门，用来让 LSTM“忘记”之前没有用的信息。它会根据当前时刻节点的输入 XtX_tXt​、上一时刻节点的状态 $C_{t -1 } $ 和上一时刻节点的输出 ht−1h_{t-1}ht−1​ 来决定哪些信息将被遗忘。 输入门，LSTM 来决定当前输入数据中哪些信息将被留下来。在 LSTM 使用遗忘门“忘记”部分信息后需要从当前的输入留下最新的记忆。输入门会根据当前时刻节点的输入 XtX_tXt​、上一时刻节点的状态 Ct−1C_{t-1}Ct−1​ 和上一时刻节点的输出 ht−1h_{t-1}ht−1​ 来决定哪些信息将进入当前时刻节点的状态 CtC_tCt​，模型需要记忆这个最新的信息。 输出门，LSTM 在得到最新节点状态 CtC_tCt​ 后，结合上一时刻节点的输出 ht−1h_{t-1}ht−1​ 和当前时刻节点的输入 XtX_tXt​ 来决定当前时刻节点的输出。 GRU 结构GRU（Gated Recurrent Unit）是2014年提出来的新的 RNN 架构，它是简化版的 LSTM。下面是 LSTM 和 GRU的结构比较图（来自于网络）： 在超参数均调优的前提下，据说效果和 LSTM 差不多，但是参数少了1/3，不容易过拟合。如果发现 LSTM 训练出来的模型过拟合比较严重，可以试试 GRU。 实战基于 Keras 的 LSTM 和 GRU 文本分类上面讲了那么多，但是 RNN 的知识还有很多，比如双向 RNN 等，这些需要自己去学习，下面，我们来实战一下基于 LSTM 和 GRU 的文本分类。 本次开发使用 Keras 来快速构建和训练模型，使用的数据集还是第06课使用的司法数据。 整个过程包括： 语料加载 分词和去停用词 数据预处理 使用 LSTM 分类 使用 GRU 分类 第一步，引入数据处理库，停用词和语料加载： #引入包 import random import jieba import pandas as pd #加载停用词 stopwords=pd.read_csv(&#39;stopwords.txt&#39;,index_col=False,quoting=3,sep=&quot;\t&quot;,names=[&#39;stopword&#39;], encoding=&#39;utf-8&#39;) stopwords=stopwords[&#39;stopword&#39;].values #加载语料 laogong_df = pd.read_csv(&#39;beilaogongda.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) laopo_df = pd.read_csv(&#39;beilaogongda.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) erzi_df = pd.read_csv(&#39;beierzida.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) nver_df = pd.read_csv(&#39;beinverda.csv&#39;, encoding=&#39;utf-8&#39;, sep=&#39;,&#39;) #删除语料的nan行 laogong_df.dropna(inplace=True) laopo_df.dropna(inplace=True) erzi_df.dropna(inplace=True) nver_df.dropna(inplace=True) #转换 laogong = laogong_df.segment.values.tolist() laopo = laopo_df.segment.values.tolist() erzi = erzi_df.segment.values.tolist() nver = nver_df.segment.values.tolist() 第二步，分词和去停用词： #定义分词和打标签函数preprocess_text #参数content_lines即为上面转换的list #参数sentences是定义的空list，用来储存打标签之后的数据 #参数category 是类型标签 def preprocess_text(content_lines, sentences, category): for line in content_lines: try: segs=jieba.lcut(line) segs = [v for v in segs if not str(v).isdigit()]#去数字 segs = list(filter(lambda x:x.strip(), segs)) #去左右空格 segs = list(filter(lambda x:len(x)&gt;1, segs))#长度为1的字符 segs = list(filter(lambda x:x not in stopwords, segs)) #去掉停用词 sentences.append((&quot; &quot;.join(segs), category))# 打标签 except Exception: print(line) continue #调用函数、生成训练数据 sentences = [] preprocess_text(laogong, sentences,0) preprocess_text(laopo, sentences, 1) preprocess_text(erzi, sentences, 2) preprocess_text(nver, sentences, 3) 第三步，先打散数据，使数据分布均匀，然后获取特征和标签列表： #打散数据，生成更可靠的训练集 random.shuffle(sentences) #控制台输出前10条数据，观察一下 for sentence in sentences[:10]: print(sentence[0], sentence[1]) #所有特征和对应标签 all_texts = [ sentence[0] for sentence in sentences] all_labels = [ sentence[1] for sentence in sentences] 第四步，使用 LSTM 对数据进行分类： #引入需要的模块 from keras.preprocessing.text import Tokenizer from keras.preprocessing.sequence import pad_sequences from keras.utils import to_categorical from keras.layers import Dense, Input, Flatten, Dropout from keras.layers import LSTM, Embedding,GRU from keras.models import Sequential #预定义变量 MAX_SEQUENCE_LENGTH = 100 #最大序列长度 EMBEDDING_DIM = 200 #embdding 维度 VALIDATION_SPLIT = 0.16 #验证集比例 TEST_SPLIT = 0.2 #测试集比例 #keras的sequence模块文本序列填充 tokenizer = Tokenizer() tokenizer.fit_on_texts(all_texts) sequences = tokenizer.texts_to_sequences(all_texts) word_index = tokenizer.word_index print(&#39;Found %s unique tokens.&#39; % len(word_index)) data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH) labels = to_categorical(np.asarray(all_labels)) print(&#39;Shape of data tensor:&#39;, data.shape) print(&#39;Shape of label tensor:&#39;, labels.shape) #数据切分 p1 = int(len(data)*(1-VALIDATION_SPLIT-TEST_SPLIT)) p2 = int(len(data)*(1-TEST_SPLIT)) x_train = data[:p1] y_train = labels[:p1] x_val = data[p1:p2] y_val = labels[p1:p2] x_test = data[p2:] y_test = labels[p2:] #LSTM训练模型 model = Sequential() model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)) model.add(LSTM(200, dropout=0.2, recurrent_dropout=0.2)) model.add(Dropout(0.2)) model.add(Dense(64, activation=&#39;relu&#39;)) model.add(Dense(labels.shape[1], activation=&#39;softmax&#39;)) model.summary() #模型编译 model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&#39;rmsprop&#39;, metrics=[&#39;acc&#39;]) print(model.metrics_names) model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=128) model.save(&#39;lstm.h5&#39;) #模型评估 print(model.evaluate(x_test, y_test)) 训练过程结果为： 第五步，使用 GRU 进行文本分类，上面就是完整的使用 LSTM 进行 文本分类，如果使用 GRU 只需要改变模型训练部分： model = Sequential() model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)) model.add(GRU(200, dropout=0.2, recurrent_dropout=0.2)) model.add(Dropout(0.2)) model.add(Dense(64, activation=&#39;relu&#39;)) model.add(Dense(labels.shape[1], activation=&#39;softmax&#39;)) model.summary() model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&#39;rmsprop&#39;, metrics=[&#39;acc&#39;]) print(model.metrics_names) model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=128) model.save(&#39;lstm.h5&#39;) print(model.evaluate(x_test, y_test)) 训练过程结果： 总结本文从词袋模型谈起，旨在引出语言模型 N-gram 以及其优化模型 NNLM 和 RNNLM，并通过 RNN 以及其变种 LSTM 和 GRU模型，理解其如何处理类似序列数据的原理，并实战基于 LSTM 和 GRU 的中文文本分类。]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>gru</tag>
        <tag>lstm</tag>
        <tag>n-gram</tag>
        <tag>rnn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nlp基础（1）]]></title>
    <url>%2F2019%2F11%2F22%2F1.nlp%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[目前，随着大数据、云计算对关系型数据处理技术趋向稳定成熟，各大互联网公司对关系数据的整合也已经落地成熟，笔者预测未来数据领域的挑战将主要集中在半结构化和非结构化数据的整合，NLP 技术对个人发展越来越重要，尤其在中文文本上挑战更大。 技术知识点 获取语料 语料是构成语料库的基本单元。所以，人们简单地用文本作为替代，并把文本中的上下文关系作为现实世界中语言的上下文关系的替代品。我们把一个文本集合称为语料库（Corpus），当有几个这样的文本集合的时候，我们称之为语料库集合(Corpora) 已有语料很多业务部门、公司等组织随着业务发展都会积累有大量的纸质或者电子文本资料。那么，对于这些资料，在允许的条件下我们稍加整合，把纸质的文本全部电子化就可以作为我们的语料库。 网络抓取获取国内外标准开放数据集，比如国内的中文汉语有搜狗语料、人民日报语料。国外的因为大都是英文或者外文，这里暂时用不到。也可以选择通过爬虫自己去抓取一些数据，然后来进行后续内容。 语料预处理在一个完整的中文自然语言处理工程应用中，语料预处理大概会占到整个50%-70%的工作量，所以开发人员大部分时间就在进行语料预处理。下面通过数据洗清、分词、词性标注、去停用词四个大的方面来完成语料的预处理工作。 语料清洗数据清洗，顾名思义就是在语料中找到我们感兴趣的东西，把不感兴趣的、视为噪音的内容清洗删除，包括对于原始文本提取标题、摘要、正文等信息，对于爬取的网页内容，去除广告、标签、HTML、JS 等代码和注释等。常见的数据清洗方式有：人工去重、对齐、删除和标注等，或者规则提取内容、正则表达式匹配、根据词性和命名实体提取、编写脚本或者代码批处理等。 分词中文语料数据为一批短文本或者长文本，比如：句子，文章摘要，段落或者整篇文章组成的一个集合。一般句子、段落之间的字、词语是连续的，有一定含义。而进行文本挖掘分析时，我们希望文本处理的最小单位粒度是词或者词语，所以这个时候就需要分词来将文本全部进行分词。 常见的分词算法有：基于字符串匹配的分词方法、基于理解的分词方法、基于统计的分词方法和基于规则的分词方法。 词性标注词性标注，就是给每个词或者词语打词类标签，如形容词、动词、名词等。这样做可以让文本在后面的处理中融入更多有用的语言信息。词性标注是一个经典的序列标注问题，不过对于有些中文自然语言处理来说，词性标注不是非必需的。比如，常见的文本分类就不用关心词性问题，但是类似情感分析、知识推理却是需要的，下图是常见的中文词性整理。 常见的词性标注方法可以分为基于规则和基于统计的方法。其中基于统计的方法，如基于最大熵的词性标注、基于统计最大概率输出词性和基于 HMM 的词性标注。 去停用词停用词一般指对文本特征没有任何贡献作用的字词，比如标点符号、语气、人称等一些词。所以在一般性的文本处理中，分词之后，接下来一步就是去停用词。但是对于中文来说，去停用词操作不是一成不变的，停用词词典是根据具体场景来决定的，比如在情感分析中，语气词、感叹号是应该保留的，因为他们对表示语气程度、感情色彩有一定的贡献和意义。 特征工程做完语料预处理之后，接下来需要考虑如何把分词之后的字和词语表示成计算机能够计算的类型。显然，如果要计算我们至少需要把中文分词的字符串转换成数字，确切的说应该是数学中的向量。有两种常用的表示模型分别是词袋模型和词向量。 词袋模型（Bag of Word, BOW)，即不考虑词语原本在句子中的顺序，直接将每一个词语或者符号统一放置在一个集合（如 list），然后按照计数的方式对出现的次数进行统计。统计词频这只是最基本的方式，TF-IDF 是词袋模型的一个经典用法。 词向量是将字、词语转换成向量矩阵的计算模型。目前为止最常用的词表示方法是 One-hot，这种方法把每个词表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为 0，只有一个维度的值为 1，这个维度就代表了当前的词。还有 Google 团队的 Word2Vec，其主要包含两个模型：跳字模型（Skip-Gram）和连续词袋模型（Continuous Bag of Words，简称 CBOW），以及两种高效训练的方法：负采样（Negative Sampling）和层序 Softmax（Hierarchical Softmax）。值得一提的是，Word2Vec 词向量可以较好地表达不同词之间的相似和类比关系。除此之外，还有一些词向量的表示方式，如 Doc2Vec、WordRank 和 FastText 等。 特征选择同数据挖掘一样，在文本挖掘相关问题中，特征工程也是必不可少的。在一个实际问题中，构造好的特征向量，是要选择合适的、表达能力强的特征。文本特征一般都是词语，具有语义信息，使用特征选择能够找出一个特征子集，其仍然可以保留语义信息；但通过特征提取找到的特征子空间，将会丢失部分语义信息。所以特征选择是一个很有挑战的过程，更多的依赖于经验和专业知识，并且有很多现成的算法来进行特征的选择。目前，常见的特征选择方法主要有 DF、 MI、 IG、 CHI、WLLR、WFO 六种。 模型训练在特征向量选择好之后，接下来要做的事情当然就是训练模型，对于不同的应用需求，我们使用不同的模型，传统的有监督和无监督等机器学习模型， 如 KNN、SVM、Naive Bayes、决策树、GBDT、K-means 等模型；深度学习模型比如 CNN、RNN、LSTM、 Seq2Seq、FastText、TextCNN 等。这些模型在后续的分类、聚类、神经序列、情感分析等示例中都会用到，这里不再赘述。下面是在模型训练时需要注意的几个点。 注意过拟合、欠拟合问题，不断提高模型的泛化能力。 过拟合：模型学习能力太强，以至于把噪声数据的特征也学习到了，导致模型泛化能力下降，在训练集上表现很好，但是在测试集上表现很差。 常见的解决方法有： 增大数据的训练量； 增加正则化项，如 L1 正则和 L2 正则； 特征选取不合理，人工筛选特征和使用特征选择算法； 采用 Dropout 方法等。 欠拟合：就是模型不能够很好地拟合数据，表现在模型过于简单。 常见的解决方法有： 添加其他特征项； 增加模型复杂度，比如神经网络加更多的层、线性模型通过添加多项式使模型泛化能力更强； 减少正则化参数，正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。 对于神经网络，注意梯度消失和梯度爆炸问题。 评价指标训练好的模型，上线之前要对模型进行必要的评估，目的让模型对语料具备较好的泛化能力。具体有以下这些指标可以参考。 错误率、精度、准确率、精确度、召回率、F1 衡量。 错误率：是分类错误的样本数占样本总数的比例。对样例集 D，分类错误率计算公式如下： 精度：是分类正确的样本数占样本总数的比例。这里的分类正确的样本数指的不仅是正例分类正确的个数还有反例分类正确的个数。对样例集 D，精度计算公式如下： 对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例（True Positive）、假正例（False Positive）、真反例（True Negative)、假反例（False Negative）四种情形，令 TP、FP、TN、FN 分别表示其对应的样例数，则显然有 TP+FP++TN+FN=样例总数。分类结果的“混淆矩阵”（Confusion Matrix）如下： 准确率，缩写表示用 P。准确率是针对我们预测结果而言的，它表示的是预测为正的样例中有多少是真正的正样例。定义公式如下： 精确度，缩写表示用 A。精确度则是分类正确的样本数占样本总数的比例。Accuracy 反应了分类器对整个样本的判定能力（即能将正的判定为正的，负的判定为负的）。定义公式如下： 召回率，缩写表示用 R。召回率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确。定义公式如下： F1 衡量，表达出对查准率/查全率的不同偏好。定义公式如下： ROC 曲线、AUC 曲线。 ROC 全称是“受试者工作特征”（Receiver Operating Characteristic）曲线。我们根据模型的预测结果，把阈值从0变到最大，即刚开始是把每个样本作为正例进行预测，随着阈值的增大，学习器预测正样例数越来越少，直到最后没有一个样本是正样例。在这一过程中，每次计算出两个重要量的值，分别以它们为横、纵坐标作图，就得到了 ROC 曲线。 ROC 曲线的纵轴是“真正例率”（True Positive Rate, 简称 TPR)，横轴是“假正例率”（False Positive Rate,简称FPR），两者分别定义为： ROC 曲线的意义有以下几点： ROC 曲线能很容易的查出任意阈值对模型的泛化性能影响；有助于选择最佳的阈值；可以对不同的模型比较性能，在同一坐标中，靠近左上角的 ROC 曲所代表的学习器准确性最高。如果两条 ROC 曲线没有相交，我们可以根据哪条曲线最靠近左上角哪条曲线代表的学习器性能就最好。但是实际任务中，情况很复杂，若两个模型的 ROC 曲线发生交叉，则难以一般性的断言两者孰优孰劣。此时如果一定要进行比较，则比较合理的判断依据是比较 ROC 曲线下的面积，即AUC（Area Under ROC Curve）。 AUC 就是 ROC 曲线下的面积，衡量学习器优劣的一种性能指标。AUC 是衡量二分类模型优劣的一种评价指标，表示预测的正例排在负例前面的概率。 前面我们所讲的都是针对二分类问题，那么如果实际需要在多分类问题中用 ROC 曲线的话，一般性的转化为多个“一对多”的问题。即把其中一个当作正例，其余当作负例来看待，画出多个 ROC 曲线。 模型上线应用模型线上应用，目前主流的应用方式就是提供服务或者将模型持久化。 第一就是线下训练模型，然后将模型做线上部署，发布成接口服务以供业务系统使用。 第二种就是在线训练，在线训练完成之后把模型 pickle 持久化，然后在线服务接口模板通过读取 pickle 而改变接口服务。 模型重构随着时间和变化，可能需要对模型做一定的重构，包括根据业务不同侧重点对上面提到的一至七步骤也进行调整，重新训练模型进行上线。 jieba安装pip install jieba git clone https://github.com/fxsjy/jieba.gitpython setup.py install 分词算法 基于统计词典，构造前缀词典，基于前缀词典对句子进行切分，得到所有切分可能，根据切分位置，构造一个有向无环图（DAG）； 基于DAG图，采用动态规划计算最大概率路径（最有可能的分词结果），根据最大概率路径分词； 对于新词(词库中没有的词），采用有汉字成词能力的 HMM 模型进行切分。 api参数 jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型。 jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细 精确分词精确模式试图将句子最精确地切开 import jieba content = &quot;现如今，机器学习和深度学习带动人工智能飞速的发展，并在图片处理、语音识别领域取得巨大成功。&quot; segs_1 = jieba.cut(content, cut_all=False) print(&quot;/&quot;.join(segs_1)) 输出：现如今/，/机器/学习/和/深度/学习/带动/人工智能/飞速/的/发展/，/并/在/图片/处理/、/语音/识别/领域/取得/巨大成功/。 全模式把句子中所有的可能是词语的都扫描出来，速度非常快，但不能解决歧义 segs_3 = jieba.cut(content, cut_all=True) print(&quot;/&quot;.join(segs_3)) 输出： 现如今/如今///机器/学习/和/深度/学习/带动/动人/人工/人工智能/智能/飞速/的/发展///并/在/图片/处理///语音/识别/领域/取得/巨大/巨大成功/大成/成功// 搜索引擎模式在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。 segs_4 = jieba.cut_for_search(content) print(&quot;/&quot;.join(segs_4)) 输出： 如今/现如今/，/机器/学习/和/深度/学习/带动/人工/智能/人工智能/飞速/的/发展/，/并/在/图片/处理/、/语音/识别/领域/取得/巨大/大成/成功/巨大成功/。 lcut生成 list segs_5 = jieba.lcut(content) print(segs_5) 输出： [‘现如今’, ‘，’, ‘机器’, ‘学习’, ‘和’, ‘深度’, ‘学习’, ‘带动’, ‘人工智能’, ‘飞速’, ‘的’, ‘发展’, ‘，’, ‘并’, ‘在’, ‘图片’, ‘处理’, ‘、’, ‘语音’, ‘识别’, ‘领域’, ‘取得’, ‘巨大成功’, ‘。’] 获取词性jieba.posseg 模块实现词性标注 import jieba.posseg as psg print([(x.word, x.flag) for x in psg.lcut(content)]) 输出：[(‘现如今’, ‘t’), (‘，’, ‘x’), (‘机器’, ‘n’), (‘学习’, ‘v’), (‘和’, ‘c’), (‘深度’, ‘ns’), (‘学习’, ‘v’), (‘带动’, ‘v’), (‘人工智能’, ‘n’), (‘飞速’, ‘n’), (‘的’, ‘uj’), (‘发展’, ‘vn’), (‘，’, ‘x’), (‘并’, ‘c’), (‘在’, ‘p’), (‘图片’, ‘n’), (‘处理’, ‘v’), (‘、’, ‘x’), (‘语音’, ‘n’), (‘识别’, ‘v’), (‘领域’, ‘n’), (‘取得’, ‘v’), (‘巨大成功’, ‘nr’), (‘。’, ‘x’)] 并行分词为文本按行分隔后，分配到多个 Python 进程并行分词，最后归并结果,默认分词器 jieba.dt 和 jieba.posseg.dt暂不支持 Windows。 jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数 。 jieba.disable_parallel() # 关闭并行分词模式 。 Counter获取分词结果中词列表的 top n from collections import Counter top5 = Counter(segs_5).most_common(5) print(top5) 输出：[(‘，’, 2), (‘学习’, 2), (‘现如今’, 1), (‘机器’, 1), (‘和’, 1)] 自定义添加词和字典txt = &quot;铁甲网是中国最大的工程机械交易平台。&quot; jieba.add_word(&quot;铁甲网&quot;) print(jieba.lcut(txt)) jieba.load_userdict(&#39;user_dict.txt&#39;) # 添加词典 print(jieba.lcut(txt)) 输出：[‘铁甲网’, ‘是’, ‘中国’, ‘最大’, ‘的’, ‘工程机械’, ‘交易平台’, ‘。’] hanlp安装 pip install pyhanlp 如报错building ‘_jpype’ extensionerror: Microsoft Visual C++ 14.0 is required，则conda install -c conda-forge jpype1;pip install pyhanlp 如ValueError: 配置错误: 数据包/pyhanlp/static\data 不存在，请修改配置文件中的root，则到https://github.com/hankcs/HanLP/releases下载data-for-1.7.2.zip下载后放入f:/anaconda3/envs/learn/lib/site-packages/pyhanlp/static\data 安装jdk环境 hanlp segment 交互分词模式 hanlp serve 内置http服务器 http://localhost:8765 分词from pyhanlp import * content = &quot;现如今，机器学习和深度学习带动人工智能飞速的发展，并在图片处理、语音识别领域取得巨大成功。&quot; print(HanLP.segment(content)) 输出：[现如今/t, ，/w, 机器学习/gi, 和/cc, 深度/n, 学习/v, 带动/v, 人工智能/n, 飞速/d, 的/ude1, 发展/vn, ，/w, 并/cc, 在/p, 图片/n, 处理/vn, 、/w, 语音/n, 识别/vn, 领域/n, 取得/v, 巨大/a, 成功/a, 。/w] 自定义词典分词txt = &quot;铁甲网是中国最大的工程机械交易平台。&quot; CustomDictionary.add(&quot;铁甲网&quot;) CustomDictionary.insert(&quot;工程机械&quot;, &quot;nz 1024&quot;) CustomDictionary.add(&quot;交易平台&quot;, &quot;nz 1024 n 1&quot;) print(HanLP.segment(txt)) 输出： [铁甲网/nz, 是/vshi, 中国/ns, 最大/gm, 的/ude1, 工程机械/nz, 交易平台/nz, 。/w] 以上两种工具可以做关键词提取、自动摘要、依存句法分析、情感分析等]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>jieba</tag>
        <tag>hanlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据可视化（4）]]></title>
    <url>%2F2019%2F11%2F22%2F4.%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[文本可视化依赖于自然语言处理，因此词袋模型、命名实体识别、关键词抽取、主题分析、情感分析等是较常用的文本分析技术。文本分析的过程主要包括特征提取，通过分词、抽取、归一化等操作提取出文本词汇级的内容，利用特征构建向量空间模型并进行降维，以便将其呈现在低维空间，或者利用主题模型处理特征，最终以灵活有效的形式表示这些处理过的数据，以便进行可视化呈现 介绍文本可视化类型，除了包含常规的图表类，如柱状图、饼图、折线图等的表现形式，在文本领域用的比较多的可视化类型有： 基于文本内容的可视化基于文本内容的可视化研究包括基于词频的可视化和基于词汇分布的可视化，常用的有词云、分布图和 Document Cards 等。 基于文本关系的可视化。基于文本关系的可视化研究文本内外关系，帮助人们理解文本内容和发现规律。常用的可视化形式有树状图、节点连接的网络图、力导向图、叠式图和 Word Tree 等。 基于多层面信息的可视化基于多层面信息的可视化主要研究如何结合信息的多个方面帮助用户从更深层次理解文本数据，发现其内在规律。其中，包含时间信息和地理坐标的文本可视化近年来受到越来越多的关注。常用的有地理热力图、ThemeRiver、SparkClouds、TextFlow 和基于矩阵视图的情感分析可视化等。 词云*第一种是默认的样式** wordcloud=WordCloud(font_path=simhei,background_color=&quot;white&quot;,max_font_size=80) word_frequence = {x[0]:x[1] for x in words_stat.head(1000).values} wordcloud=wordcloud.fit_words(word_frequence) #**第二种是自定义图片** text = &quot; &quot;.join(words_stat[&#39;segment&#39;].head(100).astype(str)) abel_mask = imread(r&quot;china.jpg&quot;) #这里设置了一张中国地图 wordcloud2 = WordCloud(background_color=&#39;white&#39;, # 设置背景颜色 mask = abel_mask, # 设置背景图片 max_words = 3000, # 设置最大现实的字数 font_path = simhei, # 设置字体格式 width=2048, height=1024, scale=4.0, max_font_size= 300, # 字体最大值 random_state=42).generate(text) # 根据图片生成词云颜色 image_colors = ImageColorGenerator(abel_mask) wordcloud2.recolor(color_func=image_colors) # 以下代码显示图片 plt.imshow(wordcloud2) plt.axis(&quot;off&quot;) plt.show() wordcloud2.to_file(r&#39;wordcloud_2.jpg&#39;) #保存结果 关系图关系图法，是指用连线图来表示事物相互关系的一种方法。最常见的关系图是数据库里的 E-R 图，表示实体、关系、属性三者之间的关系。在文本可视化里面，关系图也经常被用来表示有相互关系、原因与结果和目的与手段等复杂关系 安装 Matplotlib、NetworkX； 解决 Matplotlib 无法写中文问题。 NetworkX 绘制关系图的数据组织结构，节点和边都是 list 格式，边的 list 里面是成对的节点 classes= df[&#39;class&#39;].values.tolist() classrooms=df[&#39;classroom&#39;].values.tolist() nodes = list(set(classes + classrooms)) weights = [(df.loc[index,&#39;class&#39;],df.loc[index,&#39;classroom&#39;])for index in df.index] weights = list(set(weights)) # 设置matplotlib正常显示中文 plt.rcParams[&#39;font.sans-serif&#39;]=[&#39;SimHei&#39;] # 用黑体显示中文 plt.rcParams[&#39;axes.unicode_minus&#39;]=False colors = [&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;, &#39;yellow&#39;] #有向图 DG = nx.DiGraph() #一次性添加多节点，输入的格式为列表 DG.add_nodes_from(nodes) #添加边，数据格式为列表 DG.add_edges_from(weights) #作图，设置节点名显示,节点大小，节点颜色 nx.draw(DG,with_labels=True, node_size=1000, node_color = colors) plt.show() 地理热力图地理热力图，是以特殊高亮的形式显示用户的地理位置，借助热力图，可以直观地观察到用户的总体情况和偏好。 安装 Folium； 将地理名词通过百度转换成经纬度。 在通过分词得到城市名称后，将地理名词通过百度转换成经纬度。首先注册密钥，使用百度 Web 服务 API 下的 Geocoding API 接口来获取你所需要地址的经纬度坐标，并转化为 JSON 结构的数据（个人接口，百度每天限制调用6000次），接下来定义经纬度获取函数： #经纬度转换 def getlnglat(address): url = &#39;http://api.map.baidu.com/geocoder/v2/&#39; output = &#39;json&#39; ak = &#39;sqGDDvCDEZPSz24bt4b0BpKLnMk1dv6d&#39; add = quote(address) #由于本文城市变量为中文，为防止乱码，先用quote进行编码 uri = url + &#39;?&#39; + &#39;address=&#39; + add + &#39;&amp;output=&#39; + output + &#39;&amp;ak=&#39; + ak req = urlopen(uri) res = req.read().decode() #将其他编码的字符串解码成unicode temp = json.loads(res) #对json数据进行解析 return temp 输出：北京,116.39564503787867,39.92998577808024,840成都,104.06792346330406,30.679942845419564,291重庆,106.53063501341296,29.54460610888615,261昆明,102.71460113878045,25.049153100453157,238潍坊,119.14263382297052,36.71611487305138,214济南,117.02496706629023,36.68278472716141,212 使用 Folium 库进行热力图绘制地图lat = np.array(cities[&quot;lat&quot;][0:num]) # 获取维度之维度值 lon = np.array(cities[&quot;lng&quot;][0:num]) # 获取经度值 pop = np.array(cities[&quot;count&quot;][0:num],dtype=float) # 获取人口数，转化为numpy浮点型 data1 = [[lat[i],lon[i],pop[i]] for i in range(num)] #将数据制作成[lats,lons,weights]的形式 map_osm = folium.Map(location=[35,110],zoom_start=5) #绘制Map，开始缩放程度是5倍 HeatMap(data1).add_to(map_osm) # 将热力图添加到前面建立的map里 file_path = dir + &quot;heatmap.html&quot; map_osm.save(file_path) 可视化技术栈 第一个是百度的 Echarts，基于 Canvas，适合刚入门的新手，遵循了数据可视化的一些经典范式，只要把数据组织好，就可以轻松得到很漂亮的图表； 第二个推荐 D3.js，基于 SVG 方便自己定制，D3 V4 支持 Canvas+SVG，D3.js 比 Echarts 稍微难点，适合有一定开发经验的人； 第三个 three.js，是一个基于 WebGL 的 3D 图形的框架，可以让用户通过 JavaScript 搭建 WebGL 项目]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>wordcloud</tag>
        <tag>folium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql使用实战]]></title>
    <url>%2F2019%2F10%2F29%2Fmysql%2F</url>
    <content type="text"><![CDATA[mysql使用实战 中文转拼音模糊查询CREATE TABLE IF NOT EXISTS `t_base_pinyin` ( `pin_yin_` VARCHAR (1000) CHARACTER SET gbk NOT NULL, `code_` INT (11) NOT NULL, PRIMARY KEY (`code_`) ) ENGINE = INNODB DEFAULT CHARSET = latin1; INSERT INTO t_base_pinyin (pin_yin_, code_) VALUES (&quot;a&quot;, 20319), (&quot;ai&quot;, 20317), (&quot;an&quot;, 20304), (&quot;ang&quot;, 20295), (&quot;ao&quot;, 20292), (&quot;ba&quot;, 20283), (&quot;bai&quot;, 20265), (&quot;ban&quot;, 20257), (&quot;bang&quot;, 20242), (&quot;bao&quot;, 20230), (&quot;bei&quot;, 20051), (&quot;ben&quot;, 20036), (&quot;beng&quot;, 20032), (&quot;bi&quot;, 20026), (&quot;bian&quot;, 20002), (&quot;biao&quot;, 19990), (&quot;bie&quot;, 19986), (&quot;bin&quot;, 19982), (&quot;bing&quot;, 19976), (&quot;bo&quot;, 19805), (&quot;bu&quot;, 19784), (&quot;ca&quot;, 19775), (&quot;cai&quot;, 19774), (&quot;can&quot;, 19763), (&quot;cang&quot;, 19756), (&quot;cao&quot;, 19751), (&quot;ce&quot;, 19746), (&quot;ceng&quot;, 19741), (&quot;cha&quot;, 19739), (&quot;chai&quot;, 19728), (&quot;chan&quot;, 19725), (&quot;chang&quot;, 19715), (&quot;chao&quot;, 19540), (&quot;che&quot;, 19531), (&quot;chen&quot;, 19525), (&quot;cheng&quot;, 19515), (&quot;chi&quot;, 19500), (&quot;chong&quot;, 19484), (&quot;chou&quot;, 19479), (&quot;chu&quot;, 19467), (&quot;chuai&quot;, 19289), (&quot;chuan&quot;, 19288), (&quot;chuang&quot;, 19281), (&quot;chui&quot;, 19275), (&quot;chun&quot;, 19270), (&quot;chuo&quot;, 19263), (&quot;ci&quot;, 19261), (&quot;cong&quot;, 19249), (&quot;cou&quot;, 19243), (&quot;cu&quot;, 19242), (&quot;cuan&quot;, 19238), (&quot;cui&quot;, 19235), (&quot;cun&quot;, 19227), (&quot;cuo&quot;, 19224), (&quot;da&quot;, 19218), (&quot;dai&quot;, 19212), (&quot;dan&quot;, 19038), (&quot;dang&quot;, 19023), (&quot;dao&quot;, 19018), (&quot;de&quot;, 19006), (&quot;deng&quot;, 19003), (&quot;di&quot;, 18996), (&quot;dian&quot;, 18977), (&quot;diao&quot;, 18961), (&quot;die&quot;, 18952), (&quot;ding&quot;, 18783), (&quot;diu&quot;, 18774), (&quot;dong&quot;, 18773), (&quot;dou&quot;, 18763), (&quot;du&quot;, 18756), (&quot;duan&quot;, 18741), (&quot;dui&quot;, 18735), (&quot;dun&quot;, 18731), (&quot;duo&quot;, 18722), (&quot;e&quot;, 18710), (&quot;en&quot;, 18697), (&quot;er&quot;, 18696), (&quot;fa&quot;, 18526), (&quot;fan&quot;, 18518), (&quot;fang&quot;, 18501), (&quot;fei&quot;, 18490), (&quot;fen&quot;, 18478), (&quot;feng&quot;, 18463), (&quot;fo&quot;, 18448), (&quot;fou&quot;, 18447), (&quot;fu&quot;, 18446), (&quot;ga&quot;, 18239), (&quot;gai&quot;, 18237), (&quot;gan&quot;, 18231), (&quot;gang&quot;, 18220), (&quot;gao&quot;, 18211), (&quot;ge&quot;, 18201), (&quot;gei&quot;, 18184), (&quot;gen&quot;, 18183), (&quot;geng&quot;, 18181), (&quot;gong&quot;, 18012), (&quot;gou&quot;, 17997), (&quot;gu&quot;, 17988), (&quot;gua&quot;, 17970), (&quot;guai&quot;, 17964), (&quot;guan&quot;, 17961), (&quot;guang&quot;, 17950), (&quot;gui&quot;, 17947), (&quot;gun&quot;, 17931), (&quot;guo&quot;, 17928), (&quot;ha&quot;, 17922), (&quot;hai&quot;, 17759), (&quot;han&quot;, 17752), (&quot;hang&quot;, 17733), (&quot;hao&quot;, 17730), (&quot;he&quot;, 17721), (&quot;hei&quot;, 17703), (&quot;hen&quot;, 17701), (&quot;heng&quot;, 17697), (&quot;hong&quot;, 17692), (&quot;hou&quot;, 17683), (&quot;hu&quot;, 17676), (&quot;hua&quot;, 17496), (&quot;huai&quot;, 17487), (&quot;huan&quot;, 17482), (&quot;huang&quot;, 17468), (&quot;hui&quot;, 17454), (&quot;hun&quot;, 17433), (&quot;huo&quot;, 17427), (&quot;ji&quot;, 17417), (&quot;jia&quot;, 17202), (&quot;jian&quot;, 17185), (&quot;jiang&quot;, 16983), (&quot;jiao&quot;, 16970), (&quot;jie&quot;, 16942), (&quot;jin&quot;, 16915), (&quot;jing&quot;, 16733), (&quot;jiong&quot;, 16708), (&quot;jiu&quot;, 16706), (&quot;ju&quot;, 16689), (&quot;juan&quot;, 16664), (&quot;jue&quot;, 16657), (&quot;jun&quot;, 16647), (&quot;ka&quot;, 16474), (&quot;kai&quot;, 16470), (&quot;kan&quot;, 16465), (&quot;kang&quot;, 16459), (&quot;kao&quot;, 16452), (&quot;ke&quot;, 16448), (&quot;ken&quot;, 16433), (&quot;keng&quot;, 16429), (&quot;kong&quot;, 16427), (&quot;kou&quot;, 16423), (&quot;ku&quot;, 16419), (&quot;kua&quot;, 16412), (&quot;kuai&quot;, 16407), (&quot;kuan&quot;, 16403), (&quot;kuang&quot;, 16401), (&quot;kui&quot;, 16393), (&quot;kun&quot;, 16220), (&quot;kuo&quot;, 16216), (&quot;la&quot;, 16212), (&quot;lai&quot;, 16205), (&quot;lan&quot;, 16202), (&quot;lang&quot;, 16187), (&quot;lao&quot;, 16180), (&quot;le&quot;, 16171), (&quot;lei&quot;, 16169), (&quot;leng&quot;, 16158), (&quot;li&quot;, 16155), (&quot;lia&quot;, 15959), (&quot;lian&quot;, 15958), (&quot;liang&quot;, 15944), (&quot;liao&quot;, 15933), (&quot;lie&quot;, 15920), (&quot;lin&quot;, 15915), (&quot;ling&quot;, 15903), (&quot;liu&quot;, 15889), (&quot;long&quot;, 15878), (&quot;lou&quot;, 15707), (&quot;lu&quot;, 15701), (&quot;lv&quot;, 15681), (&quot;luan&quot;, 15667), (&quot;lue&quot;, 15661), (&quot;lun&quot;, 15659), (&quot;luo&quot;, 15652), (&quot;ma&quot;, 15640), (&quot;mai&quot;, 15631), (&quot;man&quot;, 15625), (&quot;mang&quot;, 15454), (&quot;mao&quot;, 15448), (&quot;me&quot;, 15436), (&quot;mei&quot;, 15435), (&quot;men&quot;, 15419), (&quot;meng&quot;, 15416), (&quot;mi&quot;, 15408), (&quot;mian&quot;, 15394), (&quot;miao&quot;, 15385), (&quot;mie&quot;, 15377), (&quot;min&quot;, 15375), (&quot;ming&quot;, 15369), (&quot;miu&quot;, 15363), (&quot;mo&quot;, 15362), (&quot;mou&quot;, 15183), (&quot;mu&quot;, 15180), (&quot;na&quot;, 15165), (&quot;nai&quot;, 15158), (&quot;nan&quot;, 15153), (&quot;nang&quot;, 15150), (&quot;nao&quot;, 15149), (&quot;ne&quot;, 15144), (&quot;nei&quot;, 15143), (&quot;nen&quot;, 15141), (&quot;neng&quot;, 15140), (&quot;ni&quot;, 15139), (&quot;nian&quot;, 15128), (&quot;niang&quot;, 15121), (&quot;niao&quot;, 15119), (&quot;nie&quot;, 15117), (&quot;nin&quot;, 15110), (&quot;ning&quot;, 15109), (&quot;niu&quot;, 14941), (&quot;nong&quot;, 14937), (&quot;nu&quot;, 14933), (&quot;nv&quot;, 14930), (&quot;nuan&quot;, 14929), (&quot;nue&quot;, 14928), (&quot;nuo&quot;, 14926), (&quot;o&quot;, 14922), (&quot;ou&quot;, 14921), (&quot;pa&quot;, 14914), (&quot;pai&quot;, 14908), (&quot;pan&quot;, 14902), (&quot;pang&quot;, 14894), (&quot;pao&quot;, 14889), (&quot;pei&quot;, 14882), (&quot;pen&quot;, 14873), (&quot;peng&quot;, 14871), (&quot;pi&quot;, 14857), (&quot;pian&quot;, 14678), (&quot;piao&quot;, 14674), (&quot;pie&quot;, 14670), (&quot;pin&quot;, 14668), (&quot;ping&quot;, 14663), (&quot;po&quot;, 14654), (&quot;pu&quot;, 14645), (&quot;qi&quot;, 14630), (&quot;qia&quot;, 14594), (&quot;qian&quot;, 14429), (&quot;qiang&quot;, 14407), (&quot;qiao&quot;, 14399), (&quot;qie&quot;, 14384), (&quot;qin&quot;, 14379), (&quot;qing&quot;, 14368), (&quot;qiong&quot;, 14355), (&quot;qiu&quot;, 14353), (&quot;qu&quot;, 14345), (&quot;quan&quot;, 14170), (&quot;que&quot;, 14159), (&quot;qun&quot;, 14151), (&quot;ran&quot;, 14149), (&quot;rang&quot;, 14145), (&quot;rao&quot;, 14140), (&quot;re&quot;, 14137), (&quot;ren&quot;, 14135), (&quot;reng&quot;, 14125), (&quot;ri&quot;, 14123), (&quot;rong&quot;, 14122), (&quot;rou&quot;, 14112), (&quot;ru&quot;, 14109), (&quot;ruan&quot;, 14099), (&quot;rui&quot;, 14097), (&quot;run&quot;, 14094), (&quot;ruo&quot;, 14092), (&quot;sa&quot;, 14090), (&quot;sai&quot;, 14087), (&quot;san&quot;, 14083), (&quot;sang&quot;, 13917), (&quot;sao&quot;, 13914), (&quot;se&quot;, 13910), (&quot;sen&quot;, 13907), (&quot;seng&quot;, 13906), (&quot;sha&quot;, 13905), (&quot;shai&quot;, 13896), (&quot;shan&quot;, 13894), (&quot;shang&quot;, 13878), (&quot;shao&quot;, 13870), (&quot;she&quot;, 13859), (&quot;shen&quot;, 13847), (&quot;sheng&quot;, 13831), (&quot;shi&quot;, 13658), (&quot;shou&quot;, 13611), (&quot;shu&quot;, 13601), (&quot;shua&quot;, 13406), (&quot;shuai&quot;, 13404), (&quot;shuan&quot;, 13400), (&quot;shuang&quot;, 13398), (&quot;shui&quot;, 13395), (&quot;shun&quot;, 13391), (&quot;shuo&quot;, 13387), (&quot;si&quot;, 13383), (&quot;song&quot;, 13367), (&quot;sou&quot;, 13359), (&quot;su&quot;, 13356), (&quot;suan&quot;, 13343), (&quot;sui&quot;, 13340), (&quot;sun&quot;, 13329), (&quot;suo&quot;, 13326), (&quot;ta&quot;, 13318), (&quot;tai&quot;, 13147), (&quot;tan&quot;, 13138), (&quot;tang&quot;, 13120), (&quot;tao&quot;, 13107), (&quot;te&quot;, 13096), (&quot;teng&quot;, 13095), (&quot;ti&quot;, 13091), (&quot;tian&quot;, 13076), (&quot;tiao&quot;, 13068), (&quot;tie&quot;, 13063), (&quot;ting&quot;, 13060), (&quot;tong&quot;, 12888), (&quot;tou&quot;, 12875), (&quot;tu&quot;, 12871), (&quot;tuan&quot;, 12860), (&quot;tui&quot;, 12858), (&quot;tun&quot;, 12852), (&quot;tuo&quot;, 12849), (&quot;wa&quot;, 12838), (&quot;wai&quot;, 12831), (&quot;wan&quot;, 12829), (&quot;wang&quot;, 12812), (&quot;wei&quot;, 12802), (&quot;wen&quot;, 12607), (&quot;weng&quot;, 12597), (&quot;wo&quot;, 12594), (&quot;wu&quot;, 12585), (&quot;xi&quot;, 12556), (&quot;xia&quot;, 12359), (&quot;xian&quot;, 12346), (&quot;xiang&quot;, 12320), (&quot;xiao&quot;, 12300), (&quot;xie&quot;, 12120), (&quot;xin&quot;, 12099), (&quot;xing&quot;, 12089), (&quot;xiong&quot;, 12074), (&quot;xiu&quot;, 12067), (&quot;xu&quot;, 12058), (&quot;xuan&quot;, 12039), (&quot;xue&quot;, 11867), (&quot;xun&quot;, 11861), (&quot;ya&quot;, 11847), (&quot;yan&quot;, 11831), (&quot;yang&quot;, 11798), (&quot;yao&quot;, 11781), (&quot;ye&quot;, 11604), (&quot;yi&quot;, 11589), (&quot;yin&quot;, 11536), (&quot;ying&quot;, 11358), (&quot;yo&quot;, 11340), (&quot;yong&quot;, 11339), (&quot;you&quot;, 11324), (&quot;yu&quot;, 11303), (&quot;yuan&quot;, 11097), (&quot;yue&quot;, 11077), (&quot;yun&quot;, 11067), (&quot;za&quot;, 11055), (&quot;zai&quot;, 11052), (&quot;zan&quot;, 11045), (&quot;zang&quot;, 11041), (&quot;zao&quot;, 11038), (&quot;ze&quot;, 11024), (&quot;zei&quot;, 11020), (&quot;zen&quot;, 11019), (&quot;zeng&quot;, 11018), (&quot;zha&quot;, 11014), (&quot;zhai&quot;, 10838), (&quot;zhan&quot;, 10832), (&quot;zhang&quot;, 10815), (&quot;zhao&quot;, 10800), (&quot;zhe&quot;, 10790), (&quot;zhen&quot;, 10780), (&quot;zheng&quot;, 10764), (&quot;zhi&quot;, 10587), (&quot;zhong&quot;, 10544), (&quot;zhou&quot;, 10533), (&quot;zhu&quot;, 10519), (&quot;zhua&quot;, 10331), (&quot;zhuai&quot;, 10329), (&quot;zhuan&quot;, 10328), (&quot;zhuang&quot;, 10322), (&quot;zhui&quot;, 10315), (&quot;zhun&quot;, 10309), (&quot;zhuo&quot;, 10307), (&quot;zi&quot;, 10296), (&quot;zong&quot;, 10281), (&quot;zou&quot;, 10274), (&quot;zu&quot;, 10270), (&quot;zuan&quot;, 10262), (&quot;zui&quot;, 10260), (&quot;zun&quot;, 10256), (&quot;zuo&quot;, 10254); DROP FUNCTION IF EXISTS to_pinyin; DELIMITER $ CREATE FUNCTION to_pinyin(NAME text CHARSET gbk) RETURNS text CHARSET gbk BEGIN DECLARE mycode INT; DECLARE tmp_lcode VARCHAR(2) CHARSET gbk; DECLARE lcode INT; DECLARE tmp_rcode VARCHAR(2) CHARSET gbk; DECLARE rcode INT; DECLARE mypy text CHARSET gbk DEFAULT &#39;&#39;; DECLARE lp INT; SET mycode = 0; SET lp = 1; SET NAME = HEX(NAME); WHILE lp &lt; LENGTH(NAME) DO SET tmp_lcode = SUBSTRING(NAME, lp, 2); SET lcode = CAST(ASCII(UNHEX(tmp_lcode)) AS UNSIGNED); SET tmp_rcode = SUBSTRING(NAME, lp + 2, 2); SET rcode = CAST(ASCII(UNHEX(tmp_rcode)) AS UNSIGNED); IF lcode &gt; 128 THEN SET mycode =65536 - lcode * 256 - rcode ; SELECT CONCAT(mypy,pin_yin_) INTO mypy FROM t_base_pinyin WHERE CODE_ &gt;= ABS(mycode) ORDER BY CODE_ ASC LIMIT 1; SET lp = lp + 4; ELSE SET mypy = CONCAT(mypy,CHAR(CAST(ASCII(UNHEX(SUBSTRING(NAME, lp, 2))) AS UNSIGNED))); SET lp = lp + 2; END IF; END WHILE; RETURN LOWER(mypy); END; $ DELIMITER ; CREATE VIEW v_pinyin AS SELECT u.jjbh,u.CJLB,u.SFDD,u.CJXXDD,u.BJNR,u.CLJGNR,u.CJDWMC,u.JJRQSJ ，to_pinyin (u.CLJGNR) AS CLJGNR_PINYIN,to_pinyin (u.BJNR) AS BJNR_PINYIN，u.JJRQSJ FROM p_answer_handle_alarm u 抽取文本中数字/字母/中文DELIMITER $$ DROP FUNCTION IF EXISTS `Num_char_extract`$$ CREATE FUNCTION `Num_char_extract`(Varstring VARCHAR(100)CHARSET utf8, flag INT) RETURNS VARCHAR(50) CHARSET utf8 BEGIN DECLARE len INT DEFAULT 0; DECLARE Tmp VARCHAR(100) DEFAULT &#39;&#39;; SET len=CHAR_LENGTH(Varstring); IF flag = 0 THEN WHILE len &gt; 0 DO IF MID(Varstring,len,1)REGEXP&#39;[0-9]&#39; THEN SET Tmp=CONCAT(Tmp,MID(Varstring,len,1)); END IF; SET len = len - 1; END WHILE; ELSEIF flag=1 THEN WHILE len &gt; 0 DO IF (MID(Varstring,len,1)REGEXP &#39;[a-zA-Z]&#39;) THEN SET Tmp=CONCAT(Tmp,MID(Varstring,len,1)); END IF; SET len = len - 1; END WHILE; ELSEIF flag=2 THEN WHILE len &gt; 0 DO IF ( (MID(Varstring,len,1)REGEXP&#39;[0-9]&#39;) OR (MID(Varstring,len,1)REGEXP &#39;[a-zA-Z]&#39;) ) THEN SET Tmp=CONCAT(Tmp,MID(Varstring,len,1)); END IF; SET len = len - 1; END WHILE; ELSEIF flag=3 THEN WHILE len &gt; 0 DO IF NOT (MID(Varstring,len,1)REGEXP &#39;^[u0391-uFFE5]&#39;) THEN SET Tmp=CONCAT(Tmp,MID(Varstring,len,1)); END IF; SET len = len - 1; END WHILE; ELSE SET Tmp = &#39;Error: The second paramter should be in (0,1,2,3)&#39;; RETURN Tmp; END IF; RETURN REVERSE(Tmp); END$$ DELIMITER ; 中文转首字母查询CREATE FUNCTION `fristPinyin`(P_NAME VARCHAR(255)) RETURNS varchar(255) CHARSET utf8 BEGIN DECLARE V_RETURN VARCHAR(255); SET V_RETURN = ELT(INTERVAL(CONV(HEX(left(CONVERT(P_NAME USING gbk),1)),16,10), 0xB0A1,0xB0C5,0xB2C1,0xB4EE,0xB6EA,0xB7A2,0xB8C1,0xB9FE,0xBBF7, 0xBFA6,0xC0AC,0xC2E8,0xC4C3,0xC5B6,0xC5BE,0xC6DA,0xC8BB, 0xC8F6,0xCBFA,0xCDDA,0xCEF4,0xD1B9,0xD4D1), &#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;D&#39;,&#39;E&#39;,&#39;F&#39;,&#39;G&#39;,&#39;H&#39;,&#39;J&#39;,&#39;K&#39;,&#39;L&#39;,&#39;M&#39;,&#39;N&#39;,&#39;O&#39;,&#39;P&#39;,&#39;Q&#39;,&#39;R&#39;,&#39;S&#39;,&#39;T&#39;,&#39;W&#39;,&#39;X&#39;,&#39;Y&#39;,&#39;Z&#39;); RETURN V_RETURN; END; CREATE FUNCTION `pinyin`(P_NAME VARCHAR(255)) RETURNS varchar(255) CHARSET utf8 BEGIN DECLARE V_COMPARE VARCHAR(255); DECLARE V_RETURN VARCHAR(255); DECLARE I INT; SET I = 1; SET V_RETURN = &#39;&#39;; while I &lt; LENGTH(P_NAME) do SET V_COMPARE = SUBSTR(P_NAME, I, 1); IF (V_COMPARE != &#39;&#39;) THEN #SET V_RETURN = CONCAT(V_RETURN, &#39;,&#39;, V_COMPARE); SET V_RETURN = CONCAT(V_RETURN, fristPinyin(V_COMPARE)); #SET V_RETURN = fristPinyin(V_COMPARE); END IF; SET I = I + 1; end while; IF (ISNULL(V_RETURN) or V_RETURN = &#39;&#39;) THEN SET V_RETURN = P_NAME; END IF; RETURN V_RETURN; END; select upper(pinyin(company_name)) as cn,company_name from job where upper(pinyin(company_name)) like &#39;%pa%&#39;; select pinyin(&quot;金石&quot;) 联表查询在A不在B表select * from (select DISTINCT(company_name) from job j1 where is_checked = ‘1’) j2 where j2.company_name not in(select DISTINCT(job_company_name) from standard_business s1)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>procedure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy集成selenium爬取boss直聘]]></title>
    <url>%2F2019%2F10%2F17%2Fscrapy%E9%9B%86%E6%88%90selenium%E7%88%AC%E5%8F%96boss%E7%9B%B4%E8%81%98%2F</url>
    <content type="text"><![CDATA[scrapy集成selenium爬取boss直聘 核心代码class BossSpider(scrapy.Spider): name = &#39;boss&#39; allowed_domains = [&#39;zhipin.com&#39;] start_urls = [&#39;https://www.zhipin.com/&#39;] nodes = [] def parse(self, response): driver = None chrome_options = webdriver.ChromeOptions() # proxy_url = get_random_proxy() # print(proxy_url + &quot;代理服务器正在爬取&quot;) # chrome_options.add_argument(&#39;--proxy-server=https://&#39; + proxy_url.strip()) prefs = { &#39;profile.default_content_setting_values&#39;: { &#39;images&#39;: 1, # 加载图片 &quot;User-Agent&quot;: UserAgent().random, # 更换UA } } chrome_options.add_experimental_option(&quot;prefs&quot;, prefs) chrome_options.add_experimental_option(&#39;excludeSwitches&#39;, [&#39;enable-automation&#39;]) if platform.system() == &quot;Windows&quot;: driver = webdriver.Chrome(&#39;chromedriver.exe&#39;, chrome_options=chrome_options) elif platform.system() == &quot;Linux&quot;: chrome_options.add_argument(&quot;--headless&quot;) chrome_options.add_argument(&#39;--disable-gpu&#39;) chrome_options.add_argument(&#39;--no-sandbox&#39;) driver = webdriver.Chrome( executable_path=&quot;/usr/bin/chromedriver&quot;, chrome_options=chrome_options) # driver.set_window_size(500, 200) data = [&quot;游戏&quot;, &quot;期货&quot;, &quot;贷款&quot;] for kw in data: url = &quot;https://www.zhipin.com/c101190400/?query={}&quot;.format(kw) driver.get(url) time.sleep(2) # 获取信息 last_url = driver.current_url source = etree.HTML(driver.page_source) links = source.xpath(&quot;//div[@class=&#39;job-primary&#39;]/div[@class=&#39;info-primary&#39;]//a/@href&quot;) global nodes nodes = list(map(lambda x: &quot;https://www.zhipin.com{}&quot;.format(x), links)) while len(source.xpath(&#39;//div[@class=&quot;page&quot;]/a[@class=&quot;next&quot; and @ka=&quot;page-next&quot;]&#39;)) == 1: next_page = driver.find_element_by_xpath( &#39;//div[@class=&quot;page&quot;]/a[@class=&quot;next&quot; and @ka=&quot;page-next&quot;]&#39;) WebDriverWait(driver, 10).until(expected_conditions.element_to_be_clickable( (By.XPATH, &#39;//div[@class=&quot;page&quot;]/a[@class=&quot;next&quot; and @ka=&quot;page-next&quot;]&#39;))) current_url = driver.current_url while last_url == current_url: self.loop_try(next_page) last_url = driver.current_url print(driver.current_url) source = etree.HTML(driver.page_source) new_links = source.xpath(&quot;//div[@class=&#39;job-primary&#39;]/div[@class=&#39;info-primary&#39;]//a/@href&quot;) new_nodes = list(map(lambda x: &quot;https://www.zhipin.com{}&quot;.format(x), new_links)) nodes.extend(new_nodes) yield Request(url=&quot;https://www.zhipin.com&quot;, callback=self.parse_detail, meta={&#39;params&#39;: (nodes, driver, kw)},dont_filter=True) def parse_detail(self,response): nodes, driver, kw = response.meta.get(&quot;params&quot;) for node in nodes: print(node) driver.execute_script(&quot;window.open(&#39;%s&#39;)&quot; % node) time.sleep(2) driver.switch_to.window(driver.window_handles[1]) WebDriverWait(driver, timeout=10).until( EC.presence_of_element_located((By.XPATH, &quot;//div[@class=&#39;detail-content&#39;]&quot;)) ) html = etree.HTML(driver.page_source) driver.close() driver.switch_to.window(driver.window_handles[0]) item = JobItem() item[&#39;recruitment_position&#39;] = html.xpath( &quot;//div[@class=&#39;job-primary detail-box&#39;]/div[@class=&#39;info-primary&#39;]/div[@class=&#39;name&#39;]/h1/text()&quot;)[0] item[&#39;salary&#39;] = html.xpath( &quot;//div[@class=&#39;job-primary detail-box&#39;]/div[@class=&#39;info-primary&#39;]/div[@class=&#39;name&#39;]/span/text()&quot;)[ 0] item[&#39;keyword&#39;] = kw item[&#39;url&#39;] = node item[&#39;source&#39;] = &quot;BOSS直聘&quot; item[&#39;update_date&#39;] = html.xpath(&#39;//div[@class=&quot;sider-company&quot;]/p[last()]/text()&#39;)[0] item[&#39;company_name&#39;] = html.xpath(&#39;//a[@ka=&quot;job-detail-company_custompage&quot;]&#39;)[0].attrib.get(&#39;title&#39;).strip().replace(&quot;\n招聘&quot;,&quot;&quot;) # item[&#39;company_name&#39;] = html.xpath(&#39;//div[@class=&quot;level-list&quot;]/preceding-sibling::div[1]/text()&#39;)[0] item[&#39;work_experience&#39;] = html.xpath(&#39;//*[@class=&quot;job-primary detail-box&quot;]/div[2]/p/text()&#39;)[1] item[&#39;education_background&#39;] = html.xpath(&#39;//*[@class=&quot;job-primary detail-box&quot;]/div[2]/p/text()&#39;)[2] item[&#39;job_requirements&#39;] = &quot;&quot;.join( html.xpath(&#39;//div[@class=&quot;detail-content&quot;]/div[@class=&quot;job-sec&quot;]/div[@class=&quot;text&quot;]/text()&#39;)) item[&#39;company_info&#39;] = &quot;&quot;.join( html.xpath(&#39;//div[@class=&quot;job-sec company-info&quot;]//div[@class=&quot;text&quot;]/text()&#39;)) item[&#39;company_address&#39;] = html.xpath(&#39;//*[@class=&quot;location-address&quot;]/text()&#39;)[0] item[&#39;company_welfare&#39;] = &quot;,&quot;.join(html.xpath( &#39;//div[@class=&quot;job-banner&quot;]/div[@class=&quot;job-primary detail-box&quot;]/div[@class=&quot;info-primary&quot;]/div[@class=&quot;tag-container&quot;]/div[@class=&quot;job-tags&quot;]/text()&#39;)) item[&#39;id&#39;] = get_md5(node) item[&#39;crawl_date&#39;] = datetime.now().strftime(&quot;%Y-%m-%d&quot;) yield item def loop_try(self,next_page): try: next_page.click() except: self.loop_try(next_page)]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
        <tag>selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达深度学习笔记(第三课时)]]></title>
    <url>%2F2019%2F10%2F09%2Fnew_%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E7%AC%AC%E4%B8%89%E8%AF%BE%E6%97%B6)%2F</url>
    <content type="text"><![CDATA[吴恩达深度学习笔记 结构化机器学习项目（Structuring Machine Learning Projects）第一周 机器学习（ML）策略（1）（ML strategy（1））1.1 为什么是ML策略？（Why ML Strategy?）大家好，欢迎收听本课，如何构建你的机器学习项目也就是说机器学习的策略。我希望通过这门课程你们能够学到如何更快速高效地优化你的机器学习系统。那么，什么是机器学习策略呢？ 我们从一个启发性的例子开始讲，假设你正在调试你的猫分类器，经过一段时间的调整，你的系统达到了90%准确率，但对你的应用程序来说还不够好。 你可能有很多想法去改善你的系统，比如，你可能想我们去收集更多的训练数据吧。或者你会说，可能你的训练集的多样性还不够，你应该收集更多不同姿势的猫咪图片，或者更多样化的反例集。或者你想再用梯度下降训练算法，训练久一点。或者你想尝试用一个完全不同的优化算法，比如Adam优化算法。或者尝试使用规模更大或者更小的神经网络。或者你想试试dropout或者$L2$正则化。或者你想修改网络的架构，比如修改激活函数，改变隐藏单元的数目之类的方法。 当你尝试优化一个深度学习系统时，你通常可以有很多想法可以去试，问题在于，如果你做出了错误的选择，你完全有可能白费6个月的时间，往错误的方向前进，在6个月之后才意识到这方法根本不管用。比如，我见过一些团队花了6个月时间收集更多数据，却在6个月之后发现，这些数据几乎没有改善他们系统的性能。所以，假设你的项目没有6个月的时间可以浪费，如果有快速有效的方法能够判断哪些想法是靠谱的，或者甚至提出新的想法，判断哪些是值得一试的想法，哪些是可以放心舍弃的。 我希望在这门课程中，可以教给你们一些策略，一些分析机器学习问题的方法，可以指引你们朝着最有希望的方向前进。这门课中，我会和你们分享我在搭建和部署大量深度学习产品时学到的经验和教训，我想这些内容是这门课程独有的。比如说，很多大学深度学习课程很少提到这些策略。事实上，机器学习策略在深度学习的时代也在变化，因为现在对于深度学习算法来说能够做到的事情，比上一代机器学习算法大不一样。我希望这些策略能帮助你们提高效率，让你们的深度学习系统更快投入实用。 1.2 正交化（Orthogonalization）搭建建立机器学习系统的挑战之一是，你可以尝试和改变的东西太多太多了。包括，比如说，有那么多的超参数可以调。我留意到，那些效率很高的机器学习专家有个特点，他们思维清晰，对于要调整什么来达到某个效果，非常清楚，这个步骤我们称之为正交化，让我告诉你是什么意思吧。 这是一张老式电视图片，有很多旋钮可以用来调整图像的各种性质，所以对于这些旧式电视，可能有一个旋钮用来调图像垂直方向的高度，另外有一个旋钮用来调图像宽度，也许还有一个旋钮用来调梯形角度，还有一个旋钮用来调整图像左右偏移，还有一个旋钮用来调图像旋转角度之类的。电视设计师花了大量时间设计电路，那时通常都是模拟电路来确保每个旋钮都有相对明确的功能。如一个旋钮来调整这个（高度），一个旋钮调整这个（宽度），一个旋钮调整这个（梯形角度），以此类推。 相比之下，想象一下，如果你有一个旋钮调的是$0.1x$表示图像高度，$+0.3x$表示图像宽度，$-1.7x$表示梯形角度，$+0.8x$表示图像在水平轴上的坐标之类的。如果你调整这个（其中一个）旋钮，那么图像的高度、宽度、梯形角度、平移位置全部都会同时改变，如果你有这样的旋钮，那几乎不可能把电视调好，让图像显示在区域正中。 所以在这种情况下，正交化指的是电视设计师设计这样的旋钮，使得每个旋钮都只调整一个性质，这样调整电视图像就容易得多，就可以把图像调到正中。 接下来是另一个正交化例子，你想想学车的时候，一辆车有三个主要控制，第一是方向盘，方向盘决定你往左右偏多少，还有油门和刹车。就是这三个控制，其中一个控制方向，另外两个控制你的速度，这样就比较容易解读。知道不同控制的不同动作会对车子运动有什么影响。 想象一下，如果有人这么造车，造了个游戏手柄，手柄的一个轴控制的是$0.3×$转向角-速度，然后还有一个轴控制的是$2×$转向角$+0.9×$车速，理论上来说，通过调整这两个旋钮你是可以将车子调整到你希望得到的角度和速度，但这样比单独控制转向角度，分开独立的速度控制要难得多。 所以正交化的概念是指，你可以想出一个维度，这个维度你想做的是控制转向角，还有另一个维度来控制你的速度，那么你就需要一个旋钮尽量只控制转向角，另一个旋钮，在这个开车的例子里其实是油门和刹车控制了你的速度。但如果你有一个控制旋钮将两者混在一起，比如说这样一个控制装置同时影响你的转向角和速度，同时改变了两个性质，那么就很难令你的车子以想要的速度和角度前进。然而正交化之后，正交意味着互成90度。设计出正交化的控制装置，最理想的情况是和你实际想控制的性质一致，这样你调整参数时就容易得多。可以单独调整转向角，还有你的油门和刹车，令车子以你想要的方式运动。 那么这与机器学习有什么关系呢？要弄好一个监督学习系统，你通常需要调你的系统的旋钮。 确保四件事情，首先，你通常必须确保至少系统在训练集上得到的结果不错，所以训练集上的表现必须通过某种评估，达到能接受的程度，对于某些应用，这可能意味着达到人类水平的表现，但这取决于你的应用，我们将在下周更多地谈谈如何与人类水平的表现进行比较。但是，在训练集上表现不错之后，你就希望系统也能在开发集上有好的表现，然后你希望系统在测试集上也有好的表现。在最后，你希望系统在测试集上系统的成本函数在实际使用中表现令人满意，比如说，你希望这些猫图片应用的用户满意。 我们回到电视调节的例子，如果你的电视图像太宽或太窄，你想要一个旋钮去调整，你可不想要仔细调节五个不同的旋钮，它们也会影响别的图像性质，你只需要一个旋钮去改变电视图像的宽度。 所以类似地，如果你的算法在成本函数上不能很好地拟合训练集，你想要一个旋钮，是的我画这东西表示旋钮，或者一组特定的旋钮，这样你可以用来确保你的可以调整你的算法，让它很好地拟合训练集，所以你用来调试的旋钮是你可能可以训练更大的网络，或者可以切换到更好的优化算法，比如Adam优化算法，等等。我们将在本周和下周讨论一些其他选项。 相比之下，如果发现算法对开发集的拟合很差，那么应该有独立的一组旋钮，是的，这就是我画得毛毛躁躁的另一个旋钮，你希望有一组独立的旋钮去调试。比如说，你的算法在开发集上做的不好，它在训练集上做得很好，但开发集不行，然后你有一组正则化的旋钮可以调节，尝试让系统满足第二个条件。类比到电视，就是现在你调好了电视的宽度，如果图像的高度不太对，你就需要一个不同的旋钮来调节电视图像的高度，然后你希望这个旋钮尽量不会影响到电视的宽度。增大训练集可以是另一个可用的旋钮，它可以帮助你的学习算法更好地归纳开发集的规律，现在调好了电视图像的高度和宽度。 如果它不符合第三个标准呢？如果系统在开发集上做的很好，但测试集上做得不好呢？如果是这样，那么你需要调的旋钮，可能是更大的开发集。因为如果它在开发集上做的不错，但测试集不行这可能意味着你对开发集过拟合了，你需要往回退一步，使用更大的开发集。 最后，如果它在测试集上做得很好，但无法给你的猫图片应用用户提供良好的体验，这意味着你需要回去，改变开发集或成本函数。因为如果根据某个成本函数，系统在测试集上做的很好，但它无法反映你的算法在现实世界中的表现，这意味着要么你的开发集分布设置不正确，要么你的成本函数测量的指标不对。 我们很快会逐一讲到这些例子，我们以后会详细介绍这些特定的旋钮，在本周和下周晚些时候会介绍的。所以如果现在你无法理解全部细节，别担心，但我希望你们对这种正交化过程有个概念。你要非常清楚，到底是四个问题中的哪一个，知道你可以调节哪些不同的东西尝试解决那个问题。 当我训练神经网络时，我一般不用early stopping，这个技巧也还不错，很多人都这么干。但个人而言，我觉得用early stopping有点难以分析，因为这个旋钮会同时影响你对训练集的拟合，因为如果你早期停止，那么对训练集的拟合就不太好，但它同时也用来改善开发集的表现，所以这个旋钮没那么正交化。因为它同时影响两件事情，就像一个旋钮同时影响电视图像的宽度和高度。不是说这样就不要用，如果你想用也是可以的。但如果你有更多的正交化控制，比如我这里写出的其他手段，用这些手段调网络会简单不少。 所以我希望你们对正交化的意义有点概念，就像你看电视图像一样。如果你说，我的电视图像太宽，所以我要调整这个旋钮（宽度旋钮）。或者它太高了，所以我要调整那个旋钮（高度旋钮）。或者它太梯形了，所以我要调整这个旋钮（梯形角度旋钮），这就很好。 在机器学习中，如果你可以观察你的系统，然后说这一部分是错的，它在训练集上做的不好、在开发集上做的不好、它在测试集上做的不好，或者它在测试集上做的不错，但在现实世界中不好，这就很好。必须弄清楚到底是什么地方出问题了，然后我们刚好有对应的旋钮，或者一组对应的旋钮，刚好可以解决那个问题，那个限制了机器学习系统性能的问题。 这就是我们这周和下周要讲到的，如何诊断出系统性能瓶颈到底在哪。还有找到你可以用的一组特定的旋钮来调整你的系统，来改善它特定方面的性能，我们开始详细讲讲这个过程吧。 1.3 单一数字评估指标（Single number evaluation metric）无论你是调整超参数，或者是尝试不同的学习算法，或者在搭建机器学习系统时尝试不同手段，你会发现，如果你有一个单实数评估指标，你的进展会快得多，它可以快速告诉你，新尝试的手段比之前的手段好还是差。所以当团队开始进行机器学习项目时，我经常推荐他们为问题设置一个单实数评估指标。 我们来看一个例子，你之前听过我说过，应用机器学习是一个非常经验性的过程，我们通常有一个想法，编程序，跑实验，看看效果如何，然后使用这些实验结果来改善你的想法，然后继续走这个循环，不断改进你的算法。 比如说对于你的猫分类器，之前你搭建了某个分类器$A$，通过改变超参数，还有改变训练集等手段，你现在训练出来了一个新的分类器B，所以评估你的分类器的一个合理方式是观察它的查准率（precision）和查全率（recall）。 查准率和查全率的确切细节对于这个例子来说不太重要。但简而言之，查准率的定义是在你的分类器标记为猫的例子中，有多少真的是猫。所以如果分类器$A$有95%的查准率，这意味着你的分类器说这图有猫的时候，有95%的机会真的是猫。 查全率就是，对于所有真猫的图片，你的分类器正确识别出了多少百分比。实际为猫的图片中，有多少被系统识别出来？如果分类器$A$查全率是90%，这意味着对于所有的图像，比如说你的开发集都是真的猫图，分类器$A$准确地分辨出了其中的90%。 所以关于查准率和查全率的定义，不用想太多。事实证明，查准率和查全率之间往往需要折衷，两个指标都要顾及到。你希望得到的效果是，当你的分类器说某个东西是猫的时候，有很大的机会它真的是一只猫，但对于所有是猫的图片，你也希望系统能够将大部分分类为猫，所以用查准率和查全率来评估分类器是比较合理的。 但使用查准率和查全率作为评估指标的时候，有个问题，如果分类器$A$在查全率上表现更好，分类器$B$在查准率上表现更好，你就无法判断哪个分类器更好。如果你尝试了很多不同想法，很多不同的超参数，你希望能够快速试验不仅仅是两个分类器，也许是十几个分类器，快速选出“最好的”那个，这样你可以从那里出发再迭代。如果有两个评估指标，就很难去快速地二中选一或者十中选一，所以我并不推荐使用两个评估指标，查准率和查全率来选择一个分类器。你只需要找到一个新的评估指标，能够结合查准率和查全率。 在机器学习文献中，结合查准率和查全率的标准方法是所谓的$F_1$分数，$F_1$分数的细节并不重要。但非正式的，你可以认为这是查准率$P$和查全率$R$的平均值。正式来看，$F_1$分数的定义是这个公式：$\frac{2}{\frac{1}{P} + \frac{1}{R} }$ 在数学中，这个函数叫做查准率$P$和查全率$R$的调和平均数。但非正式来说，你可以将它看成是某种查准率和查全率的平均值，只不过你算的不是直接的算术平均，而是用这个公式定义的调和平均。这个指标在权衡查准率和查全率时有一些优势。 但在这个例子中，你可以马上看出，分类器$A$的$F_1$分数更高。假设$F_1$分数是结合查准率和查全率的合理方式，你可以快速选出分类器$A$，淘汰分类器$B$。 我发现很多机器学习团队就是这样，有一个定义明确的开发集用来测量查准率和查全率，再加上这样一个单一数值评估指标，有时我叫单实数评估指标，能让你快速判断分类器$A$或者分类器$B$更好。所以有这样一个开发集，加上单实数评估指标，你的迭代速度肯定会很快，它可以加速改进您的机器学习算法的迭代过程。 我们来看另一个例子，假设你在开发一个猫应用来服务四个地理大区的爱猫人士，美国、中国、印度还有世界其他地区。我们假设你的两个分类器在来自四个地理大区的数据中得到了不同的错误率，比如算法$A$在美国用户上传的图片中达到了3%错误率，等等。 所以跟踪一下，你的分类器在不同市场和地理大区中的表现应该是有用的，但是通过跟踪四个数字，很难扫一眼这些数值就快速判断算法$A$或算法$B$哪个更好。如果你测试很多不同的分类器，那么看着那么多数字，然后快速选一个最优是很难的。所以在这个例子中，我建议，除了跟踪分类器在四个不同的地理大区的表现，也要算算平均值。假设平均表现是一个合理的单实数评估指标，通过计算平均值，你就可以快速判断。 看起来算法$C$的平均错误率最低，然后你可以继续用那个算法。你必须选择一个算法，然后不断迭代，所以你的机器学习的工作流程往往是你有一个想法，你尝试实现它，看看这个想法好不好。 所以本视频介绍的是，有一个单实数评估指标真的可以提高你的效率，或者提高你的团队做出这些决策的效率。现在我们还没有完整讨论如何有效地建立评估指标。在下一个视频中，我会教你们如何设置优化以及满足指标，我们来看下一段视频。 1.4 满足和优化指标（Satisficing and optimizing metrics）要把你顾及到的所有事情组合成单实数评估指标有时并不容易，在那些情况里，我发现有时候设立满足和优化指标是很重要的，让我告诉你是什么意思吧。 假设你已经决定你很看重猫分类器的分类准确度，这可以是$F_1$分数或者用其他衡量准确度的指标。但除了准确度之外，我们还需要考虑运行时间，就是需要多长时间来分类一张图。分类器$A$需要80毫秒，$B$需要95毫秒，$C$需要1500毫秒，就是说需要1.5秒来分类图像。 你可以这么做，将准确度和运行时间组合成一个整体评估指标。所以成本，比如说，总体成本是$cost= accuracy - 0.5 \times\text{runningTime}$，这种组合方式可能太刻意，只用这样的公式来组合准确度和运行时间，两个数值的线性加权求和。 你还可以做其他事情，就是你可能选择一个分类器，能够最大限度提高准确度，但必须满足运行时间要求，就是对图像进行分类所需的时间必须小于等于100毫秒。所以在这种情况下，我们就说准确度是一个优化指标，因为你想要准确度最大化，你想做的尽可能准确，但是运行时间就是我们所说的满足指标，意思是它必须足够好，它只需要小于100毫秒，达到之后，你不在乎这指标有多好，或者至少你不会那么在乎。所以这是一个相当合理的权衡方式，或者说将准确度和运行时间结合起来的方式。实际情况可能是，只要运行时间少于100毫秒，你的用户就不会在乎运行时间是100毫秒还是50毫秒，甚至更快。 通过定义优化和满足指标，就可以给你提供一个明确的方式，去选择“最好的”分类器。在这种情况下分类器B最好，因为在所有的运行时间都小于100毫秒的分类器中，它的准确度最好。 所以更一般地说，如果你要考虑$N$个指标，有时候选择其中一个指标做为优化指标是合理的。所以你想尽量优化那个指标，然后剩下$N-1$个指标都是满足指标，意味着只要它们达到一定阈值，例如运行时间快于100毫秒，但只要达到一定的阈值，你不在乎它超过那个门槛之后的表现，但它们必须达到这个门槛。 这里是另一个例子，假设你正在构建一个系统来检测唤醒语，也叫触发词，这指的是语音控制设备。比如亚马逊Echo，你会说“Alexa”，或者用“Okay Google”来唤醒谷歌设备，或者对于苹果设备，你会说“Hey Siri”，或者对于某些百度设备，我们用“你好百度”唤醒。 对的，这些就是唤醒词，可以唤醒这些语音控制设备，然后监听你想说的话。所以你可能会在乎触发字检测系统的准确性，所以当有人说出其中一个触发词时，有多大概率可以唤醒你的设备。 你可能也需要顾及假阳性（false positive）的数量，就是没有人在说这个触发词时，它被随机唤醒的概率有多大？所以这种情况下，组合这两种评估指标的合理方式可能是最大化精确度。所以当某人说出唤醒词时，你的设备被唤醒的概率最大化，然后必须满足24小时内最多只能有1次假阳性，对吧？所以你的设备平均每天只会没有人真的在说话时随机唤醒一次。所以在这种情况下，准确度是优化指标，然后每24小时发生一次假阳性是满足指标，你只要每24小时最多有一次假阳性就满足了。 总结一下，如果你需要顾及多个指标，比如说，有一个优化指标，你想尽可能优化的，然后还有一个或多个满足指标，需要满足的，需要达到一定的门槛。现在你就有一个全自动的方法，在观察多个成本大小时，选出”最好的”那个。现在这些评估指标必须是在训练集或开发集或测试集上计算或求出来的。所以你还需要做一件事，就是设立训练集、开发集，还有测试集。在下一个视频里，我想和大家分享一些如何设置训练、开发和测试集的指导方针，我们下一个视频继续。 1.5 训练/开发/测试集划分（Train/dev/test distributions）设立训练集，开发集和测试集的方式大大影响了你或者你的团队在建立机器学习应用方面取得进展的速度。同样的团队，即使是大公司里的团队，在设立这些数据集的方式，真的会让团队的进展变慢而不是加快，我们看看应该如何设立这些数据集，让你的团队效率最大化。 在这个视频中，我想集中讨论如何设立开发集和测试集，开发（dev）集也叫做开发集（development set），有时称为保留交叉验证集（hold out cross validation set）。然后，机器学习中的工作流程是，你尝试很多思路，用训练集训练不同的模型，然后使用开发集来评估不同的思路，然后选择一个，然后不断迭代去改善开发集的性能，直到最后你可以得到一个令你满意的成本，然后你再用测试集去评估。 现在，举个例子，你要开发一个猫分类器，然后你在这些区域里运营，美国、英国、其他欧洲国家，南美洲、印度、中国，其他亚洲国家和澳大利亚，那么你应该如何设立开发集和测试集呢？ 其中一种做法是，你可以选择其中4个区域，我打算使用这四个（前四个），但也可以是随机选的区域，然后说，来自这四个区域的数据构成开发集。然后其他四个区域，我打算用这四个（后四个），也可以随机选择4个，这些数据构成测试集。 事实证明，这个想法非常糟糕，因为这个例子中，你的开发集和测试集来自不同的分布。我建议你们不要这样，而是让你的开发集和测试集来自同一分布。我的意思是这样，你们要记住，我想就是设立你的开发集加上一个单实数评估指标，这就是像是定下目标，然后告诉你的团队，那就是你要瞄准的靶心，因为你一旦建立了这样的开发集和指标，团队就可以快速迭代，尝试不同的想法，跑实验，可以很快地使用开发集和指标去评估不同分类器，然后尝试选出最好的那个。所以，机器学习团队一般都很擅长使用不同方法去逼近目标，然后不断迭代，不断逼近靶心。所以，针对开发集上的指标优化。 然后在左边的例子中，设立开发集和测试集时存在一个问题，你的团队可能会花上几个月时间在开发集上迭代优化，结果发现，当你们最终在测试集上测试系统时，来自这四个国家或者说下面这四个地区的数据（即测试集数据）和开发集里的数据可能差异很大，所以你可能会收获”意外惊喜”，并发现，花了那么多个月的时间去针对开发集优化，在测试集上的表现却不佳。所以，如果你的开发集和测试集来自不同的分布，就像你设了一个目标，让你的团队花几个月尝试逼近靶心，结果在几个月工作之后发现，你说“等等”，测试的时候，”我要把目标移到这里”，然后团队可能会说”好吧，为什么你让我们花那么多个月的时间去逼近那个靶心，然后突然间你可以把靶心移到不同的位置？”。 所以，为了避免这种情况，我建议的是你将所有数据随机洗牌，放入开发集和测试集，所以开发集和测试集都有来自八个地区的数据，并且开发集和测试集都来自同一分布，这分布就是你的所有数据混在一起。 这里有另一个例子，这是个真实的故事，但有一些细节变了。所以我知道有一个机器学习团队，花了好几个月在开发集上优化，开发集里面有中等收入邮政编码的贷款审批数据。那么具体的机器学习问题是，输入$x$为贷款申请，你是否可以预测输出$y$，$y$是他们有没有还贷能力？所以这系统能帮助银行判断是否批准贷款。所以开发集来自贷款申请，这些贷款申请来自中等收入邮政编码，zip code就是美国的邮政编码。但是在这上面训练了几个月之后，团队突然决定要在，低收入邮政编码数据上测试一下。当然了，这个分布数据里面中等收入和低收入邮政编码数据是很不一样的，而且他们花了大量时间针对前面那组数据优化分类器，导致系统在后面那组数据中效果很差。所以这个特定团队实际上浪费了3个月的时间，不得不退回去重新做很多工作。 这里实际发生的事情是，这个团队花了三个月瞄准一个目标，三个月之后经理突然问”你们试试瞄准那个目标如何？”，这新目标位置完全不同，所以这件事对于这个团队来说非常崩溃。 所以我建议你们在设立开发集和测试集时，要选择这样的开发集和测试集，能够反映你未来会得到的数据，认为很重要的数据，必须得到好结果的数据，特别是，这里的开发集和测试集可能来自同一个分布。所以不管你未来会得到什么样的数据，一旦你的算法效果不错，要尝试收集类似的数据，而且，不管那些数据是什么，都要随机分配到开发集和测试集上。因为这样，你才能将瞄准想要的目标，让你的团队高效迭代来逼近同一个目标，希望最好是同一个目标。 我们还没提到如何设立训练集，我们会在之后的视频里谈谈如何设立训练集，但这个视频的重点在于，设立开发集以及评估指标，真的就定义了你要瞄准的目标。我们希望通过在同一分布中设立开发集和测试集，你就可以瞄准你所希望的机器学习团队瞄准的目标。而设立训练集的方式则会影响你逼近那个目标有多快，但我们可以在另一个讲座里提到。我知道有一些机器学习团队，他们如果能遵循这个方针，就可以省下几个月的工作，所以我希望这些方针也能帮到你们。 接下来，实际上你的开发集和测试集的规模，如何选择它们的大小，在深度学习时代也在变化，我们会在下一个视频里提到这些内容。 1.6 开发集和测试集的大小（Size of dev and test sets）在上一个视频中你们知道了你的开发集和测试集为什么必须来自同一分布，但它们规模应该多大？在深度学习时代，设立开发集和测试集的方针也在变化，我们来看看一些最佳做法。 你可能听说过一条经验法则，在机器学习中，把你取得的全部数据用70/30比例分成训练集和测试集。或者如果你必须设立训练集、开发集和测试集，你会这么分60%训练集，20%开发集，20%测试集。在机器学习的早期，这样分是相当合理的，特别是以前的数据集大小要小得多。所以如果你总共有100个样本，这样70/30或者60/20/20分的经验法则是相当合理的。如果你有几千个样本或者有一万个样本，这些做法也还是合理的。 但在现代机器学习中，我们更习惯操作规模大得多的数据集，比如说你有1百万个训练样本，这样分可能更合理，98%作为训练集，1%开发集，1%测试集，我们用$D$和$T$缩写来表示开发集和测试集。因为如果你有1百万个样本，那么1%就是10,000个样本，这对于开发集和测试集来说可能已经够了。所以在现代深度学习时代，有时我们拥有大得多的数据集，所以使用小于20%的比例或者小于30%比例的数据作为开发集和测试集也是合理的。而且因为深度学习算法对数据的胃口很大，我们可以看到那些有海量数据集的问题，有更高比例的数据划分到训练集里，那么测试集呢？ 要记住，测试集的目的是完成系统开发之后，测试集可以帮你评估投产系统的性能。方针就是，令你的测试集足够大，能够以高置信度评估系统整体性能。所以除非你需要对最终投产系统有一个很精确的指标，一般来说测试集不需要上百万个例子。对于你的应用程序，也许你想，有10,000个例子就能给你足够的置信度来给出性能指标了，也许100,000个之类的可能就够了，这数目可能远远小于比如说整体数据集的30%，取决于你有多少数据。 对于某些应用，你也许不需要对系统性能有置信度很高的评估，也许你只需要训练集和开发集。我认为，不单独分出一个测试集也是可以的。事实上，有时在实践中有些人会只分成训练集和测试集，他们实际上在测试集上迭代，所以这里没有测试集，他们有的是训练集和开发集，但没有测试集。如果你真的在调试这个集，这个开发集或这个测试集，这最好称为开发集。 不过在机器学习的历史里，不是每个人都把术语定义分得很清的，有时人们说的开发集，其实应该看作测试集。但如果你只要有数据去训练，有数据去调试就够了。你打算不管测试集，直接部署最终系统，所以不用太担心它的实际表现，我觉得这也是很好的，就将它们称为训练集、开发集就好。然后说清楚你没有测试集，这是不是有点不正常？我绝对不建议在搭建系统时省略测试集，因为有个单独的测试集比较令我安心。因为你可以使用这组不带偏差的数据来测量系统的性能。但如果你的开发集非常大，这样你就不会对开发集过拟合得太厉害，这种情况，只有训练集和测试集也不是完全不合理的。不过我一般不建议这么做。 总结一下，在大数据时代旧的经验规则，这个70/30不再适用了。现在流行的是把大量数据分到训练集，然后少量数据分到开发集和测试集，特别是当你有一个非常大的数据集时。以前的经验法则其实是为了确保开发集足够大，能够达到它的目的，就是帮你评估不同的想法，然后选出$A$还是$B$更好。测试集的目的是评估你最终的成本偏差，你只需要设立足够大的测试集，可以用来这么评估就行了，可能只需要远远小于总体数据量的30%。 所以我希望本视频能给你们一点指导和建议，让你们知道如何在深度学习时代设立开发和测试集。接下来，有时候在研究机器学习的问题途中，你可能需要更改评估指标，或者改动你的开发集和测试集，我们会讲什么时候需要这样做。 1.7 什么时候该改变开发/测试集和指标？（When to change dev/test sets and metrics）你已经学过如何设置开发集和评估指标，就像是把目标定在某个位置，让你的团队瞄准。但有时候在项目进行途中，你可能意识到，目标的位置放错了。这种情况下，你应该移动你的目标。 我们来看一个例子，假设你在构建一个猫分类器，试图找到很多猫的照片，向你的爱猫人士用户展示，你决定使用的指标是分类错误率。所以算法$A$和$B$分别有3％错误率和5％错误率，所以算法$A$似乎做得更好。 但我们实际试一下这些算法，你观察一下这些算法，算法$A$由于某些原因，把很多色情图像分类成猫了。如果你部署算法$A$，那么用户就会看到更多猫图，因为它识别猫的错误率只有3%，但它同时也会给用户推送一些色情图像，这是你的公司完全不能接受的，你的用户也完全不能接受。相比之下，算法$B$有5％的错误率，这样分类器就得到较少的图像，但它不会推送色情图像。所以从你们公司的角度来看，以及从用户接受的角度来看，算法$B$实际上是一个更好的算法，因为它不让任何色情图像通过。 那么在这个例子中，发生的事情就是，算法A在评估指标上做得更好，它的错误率达到3%，但实际上是个更糟糕的算法。在这种情况下，评估指标加上开发集它们都倾向于选择算法$A$，因为它们会说，看算法A的错误率较低，这是你们自己定下来的指标评估出来的。但你和你的用户更倾向于使用算法$B$，因为它不会将色情图像分类为猫。所以当这种情况发生时，当你的评估指标无法正确衡量算法之间的优劣排序时，在这种情况下，原来的指标错误地预测算法A是更好的算法这就发出了信号，你应该改变评估指标了，或者要改变开发集或测试集。在这种情况下，你用的分类错误率指标可以写成这样： $Error = \frac{1}{m_{ {dev} }}\sum_{i = 1}^{m_{ {dev} }}{I\{ y_{ {pred} }^{(i)} \neq y^{(i)}\} }$ $m_{ {dev} }$是你的开发集例子数，用$y_{ {pred} }^{(i)}$表示预测值，其值为0或1，$I$这符号表示一个函数，统计出里面这个表达式为真的样本数，所以这个公式就统计了分类错误的样本。这个评估指标的问题在于，它对色情图片和非色情图片一视同仁，但你其实真的希望你的分类器不会错误标记色情图像。比如说把一张色情图片分类为猫，然后推送给不知情的用户，他们看到色情图片会非常不满。 其中一个修改评估指标的方法是，这里（$\frac{1}{m_{ {dev} }}$与$\sum_{i =1}^{m_{ {dev} }}{I\{ y_{ {pred} }^{(i)} \neq y^{(i)}\} }$之间）加个权重项，即： $Error = \frac{1}{m_{ {dev} }}\sum_{i = 1}^{m_{ {dev} }}{w^{(i)}I\{ y_{ {pred} }^{(i)} \neq y^{(i)}\} }$ 我们将这个称为$w^{\left( i \right)}$，其中如果图片$x^{(i)}$不是色情图片，则$w^{\left( i \right)} = 1$。如果$x^{(i)}$是色情图片，$w^{(i)}$可能就是10甚至100，这样你赋予了色情图片更大的权重，让算法将色情图分类为猫图时，错误率这个项快速变大。这个例子里，你把色情图片分类成猫这一错误的惩罚权重加大10倍。 如果你希望得到归一化常数，在技术上，就是$w^{(i)}$对所有$i$求和，这样错误率仍然在0和1之间，即： $Error = \frac{1}{\sum_{}^{}w^{(i)} }\sum_{i = 1}^{m_{ {dev} }}{w^{(i)}I\{ y_{ {pred} }^{(i)} \neq y^{(i)}\} }$ 加权的细节并不重要，实际上要使用这种加权，你必须自己过一遍开发集和测试集，在开发集和测试集里，自己把色情图片标记出来，这样你才能使用这个加权函数。 但粗略的结论是，如果你的评估指标无法正确评估好算法的排名，那么就需要花时间定义一个新的评估指标。这是定义评估指标的其中一种可能方式（上述加权法）。评估指标的意义在于，准确告诉你已知两个分类器，哪一个更适合你的应用。就这个视频的内容而言，我们不需要太注重新错误率指标是怎么定义的，关键在于，如果你对旧的错误率指标不满意，那就不要一直沿用你不满意的错误率指标，而应该尝试定义一个新的指标，能够更加符合你的偏好，定义出实际更适合的算法。 你可能注意到了，到目前为止我们只讨论了如何定义一个指标去评估分类器，也就是说，我们定义了一个评估指标帮助我们更好的把分类器排序，能够区分出它们在识别色情图片的不同水平，这实际上是一个正交化的例子。 我想你处理机器学习问题时，应该把它切分成独立的步骤。一步是弄清楚如何定义一个指标来衡量你想做的事情的表现，然后我们可以分开考虑如何改善系统在这个指标上的表现。你们要把机器学习任务看成两个独立的步骤，用目标这个比喻，第一步就是设定目标。所以要定义你要瞄准的目标，这是完全独立的一步，这是你可以调节的一个旋钮。如何设立目标是一个完全独立的问题，把它看成是一个单独的旋钮，可以调试算法表现的旋钮，如何精确瞄准，如何命中目标，定义指标是第一步。 然后第二步要做别的事情，在逼近目标的时候，也许你的学习算法针对某个长这样的成本函数优化，$J=\frac{1}{m}\sum\limits_{i=1}^{m}{L({ {\hat y}^{(i)} },{ {y}^{(i)} })}$，你要最小化训练集上的损失。你可以做的其中一件事是，修改这个，为了引入这些权重，也许最后需要修改这个归一化常数，即： $J=\frac{1}{\sum{ {{w}^{(i)} }} }\sum\limits_{i=1}^{m}{ {{w}^{(i)} }L({ {\hat y}^{(i)} },{ {y}^{(i)} })}$ 再次，如何定义$J$并不重要，关键在于正交化的思路，把设立目标定为第一步，然后瞄准和射击目标是独立的第二步。换种说法，我鼓励你们将定义指标看成一步，然后在定义了指标之后，你才能想如何优化系统来提高这个指标评分。比如改变你神经网络要优化的成本函数$J$。 在继续之前，我们再讲一个例子。假设你的两个猫分类器$A$和$B$，分别有用开发集评估得到3%的错误率和5%的错误率。或者甚至用在网上下载的图片构成的测试集上，这些是高质量，取景框很专业的图像。但也许你在部署算法产品时，你发现算法$B$看起来表现更好，即使它在开发集上表现不错，你发现你一直在用从网上下载的高质量图片训练，但当你部署到手机应用时，算法作用到用户上传的图片时，那些图片取景不专业，没有把猫完整拍下来，或者猫的表情很古怪，也许图像很模糊，当你实际测试算法时，你发现算法$B$表现其实更好。 这是另一个指标和开发集测试集出问题的例子，问题在于，你做评估用的是很漂亮的高分辨率的开发集和测试集，图片取景很专业。但你的用户真正关心的是，他们上传的图片能不能被正确识别。那些图片可能是没那么专业的照片，有点模糊，取景很业余。 所以方针是，如果你在指标上表现很好，在当前开发集或者开发集和测试集分布中表现很好，但你的实际应用程序，你真正关注的地方表现不好，那么就需要修改指标或者你的开发测试集。换句话说，如果你发现你的开发测试集都是这些高质量图像，但在开发测试集上做的评估无法预测你的应用实际的表现。因为你的应用处理的是低质量图像，那么就应该改变你的开发测试集，让你的数据更能反映你实际需要处理好的数据。 但总体方针就是，如果你当前的指标和当前用来评估的数据和你真正关心必须做好的事情关系不大，那就应该更改你的指标或者你的开发测试集，让它们能更够好地反映你的算法需要处理好的数据。 有一个评估指标和开发集让你可以更快做出决策，判断算法$A$还是算法$B$更优，这真的可以加速你和你的团队迭代的速度。所以我的建议是，即使你无法定义出一个很完美的评估指标和开发集，你直接快速设立出来，然后使用它们来驱动你们团队的迭代速度。如果在这之后，你发现选的不好，你有更好的想法，那么完全可以马上改。对于大多数团队，我建议最好不要在没有评估指标和开发集时跑太久，因为那样可能会减慢你的团队迭代和改善算法的速度。本视频讲的是什么时候需要改变你的评估指标和开发测试集，我希望这些方针能让你的整个团队设立一个明确的目标，一个你们可以高效迭代，改善性能的目标。 1.8 为什么是人的表现？（Why human-level performance?）在过去的几年里，更多的机器学习团队一直在讨论如何比较机器学习系统和人类的表现，为什么呢？ 我认为有两个主要原因，首先是因为深度学习系统的进步，机器学习算法突然变得更好了。在许多机器学习的应用领域已经开始见到算法已经可以威胁到人类的表现了。其次，事实证明，当你试图让机器做人类能做的事情时，可以精心设计机器学习系统的工作流程，让工作流程效率更高，所以在这些场合，比较人类和机器是很自然的，或者你要让机器模仿人类的行为。 我们来看几个这样的例子，我看到很多机器学习任务中，当你在一个问题上付出了很多时间之后，所以$x$轴是时间，这可能是很多个月甚至是很多年。在这些时间里，一些团队或一些研究小组正在研究一个问题，当你开始往人类水平努力时，进展是很快的。但是过了一段时间，当这个算法表现比人类更好时，那么进展和精确度的提升就变得更慢了。也许它还会越来越好，但是在超越人类水平之后，它还可以变得更好，但性能增速，准确度上升的速度这个斜率，会变得越来越平缓，我们都希望能达到理论最佳性能水平。随着时间的推移，当您继续训练算法时，可能模型越来越大，数据越来越多，但是性能无法超过某个理论上限，这就是所谓的贝叶斯最优错误率（Bayes optimal error）。所以贝叶斯最优错误率一般认为是理论上可能达到的最优错误率，就是说没有任何办法设计出一个$x$到$y$的函数，让它能够超过一定的准确度。 例如，对于语音识别来说，如果$x$是音频片段，有些音频就是这么嘈杂，基本不可能知道说的是什么，所以完美的准确率可能不是100%。或者对于猫图识别来说，也许一些图像非常模糊，不管是人类还是机器，都无法判断该图片中是否有猫。所以，完美的准确度可能不是100%。 而贝叶斯最优错误率有时写作Bayesian，即省略optimal，就是从$x$到$y$映射的理论最优函数，永远不会被超越。所以你们应该不会感到意外，这紫色线，无论你在一个问题上工作多少年，你永远不会超越贝叶斯错误率，贝叶斯最佳错误率。 事实证明，机器学习的进展往往相当快，直到你超越人类的表现之前一直很快，当你超越人类的表现时，有时进展会变慢。我认为有两个原因，为什么当你超越人类的表现时，进展会慢下来。一个原因是人类水平在很多任务中离贝叶斯最优错误率已经不远了，人们非常擅长看图像，分辨里面有没有猫或者听写音频。所以，当你超越人类的表现之后也许没有太多的空间继续改善了。但第二个原因是，只要你的表现比人类的表现更差，那么实际上可以使用某些工具来提高性能。一旦你超越了人类的表现，这些工具就没那么好用了。 我的意思是这样，对于人类相当擅长的任务，包括看图识别事物，听写音频，或阅读语言，人类一般很擅长处理这些自然数据。对于人类擅长的任务，只要你的机器学习算法比人类差，你就可以从让人帮你标记数据，你可以让人帮忙或者花钱请人帮你标记例子，这样你就有更多的数据可以喂给学习算法。下周我们会讨论，人工错误率分析，但只要人类的表现比任何其他算法都要好，你就可以让人类看看你算法处理的例子，知道错误出在哪里，并尝试了解为什么人能做对，算法做错。下周我们会看到，这样做有助于提高算法的性能。你也可以更好地分析偏差和方差，我们稍后会谈一谈。但是只要你的算法仍然比人类糟糕，你就有这些重要策略可以改善算法。而一旦你的算法做得比人类好，这三种策略就很难利用了。所以这可能是另一个和人类表现比较的好处，特别是在人类做得很好的任务上。 为什么机器学习算法往往很擅长模仿人类能做的事情，然后赶上甚至超越人类的表现。特别是，即使你知道偏差是多少，方差是多少。知道人类在特定任务上能做多好可以帮助你更好地了解你应该重点尝试减少偏差，还是减少方差，我想在下一个视频中给你一个例子。 1.9 可避免偏差（Avoidable bias）我们讨论过，你希望你的学习算法能在训练集上表现良好，但有时你实际上并不想做得太好。你得知道人类水平的表现是怎样的，可以确切告诉你算法在训练集上的表现到底应该有多好，或者有多不好，让我告诉你是什么意思吧。 我们经常使用猫分类器来做例子，比如人类具有近乎完美的准确度，所以人类水平的错误是1%。在这种情况下，如果您的学习算法达到8%的训练错误率和10%的开发错误率，那么你也许想在训练集上得到更好的结果。所以事实上，你的算法在训练集上的表现和人类水平的表现有很大差距的话，说明你的算法对训练集的拟合并不好。所以从减少偏差和方差的工具这个角度看，在这种情况下，我会把重点放在减少偏差上。你需要做的是，比如说训练更大的神经网络，或者跑久一点梯度下降，就试试能不能在训练集上做得更好。 但现在我们看看同样的训练错误率和开发错误率，假设人类的表现不是1%，我们就把它抄写过来。但你知道，在不同的应用或者说用在不同的数据集上，假设人类水平错误实际上是7.5%，也许你的数据集中的图像非常模糊，即使人类都无法判断这张照片中有没有猫。这个例子可能稍微更复杂一些，因为人类其实很擅长看照片，分辨出照片里有没有猫。但就为了举这个例子，比如说你的数据集中的图像非常模糊，分辨率很低，即使人类错误率也达到7.5%。在这种情况下，即使你的训练错误率和开发错误率和其他例子里一样，你就知道，也许你的系统在训练集上的表现还好，它只是比人类的表现差一点点。在第二个例子中，你可能希望专注减少这个分量，减少学习算法的方差，也许你可以试试正则化，让你的开发错误率更接近你的训练错误率。 所以在之前的课程关于偏差和方差的讨论中，我们主要假设有一些任务的贝叶斯错误率几乎为0。所以要解释这里发生的事情，看看这个猫分类器，用人类水平的错误率估计或代替贝叶斯错误率或贝叶斯最优错误率，对于计算机视觉任务而言，这样替代相当合理，因为人类实际上是非常擅长计算机视觉任务的，所以人类能做到的水平和贝叶斯错误率相差不远。根据定义，人类水平错误率比贝叶斯错误率高一点，因为贝叶斯错误率是理论上限，但人类水平错误率离贝叶斯错误率不会太远。所以这里比较意外的是取决于人类水平错误率有多少，或者这真的就很接近贝叶斯错误率，所以我们假设它就是，但取决于我们认为什么样的水平是可以实现的。 在这两种情况下，具有同样的训练错误率和开发错误率，我们决定专注于减少偏差的策略或者减少方差的策略。那么左边的例子发生了什么？8%的训练错误率真的很高，你认为你可以把它降到1%，那么减少偏差的手段可能有效。而在右边的例子中，如果你认为贝叶斯错误率是7.5%，这里我们使用人类水平错误率来替代贝叶斯错误率，但是你认为贝叶斯错误率接近7.5%，你就知道没有太多改善的空间了，不能继续减少你的训练错误率了，你也不会希望它比7.5%好得多，因为这种目标只能通过可能需要提供更进一步的训练。而这边，就还（训练误差和开发误差之间）有更多的改进空间，可以将这个2%的差距缩小一点，使用减少方差的手段应该可行，比如正则化，或者收集更多的训练数据。 所以要给这些概念命名一下，这不是广泛使用的术语，但我觉得这么说思考起来比较流畅。就是把这个差值，贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差，你可能希望一直提高训练集表现，直到你接近贝叶斯错误率，但实际上你也不希望做到比贝叶斯错误率更好，这理论上是不可能超过贝叶斯错误率的，除非过拟合。而这个训练错误率和开发错误率之前的差值，就大概说明你的算法在方差问题上还有多少改善空间。 可避免偏差这个词说明了有一些别的偏差，或者错误率有个无法超越的最低水平，那就是说如果贝叶斯错误率是7.5%。你实际上并不想得到低于该级别的错误率，所以你不会说你的训练错误率是8%，然后8%就衡量了例子中的偏差大小。你应该说，可避免偏差可能在0.5%左右，或者0.5%是可避免偏差的指标。而这个2%是方差的指标，所以要减少这个2%比减少这个0.5%空间要大得多。而在左边的例子中，这7%衡量了可避免偏差大小，而2%衡量了方差大小。所以在左边这个例子里，专注减少可避免偏差可能潜力更大。 所以在这个例子中，当你理解人类水平错误率，理解你对贝叶斯错误率的估计，你就可以在不同的场景中专注于不同的策略，使用避免偏差策略还是避免方差策略。在训练时如何考虑人类水平表现来决定工作着力点，具体怎么做还有更多微妙的细节，所以在下一个视频中，我们会深入了解人类水平表现的真正意义。 1.10 理解人的表现（Understanding human-level performance）人类水平表现这个词在论文里经常随意使用，但我现在告诉你这个词更准确的定义，特别是使用人类水平表现这个词的定义，可以帮助你们推动机器学习项目的进展。还记得上个视频中，我们用过这个词“人类水平错误率”用来估计贝叶斯误差，那就是理论最低的错误率，任何函数不管是现在还是将来，能够到达的最低值。我们先记住这点，然后看看医学图像分类例子。 假设你要观察这样的放射科图像，然后作出分类诊断，假设一个普通的人类，未经训练的人类，在此任务上达到3%的错误率。普通的医生，也许是普通的放射科医生，能达到1%的错误率。经验丰富的医生做得更好，错误率为0.7%。还有一队经验丰富的医生，就是说如果你有一个经验丰富的医生团队，让他们都看看这个图像，然后讨论并辩论，他们达成共识的意见达到0.5%的错误率。所以我想问你的问题是，你应该如何界定人类水平错误率？人类水平错误率3%,1%, 0.7%还是0.5%？ 你也可以暂停视频思考一下，要回答这个问题，我想请你记住，思考人类水平错误率最有用的方式之一是，把它作为贝叶斯错误率的替代或估计。如果你愿意，也可以暂停视频，思考一下这个问题。 但这里我就直接给出人类水平错误率的定义，就是如果你想要替代或估计贝叶斯错误率，那么一队经验丰富的医生讨论和辩论之后，可以达到0.5%的错误率。我们知道贝叶斯错误率小于等于0.5%，因为有些系统，这些医生团队可以达到0.5%的错误率。所以根据定义，最优错误率必须在0.5%以下。我们不知道多少更好，也许有一个更大的团队，更有经验的医生能做得更好，所以也许比0.5%好一点。但是我们知道最优错误率不能高于0.5%，那么在这个背景下，我就可以用0.5%估计贝叶斯错误率。所以我将人类水平定义为0.5%，至少如果你希望使用人类水平错误来分析偏差和方差的时候，就像上个视频那样。 现在，为了发表研究论文或者部署系统，也许人类水平错误率的定义可以不一样，你可以使用1%，只要你超越了一个普通医生的表现，如果能达到这种水平，那系统已经达到实用了。也许超过一名放射科医生，一名医生的表现，意味着系统在一些情况下可以有部署价值了。 本视频的要点是，在定义人类水平错误率时，要弄清楚你的目标所在，如果要表明你可以超越单个人类，那么就有理由在某些场合部署你的系统，也许这个定义是合适的。但是如果您的目标是替代贝叶斯错误率，那么这个定义（经验丰富的医生团队——0.5%）才合适。 要了解为什么这个很重要，我们来看一个错误率分析的例子。比方说，在医学图像诊断例子中，你的训练错误率是5%，你的开发错误率是6%。而在上一张幻灯片的例子中，我们的人类水平表现，我将它看成是贝叶斯错误率的替代品，取决于你是否将它定义成普通单个医生的表现，还是有经验的医生或医生团队的表现，你可能会用1%或0.7%或0.5%。同时也回想一下，前面视频中的定义，贝叶斯错误率或者说贝叶斯错误率的估计和训练错误率直接的差值就衡量了所谓的可避免偏差，这（训练误差与开发误差之间的差值）可以衡量或者估计你的学习算法的方差问题有多严重。 所以在这个第一个例子中，无论你做出哪些选择，可避免偏差大概是4%，这个值我想介于……，如果你取1%就是4%，如果你取0.5%就是4.5%，而这个差距（训练误差与开发误差之间的差值）是1%。所以在这个例子中，我得说，不管你怎么定义人类水平错误率，使用单个普通医生的错误率定义，还是单个经验丰富医生的错误率定义或经验丰富的医生团队的错误率定义，这是4%还是4.5%，这明显比都比方差问题更大。所以在这种情况下，你应该专注于减少偏差的技术，例如培训更大的网络。 现在来看看第二个例子，比如说你的训练错误率是1%，开发错误率是5%，这其实也不怎么重要，这种问题更像学术界讨论的，人类水平表现是1%或0.7%还是0.5%。因为不管你使用哪一个定义，你测量可避免偏差的方法是，如果用那个值，就是0%到0.5%之前，对吧？那就是人类水平和训练错误率之前的差距，而这个差距是4%，所以这个4%差距比任何一种定义的可避免偏差都大。所以他们就建议，你应该主要使用减少方差的工具，比如正则化或者去获取更大的训练集。 什么时候真正有效呢? 就是比如你的训练错误率是0.7%，所以你现在已经做得很好了，你的开发错误率是0.8%。在这种情况下，你用0.5%来估计贝叶斯错误率关系就很大。因为在这种情况下，你测量到的可避免偏差是0.2%，这是你测量到的方差问题0.1%的两倍，这表明也许偏差和方差都存在问题。但是，可避免偏差问题更严重。在这个例子中，我们在上一张幻灯片中讨论的是0.5%，就是对贝叶斯错误率的最佳估计，因为一群人类医生可以实现这一目标。如果你用0.7代替贝叶斯错误率，你测得的可避免偏差基本上是0%，那你就可能忽略可避免偏差了。实际上你应该试试能不能在训练集上做得更好。 我希望讲这个能让你们有点概念，知道为什么机器学习问题上取得进展会越来越难，当你接近人类水平时进展会越来越难。 在这个例子中，一旦你接近0.7%错误率，除非你非常小心估计贝叶斯错误率，你可能无法知道离贝叶斯错误率有多远，所以你应该尽量减少可避免偏差。事实上，如果你只知道单个普通医生能达到1%错误率，这可能很难知道是不是应该继续去拟合训练集，这种问题只会出现在你的算法已经做得很好的时候，只有你已经做到0.7%,0.8%, 接近人类水平时会出现。 而在左边的两个例子中，当你远离人类水平时，将优化目标放在偏差或方差上可能更容易一点。这就说明了，为什么当你们接近人类水平时，更难分辨出问题是偏差还是方差。所以机器学习项目的进展在你已经做得很好的时候，很难更进一步。 总结一下我们讲到的，如果你想理解偏差和方差，那么在人类可以做得很好的任务中，你可以估计人类水平的错误率，你可以使用人类水平错误率来估计贝叶斯错误率。所以你到贝叶斯错误率估计值的差距，告诉你可避免偏差问题有多大，可避免偏差问题有多严重，而训练错误率和开发错误率之间的差值告诉你方差上的问题有多大，你的算法是否能够从训练集泛化推广到开发集。 今天讲的和之前课程中见到的重大区别是，以前你们比较的是训练错误率和0%，直接用这个值估计偏差。相比之下，在这个视频中，我们有一个更微妙的分析，其中并没有假设你应该得到0%错误率，因为有时贝叶斯错误率是非零的，有时基本不可能做到比某个错误率阈值更低。所以在之前的课程中，我们测量的是训练错误率，然后观察的是训练错误率比0%高多少，就用这个差值来估计偏差有多大。而事实证明，对于贝叶斯错误率几乎是0%的问题这样就行了，例如识别猫，人类表现接近完美，所以贝叶斯错误率也接近完美。所以当贝叶斯错误率几乎为零时，可以那么做。但数据噪点很多时，比如背景声音很嘈杂的语言识别，有时几乎不可能听清楚说的是什么，并正确记录下来。对于这样的问题，更好的估计贝叶斯错误率很有必要，可以帮助你更好地估计可避免偏差和方差，这样你就能更好的做出决策，选择减少偏差的策略，还是减少方差的策略。 回顾一下，对人类水平有大概的估计可以让你做出对贝叶斯错误率的估计，这样可以让你更快地作出决定是否应该专注于减少算法的偏差，或者减少算法的方差。这个决策技巧通常很有效，直到你的系统性能开始超越人类，那么你对贝叶斯错误率的估计就不再准确了，但这些技巧还是可以帮你做出明确的决定。 现在，深度学习的令人兴奋的发展之一就是对于越来越多的任务，我们的系统实际上可以超越人类了。在下一个视频中，让我们继续谈谈超越人类水平的过程。 1.11 超过人的表现（Surpassing human- level performance）很多团队会因为机器在特定的识别分类任务中超越了人类水平而激动不已，我们谈谈这些情况，看看你们自己能不能达到。 我们讨论过机器学习进展，会在接近或者超越人类水平的时候变得越来越慢。我们举例谈谈为什么会这样。 假设你有一个问题，一组人类专家充分讨论辩论之后，达到0.5%的错误率，单个人类专家错误率是1%，然后你训练出来的算法有0.6%的训练错误率，0.8%的开发错误率。所以在这种情况下，可避免偏差是多少？这个比较容易回答，0.5%是你对贝叶斯错误率的估计，所以可避免偏差就是0.1%。你不会用这个1%的数字作为参考，你用的是这个差值，所以也许你对可避免偏差的估计是至少0.1%，然后方差是0.2%。和减少可避免偏差比较起来，减少方差可能空间更大。 但现在我们来看一个比较难的例子，一个人类专家团和单个人类专家的表现和以前一样，但你的算法可以得到0.3%训练错误率，还有0.4%开发错误率。现在，可避免偏差是什么呢？现在其实很难回答，事实上你的训练错误率是0.3%，这是否意味着你过拟合了0.2%，或者说贝叶斯错误率其实是0.1%呢？或者也许贝叶斯错误率是0.2%？或者贝叶斯错误率是0.3%呢？你真的不知道。但是基于本例中给出的信息，你实际上没有足够的信息来判断优化你的算法时应该专注减少偏差还是减少方差，这样你取得进展的效率就会降低。还有比如说，如果你的错误率已经比一群充分讨论辩论后的人类专家更低，那么依靠人类直觉去判断你的算法还能往什么方向优化就很难了。所以在这个例子中，一旦你超过这个0.5%的门槛，要进一步优化你的机器学习问题就没有明确的选项和前进的方向了。这并不意味着你不能取得进展，你仍然可以取得重大进展。但现有的一些工具帮助你指明方向的工具就没那么好用了。 现在，机器学习有很多问题已经可以大大超越人类水平了。例如，我想网络广告，估计某个用户点击广告的可能性，可能学习算法做到的水平已经超越任何人类了。还有提出产品建议，向你推荐电影或书籍之类的任务。我想今天的网站做到的水平已经超越你最亲近的朋友了。还有物流预测，从$A$到$B$开车需要多久，或者预测快递车从$A$开到$B$需要多少时间。或者预测某人会不会偿还贷款，这样你就能判断是否批准这人的贷款。我想这些问题都是今天的机器学习远远超过了单个人类的表现。 请注意这四个例子，所有这四个例子都是从结构化数据中学习得来的，这里你可能有个数据库记录用户点击的历史，你的购物历史数据库，或者从A到B需要多长时间的数据库，以前的贷款申请及结果的数据库，这些并不是自然感知问题，这些不是计算机视觉问题，或语音识别，或自然语言处理任务。人类在自然感知任务中往往表现非常好，所以有可能对计算机来说在自然感知任务的表现要超越人类要更难一些。 最后，这些问题中，机器学习团队都可以访问大量数据，所以比如说，那四个应用中，最好的系统看到的数据量可能比任何人类能看到的都多，所以这样就相对容易得到超越人类水平的系统。现在计算机可以检索那么多数据，它可以比人类更敏锐地识别出数据中的统计规律。 除了这些问题，今天已经有语音识别系统超越人类水平了，还有一些计算机视觉任务，一些图像识别任务，计算机已经超越了人类水平。但是由于人类对这种自然感知任务非常擅长，我想计算机达到那种水平要难得多。还有一些医疗方面的任务，比如阅读ECG或诊断皮肤癌，或者某些特定领域的放射科读图任务，这些任务计算机做得非常好了，也许超越了单个人类的水平。 在深度学习的最新进展中，其中一个振奋人心的方面是，即使在自然感知任务中，在某些情况下，计算机已经可以超越人类的水平了。不过现在肯定更加困难，因为人类一般很擅长这种自然感知任务。 所以要达到超越人类的表现往往不容易，但如果有足够多的数据，已经有很多深度学习系统，在单一监督学习问题上已经超越了人类的水平，所以这对你在开发的应用是有意义的。我希望有一天你也能够搭建出超越人类水平的深度学习系统。 1.12 改善你的模型的表现（Improving your model performance）你们学过正交化，如何设立开发集和测试集，用人类水平错误率来估计贝叶斯错误率以及如何估计可避免偏差和方差。我们现在把它们全部组合起来写成一套指导方针，如何提高学习算法性能的指导方针。 所以我想要让一个监督学习算法达到实用，基本上希望或者假设你可以完成两件事情。首先，你的算法对训练集的拟合很好，这可以看成是你能做到可避免偏差很低。还有第二件事你可以做好的是，在训练集中做得很好，然后推广到开发集和测试集也很好，这就是说方差不是太大。 在正交化的精神下，你可以看到这里有第二组旋钮，可以修正可避免偏差问题，比如训练更大的网络或者训练更久。还有一套独立的技巧可以用来处理方差问题，比如正则化或者收集更多训练数据。 总结一下前几段视频我们见到的步骤，如果你想提升机器学习系统的性能，我建议你们看看训练错误率和贝叶斯错误率估计值之间的距离，让你知道可避免偏差有多大。换句话说，就是你觉得还能做多好，你对训练集的优化还有多少空间。然后看看你的开发错误率和训练错误率之间的距离，就知道你的方差问题有多大。换句话说，你应该做多少努力让你的算法表现能够从训练集推广到开发集，算法是没有在开发集上训练的。 如果你想用尽一切办法减少可避免偏差，我建议试试这样的策略：比如使用规模更大的模型，这样算法在训练集上的表现会更好，或者训练更久。使用更好的优化算法，比如说加入momentum或者RMSprop，或者使用更好的算法，比如Adam。你还可以试试寻找更好的新神经网络架构，或者说更好的超参数。这些手段包罗万有，你可以改变激活函数，改变层数或者隐藏单位数，虽然你这么做可能会让模型规模变大。或者试用其他模型，其他架构，如循环神经网络和卷积神经网络。在之后的课程里我们会详细介绍的，新的神经网络架构能否更好地拟合你的训练集，有时也很难预先判断，但有时换架构可能会得到好得多的结果。 另外当你发现方差是个问题时，你可以试用很多技巧，包括以下这些：你可以收集更多数据，因为收集更多数据去训练可以帮你更好地推广到系统看不到的开发集数据。你可以尝试正则化，包括$L2$正则化，dropout正则化或者我们在之前课程中提到的数据增强。同时你也可以试用不同的神经网络架构，超参数搜索，看看能不能帮助你，找到一个更适合你的问题的神经网络架构。 我想这些偏差、可避免偏差和方差的概念是容易上手，难以精通的。如果你能系统全面地应用本周课程里的概念，你实际上会比很多现有的机器学习团队更有效率、更系统、更有策略地系统提高机器学习系统的性能。 机器学习策略（2）(ML Strategy (2))2.1 进行误差分析（Carrying out error analysis）你好，欢迎回来，如果你希望让学习算法能够胜任人类能做的任务，但你的学习算法还没有达到人类的表现，那么人工检查一下你的算法犯的错误也许可以让你了解接下来应该做什么。这个过程称为错误分析，我们从一个例子开始讲吧。 假设你正在调试猫分类器，然后你取得了90%准确率，相当于10%错误，，在你的开发集上做到这样，这离你希望的目标还有很远。也许你的队员看了一下算法分类出错的例子，注意到算法将一些狗分类为猫，你看看这两只狗，它们看起来是有点像猫，至少乍一看是。所以也许你的队友给你一个建议，如何针对狗的图片优化算法。试想一下，你可以针对狗，收集更多的狗图，或者设计一些只处理狗的算法功能之类的，为了让你的猫分类器在狗图上做的更好，让算法不再将狗分类成猫。所以问题在于，你是不是应该去开始做一个项目专门处理狗？这项目可能需要花费几个月的时间才能让算法在狗图片上犯更少的错误，这样做值得吗？或者与其花几个月做这个项目，有可能最后发现这样一点用都没有。这里有个错误分析流程，可以让你很快知道这个方向是否值得努力。 这是我建议你做的，首先，收集一下，比如说100个错误标记的开发集样本，然后手动检查，一次只看一个，看看你的开发集里有多少错误标记的样本是狗。现在，假设事实上，你的100个错误标记样本中只有5%是狗，就是说在100个错误标记的开发集样本中，有5个是狗。这意味着100个样本，在典型的100个出错样本中，即使你完全解决了狗的问题，你也只能修正这100个错误中的5个。或者换句话说，如果只有5%的错误是狗图片，那么如果你在狗的问题上花了很多时间，那么你最多只能希望你的错误率从10%下降到9.5%，对吧？错误率相对下降了5%（总体下降了0.5%，100的错误样本，错误率为10%，则样本为1000），那就是10%下降到9.5%。你就可以确定这样花时间不好，或者也许应该花时间，但至少这个分析给出了一个上限。如果你继续处理狗的问题，能够改善算法性能的上限，对吧？在机器学习中，有时我们称之为性能上限，就意味着，最好能到哪里，完全解决狗的问题可以对你有多少帮助。 但现在，假设发生了另一件事，假设我们观察一下这100个错误标记的开发集样本，你发现实际有50张图都是狗，所以有50%都是狗的照片，现在花时间去解决狗的问题可能效果就很好。这种情况下，如果你真的解决了狗的问题，那么你的错误率可能就从10%下降到5%了。然后你可能觉得让错误率减半的方向值得一试，可以集中精力减少错误标记的狗图的问题。 我知道在机器学习中，有时候我们很鄙视手工操作，或者使用了太多人为数值。但如果你要搭建应用系统，那这个简单的人工统计步骤，错误分析，可以节省大量时间，可以迅速决定什么是最重要的，或者最有希望的方向。实际上，如果你观察100个错误标记的开发集样本，也许只需要5到10分钟的时间，亲自看看这100个样本，并亲自统计一下有多少是狗。根据结果，看看有没有占到5%、50%或者其他东西。这个在5到10分钟之内就能给你估计这个方向有多少价值，并且可以帮助你做出更好的决定，是不是把未来几个月的时间投入到解决错误标记的狗图这个问题。 在本幻灯片中，我们要描述一下如何使用错误分析来评估某个想法，这个样本里狗的问题是否值得解决。有时你在做错误分析时，也可以同时并行评估几个想法，比如，你有几个改善猫检测器的想法，也许你可以改善针对狗图的性能，或者有时候要注意，那些猫科动物，如狮子，豹，猎豹等等，它们经常被分类成小猫或者家猫，所以你也许可以想办法解决这个错误。或者也许你发现有些图像是模糊的，如果你能设计出一些系统，能够更好地处理模糊图像。也许你有些想法，知道大概怎么处理这些问题，要进行错误分析来评估这三个想法。 我会做的是建立这样一个表格，我通常用电子表格来做，但普通文本文件也可以。在最左边，人工过一遍你想分析的图像集，所以图像可能是从1到100，如果你观察100张图的话。电子表格的一列就对应你要评估的想法，所以狗的问题，猫科动物的问题，模糊图像的问题，我通常也在电子表格中留下空位来写评论。所以记住，在错误分析过程中，你就看看算法识别错误的开发集样本，如果你发现第一张识别错误的图片是狗图，那么我就在那里打个勾，为了帮我自己记住这些图片，有时我会在评论里注释，也许这是一张比特犬的图。如果第二张照片很模糊，也记一下。如果第三张是在下雨天动物园里的狮子，被识别成猫了，这是大型猫科动物，还有图片模糊，在评论部分写动物园下雨天，是雨天让图像模糊的之类的。最后，这组图像过了一遍之后，我可以统计这些算法(错误)的百分比，或者这里每个错误类型的百分比，有多少是狗，大猫或模糊这些错误类型。所以也许你检查的图像中8%是狗，可能43%属于大猫，61%属于模糊。这意味着扫过每一列，并统计那一列有多少百分比图像打了勾。 在这个步骤做到一半时，有时你可能会发现其他错误类型，比如说你可能发现有Instagram滤镜，那些花哨的图像滤镜，干扰了你的分类器。在这种情况下，实际上可以在错误分析途中，增加这样一列，比如多色滤镜Instagram滤镜和Snapchat滤镜，然后再过一遍，也统计一下那些问题，并确定这个新的错误类型占了多少百分比，这个分析步骤的结果可以给出一个估计，是否值得去处理每个不同的错误类型。 例如，在这个样本中，有很多错误来自模糊图片，也有很多错误类型是大猫图片。所以这个分析的结果不是说你一定要处理模糊图片，这个分析没有给你一个严格的数学公式，告诉你应该做什么，但它能让你对应该选择那些手段有个概念。它也告诉你，比如说不管你对狗图片或者Instagram图片处理得有多好，在这些例子中，你最多只能取得8%或者12%的性能提升。而在大猫图片这一类型，你可以做得更好。或者模糊图像，这些类型有改进的潜力。这些类型里，性能提高的上限空间要大得多。所以取决于你有多少改善性能的想法，比如改善大猫图片或者模糊图片的表现。也许你可以选择其中两个，或者你的团队成员足够多，也许你把团队可以分成两个团队，其中一个想办法改善大猫的识别，另一个团队想办法改善模糊图片的识别。但这个快速统计的步骤，你可以经常做，最多需要几小时，就可以真正帮你选出高优先级任务，并了解每种手段对性能有多大提升空间。 所以总结一下，进行错误分析，你应该找一组错误样本，可能在你的开发集里或者测试集里，观察错误标记的样本，看看假阳性（false positives）和假阴性（false negatives），统计属于不同错误类型的错误数量。在这个过程中，你可能会得到启发，归纳出新的错误类型，就像我们看到的那样。如果你过了一遍错误样本，然后说，天，有这么多Instagram滤镜或Snapchat滤镜，这些滤镜干扰了我的分类器，你就可以在途中新建一个错误类型。总之，通过统计不同错误标记类型占总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。在做错误分析的时候，有时你会注意到开发集里有些样本被错误标记了，这时应该怎么做呢？我们下一个视频来讨论。 2.2 清除标注错误的数据（Cleaning up Incorrectly labeled data）你的监督学习问题的数据由输入$x$和输出标签 $y$ 构成，如果你观察一下你的数据，并发现有些输出标签 $y$ 是错的。你的数据有些标签是错的，是否值得花时间去修正这些标签呢？ 我们看看在猫分类问题中，图片是猫，$y=1$；不是猫，$y=0$。所以假设你看了一些数据样本，发现这（倒数第二张图片）其实不是猫，所以这是标记错误的样本。我用了这个词，“标记错误的样本”来表示你的学习算法输出了错误的 $y$ 值。但我要说的是，对于标记错误的样本，参考你的数据集，在训练集或者测试集 $y$ 的标签，人类给这部分数据加的标签，实际上是错的，这实际上是一只狗，所以 $y$ 其实应该是0，也许做标记的那人疏忽了。如果你发现你的数据有一些标记错误的样本，你该怎么办？ 首先，我们来考虑训练集，事实证明，深度学习算法对于训练集中的随机错误是相当健壮的（robust）。只要你的标记出错的样本，只要这些错误样本离随机错误不太远，有时可能做标记的人没有注意或者不小心，按错键了，如果错误足够随机，那么放着这些错误不管可能也没问题，而不要花太多时间修复它们。 当然你浏览一下训练集，检查一下这些标签，并修正它们也没什么害处。有时候修正这些错误是有价值的，有时候放着不管也可以，只要总数据集总足够大，实际错误率可能不会太高。我见过一大批机器学习算法训练的时候，明知训练集里有$x$个错误标签，但最后训练出来也没问题。 我这里先警告一下，深度学习算法对随机误差很健壮，但对系统性的错误就没那么健壮了。所以比如说，如果做标记的人一直把白色的狗标记成猫，那就成问题了。因为你的分类器学习之后，会把所有白色的狗都分类为猫。但随机错误或近似随机错误，对于大多数深度学习算法来说不成问题。 现在，之前的讨论集中在训练集中的标记出错的样本，那么如果是开发集和测试集中有这些标记出错的样本呢？如果你担心开发集或测试集上标记出错的样本带来的影响，他们一般建议你在错误分析时，添加一个额外的列，这样你也可以统计标签 $y=1$错误的样本数。所以比如说，也许你统计一下对100个标记出错的样本的影响，所以你会找到100个样本，其中你的分类器的输出和开发集的标签不一致，有时对于其中的少数样本，你的分类器输出和标签不同，是因为标签错了，而不是你的分类器出错。所以也许在这个样本中，你发现标记的人漏了背景里的一只猫，所以那里打个勾，来表示样本98标签出错了。也许这张图实际上是猫的画，而不是一只真正的猫，也许你希望标记数据的人将它标记为$y=0$，而不是 $y=1$，然后再在那里打个勾。当你统计出其他错误类型的百分比后，就像我们在之前的视频中看到的那样，你还可以统计因为标签错误所占的百分比，你的开发集里的 $y$ 值是错的，这就解释了为什么你的学习算法做出和数据集里的标记不一样的预测1。 所以现在问题是，是否值得修正这6%标记出错的样本，我的建议是，如果这些标记错误严重影响了你在开发集上评估算法的能力，那么就应该去花时间修正错误的标签。但是，如果它们没有严重影响到你用开发集评估成本偏差的能力，那么可能就不应该花宝贵的时间去处理。 我给你看一个样本，解释清楚我的意思。所以我建议你看3个数字来确定是否值得去人工修正标记出错的数据，我建议你看看整体的开发集错误率，在我们以前的视频中的样本，我们说也许我们的系统达到了90%整体准确度，所以有10%错误率，那么你应该看看错误标记引起的错误的数量或者百分比。所以在这种情况下，6％的错误来自标记出错，所以10%的6%就是0.6%。也许你应该看看其他原因导致的错误，如果你的开发集上有10%错误，其中0.6%是因为标记出错，剩下的占9.4%，是其他原因导致的，比如把狗误认为猫，大猫图片。所以在这种情况下，我说有9.4%错误率需要集中精力修正，而标记出错导致的错误是总体错误的一小部分而已，所以如果你一定要这么做，你也可以手工修正各种错误标签，但也许这不是当下最重要的任务。 我们再看另一个样本，假设你在学习问题上取得了很大进展，所以现在错误率不再是10%了，假设你把错误率降到了2％，但总体错误中的0.6%还是标记出错导致的。所以现在，如果你想检查一组标记出错的开发集图片，开发集数据有2%标记错误了，那么其中很大一部分，0.6%除以2%，实际上变成30%标签而不是6%标签了。有那么多错误样本其实是因为标记出错导致的，所以现在其他原因导致的错误是1.4%。当测得的那么大一部分的错误都是开发集标记出错导致的，那似乎修正开发集里的错误标签似乎更有价值。 如果你还记得设立开发集的目标的话，开发集的主要目的是，你希望用它来从两个分类器$A$和$B$中选择一个。所以当你测试两个分类器$A$和$B$时，在开发集上一个有2.1%错误率，另一个有1.9%错误率，但是你不能再信任开发集了，因为它无法告诉你这个分类器是否比这个好，因为0.6%的错误率是标记出错导致的。那么现在你就有很好的理由去修正开发集里的错误标签，因为在右边这个样本中，标记出错对算法错误的整体评估标准有严重的影响。而左边的样本中，标记出错对你算法影响的百分比还是相对较小的。 现在如果你决定要去修正开发集数据，手动重新检查标签，并尝试修正一些标签，这里还有一些额外的方针和原则需要考虑。首先，我鼓励你不管用什么修正手段，都要同时作用到开发集和测试集上，我们之前讨论过为什么，开发和测试集必须来自相同的分布。开发集确定了你的目标，当你击中目标后，你希望算法能够推广到测试集上，这样你的团队能够更高效的在来自同一分布的开发集和测试集上迭代。如果你打算修正开发集上的部分数据，那么最好也对测试集做同样的修正以确保它们继续来自相同的分布。所以我们雇佣了一个人来仔细检查这些标签，但必须同时检查开发集和测试集。 其次，我强烈建议你要考虑同时检验算法判断正确和判断错误的样本，要检查算法出错的样本很容易，只需要看看那些样本是否需要修正，但还有可能有些样本算法判断正确，那些也需要修正。如果你只修正算法出错的样本，你对算法的偏差估计可能会变大，这会让你的算法有一点不公平的优势，我们就需要再次检查出错的样本，但也需要再次检查做对的样本，因为算法有可能因为运气好把某个东西判断对了。在那个特例里，修正那些标签可能会让算法从判断对变成判断错。这第二点不是很容易做，所以通常不会这么做。通常不会这么做的原因是，如果你的分类器很准确，那么判断错的次数比判断正确的次数要少得多。那么就有2%出错，98%都是对的，所以更容易检查2%数据上的标签，然而检查98%数据上的标签要花的时间长得多，所以通常不这么做，但也是要考虑到的。 最后，如果你进入到一个开发集和测试集去修正这里的部分标签，你可能会，也可能不会去对训练集做同样的事情，还记得我们在其他视频里讲过，修正训练集中的标签其实相对没那么重要，你可能决定只修正开发集和测试集中的标签，因为它们通常比训练集小得多，你可能不想把所有额外的精力投入到修正大得多的训练集中的标签，所以这样其实是可以的。我们将在本周晚些时候讨论一些步骤，用于处理你的训练数据分布和开发与测试数据不同的情况，对于这种情况学习算法其实相当健壮，你的开发集和测试集来自同一分布非常重要。但如果你的训练集来自稍微不同的分布，通常这是一件很合理的事情，我会在本周晚些时候谈谈如何处理这个问题。 最后我讲几个建议： 首先，深度学习研究人员有时会喜欢这样说：“我只是把数据提供给算法，我训练过了，效果拔群”。这话说出了很多深度学习错误的真相，更多时候，我们把数据喂给算法，然后训练它，并减少人工干预，减少使用人类的见解。但我认为，在构造实际系统时，通常需要更多的人工错误分析，更多的人类见解来架构这些系统，尽管深度学习的研究人员不愿意承认这点。 其次，不知道为什么，我看一些工程师和研究人员不愿意亲自去看这些样本，也许做这些事情很无聊，坐下来看100或几百个样本来统计错误数量，但我经常亲自这么做。当我带领一个机器学习团队时，我想知道它所犯的错误，我会亲自去看看这些数据，尝试和一部分错误作斗争。我想就因为花了这几分钟，或者几个小时去亲自统计数据，真的可以帮你找到需要优先处理的任务，我发现花时间亲自检查数据非常值得，所以我强烈建议你们这样做，如果你在搭建你的机器学习系统的话，然后你想确定应该优先尝试哪些想法，或者哪些方向。 这就是错误分析过程，在下一个视频中，我想分享一下错误分析是如何在启动新的机器学习项目中发挥作用的。 2.3 快速搭建你的第一个系统，并进行迭代（Build your first system quickly, then iterate）如果你正在开发全新的机器学习应用，我通常会给你这样的建议，你应该尽快建立你的第一个系统原型，然后快速迭代。 让我告诉你我的意思，我在语音识别领域研究了很多年，如果你正在考虑建立一个新的语音识别系统，其实你可以走很多方向，可以优先考虑很多事情。 比如，有一些特定的技术，可以让语音识别系统对嘈杂的背景更加健壮，嘈杂的背景可能是说咖啡店的噪音，背景里有很多人在聊天，或者车辆的噪音，高速上汽车的噪音或者其他类型的噪音。有一些方法可以让语音识别系统在处理带口音时更健壮，还有特定的问题和麦克风与说话人距离很远有关，就是所谓的远场语音识别。儿童的语音识别带来特殊的挑战，挑战来自单词发音方面，还有他们选择的词汇，他们倾向于使用的词汇。还有比如说，说话人口吃，或者说了很多无意义的短语，比如“哦”，“啊”之类的。你可以选择很多不同的技术，让你听写下来的文本可读性更强，所以你可以做很多事情来改进语音识别系统。 一般来说，对于几乎所有的机器学习程序可能会有50个不同的方向可以前进，并且每个方向都是相对合理的可以改善你的系统。但挑战在于，你如何选择一个方向集中精力处理。即使我已经在语音识别领域工作多年了，如果我要为一个新应用程序域构建新系统，我还是觉得很难不花时间去思考这个问题就直接选择方向。所以我建议你们，如果你想搭建全新的机器学习程序，就是快速搭好你的第一个系统，然后开始迭代。我的意思是我建议你快速设立开发集和测试集还有指标，这样就决定了你的目标所在，如果你的目标定错了，之后改也是可以的。但一定要设立某个目标，然后我建议你马上搭好一个机器学习系统原型，然后找到训练集，训练一下，看看效果，开始理解你的算法表现如何，在开发集测试集，你的评估指标上表现如何。当你建立第一个系统后，你就可以马上用到之前说的偏差方差分析，还有之前最后几个视频讨论的错误分析，来确定下一步优先做什么。特别是如果错误分析让你了解到大部分的错误的来源是说话人远离麦克风，这对语音识别构成特殊挑战，那么你就有很好的理由去集中精力研究这些技术，所谓远场语音识别的技术，这基本上就是处理说话人离麦克风很远的情况。 建立这个初始系统的所有意义在于，它可以是一个快速和粗糙的实现（quick and dirty implementation），你知道的，别想太多。初始系统的全部意义在于，有一个学习过的系统，有一个训练过的系统，让你确定偏差方差的范围，就可以知道下一步应该优先做什么，让你能够进行错误分析，可以观察一些错误，然后想出所有能走的方向，哪些是实际上最有希望的方向。 所以回顾一下，我建议你们快速建立你的第一个系统，然后迭代。不过如果你在这个应用程序领域有很多经验，这个建议适用程度要低一些。还有一种情况适应程度更低，当这个领域有很多可以借鉴的学术文献，处理的问题和你要解决的几乎完全相同，所以，比如说，人脸识别就有很多学术文献，如果你尝试搭建一个人脸识别设备，那么可以从现有大量学术文献为基础出发，一开始就搭建比较复杂的系统。但如果你第一次处理某个新问题，那我真的不鼓励你想太多，或者把第一个系统弄得太复杂。我建议你们构建一些快速而粗糙的实现，然后用来帮你找到改善系统要优先处理的方向。我见过很多机器学习项目，我觉得有些团队的解决方案想太多了，他们造出了过于复杂的系统。我也见过有限团队想的不够，然后造出过于简单的系统。平均来说，我见到更多的团队想太多，构建太复杂的系统。 所以我希望这些策略有帮助，如果你将机器学习算法应用到新的应用程序里，你的主要目标是弄出能用的系统，你的主要目标并不是发明全新的机器学习算法，这是完全不同的目标，那时你的目标应该是想出某种效果非常好的算法。所以我鼓励你们搭建快速而粗糙的实现，然后用它做偏差/方差分析，用它做错误分析，然后用分析结果确定下一步优先要做的方向。 2.4 使用来自不同分布的数据，进行训练和测试（Training and testing on different distributions）深度学习算法对训练数据的胃口很大，当你收集到足够多带标签的数据构成训练集时，算法效果最好，这导致很多团队用尽一切办法收集数据，然后把它们堆到训练集里，让训练的数据量更大，即使有些数据，甚至是大部分数据都来自和开发集、测试集不同的分布。在深度学习时代，越来越多的团队都用来自和开发集、测试集分布不同的数据来训练，这里有一些微妙的地方，一些最佳做法来处理训练集和测试集存在差异的情况，我们来看看。 假设你在开发一个手机应用，用户会上传他们用手机拍摄的照片，你想识别用户从应用中上传的图片是不是猫。现在你有两个数据来源，一个是你真正关心的数据分布，来自应用上传的数据，比如右边的应用，这些照片一般更业余，取景不太好，有些甚至很模糊，因为它们都是业余用户拍的。另一个数据来源就是你可以用爬虫程序挖掘网页直接下载，就这个样本而言，可以下载很多取景专业、高分辨率、拍摄专业的猫图片。如果你的应用用户数还不多，也许你只收集到10,000张用户上传的照片，但通过爬虫挖掘网页，你可以下载到海量猫图，也许你从互联网上下载了超过20万张猫图。而你真正关心的算法表现是你的最终系统处理来自应用程序的这个图片分布时效果好不好，因为最后你的用户会上传类似右边这些图片，你的分类器必须在这个任务中表现良好。现在你就陷入困境了，因为你有一个相对小的数据集，只有10,000个样本来自那个分布，而你还有一个大得多的数据集来自另一个分布，图片的外观和你真正想要处理的并不一样。但你又不想直接用这10,000张图片，因为这样你的训练集就太小了，使用这20万张图片似乎有帮助。但是，困境在于，这20万张图片并不完全来自你想要的分布，那么你可以怎么做呢？ 这里有一种选择，你可以做的一件事是将两组数据合并在一起，这样你就有21万张照片，你可以把这21万张照片随机分配到训练、开发和测试集中。为了说明观点，我们假设你已经确定开发集和测试集各包含2500个样本，所以你的训练集有205000个样本。现在这么设立你的数据集有一些好处，也有坏处。好处在于，你的训练集、开发集和测试集都来自同一分布，这样更好管理。但坏处在于，这坏处还不小，就是如果你观察开发集，看看这2500个样本其中很多图片都来自网页下载的图片，那并不是你真正关心的数据分布，你真正要处理的是来自手机的图片。 所以结果你的数据总量，这200,000个样本，我就用$200k$缩写表示，我把那些是从网页下载的数据总量写成$210k$，所以对于这2500个样本，数学期望值是：$2500\times \frac{200k}{210k} =2381$，有2381张图来自网页下载，这是期望值，确切数目会变化，取决于具体的随机分配操作。但平均而言，只有119张图来自手机上传。要记住，设立开发集的目的是告诉你的团队去瞄准的目标，而你瞄准目标的方式，你的大部分精力都用在优化来自网页下载的图片，这其实不是你想要的。所以我真的不建议使用第一个选项，因为这样设立开发集就是告诉你的团队，针对不同于你实际关心的数据分布去优化，所以不要这么做。 我建议你走另外一条路，就是这样，训练集，比如说还是205,000张图片，我们的训练集是来自网页下载的200,000张图片，然后如果需要的话，再加上5000张来自手机上传的图片。然后对于开发集和测试集，这数据集的大小是按比例画的，你的开发集和测试集都是手机图。而训练集包含了来自网页的20万张图片，还有5000张来自应用的图片，开发集就是2500张来自应用的图片，测试集也是2500张来自应用的图片。这样将数据分成训练集、开发集和测试集的好处在于，现在你瞄准的目标就是你想要处理的目标，你告诉你的团队，我的开发集包含的数据全部来自手机上传，这是你真正关心的图片分布。我们试试搭建一个学习系统，让系统在处理手机上传图片分布时效果良好。缺点在于，当然了，现在你的训练集分布和你的开发集、测试集分布并不一样。但事实证明，这样把数据分成训练、开发和测试集，在长期能给你带来更好的系统性能。我们以后会讨论一些特殊的技巧，可以处理训练集的分布和开发集和测试集分布不一样的情况。 我们来看另一个样本，假设你正在开发一个全新的产品，一个语音激活汽车后视镜，这在中国是个真实存在的产品，它正在进入其他国家。但这就是造一个后视镜，把这个小东西换掉，现在你就可以和后视镜对话了，然后只需要说：“亲爱的后视镜，请帮我找找到最近的加油站的导航方向”，然后后视镜就会处理这个请求。所以这实际上是一个真正的产品，假设现在你要为你自己的国家研制这个产品，那么你怎么收集数据去训练这个产品语言识别模块呢？ 嗯，也许你已经在语音识别领域上工作了很久，所以你有很多来自其他语音识别应用的数据，它们并不是来自语音激活后视镜的数据。现在我讲讲如何分配训练集、开发集和测试集。对于你的训练集，你可以将你拥有的所有语音数据，从其他语音识别问题收集来的数据，比如这些年你从各种语音识别数据供应商买来的数据，今天你可以直接买到成$x$,$y$对的数据，其中$x$是音频剪辑，$y$是听写记录。或者也许你研究过智能音箱，语音激活音箱，所以你有一些数据，也许你做过语音激活键盘的开发之类的。 举例来说，也许你从这些来源收集了500,000段录音，对于你的开发集和测试集也许数据集小得多，比如实际上来自语音激活后视镜的数据。因为用户要查询导航信息或试图找到通往各个地方的路线，这个数据集可能会有很多街道地址，对吧？“请帮我导航到这个街道地址”，或者说：“请帮助我导航到这个加油站”，所以这个数据的分布和左边大不一样，但这真的是你关心的数据，因为这些数据是你的产品必须处理好的，所以你就应该把它设成你的开发和测试集。 在这个样本中，你应该这样设立你的训练集，左边有500,000段语音，然后你的开发集和测试集，我把它简写成$D$和$T$，可能每个集包含10,000段语音，是从实际的语音激活后视镜收集的。或者换种方式，如果你觉得不需要将20,000段来自语音激活后视镜的录音全部放进开发和测试集，也许你可以拿一半，把它放在训练集里，那么训练集可能是51万段语音，包括来自那里的50万段语音，还有来自后视镜的1万段语音，然后开发集和测试集也许各自有5000段语音。所以有2万段语音，也许1万段语音放入了训练集，5000放入开发集，5000放入测试集。所以这是另一种将你的数据分成训练、开发和测试的方式。这样你的训练集大得多，大概有50万段语音，比只用语音激活后视镜数据作为训练集要大得多。 所以在这个视频中，你们见到几组样本，让你的训练集数据来自和开发集、测试集不同的分布，这样你就可以有更多的训练数据。在这些样本中，这将改善你的学习算法。 现在你可能会问，是不是应该把收集到的数据都用掉？答案很微妙，不一定都是肯定的答案，我们在下段视频看看一个反例。 2.5 数据分布不匹配时，偏差与方差的分析（Bias and Variance with mismatched data distributions）估计学习算法的偏差和方差真的可以帮你确定接下来应该优先做的方向，但是，当你的训练集来自和开发集、测试集不同分布时，分析偏差和方差的方式可能不一样，我们来看为什么。 我们继续用猫分类器为例，我们说人类在这个任务上能做到几乎完美，所以贝叶斯错误率或者说贝叶斯最优错误率，我们知道这个问题里几乎是0%。所以要进行错误率分析，你通常需要看训练误差，也要看看开发集的误差。比如说，在这个样本中，你的训练集误差是1%，你的开发集误差是10%，如果你的开发集来自和训练集一样的分布，你可能会说，这里存在很大的方差问题，你的算法不能很好的从训练集出发泛化，它处理训练集很好，但处理开发集就突然间效果很差了。 但如果你的训练数据和开发数据来自不同的分布，你就不能再放心下这个结论了。特别是，也许算法在开发集上做得不错，可能因为训练集很容易识别，因为训练集都是高分辨率图片，很清晰的图像，但开发集要难以识别得多。所以也许软件没有方差问题，这只不过反映了开发集包含更难准确分类的图片。所以这个分析的问题在于，当你看训练误差，再看开发误差，有两件事变了。首先算法只见过训练集数据，没见过开发集数据。第二，开发集数据来自不同的分布。而且因为你同时改变了两件事情，很难确认这增加的9%误差率有多少是因为算法没看到开发集中的数据导致的，这是问题方差的部分，有多少是因为开发集数据就是不一样。 为了弄清楚哪个因素影响更大，如果你完全不懂这两种影响到底是什么，别担心我们马上会再讲一遍。但为了分辨清楚两个因素的影响，定义一组新的数据是有意义的，我们称之为训练-开发集，所以这是一个新的数据子集。我们应该从训练集的分布里挖出来，但你不会用来训练你的网络。 我的意思是我们已经设立过这样的训练集、开发集和测试集了，并且开发集和测试集来自相同的分布，但训练集来自不同的分布。 我们要做的是随机打散训练集，然后分出一部分训练集作为训练-开发集（training-dev），就像开发集和测试集来自同一分布，训练集、训练-开发集也来自同一分布。 但不同的地方是，现在你只在训练集训练你的神经网络，你不会让神经网络在训练-开发集上跑后向传播。为了进行误差分析，你应该做的是看看分类器在训练集上的误差，训练-开发集上的误差，还有开发集上的误差。 比如说这个样本中，训练误差是1%，我们说训练-开发集上的误差是9%，然后开发集误差是10%，和以前一样。你就可以从这里得到结论，当你从训练数据变到训练-开发集数据时，错误率真的上升了很多。而训练数据和训练-开发数据的差异在于，你的神经网络能看到第一部分数据并直接在上面做了训练，但没有在训练-开发集上直接训练，这就告诉你，算法存在方差问题，因为训练-开发集的错误率是在和训练集来自同一分布的数据中测得的。所以你知道，尽管你的神经网络在训练集中表现良好，但无法泛化到来自相同分布的训练-开发集里，它无法很好地泛化推广到来自同一分布，但以前没见过的数据中，所以在这个样本中我们确实有一个方差问题。 我们来看一个不同的样本，假设训练误差为1%，训练-开发误差为1.5%，但当你开始处理开发集时，错误率上升到10%。现在你的方差问题就很小了，因为当你从见过的训练数据转到训练-开发集数据，神经网络还没有看到的数据，错误率只上升了一点点。但当你转到开发集时，错误率就大大上升了，所以这是数据不匹配的问题。因为你的学习算法没有直接在训练-开发集或者开发集训练过，但是这两个数据集来自不同的分布。但不管算法在学习什么，它在训练-开发集上做的很好，但开发集上做的不好，所以总之你的算法擅长处理和你关心的数据不同的分布，我们称之为数据不匹配的问题。 我们再来看几个样本，我会在下一行里写出来，因上面没空间了。所以训练误差、训练-开发误差、还有开发误差，我们说训练误差是10%，训练-开发误差是11%，开发误差为12%，要记住，人类水平对贝叶斯错误率的估计大概是0%，如果你得到了这种等级的表现，那就真的存在偏差问题了。存在可避免偏差问题，因为算法做的比人类水平差很多，所以这里的偏差真的很高。 最后一个例子，如果你的训练集错误率是10%，你的训练-开发错误率是11%，开发错误率是20%，那么这其实有两个问题。第一，可避免偏差相当高，因为你在训练集上都没有做得很好，而人类能做到接近0%错误率，但你的算法在训练集上错误率为10%。这里方差似乎很小，但数据不匹配问题很大。所以对于这个样本，我说，如果你有很大的偏差或者可避免偏差问题，还有数据不匹配问题。 我们看看这张幻灯片里做了什么，然后写出一般的原则，我们要看的关键数据是人类水平错误率，你的训练集错误率，训练-开发集错误率，所以这分布和训练集一样，但你没有直接在上面训练。根据这些错误率之间差距有多大，你可以大概知道，可避免偏差、方差数据不匹配问题各自有多大。 我们说人类水平错误率是4%的话，你的训练错误率是7%，而你的训练-开发错误率是10%，而开发错误率是12%，这样你就大概知道可避免偏差有多大。因为你知道，你希望你的算法至少要在训练集上的表现接近人类。而这大概表明了方差大小，所以你从训练集泛化推广到训练-开发集时效果如何？而这告诉你数据不匹配的问题大概有多大。技术上你还可以再加入一个数字，就是测试集表现，我们写成测试集错误率，你不应该在测试集上开发，因为你不希望对测试集过拟合。但如果你看看这个，那么这里的差距就说明你对开发集过拟合的程度。所以如果开发集表现和测试集表现有很大差距，那么你可能对开发集过拟合了，所以也许你需要一个更大的开发集，对吧？要记住，你的开发集和测试集来自同一分布，所以这里存在很大差距的话。如果算法在开发集上做的很好，比测试集好得多，那么你就可能对开发集过拟合了。如果是这种情况，那么你可能要往回退一步，然后收集更多开发集数据。现在我写出这些数字，这数字列表越往后数字越大。 这里还有个例子，其中数字并没有一直变大，也许人类的表现是4%，训练错误率是7%，训练-开发错误率是10%。但我们看看开发集，你发现，很意外，算法在开发集上做的更好，也许是6%。所以如果你见到这种现象，比如说在处理语音识别任务时发现这样，其中训练数据其实比你的开发集和测试集难识别得多。所以这两个（7%，10%）是从训练集分布评估的，而这两个（6%，6%）是从开发测试集分布评估的。所以有时候如果你的开发测试集分布比你应用实际处理的数据要容易得多，那么这些错误率可能真的会下降。所以如果你看到这样的有趣的事情，可能需要比这个分析更普适的分析，我在下一张幻灯片里快速解释一下。 所以，我们就以语音激活后视镜为例子，事实证明，我们一直写出的数字可以放到一张表里，在水平轴上，我要放入不同的数据集。比如说，你可能从一般语音识别任务里得到很多数据，所以你可能会有一堆数据，来自小型智能音箱的语音识别问题的数据，你购买的数据等等。然后你收集了和后视镜有关的语音数据，在车里录的。所以这是表格的$x$轴，不同的数据集。在另一条轴上，我要标记处理数据不同的方式或算法。 首先，人类水平，人类处理这些数据集时准确度是多少。然后这是神经网络训练过的数据集上达到的错误率，然后还有神经网络没有训练过的数据集上达到的错误率。所以结果我们上一张幻灯片说是人类水平的错误率，数字填入这个单元格里（第二行第二列），人类对这一类数据处理得有多好，比如来自各种语音识别系统的数据，那些进入你的训练集的成千上万的语音片段，而上一张幻灯片中的例子是4%。这个数字（7%），可能是我们的训练错误率，在上一张幻灯片中的例子中是7%。是的，如果你的学习算法见过这个样本，在这个样本上跑过梯度下降，这个样本来自你的训练集分布或一般的语音识别数据分布，你的算法在训练过的数据中表现如何呢？然后这就是训练-开发集错误率，通常来自这个分布的错误率会高一点，一般的语音识别数据，如果你的算法没在来自这个分布的样本上训练过，它的表现如何呢？这就是我们说的训练-开发集错误率。 如果你移到右边去，这个单元格是开发集错误率，也可能是测试集错误，在刚刚的例子中是6%。而开发集和测试集，实际上是两个数字，但都可以放入这个单元格里。如果你有来自后视镜的数据，来自从后视镜应用在车里实际录得的数据，但你的神经网络没有在这些数据上做过反向传播，那么错误率是多少呢？ 我们在上一张幻灯片作的分析是观察这两个数字之间的差异（Human level 4%和Training error 7%），还有这两个数字之间（Training error 7%和Training-dev error 10%），这两个数字之间（Training-dev error 10%和Dev/Test dev 6%）。这个差距（Human level 4%和Training error 7%）衡量了可避免偏差大小，这个差距Training error 7%和Training-dev error 10%）衡量了方差大小，而这个差距（Training-dev error 10%和Dev/Test dev 6%）衡量了数据不匹配问题的大小。 事实证明，把剩下的两个数字（rearview mirror speech data 6%和Error on examples trained on 6%），也放到这个表格里也是有用的。如果结果这也是6%，那么你获得这个数字的方式是你让一些人自己标记他们的后视镜语音识别数据，看看人类在这个任务里能做多好，也许结果也是6%。做法就是，你收集一些后视镜语音识别数据，把它放在训练集中，让神经网络去学习，然后测量那个数据子集上的错误率，但如果你得到这样的结果，好吧，那就是说你已经在后视镜语音数据上达到人类水平了，所以也许你对那个数据分布做的已经不错了。 当你继续进行更多分析时，分析并不一定会给你指明一条前进道路，但有时候你可能洞察到一些特征。比如比较这两个数字（General speech recognition Human level 4%和rearview mirror speech data 6%），告诉我们对于人类来说，后视镜的语音数据实际上比一般语音识别更难，因为人类都有6%的错误，而不是4%的错误，但看看这个差值，你就可以了解到偏差和方差，还有数据不匹配这些问题的不同程度。所以更一般的分析方法是，我已经用过几次了。我还没用过，但对于很多问题来说检查这个子集的条目，看看这些差值，已经足够让你往相对有希望的方向前进了。但有时候填满整个表格，你可能会洞察到更多特征。 最后，我们以前讲过很多处理偏差的手段，讲过处理方差的手段，但怎么处理数据不匹配呢？特别是开发集、测试集和你的训练集数据来自不同分布时，这样可以用更多训练数据，真正帮你提高学习算法性能。但是，如果问题不仅来自偏差和方差，你现在又有了这个潜在的新问题，数据不匹配，有什么好办法可以处理数据不匹配的呢？实话说，并没有很通用，或者至少说是系统解决数据不匹配问题的方法，但你可以做一些尝试，可能会有帮助，我们在下一个视频里看看这些尝试。 所以我们讲了如何使用来自和开发集、测试集不同分布的训练数据，这可以给你提供更多训练数据，因此有助于提高你的学习算法的性能，但是，潜在问题就不只是偏差和方差问题，这样做会引入第三个潜在问题，数据不匹配。如果你做了错误分析，并发现数据不匹配是大量错误的来源，那么你怎么解决这个问题呢？但结果很不幸，并没有特别系统的方法去解决数据不匹配问题，但你可以做一些尝试，可能会有帮助，我们来看下一段视频。 2.6 处理数据不匹配问题（Addressing data mismatch）如果您的训练集来自和开发测试集不同的分布，如果错误分析显示你有一个数据不匹配的问题该怎么办？这个问题没有完全系统的解决方案，但我们可以看看一些可以尝试的事情。如果我发现有严重的数据不匹配问题，我通常会亲自做错误分析，尝试了解训练集和开发测试集的具体差异。技术上，为了避免对测试集过拟合，要做错误分析，你应该人工去看开发集而不是测试集。 但作为一个具体的例子，如果你正在开发一个语音激活的后视镜应用，你可能要看看……我想如果是语音的话，你可能要听一下来自开发集的样本，尝试弄清楚开发集和训练集到底有什么不同。所以，比如说你可能会发现很多开发集样本噪音很多，有很多汽车噪音，这是你的开发集和训练集差异之一。也许你还会发现其他错误，比如在你的车子里的语言激活后视镜，你发现它可能经常识别错误街道号码，因为那里有很多导航请求都有街道地址，所以得到正确的街道号码真的很重要。当你了解开发集误差的性质时，你就知道，开发集有可能跟训练集不同或者更难识别，那么你可以尝试把训练数据变得更像开发集一点，或者，你也可以收集更多类似你的开发集和测试集的数据。所以，比如说，如果你发现车辆背景噪音是主要的错误来源，那么你可以模拟车辆噪声数据，我会在下一张幻灯片里详细讨论这个问题。或者你发现很难识别街道号码，也许你可以有意识地收集更多人们说数字的音频数据，加到你的训练集里。 现在我知道这张幻灯片只给出了粗略的指南，列出一些你可以做的尝试，这不是一个系统化的过程，我想，这不能保证你一定能取得进展。但我发现这种人工见解，我们可以一起尝试收集更多和真正重要的场合相似的数据，这通常有助于解决很多问题。所以，如果你的目标是让训练数据更接近你的开发集，那么你可以怎么做呢？ 你可以利用的其中一种技术是人工合成数据（artificial data synthesis），我们讨论一下。在解决汽车噪音问题的场合，所以要建立语音识别系统。也许实际上你没那么多实际在汽车背景噪音下录得的音频，或者在高速公路背景噪音下录得的音频。但我们发现，你可以合成。所以假设你录制了大量清晰的音频，不带车辆背景噪音的音频，“The quick brown fox jumps over the lazy dog”（音频播放），所以，这可能是你的训练集里的一段音频，顺便说一下，这个句子在AI测试中经常使用，因为这个短句包含了从a到z所有字母，所以你会经常见到这个句子。但是，有了这个“the quick brown fox jumps over the lazy dog”这段录音之后，你也可以收集一段这样的汽车噪音，（播放汽车噪音音频）这就是汽车内部的背景噪音，如果你一言不发开车的话，就是这种声音。如果你把两个音频片段放到一起，你就可以合成出”the quick brown fox jumps over the lazy dog“（带有汽车噪声），在汽车背景噪音中的效果，听起来像这样，所以这是一个相对简单的音频合成例子。在实践中，你可能会合成其他音频效果，比如混响，就是声音从汽车内壁上反弹叠加的效果。 但是通过人工数据合成，你可以快速制造更多的训练数据，就像真的在车里录的那样，那就不需要花时间实际出去收集数据，比如说在实际行驶中的车子，录下上万小时的音频。所以，如果错误分析显示你应该尝试让你的数据听起来更像在车里录的，那么人工合成那种音频，然后喂给你的机器学习算法，这样做是合理的。 现在我们要提醒一下，人工数据合成有一个潜在问题，比如说，你在安静的背景里录得10,000小时音频数据，然后，比如说，你只录了一小时车辆背景噪音，那么，你可以这么做，将这1小时汽车噪音回放10,000次，并叠加到在安静的背景下录得的10,000小时数据。如果你这么做了，人听起来这个音频没什么问题。但是有一个风险，有可能你的学习算法对这1小时汽车噪音过拟合。特别是，如果这组汽车里录的音频可能是你可以想象的所有汽车噪音背景的集合，如果你只录了一小时汽车噪音，那你可能只模拟了全部数据空间的一小部分，你可能只从汽车噪音的很小的子集来合成数据。 而对于人耳来说，这些音频听起来没什么问题，因为一小时的车辆噪音对人耳来说，听起来和其他任意一小时车辆噪音是一样的。但你有可能从这整个空间很小的一个子集出发合成数据，神经网络最后可能对你这一小时汽车噪音过拟合。我不知道以较低成本收集10,000小时的汽车噪音是否可行，这样你就不用一遍又一遍地回放那1小时汽车噪音，你就有10,000个小时永不重复的汽车噪音来叠加到10,000小时安静背景下录得的永不重复的语音录音。这是可以做的，但不保证能做。但是使用10,000小时永不重复的汽车噪音，而不是1小时重复学习，算法有可能取得更好的性能。人工数据合成的挑战在于，人耳的话，人耳是无法分辨这10,000个小时听起来和那1小时没什么区别，所以你最后可能会制造出这个原始数据很少的，在一个小得多的空间子集合成的训练数据，但你自己没意识到。 这里有人工合成数据的另一个例子，假设你在研发无人驾驶汽车，你可能希望检测出这样的车，然后用这样的框包住它。很多人都讨论过的一个思路是，为什么不用计算机合成图像来模拟成千上万的车辆呢？事实上，这里有几张车辆照片（下图后两张图片），其实是用计算机合成的，我想这个合成是相当逼真的，我想通过这样合成图片，你可以训练出一个相当不错的计算机视觉系统来检测车子。 不幸的是，上一张幻灯片介绍的情况也会在这里出现，比如这是所有车的集合，如果你只合成这些车中很小的子集，对于人眼来说也许这样合成图像没什么问题，但你的学习算法可能会对合成的这一个小子集过拟合。特别是很多人都独立提出了一个想法，一旦你找到一个电脑游戏，里面车辆渲染的画面很逼真，那么就可以截图，得到数量巨大的汽车图片数据集。事实证明，如果你仔细观察一个视频游戏，如果这个游戏只有20辆独立的车，那么这游戏看起来还行。因为你是在游戏里开车，你只看到这20辆车，这个模拟看起来相当逼真。但现实世界里车辆的设计可不只20种，如果你用着20量独特的车合成的照片去训练系统，那么你的神经网络很可能对这20辆车过拟合，但人类很难分辨出来。即使这些图像看起来很逼真，你可能真的只用了所有可能出现的车辆的很小的子集。 所以，总而言之，如果你认为存在数据不匹配问题，我建议你做错误分析，或者看看训练集，或者看看开发集，试图找出，试图了解这两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像开发集的数据作训练。 我们谈到其中一种办法是人工数据合成，人工数据合成确实有效。在语音识别中。我已经看到人工数据合成显著提升了已经非常好的语音识别系统的表现，所以这是可行的。但当你使用人工数据合成时，一定要谨慎，要记住你有可能从所有可能性的空间只选了很小一部分去模拟数据。 所以这就是如何处理数据不匹配问题，接下来，我想和你分享一些想法就是如何从多种类型的数据同时学习。 2.7 迁移学习（Transfer learning）深度学习中，最强大的理念之一就是，有的时候神经网络可以从一个任务中习得知识，并将这些知识应用到另一个独立的任务中。所以例如，也许你已经训练好一个神经网络，能够识别像猫这样的对象，然后使用那些知识，或者部分习得的知识去帮助您更好地阅读x射线扫描图，这就是所谓的迁移学习。 我们来看看，假设你已经训练好一个图像识别神经网络，所以你首先用一个神经网络，并在$(x,y)$对上训练，其中$x$是图像，$y$是某些对象，图像是猫、狗、鸟或其他东西。如果你把这个神经网络拿来，然后让它适应或者说迁移，在不同任务中学到的知识，比如放射科诊断，就是说阅读$X$射线扫描图。你可以做的是把神经网络最后的输出层拿走，就把它删掉，还有进入到最后一层的权重删掉，然后为最后一层重新赋予随机权重，然后让它在放射诊断数据上训练。 具体来说，在第一阶段训练过程中，当你进行图像识别任务训练时，你可以训练神经网络的所有常用参数，所有的权重，所有的层，然后你就得到了一个能够做图像识别预测的网络。在训练了这个神经网络后，要实现迁移学习，你现在要做的是，把数据集换成新的$(x,y)$对，现在这些变成放射科图像，而$y$是你想要预测的诊断，你要做的是初始化最后一层的权重，让我们称之为$w^{[L]}$和$b^{[L]}$随机初始化。 现在，我们在这个新数据集上重新训练网络，在新的放射科数据集上训练网络。要用放射科数据集重新训练神经网络有几种做法。你可能，如果你的放射科数据集很小，你可能只需要重新训练最后一层的权重，就是$w^{[L]}$和$b^{[L]}$并保持其他参数不变。如果你有足够多的数据，你可以重新训练神经网络中剩下的所有层。经验规则是，如果你有一个小数据集，就只训练输出层前的最后一层，或者也许是最后一两层。但是如果你有很多数据，那么也许你可以重新训练网络中的所有参数。如果你重新训练神经网络中的所有参数，那么这个在图像识别数据的初期训练阶段，有时称为预训练（pre-training），因为你在用图像识别数据去预先初始化，或者预训练神经网络的权重。然后，如果你以后更新所有权重，然后在放射科数据上训练，有时这个过程叫微调（fine tuning）。如果你在深度学习文献中看到预训练和微调，你就知道它们说的是这个意思，预训练和微调的权重来源于迁移学习。 在这个例子中你做的是，把图像识别中学到的知识应用或迁移到放射科诊断上来，为什么这样做有效果呢？有很多低层次特征，比如说边缘检测、曲线检测、阳性对象检测（positive objects），从非常大的图像识别数据库中习得这些能力可能有助于你的学习算法在放射科诊断中做得更好，算法学到了很多结构信息，图像形状的信息，其中一些知识可能会很有用，所以学会了图像识别，它就可能学到足够多的信息，可以了解不同图像的组成部分是怎样的，学到线条、点、曲线这些知识，也许对象的一小部分，这些知识有可能帮助你的放射科诊断网络学习更快一些，或者需要更少的学习数据。 这里是另一个例子，假设你已经训练出一个语音识别系统，现在$x$是音频或音频片段输入，而$y$是听写文本，所以你已经训练了语音识别系统，让它输出听写文本。现在我们说你想搭建一个“唤醒词”或“触发词”检测系统，所谓唤醒词或触发词就是我们说的一句话，可以唤醒家里的语音控制设备，比如你说“Alexa”可以唤醒一个亚马逊Echo设备,或用“OK Google”来唤醒Google设备，用”Hey Siri“来唤醒苹果设备，用”你好百度”唤醒一个百度设备。要做到这点，你可能需要去掉神经网络的最后一层，然后加入新的输出节点，但有时你可以不只加入一个新节点，或者甚至往你的神经网络加入几个新层，然后把唤醒词检测问题的标签$y$喂进去训练。再次，这取决于你有多少数据，你可能只需要重新训练网络的新层，也许你需要重新训练神经网络中更多的层。 那么迁移学习什么时候是有意义的呢？迁移学习起作用的场合是，在迁移来源问题中你有很多数据，但迁移目标问题你没有那么多数据。例如，假设图像识别任务中你有1百万个样本，所以这里数据相当多。可以学习低层次特征，可以在神经网络的前面几层学到如何识别很多有用的特征。但是对于放射科任务，也许你只有一百个样本，所以你的放射学诊断问题数据很少，也许只有100次$X$射线扫描，所以你从图像识别训练中学到的很多知识可以迁移，并且真正帮你加强放射科识别任务的性能，即使你的放射科数据很少。 对于语音识别，也许你已经用10,000小时数据训练过你的语言识别系统，所以你从这10,000小时数据学到了很多人类声音的特征，这数据量其实很多了。但对于触发字检测，也许你只有1小时数据，所以这数据太小，不能用来拟合很多参数。所以在这种情况下，预先学到很多人类声音的特征人类语言的组成部分等等知识，可以帮你建立一个很好的唤醒字检测器，即使你的数据集相对较小。对于唤醒词任务来说，至少数据集要小得多。 所以在这两种情况下，你从数据量很多的问题迁移到数据量相对小的问题。然后反过来的话，迁移学习可能就没有意义了。比如，你用100张图训练图像识别系统，然后有100甚至1000张图用于训练放射科诊断系统，人们可能会想，为了提升放射科诊断的性能，假设你真的希望这个放射科诊断系统做得好，那么用放射科图像训练可能比使用猫和狗的图像更有价值，所以这里（100甚至1000张图用于训练放射科诊断系统）的每个样本价值比这里（100张图训练图像识别系统）要大得多，至少就建立性能良好的放射科系统而言是这样。所以，如果你的放射科数据更多，那么你这100张猫猫狗狗或者随机物体的图片肯定不会有太大帮助，因为来自猫狗识别任务中，每一张图的价值肯定不如一张$X$射线扫描图有价值，对于建立良好的放射科诊断系统而言是这样。 所以，这是其中一个例子，说明迁移学习可能不会有害，但也别指望这么做可以带来有意义的增益。同样，如果你用10小时数据训练出一个语音识别系统。然后你实际上有10个小时甚至更多，比如说50个小时唤醒字检测的数据，你知道迁移学习有可能会有帮助，也可能不会，也许把这10小时数据迁移学习不会有太大坏处，但是你也别指望会得到有意义的增益。 所以总结一下，什么时候迁移学习是有意义的？如果你想从任务$A$学习并迁移一些知识到任务$B$，那么当任务$A$和任务$B$都有同样的输入$x$时，迁移学习是有意义的。在第一个例子中，$A$和$B$的输入都是图像，在第二个例子中，两者输入都是音频。当任务$A$的数据比任务$B$多得多时，迁移学习意义更大。所有这些假设的前提都是，你希望提高任务$B$的性能，因为任务$B$每个数据更有价值，对任务$B$来说通常任务$A$的数据量必须大得多，才有帮助，因为任务$A$里单个样本的价值没有比任务$B$单个样本价值大。然后如果你觉得任务$A$的低层次特征，可以帮助任务$B$的学习，那迁移学习更有意义一些。 而在这两个前面的例子中，也许学习图像识别教给系统足够多图像相关的知识，让它可以进行放射科诊断，也许学习语音识别教给系统足够多人类语言信息，能帮助你开发触发字或唤醒字检测器。 所以总结一下，迁移学习最有用的场合是，如果你尝试优化任务B的性能，通常这个任务数据相对较少，例如，在放射科中你知道很难收集很多$X$射线扫描图来搭建一个性能良好的放射科诊断系统，所以在这种情况下，你可能会找一个相关但不同的任务，如图像识别，其中你可能用1百万张图片训练过了，并从中学到很多低层次特征，所以那也许能帮助网络在任务$B$在放射科任务上做得更好，尽管任务$B$没有这么多数据。迁移学习什么时候是有意义的？它确实可以显著提高你的学习任务的性能，但我有时候也见过有些场合使用迁移学习时，任务$A$实际上数据量比任务$B$要少，这种情况下增益可能不多。 好，这就是迁移学习，你从一个任务中学习，然后尝试迁移到另一个不同任务中。从多个任务中学习还有另外一个版本，就是所谓的多任务学习，当你尝试从多个任务中并行学习，而不是串行学习，在训练了一个任务之后试图迁移到另一个任务，所以在下一个视频中，让我们来讨论多任务学习。 2.8 多任务学习（Multi-task learning）在迁移学习中，你的步骤是串行的，你从任务$A$里学习只是然后迁移到任务$B$。在多任务学习中，你是同时开始学习的，试图让单个神经网络同时做几件事情，然后希望这里每个任务都能帮到其他所有任务。 我们来看一个例子，假设你在研发无人驾驶车辆，那么你的无人驾驶车可能需要同时检测不同的物体，比如检测行人、车辆、停车标志，还有交通灯各种其他东西。比如在左边这个例子中，图像里有个停车标志，然后图像中有辆车，但没有行人，也没有交通灯。 如果这是输入图像$x^{(i)}$，那么这里不再是一个标签 $y^{(i)}$，而是有4个标签。在这个例子中，没有行人，有一辆车，有一个停车标志，没有交通灯。然后如果你尝试检测其他物体，也许 $y^{(i)}$的维数会更高，现在我们就先用4个吧，所以 $y^{(i)}$是个4×1向量。如果你从整体来看这个训练集标签和以前类似，我们将训练集的标签水平堆叠起来，像这样$y^{(1)}$一直到$y^{(m)}$： $$Y = \begin{bmatrix}| &amp; | &amp; | &amp; \ldots &amp; | \y^{(1)} &amp; y^{(2)} &amp; y^{(3)} &amp; \ldots &amp; y^{(m)} \| &amp; | &amp; | &amp; \ldots &amp; | \\end{bmatrix}$$ 不过现在$y^{(i)}$是4×1向量，所以这些都是竖向的列向量，所以这个矩阵$Y$现在变成$4×m$矩阵。而之前，当$y$是单实数时，这就是$1×m$矩阵。 那么你现在可以做的是训练一个神经网络，来预测这些$y$值，你就得到这样的神经网络，输入$x$，现在输出是一个四维向量$y$。请注意，这里输出我画了四个节点，所以第一个节点就是我们想预测图中有没有行人，然后第二个输出节点预测的是有没有车，这里预测有没有停车标志，这里预测有没有交通灯，所以这里$\hat y$是四维的。 要训练这个神经网络，你现在需要定义神经网络的损失函数，对于一个输出$\hat y$，是个4维向量，对于整个训练集的平均损失： $\frac{1}{m}\sum_{i = 1}^{m}{\sum_{j = 1}^{4}{L(\hat y_{j}^{(i)},y_{j}^{(i)})} }$ $\sum_{j = 1}^{4}{L(\hat y_{j}^{(i)},y_{j}^{(i)})}$这些单个预测的损失，所以这就是对四个分量的求和，行人、车、停车标志、交通灯，而这个标志L指的是**logistic损失**，我们就这么写： $L(\hat y_{j}^{(i)},y_{j}^{(i)}) = - y_{j}^{(i)}\log\hat y_{j}^{(i)} - (1 - y_{j}^{(i)})log(1 - \hat y_{j}^{(i)})$ 整个训练集的平均损失和之前分类猫的例子主要区别在于，现在你要对$j=1$到4求和，这与softmax回归的主要区别在于，与softmax回归不同，softmax将单个标签分配给单个样本。 而这张图可以有很多不同的标签，所以不是说每张图都只是一张行人图片，汽车图片、停车标志图片或者交通灯图片。你要知道每张照片是否有行人、或汽车、停车标志或交通灯，多个物体可能同时出现在一张图里。实际上，在上一张幻灯片中，那张图同时有车和停车标志，但没有行人和交通灯，所以你不是只给图片一个标签，而是需要遍历不同类型，然后看看每个类型，那类物体有没有出现在图中。所以我就说在这个场合，一张图可以有多个标签。如果你训练了一个神经网络，试图最小化这个成本函数，你做的就是多任务学习。因为你现在做的是建立单个神经网络，观察每张图，然后解决四个问题，系统试图告诉你，每张图里面有没有这四个物体。另外你也可以训练四个不同的神经网络，而不是训练一个网络做四件事情。但神经网络一些早期特征，在识别不同物体时都会用到，然后你发现，训练一个神经网络做四件事情会比训练四个完全独立的神经网络分别做四件事性能要更好，这就是多任务学习的力量。 另一个细节，到目前为止，我是这么描述算法的，好像每张图都有全部标签。事实证明，多任务学习也可以处理图像只有部分物体被标记的情况。所以第一个训练样本，我们说有人，给数据贴标签的人告诉你里面有一个行人，没有车，但他们没有标记是否有停车标志，或者是否有交通灯。也许第二个例子中，有行人，有车。但是，当标记人看着那张图片时，他们没有加标签，没有标记是否有停车标志，是否有交通灯等等。也许有些样本都有标记，但也许有些样本他们只标记了有没有车，然后还有一些是问号。 即使是这样的数据集，你也可以在上面训练算法，同时做四个任务，即使一些图像只有一小部分标签，其他是问号或者不管是什么。然后你训练算法的方式，即使这里有些标签是问号，或者没有标记，这就是对$j$从1到4求和，你就只对带0和1标签的$j$值求和，所以当有问号的时候，你就在求和时忽略那个项，这样只对有标签的值求和，于是你就能利用这样的数据集。 那么多任务学习什么时候有意义呢？当三件事为真时，它就是有意义的。 第一，如果你训练的一组任务，可以共用低层次特征。对于无人驾驶的例子，同时识别交通灯、汽车和行人是有道理的，这些物体有相似的特征，也许能帮你识别停车标志，因为这些都是道路上的特征。 第二，这个准则没有那么绝对，所以不一定是对的。但我从很多成功的多任务学习案例中看到，如果每个任务的数据量很接近，你还记得迁移学习时，你从$A$任务学到知识然后迁移到$B$任务，所以如果任务$A$有1百万个样本，任务$B$只有1000个样本，那么你从这1百万个样本学到的知识，真的可以帮你增强对更小数据集任务$B$的训练。那么多任务学习又怎么样呢？在多任务学习中，你通常有更多任务而不仅仅是两个，所以也许你有，以前我们有4个任务，但比如说你要完成100个任务，而你要做多任务学习，尝试同时识别100种不同类型的物体。你可能会发现，每个任务大概有1000个样本。所以如果你专注加强单个任务的性能，比如我们专注加强第100个任务的表现，我们用$A100$表示，如果你试图单独去做这个最后的任务，你只有1000个样本去训练这个任务，这是100项任务之一，而通过在其他99项任务的训练，这些加起来可以一共有99000个样本，这可能大幅提升算法性能，可以提供很多知识来增强这个任务的性能。不然对于任务$A100$，只有1000个样本的训练集，效果可能会很差。如果有对称性，这其他99个任务，也许能提供一些数据或提供一些知识来帮到这100个任务中的每一个任务。所以第二点不是绝对正确的准则，但我通常会看的是如果你专注于单项任务，如果想要从多任务学习得到很大性能提升，那么其他任务加起来必须要有比单个任务大得多的数据量。要满足这个条件，其中一种方法是，比如右边这个例子这样，或者如果每个任务中的数据量很相近，但关键在于，如果对于单个任务你已经有1000个样本了，那么对于所有其他任务，你最好有超过1000个样本，这样其他任务的知识才能帮你改善这个任务的性能。 最后多任务学习往往在以下场合更有意义，当你可以训练一个足够大的神经网络，同时做好所有的工作，所以多任务学习的替代方法是为每个任务训练一个单独的神经网络。所以不是训练单个神经网络同时处理行人、汽车、停车标志和交通灯检测。你可以训练一个用于行人检测的神经网络，一个用于汽车检测的神经网络，一个用于停车标志检测的神经网络和一个用于交通信号灯检测的神经网络。那么研究员Rich Carona几年前发现的是什么呢？多任务学习会降低性能的唯一情况，和训练单个神经网络相比性能更低的情况就是你的神经网络还不够大。但如果你可以训练一个足够大的神经网络，那么多任务学习肯定不会或者很少会降低性能，我们都希望它可以提升性能，比单独训练神经网络来单独完成各个任务性能要更好。 所以这就是多任务学习，在实践中，多任务学习的使用频率要低于迁移学习。我看到很多迁移学习的应用，你需要解决一个问题，但你的训练数据很少，所以你需要找一个数据很多的相关问题来预先学习，并将知识迁移到这个新问题上。但多任务学习比较少见，就是你需要同时处理很多任务，都要做好，你可以同时训练所有这些任务，也许计算机视觉是一个例子。在物体检测中，我们看到更多使用多任务学习的应用，其中一个神经网络尝试检测一大堆物体，比分别训练不同的神经网络检测物体更好。但我说，平均来说，目前迁移学习使用频率更高，比多任务学习频率要高，但两者都可以成为你的强力工具。 所以总结一下，多任务学习能让你训练一个神经网络来执行许多任务，这可以给你更高的性能，比单独完成各个任务更高的性能。但要注意，实际上迁移学习比多任务学习使用频率更高。我看到很多任务都是，如果你想解决一个机器学习问题，但你的数据集相对较小，那么迁移学习真的能帮到你，就是如果你找到一个相关问题，其中数据量要大得多，你就能以它为基础训练你的神经网络，然后迁移到这个数据量很少的任务上来。 今天我们学到了很多和迁移学习有关的问题，还有一些迁移学习和多任务学习的应用。但多任务学习，我觉得使用频率比迁移学习要少得多，也许其中一个例外是计算机视觉，物体检测。在那些任务中，人们经常训练一个神经网络同时检测很多不同物体，这比训练单独的神经网络来检测视觉物体要更好。但平均而言，我认为即使迁移学习和多任务学习工作方式类似。实际上，我看到用迁移学习比多任务学习要更多，我觉得这是因为你很难找到那么多相似且数据量对等的任务可以用单一神经网络训练。再次，在计算机视觉领域，物体检测这个例子是最显著的例外情况。 所以这就是多任务学习，多任务学习和迁移学习都是你的工具包中的重要工具。最后，我想继续讨论端到端深度学习，所以我们来看下一个视频来讨论端到端学习。 2.9 什么是端到端的深度学习？（What is end-to-end deep learning?）深度学习中最令人振奋的最新动态之一就是端到端深度学习的兴起，那么端到端学习到底是什么呢？简而言之，以前有一些数据处理系统或者学习系统，它们需要多个阶段的处理。那么端到端深度学习就是忽略所有这些不同的阶段，用单个神经网络代替它。 我们来看一些例子，以语音识别为例，你的目标是输入$x$，比如说一段音频，然后把它映射到一个输出$y$，就是这段音频的听写文本。所以传统上，语音识别需要很多阶段的处理。首先你会提取一些特征，一些手工设计的音频特征，也许你听过MFCC，这种算法是用来从音频中提取一组特定的人工设计的特征。在提取出一些低层次特征之后，你可以应用机器学习算法在音频片段中找到音位，所以音位是声音的基本单位，比如说“Cat”这个词是三个音节构成的，Cu-、Ah-和Tu-，算法就把这三个音位提取出来，然后你将音位串在一起构成独立的词，然后你将词串起来构成音频片段的听写文本。 所以和这种有很多阶段的流水线相比，端到端深度学习做的是，你训练一个巨大的神经网络，输入就是一段音频，输出直接是听写文本。AI的其中一个有趣的社会学效应是，随着端到端深度学习系统表现开始更好，有一些花了大量时间或者整个事业生涯设计出流水线各个步骤的研究员，还有其他领域的研究员，不只是语言识别领域的，也许是计算机视觉，还有其他领域，他们花了大量的时间，写了很多论文，有些甚至整个职业生涯的一大部分都投入到开发这个流水线的功能或者其他构件上去了。而端到端深度学习就只需要把训练集拿过来，直接学到了$x$和$y$之间的函数映射，直接绕过了其中很多步骤。对一些学科里的人来说，这点相当难以接受，他们无法接受这样构建AI系统，因为有些情况，端到端方法完全取代了旧系统，某些投入了多年研究的中间组件也许已经过时了。 事实证明，端到端深度学习的挑战之一是，你可能需要大量数据才能让系统表现良好，比如，你只有3000小时数据去训练你的语音识别系统，那么传统的流水线效果真的很好。但当你拥有非常大的数据集时，比如10,000小时数据或者100,000小时数据，这样端到端方法突然开始很厉害了。所以当你的数据集较小的时候，传统流水线方法其实效果也不错，通常做得更好。你需要大数据集才能让端到端方法真正发出耀眼光芒。如果你的数据量适中，那么也可以用中间件方法，你可能输入还是音频，然后绕过特征提取，直接尝试从神经网络输出音位，然后也可以在其他阶段用，所以这是往端到端学习迈出的一小步，但还没有到那里。 这张图上是一个研究员做的人脸识别门禁，是百度的林元庆研究员做的。这是一个相机，它会拍下接近门禁的人，如果它认出了那个人，门禁系统就自动打开，让他通过，所以你不需要刷一个RFID工卡就能进入这个设施。系统部署在越来越多的中国办公室，希望在其他国家也可以部署更多，你可以接近门禁，如果它认出你的脸，它就直接让你通过，你不需要带RFID工卡。 那么，怎么搭建这样的系统呢？你可以做的第一件事是，看看相机拍到的照片，对吧？我想我画的不太好，但也许这是相机照片，你知道，有人接近门禁了，所以这可能是相机拍到的图像$x$。有件事你可以做，就是尝试直接学习图像$x$到人物$y$身份的函数映射，事实证明这不是最好的方法。其中一个问题是，人可以从很多不同的角度接近门禁，他们可能在绿色位置，可能在蓝色位置。有时他们更靠近相机，所以他们看起来更大，有时候他们非常接近相机，那照片中脸就很大了。在实际研制这些门禁系统时，他不是直接将原始照片喂到一个神经网络，试图找出一个人的身份。 相反，迄今为止最好的方法似乎是一个多步方法，首先，你运行一个软件来检测人脸，所以第一个检测器找的是人脸位置，检测到人脸，然后放大图像的那部分，并裁剪图像，使人脸居中显示，然后就是这里红线框起来的照片，再喂到神经网络里，让网络去学习，或估计那人的身份。 研究人员发现，比起一步到位，一步学习，把这个问题分解成两个更简单的步骤。首先，是弄清楚脸在哪里。第二步是看着脸，弄清楚这是谁。这第二种方法让学习算法，或者说两个学习算法分别解决两个更简单的任务，并在整体上得到更好的表现。 顺便说一句，如果你想知道第二步实际是怎么工作的，我这里其实省略了很多。训练第二步的方式，训练网络的方式就是输入两张图片，然后你的网络做的就是将输入的两张图比较一下，判断是否是同一个人。比如你记录了10,000个员工ID，你可以把红色框起来的图像快速比较……也许是全部10,000个员工记录在案的ID，看看这张红线内的照片，是不是那10000个员工之一，来判断是否应该允许其进入这个设施或者进入这个办公楼。这是一个门禁系统，允许员工进入工作场所的门禁。 为什么两步法更好呢？实际上有两个原因。一是，你解决的两个问题，每个问题实际上要简单得多。但第二，两个子任务的训练数据都很多。具体来说，有很多数据可以用于人脸识别训练，对于这里的任务1来说，任务就是观察一张图，找出人脸所在的位置，把人脸图像框出来，所以有很多数据，有很多标签数据$(x,y)$，其中$x$是图片，$y$是表示人脸的位置，你可以建立一个神经网络，可以很好地处理任务1。然后任务2，也有很多数据可用，今天，业界领先的公司拥有，比如说数百万张人脸照片，所以输入一张裁剪得很紧凑的照片，比如这张红色照片，下面这个，今天业界领先的人脸识别团队有至少数亿的图像，他们可以用来观察两张图片，并试图判断照片里人的身份，确定是否同一个人，所以任务2还有很多数据。相比之下，如果你想一步到位，这样$(x,y)$的数据对就少得多，其中$x$是门禁系统拍摄的图像，$y$是那人的身份，因为你没有足够多的数据去解决这个端到端学习问题，但你却有足够多的数据来解决子问题1和子问题2。 实际上，把这个分成两个子问题，比纯粹的端到端深度学习方法，达到更好的表现。不过如果你有足够多的数据来做端到端学习，也许端到端方法效果更好。但在今天的实践中，并不是最好的方法。 我们再来看几个例子，比如机器翻译。传统上，机器翻译系统也有一个很复杂的流水线，比如英语机翻得到文本，然后做文本分析，基本上要从文本中提取一些特征之类的，经过很多步骤，你最后会将英文文本翻译成法文。因为对于机器翻译来说的确有很多(英文,法文)的数据对，端到端深度学习在机器翻译领域非常好用，那是因为在今天可以收集$x-y$对的大数据集，就是英文句子和对应的法语翻译。所以在这个例子中，端到端深度学习效果很好。 最后一个例子，比如说你希望观察一个孩子手部的X光照片，并估计一个孩子的年龄。你知道，当我第一次听到这个问题的时候，我以为这是一个非常酷的犯罪现场调查任务，你可能悲剧的发现了一个孩子的骨架，你想弄清楚孩子在生时是怎么样的。事实证明，这个问题的典型应用，从X射线图估计孩子的年龄，是我想太多了，没有我想象的犯罪现场调查脑洞那么大，结果这是儿科医生用来判断一个孩子的发育是否正常。 处理这个例子的一个非端到端方法，就是照一张图，然后分割出每一块骨头，所以就是分辨出那段骨头应该在哪里，那段骨头在哪里，那段骨头在哪里，等等。然后，知道不同骨骼的长度，你可以去查表，查到儿童手中骨头的平均长度，然后用它来估计孩子的年龄，所以这种方法实际上很好。 相比之下，如果你直接从图像去判断孩子的年龄，那么你需要大量的数据去直接训练。据我所知，这种做法今天还是不行的，因为没有足够的数据来用端到端的方式来训练这个任务。 你可以想象一下如何将这个问题分解成两个步骤，第一步是一个比较简单的问题，也许你不需要那么多数据，也许你不需要许多X射线图像来切分骨骼。而任务二，收集儿童手部的骨头长度的统计数据，你不需要太多数据也能做出相当准确的估计，所以这个多步方法看起来很有希望，也许比端对端方法更有希望，至少直到你能获得更多端到端学习的数据之前。 所以端到端深度学习系统是可行的，它表现可以很好，也可以简化系统架构，让你不需要搭建那么多手工设计的单独组件，但它也不是灵丹妙药，并不是每次都能成功。在下一个视频中，我想与你分享一个更系统的描述，什么时候你应该使用或者不应该使用端到端的深度学习，以及如何组装这些复杂的机器学习系统。 2.10 是否要使用端到端的深度学习？（Whether to use end-to-end learning?）假设你正在搭建一个机器学习系统，你要决定是否使用端对端方法，我们来看看端到端深度学习的一些优缺点，这样你就可以根据一些准则，判断你的应用程序是否有希望使用端到端方法。 这里是应用端到端学习的一些好处，首先端到端学习真的只是让数据说话。所以如果你有足够多的$(x,y)$数据，那么不管从$x$到$y$最适合的函数映射是什么，如果你训练一个足够大的神经网络，希望这个神经网络能自己搞清楚，而使用纯机器学习方法，直接从$x$到$y$输入去训练的神经网络，可能更能够捕获数据中的任何统计信息，而不是被迫引入人类的成见。 例如，在语音识别领域，早期的识别系统有这个音位概念，就是基本的声音单元，如cat单词的“cat”的Cu-、Ah-和Tu-，我觉得这个音位是人类语言学家生造出来的，我实际上认为音位其实是语音学家的幻想，用音位描述语言也还算合理。但是不要强迫你的学习算法以音位为单位思考，这点有时没那么明显。如果你让你的学习算法学习它想学习的任意表示方式，而不是强迫你的学习算法使用音位作为表示方式，那么其整体表现可能会更好。 端到端深度学习的第二个好处就是这样，所需手工设计的组件更少，所以这也许能够简化你的设计工作流程，你不需要花太多时间去手工设计功能，手工设计这些中间表示方式。 那么缺点呢？这里有一些缺点，首先，它可能需要大量的数据。要直接学到这个$x$到$y$的映射，你可能需要大量$(x,y)$数据。我们在以前的视频里看过一个例子，其中你可以收集大量子任务数据，比如人脸识别，我们可以收集很多数据用来分辨图像中的人脸，当你找到一张脸后，也可以找得到很多人脸识别数据。但是对于整个端到端任务，可能只有更少的数据可用。所以$x$这是端到端学习的输入端，$y$是输出端，所以你需要很多这样的$(x,y)$数据，在输入端和输出端都有数据，这样可以训练这些系统。这就是为什么我们称之为端到端学习，因为你直接学习出从系统的一端到系统的另一端。 另一个缺点是，它排除了可能有用的手工设计组件。机器学习研究人员一般都很鄙视手工设计的东西，但如果你没有很多数据，你的学习算法就没办法从很小的训练集数据中获得洞察力。所以手工设计组件在这种情况，可能是把人类知识直接注入算法的途径，这总不是一件坏事。我觉得学习算法有两个主要的知识来源，一个是数据，另一个是你手工设计的任何东西，可能是组件，功能，或者其他东西。所以当你有大量数据时，手工设计的东西就不太重要了，但是当你没有太多的数据时，构造一个精心设计的系统，实际上可以将人类对这个问题的很多认识直接注入到问题里，进入算法里应该挺有帮助的。 所以端到端深度学习的弊端之一是它把可能有用的人工设计的组件排除在外了，精心设计的人工组件可能非常有用，但它们也有可能真的伤害到你的算法表现。例如，强制你的算法以音位为单位思考，也许让算法自己找到更好的表示方法更好。所以这是一把双刃剑，可能有坏处，可能有好处，但往往好处更多，手工设计的组件往往在训练集更小的时候帮助更大。 如果你在构建一个新的机器学习系统，而你在尝试决定是否使用端到端深度学习，我认为关键的问题是，你有足够的数据能够直接学到从$x$映射到$y$足够复杂的函数吗？我还没有正式定义过这个词“必要复杂度（complexity needed）”。但直觉上，如果你想从$x$到$y$的数据学习出一个函数，就是看着这样的图像识别出图像中所有骨头的位置，那么也许这像是识别图中骨头这样相对简单的问题，也许系统不需要那么多数据来学会处理这个任务。或给出一张人物照片，也许在图中把人脸找出来不是什么难事，所以你也许不需要太多数据去找到人脸，或者至少你可以找到足够数据去解决这个问题。相对来说，把手的X射线照片直接映射到孩子的年龄，直接去找这种函数，直觉上似乎是更为复杂的问题。如果你用纯端到端方法，需要很多数据去学习。 视频最后我讲一个更复杂的例子，你可能知道我一直在花时间帮忙主攻无人驾驶技术的公司drive.ai，无人驾驶技术的发展其实让我相当激动，你怎么造出一辆自己能行驶的车呢？好，这里你可以做一件事，这不是端到端的深度学习方法，你可以把你车前方的雷达、激光雷达或者其他传感器的读数看成是输入图像。但是为了说明起来简单，我们就说拍一张车前方或者周围的照片，然后驾驶要安全的话，你必须能检测到附近的车，你也需要检测到行人，你需要检测其他的东西，当然，我们这里提供的是高度简化的例子。 弄清楚其他车和形如的位置之后，你就需要计划你自己的路线。所以换句话说，当你看到其他车子在哪，行人在哪里，你需要决定如何摆方向盘在接下来的几秒钟内引导车子的路径。如果你决定了要走特定的路径，也许这是道路的俯视图，这是你的车，也许你决定了要走那条路线，这是一条路线，那么你就需要摆动你的方向盘到合适的角度，还要发出合适的加速和制动指令。所以从传感器或图像输入到检测行人和车辆，深度学习可以做得很好，但一旦知道其他车辆和行人的位置或者动向，选择一条车要走的路，这通常用的不是深度学习，而是用所谓的运动规划软件完成的。如果你学过机器人课程，你一定知道运动规划，然后决定了你的车子要走的路径之后。还会有一些其他算法，我们说这是一个控制算法，可以产生精确的决策确定方向盘应该精确地转多少度，油门或刹车上应该用多少力。 所以这个例子就表明了，如果你想使用机器学习或者深度学习来学习某些单独的组件，那么当你应用监督学习时，你应该仔细选择要学习的$x$到$y$映射类型，这取决于那些任务你可以收集数据。相比之下，谈论纯端到端深度学习方法是很激动人心的，你输入图像，直接得出方向盘转角，但是就目前能收集到的数据而言，还有我们今天能够用神经网络学习的数据类型而言，这实际上不是最有希望的方法，或者说这个方法并不是团队想出的最好用的方法。而我认为这种纯粹的端到端深度学习方法，其实前景不如这样更复杂的多步方法。因为目前能收集到的数据，还有我们现在训练神经网络的能力是有局限的。 这就是端到端的深度学习，有时候效果拔群。但你也要注意应该在什么时候使用端到端深度学习。最后，谢谢你，恭喜你坚持到现在，如果你学完了上周的视频和本周的视频，那么我认为你已经变得更聪明，更具战略性，并能够做出更好的优先分配任务的决策，更好地推动你的机器学习项目，也许比很多机器学习工程师，还有和我在硅谷看到的研究人员都强。所以恭喜你学到这里，我希望你能看看本周的作业，应该能再给你一个机会去实践这些理念，并确保你掌握它们。]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础]]></title>
    <url>%2F2019%2F10%2F09%2Fpython%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[python基础 比心import time import os import math [([(time.sleep(a), print(&quot;\033[91m&quot;+i,end=&quot;&quot;,flush=True)) for i in (&#39;\n&#39;.join([&#39;&#39;.join([(&#39; I love U&#39;[(x-y)%9]if((x*0.05)**2+(y*0.1)**2-1)**3-(x*0.05)**2*(y*0.1)**3&lt;=0 else&#39; &#39;)for x in range(-30,30)])for y in range(15,-15,-1)]))] ,time.sleep(1/math.log(ai+3)), os.system(&#39;clear&#39;) ) for (ai,a) in enumerate([0.001,*[ 0.00001 ]*99])]![enter description here](https://www.github.com/OneJane/blog/raw/master/小书匠/1570610415940.png]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于selenium爬取智联招聘及国家企业信用信息公示系统]]></title>
    <url>%2F2019%2F09%2F18%2F%E5%9F%BA%E4%BA%8Eselenium%E7%88%AC%E5%8F%96%E6%99%BA%E8%81%94%E6%8B%9B%E8%81%98%E5%8F%8A%E5%9B%BD%E5%AE%B6%E4%BC%81%E4%B8%9A%E4%BF%A1%E7%94%A8%E4%BF%A1%E6%81%AF%E5%85%AC%E7%A4%BA%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[突破加密混淆的js文件，IP封锁，验证码识别（滑动和语序点击并存），useragent检查，多重url拼接cookie 智联招聘 通过获取链接返回的json数据拿到新的页面，selenium进行解析 class ZhilianSpider(scrapy.Spider): name = &#39;zhilian&#39; allowed_domains = [&#39;zhaopin.com&#39;] start_urls = [&#39;https://sou.zhaopin.com/&#39;] driver = None chrome_options = webdriver.ChromeOptions() # proxy_url = get_random_proxy() # print(proxy_url + &quot;代理服务器正在爬取&quot;) # chrome_options.add_argument(&#39;--proxy-server=https://&#39; + proxy_url.strip()) prefs = { &#39;profile.default_content_setting_values&#39;: { &#39;images&#39;: 1, # 不加载图片 &quot;User-Agent&quot;: UserAgent().random, # 更换UA } } chrome_options.add_experimental_option(&quot;prefs&quot;, prefs) if platform.system() == &quot;Windows&quot;: driver = webdriver.Chrome(&#39;chromedriver.exe&#39;, chrome_options=chrome_options) elif platform.system() == &quot;Linux&quot;: chrome_options.add_argument(&quot;--headless&quot;) chrome_options.add_argument(&#39;--disable-gpu&#39;) chrome_options.add_argument(&#39;--no-sandbox&#39;) driver = webdriver.Chrome( executable_path=&quot;/usr/bin/chromedriver&quot;, chrome_options=chrome_options) wait = WebDriverWait(driver, 15) def start_requests(self): data = [&quot;游戏&quot;, &quot;期货&quot;, &quot;贷款&quot;] for kw in data: yield Request( url=&quot;https://fe-api.zhaopin.com/c/i/sou?start=0&amp;pageSize=90&amp;cityId=639&amp;salary=0,0&amp;workExperience=-1&amp;education=-1&amp;companyType=-1&amp;employmentType=-1&amp;jobWelfareTag=-1&amp;kw=&quot; + kw + &quot;&amp;kt=3&quot;, meta={&quot;kw&quot;: kw}, callback=self.parse_pages) # response获取meta def parse_pages(self, response): numtotal = json.loads(response.text)[&quot;data&quot;][&quot;count&quot;] kw = response.meta.get(&quot;kw&quot;, &quot;游戏&quot;) for i in range(0, numtotal // 90 + 1): url = &quot;https://fe-api.zhaopin.com/c/i/sou?start=&quot; + str( 90 * i) + &quot;&amp;pageSize=90&amp;cityId=639&amp;salary=0,0&amp;workExperience=-1&amp;education=-1&amp;companyType=-1&amp;employmentType=-1&amp;jobWelfareTag=-1&amp;kw=&quot; + kw + &quot;&amp;kt=3&quot; yield Request( url=url, meta={&quot;kw&quot;: kw}, callback=self.parse) # response获取meta def parse(self, response): job_list = json.loads(response.text)[&quot;data&quot;][&quot;results&quot;] for job in job_list: yield Request(url=job[&quot;positionURL&quot;], callback=self.parse_detail, meta={&#39;cookiejar&#39;: &#39;chrome&#39;, &#39;kw&#39;: response.meta.get(&quot;kw&quot;, &quot;&quot;)}) def parse_detail(self, response): print(response.url) self.driver.get(response.url) self.driver.refresh() time.sleep(2) self.driver.implicitly_wait(20) dom = etree.HTML(self.driver.page_source) item = JobItem() item[&#39;recruitment_position&#39;] = null_if(dom.xpath(&#39;//*[@class=&quot;summary-plane__title&quot;]&#39;)) item[&#39;salary&#39;] = null_if(dom.xpath(&#39;//*[@class=&quot;summary-plane__salary&quot;]&#39;)) item[&#39;company_name&#39;] = dom.xpath(&#39;//*[@class=&quot;company__title&quot;]&#39;)[0].text item[&#39;work_experience&#39;] = dom.xpath(&#39;//ul[@class=&quot;summary-plane__info&quot;]/li[2]&#39;)[0].text item[&#39;education_background&#39;] = dom.xpath(&#39;//ul[@class=&quot;summary-plane__info&quot;]/li[3]&#39;)[0].text item[&#39;job_requirements&#39;] = remove_html( etree.tostring(dom.xpath(&#39;//div[@class=&quot;describtion__detail-content&quot;]&#39;)[0], encoding=&quot;utf-8&quot;).decode( &#39;utf-8&#39;)) item[&#39;company_info&#39;] = null_if(dom.xpath(&#39;//div[@class=&quot;company__description&quot;]&#39;)) item[&#39;company_address&#39;] = remove_html( etree.tostring(dom.xpath(&#39;//span[@class=&quot;job-address__content-text&quot;]&#39;)[0], encoding=&quot;utf-8&quot;).decode( &#39;utf-8&#39;)) if len(dom.xpath(&#39;//div[@class=&quot;highlights__content&quot;]&#39;)): item[&#39;company_welfare&#39;] = remove_html(etree.tostring(dom.xpath(&#39;//div[@class=&quot;highlights__content&quot;]&#39;)[0], encoding=&quot;utf-8&quot;).decode(&#39;utf-8&#39;)) else: item[&#39;company_welfare&#39;] = &#39;无&#39; item[&#39;id&#39;] = get_md5(self.driver.current_url) item[&#39;keyword&#39;] = response.meta.get(&quot;kw&quot;, &quot;&quot;) item[&#39;url&#39;] = response.url item[&#39;crawl_date&#39;] = datetime.now().strftime(&quot;%Y-%m-%d&quot;) yield item 国家企业信用信息系统获取cookiecrack.py class Crack(object): &quot;&quot;&quot; 同一ip频繁使用： 出现正常200但是没有结果 第一次解密出来是错误的 &quot;&quot;&quot; def __init__(self, url, test_url): path = os.getcwd() with open(os.path.join(path, &quot;wc_js.js&quot;), encoding=&#39;utf-8&#39;) as f: wc_js = f.read() self.wc_js = execjs.compile(wc_js) self.url = url self.test_url = test_url # 固定user_agent,后台使用user-agent验证cookies, 之后的访问也需要使用这个 self.headers = { &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.96 Safari/537.36&#39; } def acquire_js(self): &quot;&quot;&quot; 不带cookies请求首页，获得返回的js :return:页面中的js,和set_cookies中的jsluid &quot;&quot;&quot; response = requests.get(self.url, headers=self.headers) if response.status_code == 521: return response.text, response.headers[&#39;Set-Cookie&#39;].split(&#39;=&#39;)[1].split(&#39;;&#39;)[0] else: print(response.text) print(self.headers) return None, None def first_decryption(self, first_js): &quot;&quot;&quot; 解密js,获得第二层加密的js :param first_js: :return: &quot;&quot;&quot; x = re.findall(&#39;var x=&quot;(.*?)&quot;&#39;, first_js)[0] y = re.findall(&#39;,y=&quot;(.*?)&quot;&#39;, first_js)[0] second_js = self.wc_js.call(&#39;once_js&#39;, x, y) # second_js = self.wc_js.call(&#39;get_js&#39;, x, y, z) return second_js def regex(self, js): regex = &quot;!*window\[.*?\]&quot; find = re.findall(regex, js) if find: for f in find: if &#39;!&#39; in f: if len(re.findall(&#39;!&#39;, f)) % 2 == 0: js = js.replace(f, &#39;false&#39;) else: js = js.replace(f, &#39;true&#39;) else: js = js.replace(f, &#39;undefined&#39;) js = js.replace(&#39;window.headless&#39;, &#39;undefined&#39;) return js def replace_url(self, js): # 替换1 # 取出两个变量名 _3d = re.findall(&quot;(var .{0,5}=)document\.createElement\(&#39;div&#39;\);&quot;, js) _2b = re.findall(&quot;(var .{0,5}=).{0,5}\.match\(/https\?:\\\/\\\//\)\[0\];&quot;, js) # 替换成要访问的url js = re.sub(&quot;var .{0,5}=document\.createElement\(&#39;div&#39;\);&quot;, _3d[0] + f&#39;&quot;{self.url.replace(&quot;http://&quot;, &quot;&quot;)}&quot;;&#39;, js) js = re.sub(&quot;_.{0,5}\.innerHTML=&#39;&lt;a href=.{0,25}&lt;/a&gt;&#39;;&quot;, &quot;&quot;, js) js = re.sub(&quot;_.{0,5}=.{0,5}\.firstChild\.href;&quot;, &quot;&quot;, js) js = re.sub(&quot;var .{0,5}=.{0,5}\.match\(/https\?:\\\/\\\//\)\[0\];&quot;, _2b[0] + &#39;&quot;http://&quot;;&#39;, js) js = re.sub(&quot;_.{0,5}=.{0,5}\.substr\(.{0,5}\.length\)\.toLowerCase\(\);&quot;, &quot;&quot;, js) return js def second_decryption(self, second_js): &quot;&quot;&quot; 把第二层js准换成本地可以运行的js !!!此处可能会出错!!! :param second_js: 第一次解密的js :return: __jsl_clearance的值 &quot;&quot;&quot; # 转义字符 js = second_js.replace(&#39;\\\\&#39;, &#39;\\&#39;) # 切割 js = &#39;cookie&#39; + js.split(&#39;document.cookie&#39;)[1] js = js.split(&#39;GMT;Path=/;&#39;)[0] + &quot;&#39;&quot; if re.findall(&quot;(var .{0,5}=)document\.createElement\(&#39;div&#39;\);&quot;, js): js = self.replace_url(js) # 替换可能出现的window js = self.regex(js) s = &quot;&quot;&quot; function cook() { %s return cookie } &quot;&quot;&quot; new_js = s % js ctx = execjs.compile(new_js) # 切割获得的__jsl_clearance jsl = ctx.call(&#39;cook&#39;) jsl = jsl.split(&#39;;&#39;)[0] jsl_clearance = jsl.split(&#39;=&#39;)[1] return jsl_clearance def test_cookies(self, jsluid, jsl_clearance): &quot;&quot;&quot; 带cookies访问,测试拿到的是否正确 :param jsluid:cookies中的参数 :param jsl_clearance: cookies中的参数 :return: &quot;&quot;&quot; headers = self.headers.copy() headers[&#39;Cookie&#39;] = f&#39;__jsluid_h={jsluid}; __jsl_clearance={jsl_clearance};&#39; response = requests.get(self.test_url, headers=headers) print(response.text) return response.status_code def run(self): while True: first_js, jsluid = self.acquire_js() second_js = self.first_decryption(first_js) try: jsl_clearance = self.second_decryption(second_js) except: # print(second_js) continue else: code = self.test_cookies(jsluid, jsl_clearance) if code == 200: return jsluid, jsl_clearance else: print(code) # print(second_js) continue if __name__ == &#39;__main__&#39;: # # 企业信息公示系统 url = &quot;http://www.gsxt.gov.cn/index.html&quot; test_url = &quot;http://www.gsxt.gov.cn/index.html&quot; # # 66代理 # url = &quot;http://www.66ip.cn/2.html&quot; # test_url = &quot;http://www.66ip.cn/2.html&quot; # # 公安部网站 # url = &#39;http://www.mps.gov.cn/&#39; # test_url = &#39;http://www.mps.gov.cn/&#39; ck = Crack(url, test_url) jsluid, jsl_clearance = ck.run() print(&#39;jsluid:&#39;, jsluid) print(&#39;jsl_clearance:&#39;, jsl_clearance) 利用超级鹰破解验证码class SearchResultParse(object): &#39;&#39;&#39;查询结果页解析 &#39;&#39;&#39; def __init__(self, pagesource, base_url, parse_rule): self.selector = etree.HTML(pagesource) self.url_list = [] self.base_url = base_url self.parse_rule = parse_rule[&#39;search_result_url&#39;] def search_result_parse(self): self.url_list = [self.base_url + i for i in self.selector.xpath(self.parse_rule)] return self.url_list class PageDetailParse(object): &#39;&#39;&#39;详情页解析 &#39;&#39;&#39; def __init__(self, pagesource, parse_rule): self.selector = etree.HTML(pagesource) self.parse_rule = parse_rule self.info_list = {} def search_result_parse(self, primary_info=None): if primary_info is None: primary_info = [] for i in self.parse_rule[&#39;primaryinfo&#39;]: primary_info.append( self.selector.xpath(i).replace(&quot;\n&quot;, &quot;&quot;).replace(&quot;\t&quot;, &quot;&quot;).replace(&quot;\r&quot;, &quot;&quot;).replace(&quot; &quot;, &quot;&quot;)) self.info_list[&#39;primary_info&#39;] = primary_info return self.info_list class CookieRequest(object): &#39;&#39;&#39;带cookie访问查询结果 &#39;&#39;&#39; def __init__(self, url_list=None): &#39;&#39;&#39;设置requests中的session的cookie &#39;&#39;&#39; self.url_list = url_list self.session = requests.Session() self.result = [] self.headers = { &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.96 Safari/537.36&#39; } def cookie_requests(self): &#39;&#39;&#39;带cookie依次访问各个查询结果 &#39;&#39;&#39; url = &quot;http://www.gsxt.gov.cn/index.html&quot; test_url = &quot;http://www.gsxt.gov.cn/corp-query-entprise-info-hot-search-list.html?province=100000&quot; ck = Crack(url, test_url) jsluid, jsl_clearance, JSESSIONID = ck.run() self.headers[&#39;Cookie&#39;] = f&#39;__jsluid_h={jsluid}; __jsl_clearance={jsl_clearance};JSESSIONID={JSESSIONID}&#39; for url in self.url_list: response = self.session.get(url=url, headers=self.headers) self.result.append(response.text) time.sleep(5) return self.result class MaxEnterError(Exception): &#39;&#39;&#39;输入关键字最大尝试次数 &#39;&#39;&#39; def __init__(self, ErrorInfo): super().__init__(self) # 初始化父类 self.errorinfo = ErrorInfo def __str__(self): return self.errorinfo class GtClickShot(object): def __init__(self, username, password,soft_id): &#39;&#39;&#39;初始化超级鹰 softid已固化到程序 args: username(str):超级鹰普通用户名 password(str):超级鹰密码 &#39;&#39;&#39; self.username = username self.password = md5(password.encode(&quot;utf-8&quot;)).hexdigest() self.soft_id = soft_id self.base_params = { &#39;user&#39;: self.username, &#39;pass2&#39;: self.password, &#39;softid&#39;: self.soft_id, } self.headers = { &#39;Connection&#39;: &#39;Keep-Alive&#39;, &#39;User-Agent&#39;: &#39;Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)&#39;, } def PostPic(self, im, codetype): &quot;&quot;&quot;发送图片至打码平台 args： im(Byte): 图片字节 codetype(str): 题目类型 参考 http://www.chaojiying.com/price.html return(json):返回打码信息，包含坐标信息，坐标信息用“|”隔开 &quot;&quot;&quot; params = { &#39;codetype&#39;: codetype, } params.update(self.base_params) files = {&#39;userfile&#39;: (&#39;ccc.jpg&#39;, im)} r = requests.post(&#39;http://upload.chaojiying.net/Upload/Processing.php&#39;, data=params, files=files, headers=self.headers) return r.json() def ReportError(self, im_id): &quot;&quot;&quot;识别错误返回题分 args： im_id(str):报错题目的图片ID return(str):报错反馈 &quot;&quot;&quot; params = { &#39;id&#39;: im_id, } params.update(self.base_params) r = requests.post(&#39;http://upload.chaojiying.net/Upload/ReportError.php&#39;, data=params, headers=self.headers) return r.json() class CorpSearch(object): def __init__(self, init_url, index_url, headers, max_click): &#39;&#39;&#39;初始化 args: init_url:初始化url,加速乐反爬JS要求访问目标网站前需先访问初始化url获取gt和challenge index_url:目标网站首页url headers：请求头信息 max_click：最大循环点击次数为了应对点击不灵敏，设置循环检查点击。 self.wait:默认条件等待最大时间 self.click_valitimes:点击验证次数，大于0时需返回题分，等于0时不需要 &#39;&#39;&#39; chrome_options = webdriver.ChromeOptions() prefs = { &#39;profile.default_content_setting_values&#39;: { &#39;images&#39;: 1, # 加载图片 &quot;User-Agent&quot;: UserAgent().random, # 更换UA } } chrome_options.add_experimental_option(&quot;prefs&quot;, prefs) self.init_url = init_url self.index_url = index_url if platform.system() == &quot;Windows&quot;: self.driver = webdriver.Chrome(&#39;chromedriver.exe&#39;, chrome_options=chrome_options) elif platform.system() == &quot;Linux&quot;: chrome_options.add_argument(&quot;--headless&quot;) chrome_options.add_argument(&#39;--disable-gpu&#39;) chrome_options.add_argument(&#39;--no-sandbox&#39;) self.driver = webdriver.Chrome( executable_path=&quot;/usr/bin/chromedriver&quot;, chrome_options=chrome_options) self.wait = WebDriverWait(self.driver, 50) self.max_entertimes = max_click self.click_valitimes = 0 self.action = ActionChains(self.driver) self.gt_shot = GtClickShot(&quot;zhaoys&quot;, &quot;501314&quot;,&quot;901554&quot;) self.options = webdriver.ChromeOptions() self.headers = headers for option in self.headers: self.options.add_argument(option) # 初始化页面，绕过过加速乐反爬，获取gt和challenge,并加载进入首页 def init(self): &#39;&#39;&#39; 请求初始化网站，并进入首页 &#39;&#39;&#39; self.driver.get(self.init_url) self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, &quot;body &gt; pre:nth-child(1)&quot;))) self.driver.get(self.index_url) # 加载首页，输入查询关键词，点击查询按钮 # 如果点击按钮失效,自动重新回车，并设定最大回车次数，一旦超过设定值，抛出异常，结束程序 def input_query(self, keyword): &#39;&#39;&#39;输入关键词进行查询 args: keyword:查询关键词 return: 仅用于方法返回 &#39;&#39;&#39; enter_word = self.wait.until(EC.presence_of_element_located((By.ID, &quot;keyword&quot;))) self.wait.until(EC.presence_of_element_located((By.ID, &quot;btn_query&quot;))) time.sleep(random.randint(8, 15) / 10) enter_word.send_keys(keyword) time.sleep(random.randint(5, 10) / 10) enter_word.send_keys(Keys.ENTER) while True: if self.max_entertimes == 0: raise MaxEnterError(&#39;---Out of max times on the search enter---&#39;) gt_panel = self.driver.find_element_by_css_selector(&quot;body &gt; div.geetest_panel.geetest_wind&quot;) style_value = gt_panel.value_of_css_property(&quot;display&quot;) if style_value.strip() == &quot;block&quot;: break else: enter_word.send_keys(Keys.ENTER) time.sleep(random.randint(1, 5) / 10) self.max_entertimes -= 1 return # 判断页面中是否包含某个元素，注意是class_name def is_element_exist(self, class_name): &#39;&#39;&#39;判断某个元素是否存在 args: class_name:元素class属性名称 return: 存在(True),不存在(False) &#39;&#39;&#39; try: self.driver.find_element_by_class_name(class_name) return True except: return False # 屏幕截图，并将截图内容读入内存，加速计算操作 def get_screenshot(self): &#39;&#39;&#39;屏幕截图 return: 返回截图 &#39;&#39;&#39; screenshot = self.driver.get_screenshot_as_png() screenshot = Image.open(BytesIO(screenshot)) return screenshot # 获取验证验证码图片的位置，用于裁图 def get_position(self, pos_img): &#39;&#39;&#39;验证图片的坐标尺寸信息 args: pos_img:验证码定位点元素 return: 验证码定位点的坐标信息，注意依次为：左底，左高，右高，右底 &#39;&#39;&#39; location = pos_img.location size = pos_img.size top, bottom, left, right = location[&#39;y&#39;], location[&#39;y&#39;] + size[&#39;height&#39;], location[&#39;x&#39;], location[&#39;x&#39;] + size[ &#39;width&#39;] return (left, top, right, bottom) # 对于滑块验证码，获取完整的和缺块的验证码图片截图 def get_slide_images(self): &#39;&#39;&#39;获取有缺口和没缺口的图片 &#39;&#39;&#39; canvas_img = self.wait.until( EC.presence_of_element_located((By.CSS_SELECTOR, &quot;.geetest_canvas_img.geetest_absolute &gt; div&quot;))) position = self.get_position(canvas_img) befor_screenshot = self.get_screenshot() befor_img = befor_screenshot.crop(position) befor_img.save(&quot;befor_click.png&quot;) btn_slide = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, &quot;geetest_slider_button&quot;))) self.action.click_and_hold(btn_slide).perform() after_screenshot = self.get_screenshot() after_img = after_screenshot.crop(position) after_img.save(&quot;after_click.png&quot;) # 获取缺口位置，计算滑动距离（灰度化，求差值，阈值去燥，计算缺口位置，计算滑动距离） def get_slide_distance(self): &#39;&#39;&#39;获取滑动距离 return: 返回滑动距离 &#39;&#39;&#39; befor_click_img = &quot;F:\\Anaconda3\\Lib\\captcha\\gt_validate\\befor_click.png&quot; after_click_path = &quot;F:\\Anaconda3\\Lib\\captcha\\gt_validate\\after_click.png&quot; befor_img = cv2.imread(befor_click_img) after_img = cv2.imread(after_click_path) befor_gray = cv2.cvtColor(befor_img, cv2.COLOR_BGR2GRAY) after_gray = cv2.cvtColor(after_img, cv2.COLOR_BGR2GRAY) img_diff = np.array(befor_gray) - np.array(after_gray) height, width = img_diff.shape for i in range(height): for j in range(width): if img_diff[i][j] &gt; 245 or img_diff[i][j] &lt; 60: img_diff[i][j] = 0 start_position = random.choice([4, 5, 6]) reshape_img = img_diff.T sum_color = list(map(lambda x: sum(x), reshape_img)) for i in range(1, len(sum_color)): if sum_color[i] &gt; 1000 and i &gt; 60: end_position = i break slide_distance = end_position - start_position return slide_distance # 模拟鼠标轨迹，按照开始慢加速（2），中间快加速（5），后面慢加速（2），最后慢减速的方式（1） # 返回值是x值与Y值坐标以及sleep时间截点，起始中间最后都要sleep def get_track(self, distance, track_list=None): &#39;&#39;&#39;获取滑动轨迹 args: distance:滑动距离 kargs: Track_list:滑动轨迹，初始化为空 return: 滑动轨迹，断点位置(2处) &#39;&#39;&#39; if track_list is None: track_list = [] base = distance / 10 x1 = round(base * 2) x2 = round(base * 5) x3 = x1 x4 = distance - x1 - x2 - x3 ynoise_num = random.randint(5, 10) y1 = [random.randint(-2, 2) for _ in range(ynoise_num)] yrdm = list(set(random.choice(range(distance)) for _ in range(ynoise_num))) x = [1] * distance y = [0] * distance for i, j in enumerate(yrdm): y[j] = y1[i] t1 = sorted([random.randint(8, 13) / 1000 for _ in range(x1)], reverse=True) t2 = sorted([random.randint(1, 8) / 1000 for _ in range(x2)], reverse=True) t3 = sorted([random.randint(8, 13) / 1000 for _ in range(x3)], reverse=True) t4 = sorted([random.randint(12, 20) / 1000 for _ in range(x4)]) t = t1 + t2 + t3 + t4 for i in (zip(x, y, t)): track_list.append(i) return (track_list, x1 + x2, x1 + x2 + x3) # 对于点击验证码，获取验证码的校验文字和待点击图片截图,以及验证码弹框元素 def get_click_images(self): &#39;&#39;&#39;获取需点击的图片 return: 需点击坐标的图片， 提示图片(用于调试打码时的计算点击次数)， 验证码图片定位元素(用于定位鼠标位置并计算相对坐标) &#39;&#39;&#39; click_img_element = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, &quot;geetest_widget&quot;))) self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, &quot;geetest_item_img&quot;))) time.sleep(random.randint(1, 5) / 10) click_position = self.get_position(click_img_element) all_screenshot = self.get_screenshot() click_img = all_screenshot.crop(click_position) click_img.save(&quot;click_img.png&quot;) tip_img = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, &quot;geetest_tip_img&quot;))) tip_position = self.get_position(tip_img) tip_img = all_screenshot.crop(tip_position) tip_img.save(&quot;tip_img.png&quot;) return (click_img, tip_img, click_img_element) # 计算要点击的字符数量，灰度化，反向二值化,转置，沿X坐标对Y求和，判断分割点数量，判断字符数量 def cal_char_num(self, char_img_path): &#39;&#39;&#39;计算需点击的字符数量 args: char_img_path:提示图片的存储路径 return: 点击次数 &#39;&#39;&#39; flag = 0 origin_img = cv2.imread(char_img_path) gray_img = cv2.cvtColor(origin_img, cv2.COLOR_BGR2GRAY) ret, thresh1 = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY_INV) transpos_img = np.array(thresh1).T result = list(map(lambda x: sum(x), transpos_img)) for i in range(len(result) - 3): if result[i] == 0 and result[i + 1] == 0 and result[i + 2] &gt; 0: flag += 1 return flag # 返回验证码字符的坐标，每个点击点的坐标,并转化为整数坐标 def char_absolute_coord(self, img, num, coord=None): &#39;&#39;&#39;调试用，点击验证码图片返回整数值坐标 args: img:验证码图片 num：点击次数 kargs: coord:验证码字符坐标 return: 字符坐标 &#39;&#39;&#39; if coord is None: coord = [] img = Image.open(img) plt.imshow(img) points = plt.ginput(num) plt.close() for i in points: x_co, y_co = i coord.append((round(x_co), round(y_co))) return coord # 返回从起点开始依次到每个点击文字的相对位置，形式为[(xoffset,yoffset),(),(),...] def get_offset_coord(self, absolute_coord, click_track=None): &#39;&#39;&#39;获取相邻点击字符的相对坐标，用于鼠标移动点击 args: absolute_coord：验证码字符的绝对坐标 kargs: click_track:每个需点击字符间的相对坐标或位移 return: 相对坐标或位移 &#39;&#39;&#39; if click_track is None: click_track = [] for i, j in enumerate(absolute_coord): if i == 0: click_track.append(j) else: click_track.append((j[0] - absolute_coord[i - 1][0], j[1] - absolute_coord[i - 1][1])) return click_track # 验证点击验证码,获取验证码数量，人工点击，按照计算的坐标相对偏移位置，依次点击文字进行验证 # 通过打码平台，将验证码图片发送后返回坐标信息，通过超级鹰打码平台 def click_captcha_validate(self): &#39;&#39;&#39;根据打码平台返回的坐标进行验证 return: 仅仅用于方法返回 &#39;&#39;&#39; click_img, tip_img, click_img_element = self.get_click_images() bytes_array = BytesIO() click_img.save(bytes_array, format=&quot;PNG&quot;) coord_result = self.gt_shot.PostPic(bytes_array.getvalue(), &quot;9005&quot;) print(coord_result) groups = coord_result.get(&quot;pic_str&quot;).split(&#39;|&#39;) if groups == &quot;&quot;: raise RuntimeError(&quot;打码超时&quot;) pic_id = coord_result.get(&quot;pic_id&quot;) points = [[int(num) for num in group.split(&#39;,&#39;)] for group in groups] # tip_img_path=&quot;D:\\Anaconda3\\Lib\\captcha\\gt_validate\\tip_img.png&quot; # click_img_path=&quot;D:\\Anaconda3\\Lib\\captcha\\gt_validate\\click_img.png&quot; # num=self.cal_char_num(tip_img_path) # points=self.char_absolute_coord(click_img_path,num) mouse_track = self.get_offset_coord(points) print(mouse_track) self.action.move_to_element_with_offset(click_img_element, 0, 0) for position in mouse_track: self.action.move_by_offset(position[0], position[1]) self.action.click() self.action.pause(random.randint(3, 7) / 10) self.action.perform() time.sleep(random.randint(4, 6) / 10) click_submit_btn = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, &#39;geetest_commit_tip&#39;))) click_submit_btn.click() self.action.reset_actions() self.valide_process(pic_id=pic_id) return # 验证滑动验证码，获取滑动距离和滑动轨迹，分别在起始，中间，结束时随机停顿 def slide_captcha_validate(self): &#39;&#39;&#39;滑动验证码验证 return: 仅仅用于方法返回 &#39;&#39;&#39; self.get_slide_images() distance = self.get_slide_distance() track, p1, p2 = self.get_track(distance) time.sleep(random.randint(3, 7) / 10) for i, j in enumerate(track): if i == p1 or i == p2: time.sleep(random.randint(3, 7) / 10) self.action.move_by_offset(j[0], j[1]) time.sleep(j[2]) time.sleep(random.randint(3, 7) / 10) self.action.release() self.valide_process() return # 验证是否成功破解，设置重启机制 # 超过最大验证次数需点击“点击此处重试” def valide_process(self, pic_id=None): &#39;&#39;&#39;验证过程 1&gt;判断极验弹框消失且查询结果框出现，验证成功，结束验证； 2&gt;第一步验证失败，超时； 3&gt;超时原因：极验验证框没消失(跳转至第4步)或查询结果框没出现(跳转至第6步)； 4&gt;极验验证框没消失，检验是否超过最大验证次数，如果是，需点击重试，跳至第7步，如果不是，跳至第5步； 5&gt;如果不是，判断验证类型，调用响应验证方法，跳至第1步； 6&gt;如果查询结果框没出现，直接退出关闭浏览器； 7&gt;点击重试时，如果是空白响应则退出浏览器，或者判断验证类型，调用响应验证方法，跳至第1步。 args: cap_type:验证码类型 pic_id:点击类验证码图片id return: 要么验证成功，要么退出浏览器 &#39;&#39;&#39; try: WebDriverWait(self.driver, 3).until_not( EC.visibility_of_element_located((By.CSS_SELECTOR, &quot;body &gt; div.geetest_panel&quot;))) WebDriverWait(self.driver, 10).until(EC.visibility_of_element_located((By.ID, &quot;advs&quot;))) print(&quot;Validate Successful&quot;) return except TimeoutException: try: gt_panel_error = self.driver.find_element_by_css_selector( &quot;body &gt; div.geetest_panel.geetest_wind &gt; div.geetest_panel_box &gt; div.geetest_panel_error&quot;) error_display = gt_panel_error.value_of_css_property(&quot;display&quot;) if error_display.strip() == &quot;block&quot;: gt_panel_error_content = self.driver.find_element_by_css_selector( &quot;.geetest_panel_error &gt; div.geetest_panel_error_content&quot;) self.action.move_to_element(gt_panel_error_content).click().perform() self.action.reset_actions() try: WebDriverWait(self.driver, 3).until_not( EC.visibility_of_element_located((By.CSS_SELECTOR, &quot;body &gt; div.geetest_panel&quot;))) WebDriverWait(self.driver, 10).until(lambda x: x.find_element_by_id(&#39;advs&#39;).is_displayed()) print(&quot;Validate Successful&quot;) return except TimeoutException: self.slide_orclick_validate(pic_id) else: self.slide_orclick_validate(pic_id) except: print(&#39;error occured&#39;) return # 判断是执行点击还是滑块 def slide_orclick_validate(self, pic_id=None): &#39;&#39;&#39;判断下一步是选择滑动验证还是点击验证还是退出浏览器 args: pic_id:点击类验证码图片id return: 要么滑动验证，要么点击验证，要么None &#39;&#39;&#39; try: WebDriverWait(self.driver, 3).until(EC.presence_of_element_located((By.CLASS_NAME, &quot;geetest_close&quot;))) print(&#39;Validate Failed,retry again&#39;) if self.is_element_exist(&quot;geetest_canvas_img&quot;): print(&#39;captcha type is slide&#39;) return self.slide_captcha_validate() else: print(&#39;captcha type is click&#39;) if self.click_valitimes &gt; 0: self.gt_shot.ReportError(pic_id) self.click_valitimes += 1 return self.click_captcha_validate() except: print(&quot;Directly no click or slide validate&quot;) return # 带cookie切换至首页继续检索 def switch_hmpg(self): &#39;&#39;&#39;由结果页切换至首页 return: 用于方法返回 &#39;&#39;&#39; self.wait.until(EC.presence_of_element_located((By.ID, &quot;advs&quot;))) hmpg_btn = self.driver.find_element_by_css_selector( &quot;body &gt; div.container &gt; div.header_box &gt; div &gt; div &gt; a:nth-child(1)&quot;) self.action.move_to_element(hmpg_btn).click().perform() self.action.reset_actions() self.wait.until(lambda x: x.find_element_by_id(&#39;btn_query&#39;).is_displayed()) return # 通过index界面或者点击首页继续检索时的爬取步骤 def main(self, keyword, start_pg=None): &#39;&#39;&#39;操作主程序 args: keyword:查询关键词 kargs: start_pg:是否需要初始化访问加速乐，默认要 &#39;&#39;&#39; if start_pg == &quot;homepage&quot;: self.switch_hmpg() else: self.init() self.input_query(keyword) self.slide_orclick_validate() # 保存cookie和检索结果，用于requests及详情解析 def to_dict(self): &#39;&#39;&#39;保存cookie（用于requests请求及详情解析）和查询结果 args: cookie_name:cookie文件名称 &#39;&#39;&#39; htmlpage = self.driver.page_source return { &#39;page&#39;: htmlpage } if __name__ == &#39;__main__&#39;: init_url = &quot;http://www.gsxt.gov.cn/SearchItemCaptcha&quot; index_url = &quot;http://www.gsxt.gov.cn/index.html&quot; base_url = &#39;http://www.gsxt.gov.cn&#39; result_parse_rule = {&#39;search_result_url&#39;: &#39;//*[@id=&quot;advs&quot;]/div/div[2]/a/@href&#39;} detail_parse_rule = { &#39;primaryinfo&#39;: [&#39;string(//*[@id=&quot;primaryInfo&quot;]/div/div[@class=&quot;overview&quot;]/dl[{}])&#39;.format(i) for i in range(15)], } max_click = 10 chm_headers = [&#39;Host=&quot;www.gsxt.gov.cn&quot;&#39;, &#39;Connection=&quot;keep-alive&quot;&#39;, &#39;User-Agent=&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&quot;&#39;, &#39;Upgrade-Insecure-Requests=1&#39;, &#39;Accept=&quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&quot;&#39;, &#39;Accept-Encoding=&quot;gzip, deflate&quot;&#39;, &#39;Accept-Language=&quot;zh-CN,zh;q=0.9&quot;&#39;] search = CorpSearch(init_url, index_url, chm_headers, max_click) search.main(&quot;腾讯&quot;) cookie_html = search.to_dict() search_result = SearchResultParse(cookie_html[&#39;page&#39;], base_url, result_parse_rule) url_list = search_result.search_result_parse() detail_request = CookieRequest(url_list=url_list) detail_result = detail_request.cookie_requests() for pg in detail_result: pg_detail = PageDetailParse(pg, detail_parse_rule) detail = pg_detail.search_result_parse() m = re.findall(r&#39;\[(.*?)\]&#39;, str(detail)) info_list = m[0].replace(&#39;\&#39;&#39;, &#39;&#39;).split(&#39;, &#39;) sql = &quot;insert into company(code,name,type,start,end,) values(%s,%s,%s,%s.%s)&quot; count, rt_list = MysqlConnection.execute_sql(sql, (info_list[0],info_list[1],info_list[2],info_list[3]))爬虫实现class EnterPriseSpider(scrapy.Spider): name = &#39;enterprise&#39; allowed_domains = [&#39;gsxt.gov.cn&#39;] start_urls = [&#39;http://www.gsxt.gov.cn/index.html&#39;] def __init__(self, word=None, *args, **kwargs): super(eval(self.__class__.__name__), self).__init__(*args, **kwargs) self.word = word def start_requests(self): init_url = &quot;http://www.gsxt.gov.cn/SearchItemCaptcha&quot; index_url = &quot;http://www.gsxt.gov.cn/index.html&quot; base_url = &#39;http://www.gsxt.gov.cn&#39; result_parse_rule = {&#39;search_result_url&#39;: &#39;//*[@id=&quot;advs&quot;]/div/div[2]/a/@href&#39;} max_click = 10 chm_headers = [&#39;Host=&quot;www.gsxt.gov.cn&quot;&#39;, &#39;Connection=&quot;keep-alive&quot;&#39;, &#39;User-Agent=&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&quot;&#39;, &#39;Upgrade-Insecure-Requests=1&#39;, &#39;Accept=&quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&quot;&#39;, &#39;Accept-Encoding=&quot;gzip, deflate&quot;&#39;, &#39;Accept-Language=&quot;zh-CN,zh;q=0.9&quot;&#39;] search = CorpSearch(init_url, index_url, chm_headers, max_click) search.main(self.word) cookie_html = search.to_dict() search_result = SearchResultParse(cookie_html[&#39;page&#39;], base_url, result_parse_rule) url_list = search_result.search_result_parse() yield Request(url=&quot;https://www.baidu.com/&quot;,callback=self.parse, meta={&#39;url_list&#39;: url_list}) def parse(self, response): detail_parse_rule = { &#39;primaryinfo&#39;: [&#39;string(//*[@id=&quot;primaryInfo&quot;]/div/div[@class=&quot;overview&quot;]/dl[{}])&#39;.format(i) for i in range(15)], } url_list = response.meta.get(&quot;url_list&quot;, &quot;&quot;) detail_request = CookieRequest(url_list=url_list) detail_result = detail_request.cookie_requests() for pg in detail_result: pg_detail = PageDetailParse(pg, detail_parse_rule) detail = pg_detail.search_result_parse() m = re.findall(r&#39;\[(.*?)\]&#39;, str(detail)) info_list = m[0].replace(&#39;\&#39;&#39;, &#39;&#39;).split(&#39;, &#39;) item = CompanyItem() item[&#39;name&#39;] = company_info(info_list, &quot;企业名称：&quot;) item[&#39;code&#39;] = company_info(info_list, &quot;统一社会信用代码：&quot;) item[&#39;type&#39;] = company_info(info_list, &quot;类型：&quot;) start = company_info(info_list, &quot;营业期限自：&quot;) partner_start = company_info(info_list, &quot;合伙期限自：&quot;) item[&#39;start&#39;] = start if &quot;无&quot; == partner_start else partner_start end = company_info(info_list, &quot;合伙期限自：&quot;) partner_end = company_info(info_list, &quot;合伙期限至：&quot;) item[&#39;end&#39;] = end if &quot;无&quot; == partner_end else partner_end item[&#39;capital&#39;] = company_info(info_list, &quot;注册资本：&quot;) item[&#39;owner&#39;] = company_info(info_list, &quot;法定代表人：&quot;) item[&#39;establish&#39;] = company_info(info_list, &quot;成立日期：&quot;) item[&#39;registration&#39;] = company_info(info_list, &quot;登记机关：&quot;) item[&#39;check&#39;] = company_info(info_list, &quot;核准日期：&quot;) item[&#39;status&#39;] = company_info(info_list, &quot;登记状态：&quot;) residence = company_info(info_list, &quot;住所：&quot;) premises = company_info(info_list, &quot;主要经营场所：&quot;) item[&#39;address&#39;] = residence if &quot;无&quot; == premises else premises item[&#39;scope&#39;] = company_info(info_list, &quot;经营范围：&quot;) item[&#39;partner&#39;] = company_info(info_list, &quot;执行事务合伙人:&quot;) yield item main.pyfrom scrapy import cmdline from scrapy.cmdline import execute import sys import os sys.path.append(os.path.dirname(os.path.abspath(__file__))) # execute([&quot;scrapy&quot;, &quot;crawl&quot;, &quot;enterprise&quot;,&quot;-a&quot;,&quot;word=百度&quot;]) execute([&quot;scrapy&quot;, &quot;crawl&quot;, &quot;zhilian&quot;]) 安装chromewget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo curl https://intoli.com/install-google-chrome.sh | bash ldd /opt/google/chrome/chrome | grep &quot;not found&quot;]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
        <tag>selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贪心nlp基础]]></title>
    <url>%2F2019%2F09%2F04%2F%E8%B4%AA%E5%BF%83nlp%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[贪心nlp基础 机器翻译 分词-&gt;翻译-&gt;排列组合-&gt;语言模型获取概率-&gt;获得结果 通过维特比算法将Translation Model和Language Model基于动态规划解决时间复杂度O(2^n)-&gt;O(n^p) 联合概率计算过程，马尔科夫假设N-gram 自然语言处理四个维度 声音(Phonetics): 语音识别 单词(Morphology): 分词，pos(part of speech词性标注)，NER(named entity recognition命名实体识别) 句子结构(Syntax):句法分析(Parsing依赖语言，CYK基于DP)，依存分析(dependency parsing词与词之间依赖关系) 语义分析(Sematic):NLU 时间复杂度和空间复杂度int a = 0, b = 0; for (i = 0; i &lt; N; i++) { # O(N)+O(N)=2*O(N)=O(N) a = a + rand();# N*1个操作 = O(N) b = b + rand();# N*1个操作 = O(N) } for (j = 0; j &lt; N/2; j++) { b = b + rand(); # N/2 *1个操作 = 1/2*O(N)=O(N) } 时间复杂度：O(N)空间复杂度： 2个单位的内存空间 = O(1) # constant space complexity int a = 0; i,j for (i = 0; i &lt; N; i++) { for (j = N; j &gt; i; j--) { a = a + i + j; } } i=0: j=N...1 N i=1: j=N...2 N-1 i=2: j=N...3 N-2 i=N-1: j=N 1 total = 1+2+3,...+N = N*(N+1)/2 = N*N/2 + N/2 = 1/2*O(N^2) + 1/2*O(N) = O(N^2) + O(N) = O(N^2) 时间复杂度：O(N^2);空间复杂度:3个单位的内存空间，不随程序变化而改变内存，O(1) int a = 0, i = N; while (i &gt; 0) { a += i; # 1个操作 i /= 2; #1个操作 } N = 40; i=40 i=20 2 i=10 2 i=5 2 i=2 2 i=1 2 i=0 2 terminate C* O(N) = O(N) if only if C跟N没有相关性 2*6=2*log(N) = 2* O(log N) = O(log N) 时间复杂度： O(log N) int i, j, k = 0; for (i = n / 2; i &lt;= n; i++) { for (j = 2; j &lt;= n; j = j * 2) { k = k + n / 2; } } 时间复杂度：O(n*log n) 当说算法X的效率要高于Y时指的是？ 假设存在一个足够大的数M，当n&gt;M时，我们可以保证X的实际效率要优于Y的实际效率n，比较时间复杂度O(1) O(log n) o(n) o(nlog n): quicksort, heapsort, mergesort o(n^2) o(n^3).. o(2^n) o(3^n)o(log n): 寻找一个element (从tree,heap), binary search 归并排序复杂度分析利用主定理公式 T(n) = T(n-2) + T(n-1) def fib(n): # base case if n &lt; 3: return 1 return fib(n-2)+fib(n-1) print (fib(50)) Fibonanci number (斐波那契数)计算时间复杂度和空间复杂度 import numpy as np def fib(n): tmp = np.zeros(n) tmp[0] = 1 tmp[1] = 1 for i in range(2,n): tmp[i] = tmp[i-2]+tmp[i-1] return tmp[n-1] # 时间复杂度O(N)不再是O(2^n) def fib(n): a,b=1,1 c =0 for i in range(2,n): c = a + b a = b b = c return c # 空间复杂度4，时间复杂度一样 通过DP动态规划改进时间复杂度和空间复杂度 搭建一个智能客服系统相似度匹配:正则(无数据),字符串相似度(训练数据)复杂度太高，通过倒排表作为过滤器 nlp系统流程 分词贪心算法缺点： 无法细分(细分更有解) 局部最优 效率低下(依赖于max_len) 歧义(不能考虑语义)语言模型原理：首先输入语句，根据词典生成所有可能的分词情况，通过语言模型计算每一个分词后的结果概率，选择概率最高分词语句。复杂度太高维特比算法(DP)根据词典生成所有可能的分词情况，通过语言模型计算每一个分词后的结果概率 两步合为一步。拼写纠错 错别字 输入语法有误过滤词通常会过滤掉停用词,出现频率很低的词汇。词形还原/词干提取 词形还原（lemmatization），是把一个任何形式的语言词汇还原为一般形式（能表达完整语义），而词干提取（stemming）是抽取词的词干或词根形式（不一定能够表达完整语义）。 文本表示Boolean Representation Count Based Representation 并非出现次数越多越重要，并非出现次数越少越不重要 Tf-idf Representation以上Representation均属于one-hot representation,无法表达单词之间的语义相似度。 Distributed Representation词向量 长度不依赖于词典，每个位置都有具体数值，通过模型训练得到分布式词向量，可以用来形容词之间的相似度，word2vec，某种意义上可以理解成单词的意思。分布式表示方法解决了one-hot的稀疏问题(量级大且稀疏)，而分布式表示方法可以自由定义向量位数表达句子或向量，并计算出单词之间的相似度，并可视化在空间。 句子向量 Sentence Similarity计算文本相似度 欧式距离 余弦相似度]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenCV与TensorFlow手写数字刷脸识别]]></title>
    <url>%2F2019%2F09%2F03%2FOpenCV%E4%B8%8ETensorFlow%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%88%B7%E8%84%B8%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[OpenCV与TensorFlow手写数字刷脸识别 http://yann.lecun.com/exdb/mnist/ 手写数字识别KNN最近领域# 1 重要 # 2 KNN最近领域 CNN卷积神经网络 2种 # 3 样本 # 4 旧瓶装新酒 ：数字识别的不同 # 4.1 网络 4。2 每一级 4.3 先原理 后代码 # 本质：knn test 样本 K个 max4 3个1 -》1 # 1 load Data 1.1 随机数 1.2 4组 训练 测试 （图片 和 标签） # 2 knn test train distance 5*500 = 2500 784=28*28 # 3 knn k个最近的图片5 500 1-》500train （4） # 4 k个最近的图片-&gt; parse centent label # 5 label -》 数字 p9 测试图片-》数据 # 6 检测概率统计 import tensorflow as tf import numpy as np import random from tensorflow.examples.tutorials.mnist import input_data # load data 2 one_hot : 1 0000 1 fileName mnist = input_data.read_data_sets(&#39;MNIST_data&#39;,one_hot=True) # 属性设置 trainNum = 55000 testNum = 10000 trainSize = 500 testSize = 5 k = 4 # data 分解 1 trainSize 2范围0-trainNum 3 replace=False trainIndex = np.random.choice(trainNum,trainSize,replace=False) testIndex = np.random.choice(testNum,testSize,replace=False) trainData = mnist.train.images[trainIndex]# 训练图片 trainLabel = mnist.train.labels[trainIndex]# 训练标签 testData = mnist.test.images[testIndex] testLabel = mnist.test.labels[testIndex] # 28*28 = 784 print(&#39;trainData.shape=&#39;,trainData.shape)#500*784 1 图片个数 2 784? print(&#39;trainLabel.shape=&#39;,trainLabel.shape)#500*10 print(&#39;testData.shape=&#39;,testData.shape)#5*784 print(&#39;testLabel.shape=&#39;,testLabel.shape)#5*10 print(&#39;testLabel=&#39;,testLabel)# 4 :testData [0] 3:testData[1] 6 # tf input 784-&gt;image trainDataInput = tf.placeholder(shape=[None,784],dtype=tf.float32) trainLabelInput = tf.placeholder(shape=[None,10],dtype=tf.float32) testDataInput = tf.placeholder(shape=[None,784],dtype=tf.float32) testLabelInput = tf.placeholder(shape=[None,10],dtype=tf.float32) #knn distance 5*785. 5*1*784 # 5测试图片 500训练图片 784 (3D) 2500*784 f1 = tf.expand_dims(testDataInput,1) # 维度扩展 f2 = tf.subtract(trainDataInput,f1)# 784 sum(784) f3 = tf.reduce_sum(tf.abs(f2),reduction_indices=2)# 完成数据累加 784 abs # 5*500 f4 = tf.negative(f3)# 取反 f5,f6 = tf.nn.top_k(f4,k=4) # 选取f4 最大的四个值 # f3 最小的四个值 # f6 index-&gt;trainLabelInput f7 = tf.gather(trainLabelInput,f6) # f8 num reduce_sum reduction_indices=1 &#39;竖直&#39; f8 = tf.reduce_sum(f7,reduction_indices=1) # tf.argmax 选取在某一个最大的值 index f9 = tf.argmax(f8,dimension=1) # f9 -&gt; test5 image -&gt; 5 num with tf.Session() as sess: # f1 &lt;- testData 5张图片 p1 = sess.run(f1,feed_dict={testDataInput:testData[0:5]}) print(&#39;p1=&#39;,p1.shape)# p1= (5, 1, 784) p2 = sess.run(f2,feed_dict={trainDataInput:trainData,testDataInput:testData[0:5]}) print(&#39;p2=&#39;,p2.shape)#p2= (5, 500, 784) (1,100) p3 = sess.run(f3,feed_dict={trainDataInput:trainData,testDataInput:testData[0:5]}) print(&#39;p3=&#39;,p3.shape)#p3= (5, 500) print(&#39;p3[0,0]=&#39;,p3[0,0]) #130.451 knn distance p3[0,0]= 155.812 p4 = sess.run(f4,feed_dict={trainDataInput:trainData,testDataInput:testData[0:5]}) print(&#39;p4=&#39;,p4.shape) print(&#39;p4[0,0]&#39;,p4[0,0]) p5,p6 = sess.run((f5,f6),feed_dict={trainDataInput:trainData,testDataInput:testData[0:5]}) #p5= (5, 4) 每一张测试图片（5张）分别对应4张最近训练图片 #p6= (5, 4) print(&#39;p5=&#39;,p5.shape) print(&#39;p6=&#39;,p6.shape) print(&#39;p5[0,0]&#39;,p5[0]) print(&#39;p6[0,0]&#39;,p6[0])# p6 index p7 = sess.run(f7,feed_dict={trainDataInput:trainData,testDataInput:testData[0:5],trainLabelInput:trainLabel}) print(&#39;p7=&#39;,p7.shape)#p7= (5, 4, 10) print(&#39;p7[]&#39;,p7) p8 = sess.run(f8,feed_dict={trainDataInput:trainData,testDataInput:testData[0:5],trainLabelInput:trainLabel}) print(&#39;p8=&#39;,p8.shape) print(&#39;p8[]=&#39;,p8) p9 = sess.run(f9,feed_dict={trainDataInput:trainData,testDataInput:testData[0:5],trainLabelInput:trainLabel}) print(&#39;p9=&#39;,p9.shape) print(&#39;p9[]=&#39;,p9) p10 = np.argmax(testLabel[0:5],axis=1) print(&#39;p10[]=&#39;,p10) j = 0 for i in range(0,5): if p10[i] == p9[i]: j = j+1 print(&#39;ac=&#39;,j*100/5) CNN卷积神经网络#cnn : 1 卷积 # ABC # A: 激励函数+矩阵 乘法加法 # A CNN : pool（激励函数+矩阵 卷积 加法） # C：激励函数+矩阵 乘法加法（A-》B） # C：激励函数+矩阵 乘法加法（A-》B） + softmax（矩阵 乘法加法） # loss：tf.reduce_mean(tf.square(y-layer2)) # loss：code #1 import import tensorflow as tf import numpy as np from tensorflow.examples.tutorials.mnist import input_data # 2 load data mnist = input_data.read_data_sets(&#39;MNIST_data&#39;,one_hot = True) # 3 input imageInput = tf.placeholder(tf.float32,[None,784]) # 28*28 labeInput = tf.placeholder(tf.float32,[None,10]) # 10 列数 # 4 data reshape # [None,784]-&gt;M*28*28*1 2D-&gt;4D 28*28 wh 1 channel imageInputReshape = tf.reshape(imageInput,[-1,28,28,1]) # 5 卷积 w0 : 卷积内核 5*5 out:32 in:1 w0 = tf.Variable(tf.truncated_normal([5,5,1,32],stddev = 0.1)) b0 = tf.Variable(tf.constant(0.1,shape=[32])) # 6 # layer1：激励函数+卷积运算 # imageInputReshape : M*28*28*1 w0:5,5,1,32 layer1 = tf.nn.relu(tf.nn.conv2d(imageInputReshape,w0,strides=[1,1,1,1],padding=&#39;SAME&#39;)+b0) # M*28*28*32 # pool 采样 数据量减少很多M*28*28*32 =&gt; M*7*7*32 layer1_pool = tf.nn.max_pool(layer1,ksize=[1,4,4,1],strides=[1,4,4,1],padding=&#39;SAME&#39;) # [1 2 3 4]-&gt;[4] # 7 layer2 out : 激励函数+乘加运算： softmax（激励函数 + 乘加运算） # [7*7*32,1024] w1 = tf.Variable(tf.truncated_normal([7*7*32,1024],stddev=0.1)) b1 = tf.Variable(tf.constant(0.1,shape=[1024])) h_reshape = tf.reshape(layer1_pool,[-1,7*7*32])# M*7*7*32 -&gt; N*N1 # [N*7*7*32] [7*7*32,1024] = N*1024 h1 = tf.nn.relu(tf.matmul(h_reshape,w1)+b1) # 7.1 softMax w2 = tf.Variable(tf.truncated_normal([1024,10],stddev=0.1)) b2 = tf.Variable(tf.constant(0.1,shape=[10])) pred = tf.nn.softmax(tf.matmul(h1,w2)+b2)# N*1024 1024*10 = N*10 # N*10( 概率 )N1【0.1 0.2 0.4 0.1 0.2 。。。】 # label。 【0 0 0 0 1 0 0 0.。。】 loss0 = labeInput*tf.log(pred) loss1 = 0 # 7.2 for m in range(0,500):# test 100 for n in range(0,10): loss1 = loss1 - loss0[m,n] loss = loss1/500 # 8 train train = tf.train.GradientDescentOptimizer(0.01).minimize(loss) # 9 run with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for i in range(100): images,labels = mnist.train.next_batch(500) sess.run(train,feed_dict={imageInput:images,labeInput:labels}) pred_test = sess.run(pred,feed_dict={imageInput:mnist.test.images,labeInput:labels}) acc = tf.equal(tf.arg_max(pred_test,1),tf.arg_max(mnist.test.labels,1)) acc_float = tf.reduce_mean(tf.cast(acc,tf.float32)) acc_result = sess.run(acc_float,feed_dict={imageInput:mnist.test.images,labeInput:mnist.test.labels}) print(acc_result) 刷脸识别爬虫获取样本import urllib from bs4 import BeautifulSoup html = urllib.request.urlopen( &#39;https://www.duitang.com/album/?id=69001447&#39;).read() # parse url data 1 html 2 &#39;html.parser&#39; 3 &#39;utf-8&#39; soup = BeautifulSoup(html, &#39;html.parser&#39;, from_encoding=&#39;utf-8&#39;) # img images = soup.findAll(&#39;img&#39;) print(images) imageName = 0 for image in images: link = image.get(&#39;src&#39;) print(&#39;link=&#39;, link) fileFormat = link[-3:] if fileFormat == &#39;png&#39; or fileFormat == &#39;jpg&#39;: fileSavePath = &#39;C:/Users/codewj/AnacondaProjects/5刷脸识别/images/&#39; + str(imageName) + &#39;.jpg&#39; imageName = imageName + 1 urllib.request.urlretrieve(link, fileSavePath) ffmpegffmpeg -i input.mp4 -r 1 -q:v 2 -f image2 pic-%03d.jpeg 视频提取帧 ffmpeg -i input.mp4 -ss 00:00:20 -t 10 -r 1 -q:v 2 -f image2 pic-%03d.jpeg ffmpeg会从input.mp4的第20s时间开始，往下10s，即20~30s这10秒钟之间，每隔1s就抓一帧，总共会抓10帧。 ffmpeg -i input.avi output.mp4 视频转格式 ffmpeg -i a.mp4 -acodec copy -vn a.aac 视频提取音频 ffmpeg -i input.mp4 -vcodec copy -an output.mp4 视频提取音频 ffmpeg -ss 00:00:15 -t 00:00:05 -i input.mp4 -vcodec copy -acodec copy output.mp4 视频剪切 ffmpeg -i input.mp4 -b:v 2000k -bufsize 2000k -maxrate 2500k output.mp4 码率控制 ffmpeg -i input.mp4 -vcodec mpeg4 output.mp4 视频编码格式转换mpeg4 ffmpeg -i input.mp4 -vf scale=960:540 output.mp4 将输入视频缩小到960x540输出 ffmpeg -i input.mp4 -i iQIYI_logo.png -filter_complex overlay output.mp4 视频添加logo opencv预处理# 1 load xml 2 load jpg 3 haar gray 4 detect 5 draw import cv2 import numpy as np # load xml 1 file name face_xml = cv2.CascadeClassifier(&#39;haarcascade_frontalface_default.xml&#39;) eye_xml = cv2.CascadeClassifier(&#39;haarcascade_eye.xml&#39;) # load jpg img = cv2.imread(&#39;face.jpg&#39;) cv2.imshow(&#39;src&#39;,img) # haar gray gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # detect faces 1 data 2 scale 3 5 faces = face_xml.detectMultiScale(gray,1.3,5) print(&#39;face=&#39;,len(faces)) # draw index = 0 for (x,y,w,h) in faces: cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) roi_face = gray[y:y+h,x:x+w] roi_color = img[y:y+h,x:x+w] fileName = str(index)+&#39;.jpg&#39; cv2.imwrite(fileName,roi_color) index = index + 1 # 1 gray eyes = eye_xml.detectMultiScale(roi_face) print(&#39;eye=&#39;,len(eyes)) #for (e_x,e_y,e_w,e_h) in eyes: #cv2.rectangle(roi_color,(e_x,e_y),(e_x+e_w,e_y+e_h),(0,255,0),2) cv2.imshow(&#39;dst&#39;,img) cv2.waitKey(0) 某个人脸识别# 1 数据yale 2 准备train label-》train # 3 cnn 4 检测 import tensorflow as tf import numpy as np import scipy.io as sio f = open(&#39;Yale_64x64.mat&#39;,&#39;rb&#39;) mdict = sio.loadmat(f) # fea gnd train_data = mdict[&#39;fea&#39;] train_label = mdict[&#39;gnd&#39;] # 数据无序排列 train_data = np.random.permutation(train_data) train_label = np.random.permutation(train_label) test_data = train_data[0:64] test_label = train_label[0:64] np.random.seed(100) test_data = np.random.permutation(test_data) np.random.seed(100) test_label = np.random.permutation(test_label) # train [0-9] [10*N] [15*N] [0 0 1 0 0 0 0 0 0 0] -&gt; 2 train_data = train_data.reshape(train_data.shape[0],64,64,1).astype(np.float32)/255 train_labels_new = np.zeros((165,15))# 165 image 15 for i in range(0,165): j = int(train_label[i,0])-1 # 1-15 0-14 train_labels_new[i,j] = 1 test_data_input = test_data.reshape(test_data.shape[0],64,64,1).astype(np.float32)/255 test_labels_input = np.zeros((64,15))# 165 image 15 for i in range(0,64): j = int(test_label[i,0])-1 # 1-15 0-14 test_labels_input[i,j] = 1 # cnn acc tf.nn tf.layer data_input = tf.placeholder(tf.float32,[None,64,64,1]) label_input = tf.placeholder(tf.float32,[None,15]) layer1 = tf.layers.conv2d(inputs=data_input,filters=32,kernel_size=2,strides=1,padding=&#39;SAME&#39;,activation=tf.nn.relu) layer1_pool = tf.layers.max_pooling2d(layer1,pool_size=2,strides=2) layer2 = tf.reshape(layer1_pool,[-1,32*32*32]) layer2_relu = tf.layers.dense(layer2,1024,tf.nn.relu) output = tf.layers.dense(layer2_relu,15) loss = tf.losses.softmax_cross_entropy(onehot_labels=label_input,logits=output) train = tf.train.GradientDescentOptimizer(0.01).minimize(loss) accuracy = tf.metrics.accuracy(labels=tf.argmax(label_input,axis=1),predictions=tf.argmax(output,axis=1))[1] # run acc init = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer()) with tf.Session() as sess: sess.run(init) for i in range(0,200): train_data_input = np.array(train_data) train_label_input = np.array(train_labels_new) sess.run([train,loss],feed_dict={data_input:train_data_input,label_input:train_label_input}) acc = sess.run(accuracy,feed_dict={data_input:test_data_input,label_input:test_labels_input}) print(&#39;acc:%.2f&#39;,acc)]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenCV与TensorFlow 机器学习]]></title>
    <url>%2F2019%2F09%2F02%2FOpenCV%E4%B8%8ETensorFlow%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[OpenCV与TensorFlow 机器学习 视频分解图片# 1 load 2 info 3 parse 4 imshow imwrite import cv2 cap = cv2.VideoCapture(&quot;1.mp4&quot;)# 获取一个视频打开cap 1 file name isOpened = cap.isOpened# 判断是否打开‘ print(isOpened) fps = cap.get(cv2.CAP_PROP_FPS)#帧率 width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))#w h height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) print(fps,width,height) i = 0 while(isOpened): if i == 10: break else: i = i+1 (flag,frame) = cap.read()# 读取每一张 flag frame fileName = &#39;image&#39;+str(i)+&#39;.jpg&#39; print(fileName) if flag == True: cv2.imwrite(fileName,frame,[cv2.IMWRITE_JPEG_QUALITY,100]) print(&#39;end!&#39;) 图片合成视频import cv2 img = cv2.imread(&#39;image1.jpg&#39;) imgInfo = img.shape size = (imgInfo[1],imgInfo[0]) print(size) videoWrite = cv2.VideoWriter(&#39;2.mp4&#39;,-1,5,size)# 写入对象 # 1 file name 2 编码器 3 帧率 4 size for i in range(1,11): fileName = &#39;image&#39;+str(i)+&#39;.jpg&#39; img = cv2.imread(fileName) videoWrite.write(img)# 写入方法 1 jpg data print(&#39;end!&#39;) 基于Haar+Adaboost人脸识别# 1 load xml 2 load jpg 3 haar gray 4 detect 5 draw import cv2 import numpy as np # load xml 1 file name face_xml = cv2.CascadeClassifier(&#39;haarcascade_frontalface_default.xml&#39;) eye_xml = cv2.CascadeClassifier(&#39;haarcascade_eye.xml&#39;) # load jpg img = cv2.imread(&#39;face.jpg&#39;) cv2.imshow(&#39;src&#39;,img) # haar gray gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # detect faces 1 data 2 scale 3 5 faces = face_xml.detectMultiScale(gray,1.3,5) print(&#39;face=&#39;,len(faces)) # draw for (x,y,w,h) in faces: cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) roi_face = gray[y:y+h,x:x+w] roi_color = img[y:y+h,x:x+w] # 1 gray eyes = eye_xml.detectMultiScale(roi_face) print(&#39;eye=&#39;,len(eyes)) #for (e_x,e_y,e_w,e_h) in eyes: #cv2.rectangle(roi_color,(e_x,e_y),(e_x+e_w,e_y+e_h),(0,255,0),2) cv2.imshow(&#39;dst&#39;,img) cv2.waitKey(0) SVM身高体重预测# 1 思想 分类器 # 2 如何？ 寻求一个最优的超平面 分类 # 3 核：line # 4 数据：样本 # 5 训练 SVM_create train predict # svm本质 寻求一个最优的超平面 分类 # svm 核: line # 身高体重 训练 预测 import cv2 import numpy as np import matplotlib.pyplot as plt #1 准备data rand1 = np.array([[155,48],[159,50],[164,53],[168,56],[172,60]]) rand2 = np.array([[152,53],[156,55],[160,56],[172,64],[176,65]]) # 2 label label = np.array([[0],[0],[0],[0],[0],[1],[1],[1],[1],[1]]) # 3 data data = np.vstack((rand1,rand2)) data = np.array(data,dtype=&#39;float32&#39;) # svm 所有的数据都要有label # [155,48] -- 0 女生 [152,53] ---1 男生 # 监督学习 0 负样本 1 正样本 # 4 训练 svm = cv2.ml.SVM_create() # ml 机器学习模块 SVM_create() 创建 # 属性设置 svm.setType(cv2.ml.SVM_C_SVC) # svm type svm.setKernel(cv2.ml.SVM_LINEAR) # line svm.setC(0.01) # 训练 result = svm.train(data,cv2.ml.ROW_SAMPLE,label) # 预测 pt_data = np.vstack([[167,55],[162,57]]) #0 女生 1男生 pt_data = np.array(pt_data,dtype=&#39;float32&#39;) print(pt_data) (par1,par2) = svm.predict(pt_data) print(par2) Hog+SVM小狮子识别# 训练 # 1 参数 2hog 3 svm 4 computer hog 5 label 6 train 7 pred 8 draw import cv2 import numpy as np import matplotlib.pyplot as plt # 1 par PosNum = 820 # 正样本个数 NegNum = 1931 # 负样本个数 winSize = (64,128) blockSize = (16,16)# 105 blockStride = (8,8)#4 cell cellSize = (8,8) nBin = 9#9 bin 3780 # 2 hog create hog 1 win 2 block 3 blockStride 4 cell 5 bin hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nBin) # 3 svm svm = cv2.ml.SVM_create() # 4 computer hog 特征提取存储 标签标识完成 featureNum = int(((128-16)/8+1)*((64-16)/8+1)*4*9) #3780 特征维度 featureArray = np.zeros(((PosNum+NegNum),featureNum),np.float32) # 用于装在特征，行正负样本个数，列就是特征维度 labelArray = np.zeros(((PosNum+NegNum),1),np.int32) # 标签 # svm 监督学习 样本 标签 svm -》image hog for i in range(0,PosNum): fileName = &#39;pos/&#39;+str(i+1)+&#39;.jpg&#39; img = cv2.imread(fileName) hist = hog.compute(img,(8,8))# 3780 for j in range(0,featureNum): featureArray[i,j] = hist[j] # featureArray hog [1,:] hog1 [2,:]hog2 labelArray[i,0] = 1 # 正样本 label 1 for i in range(0,NegNum): fileName = &#39;neg/&#39;+str(i+1)+&#39;.jpg&#39; img = cv2.imread(fileName) hist = hog.compute(img,(8,8))# 3780 for j in range(0,featureNum): featureArray[i+PosNum,j] = hist[j] labelArray[i+PosNum,0] = -1 # 负样本 label -1 svm.setType(cv2.ml.SVM_C_SVC) svm.setKernel(cv2.ml.SVM_LINEAR) svm.setC(0.01) # 6 train ret = svm.train(featureArray,cv2.ml.ROW_SAMPLE,labelArray) # 7 myHog ：《-myDetect # myDetect-《resultArray rho # myHog-》detectMultiScale # 7 检测 核心：create Hog -》 myDetect—》array-》 # resultArray-》resultArray = -1*alphaArray*supportVArray # rho-》svm-〉svm.train alpha = np.zeros((1),np.float32) rho = svm.getDecisionFunction(0,alpha) print(rho) print(alpha) alphaArray = np.zeros((1,1),np.float32) # 支持向量机数组 supportVArray = np.zeros((1,featureNum),np.float32) resultArray = np.zeros((1,featureNum),np.float32) alphaArray[0,0] = alpha resultArray = -1*alphaArray*supportVArray # detect检测创建 myDetect = np.zeros((3781),np.float32) for i in range(0,3780): myDetect[i] = resultArray[0,i] myDetect[3780] = rho[0] # rho svm （判决） myHog = cv2.HOGDescriptor() myHog.setSVMDetector(myDetect) # load 1表示彩色图片 imageSrc = cv2.imread(&#39;Test2.jpg&#39;,1) # (8,8) win 检测目标 objs = myHog.detectMultiScale(imageSrc,0,(8,8),(32,32),1.05,2) # xy wh 三维 最后一维 x = int(objs[0][0][0]) y = int(objs[0][0][1]) w = int(objs[0][0][2]) h = int(objs[0][0][3]) # 绘制展示 图片 起始位置 终止位置 颜色 线条宽度 cv2.rectangle(imageSrc,(x,y),(x+w,y+h),(255,0,0),2) cv2.imshow(&#39;dst&#39;,imageSrc) cv2.waitKey(0)]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenCV与TensorFlow 入门人工智能图像处理]]></title>
    <url>%2F2019%2F09%2F02%2FOpenCV%E4%B8%8ETensorFlow%20%E5%85%A5%E9%97%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[OpenCV与TensorFlow 入门人工智能图像处理 AnacondaAnaconda Navigator新建Env环境,添加channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/tensorflow,opencv,numpy,matplotlib,beautifulsoup4,urllib3,scipy，并进入Home安装Jupyter notebook点击进入Jupyter Launch 基本命令yum install -y bzip2 sh Anaconda3-5.2.0-Linux-x86_64.sh 修改默认位置为/data1/anaconda3 vi /etc/profile PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$MAVEN_HOME/bin:/data1/anaconda3/bin source /etc/profile conda update conda conda info --envs conda create --name tensorflow36 activate tensorflow36 | source activate tensorflow36 | conda activate tensorflow36 source deactivate conda create -n spider python=3.6 创建虚拟环境 source activate spider pip install -i https://pypi.doubanio.com/simple/ --trusted-host pypi.doubanio.com fake_useragent scrapy browsercookie conda remove -n spider --all 删除虚拟环境 conda config --set show_channel_urls yes 设置搜索时显示通道地址 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/tensorflow/linux/cpu/ conda list conda update anaconda-navigator conda update navigator-updater pip install opencv-pythonopencv入门opencv图片读取与展示 # 引入opencv2 import cv2 # 文件读取-封装格式解析-数据解码-数据加载 img = cv2.imread(&#39;a.jpg&#39;,1) cv2.imshow(&#39;image&#39;,img) # jpg png是文件封装格式，文件头（数据解码信息，附加信息，解码器根据附加信息将文件数据还原成最原始的数据）+文件数据（非文件原始数据，是压缩编码后的数据） # stop cv2.waitKey (0) opencv图片写入import cv2 img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imwrite(&#39;image1.jpg&#39;,img) # 1 name 2 data opencv图像质量jpg有损压缩import cv2 img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imwrite(&#39;imageTest.jpg&#39;,img,[cv2.IMWRITE_JPEG_QUALITY,50]) # 1M 100k 10k 0-100 # jpg RGB颜色分量组成 1.14M=720*547*3*8 bit/8 (b)=1.14M png无损压缩# 透明度属性 import cv2 img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imwrite(&#39;imageTest.png&#39;,img,[cv2.IMWRITE_PNG_COMPRESSION,0]) # jpg 0 压缩比高0-100 png 0 压缩比低0-9 # png RGB alpha opencv像素操作import cv2 img = cv2.imread(&#39;image0.jpg&#39;,1) (b,g,r) = img[100,100] print(b,g,r)# bgr #10 100 --- 110 100 for i in range(1,100): img[10+i,100] = (255,0,0) cv2.imshow(&#39;image&#39;,img) cv2.waitKey(0) #1000 ms tensorflow入门 tf_常量变量所有变量必须初始化完成 #opencv tensorflow #类比 语法 api 原理 #基础数据类型 运算符 流程 字典 数组 import tensorflow as tf data1 = tf.constant(2,dtype=tf.int32) data2 = tf.Variable(10,name=&#39;var&#39;) print(data1) print(data2) &#39;&#39;&#39; sess = tf.Session() print(sess.run(data1)) init = tf.global_variables_initializer() sess.run(init) print(sess.run(data2)) sess.close() # 本质 tf = tensor + 计算图 # tensor 数据 # op # graphs 数据操作 # session &#39;&#39;&#39; init = tf.global_variables_initializer() sess = tf.Session() with sess: sess.run(init) print(sess.run(data2)) tf_四则运算常量import tensorflow as tf data1 = tf.constant(6) data2 = tf.constant(2) dataAdd = tf.add(data1,data2) dataMul = tf.multiply(data1,data2) dataSub = tf.subtract(data1,data2) dataDiv = tf.divide(data1,data2) with tf.Session() as sess: print(sess.run(dataAdd)) print(sess.run(dataMul)) print(sess.run(dataSub)) print(sess.run(dataDiv)) print(&#39;end!&#39;) 变量import tensorflow as tf data1 = tf.constant(6) data2 = tf.Variable(2) dataAdd = tf.add(data1,data2) dataCopy = tf.assign(data2,dataAdd)# dataAdd -&gt;data2 dataMul = tf.multiply(data1,data2) dataSub = tf.subtract(data1,data2) dataDiv = tf.divide(data1,data2) init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) # 所有变量必须完成初始化 print(sess.run(dataAdd)) print(sess.run(dataMul)) print(sess.run(dataSub)) print(sess.run(dataDiv)) print(&#39;sess.run(dataCopy)&#39;,sess.run(dataCopy))#8-&gt;data2 print(&#39;dataCopy.eval()&#39;,dataCopy.eval())#8+6-&gt;14-&gt;data2 = 14 print(&#39;tf.get_default_session()&#39;,tf.get_default_session().run(dataCopy)) print(&#39;end!&#39;) tf矩阵基础1占位#placehold import tensorflow as tf data1 = tf.placeholder(tf.float32) data2 = tf.placeholder(tf.float32) dataAdd = tf.add(data1,data2) with tf.Session() as sess: print(sess.run(dataAdd,feed_dict={data1:6,data2:2})) # 1 dataAdd 2 data (feed_dict = {1:6,2:2}) print(&#39;end!&#39;) 矩阵打印#类比 数组 M行N列 [] 内部[] [里面 列数据] [] 中括号整体 行数 #[[6,6]] [[6,6]] import tensorflow as tf data1 = tf.constant([[6,6]]) data2 = tf.constant([[2], [2]]) data3 = tf.constant([[3,3]]) data4 = tf.constant([[1,2], [3,4], [5,6]]) print(data4.shape)# 维度 with tf.Session() as sess: print(sess.run(data4)) #打印整体 print(sess.run(data4[0]))# 打印某一行 print(sess.run(data4[:,0]))#打印某列 print(sess.run(data4[0,1]))# 1 1 MN = 0 32 = M012 N01 矩阵计算import tensorflow as tf data1 = tf.constant([[6,6]]) data2 = tf.constant([[2], [2]]) data3 = tf.constant([[3,3]]) data4 = tf.constant([[1,2], [3,4], [5,6]]) matMul = tf.matmul(data1,data2) matMul2 = tf.multiply(data1,data2) matAdd = tf.add(data1,data3) with tf.Session() as sess: print(sess.run(matMul))#1 维 M=1 N2. 1X2(MK) 2X1(KN) = 1 print(sess.run(matAdd))#1行2列 print(sess.run(matMul2))# 1x2 2x1 = 2x2 print(sess.run([matMul,matAdd])) 矩阵定义import tensorflow as tf mat0 = tf.constant([[0,0,0],[0,0,0]]) mat1 = tf.zeros([2,3]) mat2 = tf.ones([3,2]) mat3 = tf.fill([2,3],15) with tf.Session() as sess: #print(sess.run(mat0)) #print(sess.run(mat1)) #print(sess.run(mat2)) print(sess.run(mat3)) mat4 = tf.constant([[2],[3],[4]]) mat5 = tf.zeros_like(mat1) mat6 = tf.linspace(0.0,2.0,11) mat7 = tf.random_uniform([2,3],-1,2) with tf.Session() as sess: print(sess.run(mat5)) print(sess.run(mat6)) print(sess.run(mat7)) tf模块Numpy的使用#CURD import numpy as np data1 = np.array([1,2,3,4,5]) print(data1) data2 = np.array([[1,2], [3,4]]) print(data2) #维度 print(data1.shape,data2.shape) # zero ones print(np.zeros([2,3]),np.ones([2,2])) # 改查 data2[1,0] = 5 print(data2) print(data2[1,1]) # 基本运算 data3 = np.ones([2,3]) print(data3*2)#对应相乘 print(data3/3) print(data3+2) # 矩阵+* data4 = np.array([[1,2,3],[4,5,6]]) print(data3+data4) print(data3*data4) tf模块matplotlib的使用import numpy as np import matplotlib.pyplot as plt # 折线 x = np.array([1,2,3,4,5,6,7,8]) y = np.array([3,5,7,6,2,6,10,15]) plt.plot(x,y,&#39;r&#39;)# 折线 1 x 2 y 3 color plt.plot(x,y,&#39;g&#39;,lw=10)# 4 line w # 柱状 x = np.array([1,2,3,4,5,6,7,8]) y = np.array([13,25,17,36,21,16,10,15]) plt.bar(x,y,0.2,alpha=1,color=&#39;b&#39;)# 5 color 4 透明度 3 0.9 plt.show() 绘制股票k线import tensorflow as tf import numpy as np import matplotlib.pyplot as plt date = np.linspace(1,15,15) endPrice = np.array([2511.90,2538.26,2510.68,2591.66,2732.98,2701.69,2701.29,2678.67,2726.50,2681.50,2739.17,2715.07,2823.58,2864.90,2919.08] ) beginPrice = np.array([2438.71,2500.88,2534.95,2512.52,2594.04,2743.26,2697.47,2695.24,2678.23,2722.13,2674.93,2744.13,2717.46,2832.73,2877.40]) print(date) # 定义绘图 plt.figure() # 数据装载 for i in range(0,15): # 1 柱状图 dateOne = np.zeros([2]) dateOne[0] = i; dateOne[1] = i; priceOne = np.zeros([2]) priceOne[0] = beginPrice[i] priceOne[1] = endPrice[i] if endPrice[i]&gt;beginPrice[i]: plt.plot(dateOne,priceOne,&#39;r&#39;,lw=8) else: plt.plot(dateOne,priceOne,&#39;g&#39;,lw=8) plt.show() 神经网络逼近股票收盘均价# layer1：激励函数+乘加运算 import tensorflow as tf import numpy as np import matplotlib.pyplot as plt date = np.linspace(1,15,15) endPrice = np.array([2511.90,2538.26,2510.68,2591.66,2732.98,2701.69,2701.29,2678.67,2726.50,2681.50,2739.17,2715.07,2823.58,2864.90,2919.08] ) beginPrice = np.array([2438.71,2500.88,2534.95,2512.52,2594.04,2743.26,2697.47,2695.24,2678.23,2722.13,2674.93,2744.13,2717.46,2832.73,2877.40]) print(date) plt.figure() for i in range(0,15): # 1 柱状图 dateOne = np.zeros([2]) dateOne[0] = i; dateOne[1] = i; priceOne = np.zeros([2]) priceOne[0] = beginPrice[i] priceOne[1] = endPrice[i] if endPrice[i]&gt;beginPrice[i]: plt.plot(dateOne,priceOne,&#39;r&#39;,lw=8) else: plt.plot(dateOne,priceOne,&#39;g&#39;,lw=8) #plt.show() # 输入矩阵A:15*1 隐藏层矩阵B:15*10 数据矩阵C:15*1 # A(15x1)*w1(1x10)+b1(1*10) = B(15x10) A-&gt;B # B(15x10)*w2(10x1)+b2(15x1) = C(15x1) B-&gt;C # 1次循环 A-|w1 w2 b1 b2|-&gt;C 与真实值相差，在2次循环时，梯度下降修改|w1 w2 b1 b2|减少2次误差..... # 1 A B C dateNormal = np.zeros([15,1]) priceNormal = np.zeros([15,1]) for i in range(0,15): dateNormal[i,0] = i/14.0; priceNormal[i,0] = endPrice[i]/3000.0; x = tf.placeholder(tf.float32,[None,1]) y = tf.placeholder(tf.float32,[None,1]) # B w1 = tf.Variable(tf.random_uniform([1,10],0,1)) b1 = tf.Variable(tf.zeros([1,10])) wb1 = tf.matmul(x,w1)+b1 layer1 = tf.nn.relu(wb1) # 激励函数 # C w2 = tf.Variable(tf.random_uniform([10,1],0,1)) b2 = tf.Variable(tf.zeros([15,1])) wb2 = tf.matmul(layer1,w2)+b2 layer2 = tf.nn.relu(wb2) loss = tf.reduce_mean(tf.square(y-layer2))#y 真实 layer2 计算 train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss) # 梯度下降缩小loss with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for i in range(0,10000): sess.run(train_step,feed_dict={x:dateNormal,y:priceNormal}) # w1w2 b1b2 A + wb --&gt;layer2 pred = sess.run(layer2,feed_dict={x:dateNormal}) predPrice = np.zeros([15,1]) for i in range(0,15): predPrice[i,0]=(pred*3000)[i,0] plt.plot(date,predPrice,&#39;b&#39;,lw=1) plt.show() 计算机视觉加强之几何变换图片缩放API图片缩放# 1 load 2 info 3 resize 4 check import cv2 # 1表示彩色图片 img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape print(imgInfo) height = imgInfo[0] width = imgInfo[1] mode = imgInfo[2] # 1 放大 缩小 2 等比例 非 2:3 dstHeight = int(height*0.5) dstWidth = int(width*0.5) #最近临域插值 双线性插值 像素关系重采样 立方插值 dst = cv2.resize(img,(dstWidth,dstHeight)) cv2.imshow(&#39;image&#39;,dst) cv2.waitKey(0) 最近临域插值 原理 src 1020 dst 5*10 dst&lt;-src (1,2) &lt;- (2,4) dst x 1 -&gt; src x 2 newX newX = x(src 行/目标 行) newX = 1（10/5） = 2 newY = y(src 列/目标 列) newY = 2*（20/10）= 4 12.3 = 12 双线性插值 原理 A1 = 20% 上+80%下 A2 B1 = 30% 左+70%右 B2 1 最终点 = A1 30% + A2 70% 2 最终点 = B1 20% + B2 80% 实质：矩阵运算 源码图片缩放# 1 info 2 空白模版 3 xy import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] dstHeight = int(height/2) dstWidth = int(width/2) dstImage = np.zeros((dstHeight,dstWidth,3),np.uint8)#0-255 for i in range(0,dstHeight):#行 for j in range(0,dstWidth):#列 iNew = int(i*(height*1.0/dstHeight)) jNew = int(j*(width*1.0/dstWidth)) dstImage[i,j] = img[iNew,jNew] cv2.imshow(&#39;dst&#39;,dstImage) cv2.waitKey(0) # 1 opencv API resize 2 算法原理 3 源码 源码图片剪切#100 -》200 x #100-》300 y import cv2 img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape dst = img[100:200,100:300] cv2.imshow(&#39;image&#39;,dst) cv2.waitKey(0) 矩阵图片移位# 1 API 2 算法原理 3 源代码 import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] #### matShift = np.float32([[1,0,100],[0,1,200]])# 2*3 dst = cv2.warpAffine(img,matShift,(height,width))#1 data 2 mat 3 info # 移位 矩阵 cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) [1,0,100],[0,1,200] 22 21 组成[[1,0],[0,1]] 22 A[[100],[200]] 21 Bxy CAC+B = [[1x+0y],[0x+1*y]]+[[100],[200]] = [[x+100],[y+200]](10,20)-&gt;(110,120) 矩阵图片缩放#[[A1 A2 B1],[A3 A4 B2]] # [[A1 A2],[A3 A4]] [[B1],[B2]] # newX = A1*x + A2*y+B1 # newY = A3*x +A4*y+B2 # x-&gt;x*0.5 y-&gt;y*0.5 # newX = 0.5*x import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] matScale = np.float32([[0.5,0,0],[0,0.5,0]]) dst = cv2.warpAffine(img,matScale,(int(width/2),int(height/2))) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 源码图片移位import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape dst = np.zeros(img.shape,np.uint8) height = imgInfo[0] width = imgInfo[1] for i in range(0,height): for j in range(0,width-100): dst[i,j+100]=img[i,j] cv2.imshow(&#39;image&#39;,dst) cv2.waitKey(0) 源码图片镜像import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] deep = imgInfo[2] newImgInfo = (height*2,width,deep) dst = np.zeros(newImgInfo,np.uint8)#uint8 for i in range(0,height): for j in range(0,width): dst[i,j] = img[i,j] #x y = 2*h - y -1 dst[height*2-i-1,j] = img[i,j] for i in range(0,width): dst[height,i] = (0,0,255)#BGR cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 仿射变换import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] #src 3-&gt;dst 3 (左上角 左下角 右上角) matSrc = np.float32([[0,0],[0,height-1],[width-1,0]]) matDst = np.float32([[50,50],[300,height-200],[width-300,100]]) #组合 定义仿射变换矩阵 matAffine = cv2.getAffineTransform(matSrc,matDst)# mat 1 src 2 dst dst = cv2.warpAffine(img,matAffine,(width,height)) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) API图片旋转import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] # 2*3 matRotate = cv2.getRotationMatrix2D((height*0.5,width*0.5),45,1)# mat rotate 1 center 2 angle 3 scale #100*100 25 dst = cv2.warpAffine(img,matRotate,(height,width)) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 计算机视觉加强之图像特效API灰度处理#imread #方法1 imread import cv2 img0 = cv2.imread(&#39;image0.jpg&#39;,0) img1 = cv2.imread(&#39;image0.jpg&#39;,1) print(img0.shape) print(img1.shape) cv2.imshow(&#39;src&#39;,img0) cv2.waitKey(0) #方法2 cvtColor img = cv2.imread(&#39;image0.jpg&#39;,1) dst = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)# 颜色空间转换 1 data 2 BGR gray cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 源码灰度处理import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] # RGB R=G=B = gray (R+G+B)/3 dst = np.zeros((height,width,3),np.uint8) for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] gray = (int(b)+int(g)+int(r))/3 dst[i,j] = np.uint8(gray) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) #方法4 gray = r*0.299+g*0.587+b*0.114 dst = np.zeros((height,width,3),np.uint8) for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] b = int(b) g = int(g) r = int(r) gray = r*0.299+g*0.587+b*0.114 dst[i,j] = np.uint8(gray) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0)算法优化# 1 灰度 最重要 2 基础 3 实时性 # 定点-》浮点 +- */ &gt;&gt; # r*0.299+g*0.587+b*0.114 import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] # RGB R=G=B = gray (R+G+B)/3 dst = np.zeros((height,width,3),np.uint8) for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] b = int(b) g = int(g) r = int(r) #gray = (r*1+g*2+b*1)/4 gray = (r+(g&lt;&lt;1)+b)&gt;&gt;2 dst[i,j] = np.uint8(gray) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 图片颜色反转#0-255 255-当前 灰度图片颜色反转 import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # 1表示一个像素一种颜色 dst = np.zeros((height,width,1),np.uint8) for i in range(0,height): for j in range(0,width): grayPixel = gray[i,j] dst[i,j] = 255-grayPixel cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) #RGB 255-R=newR 彩色图片颜色反转 dst = np.zeros((height,width,3),np.uint8) for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] dst[i,j] = (255-b,255-g,255-r) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 马赛克import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] for m in range(100,300): for n in range(100,200): # pixel -&gt;10*10 所有像素点用一个点替代 if m%10 == 0 and n%10==0: # for循环填充小矩形 for i in range(0,10): for j in range(0,10): (b,g,r) = img[m,n] img[i+m,j+n] = (b,g,r) cv2.imshow(&#39;dst&#39;,img) cv2.waitKey(0) 毛玻璃import cv2 import numpy as np import random img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] dst = np.zeros((height,width,3),np.uint8) mm = 8 ## -mm防止当前矩阵越界 for m in range(0,height-mm): for n in range(0,width-mm): index = int(random.random()*8)#0-8 (b,g,r) = img[m+index,n+index] dst[m,n] = (b,g,r) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 图片融合# dst = src1*a+src2*(1-a) 两张图片都需要大于第一张图片宽和高度的一半 import cv2 import numpy as np img0 = cv2.imread(&#39;image0.jpg&#39;,1) img1 = cv2.imread(&#39;image1.jpg&#39;,1) imgInfo = img0.shape height = imgInfo[0] width = imgInfo[1] # ROI roiH = int(height/2) roiW = int(width/2) img0ROI = img0[0:roiH,0:roiW] img1ROI = img1[0:roiH,0:roiW] # dst dst = np.zeros((roiH,roiW,3),np.uint8) dst = cv2.addWeighted(img0ROI,0.5,img1ROI,0.5,0)#add src1*a+src2*(1-a) # 1 src1 2 a 3 src2 4 1-a cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 图片边缘检测import cv2 import numpy as np import random img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] cv2.imshow(&#39;src&#39;,img) #canny 1 gray 2 高斯 3 canny gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) imgG = cv2.GaussianBlur(gray,(3,3),0) dst = cv2.Canny(img,50,50) #图片卷积——》th cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 源码边缘检测import cv2 import numpy as np import random import math img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] cv2.imshow(&#39;src&#39;,img) # sobel 1 算子模版 2 图片卷积 3 阈值判决 # [1 2 1 [ 1 0 -1 # 0 0 0 2 0 -2 # -1 -2 -1 ] 1 0 -1 ] # 四个点 [1 2 3 4] 计算模板 [a b c d] 卷积后 a*1+b*2+c*3+d*4 = dst # sqrt(a*a+b*b) = f&gt;th 则为边缘 gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) dst = np.zeros((height,width,1),np.uint8) for i in range(0,height-2): for j in range(0,width-2): # 竖直方向梯度 gy = gray[i,j]*1+gray[i,j+1]*2+gray[i,j+2]*1-gray[i+2,j]*1-gray[i+2,j+1]*2-gray[i+2,j+2]*1 # 水平方向梯度 gx = gray[i,j]+gray[i+1,j]*2+gray[i+2,j]-gray[i,j+2]-gray[i+1,j+2]*2-gray[i+2,j+2] # 计算梯度 grad = math.sqrt(gx*gx+gy*gy) if grad&gt;50: dst[i,j] = 255 else: dst[i,j] = 0 cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 浮雕效果import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # newP = gray0-gray1+150 dst = np.zeros((height,width,1),np.uint8) for i in range(0,height): for j in range(0,width-1): grayP0 = int(gray[i,j]) grayP1 = int(gray[i,j+1]) newP = grayP0-grayP1+150 if newP &gt; 255: newP = 255 if newP &lt; 0: newP = 0 dst[i,j] = newP cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 颜色风格import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] #rgb -》RGB new “蓝色” # b=b*1.5 # g = g*1.3 dst = np.zeros((height,width,3),np.uint8) for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] b = b*1.5 g = g*1.3 if b&gt;255: b = 255 if g&gt;255: g = 255 dst[i,j]=(b,g,r) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 油画特效# 1 gray # 2 7*7 10*10 3 0-255 256 4 64 0-63 64-127 # 3 10 0-63 99 64-127 # 4 count 5 dst = result import cv2 import numpy as np img = cv2.imread(&#39;image00.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) dst = np.zeros((height,width,3),np.uint8) for i in range(4,height-4): for j in range(4,width-4): array1 = np.zeros(8,np.uint8) # 定义8*8小方块 for m in range(-4,4): for n in range(-4,4): # 灰度等级划分8个段 每段32，/32知道p1投影在哪个灰度等级段 p1 = int(gray[i+m,j+n]/32) # 当前像素值完成累加 array1[p1] = array1[p1]+1 currentMax = array1[0] # l定义某一段 l = 0 for k in range(0,8): if currentMax&lt;array1[k]: currentMax = array1[k] l = k # 简化或者均值 for m in range(-4,4): for n in range(-4,4): if gray[i+m,j+n]&gt;=(l*32) and gray[i+m,j+n]&lt;=((l+1)*32): (b,g,r) = img[i+m,j+n] dst[i,j] = (b,g,r) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 线段绘制import cv2 import numpy as np newImageInfo = (500,500,3) dst = np.zeros(newImageInfo,np.uint8) # line # 绘制线段 1 dst 2 begin 3 end 4 color cv2.line(dst,(100,100),(400,400),(0,0,255)) # 5 line w cv2.line(dst,(100,200),(400,200),(0,255,255),20) # 6 line type cv2.line(dst,(100,300),(400,300),(0,255,0),20,cv2.LINE_AA) cv2.line(dst,(200,150),(50,250),(25,100,255)) cv2.line(dst,(50,250),(400,380),(25,100,255)) cv2.line(dst,(400,380),(200,150),(25,100,255)) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 矩形圆形绘制import cv2 import numpy as np newImageInfo = (500,500,3) dst = np.zeros(newImageInfo,np.uint8) # 1 2 左上角 3 右下角 4 5 fill -1 &gt;0 line w cv2.rectangle(dst,(50,100),(200,300),(255,0,0),5) # 2 center 3 r cv2.circle(dst,(250,250),(50),(0,255,0),2) # 2 center 3 轴 4 angle 5 begin 6 end 7 cv2.ellipse(dst,(256,256),(150,100),0,0,180,(255,255,0),-1) points = np.array([[150,50],[140,140],[200,170],[250,250],[150,50]],np.int32) print(points.shape) points = points.reshape((-1,1,2)) print(points.shape) cv2.polylines(dst,[points],True,(0,255,255)) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 文字图片绘制import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) font = cv2.FONT_HERSHEY_SIMPLEX cv2.rectangle(img,(200,100),(500,400),(0,255,0),3) # 1 dst 2 文字内容 3 坐标 4 5 字体大小 6 color 7 粗细 8 line type cv2.putText(img,&#39;this is flow&#39;,(100,300),font,1,(200,100,255),2,cv2.LINE_AA) cv2.imshow(&#39;src&#39;,img) cv2.waitKey(0) height = int(img.shape[0]*0.2) width = int(img.shape[1]*0.2) imgResize = cv2.resize(img,(width,height)) for i in range(0,height): for j in range(0,width): img[i+200,j+350] = imgResize[i,j] cv2.imshow(&#39;src&#39;,img) cv2.waitKey(0) 计算机视觉加强之图像美化灰度直方图源码# 1 0-255 2 概率 # 本质：统计每个像素灰度 出现的概率 0-255 p import cv2 import numpy as np import matplotlib.pyplot as plt img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) count = np.zeros(256,np.float) for i in range(0,height): for j in range(0,width): pixel = gray[i,j] index = int(pixel) count[index] = count[index]+1 for i in range(0,255): count[i] = count[i]/(height*width) x = np.linspace(0,255,256) y = count plt.bar(x,y,0.9,alpha=1,color=&#39;b&#39;) plt.show() cv2.waitKey(0)彩色直方图源码# 本质：统计每个像素灰度 出现的概率 0-255 p import cv2 import numpy as np import matplotlib.pyplot as plt img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] count_b = np.zeros(256,np.float) count_g = np.zeros(256,np.float) count_r = np.zeros(256,np.float) for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] index_b = int(b) index_g = int(g) index_r = int(r) count_b[index_b] = count_b[index_b]+1 count_g[index_g] = count_g[index_g]+1 count_r[index_r] = count_r[index_r]+1 for i in range(0,256): count_b[i] = count_b[i]/(height*width) count_g[i] = count_g[i]/(height*width) count_r[i] = count_r[i]/(height*width) x = np.linspace(0,255,256) y1 = count_b plt.figure() plt.bar(x,y1,0.9,alpha=1,color=&#39;b&#39;) y2 = count_g plt.figure() plt.bar(x,y2,0.9,alpha=1,color=&#39;g&#39;) y3 = count_r plt.figure() plt.bar(x,y3,0.9,alpha=1,color=&#39;r&#39;) plt.show() cv2.waitKey(0) 灰度直方图均衡化# 本质：统计每个像素灰度 出现的概率 0-255 p # 累计概率 # 1 0.2 0.2 # 2 0.3 0.5 # 3 0.1 0.6 # 256 # 100 0.5 255*0.5 = new import cv2 import numpy as np import matplotlib.pyplot as plt img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) cv2.imshow(&#39;src&#39;,gray) count = np.zeros(256,np.float) for i in range(0,height): for j in range(0,width): pixel = gray[i,j] index = int(pixel) count[index] = count[index]+1 for i in range(0,255): count[i] = count[i]/(height*width) #计算累计概率 sum1 = float(0) for i in range(0,256): sum1 = sum1+count[i] count[i] = sum1 #print(count) # 计算映射表 map1 = np.zeros(256,np.uint16) for i in range(0,256): map1[i] = np.uint16(count[i]*255) # 映射 for i in range(0,height): for j in range(0,width): pixel = gray[i,j] gray[i,j] = map1[pixel] cv2.imshow(&#39;dst&#39;,gray) cv2.waitKey(0)彩色直方图均衡化# 本质：统计每个像素灰度 出现的概率 0-255 p # 累计概率 # 1 0.2 0.2 # 2 0.3 0.5 # 3 0.1 0.6 # 256 # 100 0.5 255*0.5 = new # 1 统计每个颜色出现的概率 2 累计概率 1 3 0-255 255*p # 4 pixel import cv2 import numpy as np import matplotlib.pyplot as plt img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] count_b = np.zeros(256,np.float) count_g = np.zeros(256,np.float) count_r = np.zeros(256,np.float) for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] index_b = int(b) index_g = int(g) index_r = int(r) count_b[index_b] = count_b[index_b]+1 count_g[index_g] = count_g[index_g]+1 count_r[index_r] = count_r[index_r]+1 for i in range(0,255): count_b[i] = count_b[i]/(height*width) count_g[i] = count_g[i]/(height*width) count_r[i] = count_r[i]/(height*width) #计算累计概率 sum_b = float(0) sum_g = float(0) sum_r = float(0) for i in range(0,256): sum_b = sum_b+count_b[i] sum_g = sum_g+count_g[i] sum_r = sum_r+count_r[i] count_b[i] = sum_b count_g[i] = sum_g count_r[i] = sum_r #print(count) # 计算映射表 map_b = np.zeros(256,np.uint16) map_g = np.zeros(256,np.uint16) map_r = np.zeros(256,np.uint16) for i in range(0,256): map_b[i] = np.uint16(count_b[i]*255) map_g[i] = np.uint16(count_g[i]*255) map_r[i] = np.uint16(count_r[i]*255) # 映射 dst = np.zeros((height,width,3),np.uint8) for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] b = map_b[b] g = map_g[g] r = map_r[r] dst[i,j] = (b,g,r) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 彩色直方图APIimport cv2 import numpy as np def ImageHist(image,type): color = (255,255,255) windowName = &#39;Gray&#39; if type == 31: color = (255,0,0) windowName = &#39;B Hist&#39; elif type == 32: color = (0,255,0) windowName = &#39;G Hist&#39; elif type == 33: color = (0,0,255) windowName = &#39;R Hist&#39; # 计算图片直方图1 image 2 [0]灰度直方图 3 mask None蒙版 4 256 5 0-255 hist = cv2.calcHist([image],[0],None,[256],[0.0,255.0]) # 获取像素值中最大最小值及各自下标 归一化处理 minV,maxV,minL,maxL = cv2.minMaxLoc(hist) histImg = np.zeros([256,256,3],np.uint8) for h in range(256): #处理完后绘制结果 intenNormal = int(hist[h]*256/maxV) cv2.line(histImg,(h,256),(h,256-intenNormal),color) cv2.imshow(windowName,histImg) return histImg img = cv2.imread(&#39;image0.jpg&#39;,1) channels = cv2.split(img)# RGB - R G B for i in range(0,3): ImageHist(channels[i],31+i) cv2.waitKey(0) 直方图均衡化#灰度 直方图均衡化 import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) cv2.imshow(&#39;src&#39;,gray) dst = cv2.equalizeHist(gray) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) #彩色 直方图均衡化 import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) (b,g,r) = cv2.split(img)#通道分解 bH = cv2.equalizeHist(b) gH = cv2.equalizeHist(g) rH = cv2.equalizeHist(r) result = cv2.merge((bH,gH,rH))# 通道合成 cv2.imshow(&#39;dst&#39;,result) cv2.waitKey(0) #YUV 直方图均衡化 import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) imgYUV = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb) cv2.imshow(&#39;src&#39;,img) channelYUV = cv2.split(imgYUV) channelYUV[0] = cv2.equalizeHist(channelYUV[0]) channels = cv2.merge(channelYUV) result = cv2.cvtColor(channels,cv2.COLOR_YCrCb2BGR) cv2.imshow(&#39;dst&#39;,result) cv2.waitKey(0) 图片修补生成坏图import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) for i in range(200,300): img[i,200] = (255,255,255) img[i,200+1] = (255,255,255) img[i,200-1] = (255,255,255) for i in range(150,250): img[250,i] = (255,255,255) img[250+1,i] = (255,255,255) img[250-1,i] = (255,255,255) cv2.imwrite(&#39;damaged.jpg&#39;,img) cv2.imshow(&#39;image&#39;,img) cv2.waitKey(0)修补#1 坏图 2 array 3 inpaint import cv2 import numpy as np img = cv2.imread(&#39;damaged.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] paint = np.zeros((height,width,1),np.uint8) # 描绘坏的部分的数组 for i in range(200,300): paint[i,200] = 255 paint[i,200+1] = 255 paint[i,200-1] = 255 for i in range(150,250): paint[250,i] = 255 paint[250+1,i] = 255 paint[250-1,i] = 255 cv2.imshow(&#39;paint&#39;,paint) #1 src 2 mask imgDst = cv2.inpaint(img,paint,3,cv2.INPAINT_TELEA) cv2.imshow(&#39;image&#39;,imgDst) cv2.waitKey(0) 亮度增强p = p+40import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] cv2.imshow(&#39;src&#39;,img) dst = np.zeros((height,width,3),np.uint8) for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] bb = int(b)+40 gg = int(g)+40 rr = int(r)+40 if bb&gt;255: bb = 255 if gg&gt;255: gg = 255 if rr&gt;255: rr = 255 dst[i,j] = (bb,gg,rr) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) p = p*1.2+40import cv2 import numpy as np img = cv2.imread(&#39;image0.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] cv2.imshow(&#39;src&#39;,img) dst = np.zeros((height,width,3),np.uint8) for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] bb = int(b*1.3)+10 gg = int(g*1.2)+15 if bb&gt;255: bb = 255 if gg&gt;255: gg = 255 dst[i,j] = (bb,gg,r) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 磨皮美白### 双边滤波 import cv2 img = cv2.imread(&#39;1.png&#39;,1) cv2.imshow(&#39;src&#39;,img) dst = cv2.bilateralFilter(img,15,35,35) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 高斯滤波import cv2 import numpy as np img = cv2.imread(&#39;image11.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) dst = cv2.GaussianBlur(img,(5,5),1.5) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 均值滤波#均值 6*6 1 。 * 【6*6】/36 = mean -》P import cv2 import numpy as np img = cv2.imread(&#39;image11.jpg&#39;,1) cv2.imshow(&#39;src&#39;,img) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] dst = np.zeros((height,width,3),np.uint8) for i in range(3,height-3): for j in range(3,width-3): sum_b = int(0) sum_g = int(0) sum_r = int(0) for m in range(-3,3):#-3 -2 -1 0 1 2 for n in range(-3,3): (b,g,r) = img[i+m,j+n] sum_b = sum_b+int(b) sum_g = sum_g+int(g) sum_r = sum_r+int(r) b = np.uint8(sum_b/36) g = np.uint8(sum_g/36) r = np.uint8(sum_r/36) dst[i,j] = (b,g,r) cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) 中值滤波# 中值滤波 3*3 import cv2 import numpy as np img = cv2.imread(&#39;image11.jpg&#39;,1) imgInfo = img.shape height = imgInfo[0] width = imgInfo[1] img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY) cv2.imshow(&#39;src&#39;,img) dst = np.zeros((height,width,3),np.uint8) collect = np.zeros(9,np.uint8) for i in range(1,height-1): for j in range(1,width-1): k = 0 for m in range(-1,2): for n in range(-1,2): gray = img[i+m,j+n] collect[k] = gray k = k+1 # 0 1 2 3 4 5 6 7 8 # 1 for k in range(0,9): p1 = collect[k] for t in range(k+1,9): if p1&lt;collect[t]: mid = collect[t] collect[t] = p1 p1 = mid dst[i,j] = collect[4] cv2.imshow(&#39;dst&#39;,dst) cv2.waitKey(0) Q1:ImportError: libXext.so.6: cannot open shared object file: No such file or directory yum install libXext.x86_64 Q2: ImportError: libSM.so.6: cannot open shared object file: No such file or directory yum install libSM.x86_64 Q3:libXrender.so.1: cannot open shared object file: No such file or directory yum install libXrender.x86_64]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow与Flask结合打造手写体数字识别]]></title>
    <url>%2F2019%2F08%2F30%2FTensorFlow%E4%B8%8EFlask%E7%BB%93%E5%90%88%E6%89%93%E9%80%A0%E6%89%8B%E5%86%99%E4%BD%93%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[TensorFlow与Flask结合打造手写体数字识别 AnacondaAnaconda Navigator新建Env环境,添加channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/tensorflow和opencv，并进入Home安装Jupyter notebook 定义模型modelmnist_testdemo/mnist/model.py 线性模型import tensorflow as tf # Y=W*x+b 线性模型 def regression(x): W = tf.Variable(tf.zeros([784, 10]), name=&quot;W&quot;) b = tf.Variable(tf.zeros([10]), name=&quot;b&quot;) y = tf.nn.softmax(tf.matmul(x, W) + b) return y, [W, b] 卷积模型# 卷积模型 def convolutional(x, keep_prob): # 卷积层 def conv2d(x, W): return tf.nn.conv2d(x, W, [1, 1, 1, 1], padding=&#39;SAME&#39;) # 池化层 def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;) # 定义权重 def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial) # 边 def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial) x_image = tf.reshape(x, [-1, 28, 28, 1]) W_conv1 = weight_variable([5, 5, 1, 32]) b_conv1 = bias_variable([32]) h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) h_pool1 = max_pool_2x2(h_conv1) W_conv2 = weight_variable([5, 5, 32, 64]) b_conv2 = bias_variable([64]) h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) h_pool2 = max_pool_2x2(h_conv2) # full connection W_fc1 = weight_variable([7 * 7 * 64, 1024]) b_fc1 = bias_variable([1024]) h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64]) h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) W_fc2 = weight_variable([1024, 10]) b_fc2 = bias_variable([10]) y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) return y, [W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2] 定义数据mnist_testdemo/mnist/input_data.py from __future__ import absolute_import from __future__ import division from __future__ import print_function import gzip import os import tempfile import numpy from six.moves import urllib from six.moves import xrange import tensorflow as tf from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets 训练线性模型import os import input_data import model import tensorflow as tf # 从input_data中下载数据到MNIST_data data = input_data.read_data_sets(&#39;MNIST_data&#39;, one_hot=True) # create model with tf.variable_scope(&quot;regression&quot;): # 用户输入占位符 x = tf.placeholder(tf.float32, [None, 784]) y, variables = model.regression(x) # train y_ = tf.placeholder(&quot;float&quot;, [None, 10]) cross_entropy = -tf.reduce_sum(y_ * tf.log(y)) # 训练步骤 train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy) # 预测 correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) # 准确度 accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # 保存训练变量参数 saver = tf.train.Saver(variables) # 开始训练 with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for _ in range(20000): batch_xs, batch_ys = data.train.next_batch(100) sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) # 打印测试集和训练集的精准度 print((sess.run(accuracy, feed_dict={x:data.test.images, y_:data.test.labels}))) # 保存训练好的模型 path = saver.save( sess,os.path.join(os.path.dirname(__file__),&#39;data&#39;,&#39;regression.ckpt&#39;), write_meta_graph=False,write_state=False) print(&quot;Saved:&quot;, path) 生成mnist_testdemo/mnist/data/regression.ckpt.data-00000-of-00001和mnist_testdemo/mnist/data/regression.ckpt.index 训练卷积模型import os import model import tensorflow as tf import input_data data = input_data.read_data_sets(&#39;MNIST_data&#39;, one_hot=True) #model with tf.variable_scope(&quot;convolutional&quot;): x = tf.placeholder(tf.float32, [None, 784], name=&#39;x&#39;) keep_prob = tf.placeholder(tf.float32) y, variables = model.convolutional(x, keep_prob) #train y_ = tf.placeholder(tf.float32, [None, 10], name=&#39;y&#39;) cross_entropy = -tf.reduce_sum(y_ * tf.log(y)) # 随机梯度下降 train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) saver = tf.train.Saver(variables) with tf.Session() as sess: merged_summary_op = tf.summary.merge_all() summay_writer = tf.summary.FileWriter(&#39;./mnist_log/1&#39;, sess.graph) summay_writer.add_graph(sess.graph) sess.run(tf.global_variables_initializer()) for i in range(20000): batch = data.train.next_batch(50) if i % 100 == 0: train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0}) print(&quot;step %d, training accuracy %g&quot; % (i, train_accuracy)) sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5}) print(sess.run(accuracy, feed_dict={x: data.test.images, y_: data.test.labels, keep_prob: 1.0})) path = saver.save( sess, os.path.join(os.path.dirname(__file__), &#39;data&#39;, &#39;convalutional.ckpt&#39;), write_meta_graph=False, write_state=False) print(&quot;Saved:&quot;, path) 生成 mnist_testdemo/mnist/data/convalutional.ckpt.data-00000-of-00001和mnist_testdemo/mnist/data/convalutional.ckpt.index 集成flaskmnist_testdemo/main.py # -*- coding:utf-8 -*- import numpy as np import tensorflow as tf from flask import Flask, jsonify, render_template, request import pprint from mnist import model x = tf.placeholder(&quot;float&quot;, [None, 784]) sess = tf.Session() # 取出训练好的线性模型 with tf.variable_scope(&quot;regression&quot;): y1, variables = model.regression(x) saver = tf.train.Saver(variables) saver.restore(sess, &quot;mnist/data/regression.ckpt&quot;) # 取出训练好的卷积模型 with tf.variable_scope(&quot;convolutional&quot;): keep_prob = tf.placeholder(&quot;float&quot;) y2, variables = model.convolutional(x, keep_prob) saver = tf.train.Saver(variables) saver.restore(sess, &quot;mnist/data/convalutional.ckpt&quot;) # 根据输入调用线性模型并返回识别结果 def regression(input): return sess.run(y1, feed_dict={x: input}).flatten().tolist() # 根据输入调用卷积模型并返回识别结果 def convolutional(input): return sess.run(y2, feed_dict={x: input, keep_prob: 1.0}).flatten().tolist() app = Flask(__name__) @app.route(&#39;/api/mnist&#39;, methods=[&#39;POST&#39;]) def mnist(): # pprint.pprint(request.json) input = ((255 - np.array(request.json, dtype=np.uint8)) / 255.0).reshape(1, 784) output1 = regression(input) output2 = convolutional(input) pprint.pprint(output1) pprint.pprint(output2) return jsonify(results=[output1, output2]) @app.route(&#39;/&#39;) def main(): return render_template(&#39;index.html&#39;) if __name__ == &#39;__main__&#39;: app.debug = True app.run(host=&#39;0.0.0.0&#39;, port=8889) js核心代码drawInput() { var ctx = this.input.getContext(&#39;2d&#39;); var img = new Image(); img.onload = () =&gt; { var inputs = []; var small = document.createElement(&#39;canvas&#39;).getContext(&#39;2d&#39;); small.drawImage(img, 0, 0, img.width, img.height, 0, 0, 28, 28); var data = small.getImageData(0, 0, 28, 28).data; for (var i = 0; i &lt; 28; i++) { for (var j = 0; j &lt; 28; j++) { var n = 4 * (i * 28 + j); inputs[i * 28 + j] = (data[n + 0] + data[n + 1] + data[n + 2]) / 3; ctx.fillStyle = &#39;rgb(&#39; + [data[n + 0], data[n + 1], data[n + 2]].join(&#39;,&#39;) + &#39;)&#39;; ctx.fillRect(j * 5, i * 5, 5, 5); } } if (Math.min(...inputs) === 255) { return; } $.ajax({ url: &#39;/api/mnist&#39;, type: &#39;POST&#39;, contentType: &#39;application/json&#39;, data: JSON.stringify(inputs), success: (data) =&gt; { data = JSON.parse(data); for (let i = 0; i &lt; 2; i++) { var max = 0; var max_index = 0; for (let j = 0; j &lt; 10; j++) { var value = Math.round(data.results[i][j] * 1000); if (value &gt; max) { max = value; max_index = j; } var digits = String(value).length; for (var k = 0; k &lt; 3 - digits; k++) { value = &#39;0&#39; + value; } var text = &#39;0.&#39; + value; if (value &gt; 999) { text = &#39;1.000&#39;; } $(&#39;#output tr&#39;).eq(j + 1).find(&#39;td&#39;).eq(i).text(text); } for (let j = 0; j &lt; 10; j++) { if (j === max_index) { $(&#39;#output tr&#39;).eq(j + 1).find(&#39;td&#39;).eq(i).addClass(&#39;success&#39;); } else { $(&#39;#output tr&#39;).eq(j + 1).find(&#39;td&#39;).eq(i).removeClass(&#39;success&#39;); } } } } }); }; img.src = this.canvas.toDataURL(); } 前端将数据inputs以json传入/api/mnist regression(input)和convolutional(input)调用模型feed_dict喂参数返回结果]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nlp依存句法和语义依存分析]]></title>
    <url>%2F2019%2F08%2F27%2Fnlp%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95%E5%92%8C%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[nlp依存句法和语义依存分析 依存句法分析 依存语法 (Dependency Parsing, DP) 通过分析语言单位内成分之间的依存关系揭示其句法结构。 直观来讲,依存句法分析识别句子中的“主谓宾”、“定状补”这些语法成分,并分析各成分之间的关系。 依存句法分析标注关系 (共14种) 及含义如下:主谓关系 SBV subject-verb 我送她一束花 (我 &lt;– 送) 动宾关系 VOB 直接宾语,verb-object 我送她一束花 (送 –&gt; 花) 间宾关系 IOB 间接宾语,indirect-object 我送她一束花 (送 –&gt; 她) 前置宾语 FOB 前置宾语,fronting-object 他什么乢都读 (乢 &lt;– 读) 兼语 DBL double 他请我吃饭 (请 –&gt; 我) 定中关系 ATT attribute 红苹果 (红 &lt;– 苹果) 状中结构 ADV adverbial 非常美丽 (非常 &lt;– 美丽) 动补结构 CMP complement 做完了作业 (做 –&gt; 完) 并列关系 COO coordinate 大山和大海 (大山 –&gt; 大海) 介宾关系 POB preposition-object 在贸易区内 (在 –&gt; 内) 左附加关系 LAD left adjunct 大山和大海 (和 &lt;– 大海) 右附加关系 RAD right adjunct 孩子们 (孩子 –&gt; 们) 独立结构 IS independent structure 两个单句在结构上彼此独立 核心关系 HED head 指整个句子的核心 依存句法树解析recursionSearch.py # encoding=utf8 import re, os, json from stanfordParse import pos from stanfordParse import parse_sentence from recursionSearch import search def split_long_sentence_by_pos(text): del_flag = [&#39;DEC&#39;, &#39;AD&#39;, &#39;DEG&#39;, &#39;DER&#39;, &#39;DEV&#39;, &#39;SP&#39;, &#39;AS&#39;, &#39;ETC&#39;, &#39;SP&#39;, &#39;MSP&#39;, &#39;IJ&#39;, &#39;ON&#39;, &#39;JJ&#39;, &#39;FW&#39;, &#39;LB&#39;, &#39;SB&#39;, &#39;BA&#39;, &#39;AD&#39;, &#39;PN&#39;, &#39;RB&#39;] pos_tag = pos(text) new_str = &#39;&#39; for apos in pos_tag: if apos[1] not in del_flag: new_str += apos[0] return new_str def extract_parallel(text): parallel_text = [] pattern = re.compile(&#39;[，,][\u4e00-\u9fa5]{2,4}[，,]&#39;) search_obj = pattern.search(text) if search_obj: start_start, end = search_obj.span() rep = text[start_start:end - 2] rep1 = text[start_start:end - 1] if &#39;，&#39; in rep1: rep1.replace(&#39;，&#39;, &#39;、&#39;) if &#39;,&#39; in rep1: rep1.replace(&#39;,&#39;, &#39;、&#39;) text.replace(rep1, text) parallel_text.append(rep[1:]) text_leave = text.replace(rep, &#39;&#39;) while pattern.search(text_leave): start, end = pattern.search(text_leave).span() rep = text_leave[start:end - 2] rep1 = text[start_start:end - 1] if &#39;，&#39; in rep1: rep1.replace(&#39;，&#39;, &#39;、&#39;) if &#39;,&#39; in rep1: rep1.replace(&#39;,&#39;, &#39;、&#39;) text.replace(rep1, text) text_leave = text_leave.replace(rep, &#39;&#39;) parallel_text.append(rep[1:]) return parallel_text, text else: return None, text def split_long_sentence_by_sep(text): segment = [] if &#39;。&#39; or &#39;.&#39; or &#39;!&#39; or &#39;！&#39; or &#39;?&#39; or &#39;？&#39; or &#39;;&#39; or &#39;；&#39; in text: text = re.split(r&#39;[。.!！?？;；]&#39;, text) for seg in text: if seg == &#39;&#39; or seg == &#39; &#39;: continue para, seg = extract_parallel(seg) if len(seg) &gt; 19: seg = split_long_sentence_by_pos(seg) if len(seg) &gt; 19: seg = re.split(&#39;[，,]&#39;, seg) if isinstance(seg, list) and &#39;&#39; in seg: seg = seg.remove(&#39;&#39;) if isinstance(seg, list) and &#39; &#39; in seg: seg = seg.remove(&#39; &#39;) segment.append(seg) return segment def read_data(path): return open(path, &quot;r&quot;, encoding=&quot;utf8&quot;) def get_np_words(t): noun_phrase_list = [] for tree in t.subtrees(lambda t: t.height() == 3): if tree.label() == &#39;NP&#39; and len(tree.leaves()) &gt; 1: noun_phrase = &#39;&#39;.join(tree.leaves()) noun_phrase_list.append(noun_phrase) return noun_phrase_list def get_n_v_pair(t): for tree in t.subtrees(lambda t: t.height() == 3): if tree.label() == &#39;NP&#39; and len(tree.leaves()) &gt; 1: noun_phrase = &#39;&#39;.join(tree.leaves()) if __name__ == &quot;__main__&quot;: out = open(&quot;dependency.txt&quot;, &#39;w&#39;, encoding=&#39;utf8&#39;) itera = read_data(&#39;text.txt&#39;) for it in itera: s = parse_sentence(it) # 通过Stanfordnlp依存句法分析得到一个句法树 用nltk包装成树的结构 res = search(s) # 使用nltk遍历树，然后把短语合并 print(res) stanfordParse.py # encoding=utf8 from stanfordcorenlp import StanfordCoreNLP from nltk import Tree, ProbabilisticTree nlp = StanfordCoreNLP(&#39;E:/stanford-corenlp-full-2018-10-05&#39;, lang=&#39;zh&#39;) import nltk, re grammer = &quot;NP: {&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;}&quot; cp = nltk.RegexpParser(grammer) # 生成规则 pattern = re.compile(u&#39;[^a-zA-Z\u4E00-\u9FA5]&#39;) pattern_del = re.compile(&#39;(\a-zA-Z0-9+)&#39;) def _replace_c(text): &quot;&quot;&quot; 将英文标点符号替换成中文标点符号，并去除html语言的一些标志等噪音 :param text: :return: &quot;&quot;&quot; intab = &quot;,?!()&quot; outtab = &quot;，？！（）&quot; deltab = &quot; \n&lt;li&gt;&lt; li&gt;+_-.&gt;&lt;li \U0010fc01 _&quot; trantab = text.maketrans(intab, outtab, deltab) return text.translate(trantab) def parse_sentence(text): text = _replace_c(text) # 文本去噪 try: if len(text.strip()) &gt; 6: # 判断，文本是否大于6个字，小于6个字的我们认为不是句子 return Tree.fromstring( nlp.parse(text.strip())) # nlp.parse(text.strip())：是将句子变成依存句法树 Tree.fromstring是将str类型的树转换成nltk的结构的树 except: pass def pos(text): text = _replace_c(text) if len(text.strip()) &gt; 6: return nlp.pos_tag(text) else: return False def denpency_parse(text): return nlp.dependency_parse(text) from nltk.chunk.regexp import * sentenceSplit_host.py # encoding=utf8 import re, os, json from stanfordParse import pos from stanfordParse import parse_sentence from recursionSearch import search def split_long_sentence_by_pos(text): del_flag = [&#39;DEC&#39;, &#39;AD&#39;, &#39;DEG&#39;, &#39;DER&#39;, &#39;DEV&#39;, &#39;SP&#39;, &#39;AS&#39;, &#39;ETC&#39;, &#39;SP&#39;, &#39;MSP&#39;, &#39;IJ&#39;, &#39;ON&#39;, &#39;JJ&#39;, &#39;FW&#39;, &#39;LB&#39;, &#39;SB&#39;, &#39;BA&#39;, &#39;AD&#39;, &#39;PN&#39;, &#39;RB&#39;] pos_tag = pos(text) new_str = &#39;&#39; for apos in pos_tag: if apos[1] not in del_flag: new_str += apos[0] return new_str def extract_parallel(text): parallel_text = [] pattern = re.compile(&#39;[，,][\u4e00-\u9fa5]{2,4}[，,]&#39;) search_obj = pattern.search(text) if search_obj: start_start, end = search_obj.span() rep = text[start_start:end - 2] rep1 = text[start_start:end - 1] if &#39;，&#39; in rep1: rep1.replace(&#39;，&#39;, &#39;、&#39;) if &#39;,&#39; in rep1: rep1.replace(&#39;,&#39;, &#39;、&#39;) text.replace(rep1, text) parallel_text.append(rep[1:]) text_leave = text.replace(rep, &#39;&#39;) while pattern.search(text_leave): start, end = pattern.search(text_leave).span() rep = text_leave[start:end - 2] rep1 = text[start_start:end - 1] if &#39;，&#39; in rep1: rep1.replace(&#39;，&#39;, &#39;、&#39;) if &#39;,&#39; in rep1: rep1.replace(&#39;,&#39;, &#39;、&#39;) text.replace(rep1, text) text_leave = text_leave.replace(rep, &#39;&#39;) parallel_text.append(rep[1:]) return parallel_text, text else: return None, text def split_long_sentence_by_sep(text): segment = [] if &#39;。&#39; or &#39;.&#39; or &#39;!&#39; or &#39;！&#39; or &#39;?&#39; or &#39;？&#39; or &#39;;&#39; or &#39;；&#39; in text: text = re.split(r&#39;[。.!！?？;；]&#39;, text) for seg in text: if seg == &#39;&#39; or seg == &#39; &#39;: continue para, seg = extract_parallel(seg) if len(seg) &gt; 19: seg = split_long_sentence_by_pos(seg) if len(seg) &gt; 19: seg = re.split(&#39;[，,]&#39;, seg) if isinstance(seg, list) and &#39;&#39; in seg: seg = seg.remove(&#39;&#39;) if isinstance(seg, list) and &#39; &#39; in seg: seg = seg.remove(&#39; &#39;) segment.append(seg) return segment def read_data(path): return open(path, &quot;r&quot;, encoding=&quot;utf8&quot;) def get_np_words(t): noun_phrase_list = [] for tree in t.subtrees(lambda t: t.height() == 3): if tree.label() == &#39;NP&#39; and len(tree.leaves()) &gt; 1: noun_phrase = &#39;&#39;.join(tree.leaves()) noun_phrase_list.append(noun_phrase) return noun_phrase_list def get_n_v_pair(t): for tree in t.subtrees(lambda t: t.height() == 3): if tree.label() == &#39;NP&#39; and len(tree.leaves()) &gt; 1: noun_phrase = &#39;&#39;.join(tree.leaves()) if __name__ == &quot;__main__&quot;: out = open(&quot;dependency.txt&quot;, &#39;w&#39;, encoding=&#39;utf8&#39;) itera = read_data(&#39;text.txt&#39;) for it in itera: s = parse_sentence(it) # 通过Stanfordnlp依存句法分析得到一个句法树 用nltk包装成树的结构 res = search(s) # 使用nltk遍历树，然后把短语合并 print(res) 语义依存分析 语义依存分析：分析句子各个语言单位之间的语义关联,并将语义关联以依存结构呈现。使用语义依存刻画句子语义,好处在于丌需要去抽象词汇本身,而是通过词汇所承受的语义框架来描述该词汇,而论元的数目相对词汇来说数量总是少了很多的。语义依存分析目标是跨越句子表层句法结构的束缚,直接获取深层的语义信息。 例如以下三个句子,用不同的表达方式表达了同一个语义信息,即张三实施了一个吃的动作,吃的动作是对苹果实施的。 • 语义依存分析不受句法结构的影响,将具有直接语义关联的语言单元直接连接依存弧并标记上相应的语义关系。这也是语义依存分析不句法依存分析的重要区别。 • 语义依存关系分为三类,分别是主要语义角色,每一种语义角色对应存在一个嵌套关系和反关系;事件关系,描述两个事件间的关系;语义依附标记,标记说话者语气等依附性信息。 语义依存分析标注关系及含义如下:关系类型 Tag Description Example 施事关系 Agt Agent 我送她一束花 (我 &lt;-- 送) 当事关系 Exp Experiencer 我跑得快 (跑 --&gt; 我) 感事关系 Aft Affection 我思念家乡 (思念 --&gt; 我) 领事关系 Poss Possessor 他有一本好读 (他 &lt;-- 有) 受事关系 Pat Patient 他打了小明 (打 --&gt; 小明) 客事关系 Cont Content 他听到鞭炮声 (听 --&gt; 鞭炮声) 成事关系 Prod Product 他写了本小说 (写 --&gt; 小说) 源事关系 Orig Origin 我军缴获敌人四辆坦克 (缴获 --&gt; 坦克) 涉事关系 Datv Dative 他告诉我个秘密 ( 告诉 --&gt; 我 ) 比较角色 Comp Comitative 他成绩比我好 (他 --&gt; 我) 属事角色 Belg Belongings 老赵有俩女儿 (老赵 &lt;-- 有) 类事角色 Clas Classification 他是中学生 (是 --&gt; 中学生) 依据角色 Accd According 本庭依法宣判 (依法 &lt;-- 宣判) 缘故角色 Reas Reason 他在愁女儿婚事 (愁 --&gt; 婚事) 。。。。。。 名词短语块挖掘# encoding=utf8 import os, json, nltk, re from jpype import * from tokenizer import cut_hanlp huanhang = set([&#39;。&#39;, &#39;？&#39;, &#39;！&#39;, &#39;?&#39;]) keep_pos = &quot;q,qg,qt,qv,s,t,tg,g,gb,gbc,gc,gg,gm,gp,mg,Mg,n,an,ude1,nr,ns,nt,nz,nb,nba,nbc,nbp,nf,ng,nh,nhd,o,nz,nx,ntu,nts,nto,nth,ntch,ntcf,ntcb,ntc,nt,nsf,ns,nrj,nrf,nr2,nr1,nr,nnt,nnd,nn,nmc,nm,nl,nit,nis,nic,ni,nhm,nhd&quot; keep_pos_nouns = set(keep_pos.split(&quot;,&quot;)) keep_pos_v = &quot;v,vd,vg,vf,vl,vshi,vyou,vx,vi,vn&quot; keep_pos_v = set(keep_pos_v.split(&quot;,&quot;)) keep_pos_p = set([&#39;p&#39;, &#39;pbei&#39;, &#39;pba&#39;]) merge_pos = keep_pos_p | keep_pos_v keep_flag = set( [&#39;：&#39;, &#39;，&#39;, &#39;？&#39;, &#39;。&#39;, &#39;！&#39;, &#39;；&#39;, &#39;、&#39;, &#39;-&#39;, &#39;.&#39;, &#39;!&#39;, &#39;,&#39;, &#39;:&#39;, &#39;;&#39;, &#39;?&#39;, &#39;(&#39;, &#39;)&#39;, &#39;（&#39;, &#39;）&#39;, &#39;&lt;&#39;, &#39;&gt;&#39;, &#39;《&#39;, &#39;》&#39;]) drop_pos_set = set( [&#39;xu&#39;, &#39;xx&#39;, &#39;y&#39;, &#39;yg&#39;, &#39;wh&#39;, &#39;wky&#39;, &#39;wkz&#39;, &#39;wp&#39;, &#39;ws&#39;, &#39;wyy&#39;, &#39;wyz&#39;, &#39;wb&#39;, &#39;u&#39;, &#39;ud&#39;, &#39;ude1&#39;, &#39;ude2&#39;, &#39;ude3&#39;, &#39;udeng&#39;, &#39;udh&#39;]) def getNodes(parent, model_tagged_file): # 使用for循环遍历树 text = &#39;&#39; for node in parent: if type(node) is nltk.Tree: # 如果是NP或者VP的合并分词 if node.label() == &#39;NP&#39;: text += &#39;&#39;.join(node_child[0].strip() for node_child in node.leaves()) + &quot;/NP&quot; + 3 * &quot; &quot; if node.label() == &#39;VP&#39;: text += &#39;&#39;.join(node_child[0].strip() for node_child in node.leaves()) + &quot;/VP&quot; + 3 * &quot; &quot; else: # 不是树的，就是叶子节点，我们直接表解词PP或者其他O if node[1] in keep_pos_p: text += node[0].strip() + &quot;/PP&quot; + 3 * &quot; &quot; if node[0] in huanhang: text += node[0].strip() + &quot;/O&quot; + 3 * &quot; &quot; if node[1] not in merge_pos: text += node[0].strip() + &quot;/O&quot; + 3 * &quot; &quot; # print(&quot;hh&quot;) model_tagged_file.write(text + &quot;\n&quot;) def grammer(sentence, model_tagged_file): # {内/f 训/v 师/ng 单/b 柜/ng} &quot;&quot;&quot; input sentences shape like :[(&#39;工作&#39;, &#39;vn&#39;), (&#39;描述&#39;, &#39;v&#39;), (&#39;：&#39;, &#39;w&#39;), (&#39;我&#39;, &#39;rr&#39;), (&#39;曾&#39;, &#39;d&#39;), (&#39;在&#39;, &#39;p&#39;)] &quot;&quot;&quot; # 定义名词块 “&lt; &gt;”:一个单元 “*”：匹配零次或多次 “+”：匹配一次或多次 “&lt;ude1&gt;?”： “的”出现零次或一次 grammar1 = r&quot;&quot;&quot;NP: {&lt;m|mg|Mg|mq|q|qg|qt|qv|s|&gt;*&lt;a|an|ag&gt;*&lt;s|g|gb|gbc|gc|gg|gm|gp|n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|o|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd&gt;+&lt;f&gt;?&lt;ude1&gt;?&lt;g|gb|gbc|gc|gg|gm|gp|n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|o|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd&gt;+} {&lt;n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd&gt;+&lt;cc&gt;+&lt;n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd&gt;+} {&lt;m|mg|Mg|mq|q|qg|qt|qv|s|&gt;*&lt;q|qg|qt|qv&gt;*&lt;f|b&gt;*&lt;vi|v|vn|vg|vd&gt;+&lt;ude1&gt;+&lt;n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd&gt;+} {&lt;g|gb|gbc|gc|gg|gm|gp|n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd&gt;+&lt;vi&gt;?} VP:{&lt;v|vd|vg|vf|vl|vshi|vyou|vx|vi|vn&gt;+} &quot;&quot;&quot; # 动词短语块 cp = nltk.RegexpParser(grammar1) try: result = cp.parse(sentence) # nltk的依存语法分析，输出是以grammer设置的名词块为单位的树 except: pass else: getNodes(result, model_tagged_file) # 使用 getNodes 遍历树【这个是使用for循环，上一个是使用栈动态添加】 def data_read(): fout = open(&#39;nvp.txt&#39;, &#39;w&#39;, encoding=&#39;utf8&#39;) for line in open(&#39;text.txt&#39;, &#39;r&#39;, encoding=&#39;utf8&#39;): line = line.strip() grammer(cut_hanlp(line), fout) # 先进行hanlp进行分词，在使用grammer进行合并短语 fout.close() if __name__ == &#39;__main__&#39;: data_read() 自定义语法与CFG什么是语法解析? • 在自然语言学习过程中,每个人一定都学过语法,例如句子可以用主语、谓语、宾语来表示。在自然语言的处理过程中,有许多应用场景都需要考虑句子的语法,因此研究语法解析变得非常重要。 • 语法解析有两个主要的问题,其一是句子语法在计算机中的表达与存储方法,以及语料数据集;其二是语法解析的算法。 句子语法在计算机中的表达与存储方法• 对于第一个问题,我们可以用树状结构图来表示,如下图所示,S表示句子;NP、VP、PP是名词、动词、介词短语(短语级别);N、V、P分别是名词、动词、介词。 语法解析的算法上下文无关语法(Context-Free Grammer)• 为了生成句子的语法树,我们可以定义如下的一套上下文无关语法。 • 1)N表示一组非叶子节点的标注,例如{S、NP、VP、N...} • 2)Σ表示一组叶子结点的标注,例如{boeing、is...} • 3)R表示一组觃则,每条规则可以表示为 • 4)S表示语法树开始的标注 • 举例来说,语法的一个语法子集可以表示为下图所示。 当给定一个句子时,我们便可以按照从左到右的顺序来解析语法。 例如,句子the man sleeps就可以表示为(S (NP (DT the) (NN man)) (VP sleeps))。 概率分布的上下文无关语法(Probabilistic Context-Free Grammar)• 上下文无关的语法可以很容易的推导出一个句子的语法结构,但是缺点是推导出的结构可能存在二义性。 • 由于语法的解析存在二义性,我们就需要找到一种方法从多种可能的语法树中找出最可能的一棵树。 一种常见的方法既是PCFG (Probabilistic Context-Free Grammar)。 如下图所示,除了常见的语法规则以外,我们还对每一条规则赋予了一个概率。 对于每一棵生成的语法树,我们将其中所有规则的概率的乘积作为语法树的出现概率。 当我们获得多颗语法树时,我们可以分别计算每颗语法树的概率p(t),出现概率最大的那颗语法树就是我们希望得到的结果,即arg max p(t)。 训练算法• 我们已经定义了语法解析的算法,而这个算法依赖于CFG中对于N、Σ、 R、S的定义以及PCFG中的p(x)。上文中我们提到了Penn Treebank通 过手工的方法已经提供了一个非常大的语料数据集,我们的任务就是从 语料库中训练出PCFG所需要的参数。 • 1)统计出语料库中所有的N与Σ; • 2)利用语料库中的所有规则作为R; • 3)针对每个规则A -&gt; B,从语料库中估算p(x) = p(A -&gt; B) / p(A); • 在CFG的定义的基础上,我们重新定义一种叫Chomsky的语法格式。 这种格式要求每条规则只能是X -&gt; Y1 Y2或者X -&gt; Y的格式。实际上 Chomsky语法格式保证生产的语法树总是二叉树的格式,同时任意一 棵语法树总是能够转化成Chomsky语法格式。语法树预测算法• 假设我们已经有一个PCFG的模型,包含N、Σ、R、S、p(x)等参数,并 且语法树总是Chomsky语法格式。当输入一个句子x1, x2, ... , xn时, 我们要如何计算句子对应的语法树呢? • 第一种方法是暴力遍历的方法,每个单词x可能有m = len(N)种取值, 句子长度是n,每种情况至少存在n个规则,所以在时间复杂度O(m n n) 的情况下,我们可以判断出所有可能的语法树并计算出最佳的那个。 • 第二种方法当然是动态规划,我们定义w[i, j, X]是第i个单词至第j个单 词由标注X来表示的最大概率。直观来讲,例如xi, xi+1, ... , xj,当 X=PP时,子树可能是多种解释方式,如(P NP)或者(PP PP),但是w[i, j, PP]代表的是继续往上一层递归时,我们只选择当前概率最大的组合 方式。 语法解析按照上述的算法过程便完成了。虽说PCFG也有一些缺点,例如:1)缺乏词法信息;2)连续短语(如名词、介词)的处理等。但总体来讲它给语法解析提供了一种非常有效的实现方法。 # encoding=utf8 def exec_cmd(cmd): p = subprocess.Popen( cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, env=ENVIRON) out, err = p.communicate() return out, err import nltk, os, jieba from nltk.tree import Tree from nltk.draw import TreeWidget from nltk.draw.tree import TreeView from nltk.draw.util import CanvasFrame from nltk.parse import RecursiveDescentParser class Cfg(): &#39;&#39;&#39; &#39;&#39;&#39; def setUp(self): pass def tearDown(self): pass def test_sample(self): print(&quot;test_sample&quot;) # This is a CFG grammar, where: # Start Symbol : S # Nonterminal : NP,VP,DT,NN,VB # Terminal : &quot;I&quot;, &quot;a&quot; ,&quot;saw&quot; ,&quot;dog&quot; grammar = nltk.grammar.CFG.fromstring(&quot;&quot;&quot; S -&gt; NP VP NP -&gt; DT NN | NN VP -&gt; VB NP DT -&gt; &quot;a&quot; NN -&gt; &quot;I&quot; | &quot;dog&quot; VB -&gt; &quot;saw&quot; &quot;&quot;&quot;) sentence = &quot;I saw a dog&quot;.split() parser = RecursiveDescentParser(grammar) final_tree = parser.parse(sentence) for i in final_tree: print(i) def test_nltk_cfg_qtype(self): print(&quot;test_nltk_cfg_qtype&quot;) gfile = os.path.join( curdir, os.path.pardir, &quot;config&quot;, &quot;grammar.question-type.cfg&quot;) question_grammar = nltk.data.load(&#39;file:%s&#39; % gfile) def get_missing_words(grammar, tokens): &quot;&quot;&quot; Find list of missing tokens not covered by grammar &quot;&quot;&quot; missing = [tok for tok in tokens if not grammar._lexical_index.get(tok)] return missing sentence = &quot;what is your name&quot; sent = sentence.split() missing = get_missing_words(question_grammar, sent) target = [] for x in sent: if x in missing: continue target.append(x) rd_parser = RecursiveDescentParser(question_grammar) result = [] print(&quot;target: &quot;, target) for tree in rd_parser.parse(target): result.append(x) print(&quot;Question Type\n&quot;, tree) if len(result) == 0: print(&quot;Not Question Type&quot;) def cfg_en(self): print(&quot;test_nltk_cfg_en&quot;) # 定义英文语法规则 grammar = nltk.CFG.fromstring(&quot;&quot;&quot; S -&gt; NP VP VP -&gt; V NP | V NP PP V -&gt; &quot;saw&quot; | &quot;ate&quot; NP -&gt; &quot;John&quot; | &quot;Mary&quot; | &quot;Bob&quot; | Det N | Det N PP Det -&gt; &quot;a&quot; | &quot;an&quot; | &quot;the&quot; | &quot;my&quot; N -&gt; &quot;dog&quot; | &quot;cat&quot; | &quot;cookie&quot; | &quot;park&quot; PP -&gt; P NP P -&gt; &quot;in&quot; | &quot;on&quot; | &quot;by&quot; | &quot;with&quot; &quot;&quot;&quot;) sent = &quot;Mary saw Bob&quot;.split() rd_parser = RecursiveDescentParser(grammar) result = [] for i, tree in enumerate(rd_parser.parse(sent)): result.append(tree) assert len(result) &gt; 0, &quot; CFG tree parse fail.&quot; print(result) def cfg_zh(self): grammar = nltk.CFG.fromstring(&quot;&quot;&quot; S -&gt; N VP VP -&gt; V NP | V NP | V N V -&gt; &quot;尊敬&quot; N -&gt; &quot;我们&quot; | &quot;老师&quot; &quot;&quot;&quot;) sent = &quot;我们 尊敬 老师&quot;.split() rd_parser = RecursiveDescentParser(grammar) result = [] for i, tree in enumerate(rd_parser.parse(sent)): result.append(tree) print(&quot;Tree [%s]: %s&quot; % (i + 1, tree)) assert len(result) &gt; 0, &quot;Can not recognize CFG tree.&quot; if len(result) == 1: print(&quot;Draw tree with Display ...&quot;) result[0].draw() else: print(&quot;WARN: Get more then one trees.&quot;) print(result) if __name__ == &#39;__main__&#39;: cfg = Cfg() cfg.cfg_en() cfg.cfg_zh()]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nlp分词词性标注及命名实体]]></title>
    <url>%2F2019%2F08%2F27%2Fnlp%E5%88%86%E8%AF%8D%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8%E5%8F%8A%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%2F</url>
    <content type="text"><![CDATA[nlp分词词性标注及命名实体 分词==中文分词==(Chinese Word Segmentation) 指的是将一个汉字序列切分成一个一个单独的词。分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。 词性标注==词性标注==(Part-of-Speech tagging 或POS tagging) 又称词类标注或者简称标注,是指为分词结果中的每个单词标注一个正确的词性的程 序,也即确定每个词是名词、动词、形容词或其他词性的过程。在汉语中,词性标注比较简单,因为汉语词汇词性多变的情况比较少见,大多词语只有一个词性,或者出现频次最高的词性远远高于第二位的词性。据说,只需选取最高频词性,即可实现80%准确率的中文词性标注程序。 命名实体识别==命名实体识别==(Named Entity Recognition,简称NER) 又称作“专名识别”,是指识别文本中具有特定意义的实体,主要包括人名、地名、机构名、专有名词等。一般来说,命名实体识别的任务就是识别出待处理文本中三大类(实体类、时间类和数字类)、七小类(人名、机构名、地名、时间、日期、货币和百分比)命名实体。 在不同的顷目中,命名实体类别具有不同的定义。 准确分词之加载自定义字典分词当分词工具分词不准确时,该怎么办? 加载自定义字典?该如何加载?cut_data.py # -*- coding=utf8 -*- import jieba import re from tokenizer import cut_hanlp # 加载字典 jieba.load_userdict(&quot;dict.txt&quot;) # 交叉拼接list，把FLAG*替换成*期 def merge_two_list(a, b): c = [] len_a, len_b = len(a), len(b) minlen = min(len_a, len_b) for i in range(minlen): c.append(a[i]) c.append(b[i]) if len_a &gt; len_b: for i in range(minlen, len_a): c.append(a[i]) else: for i in range(minlen, len_b): c.append(b[i]) return c if __name__ == &quot;__main__&quot;: fp = open(&quot;text.txt&quot;, &quot;r&quot;, encoding=&quot;utf8&quot;) fout = open(&quot;result_cut.txt&quot;, &quot;w&quot;, encoding=&quot;utf8&quot;) # 特殊符号字典无法分离，正则区分 regex1 = u&#39;(?:[^\u4e00-\u9fa5（）*&amp;……%￥$，,。.@! ！]){1,5}期&#39; # 非汉字xxx期 regex2 = r&#39;(?:[0-9]{1,3}[.]?[0-9]{1,3})%&#39; # xx.xx% p1 = re.compile(regex1) p2 = re.compile(regex2) for line in fp.readlines(): # 逐行读取 result1 = p1.findall(line) # 返回匹配到的list if result1: regex_re1 = result1 line = p1.sub(&quot;FLAG1&quot;, line) # 将匹配到的替换成FLAG1 result2 = p2.findall(line) if result2: line = p2.sub(&quot;FLAG2&quot;, line) words = jieba.cut(line) # 结巴分词，type(word)返回一个generator object result = &quot; &quot;.join(words) # 结巴分词结果 本身是一个generator object，所以使用 “ ”.join() 拼接起来 # E:\hanlp\data\dictionary\custom\resume_nouns.txt在E:\hanlp\hanlp.properties配置 # CustomDictionaryPath=data/dictionary/custom/CustomDictionary.txt; 现代汉语补充词库.txt; 全国地名大全.txt ns; 人名词典.txt; 机构名词典.txt; resume_nouns.txt; 上海地名.txt ns;data/dictionary/person/nrf.txt nrf; words1 = cut_hanlp(line) # hanlp分词结果，返回的是str if &quot;FLAG1&quot; in result: result = result.split(&quot;FLAG1&quot;) result = merge_two_list(result, result1) ss = result result = &quot;&quot;.join(result) # 本身是个list，我们需要的是str，所以使用 &quot;&quot;.join() 拼接起来 if &quot;FLAG2&quot; in result: result = result.split(&quot;FLAG2&quot;) result = merge_two_list(result, result2) result = &quot;&quot;.join(result) # print(result) fout.write(&quot;jieba:&quot; + result) fout.write(&quot;hanlp:&quot; + words1) fout.close() tokenizer.py # encoding=utf8 import os, gc, re, sys from jpype import * root_path = &quot;E:/hanlp&quot; djclass_path = &quot;-Djava.class.path=&quot; + root_path + os.sep + &quot;hanlp-1.7.4.jar;&quot; + root_path startJVM(getDefaultJVMPath(), djclass_path, &quot;-Xms1g&quot;, &quot;-Xmx1g&quot;) Tokenizer = JClass(&#39;com.hankcs.hanlp.tokenizer.StandardTokenizer&#39;) def to_string(sentence, return_generator=False): if return_generator: return (word_pos_item.toString().split(&#39;/&#39;) for word_pos_item in Tokenizer.segment(sentence)) else: return &quot; &quot;.join([word_pos_item.toString().split(&#39;/&#39;)[0] for word_pos_item in Tokenizer.segment(sentence)]) # 这里的“”.split(&#39;/&#39;)可以将string拆分成list 如：&#39;ssfa/fsss&#39;.split(&#39;/&#39;) =&gt; [&#39;ssfa&#39;, &#39;fsss&#39;] def seg_sentences(sentence, with_filter=True, return_generator=False): segs = to_string(sentence, return_generator=return_generator) if with_filter: g = [word_pos_pair[0] for word_pos_pair in segs if len(word_pos_pair) == 2 and word_pos_pair[0] != &#39; &#39; and word_pos_pair[1] not in drop_pos_set] else: g = [word_pos_pair[0] for word_pos_pair in segs if len(word_pos_pair) == 2 and word_pos_pair[0] != &#39; &#39;] return iter(g) if return_generator else g def cut_hanlp(raw_sentence, return_list=True): if len(raw_sentence.strip()) &gt; 0: return to_string(raw_sentence) if return_list else iter(to_string(raw_sentence)) 准确分词之动态调整词频和字典顺序当分词字典的词冲突,相互影响该怎么办? 调整词频和字典顺序。cut_data.py # -*- coding=utf8 -*- import jieba import re from tokenizer import cut_hanlp jieba.load_userdict(&quot;dict.txt&quot;) # # 设置高词频：一个 # jieba.suggest_freq(&#39;台中&#39;,tune=True) # 设置高词频：dict.txt中的每一行都设置一下 # fp=open(&quot;dict.txt&quot;, &#39;r&#39;, encoding=&#39;utf8&#39;) # for line in fp: # line = line.strip() # jieba.suggest_freq(line, tune=True) # # 设置高词频：dict.txt中的每一行都设置一下快速方法 [jieba.suggest_freq(line.strip(), tune=True) for line in open(&quot;dict.txt&quot;, &#39;r&#39;, encoding=&#39;utf8&#39;)] if __name__ == &quot;__main__&quot;: string = &quot;台中正确应该不会被切开。&quot; # 通过调整词频 suggest_freq(line, tune=True) words_jieba = &quot; &quot;.join(jieba.cut(string, HMM=False)) # 通过排序sort_dict_by_lenth，优先按照长的字典项匹配 words_hanlp = cut_hanlp(string) print(&quot;words_jieba:&quot; + words_jieba, &#39;\n&#39;, &quot;words_hanlp:&quot; + words_hanlp) sort_dict_by_lenth.py # encoding=utf8 import os dict_file = open( &quot;E:&quot; + os.sep + &quot;hanlp&quot; + os.sep + &quot;data&quot; + os.sep + &quot;dictionary&quot; + os.sep + &quot;custom&quot; + os.sep + &quot;resume_nouns.txt&quot;, &#39;r&#39;, encoding=&#39;utf8&#39;) d = {} [d.update({line: len(line.split(&quot; &quot;)[0])}) for line in dict_file] # 读取源字典文件并从长到短排序 优先匹配长字典项 f = sorted(d.items(), key=lambda x: x[1], reverse=True) dict_file = open( &quot;E:&quot; + os.sep + &quot;hanlp&quot; + os.sep + &quot;data&quot; + os.sep + &quot;dictionary&quot; + os.sep + &quot;custom&quot; + os.sep + &quot;resume_nouns1.txt&quot;, &#39;w&#39;, encoding=&#39;utf8&#39;) [dict_file.write(item[0]) for item in f] dict_file.close() 词性标注代码实现及信息提取extract_data.py # -*- coding=utf8 -*- import jieba import re from tokenizer import seg_sentences fp = open(&quot;text.txt&quot;, &#39;r&#39;, encoding=&#39;utf8&#39;) fout = open(&quot;out.txt&quot;, &#39;w&#39;, encoding=&#39;utf8&#39;) for line in fp: line = line.strip() if len(line) &gt; 0: fout.write(&#39; &#39;.join(seg_sentences(line)) + &quot;\n&quot;) fout.close() if __name__ == &quot;__main__&quot;: pass tokenizer.py # encoding=utf8 import os, gc, re, sys from jpype import * root_path = &quot;E:/hanlp&quot; djclass_path = &quot;-Djava.class.path=&quot; + root_path + os.sep + &quot;hanlp-1.7.4.jar;&quot; + root_path startJVM(getDefaultJVMPath(), djclass_path, &quot;-Xms1g&quot;, &quot;-Xmx1g&quot;) Tokenizer = JClass(&#39;com.hankcs.hanlp.tokenizer.StandardTokenizer&#39;) keep_pos = &quot;q,qg,qt,qv,s,t,tg,g,gb,gbc,gc,gg,gm,gp,m,mg,Mg,mq,n,an,vn,ude1,nr,ns,nt,nz,nb,nba,nbc,nbp,nf,ng,nh,nhd,o,nz,nx,ntu,nts,nto,nth,ntch,ntcf,ntcb,ntc,nt,nsf,ns,nrj,nrf,nr2,nr1,nr,nnt,nnd,nn,nmc,nm,nl,nit,nis,nic,ni,nhm,nhd&quot; keep_pos_nouns = set(keep_pos.split(&quot;,&quot;)) keep_pos_v = &quot;v,vd,vg,vf,vl,vshi,vyou,vx,vi&quot; keep_pos_v = set(keep_pos_v.split(&quot;,&quot;)) keep_pos_p = set([&#39;p&#39;, &#39;pbei&#39;, &#39;pba&#39;]) drop_pos_set = set( [&#39;xu&#39;, &#39;xx&#39;, &#39;y&#39;, &#39;yg&#39;, &#39;wh&#39;, &#39;wky&#39;, &#39;wkz&#39;, &#39;wp&#39;, &#39;ws&#39;, &#39;wyy&#39;, &#39;wyz&#39;, &#39;wb&#39;, &#39;u&#39;, &#39;ud&#39;, &#39;ude1&#39;, &#39;ude2&#39;, &#39;ude3&#39;, &#39;udeng&#39;, &#39;udh&#39;, &#39;p&#39;, &#39;rr&#39;, &#39;w&#39;]) han_pattern = re.compile(r&#39;[^\dA-Za-z\u3007\u4E00-\u9FCB\uE815-\uE864]+&#39;) HanLP = JClass(&#39;com.hankcs.hanlp.HanLP&#39;) def to_string(sentence, return_generator=False): if return_generator: return (word_pos_item.toString().split(&#39;/&#39;) for word_pos_item in Tokenizer.segment(sentence)) else: return [(word_pos_item.toString().split(&#39;/&#39;)[0], word_pos_item.toString().split(&#39;/&#39;)[1]) for word_pos_item in Tokenizer.segment(sentence)] def seg_sentences(sentence, with_filter=True, return_generator=False): segs = to_string(sentence, return_generator=return_generator) if with_filter: g = [word_pos_pair[0] for word_pos_pair in segs if len(word_pos_pair) == 2 and word_pos_pair[0] != &#39; &#39; and word_pos_pair[1] not in drop_pos_set] else: g = [word_pos_pair[0] for word_pos_pair in segs if len(word_pos_pair) == 2 and word_pos_pair[0] != &#39; &#39;] return iter(g) if return_generator else g TextRank算法原理介绍tex_rank.py # -*- coding=utf8 -*- from jieba import analyse # 引入TextRank关键词抽取接口 textrank = analyse.textrank # 原始文本 text = &quot;非常线程是程序执行时的最小单位，它是进程的一个执行流，\ 是CPU调度和分派的基本单位，一个进程可以由很多个线程组成，\ 线程间共享进程的所有资源，每个线程有自己的堆栈和局部变量。\ 线程由CPU独立调度执行，在多CPU环境下就允许多个线程同时运行。\ 同样多线程也可以实现并发操作，每个请求分配一个线程来处理。&quot; print(&quot;\nkeywords by textrank:&quot;) # 基于TextRank算法进行关键词抽取 keywords = textrank(text, topK=10, withWeight=True, allowPOS=(&#39;ns&#39;, &#39;n&#39;)) # 输出抽取出的关键词 f words = [keyword for keyword, w in keywords if w &gt; 0.2] print(&#39; &#39;.join(words) + &quot;\n&quot;) jieba 词性标注 标注 含义 来源 Ag 形语素 形容词性语素形容词代码为 a,语素代码g前面置以A a 形容词 取英语形容词 adjective的第1个字母 ad 副形词 直接作状语的形容词形容词代码 a和副词代码d并在一起 an 名形词 具有名词功能的形容词形容词代码 a和名词代码n并在一起 b 区别词 取汉字“别”的声母 c 连词 取英语连词 conjunction的第1个字母 dg 副语素 副词性语素副词代码为 d,语素代码g前面置以D d 副词 取 adverb的第2个字母,因其第1个字母已用于形容词 e 叹词 取英语叹词 exclamation的第1个字母 f 方位词 取汉字“方” g 语素 绝大多数语素都能作为合成词的“词根”,取汉字“根”的声母 h 前接成分 取英语 head的第1个字母 i 成语 取英语成语 idiom的第1个字母 j 简称略语 取汉字“简”的声母 k 后接成分 l 习用语 习用语尚未成为成语,有点“临时性”,取“临”的声母 m 数词 取英语 numeral的第3个字母,n,u已有他用 Ng 名语素 名词性语素名词代码为 n,语素代码g前面置以N n 名词 取英语名词 noun的第1个字母 nr 人名 名词代码 n和“人(ren)”的声母并在一起 ns 地名 名词代码 n和处所词代码s并在一起 nt 机构团体 “团”的声母为 t,名词代码n和t并在一起 nz 其他丏名 “丏”的声母的第 1个字母为z,名词代码n和z并在一起 o 拟声词 取英语拟声词 onomatopoeia的第1个字母 p 介词 取英语介词 prepositional的第1个字母 q 量词 取英语 quantity的第1个字母 r 代词 取英语代词 pronoun的第2个字母,因p已用于介词 s 处所词 取英语 space的第1个字母 tg 时语素 时间词性语素时间词代码为 t,在语素的代码g前面置以T t 时间词 取英语 time的第1个字母 u 助词 取英语助词 auxiliary vg 动语素 动词性语素动词代码为 v在语素的代码g前面置以V v 动词 取英语动词 verb的第一个字母 vd 副动词 直接作状语的动词动词和副词的代码并在一起 vn 名动词 指具有名词功能的动词动词和名词的代码并在一起 w 标点符号 x 非语素字 非语素字只是一个符号,字母 x通常用于代表未知数、符号 y 语气词 取汉字“语”的声母 z 状态词 取汉字“状”的声母的前一个字母 un 未知词 不可识别词及用户自定义词组取英文Unkonwn首两个字母(非北大标准,CSW分词中定义) hanlp词性标注 标注 含义 a 形容词 ad 副形词 ag 形容词性语素 al 形容词性惯用语 an 名形词 b 区别词 begin 仅用于始##始 bg 区别语素 bl 区别词性惯用语 c 连词 cc 并列连词 d 副词 dg 辄,俱,复之类的副词 dl 连语 e 叹词 end 仅用于终##终 f 方位词 g 学术词汇 gb 生物相关词汇 gbc 生物类别 gc 化学相关词汇 gg 地理地质相关词汇 gi 计算机相关词汇 gm 数学相关词汇 gp 物理相关词汇 h 前缀 i 成语 j 简称略语 k 后缀 l 习用语 m 数词 mg 数语素 Mg 甲乙丙丁之类的数词 mq 数量词 n 名词 nb 生物名 nba 动物名 nbc 动物纲目 nbp 植物名 nf 食品，比如“薯片” ng 名词性语素 nh 医药疾病等健康相关名词 nhd 疾病 nhm 药品 ni 机构相关（不是独立机构名） nic 下属机构 nis 机构后缀 nit 教育相关机构 nl 名词性惯用语 nm 物品名 nmc 化学品名 nn 工作相关名词 nnd 职业 nnt 职务职称 nr 人名 nr1 复姓 nr2 蒙古姓名 nrf 音译人名 nrj 日语人名 ns 地名 nsf 音译地名 nt 机构团体名 ntc 公司名 ntcb 银行 ntcf 工厂 ntch 酒店宾馆 nth 医院 nto 政府机构 nts 中小学 ntu 大学 nx 字母专名 nz 其他专名 o 拟声词 p 介词 pba 介词“把” pbei 介词“被” q 量词 qg 量词语素 qt 时量词 qv 动量词 r 代词 rg 代词性语素 Rg 古汉语代词性语素 rr 人称代词 ry 疑问代词 rys 处所疑问代词 ryt 时间疑问代词 ryv 谓词性疑问代词 rz 指示代词 rzs 处所指示代词 rzt 时间指示代词 rzv 谓词性指示代词 s 处所词 t 时间词 tg 时间词性语素 u 助词 ud 助词 ude1 的 底 ude2 地 ude3 得 udeng 等 等等 云云 udh 的话 ug 过 uguo 过 uj 助词 ul 连词 ule 了 喽 ulian 连 （“连小学生都会”） uls 来讲 来说 而言 说来 usuo 所 uv 连词 uyy 一样 一般 似的 般 uz 着 uzhe 着 uzhi 之 v 动词 vd 副动词 vf 趋向动词 vg 动词性语素 vi 不及物动词（内动词） vl 动词性惯用语 vn 名动词 vshi 动词“是” vx 形式动词 vyou 动词“有” w 标点符号 wb 百分号千分号，全角：％ ‰ 半角：% wd 逗号，全角：， 半角：, wf 分号，全角：； 半角： ; wh 单位符号，全角：￥ ＄ ￡ ° ℃ 半角：$ wj 句号，全角：。 wky 右括号，全角：） 〕 ］ ｝ 》 】 〗 〉 半角： ) ] { &gt; wkz 左括号，全角：（ 〔 ［ ｛ 《 【 〖 〈 半角：( [ { &lt; wm 冒号，全角：： 半角： : wn 顿号，全角：、 wp 破折号，全角：—— －－ ——－ 半角：— —- ws 省略号，全角：…… … wt 叹号，全角：！ ww 问号，全角：？ wyy 右引号，全角：” ’ 』 wyz 左引号，全角：“ ‘ 『 x 字符串 xu 网址URL xx 非语素字 y 语气词(delete yg) yg 语气语素 z 状态词 zg 状态词]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nlp基础]]></title>
    <url>%2F2019%2F08%2F26%2Fnlp%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[nlp基础 简介 NLP( Natural Language Processing ) 是 自然 语言 处理 的 简称,是研究人与计算机交互的语言问题的一门学科。机器理解并解释人类写作与说话方式的能力。近年来,深度学习技术在自然语言处理方面的研究和应用也取得了显著的成果。 提问和回答、知识工程、语言生成、语音识别,语音合成,自动分词,句法分析,语法纠错,关键词提取,文本分类/聚类,文本自动摘要,信息检索(ES,Solr),信息抽取,知识图谱,机器翻译,人机对话,机器写作,情感分析,文字识别,阅读理解,推荐系统,高考机器人等。 环境搭建Anaconda3-5.1.0-Windows-x86_64.exe将Anaconda加入系统环境变量 常用开发包numpy numpy系统是Python的一种开源的数值计算包。 包括：1、一个强大的N维数组对象Array；2、比较成熟的（广播）函数库；3、用于整合C/C++和Fortran代码的工具包；4、实用的线性代数、傅里叶变换和随机数生成函数。numpy和稀疏矩阵运算包scipy配合使用更加方便。 conda install numpy NLTK Natural Language Toolkit，自然语言处理工具包，在NLP领域中， 最常使用的一个Python库。 conda install nltk Gensim Gensim是一个占内存低，接口简单，免费的Python库，它可以用来从文档中自动提取语义主题。它包含了很多非监督学习算法如：TF/IDF，潜在语义分析（Latent Semantic Analysis，LSA）、隐含狄利克雷分配（Latent Dirichlet Allocation，LDA），层次狄利克雷过程 （Hierarchical Dirichlet Processes，HDP）等。 Gensim支持Word2Vec,Doc2Vec等模型。 conda install gensimpip install gensim如不可安装python库gensim‑3.8.0‑cp36‑cp36m‑win_amd64.whl下载后pip install Tensorflow TensorFlow是谷歌基于DistBelief进行研发的第二代人工智能学习系统。TensorFlow可被用于语音识别或图像识别等多项机器学习和深度学习领域。TensorFlow是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（戒GPU），服务器，移动设备等等。TensorFlow 最初由Google大脑小组（隶属于Google机器智能研究机构）的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用 性使其也可广泛用于其他计算领域。 conda install tensorflowpip install tensorflow python库pip install tensorflow-1.9.0-cp36-cp36m-win_amd64.whl下载后pip install jieba “结巴”中文分词：是广泛使用的中文分词工具，具有以下特点： 1）三种分词模式：精确模式，全模式和搜索引擎模式 2）词性标注和返回词语在原文的起止位置（ Tokenize） 3）可加入自定义字典 4）代码对 Python 2/3 均兼容 5）支持多种语言，支持简体繁体 项目地址 pip install jieba demo# encoding=utf-8 import jieba import jieba.posseg as pseg print(&quot;\njieba分词全模式：&quot;) seg_list = jieba.cut(&quot;我来到北京清华大学&quot;, cut_all=True) print(&quot;Full Mode: &quot; + &quot;/ &quot;.join(seg_list)) # 全模式 print(&quot;\njieba分词精确模式：&quot;) seg_list = jieba.cut(&quot;我来到北京清华大学&quot;, cut_all=False) print(&quot;Default Mode: &quot; + &quot;/ &quot;.join(seg_list)) # 精确模式 print(&quot;\njieba默认分词是精确模式：&quot;) seg_list = jieba.cut(&quot;他来到了网易杭研大厦&quot;) # 默认是精确模式 print(&quot;, &quot;.join(seg_list)) print(&quot;\njiba搜索引擎模式：&quot;) seg_list = jieba.cut_for_search(&quot;小明硕士毕业于中国科学院计算所，后在日本京都大学深造&quot;) # 搜索引擎模式 print(&quot;, &quot;.join(seg_list)) strings=&quot;是广泛使用的中文分词工具，具有以下特点：&quot; words = pseg.cut(strings) print(&quot;\njieba词性标注：&quot;) for word, flag in words: print(&#39;%s %s&#39; % (word, flag)) Stanford NLP Stanford NLP提供了一系列自然语言分析工具。它能够给出基本的 词形，词性，不管是公司名还是人名等，格式化的日期，时间，量词， 并且能够标记句子的结构，语法形式和字词依赖，指明那些名字指向同 样的实体，指明情绪，提取发言中的开放关系等。 1.一个集成的语言分析工具集； 2.进行快速，可靠的任意文本分析； 3.整体的高质量的文本分析; 4.支持多种主流语言; 5.多种编程语言的易用接口; 6.方便的简单的部署web服务。 Python 版本stanford nlp 安装 • 1)安装stanford nlp自然语言处理包: pip install stanfordcorenlp • 2)下载Stanford CoreNLP文件 https://stanfordnlp.github.io/CoreNLP/download.html • 3)下载中文模型jar包,https://nlp.stanford.edu/software/stanford-chinese-corenlp-2018-10-05-models.jar • 4)把下载的stanford-chinese-corenlp-2018-10-05-models.jar放在解压后的Stanford CoreNLP文件夹中，改Stanford CoreNLP文件夹名为stanfordnlp（可选） • 5)在Python中引用模型: • from stanfordcorenlp import StanfordCoreNLP • nlp = StanfordCoreNLP(r‘path&#39;, lang=&#39;zh&#39;) 例如： nlp = StanfordCoreNLP(r&#39;/home/kuo/NLP/module/stanfordnlp/&#39;, lang=&#39;zh&#39;) demo# -*-encoding=utf8-*- from stanfordcorenlp import StanfordCoreNLP nlp = StanfordCoreNLP(r&#39;E:\stanford-corenlp-full-2018-10-05&#39;, lang=&#39;zh&#39;) fin = open(&#39;news.txt&#39;, &#39;r&#39;, encoding=&#39;utf8&#39;) fner = open(&#39;ner.txt&#39;, &#39;w&#39;, encoding=&#39;utf8&#39;) ftag = open(&#39;pos_tag.txt&#39;, &#39;w&#39;, encoding=&#39;utf8&#39;) for line in fin: line = line.strip() # 去掉空行 if len(line) &lt; 1: continue # 命名实体识别 fner.write(&quot; &quot;.join([each[0] + &quot;/&quot; + each[1] for each in nlp.ner(line) if len(each) == 2]) + &quot;\n&quot;) # 词性识别 ftag.write(&quot; &quot;.join([each[0] + &quot;/&quot; + each[1] for each in nlp.pos_tag(line) if len(each) == 2]) + &quot;\n&quot;) fner.close() ftag.close() print(&quot;okkkkk&quot;) sentence = &#39;清华大学位于北京。&#39; print(nlp.word_tokenize(sentence)) print(nlp.pos_tag(sentence)) print(nlp.ner(sentence)) print(nlp.parse(sentence)) print(nlp.dependency_parse(sentence)) Hanlp HanLP是由一系列模型与算法组成的Java工具包，目标是普及自然 语言处理在生产环境中的应用。HanLP具备功能完善、性能高效、架构 清晰、语料时新、可自定义的特点。 功能：中文分词 词性标注 命名实体识别 依存句法分析 关键词提取 新词发现 短语提取 自动摘要 文本分类 拼音简繁 • 1、安装Java:我装的是Java 1.8 • 2、安裝Jpype, conda install -c conda-forge jpype1=0.7 [或者]pip install jpype1 • 3、测试是否按照成功: from jpype import * startJVM(getDefaultJVMPath(), &quot;-ea&quot;) java.lang.System.out.println(&quot;Hello World&quot;) shutdownJVM() • 比如data目录是root=E:/hanlp/data,那么root=root=E:/hanlp • 1、https://github.com/hankcs/HanLP/releases 下载hanlp-1.7.4-release.zip包，data-for-1.7.4.zip包,解压后重命名为hanlp• 2、配置文件• 示例配置文件:hanlp.properties• 配置文件的作用是告诉HanLP数据包的位置,只需修改第一行:root=E:/hanlp demo#-*- coding:utf-8 -*- from jpype import * startJVM(getDefaultJVMPath(), &quot;-Djava.class.path=E:\hanlp\hanlp-1.7.4.jar;E:\hanlp&quot;, &quot;-Xms1g&quot;, &quot;-Xmx1g&quot;) # 启动JVM，Linux需替换分号;为冒号: print(&quot;=&quot; * 30 + &quot;HanLP分词&quot; + &quot;=&quot; * 30) HanLP = JClass(&#39;com.hankcs.hanlp.HanLP&#39;) # 中文分词 print(HanLP.segment(&#39;你好，欢迎在Python中调用HanLP的API&#39;)) print(&quot;-&quot; * 70) print(&quot;=&quot; * 30 + &quot;标准分词&quot; + &quot;=&quot; * 30) StandardTokenizer = JClass(&#39;com.hankcs.hanlp.tokenizer.StandardTokenizer&#39;) print(StandardTokenizer.segment(&#39;你好，欢迎在Python中调用HanLP的API&#39;)) print(&quot;-&quot; * 70) # NLP分词NLPTokenizer会执行全部命名实体识别和词性标注 print(&quot;=&quot; * 30 + &quot;NLP分词&quot; + &quot;=&quot; * 30) NLPTokenizer = JClass(&#39;com.hankcs.hanlp.tokenizer.NLPTokenizer&#39;) print(NLPTokenizer.segment(&#39;中国科学院计算技术研究所的宗成庆教授正在教授自然语言处理课程&#39;)) print(&quot;-&quot; * 70) print(&quot;=&quot; * 30 + &quot;索引分词&quot; + &quot;=&quot; * 30) IndexTokenizer = JClass(&#39;com.hankcs.hanlp.tokenizer.IndexTokenizer&#39;) termList = IndexTokenizer.segment(&quot;主副食品&quot;); for term in termList: print(str(term) + &quot; [&quot; + str(term.offset) + &quot;:&quot; + str(term.offset + len(term.word)) + &quot;]&quot;) print(&quot;-&quot; * 70) print(&quot;=&quot; * 30 + &quot; CRF分词&quot; + &quot;=&quot; * 30) print(&quot;-&quot; * 70) print(&quot;=&quot; * 30 + &quot; 极速词典分词&quot; + &quot;=&quot; * 30) SpeedTokenizer = JClass(&#39;com.hankcs.hanlp.tokenizer.SpeedTokenizer&#39;) print(NLPTokenizer.segment(&#39;江西鄱阳湖干枯，中国最大淡水湖变成大草原&#39;)) print(&quot;-&quot; * 70) print(&quot;=&quot; * 30 + &quot; 自定义分词&quot; + &quot;=&quot; * 30) CustomDictionary = JClass(&#39;com.hankcs.hanlp.dictionary.CustomDictionary&#39;) CustomDictionary.add(&#39;攻城狮&#39;) CustomDictionary.add(&#39;单身狗&#39;) HanLP = JClass(&#39;com.hankcs.hanlp.HanLP&#39;) print(HanLP.segment(&#39;攻城狮逆袭单身狗，迎娶白富美，走上人生巅峰&#39;)) print(&quot;-&quot; * 70) print(&quot;=&quot; * 20 + &quot;命名实体识别与词性标注&quot; + &quot;=&quot; * 30) NLPTokenizer = JClass(&#39;com.hankcs.hanlp.tokenizer.NLPTokenizer&#39;) print(NLPTokenizer.segment(&#39;中国科学院计算技术研究所的宗成庆教授正在教授自然语言处理课程&#39;)) print(&quot;-&quot; * 70) document = &quot;水利部水资源司司长陈明忠9月29日在国务院新闻办举行的新闻发布会上透露，&quot; \ &quot;根据刚刚完成了水资源管理制度的考核，有部分省接近了红线的指标，&quot; \ &quot;有部分省超过红线的指标。对一些超过红线的地方，陈明忠表示，对一些取用水项目进行区域的限批，&quot; \ &quot;严格地进行水资源论证和取水许可的批准。&quot; print(&quot;=&quot; * 30 + &quot;关键词提取&quot; + &quot;=&quot; * 30) print(HanLP.extractKeyword(document, 8)) print(&quot;-&quot; * 70) print(&quot;=&quot; * 30 + &quot;自动摘要&quot; + &quot;=&quot; * 30) print(HanLP.extractSummary(document, 3)) print(&quot;-&quot; * 70) text = r&quot;算法工程师\n 算法（Algorithm）是一系列解决问题的清晰指令，也就是说，能够对一定规范的输入，在有限时间内获得所要求的输出。如果一个算法有缺陷，或不适合于某个问题，执行这个算法将不会解决这个问题。不同的算法可能用不同的时间、空间或效率来完成同样的任务。一个算法的优劣可以用空间复杂度与时间复杂度来衡量。算法工程师就是利用算法处理事物的人。\n \n 1职位简介\n 算法工程师是一个非常高端的职位；\n 专业要求：计算机、电子、通信、数学等相关专业；\n 学历要求：本科及其以上的学历，大多数是硕士学历及其以上；\n 语言要求：英语要求是熟练，基本上能阅读国外专业书刊；\n 必须掌握计算机相关知识，熟练使用仿真工具MATLAB等，必须会一门编程语言。\n\n2研究方向\n 视频算法工程师、图像处理算法工程师、音频算法工程师 通信基带算法工程师\n \n 3目前国内外状况\n 目前国内从事算法研究的工程师不少，但是高级算法工程师却很少，是一个非常紧缺的专业工程师。算法工程师根据研究领域来分主要有音频/视频算法处理、图像技术方面的二维信息算法处理和通信物理层、雷达信号处理、生物医学信号处理等领域的一维信息算法处理。\n 在计算机音视频和图形图像技术等二维信息算法处理方面目前比较先进的视频处理算法：机器视觉成为此类算法研究的核心；另外还有2D转3D算法(2D-to-3D conversion)，去隔行算法(de-interlacing)，运动估计运动补偿算法(Motion estimation/Motion Compensation)，去噪算法(Noise Reduction)，缩放算法(scaling)，锐化处理算法(Sharpness)，超分辨率算法(Super Resolution),手势识别(gesture recognition),人脸识别(face recognition)。\n 在通信物理层等一维信息领域目前常用的算法：无线领域的RRM、RTT，传送领域的调制解调、信道均衡、信号检测、网络优化、信号分解等。\n 另外数据挖掘、互联网搜索算法也成为当今的热门方向。\n&quot; print(&quot;=&quot; * 30 + &quot;短语提取&quot; + &quot;=&quot; * 30) print(HanLP.extractPhrase(text, 10)) print(&quot;-&quot; * 70) shutdownJVM()]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>nlp</tag>
        <tag>numpy</tag>
        <tag>NLTK</tag>
        <tag>Gensim</tag>
        <tag>Stanford NLP</tag>
        <tag>Hanlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jmeter基础]]></title>
    <url>%2F2019%2F08%2F26%2Fjmeter%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[jmeter基本环境搭建及基础操作 压力测试工具对比 loadrunner 性能稳定，压测结果及细粒度大，可以自定义脚本进行压测，但是太过于重大，功能比较繁多 apache ab(单接口压测最方便) 模拟多线程并发请求,ab命令对发出负载的计算机要求很低，既不会占用很多CPU，也不会占用太多的内存，但却会给目标服务器造成巨大的负载, 简单DDOS攻击等 webbench webbench首先fork出多个子进程，每个子进程都循环做web访问测试。子进程把访问的结果通过pipe告诉父进程，父进程做最终的统计结果。 jmeter 压测不同的协议和应用 1) Web - HTTP, HTTPS (Java, NodeJS, PHP, ASP.NET, …) 2) SOAP / REST Webservices 3) FTP 4) Database via JDBC 5) LDAP 轻量目录访问协议 6) Message-oriented middleware (MOM) via JMS 7) Mail - SMTP(S), POP3(S) and IMAP(S) 8) TCP等等 使用场景及优点 1）功能测试 2）压力测试 3）分布式压力测试 4）纯java开发 5）上手容易，高性能 4）提供测试数据分析 5）各种报表数据图形展示环境搭建 需要安装JDK8。或者JDK9,JDK10 快速下载 windows： https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-4.0.zip mac或者linux：https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-4.0.tgz 目录 bin:核心可执行文件，包含配置 jmeter.bat: windows启动文件： jmeter: mac或者linux启动文件： jmeter-server：mac或者Liunx分布式压测使用的启动文件 jmeter-server.bat：mac或者Liunx分布式压测使用的启动文件 jmeter.properties: 核心配置文件 extras：插件拓展的包 lib:核心的依赖包 ext:核心包 junit:单元测试包 修改界面语言 1、控制台修改 menu -&gt; options -&gt; choose language 2、配置文件修改 bin目录 -&gt; jmeter.properties 默认 #language=en 改为 language=zh_CN 基本测试 java -jar gs-spring-boot-0.1.0.jar 添加-&gt;threads-&gt;线程组（控制总体并发） 线程数：虚拟用户数。一个虚拟用户占用一个进程或线程准备时长（Ramp-Up Period(in seconds)）：全部线程启动的时长，比如100个线程，20秒，则表示20秒内100个线程都要启动完成，每秒启动5个线程循环次数：每个线程发送的次数，假如值为5，100个线程，则会发送500次请求，可以勾选永远循环 线程组-&gt;添加-&gt; Sampler(采样器) -&gt; Http （一个线程组下面可以增加几个Sampler） 名称：采样器名称 注释：对这个采样器的描述web服务器： 默认协议是http 默认端口是80 服务器名称或IP ：请求的目标服务器名称或IP地址路径：服务器URLUse multipart/from-data for HTTP POST ：当发送POST请求时，使用Use multipart/from-data方法发送，默认不选中。 线程组-&gt;添加-&gt;监听器-&gt;察看结果树 该结果树属于全局，可已针对每一个请求设置结果树 线程组 -&gt; 添加 -&gt; 断言 -&gt; 响应断言 apply to(应用范围): Main sample only: 仅当前父取样器 进行断言，一般一个请求，如果发一个请求会触发多个，则就有sub sample（比较少用）要测试的响应字段： 响应文本：即响应的数据，比如json等文本 响应代码：http的响应状态码，比如200，302，404这些 响应信息：http响应代码对应的响应信息，例如：OK, Found Response Header: 响应头模式匹配规则： 包括：包含在里面就成功 匹配：响应内容完全匹配，不区分大小写 equals：完全匹配，区分大小写 线程组-&gt; 添加 -&gt; 监听器 -&gt; 断言结果 里面的内容是sampler采样器的名称断言失败，查看结果树任务结果颜色标红(通过结果数里面双击不通过的记录，可以看到错误信息)每个sample下面可以加单独的结果树，然后同时加多个断言，最外层可以加个结果树进行汇总 线程组-&gt;添加-&gt;监听器-&gt;聚合报告（Aggregate Report） lable: sampler的名称 Samples: 一共发出去多少请求,例如10个用户，循环10次，则是 100 Average: 平均响应时间 Median: 中位数，也就是 50％ 用户的响应时间 90% Line : 90％ 用户的响应不会超过该时间 （90% of the samples took no more than this time. The remaining samples at least as long as this） 95% Line : 95％ 用户的响应不会超过该时间 99% Line : 99％ 用户的响应不会超过该时间 min : 最小响应时间 max : 最大响应时间 Error%：错误的请求的数量/请求的总数 Throughput： 吞吐量——默认情况下表示每秒完成的请求数（Request per Second) 可类比为qps,并发数提高，qps不涨则瓶颈 KB/Sec: 每秒接收数据量 启动测试http请求 变量实操很多变量在全局中都有使用，或者测试数据更改，可以在一处定义，四处使用，比如服务器地址 线程组-&gt;add -&gt; Config Element(配置原件)-&gt; User Definde Variable（用户定义的变量） 通过${xx}调用 线程组-&gt;add -&gt; Config Element(配置原件)-&gt; CSV data set config (CSV数据文件设置) csv变量使用csv_name txt多变量使用csv_name csv_pwd 数据库test1 Add directory or jar to classpath添加mysql-connector-java-5.1.30.jarThread Group -&gt; add -&gt; sampler -&gt; jdbc request 无参查询 有参查询 预编译 更新 预编译 JDBC request-&gt;add -&gt; config element -&gt; JDBC connection configuration Variable Name for created pool同JDBC request 的Variable Name for created pool declared in JDBC connection configuration Thread Group -&gt; add -&gt; sampler -&gt; debug sampler variable name of pool declared in JDBC connection configuration（和配置文件同名）Query Type 查询类型parameter values 参数值parameter types 参数类型variable names sql执行结果变量名result variable names 所有结果当做一个对象存储query timeouts 查询超时时间handle results 处理结果集 分布式压测]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>jmeter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy爬取ssr链接]]></title>
    <url>%2F2019%2F08%2F23%2Fscrapy%E7%88%AC%E5%8F%96ssr%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[基于scrapy爬取ssr链接 环境搭建python3.5 虚拟环境virtualenvpip install virtualenv 提示pip版本太低 python -m pip install --upgrade pip pip install -i https://pypi.doubanio.com/simple/ --trusted-host pypi.doubanio.com django 使用豆瓣源加速 pip uninstall django 卸载django virtualenv scrapytest 默认环境创建虚拟环境 cd scrapytest/Scripts &amp;&amp; activate.bat &amp;&amp; python 进入3.5虚拟环境 virtualenv -p D:\Python27\python.exe scrapytest cd scrapytest/Scripts &amp;&amp; activate.bat &amp;&amp; python 进入2.7虚拟环境 deactivate.bat 退出虚拟环境 apt-get install python-virtualenv 安装虚拟环境 virtualenv py2 &amp;&amp; cd py2 &amp;&amp; cd bin &amp;&amp; source activate &amp;&amp; python 进入2.7虚拟环境 virtualenv -p /usr/bin/python3 py3 &amp;&amp; &amp;&amp; cd py3 &amp;&amp; cd bin &amp;&amp; source activate &amp;&amp; python 进入3.5虚拟环境虚拟环境virtualenvwrapperpip install virtualenvwrapper pip install virtualenvwrapper-win 解决workon不是内部指令 workon 列出所有虚拟环境 新建环境变量 WORKON_HOME=E:\envs mkvirtualenv py3scrapy 新建并进入虚拟环境 deactivate 退出虚拟环境 workon py3scrapy 进入指定虚拟环境 pip install -i https://pypi.douban.com/simple scrapy 安装scrapy源 若缺少lxml出错https://www.lfd.uci.edu/~gohlke/pythonlibs/寻找对应版本的lxml的whl源 python -m pip install --upgrade pip 更新pip pip install lxml-4.1.1-cp35-cp35m-win_amd64.whl 若缺少Twisted出错http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml搜对应版本Twisted pip install Twisted‑17.9.0‑cp35‑cp35m‑win_amd64.whl mkvirtualenv --python=D:\Python27\python.exe py2scrapy 一般不会出问题 pip install -i https://pypi.douban.com/simple scrapy pip install virtualenvwrapper find / -name virualenvwrapper.sh vim ~/.bashrc export WORKON_HOME=$HOME/.virtualenvs source /home/wj/.local/bin/virtualenvwrapper.sh source ~/.bashrc mkvirtualenv py2scrapy 指向生成~/.virtualenv deactivate 退出虚拟环境 mkdirtualenv --python=/usr/bin/python3 py3scrapy项目实战项目搭建pip install virtualenvwrapper-win mkvirtualenv --python=F:\Python\Python35\python.exe ssr pip install Twisted-17.9.0-cp35-cp35m-win_amd64.whl pip install -i https://pypi.douban.com/simple/ scrapy scrapy startproject ssr cd ssr scrapy genspider ssr https://freevpn-ss.tk/category/technology/ scrapy genspider --list scrapy genspider -t crawl lagou www.lagou.com 使用crawl模板 pycharm--新建项目---Pure Python---Interpreter为E:\envs\ssr\Scripts\python.exe pycharm--打开---ssr,修改settings--project Interpreter为D:\Envs\ss pip list pip install -i https://pypi.douban.com/simple pypiwin32 pillow requests redis fake-useragent pip install mysqlclient-1.4.4-cp35-cp35m-win_amd64.whl 或者pip install -i https://pypi.douban.com/simple mysqlclient 出错apt-get install libmysqlclient-dev 或者yum install python-devel mysql-devel scrapy crawl jobbole 修改settings.py ROBOTSTXT_OBEY = False scrapy shell http://blog.jobbole.com/ 可以在脚本中调试xpath或者chrome浏览器右键copy xpath,chrome浏览器右键copy selector scrapy shell -s USER_AGENT=&quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:51.0) Gecko/20100101 Firefox/51.0&quot; https://www.zhihu.com/question/56320032 pip freeze &gt; requirements.txt 生成依赖到文件 pip install -r requirements.txt 一键安装依赖 job_list = json.loads(response.text)[&quot;data&quot;][&quot;results返回response爬虫开发1scrapy shell https://freevpn-ss.tk/category/technology/ shell中查看节点 response.css(&quot;.posts-list .panel a::attr(href)&quot;).extract_first() response.css(&quot;.posts-list .panel a img::attr(src)&quot;).extract_first() response.xpath(&quot;//*[@id=&#39;container&#39;]/div/ul/li/article/a/img/@src&quot;).extract_first() view(response) 启动类main.py from scrapy.cmdline import execute import sys import os sys.path.append(os.path.dirname(os.path.abspath(__file__))) execute([&quot;scrapy&quot;, &quot;crawl&quot;, &quot;freevpn-ss.tk&quot;]) 基础配置ssr/settings.py import os BOT_NAME = &#39;ssr&#39; SPIDER_MODULES = [&#39;ssr.spiders&#39;] NEWSPIDER_MODULE = &#39;ssr.spiders&#39; # Crawl responsibly by identifying yourself (and your website) on the user-agent #USER_AGENT = &#39;ssr (+http://www.yourdomain.com)&#39; # Obey robots.txt rules ROBOTSTXT_OBEY = False import sys BASE_DIR = os.path.dirname(os.path.abspath(os.path.dirname(__file__))) sys.path.insert(0, os.path.join(BASE_DIR, &#39;ssr&#39;)) MYSQL_HOST = &quot;127.0.0.1&quot; MYSQL_DBNAME = &quot;scrapy&quot; MYSQL_USER = &quot;root&quot; MYSQL_PASSWORD = &quot;&quot; ITEM_PIPELINES = { &#39;ssr.pipelines.MysqlTwistedPipline&#39;: 2,#连接池异步插入 &#39;ssr.pipelines.JsonExporterPipleline&#39;: 1,#连接池异步插入 } ssr/pipelines.py from scrapy.exporters import JsonItemExporter from scrapy.pipelines.images import ImagesPipeline import codecs import json import MySQLdb import MySQLdb.cursors from twisted.enterprise import adbapi from ssr.utils.common import DateEncoder class SsrPipeline(object): def process_item(self, item, spider): return item class SsrImagePipeline(ImagesPipeline): def item_completed(self, results, item, info): if &quot;front_image_url&quot; in item: for ok, value in results: image_file_path = value[&quot;path&quot;] # 填充自定义路径 item[&quot;front_image_path&quot;] = image_file_path return item class JsonWithEncodingPipeline(object): # 自定义json文件的导出 def __init__(self): self.file = codecs.open(&#39;article.json&#39;, &#39;w&#39;, encoding=&quot;utf-8&quot;) def process_item(self, item, spider): # 序列化，ensure_ascii利于中文,json没法序列化date格式，需要新写函数 lines = json.dumps(dict(item), ensure_ascii=False, cls=DateEncoder) + &quot;\n&quot; self.file.write(lines) return item def spider_closed(self, spider): self.file.close() class JsonExporterPipleline(object): # 调用scrapy提供的json export导出json文件 def __init__(self): self.file = open(&#39;ssr.json&#39;, &#39;wb&#39;) self.exporter = JsonItemExporter(self.file, encoding=&quot;utf-8&quot;, ensure_ascii=False) self.exporter.start_exporting() def close_spider(self, spider): self.exporter.finish_exporting() self.file.close() def process_item(self, item, spider): self.exporter.export_item(item) return item class MysqlPipeline(object): # 采用同步的机制写入mysql def __init__(self): self.conn = MySQLdb.connect(&#39;127.0.0.1&#39;, &#39;root&#39;, &#39;123456&#39;, &#39;scrapy&#39;, charset=&quot;utf8&quot;, use_unicode=True) self.cursor = self.conn.cursor() def process_item(self, item, spider): insert_sql = &quot;&quot;&quot; insert into ssr(url, ip,ssr, port,password,secret) VALUES (%s, %s, %s, %s, %s) &quot;&quot;&quot; self.cursor.execute(insert_sql, (item[&quot;url&quot;],item[&quot;ssr&quot;], item[&quot;ip&quot;], item[&quot;port&quot;], item[&quot;password&quot;], item[&quot;secret&quot;])) self.conn.commit() class MysqlTwistedPipline(object): # 异步连接池插入数据库，不会阻塞 def __init__(self, dbpool): self.dbpool = dbpool @classmethod def from_settings(cls, settings):# 初始化时即被调用静态方法 dbparms = dict( host = settings[&quot;MYSQL_HOST&quot;],#setttings中定义 db = settings[&quot;MYSQL_DBNAME&quot;], user = settings[&quot;MYSQL_USER&quot;], passwd = settings[&quot;MYSQL_PASSWORD&quot;], charset=&#39;utf8&#39;, cursorclass=MySQLdb.cursors.DictCursor, use_unicode=True, ) dbpool = adbapi.ConnectionPool(&quot;MySQLdb&quot;, **dbparms) return cls(dbpool) def process_item(self, item, spider): #使用twisted将mysql插入变成异步执行 query = self.dbpool.runInteraction(self.do_insert, item) query.addErrback(self.handle_error, item, spider) #处理异常 def handle_error(self, failure, item, spider): #处理异步插入的异常 print (failure) def do_insert(self, cursor, item): #执行具体的插入，不具体的如MysqlPipeline.process_item() #根据不同的item 构建不同的sql语句并插入到mysql中 insert_sql, params = item.get_insert_sql() cursor.execute(insert_sql, params) 实体类ssr/items.py import scrapy from scrapy.loader import ItemLoader from scrapy.loader.processors import MapCompose, TakeFirst, Join import re import datetime from w3lib.html import remove_tags def date_convert(value): try: create_date = datetime.datetime.strptime(value, &quot;%Y/%m/%d&quot;).date() except Exception as e: create_date = datetime.datetime.now().date() return create_date def get_nums(value): match_re = re.match(&quot;.*?(\d+).*&quot;, value) if match_re: nums = int(match_re.group(1)) else: nums = 0 return nums def return_value(value): return value class SsrItemLoader(ItemLoader): # 自定义itemloader default_output_processor = TakeFirst() class SsrItem(scrapy.Item): url = scrapy.Field() ip = scrapy.Field( input_processor=MapCompose(return_value),#传递进来可以预处理 ) port = scrapy.Field() ssr = scrapy.Field() front_image_url = scrapy.Field() password = scrapy.Field() secret = scrapy.Field() def get_insert_sql(self): insert_sql = &quot;&quot;&quot; insert into ssr(url,ssr, ip, port, password,secret) VALUES (%s, %s,%s, %s, %s,%s) ON DUPLICATE KEY UPDATE ssr=VALUES(ssr) &quot;&quot;&quot; params = (self[&quot;url&quot;],self[&quot;ssr&quot;], self[&quot;ip&quot;],self[&quot;port&quot;], self[&quot;password&quot;],self[&quot;secret&quot;]) return insert_sql, params 核心代码ssr/spiders/freevpn_ss_tk.py # -*- coding: utf-8 -*- import time from datetime import datetime from urllib import parse import scrapy from scrapy.http import Request from ssr.items import SsrItemLoader, SsrItem class FreevpnSsTkSpider(scrapy.Spider): name = &#39;freevpn-ss.tk&#39; # 必须一级域名 allowed_domains = [&#39;freevpn-ss.tk&#39;] start_urls = [&#39;https://freevpn-ss.tk/category/technology/&#39;] custom_settings = { # 优先并覆盖项目，避免被重定向 &quot;COOKIES_ENABLED&quot;: False, # 关闭cookies &quot;DOWNLOAD_DELAY&quot;: 1, &#39;DEFAULT_REQUEST_HEADERS&#39;: { &#39;Accept&#39;: &#39;application/json, text/javascript, */*; q=0.01&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate, br&#39;, &#39;Accept-Language&#39;: &#39;zh-CN,zh;q=0.8&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;, &#39;Cookie&#39;: &#39;&#39;, &#39;Host&#39;: &#39;freevpn-ss.tk&#39;, &#39;Origin&#39;: &#39;https://freevpn-ss.tk/&#39;, &#39;Referer&#39;: &#39;https://freevpn-ss.tk/&#39;, &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36&#39;, } } def parse(self, response): # post_nodes = response.css(&quot;.posts-list .panel&gt;a&quot;) # for post_node in post_nodes: # image_url = post_node.css(&quot;img::attr(src)&quot;).extract_first(&quot;&quot;) # post_url = post_node.css(&quot;::attr(href)&quot;).extract_first(&quot;&quot;) # yield Request(url=parse.urljoin(response.url, post_url), meta={&quot;front_image_url&quot;: image_url},callback=self.parse_detail) # response获取meta # # next_url = response.css(&quot;.next-page a::attr(href)&quot;).extract_first(&quot;&quot;) # if next_url: # print(next_url) # yield Request(url=parse.urljoin(response.url, next_url), callback=self.parse) post_node = response.css(&quot;.posts-list .panel&gt;a&quot;)[0] image_url = post_node.css(&quot;img::attr(src)&quot;).extract_first(&quot;&quot;) post_url = post_node.css(&quot;::attr(href)&quot;).extract_first(&quot;&quot;) yield Request(url=parse.urljoin(response.url, post_url), meta={&quot;front_image_url&quot;: image_url}, callback=self.parse_detail) # response获取meta def parse_detail(self, response): # 通过item loader加载item front_image_url = response.meta.get(&quot;front_image_url&quot;, &quot;&quot;) # 文章封面图 ssr_nodes = response.css(&quot;table tbody tr&quot;) with open(datetime.now().strftime(&#39;%Y-%m-%d&#39;), &#39;a&#39;) as file_object: for ssr in ssr_nodes: item_loader = SsrItemLoader(item=SsrItem(), response=response) # 默认ItemLoader是一个list，自定义TakeFirst() print(ssr.xpath(&quot;td[4]/text()&quot;).extract_first(&quot;&quot;)) item_loader.add_value(&quot;url&quot;, response.url) item_loader.add_value(&quot;ssr&quot;, ssr.css(&quot;td:nth-child(1)&gt;a::attr(href)&quot;).extract_first(&quot;&quot;)) item_loader.add_value(&quot;ip&quot;, ssr.css(&quot;td:nth-child(2)::text&quot;).extract_first(&quot;&quot;)) item_loader.add_value(&quot;front_image_url&quot;, front_image_url) item_loader.add_value(&quot;port&quot;, ssr.xpath(&quot;td[3]/text()&quot;).extract_first(&quot;&quot;)) item_loader.add_value(&quot;password&quot;, ssr.xpath(&quot;td[4]/text()&quot;).extract_first(&quot;&quot;)) item_loader.add_value(&quot;secret&quot;, ssr.xpath(&quot;td[5]/text()&quot;).extract_first(&quot;&quot;)) ssr_item = item_loader.load_item() file_object.write(ssr.css(&quot;td:nth-child(1)&gt;a::attr(href)&quot;).extract_first(&quot;&quot;)+&quot;\n&quot;) yield ssr_item # 将传到piplines中 爬虫开发2# -*- coding: utf-8 -*- import time from datetime import datetime from urllib import parse import scrapy from scrapy.http import Request from ssr.items import SsrItemLoader, SsrItem class FanQiangSpider(scrapy.Spider): name = &#39;fanqiang.network&#39; # 必须一级域名 allowed_domains = [&#39;fanqiang.network&#39;] start_urls = [&#39;https://fanqiang.network/免费ssr&#39;] def parse(self, response): post_nodes = response.css(&quot;.post-content table tbody tr&quot;) item_loader = SsrItemLoader(item=SsrItem(), response=response) with open(datetime.now().strftime(&#39;%Y-%m-%d&#39;), &#39;a&#39;) as file_object: for post_node in post_nodes: item_loader.add_value(&quot;url&quot;, response.url) item_loader.add_value(&quot;ssr&quot;, post_node.css(&quot;td:nth-child(1)&gt;a::attr(href)&quot;).extract_first(&quot;&quot;).replace(&quot;http://freevpn-ss.tk/&quot;, &quot;&quot;)) item_loader.add_value(&quot;ip&quot;, post_node.css(&quot;td:nth-child(2)::text&quot;).extract_first(&quot;&quot;)) item_loader.add_value(&quot;port&quot;, post_node.xpath(&quot;td[3]/text()&quot;).extract_first(&quot;&quot;)) item_loader.add_value(&quot;password&quot;, post_node.xpath(&quot;td[4]/text()&quot;).extract_first(&quot;&quot;)) item_loader.add_value(&quot;secret&quot;, post_node.xpath(&quot;td[5]/text()&quot;).extract_first(&quot;&quot;)) ssr_item = item_loader.load_item() file_object.write(post_node.css(&quot;td:nth-child(1)&gt;a::attr(href)&quot;).extract_first(&quot;&quot;).replace(&quot;http://freevpn-ss.tk/&quot;, &quot;&quot;) + &quot;\n&quot;) yield ssr_item # 将传到piplines中 多爬虫同时运行settings.py COMMANDS_MODULE = &#39;ssr&#39; ssr/crawlall.py from scrapy.commands import ScrapyCommand class Command(ScrapyCommand): requires_project = True def syntax(self): return &#39;[options]&#39; def short_desc(self): return &#39;Runs all of the spiders&#39; def run(self, args, opts): spider_list = self.crawler_process.spiders.list() for name in spider_list: self.crawler_process.crawl(name, **opts.__dict__) self.crawler_process.start()main.py from scrapy import cmdline from scrapy.cmdline import execute import sys import os sys.path.append(os.path.dirname(os.path.abspath(__file__))) # execute([&quot;scrapy&quot;, &quot;crawl&quot;, &quot;freevpn-ss.tk&quot;]) # execute([&quot;scrapy&quot;, &quot;crawl&quot;, &quot;fanqiang.network&quot;]) cmdline.execute(&quot;scrapy crawlall&quot;.split()) 防反爬随机uapip install -i https://pypi.doubanio.com/simple/ –trusted-host pypi.doubanio.com scrapy-fake-useragent DOWNLOADER_MIDDLEWARES = { &#39;scrapy_fake_useragent.middleware.RandomUserAgentMiddleware&#39;: 1, } 报错socket.timeout: timed out，查看F:/Anaconda3/Lib/site-packages/fake_useragent/settings.py __version__ = &#39;0.1.11&#39; DB = os.path.join( tempfile.gettempdir(), &#39;fake_useragent_{version}.json&#39;.format( version=__version__, ), ) CACHE_SERVER = &#39;https://fake-useragent.herokuapp.com/browsers/{version}&#39;.format( version=__version__, ) BROWSERS_STATS_PAGE = &#39;https://www.w3schools.com/browsers/default.asp&#39; BROWSER_BASE_PAGE = &#39;http://useragentstring.com/pages/useragentstring.php?name={browser}&#39; # noqa BROWSERS_COUNT_LIMIT = 50 REPLACEMENTS = { &#39; &#39;: &#39;&#39;, &#39;_&#39;: &#39;&#39;, } SHORTCUTS = { &#39;internet explorer&#39;: &#39;internetexplorer&#39;, &#39;ie&#39;: &#39;internetexplorer&#39;, &#39;msie&#39;: &#39;internetexplorer&#39;, &#39;edge&#39;: &#39;internetexplorer&#39;, &#39;google&#39;: &#39;chrome&#39;, &#39;googlechrome&#39;: &#39;chrome&#39;, &#39;ff&#39;: &#39;firefox&#39;, } OVERRIDES = { &#39;Edge/IE&#39;: &#39;Internet Explorer&#39;, &#39;IE/Edge&#39;: &#39;Internet Explorer&#39;, } HTTP_TIMEOUT = 5 HTTP_RETRIES = 2 HTTP_DELAY = 0.1 http://useragentstring.com/pages/useragentstring.php?name=Chrome 打开超时报错，其中CACHE_SERVER是存储了所有UserAgent的json数据，再次观察其中DB这个变量，结合fake_useragent\fake.py中的逻辑，判断这个变量应该是存储json数据的，所以大体逻辑应该是，首次初始化时，会自动爬取CACHE_SERVER中的json数据，然后将其存储到本地，所以我们直接将json存到指定路径下，再次初始化时，应该就不会报错 &gt;&gt;&gt; import tempfile &gt;&gt;&gt; print(tempfile.gettempdir()) C:\Users\codewj\AppData\Local\Temp 将CACHE_SERVER的json数据保存为fake_useragent_0.1.11.json,并放到目录C:\Users\codewj\AppData\Local\Temp中 &gt;&gt;&gt; import fake_useragent &gt;&gt;&gt; ua = fake_useragent.UserAgent() &gt;&gt;&gt; ua.data_browsers[&#39;chrome&#39;][0] &#39;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36&#39; 注：如果CACHE_SERVER不是https://fake-useragent.herokuapp.com/browsers/0.1.11，请更新一下库pip install –upgrade fake_useragent]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
        <tag>selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好客租房mybatisplus]]></title>
    <url>%2F2019%2F08%2F22%2F%E5%A5%BD%E5%AE%A2%E7%A7%9F%E6%88%BFmybatisplus%2F</url>
    <content type="text"><![CDATA[基于dubbo react mybatisplus elk实战整合开发 mysqldocker run -di --name=mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 docker.io/mysql mysql -u root -p ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;; docker logs -fn 500 mysql MybatisPlus入门执行建表 haoke.sql mybatis-plus/pom.xml &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mybatis-plus的springboot支持--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.5&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.properties spring.application.name = itcast-mybatis-plus spring.datasource.driver-class-name=com.mysql.jdbc.Driver spring.datasource.url=jdbc:mysql://192.168.3.237:3306/haoke?useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false spring.datasource.username=root spring.datasource.password=123456 com/onejane/mybatisplus/pojo/User.java @Data public class User { @TableId(value = &quot;ID&quot;, type = IdType.AUTO) private Long id; private String name; private Integer age; private String email; } com/onejane/mybatisplus/mapper/UserMapper.java public interface UserMapper extends BaseMapper&lt;User&gt; { } com/onejane/mybatisplus/MyApplication.java @MapperScan(&quot;com.onejane.mybatisplus.mapper&quot;) //设置mapper接口的扫描包 @SpringBootApplication public class MyApplication { /** * 分页插件 */ @Bean public PaginationInterceptor paginationInterceptor() { return new PaginationInterceptor(); } public static void main(String[] args) { SpringApplication.run(MyApplication.class, args); } } com/onejane/mybatisplus/mapper/UserMaperTest.java @RunWith(SpringRunner.class) @SpringBootTest public class UserMaperTest { @Autowired private UserMapper userMapper; @Test public void testSelect(){ List&lt;User&gt; users = this.userMapper.selectList(null); for (User user : users) { System.out.println(user); } } @Test public void testSelectById(){ User user = this.userMapper.selectById(3L); System.out.println(user); } @Test public void testSelectByLike(){ QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;User&gt;(); wrapper.like(&quot;name&quot;, &quot;o&quot;); List&lt;User&gt; list = this.userMapper.selectList(wrapper); for (User user : list) { System.out.println(user); } } @Test public void testSelectByLe(){ QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;User&gt;(); wrapper.le(&quot;age&quot;, 20); List&lt;User&gt; list = this.userMapper.selectList(wrapper); for (User user : list) { System.out.println(user); } } @Test public void testSave(){ User user = new User(); user.setAge(25); user.setEmail(&quot;zhangsan@qq.com&quot;); user.setName(&quot;zhangsan&quot;); int count = this.userMapper.insert(user); System.out.println(&quot;新增数据成功! count =&gt; &quot; + count); } @Test public void testDelete(){ this.userMapper.deleteById(7L); System.out.println(&quot;删除成功!&quot;); } @Test public void testUpdate(){ User user = new User(); user.setId(6L); user.setName(&quot;lisi&quot;); this.userMapper.updateById(user); System.out.println(&quot;修改成功!&quot;); } @Test public void testSelectPage() { Page&lt;User&gt; page = new Page&lt;&gt;(2, 2); IPage&lt;User&gt; userIPage = this.userMapper.selectPage(page, null); System.out.println(&quot;总条数 ------&gt; &quot; + userIPage.getTotal()); System.out.println(&quot;当前页数 ------&gt; &quot; + userIPage.getCurrent()); System.out.println(&quot;当前每页显示数 ------&gt; &quot; + userIPage.getSize()); List&lt;User&gt; records = userIPage.getRecords(); for (User user : records) { System.out.println(user); } } } 兼容配置application.properties ## 指定全局配置文件 mybatis-plus.config-location = classpath:mybatis-config.xml # 指定mapper.xml文件 mybatis-plus.mapper-locations = classpath*:mybatis/*.xml Lombok&lt;!--简化代码的工具包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;version&gt;1.18.4&lt;/version&gt; &lt;/dependency&gt; 安装idea Lombok插件 @Data：注解在类上；提供类所有属性的 getting 和 setting 方法，此外还提供了equals、canEqual、hashCode、toString 方法 @Setter setting 方法 @Getter：注解在属性上；为属性提供 getting 方法 @Slf4j：注解在类上；为类提供一个 属性名为log 的 slf4j日志对象 @NoArgsConstructor：注解在类上；为类提供一个无参的构造方法 @AllArgsConstructor：注解在类上；为类提供一个全参的构造方法 @Builder：使用Builder模式构建对象 @Slf4j @Data @AllArgsConstructor @Builder public class Item { private Long id; private String title; private Long price; public Item() { log.info(&quot;写日志。。。。。&quot;); } public static void main(String[] args) { Item item1 = new Item(1L,&quot;哈哈哈&quot;,10L); Item item2 = Item.builder().price(100L)title(&quot;hello&quot;).id(1L).build(); System.out.println(item1.getId()); } } 搭建后台服务系统haoke-manage├─haoke-manage-api-server├─haoke-manage-dubbo-server│ ├─haoke-manage-dubbo-server-ad│ ├─haoke-manage-dubbo-server-common│ ├─haoke-manage-dubbo-server-generator MybatisPlus的AutoGenerator插件生成代码文件│ ├─haoke-manage-dubbo-server-house-resources│ │ ├─haoke-manage-dubbo-server-house-resources-dubbo-interface 对外提供的sdk包 只提供pojo实体以及接口，不提供实现类│ │ ├─haoke-manage-dubbo-server-house-resources-dubbo-service 具体实现 haoke-manage&lt;!--spring boot的支持放在groupId上面--&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!--springboot 测试支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--dubbo的springboot支持--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--dubbo框架--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.7&lt;/version&gt; &lt;/dependency&gt; &lt;!--zk依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; haoke-manage-api-serverpom.xml &lt;dependencies&gt; &lt;!--springboot的web支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.onejane&lt;/groupId&gt; &lt;artifactId&gt;haoke-manage-dubbo-server-house-resources-dubbo-interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.properties # Spring boot application spring.application.name = haoke-manage-api-server server.port = 18080 #logging.level.root=DEBUG # dubbo的应用名称 dubbo.application.name = dubbo-consumer-haoke-manage # zk注册中心 dubbo.registry.address = zookeeper://192.168.3.237:2181 dubbo.registry.client = zkclient Pagination @Data @AllArgsConstructor public class Pagination { private Integer current; private Integer pageSize; private Integer total; }TableResult @Data @AllArgsConstructor public class TableResult&lt;T&gt; { private List&lt;T&gt; list; private Pagination pagination; } HouseResourcesService @Service public class HouseResourcesService { @Reference(version = &quot;1.0.0&quot;) private ApiHouseResourcesService apiHouseResourcesService; public boolean save(HouseResources houseResources) { int result = this.apiHouseResourcesService.saveHouseResources(houseResources); return result == 1; } public TableResult&lt;HouseResources&gt; queryList(HouseResources houseResources, Integer currentPage, Integer pageSize) { PageInfo&lt;HouseResources&gt; pageInfo = this.apiHouseResourcesService. queryHouseResourcesList(currentPage, pageSize, houseResources); return new TableResult&lt;&gt;(pageInfo.getRecords(), new Pagination(currentPage, pageSize, pageInfo.getTotal())); } /** * 根据id查询房源数据 * * @param id * @return */ public HouseResources queryHouseResourcesById(Long id){ // 调用dubbo中的服务进行查询数据 return this.apiHouseResourcesService.queryHouseResourcesById(id); } public boolean update(HouseResources houseResources) { return this.apiHouseResourcesService.updateHouseResources(houseResources); } }HouseResourcesController @Controller @RequestMapping(&quot;house/resources&quot;) public class HouseResourcesController { @Autowired private HouseResourcesService houseResourcesService; /** * 新增房源 * * @param houseResources json数据 * @return */ @PostMapping @ResponseBody public ResponseEntity&lt;Void&gt; save(@RequestBody HouseResources houseResources) { try { boolean bool = this.houseResourcesService.save(houseResources); if (bool) { return ResponseEntity.status(HttpStatus.CREATED).build(); } } catch (Exception e) { e.printStackTrace(); } return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build(); } /** * 查询房源列表 * * @param houseResources * @param currentPage * @param pageSize * @return */ @GetMapping @ResponseBody public ResponseEntity&lt;TableResult&gt; list(HouseResources houseResources, @RequestParam(name = &quot;currentPage&quot;, defaultValue = &quot;1&quot;) Integer currentPage, @RequestParam(name = &quot;pageSize&quot;, defaultValue = &quot;10&quot;) Integer pageSize) { return ResponseEntity.ok(this.houseResourcesService.queryList(houseResources, currentPage, pageSize)); } /** * 修改房源 * * @param houseResources json数据 * @return */ @PutMapping @ResponseBody public ResponseEntity&lt;Void&gt; update(@RequestBody HouseResources houseResources) { try { boolean bool = this.houseResourcesService.update(houseResources); if (bool) { return ResponseEntity.status(HttpStatus.NO_CONTENT).build(); } } catch (Exception e) { e.printStackTrace(); } return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build(); } } DubboApiApplication @SpringBootApplication public class DubboApiApplication { public static void main(String[] args) { SpringApplication.run(DubboApiApplication.class, args); } }haoke-manage-dubbo-serverpom.xml &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; haoke-manage-dubbo-server-generatorpom.xml &lt;dependencies&gt; &lt;!-- freemarker 模板引擎 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.28&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.5&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; CodeGenerator 配置数据源及账户密码，运行即可生成对应文件，并将pojo类拷贝到工程中备用 public class CodeGenerator { /** * &lt;p&gt; * 读取控制台内容 * &lt;/p&gt; */ public static String scanner(String tip) { Scanner scanner = new Scanner(System.in); StringBuilder help = new StringBuilder(); help.append(&quot;请输入&quot; + tip + &quot;：&quot;); System.out.println(help.toString()); if (scanner.hasNext()) { String ipt = scanner.next(); if (StringUtils.isNotEmpty(ipt)) { return ipt; } } throw new MybatisPlusException(&quot;请输入正确的&quot; + tip + &quot;！&quot;); } public static void main(String[] args) { // 代码生成器 AutoGenerator mpg = new AutoGenerator(); // 全局配置 GlobalConfig gc = new GlobalConfig(); String projectPath = System.getProperty(&quot;user.dir&quot;); gc.setOutputDir(projectPath + &quot;/src/main/java&quot;); gc.setAuthor(&quot;onejane&quot;); gc.setOpen(false); mpg.setGlobalConfig(gc); // 数据源配置 DataSourceConfig dsc = new DataSourceConfig(); dsc.setUrl(&quot;jdbc:mysql://192.168.3.237:3306/haoke?useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&quot;); // dsc.setSchemaName(&quot;public&quot;); dsc.setDriverName(&quot;com.mysql.jdbc.Driver&quot;); dsc.setUsername(&quot;root&quot;); dsc.setPassword(&quot;123456&quot;); mpg.setDataSource(dsc); // 包配置 PackageConfig pc = new PackageConfig(); pc.setModuleName(scanner(&quot;模块名&quot;)); pc.setParent(&quot;com.onejane.haoke.dubbo.server&quot;); mpg.setPackageInfo(pc); // 自定义配置 InjectionConfig cfg = new InjectionConfig() { @Override public void initMap() { // to do nothing } }; List&lt;FileOutConfig&gt; focList = new ArrayList&lt;&gt;(); focList.add(new FileOutConfig(&quot;/templates/mapper.xml.ftl&quot;) { @Override public String outputFile(TableInfo tableInfo) { // 自定义输入文件名称 return projectPath + &quot;/src/main/resources/mapper/&quot; + pc.getModuleName() + &quot;/&quot; + tableInfo.getEntityName() + &quot;Mapper&quot; + StringPool.DOT_XML; } }); cfg.setFileOutConfigList(focList); mpg.setCfg(cfg); mpg.setTemplate(new TemplateConfig().setXml(null)); // 策略配置 StrategyConfig strategy = new StrategyConfig(); strategy.setNaming(NamingStrategy.underline_to_camel); strategy.setColumnNaming(NamingStrategy.underline_to_camel); strategy.setSuperEntityClass(&quot;com.onejane.haoke.dubbo.server.pojo.BasePojo&quot;); strategy.setEntityLombokModel(true); strategy.setRestControllerStyle(true); strategy.setSuperControllerClass(&quot;com.baomidou.ant.common.BaseController&quot;); strategy.setInclude(scanner(&quot;表名&quot;)); strategy.setSuperEntityColumns(&quot;id&quot;); strategy.setControllerMappingHyphenStyle(true); strategy.setTablePrefix(pc.getModuleName() + &quot;_&quot;); mpg.setStrategy(strategy); mpg.setTemplateEngine(new FreemarkerTemplateEngine()); mpg.execute(); } } 测试 haoke-manage-dubbo-server-house-resourcespom.xml &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.onejane&lt;/groupId&gt; &lt;artifactId&gt;haoke-manage-dubbo-server-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;!--需要注意：传递依赖中，如果需要使用，请显示引入--&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.5&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; haoke-manage-dubbo-server-house-resources-dubbo-interfaceApiHouseResourcesService // dubbo service public interface ApiHouseResourcesService { /** * 新增房源 * * @param houseResources * @return -1:输入的参数不符合要求，0：数据插入数据库失败，1：成功 */ int saveHouseResources(HouseResources houseResources); /** * 分页查询房源列表 * * @param page 当前页 * @param pageSize 页面大小 * @param queryCondition 查询条件 * @return */ PageInfo&lt;HouseResources&gt; queryHouseResourcesList(int page, int pageSize, HouseResources queryCondition); /** * 根据id查询房源数据 * * @param id * @return */ HouseResources queryHouseResourcesById(Long id); boolean updateHouseResources(HouseResources houseResources); } HouseResources @Data @Accessors(chain = true) @TableName(&quot;tb_house_resources&quot;) public class HouseResources extends BasePojo { private static final long serialVersionUID = 779152022777511825L; @TableId(value = &quot;id&quot;, type = IdType.AUTO) private Long id; /** * 房源标题 */ private String title; /** * 楼盘id */ private Long estateId; /** * 楼号（栋） */ private String buildingNum; /** * 单元号 */ private String buildingUnit; /** * 门牌号 */ private String buildingFloorNum; /** * 租金 */ private Integer rent; /** * 租赁方式，1-整租，2-合租 */ private Integer rentMethod; /** * 支付方式，1-付一押一，2-付三押一，3-付六押一，4-年付押一，5-其它 */ private Integer paymentMethod; /** * 户型，如：2室1厅1卫 */ private String houseType; /** * 建筑面积 */ private String coveredArea; /** * 使用面积 */ private String useArea; /** * 楼层，如：8/26 */ private String floor; /** * 朝向：东、南、西、北 */ private String orientation; /** * 装修，1-精装，2-简装，3-毛坯 */ private Integer decoration; /** * 配套设施， 如：1,2,3 */ private String facilities; /** * 图片，最多5张 */ private String pic; /** * 描述 */ private String houseDesc; /** * 联系人 */ private String contact; /** * 手机号 */ private String mobile; /** * 看房时间，1-上午，2-中午，3-下午，4-晚上，5-全天 */ private Integer time; /** * 物业费 */ private String propertyCost; } haoke-manage-dubbo-server-house-resources-dubbo-servicepom.xml &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.onejane&lt;/groupId&gt; &lt;artifactId&gt;haoke-manage-dubbo-server-house-resources-dubbo-interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.properties # Spring boot application spring.application.name = haoke-manage-dubbo-server-house-resources # 数据库 spring.datasource.driver-class-name=com.mysql.jdbc.Driver spring.datasource.url=jdbc:mysql://192.168.3.237:3306/haoke?useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false spring.datasource.username=root spring.datasource.password=123456 # 服务的扫描包 dubbo.scan.basePackages = com.onejane.haoke.dubbo.server.api # 应用名称 dubbo.application.name = dubbo-provider-house-resources # 协议以及端口 dubbo.protocol.name = dubbo dubbo.protocol.port = 20880 # zk注册中心 dubbo.registry.address = zookeeper://192.168.3.237:2181 dubbo.registry.client = zkclient MybatisConfig @MapperScan(&quot;com.onejane.haoke.dubbo.server.mapper&quot;) @Configuration public class MybatisConfig { } HouseResourcesMapper public interface HouseResourcesMapper extends BaseMapper&lt;HouseResources&gt; { } HouseResourcesService // spring service public interface HouseResourcesService { /** * @param houseResources * * @return -1:输入的参数不符合要求，0：数据插入数据库失败，1：成功 */ int saveHouseResources(HouseResources houseResources); PageInfo&lt;HouseResources&gt; queryHouseResourcesList(int page, int pageSize, HouseResources queryCondition); /** * 根据房源id查询房源数据 * * @param id * @return */ HouseResources queryHouseResourcesById(Long id); /** * 更新房源数据 * * @param houseResources * @return */ boolean updateHouseResources(HouseResources houseResources); }HouseResourcesServiceImpl @Transactional @Service public class HouseResourcesServiceImpl extends BaseServiceImpl&lt;HouseResources&gt; implements HouseResourcesService { /** * @param houseResources * @return -1:输入的参数不符合要求，0：数据插入数据库失败，1：成功 */ @Override public int saveHouseResources(HouseResources houseResources) { // 添加校验或者是其他的一些逻辑 if (StringUtils.isBlank(houseResources.getTitle())) { // 不符合要求 return -1; } return super.save(houseResources); } @Override public PageInfo&lt;HouseResources&gt; queryHouseResourcesList(int page, int pageSize, HouseResources queryCondition) { QueryWrapper queryWrapper = new QueryWrapper(); // 根据数据的更新时间做倒序排序 queryWrapper.orderByDesc(&quot;updated&quot;); IPage iPage = super.queryPageList(queryWrapper, page, pageSize); return new PageInfo&lt;HouseResources&gt;(Long.valueOf(iPage.getTotal()).intValue(), page, pageSize, iPage.getRecords()); } public HouseResources queryHouseResourcesById(Long id) { return super.queryById(id); } @Override public boolean updateHouseResources(HouseResources houseResources) { return super.update(houseResources) == 1; } } DubboProvider @SpringBootApplication public class DubboProvider { /** * 分页插件 */ @Bean public PaginationInterceptor paginationInterceptor() { return new PaginationInterceptor(); } public static void main(String[] args) { new SpringApplicationBuilder(DubboProvider.class) .web(WebApplicationType.NONE) // 非 Web 应用 .run(args); } } ApiHouseResourcesServiceImpl @Service(version = &quot;1.0.0&quot;) // 分离dubbo服务和spring服务，易于扩展 public class ApiHouseResourcesServiceImpl implements ApiHouseResourcesService { @Autowired private HouseResourcesService houseResourcesService; @Override public int saveHouseResources(HouseResources houseResources) { return this.houseResourcesService.saveHouseResources(houseResources); } @Override public PageInfo&lt;HouseResources&gt; queryHouseResourcesList(int page, int pageSize, HouseResources queryCondition) { return this.houseResourcesService.queryHouseResourcesList(page, pageSize, queryCondition); } public HouseResources queryHouseResourcesById(Long id) { return this.houseResourcesService.queryHouseResourcesById(id); } @Override public boolean updateHouseResources(HouseResources houseResources) { return this.houseResourcesService.updateHouseResources(houseResources); } } 启动DubboAdmin中显示 测试 整合前端src/pages/haoke/House/AddResource.js添加标题及修改表单提交地址 &lt;FormItem {...formItemLayout} label=&quot;房源标题&quot;&gt; {getFieldDecorator(&#39;title&#39;,{rules:[{ required: true, message:&quot;此项为必填项&quot; }]})(&lt;Input style={{ width: '100%' }} /&gt;)} &lt;/FormItem&gt; dispatch({ type: &#39;house/submitHouseForm&#39;, payload: values, }); src/pages/haoke/House/models/form.js增加model import { routerRedux } from &#39;dva/router&#39;; import { message } from &#39;antd&#39;; import { addHouseResource } from &#39;@/services/haoke&#39;; export default { namespace: &#39;house&#39;, state: { }, effects: { *submitHouseForm({ payload }, { call }) { yield call(addHouseResource, payload); message.success(&#39;提交成功&#39;); } }, reducers: { saveStepFormData(state, { payload }) { return { ...state }; }, }, }; src/services/haoke.js增加服务，请求服务并且处理业务逻辑 import request from &#39;@/utils/request&#39;; export async function addHouseResource(params) { return request(&#39;/haoke/house/resources&#39;, { method: &#39;POST&#39;, body: params }); } 由于我们前端系统8000和后台服务系统18080的端口不同，会导致跨域问题，我们通过umi提供的反向代理功能解决这个问题。haoke-manage-web/config/config.js proxy: { &#39;/haoke/&#39;: { target: &#39;http://127.0.0.1:18080/&#39;, changeOrigin: true, pathRewrite: { &#39;^/haoke/&#39;: &#39;&#39; } } }, 代理效果是这样的：以haoke开头的请求都会被代理请求：http://localhost:8000/haoke/house/resources实际：http://127.0.0.1:18080/house/resources 测试启动前端：itcast-haoke-manage-web&gt;tyarn start启动提供者：itcast-haoke-manage-dubbo-server-house-resources-dubbo-service/DubboProvider启动消费者：tcast-haoke-manage/itcast-haoke-manage-api-server/DubboApiApplication]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>mybatisplus</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好客租房dubbo]]></title>
    <url>%2F2019%2F08%2F21%2F%E5%A5%BD%E5%AE%A2%E7%A7%9F%E6%88%BFdubbo%2F</url>
    <content type="text"><![CDATA[基于dubbo react elk实战整合开发 整体架构 后端架构：SpringBoot+StringMVC+Dubbo+Mybatis+ELK+区块链 前端架构：React.js+html5+百度地图+微信小程序前端初始化haoke-manage-web tyarn install tyarn start 修改logo及版权信息src/layouts/BasicLayout.js 全局的布局文件 &lt;SiderMenu![itcast-haoke-manage-web](./attachments/itcast-haoke-manage-web.zip) logo={logo} Authorized={Authorized} theme={navTheme} onCollapse={this.handleMenuCollapse} menuData={menuData} isMobile={isMobile} {...this.props} /&gt; src/components/SiderMenu/index.js &lt;SiderMenu {...props} flatMenuKeys={getFlatMenuKeys(menuData)} collapsed={isMobile ? false : collapsed} /&gt; src/components/SiderMenu/SiderMenu.js &lt;div className={styles.logo} id=&quot;logo&quot;&gt; &lt;Link to=&quot;/&quot;&gt; {/* &lt;img src={logo} alt=&quot;logo&quot; /&gt; */} &lt;h1&gt;好客租房 · 管理系统&lt;/h1&gt; &lt;/Link&gt; &lt;/div&gt; src/layouts/Footer.js &lt;Footer style={{ padding: 0 }}&gt; &lt;GlobalFooter copyright={ &lt;Fragment&gt; Copyright &lt;Icon type=&quot;copyright&quot; /&gt; 2018 黑马程序员 博学谷 出品 &lt;/Fragment&gt; } /&gt; &lt;/Footer&gt; 新增房源config/router.config.js { path: &#39;/&#39;, redirect: &#39;/house/resource&#39; }, // 进入系统默认打开房源管理 { //房源管理 path: &#39;/house&#39;, name: &#39;house&#39;, icon: &#39;home&#39;, routes: [ { path: &#39;/house/resource&#39;, name: &#39;resource&#39;, component: &#39;./haoke/House/Resource&#39; }, { path: &#39;/house/addResource&#39;, name: &#39;addResource&#39;, component: &#39;./haoke/House/AddResource&#39; }, { path: &#39;/house/kanfang&#39;, name: &#39;kanfang&#39;, component: &#39;./haoke/House/KanFang&#39; }, { path: &#39;/house/zufang&#39;, name: &#39;zufang&#39;, component: &#39;./haoke/House/ZuFang&#39; } ] }, src/pages/haoke/House/AddResource.js @Form.create() 对页面进行了包装，包装之后，会在this.props中增加form对象,将拥有getFieldDecorator 双向绑定等功能,经过 getFieldDecorator 包装的控件，表单控件会自动添加 value （或 valuePropName 指定的其他属性） onChange （或 trigger 指定的其他属性），数据同步将被 Form 接管 你不再需要也不应该用 onChange 来做同步，但还是可以继续监听 onChange 等事件。 你不能用控件的 value defaultValue 等属性来设置表单域的值，默认值可以用getFieldDecorator 里的 initialValue,利用rule进行参数规则校验 你不应该用 setState ，可以使用 this.props.form.setFieldsValue 来动态改变表单值。 表单提交&lt;Button type=&quot;primary&quot; htmlType=&quot;submit&quot; loading={submitting}&gt; &lt;Form onSubmit={this.handleSubmit} hideRequiredMark style={{ marginTop: 8 }}&gt; 进行提交拦截 handleSubmit = e =&gt; { 通过form.validateFieldsAndScroll()对表单进行校验，通过values获取表单中输入的值。通过dispatch()调用model中定义的方法。 const { dispatch, form } = this.props; e.preventDefault(); console.log(this.state.fileList); form.validateFieldsAndScroll((err, values) =&gt; { if (!err) { if(values.facilities){ values.facilities = values.facilities.join(&quot;,&quot;); } if(values.floor_1 &amp;&amp; values.floor_2){ values.floor = values.floor_1 + &quot;/&quot; + values.floor_2; } values.houseType = values.houseType_1 + &quot;室&quot; + values.houseType_2 + &quot;厅&quot; + values.houseType_3 + &quot;卫&quot; + values.houseType_4 + &quot;厨&quot; + values.houseType_2 + &quot;阳台&quot;; delete values.floor_1; delete values.floor_2; delete values.houseType_1; delete values.houseType_2; delete values.houseType_3; delete values.houseType_4; delete values.houseType_5; dispatch({ type: &#39;form/submitRegularForm&#39;, payload: values, }); } }); }; 自动完成const estateMap = new Map([ [&#39;中远两湾城&#39;,&#39;1001|上海市,上海市,普陀区,远景路97弄&#39;], [&#39;上海康城&#39;,&#39;1002|上海市,上海市,闵行区,莘松路958弄&#39;], [&#39;保利西子湾&#39;,&#39;1003|上海市,上海市,松江区,广富林路1188弄&#39;], [&#39;万科城市花园&#39;,&#39;1004|上海市,上海市,闵行区,七莘路3333弄2区-15区&#39;], [&#39;上海阳城&#39;,&#39;1005|上海市,上海市,闵行区,罗锦路888弄&#39;] ]); &lt;AutoComplete style={{ width: '100%' }} dataSource={this.state.estateDataSource} placeholder=&quot;搜索楼盘&quot; onSelect={(value, option)=&gt;{ let v = estateMap.get(value); this.setState({ estateAddress: v.substring(v.indexOf(&#39;|&#39;)+1), estateId : v.substring(0,v.indexOf(&#39;|&#39;)) }); }} onSearch={this.handleSearch} filterOption={(inputValue, option) =&gt; option.props.children.toUpperCase().indexOf(inputValue.toUpperCase()) !== -1} /&gt; 通过onSearch进行动态设置数据源，这里使用的数据是静态数据 handleSearch = (value)=&gt;{ let arr = new Array(); if(value.length &gt; 0 ){ estateMap.forEach((v, k) =&gt; { if(k.startsWith(value)){ arr.push(k); } }); } this.setState({ estateDataSource: arr }); } ; 通过onSelect设置 选中楼盘后，在楼盘地址中填写地址数据 onSelect={(value, option)=&gt;{ let v = estateMap.get(value); this.setState({ estateAddress: v.substring(v.indexOf(&#39;|&#39;)+1), estateId : v.substring(0,v.indexOf(&#39;|&#39;)) }); }} 图片上传父组件通过属性的方式进行引用子组件，自组件在bind方法中改变this的引用为父组件 &lt;FormItem {...formItemLayout} label=&quot;上传室内图&quot;&gt; &lt;PicturesWall handleFileList={this.handleFileList.bind(this)}/&gt; &lt;/FormItem&gt; 父组件中获取数据 handleFileList = (obj)=&gt;{ console.log(obj, &quot;图片列表&quot;); } src/pages/haoke/Utils/PicturesWall.js 在子组件中通过this.props获取父组件方法传入的函数，进行调用，即可把数据传递到父组件中 handleChange = ({ fileList }) =&gt; { this.setState({ fileList }); this.props.handleFileList(this.state.fileList); } &lt;Upload action=&quot;1111111&quot; listType=&quot;picture-card&quot; fileList={fileList} onPreview={this.handlePreview} onChange={this.handleChange} &gt; {fileList.length &gt;= 5 ? null : uploadButton} &lt;/Upload&gt; 后端后台系统服务采用RPC+微服务的架构思想，RPC采用dubbo架构作为服务治理框架，对外接口采用RESTFul+GraphQL接口方式。 单一应用架构当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。 垂直应用架构当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。 分布式服务架构当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。 流动计算架构当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键。调用关系说明 服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。流程说明： 服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址 服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向/dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址 监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。支持以下功能： 当提供者出现断电等异常停机时，注册中心能自动删除提供者信息 当注册中心重启时，能自动恢复注册数据，以及订阅请求 当会话过期时，能自动恢复注册数据，以及订阅请求 当设置 &lt;dubbo:registry check=”false” /&gt; 时，记录失败注册和订阅请求，后台定时重试 可通过 &lt;dubbo:registry username=”admin” password=”1234” /&gt; 设置 zookeeper 登录信息 可通过 &lt;dubbo:registry group=”dubbo” /&gt; 设置 zookeeper 的根节点，不设置将使用无根树 支持 * 号通配符 &lt;dubbo:reference group=”*” version=”*” /&gt; ，可订阅服务的所有分组和所有版本的提供者 zk安装apt-get install --reinstall systemd -y apt-get install -y docker.io systemctl start docker docker create --name zk -p 2181:2181 zookeeper:3.5 docker start zk 可以通过ZooInspector连接查看 yum install -y yum-utils device-mapper-persistent-data lvm2 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum makecache fast yum list docker-ce --showduplicates | sort -r yum install -y docker-ce-18.09.5 systemctl restart docker docker create --name zk -p 2181:2181 zookeeper:3.5 docker start zk ZooInspector执行ZooInspector\build\start.bat查看zk信息 服务提供方dubbo/pom.xml &lt;!--添加SpringBoot parent支持--&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!--添加SpringBoot测试--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--添加dubbo的springboot依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--添加dubbo依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!--添加springboot的maven插件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; dubbo/dubbo-service/pom.xml &lt;dependencies&gt; &lt;!--添加springboot依赖，非web项目--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; com/onejane/dubbo/pojo/User.java // 使用dubbo要求传输的对象必须实现序列化接口 public class User implements java.io.Serializable { private static final long serialVersionUID = -7341603933521593227L; private Long id; private String username; private String password; private Integer age; } com/onejane/dubbo/service/UserService.java public interface UserService { List&lt;User&gt; queryAll(); } com/onejane/dubbo/service/impl/UserServiceImpl.java @Service(version = &quot;${dubbo.service.version}&quot;) //声明这是一个dubbo服务 public class UserServiceImpl implements UserService { public List&lt;User&gt; queryAll() { List&lt;User&gt; list = new ArrayList&lt;User&gt;(); for (int i = 0; i &lt; 10; i++) { User user = new User(); user.setAge(10 + i); user.setId(Long.valueOf(i + 1)); user.setPassword(&quot;123456&quot;); user.setUsername(&quot;username_&quot; + i); list.add(user); } System.out.println(&quot;---------Service 3------------&quot;); return list; } } application.properties # Spring boot application spring.application.name = dubbo-service server.port = 9090 # Service version dubbo.service.version = 1.0.0 # 服务的扫描包 dubbo.scan.basePackages =com.onejane.dubbo.service # 应用名称 dubbo.application.name = dubbo-provider-demo # 协议以及端口 dubbo.protocol.name = dubbo dubbo.protocol.port = 20882 # zk注册中心 dubbo.registry.address = zookeeper://192.168.3.237:2181 dubbo.registry.client = zkclient com/onejane/dubbo/DubboProvider.java @SpringBootApplication public class DubboProvider { public static void main(String[] args) { new SpringApplicationBuilder(DubboProvider.class) .web(WebApplicationType.NONE) // 非 Web 应用 .run(args); } } 服务消费方dubbo/dubbo-comsumer/pom.xml &lt;dependencies&gt; &lt;!--添加springboot依赖，非web项目--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--引入service的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.onejane&lt;/groupId&gt; &lt;artifactId&gt;dubbo-service&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.properties # Spring boot application spring.application.name = dubbo-consumer server.port = 9091 # 应用名称 dubbo.application.name = dubbo-consumer-demo # zk注册中心 dubbo.registry.address = zookeeper://192.168.3.237:2181 dubbo.registry.client = zkclient com/onejane/dubbo/UserServiceTest.java @RunWith(SpringRunner.class) @SpringBootTest public class UserServiceTest { // 负载均衡策略 默认随机 测试时启动dubbo.protocol.port多个不同端口的userService服务，并修改打印值进行区分 // loadbalance = &quot;roundrobin&quot;设置负载均衡策略 @Reference(version = &quot;1.0.0&quot;, loadbalance = &quot;roundrobin&quot;) private UserService userService; @Test public void testQueryAll() { for (int i = 0; i &lt; 100; i++) { System.out.println(&quot;开始调用远程服务 &gt;&gt;&gt;&gt;&gt;&quot; + i); List&lt;User&gt; users = this.userService.queryAll(); for (User user : users) { System.out.println(user); } try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } }启动服务后，即可测试 Dubbo Admintar zxf incubator-dubbo-ops.tar.gz -C /usr/local/ tar zxf apache-maven-3.6.0-bin.tar.gz -C /usr/local/ vim incubator-dubbo-ops/dubbo-admin-backend/src/main/resources/application.properties dubbo.registry.address=zookeeper://192.168.3.237:2181 vim /etc/profile 如误操作导致基础命令丢失，export PATH=/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin export MAVEN_HOME=/usr/local/apache-maven-3.6.0 export JAVA_HOME=/usr/local/jdk export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$MAVEN_HOME/bin:$PATH source /etc/profile cd /usr/local/incubator-dubbo-ops &amp;&amp; mvn clean install vim dubbo-admin-backend/src/main/resources/application.properties server.port=8888 mvn --projects dubbo-admin-backend spring-boot:run http://192.168.3.237:8888Dubbo 缺省协议不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低。Dubbo 缺省协议dubbo:// 协议采用单一长连接和 NIO 异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。 Transporter （传输）: mina, netty, grizzySerialization（序列化）: dubbo, hessian2, java, jsonDispatcher（分发调度）: all, direct, message, execution, connectionThreadPool（线程池）: fixed, cached 连接个数：单连接 连接方式：长连接 传输协议：TCP 传输方式：NIO 异步传输 序列化：Hessian 二进制序列化 适用范围：传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供 者，尽量不要用 dubbo 协议传输大文件或超大字符串。 适用场景：常规远程服务方法调用]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>ant design pro</tag>
        <tag>dubbo</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好客租房react]]></title>
    <url>%2F2019%2F08%2F21%2F%E5%A5%BD%E5%AE%A2%E7%A7%9F%E6%88%BFreact%2F</url>
    <content type="text"><![CDATA[基于spring cloud alibaba实战整合开发 React入门mock dvareact/config/config.js export default { plugins:[ [&#39;umi-plugin-react&#39;,{ dva: true, //开启dva进行数据分层管理 }] ] }; react/mock/MockListData.js export default { &#39;get /ds/list&#39;: function (req, res) { //模拟请求返回数据 res.json({ data: [1, 2, 3, 4, 5], maxNum: 5 }); } } react/src/util/request.js // import fetch from &#39;dva/fetch&#39;; function checkStatus(response) { if (response.status &gt;= 200 &amp;&amp; response.status &lt; 300) { return response; } const error = new Error(response.statusText); error.response = response; throw error; } /** * Requests a URL, returning a promise. * * @param {string} url The URL we want to request * @param {object} [options] The options we want to pass to &quot;fetch&quot; * @return {object} An object containing either &quot;data&quot; or &quot;err&quot; */ export default async function request(url, options) { const response = await fetch(url, options); checkStatus(response); return await response.json(); } react/src/models/ListData.js import request from &#39;../util/request&#39;; export default { namespace: &#39;list&#39;, state: { data: [], maxNum: 1 }, reducers : { // 定义的一些函数 addNewData : function (state, result) { // state：指的是更新之前的状态数据, result: 请求到的数据 if(result.data){ //如果state中存在data数据，直接返回，在做初始化的操作 return result.data; } let maxNum = state.maxNum + 1; let newArr = [...state.data, maxNum]; return { data : newArr, maxNum : maxNum } //通过return 返回更新后的数据 } }, effects: { //新增effects配置，用于异步加载数据 *initData(params, sagaEffects) { //定义异步方法 const {call, put} = sagaEffects; //获取到call、put方法 const url = &quot;/ds/list&quot;; // 定义请求的url let data = yield call(request, url); //执行请求 yield put({ // 调用reducers中的方法 type : &quot;addNewData&quot;, //指定方法名 data : data //传递ajax回来的数据 }); } } } react/src/pages/List.js import React from &#39;react&#39;; import { connect } from &#39;dva&#39;; const namespace = &quot;list&quot;; // 说明：第一个回调函数，作用：将page层和model层进行链接，返回modle中的数据,并且将返回的数据，绑定到this.props // 接收第二个函数，这个函数的作用：将定义的函数绑定到this.props中，调用model层中定义的函数 @connect((state) =&gt; { return { dataList : state[namespace].data, maxNum : state[namespace].maxNum } }, (dispatch) =&gt; { // dispatch的作用：可以调用model层定义的函数 return { // 将返回的函数，绑定到this.props中 add : function () { dispatch({ //通过dispatch调用modle中定义的函数,通过type属性，指定函数命名，格式：namespace/函数名 type : namespace + &quot;/addNewData&quot; }); }, init : () =&gt; { dispatch({ //通过dispatch调用modle中定义的函数,通过type属性，指定函数命名，格式：namespace/函数名 type : namespace + &quot;/initData&quot; }); } } }) class List extends React.Component{ componentDidMount(){ //初始化的操作 this.props.init(); } render(){ return ( &lt;div&gt; &lt;ul&gt; { this.props.dataList.map((value,index)=&gt;{ return &lt;li key={index}&gt;{value}&lt;/li&gt; }) } &lt;/ul&gt; &lt;button onClick={() =&gt; { this.props.add(); }}&gt;点我&lt;/button&gt; &lt;/div&gt; ); } } export default List; umi dev Ant Design 入门react/config/config.js export default { plugins:[ [&#39;umi-plugin-react&#39;,{ dva: true, //开启dva进行数据分层管理 antd: true // 开启Ant Design功能 }] ], routes: [{ path: &#39;/&#39;, component: &#39;../layouts&#39;, //配置布局路由 routes: [ { path: &#39;/&#39;, component: &#39;./index&#39; }, { path: &#39;/myTabs&#39;, component: &#39;./myTabs&#39; }, { path: &#39;/user&#39;, routes: [ { path: &#39;/user/list&#39;, component: &#39;./user/UserList&#39; }, { path: &#39;/user/add&#39;, component: &#39;./user/UserAdd&#39; } ] } ] }] }; react/mock/MockListData.js &#39;get /ds/user/list&#39;: function (req, res) { res.json([{ key: &#39;1&#39;, name: &#39;张三1&#39;, age: 32, address: &#39;上海市&#39;, tags: [&#39;程序员&#39;, &#39;帅气&#39;], }, { key: &#39;2&#39;, name: &#39;李四2&#39;, age: 42, address: &#39;北京市&#39;, tags: [&#39;屌丝&#39;], }, { key: &#39;3&#39;, name: &#39;王五3&#39;, age: 32, address: &#39;杭州市&#39;, tags: [&#39;高富帅&#39;, &#39;富二代&#39;], }]); react/src/models/UserListData.js import request from &quot;../util/request&quot;; export default { namespace: &#39;userList&#39;, state: { list: [] }, effects: { *initData(params, sagaEffects) { const {call, put} = sagaEffects; const url = &quot;/ds/user/list&quot;; let data = yield call(request, url); yield put({ type : &quot;queryList&quot;, data : data }); } }, reducers: { queryList(state, result) { let data = [...result.data]; return { //更新状态值 list: data } } } } react/src/layouts/index.js import React from &#39;react&#39;; import { Layout, Menu, Icon } from &#39;antd&#39;; import Link from &#39;umi/link&#39;; const { Header, Footer, Sider, Content } = Layout; const SubMenu = Menu.SubMenu; // layouts/index.js文件将被作为全 局的布局文件。 class BasicLayout extends React.Component{ constructor(props){ super(props); this.state = { collapsed: true, } } render(){ return ( &lt;Layout&gt; &lt;Sider width={256} style={{minHeight: '100vh', color: 'white'}}&gt; &lt;div style={{ height: '32px', background: 'rgba(255,255,255,.2)', margin: '16px'}}/&gt; &lt;Menu defaultSelectedKeys={[&#39;1&#39;]} defaultOpenKeys={[&#39;sub1&#39;]} mode=&quot;inline&quot; theme=&quot;dark&quot; inlineCollapsed={this.state.collapsed} &gt; &lt;SubMenu key=&quot;sub1&quot; title={&lt;span&gt;&lt;Icon type=&quot;user&quot;/&gt;&lt;span&gt;用户管理&lt;/span&gt;&lt;/span&gt;}&gt; &lt;Menu.Item key=&quot;1&quot;&gt;&lt;Link to=&quot;/user/add&quot;&gt;新增用户&lt;/Link&gt;&lt;/Menu.Item&gt; &lt;Menu.Item key=&quot;2&quot;&gt;&lt;Link to=&quot;/user/list&quot;&gt;新增列表&lt;/Link&gt;&lt;/Menu.Item&gt; &lt;/SubMenu&gt; &lt;/Menu&gt; &lt;/Sider&gt; &lt;Layout&gt; &lt;Header style={{ background: '#fff', textAlign: 'center', padding: 0 }}&gt;Header&lt;/Header&gt; &lt;Content style={{ margin: '24px 16px 0' }}&gt; &lt;div style={{ padding: 24, background: '#fff', minHeight: 360 }}&gt; { this.props.children } &lt;/div&gt; &lt;/Content&gt; &lt;Footer style={{ textAlign: 'center' }}&gt;后台系统&lt;/Footer&gt; &lt;/Layout&gt; &lt;/Layout&gt; ) } } export default BasicLayout; react/src/pages/MyTabs.js import React from &#39;react&#39;; import { Tabs } from &#39;antd&#39;; // 第一步，导入需要使用的组件 const TabPane = Tabs.TabPane; function callback(key) { console.log(key); } class MyTabs extends React.Component{ render(){ return ( &lt;Tabs defaultActiveKey=&quot;1&quot; onChange={callback}&gt; &lt;TabPane tab=&quot;Tab 1&quot; key=&quot;1&quot;&gt;hello antd wo de 第一个 tabs&lt;/TabPane&gt; &lt;TabPane tab=&quot;Tab 2&quot; key=&quot;2&quot;&gt;Content of Tab Pane 2&lt;/TabPane&gt; &lt;TabPane tab=&quot;Tab 3&quot; key=&quot;3&quot;&gt;Content of Tab Pane 3&lt;/TabPane&gt; &lt;/Tabs&gt; ) } } export default MyTabs;react/src/pages/user/UserList.js import React from &#39;react&#39;; import { connect } from &#39;dva&#39;; import {Table, Divider, Tag, Pagination } from &#39;antd&#39;; const {Column} = Table; const namespace = &#39;userList&#39;; @connect((state)=&gt;{ return { data : state[namespace].list } }, (dispatch) =&gt; { return { initData : () =&gt; { dispatch({ type: namespace + &quot;/initData&quot; }); } } }) class UserList extends React.Component { componentDidMount(){ this.props.initData(); } render() { return ( &lt;div&gt; &lt;Table dataSource={this.props.data} pagination={{position:"bottom",total:500,pageSize:10, defaultCurrent:3}}&gt; &lt;Column title=&quot;姓名&quot; dataIndex=&quot;name&quot; key=&quot;name&quot; /&gt; &lt;Column title=&quot;年龄&quot; dataIndex=&quot;age&quot; key=&quot;age&quot; /&gt; &lt;Column title=&quot;地址&quot; dataIndex=&quot;address&quot; key=&quot;address&quot; /&gt; &lt;Column title=&quot;标签&quot; dataIndex=&quot;tags&quot; key=&quot;tags&quot; render={tags =&gt; ( &lt;span&gt; {tags.map(tag =&gt; &lt;Tag color=&quot;blue&quot; key={tag}&gt;{tag}&lt;/Tag&gt;)} &lt;/span&gt; )} /&gt; &lt;Column title=&quot;操作&quot; key=&quot;action&quot; render={(text, record) =&gt; ( &lt;span&gt; &lt;a href=&quot;javascript:;&quot;&gt;编辑&lt;/a&gt; &lt;Divider type=&quot;vertical&quot;/&gt; &lt;a href=&quot;javascript:;&quot;&gt;删除&lt;/a&gt; &lt;/span&gt; )} /&gt; &lt;/Table&gt; &lt;/div&gt; ); } } export default UserList; react/src/pages/user/UserAdd.js import React from &#39;react&#39; class UserAdd extends React.Component{ render(){ return ( &lt;div&gt;新增用户&lt;/div&gt; ); } } export default UserAdd; react/src/pages/index.js import React from &#39;react&#39; class Index extends React.Component { render(){ return &lt;div&gt;首页&lt;/div&gt; } } export default Index; // http://localhost:8000/Ant Design Pro 入门https://github.com/ant-design/ant-design-pro├── config # umi 配置，包含路由，构建等配置├── mock # 本地模拟数据├── public│ └── favicon.png # Favicon├── src│ ├── assets # 本地静态资源│ ├── components # 业务通用组件│ ├── e2e # 集成测试用例│ ├── layouts # 通用布局│ ├── models # 全局 dva model│ ├── pages # 业务页面入口和常用模板│ ├── services # 后台接口服务│ ├── utils # 工具库│ ├── locales # 国际化资源│ ├── global.less # 全局样式│ └── global.js # 全局 JS├── tests # 测试工具├── README.md└── package.json tyarn install #安装相关依赖 tyarn start #启动服务 http://localhost:8000/dashboard/analysis 测试新增路由config/router.config.js 默认配置两套路由 { path: &#39;/new&#39;, name: &#39;new&#39;, icon: &#39;user&#39;, routes: [ { path: &#39;/new/analysis&#39;, name: &#39;analysis&#39;, component: &#39;./New/NewAnalysis&#39;, }, { path: &#39;/new/monitor&#39;, name: &#39;monitor&#39;, component: &#39;./Dashboard/Monitor&#39;, }, { path: &#39;/new/workplace&#39;, name: &#39;workplace&#39;, component: &#39;./Dashboard/Workplace&#39;, }, ], }, src/pages/New/NewAnalysis.js import React from &#39;react&#39; class NewAnalysis extends React.Component { render() { return (&lt;div&gt;NewAnalysis&lt;/div&gt;); } } export default NewAnalysis; src/locales/zh-CN.js &#39;menu.new&#39;: &#39;New Dashboard&#39;, &#39;menu.new.analysis&#39;: &#39;New 分析页&#39;, &#39;menu.new.monitor&#39;: &#39;New 监控页&#39;, &#39;menu.new.workplace&#39;: &#39;New 工作台&#39;, model执行流程http://localhost:8000/list/table-listsrc/pages/List/TableList.js Table组件生成表格，数据源是data &lt;StandardTable selectedRows={selectedRows} loading={loading} data={data} columns={this.columns} onSelectRow={this.handleSelectRows} onChange={this.handleStandardTableChange} /&gt; data数据从构造方法的props中获取 const { rule: { data }, loading, } = this.props; rule数据由@connect装饰器获取，{ rule, loading }是解构表达式，props从connect中获取数据 @connect(({ rule, loading }) =&gt; ({ rule, loading: loading.models.rule, })) src/pages/List/models/rule.js 生成数据rule reducers: { save(state, action) { return { ...state, data: action.payload, }; }, src/pages/List/TableList.js 组件加载完成后加载数据 componentDidMount() { const { dispatch } = this.props; dispatch({ type: &#39;rule/fetch&#39;, }); } src/pages/List/models/rule.js 从rule.js中reducers加载save方法数据 *fetch({ payload }, { call, put }) { const response = yield call(queryRule, payload); yield put({ type: &#39;save&#39;, payload: response, }); }, queryRule是在/services/api中进行了定义 export async function queryRule(params) { return request(`/api/rule?${stringify(params)}`); } 数据的mock在mock/rule.js中完成 export default { &#39;GET /api/rule&#39;: getRule, &#39;POST /api/rule&#39;: postRule, }; git commit -m “ant-design-pro 下载” –no-verify]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>react</tag>
        <tag>ant design</tag>
        <tag>ant design pro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好客租房es6语法]]></title>
    <url>%2F2019%2F08%2F21%2F%E5%A5%BD%E5%AE%A2%E7%A7%9F%E6%88%BFes6%2F</url>
    <content type="text"><![CDATA[基于dubbo react elk实战整合开发 基础语法&lt;!DOCTYPE html&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script&gt; // var 定义全局变量 for (var i = 0; i &lt; 5; i++) { console.log(i); } console.log(&quot;循环外：&quot; + i); // let 控制变量作用域 for (let j = 0; j &lt; 5; j++) { console.log(j); } console.log(&quot;循环外：&quot; + j); // const声明常量 不可修改 const a = 1; console.log(&quot;a=&quot;, a); a = 2; console.log(&quot;a=&quot;, a) // 字符串拓展函数 console.log(&quot;hello world&quot;.includes(&quot;hello&quot;)); console.log(&quot;hello world&quot;.startsWith(&quot;hello&quot;)); console.log(&quot;hello world&quot;.endsWith(&quot;world&quot;)); // 字符串模板保留换行源格式 let str = ` hello world `; console.log(str); // 新定义数组解构获取顺序获取值 let arr = [1, 2, 3] const [x, y, z] = arr; console.log(x, y, z) const [m] = arr; console.log(m) // 新定义对象结构顺序获取属性值 const person = { name: &#39;wj&#39;, age: 21, language: [&#39;java&#39;, &#39;js&#39;, &#39;php&#39;] } const {name, age, language} = person console.log(name, age, language) const {name: n, age: a, language: l} = person; console.log(n) // 函数默认值 function add(a, b = 1) { // b = b || 1; return a + b; } console.log(add(10)) // 箭头函数 var print = obj =&gt; (console.log(obj)) //一个参数 var sum = (a, b) =&gt; a + b // 多个参数 var sayHello1 = () =&gt; console.log(&quot;hello&quot;) // 没有参数 var sayHello2 = (a, b) =&gt; { // 多个函数 console.log(&quot;hello&quot;) console.log(&quot;world&quot;) return a + b; } // 对象函数属性简写 let persons = { name: &quot;jack&quot;, eat: food =&gt; console.log(persons.name + &quot;再吃&quot; + food), // 这里拿不到this eat1(food) { console.log(this.name + &quot;再吃&quot; + food) }, eat2(food) { console.log(this.name + &quot;再吃&quot; + food) } }; persons.eat(&quot;西瓜&quot;) // 箭头函数结合解构表达式 var hi = ({name}) =&gt; console.log(&quot;hello,&quot; + name) hi(persons) // map reduce let array = [&#39;1&#39;, &#39;2&#39;].map(s =&gt; parseInt(s)); //将原数组所有元素用函数处理哇年后放入新数组返回 let array1 = arr.map(function (s) { return parseInt(s); }) console.log(array) let num = [1, 20, 6, 5]; console.log(num.reduce((a, b) =&gt; a + b)) // 从左到友依次用reduce处理，并把结果作为下次reduce的第一个参数 let result = arr.reduce((a, b) =&gt; { return a + b; }, 1); //接受函数必须，初始值可选 // 扩展运算符 console.log(...[2, 3], ...[1, 20, 6, 5], 0) // 数组合并 let add1 = (x, y) =&gt; x + y; console.log(add1(...[1, 2])) const [f, ...l] = [1, 2, 3, 4, 5] //结合结构表达式 console.log(f, l) console.log(...&#39;heool&#39;) //字符串转数组 // promise 异步执行 const p = new Promise((resolve, reject) =&gt; { setTimeout(() =&gt; { const num = Math.random(); // 随机返回成功或失败 if (num &lt; 0.5) { resolve(&quot;成功 num=&quot; + num) } else { reject(&quot;失败 num=&quot; + num) } }, 300) }) p.then(function (msg) { console.log(msg) }).catch(function (msg) { console.log(msg) }) // set map let set = new Set() set.add(1) // clear delete has forEach(function(){}) size set.forEach(value =&gt; console.log(value)) let set2 = new Set([1, 2, 2, 1, 1]) // map为&lt;object,object&gt; const map = new Map([ [&#39;key1&#39;, &#39;value1&#39;], [&#39;value2&#39;, &#39;value2&#39;] ]) const set3 = new Set([ [&#39;t&#39;, &#39;t&#39;], [&#39;h&#39;, &#39;h&#39;] ]) const map2 = new Map(set3) const map3 = new Map(map) map.set(&#39;z&#39;, &#39;z&#39;) // clear delete(key) has(key) forEach(function(value,key){}) size values keys entries for (let key of map.keys()) { console.log(key) } console.log(...map.values()) // 类的基本用法 class User { constructor(name, age = 20) { this.name = name; this.age = age; } sayHi() { return &quot;hi&quot; } static isAdult(age) { if (age &gt;= 18) { return &quot;成年人&quot; } return &quot;未成年人&quot; } } class zhangsan extends User { // 类的继承 constructor() { super(&quot;张三&quot;, 10) this.address = &quot;上海&quot; } test(){ return &quot;name=&quot;+this.name; } } let user = new User(&quot;张三&quot;) let zs = new zhangsan() console.log(user) console.log(user.sayHi()) console.log(User.isAdult(20)) console.log(zs.name, zs.address) console.log(zs.sayHi()) // Generator函数 function* hello() { yield &quot;h&quot; yield &quot;e&quot; return &quot;a&quot; } let h = hello(); for (let obj of h) { //循环遍历或next遍历 console.log(&quot;===&quot; + obj) } console.log(h.next()) console.log(h.next()) console.log(h.next()) // 修饰器 修改类的行为 @T class Animal { constructor(name,age=20){ this.name=name; this.age=age; } } function T(target){ console.log(target); target.contry = &quot;china&quot; //通过修饰器添加的属性是静态属性 } console.log(Animal.contry) // 无法运行，需要转码：将ES6活ES2017转为ES5使用（将箭头函数转为普通函数） &lt;/script&gt; &lt;/html&gt;umi转码 node -v v8.12.0 npm i yarn tyarn -g tyarn使用淘宝源 tyarn -v 1.16.0 若报错通过yarn global bin获取路径加入Path tyarn global add umi umi tyarn init -y 多一个package.json umi g page index 生成page文件夹 编辑index.js index.js // 修饰器 function T(target) { console.log(target); target.country=&quot;中国&quot; } @T class People{ constructor(name,age=20){ this.name=name; this.age=age; } } console.log(People.country); import Util from &#39;./Util&#39;; console.log(Util.sum(10, 5)); Util.js class Util { static sum = (a,b) =&gt; { return a + b; } } export default Util; umi dev,通过http://localhost:8000/ 查看控制台 reactjs tyarn init -y tyarn add umi –dev tyarn add umi-plugin-react –dev umi jsxreact/config/config.js export default {}; react/src/pages/HelloWorld.js export default ()=&gt;{ const t=()=&gt;&quot;pig&quot; return ( &lt;div&gt;hello world {t()}&lt;/div&gt; ); } umi build 转码生成文件 dist\umi.jsumi dev 访问http://localhost:8000 todolistreact/src/pages/HelloWorld.js import React from &#39;react&#39; class HelloWorld extends React.Component{ render() { // this.props.name接受属性，this.props.children接受标签内容 return &lt;div&gt;hello name={this.props.name},say={this.props.children}&lt;/div&gt; } } export default HelloWorld; react/src/pages/Show.js import React from &#39;react&#39; import HelloWorld from &#39;./HelloWorld&#39; class Show extends React.Component{ render() { return &lt;HelloWorld name=&quot;zhansan&quot;&gt;haha&lt;/HelloWorld&gt; } } export default Show; react/src/pages/List.js import React from &#39;react&#39;; class List extends React.Component{ constructor(props){ super(props); this.state = { dataList : [1,2,3], maxNum : 3 }; } /*this.state值在构造参数中完成，要修改this.state的值，需要调用this.setState()完成*/ render(){ return ( &lt;div&gt; &lt;ul&gt; { this.state.dataList.map((value,index)=&gt;{ return &lt;li key={index}&gt;{value}&lt;/li&gt; }) } &lt;/ul&gt; &lt;button onClick={() =&gt; { let maxNum = this.state.maxNum + 1; let list = [...this.state.dataList,maxNum]; this.setState({ dataList: list, maxNum: maxNum }); }}&gt;点我&lt;/button&gt; &lt;/div&gt; ); } } export default List; LifeCycleimport React from &#39;react&#39;; //第一步，导入React class LifeCycle extends React.Component { constructor(props) { super(props); //构造方法 console.log(&quot;constructor()&quot;); } componentDidMount() { //组件挂载后调用 console.log(&quot;componentDidMount()&quot;); } componentWillUnmount() { //在组件从 DOM 中移除之前立刻被调用。 console.log(&quot;componentWillUnmount()&quot;); } componentDidUpdate() { //在组件完成更新后立即调用。在初始化时不会被调用。 console.log(&quot;componentDidUpdate()&quot;); } shouldComponentUpdate(nextProps, nextState){ // 每当this.props或this.state有变化，在render方法执行之前，就会调用这个方法。 // 该方法返回一个布尔值，表示是否应该继续执行render方法，即如果返回false，UI 就不会更新，默认返回true。 // 组件挂载时，render方法的第一次执行，不会调用这个方法。 console.log(&quot;shouldComponentUpdate()&quot;); } render() { return ( &lt;div&gt; &lt;h1&gt;React Life Cycle!&lt;/h1&gt; &lt;/div&gt; ); } } export default LifeCycle;]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>react</tag>
        <tag>umi</tag>
        <tag>es6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alibaba网关服务]]></title>
    <url>%2F2019%2F08%2F21%2FAlibaba%E7%BD%91%E5%85%B3%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[基于spring cloud alibaba实战整合开发 ht-micro-record-service-gateway&lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../ht-micro-record-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-service-gateway&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ht-micro-record-service-gateway&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.code.findbugs&lt;/groupId&gt; &lt;artifactId&gt;jsr305&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Commons Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Commons Begin --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- docker的maven插件，官网 https://github.com/spotify/docker-maven-plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;192.168.2.7:5000/${project.artifactId}:${project.version}&lt;/imageName&gt; &lt;baseImage&gt;onejane-jdk1.8 &lt;/baseImage&gt; &lt;entryPoint&gt;[&quot;java&quot;, &quot;-jar&quot;,&quot;/${project.build.finalName}.jar&quot;]&lt;/entryPoint&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;dockerHost&gt;http://192.168.2.7:2375&lt;/dockerHost&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.ht.micro.record.service.gateway.GatewayServiceApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; bootstrap.properties spring.application.name=ht-micro-record-service-gateway-config spring.main.allow-bean-definition-overriding=true spring.cloud.nacos.config.file-extension=yaml spring.cloud.nacos.config.server-addr=192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 nacos配置 spring: application: name: ht-micro-record-service-gateway jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8 default-property-inclusion: non_null cloud: nacos: discovery: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 sentinel: transport: port: 8721 dashboard: 192.168.2.7:190 gateway: discovery: locator: enabled: true routes: http://localhost:9000/api/user/user/20 访问user服务 - id: HT-MICRO-RECORD-SERVICE-USER uri: lb://ht-micro-record-service-user predicates: - Path=/api/user/** filters: - StripPrefix=2 server: port: 9000 feign: sentinel: enabled: true management: endpoints: web: exposure: include: &quot;*&quot; logging: level: org.springframework.cloud.gateway: debug GatewayServiceApplication.java @SpringBootApplication @EnableDiscoveryClient @EnableFeignClients public class GatewayServiceApplication { // ----------------------------- 解决跨域 Begin ----------------------------- private static final String ALL = &quot;*&quot;; private static final String MAX_AGE = &quot;18000L&quot;; @Bean public RouteDefinitionLocator discoveryClientRouteDefinitionLocator(DiscoveryClient discoveryClient, DiscoveryLocatorProperties properties) { return new DiscoveryClientRouteDefinitionLocator(discoveryClient, properties); } @Bean public ServerCodecConfigurer serverCodecConfigurer() { return new DefaultServerCodecConfigurer(); } @Bean public WebFilter corsFilter() { return (ServerWebExchange ctx, WebFilterChain chain) -&gt; { ServerHttpRequest request = ctx.getRequest(); if (!CorsUtils.isCorsRequest(request)) { return chain.filter(ctx); } HttpHeaders requestHeaders = request.getHeaders(); ServerHttpResponse response = ctx.getResponse(); HttpMethod requestMethod = requestHeaders.getAccessControlRequestMethod(); HttpHeaders headers = response.getHeaders(); headers.add(HttpHeaders.ACCESS_CONTROL_ALLOW_ORIGIN, requestHeaders.getOrigin()); headers.addAll(HttpHeaders.ACCESS_CONTROL_ALLOW_HEADERS, requestHeaders.getAccessControlRequestHeaders()); if (requestMethod != null) { headers.add(HttpHeaders.ACCESS_CONTROL_ALLOW_METHODS, requestMethod.name()); } headers.add(HttpHeaders.ACCESS_CONTROL_ALLOW_CREDENTIALS, &quot;true&quot;); headers.add(HttpHeaders.ACCESS_CONTROL_EXPOSE_HEADERS, ALL); headers.add(HttpHeaders.ACCESS_CONTROL_MAX_AGE, MAX_AGE); if (request.getMethod() == HttpMethod.OPTIONS) { response.setStatusCode(HttpStatus.OK); return Mono.empty(); } return chain.filter(ctx); }; } // ----------------------------- 解决跨域 End ----------------------------- public static void main(String[] args) { SpringApplication.run(GatewayServiceApplication.class, args); } }]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>spring cloud alibaba</tag>
        <tag>gateway</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alibaba分布式session]]></title>
    <url>%2F2019%2F08%2F21%2FAlibaba%E5%88%86%E5%B8%83%E5%BC%8Fsession%2F</url>
    <content type="text"><![CDATA[基于spring cloud alibaba实战整合开发 com.ht.micro.record.commons.domain.User @Data public class User implements Serializable { private long userId; private String username; private String password; } ht-micro-record-service-smspom.xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt;SmsServiceApplication.java @EnableRedisHttpSession(maxInactiveIntervalInSeconds= 1800) //开启redis session支持,并配置session过期时间UserController.java @Controller @RequestMapping(value = &quot;user&quot;) public class UserController extends AbstractBaseController&lt;TbUser&gt; { @RequestMapping public String index() { return &quot;index&quot;; } @RequestMapping(&quot;home&quot;) public String home() { return &quot;home&quot;; } @PostMapping(&quot;login&quot;) public String login(User user, HttpSession session) { // 随机生成用户id user.setUserId(Math.round(Math.floor(Math.random() * 10 * 1000))); // 将用户信息保存到id中 session.setAttribute(&quot;USER&quot;, user); return &quot;home&quot;; } @PostMapping(&quot;logout&quot;) public String logout(HttpSession session) { session.removeAttribute(&quot;USER&quot;); session.invalidate(); return &quot;home&quot;; } }templates/home.ftl &lt;!doctype html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;title&gt;主页面&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h5&gt;登录用户: ${Session[&quot;USER&quot;].username} &lt;/h5&gt; &lt;h5&gt;用户编号: ${Session[&quot;USER&quot;].userId} &lt;/h5&gt; &lt;/body&gt; &lt;/html&gt;templates/index.ftl &lt;!doctype html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;title&gt;登录页面&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=&quot;/user/login&quot; method=&quot;post&quot;&gt; 用户：&lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;br/&gt; 密码：&lt;input type=&quot;password&quot; name=&quot;password&quot;&gt;&lt;br/&gt; &lt;button type=&quot;submit&quot;&gt;登录&lt;/button&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt;ht-micro-record-service-user pom.xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; application.yml所有模块加入redis配置 redis: #host: 127.0.0.1 #port: 6379 jedis: pool: # 连接池最大连接数,使用负值表示无限制。 max-active: 8 # 连接池最大阻塞等待时间,使用负值表示无限制。 max-wait: -1s # 连接池最大空闲数,使用负值表示无限制。 max-idle: 8 # 连接池最小空闲连接，只有设置为正值时候才有效 min-idle: 1 timeout: 300ms session: # session 存储方式 支持redis、mongo、jdbc、hazelcast store-type: redis cluster: nodes: 192.168.2.5:8001,192.168.2.5:8002,192.168.2.5:8003,192.168.2.7:8004,192.168.2.7:8005,192.168.2.7:8006 # 如果是集群节点 采用如下配置指定节点 #spring.redis.cluster.nodes templates/index.ftl &lt;!doctype html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;title&gt;登录页面&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=&quot;/user/login&quot; method=&quot;post&quot;&gt; 用户：&lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;br/&gt; 密码：&lt;input type=&quot;password&quot; name=&quot;password&quot;&gt;&lt;br/&gt; &lt;button type=&quot;submit&quot;&gt;登录&lt;/button&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; templates/home.ftl &lt;!doctype html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;title&gt;主页面&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h5&gt;登录用户: ${Session[&quot;USER&quot;].username} &lt;/h5&gt; &lt;h5&gt;用户编号: ${Session[&quot;USER&quot;].userId} &lt;/h5&gt; &lt;/body&gt; &lt;/html&gt;UserServiceApplication.java @EnableRedisHttpSession(maxInactiveIntervalInSeconds= 1800) //开启redis session支持,并配置session过期时间 UserController.java @Controller @RequestMapping(value = &quot;user&quot;) public class UserController extends AbstractBaseController&lt;TbUser&gt; { @Autowired private TbUserService tbUserService; @Autowired private UserService userService; @RequestMapping public String index() { return &quot;index&quot;; } @RequestMapping(&quot;home&quot;) public String home() { return &quot;home&quot;; } @PostMapping(&quot;login&quot;) public String login(User user, HttpSession session) { // 随机生成用户id user.setUserId(Math.round(Math.floor(Math.random() * 10 * 1000))); // 将用户信息保存到id中 session.setAttribute(&quot;USER&quot;, user); return &quot;home&quot;; } @PostMapping(&quot;logout&quot;) public String logout(HttpSession session) { session.removeAttribute(&quot;USER&quot;); session.invalidate(); return &quot;home&quot;; } } http://localhost:9507/user 登陆后，进入http://localhost:9507/user/login 页面查看用户信息手动进入http://localhost:9506/user/home 查看相同用户信息，User实体位置在两个服务中保持一致。如果项目中有es配置，需要es优先配置Netty @PostConstruct public void init() { /*由于netty的冲突，需要在ElasticConfig中显示指定早于RedisConfig装配，并且指定初始化时再一次添加忽略es中netty的一些配置*/ System.setProperty(&quot;es.set.netty.runtime.available.processors&quot;, &quot;false&quot;); bulkRequest = elasticClientSingleton.getBulkRequest(esConfig); }]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>session</tag>
        <tag>redis</tag>
        <tag>freemarker</tag>
        <tag>spring cloud alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alibaba整合xxl-job]]></title>
    <url>%2F2019%2F08%2F21%2FAlibaba%E5%AE%9A%E6%97%B6%E5%99%A8%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[基于spring cloud alibaba实战整合开发 ht-micro-record-service-job &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../ht-micro-record-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-service-job&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ht-micro-record-service-job&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuxueli&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.code.findbugs&lt;/groupId&gt; &lt;artifactId&gt;jsr305&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Projects Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-commons-service&lt;/artifactId&gt; &lt;version&gt;${project.parent.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Projects End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;ht.micro.record.service.job.JobServiceApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; bootstrap.properties spring.application.name=ht-micro-record-service-xxl-job-config spring.cloud.nacos.config.file-extension=yaml spring.cloud.nacos.config.server-addr=192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 application.yaml spring: datasource: druid: url: jdbc:mysql://192.168.2.7:185/ht_micro_record?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 initial-size: 1 min-idle: 1 max-active: 20 test-on-borrow: true driver-class-name: com.mysql.jdbc.Driver cloud: nacos: discovery: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 config: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 server: port: 9701 xxl: job: executor: logpath: logs/xxl-job/jobhandler appname: xxl-job-executor port: 1234 logretentiondays: -1 ip: 192.168.3.233 admin: addresses: http://192.168.2.7:183/xxl-job-admin accessToken:nacos配置 spring: application: name: ht-micro-record-service-xxl-job cloud: nacos: discovery: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 sentinel: transport: port: 8719 dashboard: 192.168.2.7:190 server: port: 9701 management: endpoints: web: exposure: include: &quot;*&quot; com/ht/micro/record/service/job/JobServiceApplication.java @SpringBootApplication(scanBasePackages = &quot;com.ht.micro.record&quot;) @EnableDiscoveryClient @MapperScan(basePackages = &quot;com.ht.micro.record.commons.mapper&quot;) public class JobServiceApplication { public static void main(String[] args) { SpringApplication.run(JobServiceApplication.class, args); } } com/ht/micro/record/service/job/config/XxlJobConfig.java @Configuration @ComponentScan(basePackages = &quot;com.ht.micro.record.service.job.handler&quot;) public class XxlJobConfig { private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class); @Value(&quot;${xxl.job.admin.addresses}&quot;) private String adminAddresses; @Value(&quot;${xxl.job.executor.appname}&quot;) private String appName; @Value(&quot;${xxl.job.executor.ip}&quot;) private String ip; @Value(&quot;${xxl.job.executor.port}&quot;) private int port; @Value(&quot;${xxl.job.accessToken}&quot;) private String accessToken; @Value(&quot;${xxl.job.executor.logpath}&quot;) private String logPath; @Value(&quot;${xxl.job.executor.logretentiondays}&quot;) private int logRetentionDays; @Bean(initMethod = &quot;start&quot;, destroyMethod = &quot;destroy&quot;) public XxlJobSpringExecutor xxlJobExecutor() { logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init.&quot;); XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor(); xxlJobSpringExecutor.setAdminAddresses(adminAddresses); xxlJobSpringExecutor.setAppName(appName); xxlJobSpringExecutor.setIp(ip); xxlJobSpringExecutor.setPort(port); xxlJobSpringExecutor.setAccessToken(accessToken); xxlJobSpringExecutor.setLogPath(logPath); xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays); return xxlJobSpringExecutor; } } com/ht/micro/record/service/job/handler/TestJobHandler.java @JobHandler(value=&quot;testJobHandler&quot;) @Component public class TestJobHandler extends IJobHandler { @Override public ReturnT&lt;String&gt; execute(String param) throws Exception { XxlJobLogger.log(&quot;XXL-JOB, Hello World.&quot;); for (int i = 0; i &lt; 5; i++) { XxlJobLogger.log(&quot;beat at:&quot; + i); TimeUnit.SECONDS.sleep(2); } return SUCCESS; } } http://192.168.2.7:183/xxl-job-admin]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>spring cloud alibaba</tag>
        <tag>xxl-job</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alibaba服务间调用的多种方式]]></title>
    <url>%2F2019%2F08%2F21%2FAlibaba%E6%9C%8D%E5%8A%A1%E9%97%B4%E8%B0%83%E7%94%A8%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[基于spring cloud alibaba实战整合开发 @[TOC] ht-micro-record-service-dubbopom.xml &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;modules&gt; &lt;module&gt;ht-micro-record-service-dubbo-provider&lt;/module&gt; &lt;module&gt;ht-micro-record-service-dubbo-consumer&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../ht-micro-record-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-service-dubbo&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;ht-micro-record-service-dubbo&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; ht-micro-record-service-dubbo-apipom.xml &lt;parent&gt; &lt;artifactId&gt;ht-micro-record-service-dubbo&lt;/artifactId&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;artifactId&gt;ht-micro-record-service-dubbo-api&lt;/artifactId&gt; PortApi.java public interface PortApi { String showPort(); } ht-micro-record-service-dubbo-providerpom.xml &lt;parent&gt; &lt;artifactId&gt;ht-micro-record-service-dubbo&lt;/artifactId&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;ht-micro-record-service-dubbo-provider&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-service-dubbo-api&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--elasticsearch--&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.java.dev.jna&lt;/groupId&gt; &lt;artifactId&gt;jna&lt;/artifactId&gt; &lt;!-- &lt;version&gt;3.0.9&lt;/version&gt; --&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.ht.micro.record.service.dubbo.provider.DubboProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; logback.xml &lt;configuration&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符 --&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径 --&gt; &lt;property name=&quot;LOG_HOME&quot; value=&quot;E:/log&quot; /&gt; &lt;!-- 按照每天生成日志文件 --&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!--日志文件输出的文件名 --&gt; &lt;FileNamePattern&gt;${LOG_HOME}/log.%d{yyyy-MM-dd}.log&lt;/FileNamePattern&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/layout&gt; &lt;!--日志文件最大的大小 --&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt; &lt;!--mybatis 日志配置--&gt; &lt;logger name=&quot;com.mapper&quot; level=&quot;DEBUG&quot; /&gt; &lt;/configuration&gt; bootstrap.yml spring: application: name: ht-micro-record-service-dubbo-provider cloud: nacos: config: file-extension: yaml server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 main: allow-bean-definition-overriding: true dubbo: scan: base-packages: com.ht.micro.record.service.dubbo.provider.dubbo protocol: name: dubbo port: -1 registry: address: spring-cloud://192.168.2.7:8848?backup=192.168.2.7:8849,192.168.2.7:8850 es: nodes: 192.168.2.5:1800,192.168.2.7:1800 host: 192.168.2.5,192.168.2.7 port: 1801,1801 types: doc clusterName: elasticsearch-cluster #笔录分析库 blDbName: t_record_analyze #接警信息库 jjDbName: p_answer_alarm #处警信息库 cjDbName: p_handle_alarm #警情分析结果信息库 jqfxDbName: t_alarm_analysis_result #标准化分析 cjjxqDbName: t_cjjxq #接处警整合库 jcjDbName: p_answer_handle_alarm #警情分析 daDbName: t_data_analysis #警情结果表(neo4j使用) neo4jData: t_neo4j_data #市局接处警表 cityDbName: city_answer_handle_alarm nacos配置ht-micro-record-service-dubbo-provider.yaml spring: application: name: ht-micro-record-service-dubbo-provider cloud: nacos: discovery: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 sentinel: transport: port: 8719 dashboard: 192.168.2.7:190 server: port: 9502com.ht.micro.record.service.dubbo.provider.DubboProviderApplication @SpringBootApplication @EnableDiscoveryClient public class DubboProviderApplication { public static void main(String[] args) { SpringApplication.run(DubboProviderApplication.class, args); } } com.ht.micro.record.service.dubbo.provider.utils.ElasticClient @Service public class ElasticClient { @Autowired private EsConfig esConfig; private static final Logger logger = LoggerFactory.getLogger(ElasticClient.class); private static BulkRequestBuilder bulkRequest; @Autowired private ElasticClientSingleton elasticClientSingleton; @PostConstruct public void init() { bulkRequest = elasticClientSingleton.getBulkRequest(esConfig); } /** * @param url * @param query * @return * @Description 发送请求 * @Author 裴健(peij@htdatacloud.com) * @Date 2016年6月13日 * @History * @his1 */ public static String postRequest(String url, String query) { RestTemplate restTemplate = new RestTemplate(); MediaType type = MediaType.parseMediaType(&quot;application/json; charset=UTF-8&quot;); HttpHeaders headers = new HttpHeaders(); headers.setContentType(type); headers.add(&quot;Accept&quot;, MediaType.APPLICATION_JSON.toString()); HttpEntity&lt;String&gt; formEntity = new HttpEntity&lt;String&gt;(query, headers); String result = restTemplate.postForObject(url, formEntity, String.class); return result; } /** * action 提交操作 */ // public void action() { // int reqSize = bulkRequest.numberOfActions(); // //读不到数据了，默认已经全部读取 // if (reqSize == 0) { // bulkRequest.request().requests().clear(); // } // bulkRequest.setTimeout(new TimeValue(1000 * 60 * 5)); //超时30秒 // BulkResponse bulkResponse = bulkRequest.execute().actionGet(); // //持久化异常 // if (bulkResponse.hasFailures()) { // logger.error(bulkResponse.buildFailureMessage()); // bulkRequest.request().requests().clear(); // } // logger.info(&quot;import over....&quot; + bulkResponse.getItems().length); // } }com.ht.micro.record.service.dubbo.provider.utils.ElasticClientSingleton @Service public class ElasticClientSingleton { protected final Logger logger = LoggerFactory.getLogger(ElasticClientSingleton.class); private AtomicInteger atomicPass = new AtomicInteger(); // 0 未初始化, 1 已初始化 private TransportClient transportClient; private BulkRequestBuilder bulkRequest; public synchronized void init(EsConfig esConfig) { try { String ipArray = esConfig.getHost(); String portArray = esConfig.getPort(); String cluster = esConfig.getClusterName(); Settings settings = Settings.builder() .put(&quot;cluster.name&quot;, cluster) //连接的集群名 .put(&quot;client.transport.ignore_cluster_name&quot;, true) .put(&quot;client.transport.sniff&quot;, false)//如果集群名不对，也能连接 .build(); transportClient = new PreBuiltTransportClient(settings); String[] ips = ipArray.split(&quot;,&quot;); String[] ports = portArray.split(&quot;,&quot;); for (int i = 0; i &lt; ips.length; i++) { transportClient.addTransportAddress(new TransportAddress(InetAddress.getByName(ips[i]), Integer .parseInt(ports[i]))); } atomicPass.set(1); } catch (Exception e) { e.printStackTrace(); logger.error(e.getMessage()); atomicPass.set(0); destroy(); } } public void destroy() { if (transportClient != null) { transportClient.close(); transportClient = null; } } public BulkRequestBuilder getBulkRequest(EsConfig esConfig) { if (atomicPass.get() == 0) { // 初始化 init(esConfig); } bulkRequest = transportClient.prepareBulk(); return bulkRequest; } public TransportClient getTransportClient(EsConfig esConfig) { if (atomicPass.get() == 0) { // 初始化 init(esConfig); } return transportClient; } }com.ht.micro.record.service.dubbo.provider.utils.EsConfig @Service public class EsConfig { @Value(&quot;${es.nodes}&quot;) private String nodes; @Value(&quot;${es.host}&quot;) private String host; @Value(&quot;${es.port}&quot;) private String port; @Value(&quot;${es.blDbName}&quot;) private String blDbName; @Value(&quot;${es.jjDbName}&quot;) private String jjDbName; @Value(&quot;${es.cjDbName}&quot;) private String cjDbName; @Value(&quot;${es.jqfxDbName}&quot;) private String jqfxDbName; @Value(&quot;${es.clusterName}&quot;) private String clusterName; @Value(&quot;${es.jjDbName}&quot;) private String answerDbName; @Value(&quot;${es.cjDbName}&quot;) private String handleDbName; @Value(&quot;${es.cjjxqDbName}&quot;) private String cjjxqDbName; @Value(&quot;${es.jcjDbName}&quot;) private String jcjDbName; @Value(&quot;${es.daDbName}&quot;) private String daDbName; @Value(&quot;${es.daDbName}&quot;) private String fxDbName; @Value(&quot;${es.types}&quot;) private String types; @Value(&quot;${es.neo4jData}&quot;) private String neo4jData; @Value(&quot;${es.cityDbName}&quot;) private String cityDbName; public String getCityDbName() { return cityDbName; } public String getTypes() { return types; } public String getFxDbName() { return fxDbName; } public String getDaDbName() { return daDbName; } public String getJcjDbName() { return jcjDbName; } public String getCjjxqDbName() { return cjjxqDbName; } public String getNodes() { return nodes; } public String getHost() { return host; } public String getPort() { return port; } public String getClusterName() { return clusterName; } public String getBlDbName() { return blDbName; } public String getJjDbName() { return jjDbName; } public String getCjDbName() { return cjDbName; } public String getJqfxDbName() { return jqfxDbName; } public String getNeo4jData() { return neo4jData; } } com.ht.micro.record.service.dubbo.provider.dubbo.PortApiImpl @Service public class PortApiImpl implements PortApi { @Value(&quot;${server.port}&quot;) private Integer port; @Override public String showPort() { return &quot;port= &quot;+ port; } }com.ht.micro.record.service.dubbo.provider.controller.ProviderController @RestController @RequestMapping(&quot;/provider&quot;) public class ProviderController { @Autowired private ConfigurableApplicationContext applicationContext; @Value(&quot;${server.port}&quot;) private Integer port; @GetMapping(&quot;/port&quot;) public Object port() { return &quot;port= &quot;+ port + &quot;, name=&quot; + applicationContext.getEnvironment().getProperty(&quot;user.name&quot;); } }ht-micro-record-service-dubbo-consumerpom.xml &lt;parent&gt; &lt;artifactId&gt;ht-micro-record-service-dubbo&lt;/artifactId&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;ht-micro-record-service-dubbo-consumer&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-service-dubbo-api&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.code.findbugs&lt;/groupId&gt; &lt;artifactId&gt;jsr305&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.ht.micro.record.service.dubbo.consumer.DubboConsumerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;bootstrap.yml spring: application: name: ht-micro-record-service-dubbo-consumer main: allow-bean-definition-overriding: true cloud: nacos: config: file-extension: yaml server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 # 与nacos兼容性不好，配置到项目中 dubbo: scan: base-packages: com.ht.micro.record.service.dubbo.consumer protocol: name: dubbo port: -1 registry: address: spring-cloud://192.168.2.7:8848?backup=192.168.2.7:8849,192.168.2.7:8850com.ht.micro.record.service.dubbo.consumer.DubboConsumerApplication @SpringBootApplication(scanBasePackages = &quot;com.ht.micro.record&quot;, exclude = {DataSourceAutoConfiguration.class}) @EnableFeignClients @EnableDiscoveryClient public class DubboConsumerApplication { public static void main(String[] args) { SpringApplication.run(DubboConsumerApplication.class, args); } } com.ht.micro.record.service.dubbo.consumer.service.PortService @FeignClient(value = &quot;ht-micro-record-service-dubbo-provider&quot;) public interface PortService { @GetMapping(value = &quot;/provider/port&quot;) String showPort(); }com.ht.micro.record.service.dubbo.consumer.controller.ConsumerController @RestController @RequestMapping(&quot;/consumer&quot;) public class ConsumerController { @Autowired private LoadBalancerClient loadBalancerClient; @Autowired private PortService portService; private RestTemplate restTemplate = new RestTemplate(); @Reference(check = false) private PortApi portApi; @GetMapping(&quot;/rest&quot;) public Object rest() { ServiceInstance serviceInstance = loadBalancerClient.choose(&quot;ht-micro-record-service-dubbo-provider&quot;); String url = String.format(&quot;http://%s:%s/provider/port&quot;, serviceInstance.getHost(), serviceInstance.getPort()); System.out.println(&quot;request url:&quot; + url); return restTemplate.getForObject(url, String.class); } @GetMapping(&quot;/rpc&quot;) public Object rpc() { return portApi.showPort(); } @GetMapping(&quot;/feign&quot;) public Object feign(){ return portService.showPort(); } }]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>spring cloud alibaba</tag>
        <tag>dubbo</tag>
        <tag>nacos</tag>
        <tag>feign</tag>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alibaba服务搭建]]></title>
    <url>%2F2019%2F08%2F21%2FAlibaba%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[基于spring cloud alibaba实战整合开发 基础服务通用类com.ht.micro.record.commonsdto.AbstractBaseDomain @Data public abstract class AbstractBaseDomain implements Serializable { /** * 该注解需要保留，用于 tk.mybatis 回显 ID */ @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; /** * 格式化日期，由于是北京时间（我们是在东八区），所以时区 +8 */ @JsonFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;, timezone = &quot;GMT+8&quot;) private Date created; @JsonFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;, timezone = &quot;GMT+8&quot;) private Date updated; } dto.AbstractBaseResult @Data public abstract class AbstractBaseResult implements Serializable { /** * 此为内部类,JsonInclude.Include.NON_NULL去掉返回值中为null的属性 */ @Data @JsonInclude(JsonInclude.Include.NON_NULL) protected static class Links { private String self; private String next; private String last; } @Data @JsonInclude(JsonInclude.Include.NON_NULL) protected static class DataBean&lt;T extends AbstractBaseDomain&gt; { private String type; private Long id; private T attributes; private T relationships; private Links links; } } dto.BaseResultFactory public class BaseResultFactory&lt;T extends AbstractBaseDomain&gt; { /** * 设置日志级别，用于限制发生错误时，是否显示调试信息(detail) * * @see ErrorResult#detail */ public static final String LOGGER_LEVEL_DEBUG = &quot;DEBUG&quot;; private static BaseResultFactory baseResultFactory; private BaseResultFactory() { } // 设置通用的响应 private static HttpServletResponse response; public static BaseResultFactory getInstance(HttpServletResponse response) { if (baseResultFactory == null) { synchronized (BaseResultFactory.class) { if (baseResultFactory == null) { baseResultFactory = new BaseResultFactory(); } } } BaseResultFactory.response = response; // 设置通用响应 baseResultFactory.initResponse(); return baseResultFactory; } public static BaseResultFactory getInstance() { if (baseResultFactory == null) { synchronized (BaseResultFactory.class) { if (baseResultFactory == null) { baseResultFactory = new BaseResultFactory(); } } } return baseResultFactory; } /** * 构建单笔数据结果集 * * @param self 当前请求路径 * @return */ public AbstractBaseResult build(String self, T attributes) { return new SuccessResult(self, attributes); } /** * 构建多笔数据结果集 * * @param self 当前请求路径 * @param next 下一页的页码 * @param last 最后一页的页码 * @return */ public AbstractBaseResult build(String self, int next, int last, List&lt;T&gt; attributes) { return new SuccessResult(self, next, last, attributes); } /** * 构建请求错误的响应结构，调试显示detail，上线不显示，通过配置日志级别 * * @param code HTTP 状态码 * @param title 错误信息 * @param detail 调试信息 * @param level 日志级别，只有 DEBUG 时才显示详情 * @return */ public AbstractBaseResult build(int code, String title, String detail, String level) { // 设置请求失败的响应码 response.setStatus(code); if (LOGGER_LEVEL_DEBUG.equals(level)) { return new ErrorResult(code, title, detail); } else { return new ErrorResult(code, title, null); } } /** * 初始化 HttpServletResponse */ private void initResponse() { // 需要符合 JSON API 规范 response.setHeader(&quot;Content-Type&quot;, &quot;application/vnd.api+json&quot;); } } dto.ErrorResult @Data @AllArgsConstructor @EqualsAndHashCode(callSuper = false) // JSON 不显示为 null 的属性 @JsonInclude(JsonInclude.Include.NON_NULL) public class ErrorResult extends AbstractBaseResult { private int code; private String title; /** * 调试信息 */ private String detail; } dto.SuccessResult @Data @EqualsAndHashCode(callSuper = false) public class SuccessResult&lt;T extends AbstractBaseDomain&gt; extends AbstractBaseResult { private Links links; private List&lt;DataBean&gt; data; /** * 请求的结果（单笔） * @param self 当前请求路径 * @param attributes 领域模型 */ public SuccessResult(String self, T attributes) { links = new Links(); links.setSelf(self); createDataBean(null, attributes); } /** * 请求的结果（分页） * @param self 当前请求路径 * @param next 下一页的页码 * @param last 最后一页的页码 * @param attributes 领域模型集合 */ public SuccessResult(String self, int next, int last, List&lt;T&gt; attributes) { links = new Links(); links.setSelf(self); links.setNext(self + &quot;?page=&quot; + next); links.setLast(self + &quot;?page=&quot; + last); attributes.forEach(attribute -&gt; createDataBean(self, attribute)); } /** * 创建 DataBean * @param self 当前请求路径 * @param attributes 领域模型 */ private void createDataBean(String self, T attributes) { if (data == null) { data = new ArrayList&lt;&gt;(); } DataBean dataBean = new DataBean(); dataBean.setId(attributes.getId()); dataBean.setType(attributes.getClass().getSimpleName()); dataBean.setAttributes(attributes); if (StringUtils.isNotBlank(self)) { Links links = new Links(); links.setSelf(self + &quot;/&quot; + attributes.getId()); dataBean.setLinks(links); } data.add(dataBean); } } utils.MapperUtils public class MapperUtils { private final static ObjectMapper objectMapper = new ObjectMapper(); public static ObjectMapper getInstance() { return objectMapper; } /** * 转换为 JSON 字符串 * * @param obj * @return * @throws Exception */ public static String obj2json(Object obj) throws Exception { return objectMapper.writeValueAsString(obj); } /** * 转换为 JSON 字符串，忽略空值 * * @param obj * @return * @throws Exception */ public static String obj2jsonIgnoreNull(Object obj) throws Exception { ObjectMapper mapper = new ObjectMapper(); mapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); return mapper.writeValueAsString(obj); } /** * 转换为 JavaBean * * @param jsonString * @param clazz * @return * @throws Exception */ public static &lt;T&gt; T json2pojo(String jsonString, Class&lt;T&gt; clazz) throws Exception { objectMapper.configure(DeserializationFeature.ACCEPT_SINGLE_VALUE_AS_ARRAY, true); return objectMapper.readValue(jsonString, clazz); } /** * 字符串转换为 Map&lt;String, Object&gt; * * @param jsonString * @return * @throws Exception */ public static &lt;T&gt; Map&lt;String, Object&gt; json2map(String jsonString) throws Exception { ObjectMapper mapper = new ObjectMapper(); mapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); return mapper.readValue(jsonString, Map.class); } /** * 字符串转换为 Map&lt;String, T&gt; */ public static &lt;T&gt; Map&lt;String, T&gt; json2map(String jsonString, Class&lt;T&gt; clazz) throws Exception { Map&lt;String, Map&lt;String, Object&gt;&gt; map = objectMapper.readValue(jsonString, new TypeReference&lt;Map&lt;String, T&gt;&gt;() { }); Map&lt;String, T&gt; result = new HashMap&lt;String, T&gt;(); for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : map.entrySet()) { result.put(entry.getKey(), map2pojo(entry.getValue(), clazz)); } return result; } /** * 深度转换 JSON 成 Map * * @param json * @return */ public static Map&lt;String, Object&gt; json2mapDeeply(String json) throws Exception { return json2MapRecursion(json, objectMapper); } /** * 把 JSON 解析成 List，如果 List 内部的元素存在 jsonString，继续解析 * * @param json * @param mapper 解析工具 * @return * @throws Exception */ private static List&lt;Object&gt; json2ListRecursion(String json, ObjectMapper mapper) throws Exception { if (json == null) { return null; } List&lt;Object&gt; list = mapper.readValue(json, List.class); for (Object obj : list) { if (obj != null &amp;&amp; obj instanceof String) { String str = (String) obj; if (str.startsWith(&quot;[&quot;)) { obj = json2ListRecursion(str, mapper); } else if (obj.toString().startsWith(&quot;{&quot;)) { obj = json2MapRecursion(str, mapper); } } } return list; } /** * 把 JSON 解析成 Map，如果 Map 内部的 Value 存在 jsonString，继续解析 * * @param json * @param mapper * @return * @throws Exception */ private static Map&lt;String, Object&gt; json2MapRecursion(String json, ObjectMapper mapper) throws Exception { if (json == null) { return null; } Map&lt;String, Object&gt; map = mapper.readValue(json, Map.class); for (Map.Entry&lt;String, Object&gt; entry : map.entrySet()) { Object obj = entry.getValue(); if (obj != null &amp;&amp; obj instanceof String) { String str = ((String) obj); if (str.startsWith(&quot;[&quot;)) { List&lt;?&gt; list = json2ListRecursion(str, mapper); map.put(entry.getKey(), list); } else if (str.startsWith(&quot;{&quot;)) { Map&lt;String, Object&gt; mapRecursion = json2MapRecursion(str, mapper); map.put(entry.getKey(), mapRecursion); } } } return map; } /** * 将 JSON 数组转换为集合 * * @param jsonArrayStr * @param clazz * @return * @throws Exception */ public static &lt;T&gt; List&lt;T&gt; json2list(String jsonArrayStr, Class&lt;T&gt; clazz) throws Exception { JavaType javaType = getCollectionType(ArrayList.class, clazz); List&lt;T&gt; list = (List&lt;T&gt;) objectMapper.readValue(jsonArrayStr, javaType); return list; } /** * 获取泛型的 Collection Type * * @param collectionClass 泛型的Collection * @param elementClasses 元素类 * @return JavaType Java类型 * @since 1.0 */ public static JavaType getCollectionType(Class&lt;?&gt; collectionClass, Class&lt;?&gt;... elementClasses) { return objectMapper.getTypeFactory().constructParametricType(collectionClass, elementClasses); } /** * 将 Map 转换为 JavaBean * * @param map * @param clazz * @return */ public static &lt;T&gt; T map2pojo(Map map, Class&lt;T&gt; clazz) { return objectMapper.convertValue(map, clazz); } /** * 将 Map 转换为 JSON * * @param map * @return */ public static String mapToJson(Map map) { try { return objectMapper.writeValueAsString(map); } catch (Exception e) { e.printStackTrace(); } return &quot;&quot;; } /** * 将 JSON 对象转换为 JavaBean * * @param obj * @param clazz * @return */ public static &lt;T&gt; T obj2pojo(Object obj, Class&lt;T&gt; clazz) { return objectMapper.convertValue(obj, clazz); } } utils.RegexpUtils public class RegexpUtils { /** * 验证手机号 */ public static final String PHONE = &quot;^((13[0-9])|(15[^4,\\D])|(18[0,5-9]))\\d{8}$&quot;; /** * 验证邮箱地址 */ public static final String EMAIL = &quot;\\w+(\\.\\w)*@\\w+(\\.\\w{2,3}){1,3}&quot;; /** * 验证手机号 * @param phone * @return */ public static boolean checkPhone(String phone) { return phone.matches(PHONE); } /** * 验证邮箱 * @param email * @return */ public static boolean checkEmail(String email) { return email.matches(EMAIL); } } web.AbstractBaseController public abstract class AbstractBaseController&lt;T extends AbstractBaseDomain&gt; { // 用于动态获取配置文件的属性值 private static final String ENVIRONMENT_LOGGING_LEVEL_MY_SHOP = &quot;logging.level.com.ht.micro.record&quot;; @Resource protected HttpServletRequest request; @Resource protected HttpServletResponse response; @Autowired private ConfigurableApplicationContext applicationContext; @ModelAttribute public void initReqAndRes(HttpServletRequest request, HttpServletResponse response) { this.request = request; this.response = response; } /** * 请求成功 * @param self * @param attribute * @return */ protected AbstractBaseResult success(String self, T attribute) { return BaseResultFactory.getInstance(response).build(self, attribute); } /** * 请求成功 * @param self * @param next * @param last * @param attributes * @return */ protected AbstractBaseResult success(String self, int next, int last, List&lt;T&gt; attributes) { return BaseResultFactory.getInstance(response).build(self, next, last, attributes); } /** * 请求失败 * @param title * @param detail * @return */ protected AbstractBaseResult error(String title, String detail) { return error(HttpStatus.UNAUTHORIZED.value(), title, detail); } /** * 请求失败 * @param code * @param title * @param detail * @return */ protected AbstractBaseResult error(int code, String title, String detail) { return BaseResultFactory.getInstance(response).build(code, title, detail, applicationContext.getEnvironment().getProperty(ENVIRONMENT_LOGGING_LEVEL_MY_SHOP)); } } ht-micro-record-commons-domaindomain.TbUser @Table(name = &quot;tb_user&quot;) @JsonInclude(JsonInclude.Include.NON_NULL) public class TbUser extends AbstractBaseDomain { /** * 用户名 */ @NotNull(message = &quot;用户名不可为空&quot;) @Length(min = 5, max = 20, message = &quot;用户名长度必须介于 5 和 20 之间&quot;) private String username; /** * 密码，加密存储 */ @JsonIgnore private String password; /** * 注册手机号 */ private String phone; /** * 注册邮箱 */ @NotNull(message = &quot;邮箱不可为空&quot;) @Pattern(regexp = RegexpUtils.EMAIL, message = &quot;邮箱格式不正确&quot;) private String email; /** * 获取用户名 * * @return username - 用户名 */ public String getUsername() { return username; } /** * 设置用户名 * * @param username 用户名 */ public void setUsername(String username) { this.username = username; } /** * 获取密码，加密存储 * * @return password - 密码，加密存储 */ public String getPassword() { return password; } /** * 设置密码，加密存储 * * @param password 密码，加密存储 */ public void setPassword(String password) { this.password = password; } /** * 获取注册手机号 * * @return phone - 注册手机号 */ public String getPhone() { return phone; } /** * 设置注册手机号 * * @param phone 注册手机号 */ public void setPhone(String phone) { this.phone = phone; } /** * 获取注册邮箱 * * @return email - 注册邮箱 */ public String getEmail() { return email; } /** * 设置注册邮箱 * * @param email 注册邮箱 */ public void setEmail(String email) { this.email = email; } } validator.BeanValidator @Component public class BeanValidator { @Autowired private Validator validatorInstance; private static Validator validator; // 系统启动时将静态对象注入容器，不可用Autowire直接注入 @PostConstruct public void init() { BeanValidator.validator = validatorInstance; } /** * 调用 JSR303 的 validate 方法, 验证失败时抛出 ConstraintViolationException. */ private static void validateWithException(Validator validator, Object object, Class&lt;?&gt;... groups) throws ConstraintViolationException { Set constraintViolations = validator.validate(object, groups); if (!constraintViolations.isEmpty()) { throw new ConstraintViolationException(constraintViolations); } } /** * 辅助方法, 转换 ConstraintViolationException 中的 Set&lt;ConstraintViolations&gt; 中为 List&lt;message&gt;. */ private static List&lt;String&gt; extractMessage(ConstraintViolationException e) { return extractMessage(e.getConstraintViolations()); } /** * 辅助方法, 转换 Set&lt;ConstraintViolation&gt; 为 List&lt;message&gt; */ private static List&lt;String&gt; extractMessage(Set&lt;? extends ConstraintViolation&gt; constraintViolations) { List&lt;String&gt; errorMessages = new ArrayList&lt;&gt;(); for (ConstraintViolation violation : constraintViolations) { errorMessages.add(violation.getMessage()); } return errorMessages; } /** * 辅助方法, 转换 ConstraintViolationException 中的 Set&lt;ConstraintViolations&gt; 为 Map&lt;property, message&gt;. */ private static Map&lt;String, String&gt; extractPropertyAndMessage(ConstraintViolationException e) { return extractPropertyAndMessage(e.getConstraintViolations()); } /** * 辅助方法, 转换 Set&lt;ConstraintViolation&gt; 为 Map&lt;property, message&gt;. */ private static Map&lt;String, String&gt; extractPropertyAndMessage(Set&lt;? extends ConstraintViolation&gt; constraintViolations) { Map&lt;String, String&gt; errorMessages = new HashMap&lt;&gt;(); for (ConstraintViolation violation : constraintViolations) { errorMessages.put(violation.getPropertyPath().toString(), violation.getMessage()); } return errorMessages; } /** * 辅助方法, 转换 ConstraintViolationException 中的 Set&lt;ConstraintViolations&gt; 为 List&lt;propertyPath message&gt;. */ private static List&lt;String&gt; extractPropertyAndMessageAsList(ConstraintViolationException e) { return extractPropertyAndMessageAsList(e.getConstraintViolations(), &quot; &quot;); } /** * 辅助方法, 转换 Set&lt;ConstraintViolations&gt; 为 List&lt;propertyPath message&gt;. */ private static List&lt;String&gt; extractPropertyAndMessageAsList(Set&lt;? extends ConstraintViolation&gt; constraintViolations) { return extractPropertyAndMessageAsList(constraintViolations, &quot; &quot;); } /** * 辅助方法, 转换 ConstraintViolationException 中的 Set&lt;ConstraintViolations&gt; 为 List&lt;propertyPath + separator + message&gt;. */ private static List&lt;String&gt; extractPropertyAndMessageAsList(ConstraintViolationException e, String separator) { return extractPropertyAndMessageAsList(e.getConstraintViolations(), separator); } /** * 辅助方法, 转换 Set&lt;ConstraintViolation&gt; 为 List&lt;propertyPath + separator + message&gt;. */ private static List&lt;String&gt; extractPropertyAndMessageAsList(Set&lt;? extends ConstraintViolation&gt; constraintViolations, String separator) { List&lt;String&gt; errorMessages = new ArrayList&lt;&gt;(); for (ConstraintViolation violation : constraintViolations) { errorMessages.add(violation.getPropertyPath() + separator + violation.getMessage()); } return errorMessages; } /** * 服务端参数有效性验证 * * @param object 验证的实体对象 * @param groups 验证组 * @return 验证成功：返回 null；验证失败：返回错误信息 */ public static String validator(Object object, Class&lt;?&gt;... groups) { try { validateWithException(validator, object, groups); } catch (ConstraintViolationException ex) { List&lt;String&gt; list = extractMessage(ex); list.add(0, &quot;数据验证失败：&quot;); // 封装错误消息为字符串 StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; list.size(); i++) { String exMsg = list.get(i); if (i != 0) { sb.append(String.format(&quot;%s. %s&quot;, i, exMsg)).append(list.size() &gt; 1 ? &quot;&lt;br/&gt;&quot; : &quot;&quot;); } else { sb.append(exMsg).append(list.size() &gt; 1 ? &quot;&lt;br/&gt;&quot; : &quot;&quot;); } } return sb.toString(); } return null; } } ht-micro-record-commons-mapper├─src│ └─main│ ├─java│ │ ├─com│ │ │ └─ht│ │ │ └─micro│ │ │ └─record│ │ │ └─commons│ │ │ └─mapper│ │ │ ├─baseMapper│ │ │ └─dicMapper│ │ └─tk│ │ └─mybatis│ │ └─mapper│ └─resources│ ├─baseMapper│ └─dicMappermapper分开存储用来识别多数据源tk.mybatis.mapper.MyMapper public interface MyMapper&lt;T&gt; extends Mapper&lt;T&gt;, MySqlMapper&lt;T&gt; { } ht-micro-record-commons-serviceBaseCrudService public interface BaseCrudService&lt;T extends AbstractBaseDomain&gt; { /** * 查询属性值是否唯一 * * @param property * @param value * @return true/唯一，false/不唯一 */ default boolean unique(String property, String value) { return false; } /** * 保存 * * @param domain * @return */ default T save(T domain) { return null; } /** * 分页查询 * @param domain * @param pageNum * @param pageSize * @return */ default PageInfo&lt;T&gt; page(T domain, int pageNum, int pageSize) { return null; } } impl.BaseCrudServiceImpl public class BaseCrudServiceImpl&lt;T extends AbstractBaseDomain, M extends MyMapper&lt;T&gt;&gt; implements BaseCrudService&lt;T&gt; { @Autowired protected M mapper; private Class&lt;T&gt; entityClass = (Class&lt;T&gt;) ((ParameterizedType) getClass().getGenericSuperclass()).getActualTypeArguments()[0]; @Override public boolean unique(String property, String value) { Example example = new Example(entityClass); example.createCriteria().andEqualTo(property, value); int result = mapper.selectCountByExample(example); if (result &gt; 0) { return false; } return true; } @Override public T save(T domain) { int result = 0; Date currentDate = new Date(); // 创建 if (domain.getId() == null) { /** * 用于自动回显 ID，领域模型中需要 @ID 注解的支持 * {@link AbstractBaseDomain} */ result = mapper.insertUseGeneratedKeys(domain); } // 更新 else { result = mapper.updateByPrimaryKey(domain); } // 保存数据成功 if (result &gt; 0) { return domain; } // 保存数据失败 return null; } @Override public PageInfo&lt;T&gt; page(T domain, int pageNum, int pageSize) { Example example = new Example(entityClass); example.createCriteria().andEqualTo(domain); PageHelper.startPage(pageNum, pageSize); PageInfo&lt;T&gt; pageInfo = new PageInfo&lt;&gt;(mapper.selectByExample(example)); return pageInfo; } } TbUserService public interface TbUserService extends BaseCrudService&lt;TbUser&gt; { TbUser getById(long id); } impl.TbUserServiceImpl @Service public class TbUserServiceImpl extends BaseCrudServiceImpl&lt;TbUser, TbUserMapper&gt; implements TbUserService { @Autowired private TbUserMapper tbUserMapper; public TbUser getById(long id){ return tbUserMapper.selectByPrimaryKey(id); } } ht-micro-record-service-user &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-service-user&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ht-micro-record-service-user&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.code.findbugs&lt;/groupId&gt; &lt;artifactId&gt;jsr305&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.code.findbugs&lt;/groupId&gt; &lt;artifactId&gt;jsr305&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Projects Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-commons-service&lt;/artifactId&gt; &lt;version&gt;${project.parent.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Projects End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- docker的maven插件，官网 https://github.com/spotify/docker-maven-plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;192.168.2.7:5000/${project.artifactId}:${project.version}&lt;/imageName&gt; &lt;baseImage&gt;onejane-jdk1.8 &lt;/baseImage&gt; &lt;entryPoint&gt;[&quot;java&quot;, &quot;-jar&quot;,&quot;/${project.build.finalName}.jar&quot;]&lt;/entryPoint&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;dockerHost&gt;http://192.168.2.7:2375&lt;/dockerHost&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.ht.micro.record.UserServiceApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; application.yml配置多数据源及RocketMQ spring: cloud: stream: rocketmq: binder: name-server: 192.168.2.7:9876 bindings: output: content-type: application/json destination: topic-email producer: group: group-email datasource: base: #监控统计拦截的filters filters: stat type: com.alibaba.druid.pool.DruidDataSource jdbc-url: jdbc:mysql://192.168.2.7:185/ht_micro_record?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver max-idle: 10 max-wait: 10000 min-idle: 5 initial-size: 5 validation-query: SELECT 1 test-on-borrow: false test-while-idle: true time-between-eviction-runs-millis: 18800 dic: #监控统计拦截的filters filters: stat type: com.alibaba.druid.pool.DruidDataSource jdbc-url: jdbc:mysql://192.168.1.48:3306/ht_nlp?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false username: root password: Sonar@1234 driver-class-name: com.mysql.jdbc.Driver max-idle: 10 max-wait: 10000 min-idle: 5 initial-size: 5 validation-query: SELECT 1 test-on-borrow: false test-while-idle: true time-between-eviction-runs-millis: 18800 bootstrap.properties spring.application.name=ht-micro-record-service-user-config spring.cloud.nacos.config.file-extension=yaml spring.cloud.nacos.config.server-addr=192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 logging.level.com.ht.micro.record=DEBUG nacos配置 spring: application: name: ht-micro-record-service-user cloud: nacos: discovery: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 sentinel: transport: port: 8719 dashboard: 192.168.2.7:190 server: port: 9506 management: endpoints: web: exposure: include: &quot;*&quot; com.ht.micro.record.UserServiceApplication @SpringBootApplication(scanBasePackages = &quot;com.ht.micro.record&quot;,exclude = {DataSourceAutoConfiguration.class, DataSourceTransactionManagerAutoConfiguration.class, MybatisAutoConfiguration.class}) @EnableDiscoveryClient @EnableBinding({Source.class}) @MapperScan(basePackages = &quot;com.ht.micro.record.commons.mapper&quot;) @EnableAsync @EnableSwagger2 public class UserServiceApplication { public static void main(String[] args) { SpringApplication.run(UserServiceApplication.class, args); } } com.ht.micro.record.user.config.BaseMybatisConfig @Configuration @MapperScan(basePackages = {&quot;com.ht.micro.record.commons.mapper.baseMapper&quot;}, sqlSessionTemplateRef = &quot;baseSqlSessionTemplate&quot;) public class BaseMybatisConfig { @Value(&quot;${spring.datasource.base.filters}&quot;) String filters; @Value(&quot;${spring.datasource.base.driver-class-name}&quot;) String driverClassName; @Value(&quot;${spring.datasource.base.username}&quot;) String username; @Value(&quot;${spring.datasource.base.password}&quot;) String password; @Value(&quot;${spring.datasource.base.jdbc-url}&quot;) String url; @Bean(name=&quot;baseDataSource&quot;) @Primary//必须加此注解，不然报错，下一个类则不需要添加 spring.datasource @ConfigurationProperties(prefix=&quot;spring.datasource.base&quot;)//prefix值必须是application.properteis中对应属性的前缀 public DataSource baseDataSource() throws SQLException { DruidDataSource druid = new DruidDataSource(); // 监控统计拦截的filters druid.setFilters(filters); // 配置基本属性 druid.setDriverClassName(driverClassName); druid.setUsername(username); druid.setPassword(password); druid.setUrl(url); return druid; } @Bean(name=&quot;baseSqlSessionFactory&quot;) @Primary public SqlSessionFactory baseSqlSessionFactory(@Qualifier(&quot;baseDataSource&quot;)DataSource dataSource)throws Exception{ // 创建Mybatis的连接会话工厂实例 SqlSessionFactoryBean bean=new SqlSessionFactoryBean(); bean.setDataSource(dataSource);//// 设置数据源bean //添加XML目录 ResourcePatternResolver resolver=new PathMatchingResourcePatternResolver(); try{ bean.setMapperLocations(resolver.getResources(&quot;classpath:baseMapper/*Mapper.xml&quot;));//// 设置mapper文件路径 return bean.getObject(); }catch(Exception e){ e.printStackTrace(); throw new RuntimeException(e); } } @Bean(name=&quot;baseSqlSessionTemplate&quot;) @Primary public SqlSessionTemplate baseSqlSessionTemplate(@Qualifier(&quot;baseSqlSessionFactory&quot;)SqlSessionFactory sqlSessionFactory)throws Exception{ SqlSessionTemplate template=new SqlSessionTemplate(sqlSessionFactory);//使用上面配置的Factory return template; } } com.ht.micro.record.user.config.DicMybatisConfig @Configuration @MapperScan(basePackages = {&quot;com.ht.micro.record.commons.mapper.dicMapper&quot;}, sqlSessionTemplateRef = &quot;dicSqlSessionTemplate&quot;) public class DicMybatisConfig { @Value(&quot;${spring.datasource.dic.filters}&quot;) String filters; @Value(&quot;${spring.datasource.dic.driver-class-name}&quot;) String driverClassName; @Value(&quot;${spring.datasource.dic.username}&quot;) String username; @Value(&quot;${spring.datasource.dic.password}&quot;) String password; @Value(&quot;${spring.datasource.dic.jdbc-url}&quot;) String url; @Bean(name = &quot;dicDataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.datasource.dic&quot;) public DataSource dicDataSource() throws SQLException { DruidDataSource druid = new DruidDataSource(); // 监控统计拦截的filters // druid.setFilters(filters); // 配置基本属性 druid.setDriverClassName(driverClassName); druid.setUsername(username); druid.setPassword(password); druid.setUrl(url); /* //初始化时建立物理连接的个数 druid.setInitialSize(initialSize); //最大连接池数量 druid.setMaxActive(maxActive); //最小连接池数量 druid.setMinIdle(minIdle); //获取连接时最大等待时间，单位毫秒。 druid.setMaxWait(maxWait); //间隔多久进行一次检测，检测需要关闭的空闲连接 druid.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); //一个连接在池中最小生存的时间 druid.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis); //用来检测连接是否有效的sql druid.setValidationQuery(validationQuery); //建议配置为true，不影响性能，并且保证安全性。 druid.setTestWhileIdle(testWhileIdle); //申请连接时执行validationQuery检测连接是否有效 druid.setTestOnBorrow(testOnBorrow); druid.setTestOnReturn(testOnReturn); //是否缓存preparedStatement，也就是PSCache，oracle设为true，mysql设为false。分库分表较多推荐设置为false druid.setPoolPreparedStatements(poolPreparedStatements); // 打开PSCache时，指定每个连接上PSCache的大小 druid.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize); */ return druid; } @Bean(name = &quot;dicSqlSessionFactory&quot;) public SqlSessionFactory dicSqlSessionFactory(@Qualifier(&quot;dicDataSource&quot;)DataSource dataSource)throws Exception{ SqlSessionFactoryBean bean=new SqlSessionFactoryBean(); bean.setDataSource(dataSource); //添加XML目录 ResourcePatternResolver resolver=new PathMatchingResourcePatternResolver(); try{ bean.setMapperLocations(resolver.getResources(&quot;classpath:dicMapper/*Mapper.xml&quot;)); return bean.getObject(); }catch(Exception e){ e.printStackTrace(); throw new RuntimeException(e); } } @Bean(name=&quot;dicSqlSessionTemplate&quot;) public SqlSessionTemplate dicSqlSessionTemplate(@Qualifier(&quot;dicSqlSessionFactory&quot;)SqlSessionFactory sqlSessionFactory)throws Exception{ SqlSessionTemplate template=new SqlSessionTemplate(sqlSessionFactory);//使用上面配置的Factory return template; } } com.ht.micro.record.user.service.UserService @Service public class UserService { @Autowired private MessageChannel output; // @EnableAsync在Application中开启异步 @Async public void sendEmail(TbUser tbUser) throws Exception { output.send(MessageBuilder.withPayload(MapperUtils.obj2json(tbUser)).build()); } } com.ht.micro.record.user.controller.UserController @RestController @RequestMapping(value = &quot;user&quot;) public class UserController extends AbstractBaseController&lt;TbUser&gt; { @Autowired private TbUserService tbUserService; @Autowired private UserService userService; // http://localhost:9506/user/2 // @ApiOperation(value = &quot;查询用户&quot;, notes = &quot;根据id获取用户名&quot;) @GetMapping(value = {&quot;{id}&quot;}) public String getName(@PathVariable long id){ return tbUserService.getById(id).getUsername(); } @ApiOperation(value = &quot;用户注册&quot;, notes = &quot;参数为实体类，注意用户名和邮箱不要重复&quot;) @PostMapping(value = &quot;reg&quot;) public AbstractBaseResult reg(@ApiParam(name = &quot;tbUser&quot;, value = &quot;用户模型&quot;) TbUser tbUser) { // 数据校验 String message = BeanValidator.validator(tbUser); if (StringUtils.isNotBlank(message)) { return error(message, null); } // 验证密码是否为空 if (StringUtils.isBlank(tbUser.getPassword())) { return error(&quot;密码不可为空&quot;, null); } // 验证用户名是否重复 if (!tbUserService.unique(&quot;username&quot;, tbUser.getUsername())) { return error(&quot;用户名已存在&quot;, null); } // 验证邮箱是否重复 if (!tbUserService.unique(&quot;email&quot;, tbUser.getEmail())) { return error(&quot;邮箱重复，请重试&quot;, null); } // 注册用户 try { tbUser.setPassword(DigestUtils.md5DigestAsHex(tbUser.getPassword().getBytes())); TbUser user = tbUserService.save(tbUser); if (user != null) { userService.sendEmail(user); response.setStatus(HttpStatus.CREATED.value()); return success(request.getRequestURI(), user); } } catch (Exception e) { // 这里补一句，将 RegService 中的异常抛到 Controller 中，这样可以打印出调试信息 return error(HttpStatus.INTERNAL_SERVER_ERROR.value(), &quot;注册邮件发送失败&quot;, e.getMessage()); } // 注册失败 return error(&quot;注册失败，请重试&quot;, null); } } ht-micro-record-service-sms &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../ht-micro-record-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-service-sms&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ht-micro-record-service-sms&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.code.findbugs&lt;/groupId&gt; &lt;artifactId&gt;jsr305&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Projects Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-commons-domain&lt;/artifactId&gt; &lt;version&gt;${project.parent.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Projects End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;ht-micro-record-service-sms&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.ht.micro.record.service.email.SmsServiceApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- docker的maven插件，官网 https://github.com/spotify/docker-maven-plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;192.168.2.7:5000/${project.artifactId}:${project.version}&lt;/imageName&gt; &lt;baseImage&gt;jdk1.8&lt;/baseImage&gt; &lt;entryPoint&gt;[&quot;java&quot;, &quot;-jar&quot;,&quot;/${project.build.finalName}.jar&quot;]&lt;/entryPoint&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;dockerHost&gt;http://192.168.2.7:2375&lt;/dockerHost&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; application.yml spring: cloud: stream: rocketmq: binder: name-server: 192.168.2.7:9876 bindings: input: consumer: orderly: true bindings: input: destination: topic-email content-type: application/json group: group-email consumer: maxAttempts: 1 thymeleaf: cache: false mode: HTML encoding: UTF-8 servlet: content-type: text/html bootstrap.properties spring.application.name=ht-micro-record-service-sms-config spring.cloud.nacos.config.file-extension=yaml spring.cloud.nacos.config.server-addr=192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 nacos配置 spring: application: name: ht-micro-record-service-sms mail: host: smtp.163.com port: 25 # 你的邮箱授权码 password: codewj123456 properties: mail: smtp: auth: true starttls: enable: true required: true # 发送邮件的邮箱地址 username: m15806204096@163.com cloud: nacos: discovery: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 sentinel: transport: port: 8719 dashboard: 192.168.2.7:190 server: port: 9507 management: endpoints: web: exposure: include: &quot;*&quot; com.ht.micro.record.service.email.SmsServiceApplication @SpringBootApplication(scanBasePackages = &quot;com.ht.micro.record&quot;) @EnableDiscoveryClient @EnableBinding({Sink.class}) @EnableAsync public class SmsServiceApplication { public static void main(String[] args) { SpringApplication.run(SmsServiceApplication.class, args); } } com.ht.micro.record.service.email.service.EmailService @Service public class EmailService { @Autowired private ConfigurableApplicationContext applicationContext; @Autowired private JavaMailSender javaMailSender; @Autowired private TemplateEngine templateEngine; @StreamListener(&quot;input&quot;) public void receive(String json) { try { // 发送普通邮件 TbUser tbUser = MapperUtils.json2pojo(json, TbUser.class); sendEmail(&quot;欢迎注册&quot;, &quot;欢迎 &quot; + tbUser.getUsername() + &quot; 加入华通晟云！&quot;, tbUser.getEmail()); // 发送 HTML 模板邮件 Context context = new Context(); context.setVariable(&quot;username&quot;, tbUser.getUsername()); String emailTemplate = templateEngine.process(&quot;reg&quot;, context); sendTemplateEmail(&quot;欢迎注册&quot;, emailTemplate, tbUser.getEmail()); } catch (Exception e) { e.printStackTrace(); } } /** * 发送普通邮件 * @param subject * @param body * @param to */ @Async public void sendEmail(String subject, String body, String to) { SimpleMailMessage message = new SimpleMailMessage(); message.setFrom(applicationContext.getEnvironment().getProperty(&quot;spring.mail.username&quot;)); message.setTo(to); message.setSubject(subject); message.setText(body); javaMailSender.send(message); } /** * 发送 HTML 模板邮件 * @param subject * @param body * @param to */ @Async public void sendTemplateEmail(String subject, String body, String to) { MimeMessage message = javaMailSender.createMimeMessage(); try { MimeMessageHelper helper = new MimeMessageHelper(message, true); helper.setFrom(applicationContext.getEnvironment().getProperty(&quot;spring.mail.username&quot;)); helper.setTo(to); helper.setSubject(subject); helper.setText(body, true); javaMailSender.send(message); } catch (Exception e) { } } } templates/reg.html &lt;!DOCTYPE html SYSTEM &quot;http://www.thymeleaf.org/dtd/xhtml1-strict-thymeleaf-spring4-4.dtd&quot;&gt; &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;注册通知&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; 欢迎 &lt;span th:text=&quot;${username}&quot;&gt;&lt;/span&gt; 加入 华通晟云！！ &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; post http://localhost:9506/user/reg?password=123456&amp;username=codewj&amp;email=1051103813@qq.com 实现注册 集成Swagger2ht-micro-record-commons/pom.xml &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;/dependency&gt;com.ht.micro.record.commons.config.Swagger2Configuration @Configuration public class Swagger2Configuration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.ht.micro.record&quot;)) // 配置controller地址 .paths(PathSelectors.any()) .build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(&quot;微服务 API 文档&quot;) .description(&quot;微服务 API 网关接口，http://www.htdatacloud.com/&quot;) .termsOfServiceUrl(&quot;http://www.htdatacloud.com&quot;) .version(&quot;1.0.0&quot;) .build(); } }com.ht.micro.record.UserServiceApplication @EnableSwagger2 com.ht.micro.record.user.controller.UserController @ApiOperation(value = &quot;用户注册&quot;, notes = &quot;参数为实体类，注意用户名和邮箱不要重复&quot;) @PostMapping 服务提供消费配置项目skywalking链路追踪并启动 -javaagent:E:\Project\ht-micro-record\ht-micro-record-external-skywalking\agent\skywalking-agent.jar -Dskywalking.agent.service_name=ht-micro-record-service-user -Dskywalking.collector.backend_service=192.168.2.7:11800 -javaagent:E:\Project\hello-spring-cloud-alibaba\hello-spring-cloud-external-skywalking\agent\skywalking-agent.jar -Dskywalking.agent.service_name=nacos-consumer-feign -Dskywalking.collector.backend_service=192.168.3.229:11800http://192.168.3.233:9501/user/10 调用服务http://192.168.2.7:193/#/monitor/dashboard 查看skywalking的链路追踪]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>spring cloud alibaba</tag>
        <tag>skywalking</tag>
        <tag>rocketmq</tag>
        <tag>validate</tag>
        <tag>multi druid</tag>
        <tag>swagger</tag>
        <tag>email</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alibaba环境搭建]]></title>
    <url>%2F2019%2F08%2F21%2FAlibaba%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[基于spring cloud alibaba实战整合开发 创建统一的依赖管理ht-micro-record-dependencies &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;ht-micro-record-dependencies&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;properties&gt; &lt;!-- Environment Settings --&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- Spring Cloud Settings --&gt; &lt;spring-cloud.version&gt;Greenwich.RELEASE&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.9.0.RELEASE&lt;/spring-cloud-alibaba.version&gt; &lt;!-- Spring Boot Settings --&gt; &lt;spring-boot-alibaba-druid.version&gt;1.1.18&lt;/spring-boot-alibaba-druid.version&gt; &lt;spring-boot-tk-mybatis.version&gt;2.1.4&lt;/spring-boot-tk-mybatis.version&gt; &lt;spring-boot-pagehelper.version&gt;1.2.12&lt;/spring-boot-pagehelper.version&gt; &lt;!-- Commons Settings --&gt; &lt;mysql.version&gt;5.1.38&lt;/mysql.version&gt; &lt;swagger2.version&gt;2.9.2&lt;/swagger2.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${spring-boot-alibaba-druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${spring-boot-tk-mybatis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${spring-boot-pagehelper.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Commons Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;${swagger2.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;${swagger2.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--防止版本冲突，统一版本在父pom中--&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;24.0-jre&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Commons End --&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- Compiler 插件, 设定 JDK 版本，所有子服务统一打包jdk版本 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 打包 jar 文件时，配置 manifest 文件，加入 lib 包的 jar 依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- Add directory entries --&gt; &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt; &lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- resource --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- install --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- clean --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- ant --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- dependency --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 资源文件配置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Repository&lt;/name&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos-s&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Plugin Repository&lt;/name&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;创建通用的工具类库ht-micro-record-commons &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-commons&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ht-micro-record-commons&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Begin ，每个RequestMapping之上都执行@ModelAttribute注解的方法，请求时都会带入request和response--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-core&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring End HttpServletRequest等实体，provided 其他服务依赖commons时不会自动引入tomcat依赖--&gt; &lt;!-- Apache Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Apache End --&gt; &lt;!-- Commons Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.persistence&lt;/groupId&gt; &lt;artifactId&gt;javax.persistence-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Commons End --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;ht-micro-record-commons&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;mainClass&gt;com.ht.micro.record.commons.CommonsApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;创建通用的领域模型ht-micro-record-commons-domain &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-commons-domain&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ht-micro-record-commons-domain&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring End --&gt; &lt;!-- Commons Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Commons End --&gt; &lt;!-- Projects Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-commons&lt;/artifactId&gt; &lt;version&gt;${project.parent.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Projects End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;ht-micro-record-commons-domain&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;mainClass&gt;com.ht.micro.record.commons.CommonsDomainApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;创建通用的数据访问ht-micro-record-commons-mapper &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../ht-micro-record-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-commons-mapper&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ht-micro-record-commons-mapper&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Commons Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Commons End --&gt; &lt;!-- Projects Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-commons-domain&lt;/artifactId&gt; &lt;version&gt;${project.parent.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Projects End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;ht-micro-record-commons-domain&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;mainClass&gt;com.ht.micro.record.commons.CommonsMapperApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;创建通用的业务逻辑ht-micro-record-commons-service &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../ht-micro-record-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-commons-service&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ht-micro-record-commons-service&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-commons-mapper&lt;/artifactId&gt; &lt;version&gt;${project.parent.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;ht-micro-record-commons-domain&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;mainClass&gt;com.ht.micro.record.commons.CommonsMapperApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;创建通用的代码生成ht-micro-record-database &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../ht-micro-record-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-database&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ht-micro-record-database&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2018-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;4.1.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;${basedir}/src/main/resources/generator/generatorConfig.xml&lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;4.1.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;tk.mybatis.mapper.MyMapper public interface MyMapper&lt;T&gt; extends Mapper&lt;T&gt;, MySqlMapper&lt;T&gt; { }generator/generatorConfig.xml &lt;generatorConfiguration&gt; &lt;!-- 引入数据库连接配置 --&gt; &lt;properties resource=&quot;jdbc.properties&quot;/&gt; &lt;context id=&quot;Mysql&quot; targetRuntime=&quot;MyBatis3Simple&quot; defaultModelType=&quot;flat&quot;&gt; &lt;property name=&quot;beginningDelimiter&quot; value=&quot;`&quot;/&gt; &lt;property name=&quot;endingDelimiter&quot; value=&quot;`&quot;/&gt; &lt;!-- 配置 tk.mybatis 插件 --&gt; &lt;plugin type=&quot;tk.mybatis.mapper.generator.MapperPlugin&quot;&gt; &lt;property name=&quot;mappers&quot; value=&quot;tk.mybatis.mapper.MyMapper&quot;/&gt; &lt;/plugin&gt; &lt;!-- 配置数据库连接 --&gt; &lt;jdbcConnection driverClass=&quot;${jdbc.driverClass}&quot; connectionURL=&quot;${jdbc.connectionURL}&quot; userId=&quot;${jdbc.username}&quot; password=&quot;${jdbc.password}&quot;&gt; &lt;/jdbcConnection&gt; &lt;!-- 配置实体类存放路径 --&gt; &lt;javaModelGenerator targetPackage=&quot;com.ht.micro.record.commons.domain&quot; targetProject=&quot;src/main/java&quot;/&gt; &lt;!-- 配置 XML 存放路径 --&gt; &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;src/main/resources/baseMapper&quot;/&gt; &lt;!-- 配置 DAO 存放路径 --&gt; &lt;javaClientGenerator targetPackage=&quot;com.ht.micro.record.commons.mapper.baseMapper&quot; targetProject=&quot;src/main/java&quot; type=&quot;XMLMAPPER&quot;/&gt; &lt;!-- 配置需要指定生成的数据库和表，% 代表所有表 生成@Table中删除ht-micro-record.. --&gt; &lt;table catalog=&quot;ht_micro_record&quot; tableName=&quot;%&quot;&gt; &lt;!-- mysql 配置 --&gt; &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;Mysql&quot; identity=&quot;true&quot;/&gt; &lt;/table&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt;jdbc.properties jdbc.driverClass=com.mysql.jdbc.Driver jdbc.connectionURL=jdbc:mysql://192.168.2.5:185/ht_micro_record?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false jdbc.username=root jdbc.password=123456mvn mybatis-generator:generate 自动生成表实体和mapper接口 创建外部链路追踪ht-micro-record-external-skywalking &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../ht-micro-record-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-external-skywalking&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;ht-micro-record-external-skywalking&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;!-- 配置执行器 --&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- 绑定到 package 生命周期阶段上 --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;!-- 只运行一次 --&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;finalName&gt;skywalking&lt;/finalName&gt; &lt;descriptors&gt; &lt;!-- 配置描述文件路径 --&gt; &lt;descriptor&gt;src/main/assembly/assembly.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;ht-micro-record-external-skywalking/src/main/assembly/assembly.xml &lt;assembly&gt; &lt;id&gt;6.0.0-Beta&lt;/id&gt; &lt;formats&gt; &lt;!-- 打包的文件格式，支持 zip、tar.gz、tar.bz2、jar、dir、war --&gt; &lt;format&gt;tar.gz&lt;/format&gt; &lt;/formats&gt; &lt;!-- tar.gz 压缩包下是否生成和项目名相同的根目录，有需要请设置成 true --&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;!-- 是否把本项目添加到依赖文件夹下，有需要请设置成 true --&gt; &lt;useProjectArtifact&gt;false&lt;/useProjectArtifact&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;!-- 将 scope 为 runtime 的依赖包打包 --&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;!-- 设置需要打包的文件路径 --&gt; &lt;directory&gt;agent&lt;/directory&gt; &lt;!-- 打包后的输出路径 --&gt; &lt;outputDirectory&gt;&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;/assembly&gt;apache-skywalking-apm-incubating-6.0.0-beta.tar.gz解压获取apache-skywalking-apm-bin/agent到ht-micro-record-external-skywalking下mvn clean package 会在 target 目录下创建名为 skywalking-6.0.0-Beta.tar.gz 的压缩包mvn clean install 会在本地仓库目录下创建名为 hello-spring-cloud-external-skywalking-1.0.0-SNAPSHOT-6.0.0-Beta.tar.gz 的压缩包 mkdir /data2/skywalking vim docker-compose.yml version: &#39;3.3&#39; services: elasticsearch: image: wutang/elasticsearch-shanghai-zone:6.3.2 container_name: elasticsearch restart: always ports: - 191:9200 - 192:9300 environment: cluster.name: elasticsearch docker-compose up -d https://mirrors.huaweicloud.com/apache/incubator/skywalking/6.0.0-beta/apache-skywalking-apm-incubating-6.0.0-beta.tar.gz tar zxf apache-skywalking-apm-incubating-6.0.0-beta.tar.gz cd apache-skywalking-apm-incubating vim apache-skywalking-apm-bin/config/application.yml 注释h2,打开es并修改clusterNodes地址 # h2: # driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource} # url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db} # user: ${SW_STORAGE_H2_USER:sa} elasticsearch: nameSpace: ${SW_NAMESPACE:&quot;&quot;} clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:192.168.2.7:191} indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2} indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:2000} # Execute the bulk every 2000 requests bulkSize: ${SW_STORAGE_ES_BULK_SIZE:20} # flush the bulk every 20mb flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests apache-skywalking-apm-incubating/webapp/webapp.yml port 193 ./apache-skywalking-apm-incubating/bin/startup.sh]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>spring cloud alibaba</tag>
        <tag>tk mybatis</tag>
        <tag>skywalking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alibaba限流熔断降级]]></title>
    <url>%2F2019%2F08%2F21%2FAlibaba%E9%99%90%E6%B5%81%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[基于spring cloud alibaba实战整合开发 限流sentinel存储 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; application.yml spring: application: name: ht-micro-record-service-user cloud: nacos: discovery: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 sentinel: transport: port: 8719 dashboard: 192.168.2.7:19 访问ht-micro-record-service-user服务，http://localhost:9506/apply/page/1/2快速的调用两次http://localhost:9506/apply/page/1/2 接口之后，第三次调用被限流了 nacos存储 &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; application.yml spring: cloud: sentinel: datasource: ds: nacos: dataId: ${spring.application.name}-sentinel groupId: DEFAULT_GROUP rule-type: flow server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850nacos中配置ht-micro-record-service-user-sentinel [ { &quot;resource&quot;: &quot;/apply/page/1/2&quot;, &quot;limitApp&quot;: &quot;default&quot;, &quot;grade&quot;: 1, &quot;count&quot;: 5, &quot;strategy&quot;: 0, &quot;controlBehavior&quot;: 0, &quot;clusterMode&quot;: false } ] 进入http://192.168.2.7:190/#/dashboard/identity/ht-micro-record-service-user 访问 Sentinel控制台中修改规则：仅存在于服务的内存中，不会修改Nacos中的配置值，重启后恢复原来的值。 Nacos控制台中修改规则：服务的内存中规则会更新，Nacos中持久化规则也会更新，重启后依然保持。限流捕获处理异常ht-micro-record-service-dubbo-provider &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; com.ht.micro.record.service.dubbo.provider.DubboProviderApplication // 注解支持的配置Bean @Bean public SentinelResourceAspect sentinelResourceAspect() { return new SentinelResourceAspect(); } bootstrap.yml spring: application: name: ht-micro-record-service-dubbo-provider cloud: nacos: config: file-extension: yaml server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 sentinel: transport: port: 8720 dashboard: 192.168.2.7:190 datasource: ds: nacos: dataId: ${spring.application.name}-sentinel groupId: DEFAULT_GROUP rule-type: flow data-type: json server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850nacos配置ht-micro-record-service-dubbo-provider-sentinel [ { &quot;resource&quot;: &quot;protected-resource&quot;, &quot;controlBehavior&quot;: 2, &quot;count&quot;: 1, &quot;grade&quot;: 1, &quot;limitApp&quot;: &quot;default&quot;, &quot;strategy&quot;: 0 } ] nacos配置ht-micro-record-service-dubbo-provider.yaml spring: application: name: ht-micro-record-service-dubbo-provider cloud: nacos: discovery: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 server: port: 9502 com.ht.micro.record.service.dubbo.provider.controller.ProviderController @GetMapping(&quot;/port&quot;) @SentinelResource(value = &quot;protected-resource&quot;, blockHandler = &quot;handleBlock&quot;) public Object port() { return &quot;port= &quot;+ port + &quot;, name=&quot; + applicationContext.getEnvironment().getProperty(&quot;user.name&quot;); } public String handleBlock(BlockException ex) { return &quot;限流了&quot;; }启动服务后http://192.168.2.7:190/#/dashboard/flow/ht-micro-record-service-dubbo-provider快速访问http://localhost:9502/provider/port 每秒超过1个请求将会显示限流了 熔断 @GetMapping(&quot;name&quot;) @SentinelResource(value = &quot;getName&quot;, fallback = &quot;getNameFallback&quot;) public String userName(String name){ for (int i = 0; i &lt; 100000000L; i++) { } return &quot;getName &quot; + name; } // 该方法降级处理函数，参数要与原函数getName相同，并且返回值类型也要与原函数相同，此外，该方法必须与原函数在同一个类中 public String getNameFallback(String name){ return &quot;getNameFallback&quot;; } 访问http://localhost:9502/provider/name查看http://192.168.2.7:190/#/dashboard/identity/ht-micro-record-service-dubbo-provider根据响应时间，大于10毫秒，则熔断降级（要连续超过5个请求超过10毫秒才会熔断）快速访问http://localhost:9502/provider/name @GetMapping(&quot;name&quot;) @SentinelResource(value = &quot;getName&quot;, fallback = &quot;getNameFallback&quot;) public String userName(String name){ for (int i = 0; i &lt; 100000000L; i++) { throw new RuntimeException(); } return &quot;getName &quot; + name; } // 该方法降级处理函数，参数要与原函数getName相同，并且返回值类型也要与原函数相同，此外，该方法必须与原函数在同一个类中 public String getNameFallback(String name){ return &quot;getNameFallback&quot;; } 显示抛出是10个异常，然后返回结果是熔断处理方法返回结果 流控规则 降级规则timeWindow为熔断恢复时间熔断模式，当熔断触发后，需要等待timewindow时间，再关闭熔断器。 0 根据rt时间，当超过指定规则的时间连续超过5笔，则触发熔断。 1 根据异常比例熔断 DEGRADE_GRADE_EXCEPTION_RATIO 2 根据单位时间内异常总数做熔断热点规则系统规则授权规则 Sentinel整合Nacos动态发布git clone https://github.com/alibaba/Sentinel.git cd Sentinel/sentinel-dashboard vim pom.xml &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;!--&lt;scope&gt;test&lt;/scope&gt;--&gt; &lt;/dependency&gt; 修改resources/app/scripts/directives/sidebar/sidebar.html &lt;li ui-sref-active=&quot;active&quot;&gt; &lt;a ui-sref=&quot;dashboard.flowV1({app: entry.app})&quot;&gt; &lt;i class=&quot;glyphicon glyphicon-filter&quot;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;流控规则 &lt;/a&gt; &lt;/li&gt; 为 &lt;li ui-sref-active=&quot;active&quot;&gt; &lt;a ui-sref=&quot;dashboard.flow({app: entry.app})&quot;&gt; &lt;i class=&quot;glyphicon glyphicon-filter&quot;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;流控规则 &lt;/a&gt; &lt;/li&gt; com.alibaba.csp.sentinel.dashboard.rule.nacos.NacosConfigConstant public final class NacosConfigConstant { public static final String GROUP_ID = &quot;DEFAULT_GROUP&quot;; public static final String FLOW_DATA_ID_POSTFIX = &quot;-flow-rules&quot;; public static final String PARAM_FLOW_DATA_ID_POSTFIX = &quot;-param-flow-rules&quot;; public static final String DEGRADE_DATA_ID_POSTFIX = &quot;-degrade-rules&quot;; public static final String SYSTEM_DATA_ID_POSTFIX = &quot;-system-rules&quot;; public static final String AUTHORITY_DATA_ID_POSTFIX = &quot;-authority-rules&quot;; } com.alibaba.csp.sentinel.dashboard.rule.nacos.NacosConfigProperties @Component public class NacosConfigProperties { @Value(&quot;${houyi.nacos.server.ip}&quot;) private String ip; @Value(&quot;${houyi.nacos.server.port}&quot;) private String port; @Value(&quot;${houyi.nacos.server.namespace}&quot;) private String namespace; @Value(&quot;${houyi.nacos.server.group-id}&quot;) private String groupId; public String getIp() { return ip; } public void setIp(String ip) { this.ip = ip; } public String getPort() { return port; } public void setPort(String port) { this.port = port; } public String getNamespace() { return namespace; } public void setNamespace(String namespace) { this.namespace = namespace; } public String getGroupId() { return groupId; } public void setGroupId(String groupId) { this.groupId = groupId; } public String getServerAddr() { return this.getIp()+&quot;:&quot;+this.getPort(); } @Override public String toString() { return &quot;NacosConfigProperties [ip=&quot; + ip + &quot;, port=&quot; + port + &quot;, namespace=&quot; + namespace + &quot;, groupId=&quot; + groupId + &quot;]&quot;; } } com.alibaba.csp.sentinel.dashboard.rule.nacos.NacosConfig @Configuration public class NacosConfig { @Autowired private NacosConfigProperties nacosConfigProperties; @Bean public ConfigService nacosConfigService() throws Exception { Properties properties = new Properties(); properties.put(PropertyKeyConst.SERVER_ADDR, nacosConfigProperties.getServerAddr()); if(nacosConfigProperties.getNamespace() != null &amp;&amp; !&quot;&quot;.equals(nacosConfigProperties.getNamespace())) properties.put(PropertyKeyConst.NAMESPACE, nacosConfigProperties.getNamespace()); return ConfigFactory.createConfigService(properties); } } application.properties houyi.nacos.server.ip=192.168.2.7 houyi.nacos.server.port=8848 houyi.nacos.server.namespace= houyi.nacos.server.group-id=DEFAULT_GROUP FlowRulecom.alibaba.csp.sentinel.dashboard.rule.nacos.FlowRuleNacosPublisher @Component(&quot;flowRuleNacosPublisher&quot;) public class FlowRuleNacosPublisher implements DynamicRulePublisher&lt;List&lt;FlowRuleEntity&gt;&gt; { @Autowired private ConfigService configService; @Autowired private NacosConfigProperties nacosConfigProperties; @Override public void publish(String app, List&lt;FlowRuleEntity&gt; rules) throws Exception { AssertUtil.notEmpty(app, &quot;app name cannot be empty&quot;); if (rules == null) { return; } configService.publishConfig(app + NacosConfigConstant.FLOW_DATA_ID_POSTFIX, nacosConfigProperties.getGroupId(), JSON.toJSONString(rules.stream().map(FlowRuleEntity::toRule).collect(Collectors.toList()))); } } com.alibaba.csp.sentinel.dashboard.rule.nacos.FlowRuleNacosProvider @Component(&quot;flowRuleNacosProvider&quot;) public class FlowRuleNacosProvider implements DynamicRuleProvider&lt;List&lt;FlowRuleEntity&gt;&gt; { private static Logger logger = LoggerFactory.getLogger(FlowRuleNacosProvider.class); @Autowired private ConfigService configService; @Autowired private NacosConfigProperties nacosConfigProperties; @Override public List&lt;FlowRuleEntity&gt; getRules(String appName) throws Exception { String rulesStr = configService.getConfig(appName + NacosConfigConstant.FLOW_DATA_ID_POSTFIX, nacosConfigProperties.getGroupId(), 3000); logger.info(&quot;nacosConfigProperties{}:&quot;, nacosConfigProperties); logger.info(&quot;从Nacos中获取到限流规则信息{}&quot;, rulesStr); if (StringUtil.isEmpty(rulesStr)) { return new ArrayList&lt;&gt;(); } List&lt;FlowRule&gt; rules = RuleUtils.parseFlowRule(rulesStr); if (rules != null) { return rules.stream().map(rule -&gt; FlowRuleEntity.fromFlowRule(appName, nacosConfigProperties.getIp(), Integer.valueOf(nacosConfigProperties.getPort()), rule)) .collect(Collectors.toList()); } else { return new ArrayList&lt;&gt;(); } } } com.alibaba.csp.sentinel.dashboard.controller.FlowControllerV1将原始HTTP调用改为对应的Provider及Publisher去除 @Autowired private SentinelApiClient sentinelApiClient; 新增Qualifier和Component值保持一致 @Autowired @Qualifier(&quot;flowRuleNacosProvider&quot;) private DynamicRuleProvider&lt;List&lt;FlowRuleEntity&gt;&gt; provider; @Autowired @Qualifier(&quot;flowRuleNacosPublisher&quot;) private DynamicRulePublisher&lt;List&lt;FlowRuleEntity&gt;&gt; publisher; @GetMapping(&quot;/rules&quot;) public Result&lt;List&lt;FlowRuleEntity&gt;&gt; apiQueryMachineRules(HttpServletRequest request, @RequestParam String app, @RequestParam String ip, @RequestParam Integer port) { AuthUser authUser = authService.getAuthUser(request); authUser.authTarget(app, PrivilegeType.READ_RULE); if (StringUtil.isEmpty(app)) { return Result.ofFail(-1, &quot;app can&#39;t be null or empty&quot;); } if (StringUtil.isEmpty(ip)) { return Result.ofFail(-1, &quot;ip can&#39;t be null or empty&quot;); } if (port == null) { return Result.ofFail(-1, &quot;port can&#39;t be null&quot;); } try { List&lt;FlowRuleEntity&gt; rules = provider.getRules(app); rules = repository.saveAll(rules); return Result.ofSuccess(rules); } catch (Throwable throwable) { logger.error(&quot;Error when querying flow rules&quot;, throwable); return Result.ofThrowable(-1, throwable); } } private boolean publishRules(String app, String ip, Integer port) { List&lt;FlowRuleEntity&gt; rules = repository.findAllByMachine(MachineInfo.of(app, ip, port)); try { publisher.publish(app, rules); logger.info(&quot;添加限流规则成功{}&quot;, JSON.toJSONString(rules.stream().map(FlowRuleEntity::toRule).collect(Collectors.toList()))); return true; } catch (Exception e) { logger.info(&quot;添加限流规则失败{}&quot;,JSON.toJSONString(rules.stream().map(FlowRuleEntity::toRule).collect(Collectors.toList()))); e.printStackTrace(); return false; } } DegradeRulecom.alibaba.csp.sentinel.dashboard.rule.nacos.DegradeRuleNacosPublisher @Component(&quot;degradeRuleNacosPublisher&quot;) public class DegradeRuleNacosPublisher implements DynamicRulePublisher&lt;List&lt;DegradeRuleEntity&gt;&gt; { @Autowired private ConfigService configService; @Autowired private NacosConfigProperties nacosConfigProperties; @Override public void publish(String app, List&lt;DegradeRuleEntity&gt; rules) throws Exception { AssertUtil.notEmpty(app, &quot;app name cannot be empty&quot;); if (rules == null) { return; } configService.publishConfig(app + NacosConfigConstant.DEGRADE_DATA_ID_POSTFIX, nacosConfigProperties.getGroupId(), JSON.toJSONString(rules.stream().map(DegradeRuleEntity::toRule).collect(Collectors.toList()))); } } com.alibaba.csp.sentinel.dashboard.rule.nacos.DegradeRuleNacosProvider @Component(&quot;degradeRuleNacosProvider&quot;) public class DegradeRuleNacosProvider implements DynamicRuleProvider&lt;List&lt;DegradeRuleEntity&gt;&gt; { private static Logger logger = LoggerFactory.getLogger(DegradeRuleNacosProvider.class); @Autowired private ConfigService configService; @Autowired private NacosConfigProperties nacosConfigProperties; @Override public List&lt;DegradeRuleEntity&gt; getRules(String appName) throws Exception { String rulesStr = configService.getConfig(appName + NacosConfigConstant.DEGRADE_DATA_ID_POSTFIX, nacosConfigProperties.getGroupId(), 3000); logger.info(&quot;nacosConfigProperties{}:&quot;, nacosConfigProperties); logger.info(&quot;从Nacos中获取到熔断降级规则信息{}&quot;, rulesStr); if (StringUtil.isEmpty(rulesStr)) { return new ArrayList&lt;&gt;(); } List&lt;DegradeRule&gt; rules = RuleUtils.parseDegradeRule(rulesStr); if (rules != null) { return rules.stream().map(rule -&gt; DegradeRuleEntity.fromDegradeRule(appName, nacosConfigProperties.getIp(), Integer.valueOf(nacosConfigProperties.getPort()), rule)) .collect(Collectors.toList()); } else { return new ArrayList&lt;&gt;(); } } } com.alibaba.csp.sentinel.dashboard.controller.DegradeController去除 @Autowired private SentinelApiClient sentinelApiClient;新增 @Autowired @Qualifier(&quot;degradeRuleNacosProvider&quot;) private DynamicRuleProvider&lt;List&lt;DegradeRuleEntity&gt;&gt; provider; @Autowired @Qualifier(&quot;degradeRuleNacosPublisher&quot;) private DynamicRulePublisher&lt;List&lt;DegradeRuleEntity&gt;&gt; publisher; @ResponseBody @RequestMapping(&quot;/rules.json&quot;) public Result&lt;List&lt;DegradeRuleEntity&gt;&gt; queryMachineRules(HttpServletRequest request, String app, String ip, Integer port) { AuthUser authUser = authService.getAuthUser(request); authUser.authTarget(app, PrivilegeType.READ_RULE); if (StringUtil.isEmpty(app)) { return Result.ofFail(-1, &quot;app can&#39;t be null or empty&quot;); } if (StringUtil.isEmpty(ip)) { return Result.ofFail(-1, &quot;ip can&#39;t be null or empty&quot;); } if (port == null) { return Result.ofFail(-1, &quot;port can&#39;t be null&quot;); } try { List&lt;DegradeRuleEntity&gt; rules = provider.getRules(app); rules = repository.saveAll(rules); return Result.ofSuccess(rules); } catch (Throwable throwable) { logger.error(&quot;queryApps error:&quot;, throwable); return Result.ofThrowable(-1, throwable); } } private boolean publishRules(String app, String ip, Integer port) { List&lt;DegradeRuleEntity&gt; rules = repository.findAllByMachine(MachineInfo.of(app, ip, port)); try { publisher.publish(app, rules); logger.info(&quot;添加熔断降级规则成功{}&quot;, JSON.toJSONString(rules.stream().map(DegradeRuleEntity::toRule).collect(Collectors.toList()))); return true; } catch (Exception e) { logger.info(&quot;添加熔断降级规则失败{}&quot;,JSON.toJSONString(rules.stream().map(DegradeRuleEntity::toRule).collect(Collectors.toList()))); e.printStackTrace(); return false; } }重新打包启动 mvn clean package -DskipTests cd sentinel-dashboard/target/ nohup java -Dserver.port=190 -Dcsp.sentinel.dashboard.server=localhost:190 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar &amp;项目中bootstrap.yml spring: application: name: ht-micro-record-service-dubbo-provider cloud: nacos: config: file-extension: yaml server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 sentinel: transport: port: 8720 dashboard: localhost:8080 datasource: ds: nacos: dataId: ${spring.application.name}-flow-rules groupId: DEFAULT_GROUP rule-type: flow # 流控 # rule-type: degrade # 熔断 data-type: json server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 ds1: nacos: dataId: ${spring.application.name}-degrade-rules groupId: DEFAULT_GROUP rule-type: degrade # 熔断 data-type: json server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 nacos配置ht-micro-record-service-dubbo-provider.yaml spring: application: name: ht-micro-record-service-dubbo-provider cloud: nacos: discovery: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 server: port: 9502http://localhost:8080/#/dashboard 新增规则在http://192.168.2.7:8848/nacos 中自动同步暂时实现flow，degrade 基于Feign的熔断controller @GetMapping(&quot;name&quot;) @SentinelResource(value = &quot;getName&quot;, fallback = &quot;getNameFallback&quot;) public String userName(String name){ microServiceUserInf.getUserInfoById(1); return &quot;getName &quot; + name; } service@FeignClient(value = &quot;ht-micro-record-service-user&quot;,fallback = MicroServiceUserInfFallBack.class) public interface MicroServiceUserInf { /** * 通过用户id 获取用户信息 * @param id * @return */ @GetMapping(value = &quot;/user/getUserInfoById/{id}&quot;) TUser getUserInfoById(@PathVariable(value=&quot;id&quot; ) Integer id); } serviceFallBack@Component public class MicroServiceUserInfFallBack implements MicroServiceUserInf { @Autowired private TUserMapper userMapper; @Override public TUser getUserInfoById(Integer id) { log.info(&quot;开启熔断&quot;); return userMapper.selectByPrimaryKey(id); } } nacosspring: application: name: ht-micro-record-service-caserecord cloud: nacos: discovery: server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 sentinel: transport: port: 8723 dashboard: 192.168.2.7:190 datasource: ds: nacos: dataId: ${spring.application.name}-degrade-rules groupId: DEFAULT_GROUP rule-type: degrade data-type: json server-addr: 192.168.2.7:8848,192.168.2.7:8849,192.168.2.7:8850 feign: sentinel: enabled: true pom&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.code.findbugs&lt;/groupId&gt; &lt;artifactId&gt;jsr305&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>spring cloud alibaba</tag>
        <tag>sentinel</tag>
        <tag>nacos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux]]></title>
    <url>%2F2019%2F08%2F20%2Flinux%2F</url>
    <content type="text"><![CDATA[linux使用技巧及常规软件安装 网卡防火墙vi /etc/sysconfig/network-scripts/ifcfg-eth0 ONBOOT=yes IPADDR=192.168.56.101 BOOTPROTO=static IPADDR与当前网卡在同一个网段 service network restart service iptables stop firewall-cmd --permanent --add-port=8080-8085/tcp firewall-cmd --permanent --remove-port=8080-8085/tcp firewall-cmd --permanent --list-ports firewall-cmd --permanent --list-services 查看使用互联网的程序 firewall-cmd --reload chkconfig --del iptables setenforce 0 systemctl stop firewalld.service systemctl disable firewalld.service vim /etc/sysconfig/selinux SELINUX=disabled 基本命令du -h --max-depth=1 查看各文件夹大小 nohup sh inotify3.sh &gt;&gt;333.out &amp; 后台执行脚本并把输出都指定文件 jobs -l 查看运行的后台进程 fg 1 通过jobid将后台进程提取到前台运行 ctrl + z 将暂停当前正在运行到进程，fg放入后台运行 yum -c /etc/yum.conf --installroot=/usr/local --releasever=/ install lszrz 安装文件到其他目录ekillvim /usr/local/bin/ekill ps aux | grep -e $* | grep -v grep | awk &#39;{print $2}&#39; | xargs -i kill {}chmod a+x /usr/local/bin/ekill 通过ekill删除进程 免密登陆192.168.2.7： ssh-keygen -t rsa ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.2.5 ssh root@192.168.2.5 jdk+maventar zxf jdk-8u60-linux-x64.tar.gz -C /data2/ &amp;&amp; mv jdk1.8.0_60 jdk tar zxf apache-maven-3.6.1-bin.tar.gz -C /data2 &amp;&amp; mv apache-maven-3.6.1 maven vim /etc/profile JAVA_HOME=/data2/jdk JRE_HOME=$JAVA_HOME/jre MAVEN_HOME=/data2/maven PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$MAVEN_HOME/bin CLASSPATH=:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib/dt.jar export JAVA_HOME JRE_HOME PATH CLASSPATH MAVEN_HOME source /etc/profile vim setting.xml &lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;!-- localRepository | The path to the local repository maven will use to store artifacts. | | Default: ${user.home}/.m2/repository &lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt; --&gt; &lt;localRepository&gt;E:\apache-maven-3.6.1\respository&lt;/localRepository&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;3rdParty&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;ui&lt;/id&gt; &lt;name&gt;Mirror from UK&lt;/name&gt; &lt;url&gt;http://uk.maven.org/maven2/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;mirrorOf&gt;maven-releases&lt;/mirrorOf&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-releases/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;mirrorOf&gt;maven-snapshots&lt;/mirrorOf&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-snapshots/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-releases/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-snapshots/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;3rdParty&lt;/id&gt; &lt;url&gt;http://192.168.2.7:182/repository/3rdParty/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;!-- 私有库地址--&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;url&gt;http://192.168.2.4:8081/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;ui&lt;/id&gt; &lt;name&gt;ui&lt;/name&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;url&gt;http://uk.maven.org/maven2/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;!--插件库地址--&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;url&gt;http://192.168.2.4:8081/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-releases/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-snapshots/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;aliyun&lt;/id&gt; &lt;name&gt;aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt; &lt;/activeProfiles&gt; &lt;/settings&gt; Gitgitignore无效git rm -r --cached . git add . git commit -m &#39;.gitignore&#39; git push origin master git config –system core.longpaths true 提交长文件名或者idea取消run git hooks Mongowindows 管理员身份启动cmd https://fastdl.mongodb.org/win32/mongodb-win32-x86_64-2008plus-ssl-3.6.2-signed.msi mkdir data\db 进入bin执行mongod --dbpath D:\MongoDB\Server\3.6\data\db 进入bin执行mongo进入客户端，db.test.insert({&#39;a&#39;:&#39;b&#39;}) , db.test.find() 管理员cmd：touch data\logs\mongo.log ,进入bin: mongod --bind_ip 0.0.0.0 --logpath D:\MongoDB\Server\3.6\data\logs\mongo.log --logappend --dbpath D:\MongoDB\Server\3.6\data\db --port 27017 --serviceName &quot;MongoDB&quot; --serviceDisplayName &quot;MongoDB&quot; --install linux https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu1404-3.6.2.tgz uname -a 查看系统描述 lsb_release -a 查看系统版本 tar -zxvf mongodb-linux-i686-2.0.1.tgz &amp;&amp; mv mongodb-linux-i686-2.0.1 mongodb cd mongodb/ &amp;&amp; mkdir log &amp;&amp; mkdir data touch log/mongodb ./mongod -port 10001 --dbpath ~/mongodb/data/ --logpath ~/mongodb/log/mongodb.log 新开窗口./bin/mongo 127.0.0.1:10001 mongo --port 27017 配置密码 show dbs 查看所有库 use yapi 使用yapi库 db 查看当前所在库 db.qa.insert({&#39;username&#39;:&#39;aaa&#39;,&#39;age&#39;:&#39;18&#39;}) db.qa.find() 查看所有集合 db.createUser( { user: &quot;yapi&quot;, pwd: &quot;df123456&quot;, roles: [ { role: &quot;dbOwner&quot;, db: &quot;yapi&quot; } ] } ) db.system.users.find() db.system.users.remove({}) systemctl restart mongod /etc/mongodb.conf 远程访问 net: bind_ip = 0.0.0.0 port = 27017 security: authorization: enabled javascriptEnabled: false db.auth(&#39;yapi&#39;,&#39;df123456&#39;)GitLab方案1docker run \ --publish 1443:443 --publish 180:80 --publish 122:22 \ --name gitlab \ --volume /usr/local/docker/gitlab/config:/etc/gitlab \ --volume /usr/local/docker/gitlab/logs:/var/log/gitlab \ --volume /usr/local/docker/gitlab/data:/var/opt/gitlab \ gitlab/gitlab-ce方案2vim /usr/local/docker/gitlab/docker-compose.yml version: &#39;3&#39; services: gitlab: image: &#39;twang2218/gitlab-ce-zh:10.5&#39; restart: always hostname: &#39;192.168.2.5&#39; container_name: gitlab environment: TZ: &#39;Asia/Shanghai&#39; GITLAB_OMNIBUS_CONFIG: | external_url &#39;http://192.168.2.5:180&#39; gitlab_rails[&#39;gitlab_shell_ssh_port&#39;] = 2222 unicorn[&#39;port&#39;] = 8888 nginx[&#39;listen_port&#39;] = 8080 ports: - &#39;180:8080&#39; - &#39;8443:443&#39; - &#39;2222:22&#39; volumes: - /usr/local/docker/gitlab/config:/etc/gitlab - /usr/local/docker/gitlab/data:/var/opt/gitlab - /usr/local/docker/gitlab/logs:/var/log/gitlab ERROR: error while removing network: network gitlab_default id e3f084651bcc6b6ca5d5b7fb122d0ef3aba108292989441abc82f14343fea827 has active endpoints docker network inspect gitlab_default docker network disconnect -f gitlab_default gitlab docker-compose down --remove-orphans docker-compose logs -ft gitlab 配置邮箱 vim /usr/local/docker/gitlab/config/gitlab.rb gitlab_rails[&#39;smtp_enable&#39;] = true gitlab_rails[&#39;smtp_address&#39;] = &quot;smtp.163.com&quot; gitlab_rails[&#39;smtp_port&#39;] = 25 gitlab_rails[&#39;smtp_user_name&#39;] = &quot;m15806204096@163.com&quot; gitlab_rails[&#39;smtp_password&#39;] = &quot;codewj123456&quot; gitlab_rails[&#39;smtp_domain&#39;] = &quot;163.com&quot; gitlab_rails[&#39;smtp_authentication&#39;] = &quot;login&quot; gitlab_rails[&#39;smtp_enable_starttls_auto&#39;] = true gitlab_rails[&#39;smtp_tls&#39;] = false gitlab_rails[&#39;gitlab_email_from&#39;] = &quot;m15806204096@163.com&quot; user[&quot;git_user_email&quot;] = &quot;m15806204096@163.com&quot;root/123456 管理区域-&gt;设置-&gt;开启注册 注册时发送确认邮件docker-compose restart新增ssh密钥 ssh-keygen -t rsa -C “15806204096@163.com“,将.ssh的公钥加入Gitlab的SSH密钥访问 http://192.168.2.5:180/ root 12345678 方案3安装gityum –y install git cd /usr/local mkdir git cd git git init --bare learngit.git useradd git passwd git chown -R git:git learngit.git vi /etc/passwd git:x:1000:1000::/home/git:/usr/bin/git-shell 复制客户端的ssh-keygen -t rsa -C &quot;你的邮箱&quot; 获得的id_rsa.pub公钥到/root/.ssh/authorized_keys和/root/.ssh/authorized_keys gitignore无效的解决方案 git rm -r --cached . git add . git commit -m &#39;.gitignore&#39; git push origin master *.cache *.cache.lock *.iml *.log **/target **/logs .idea **/.project **/.settingsgitlab安装git config --global http.sslVerify false yum -y install curl policycoreutils openssh-server openssh-clients postfix systemctl start sshd systemctl start postfix systemctl enable sshd systemctl enable postfix curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash yum -y install gitlab-ce 太慢的话使用清华的源，yum makecache再install vim /etc/yum.repos.d/gitlab_gitlab-ce.repo [gitlab-ce] name=gitlab-ce baseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el6 repo_gpgcheck=0 gpgcheck=0 enabled=1 gpgkey=https://packages.gitlab.com/gpg.key mkdir -p /etc/gitlab/ssl openssl genrsa -out &quot;/etc/gitlab/ssl/gitlab.example.com.key&quot; 2048 openssl req -new -key &quot;/etc/gitlab/ssl/gitlab.example.com.key&quot; -out &quot;/etc/gitlab/ssl/gitlab.example.com.csr&quot; Country Name (2 letter code) [XX]:cn State or Province Name (full name) []:bj Locality Name (eg, city) (Default City]:bj Organization Name (eg, company) [Default Company Ltd]: Organizational Unit Name (eg, section) []: Common Name (eg, your name or your server&#39;s hostname) []:gitlab.example.com Email Address (]:admin@example.com Please enter the following &#39;extra&#39; attributes to be sent with your certificate request A challenge password [):123456 An optional company name []:GitLab基本配置openssl x509 -req -days 3650 -in &quot;/etc/gitlab/ssl/gitlab.example.com.csr&quot; -signkey &quot;/etc/gitlab/ssl/gitlab.example.com.key&quot; -out &quot;/etc/gitlab/ssl/gitlab.example.com.crt&quot; openssl dhparam -out /etc/gitlab/ssl/dhparams.pem 2048 chmod 600 /etc/gitlab/ssl/* vim /etc/gitlab/gitlab.rb 将external_url &#39;http://gitlab.example.com&#39;的http修改为https 将# nginx[&#39;redirect_http_to_https&#39;] = false的注释去掉，修改为nginx[&#39;redirect_http_to_https&#39;] = true 将# nginx[&#39;ssl_certificate&#39;] = &quot;/etc/gitlab/ssl/#{node[&#39;fqdn&#39;]}.crt&quot;修改为# nginx[&#39;ssl_certificate&#39;] = &quot;/etc/gitlab/ssl/gitlab.example.com.crt&quot; 将# nginx[&#39;ssl_certificate_key&#39;] = &quot;/etc/gitlab/ssl/#{node[&#39;fqdn&#39;]}.key&quot;修改为# nginx[&#39;ssl_certificate_key&#39;] = &quot;/etc/gitlab/ssl/gitlab.example.com.key&quot; 将# nginx[&#39;ssl_dhparam&#39;] = nil 修改为# nginx[&#39;ssl_dhparam&#39;] = &quot;/etc/gitlab/ssl/dhparams.pem&quot; gitlab-ctl reconfigure vim /var/opt/gitlab/nginx/conf/gitlab-http.conf 在server_name下添加如下配置内容：rewrite ^(.*)$ https://$host$1 permanent; 重启gitlab，使配置生效,gitlab-ctl restart，如遇到访问错误直接等待启动完成 修改本地hosts文件 将gitlab服务器的地址添加 gitlab.example.com 初始化时修改管理员密码，root 12345678 git -c http.sslVerify=false clone https://gitlab.example.com/root/test-repo.git git add . #git config --global user.email &quot;admin@example.com&quot; #git config --global user.name &quot;admin&quot; git commit -m &#39;init&#39; git -c http.sslVerify=false pull origin master git -c http.sslVerify=false push origin master https://gitlab.example.com/admin/system_info 查看系统资源状态值 https://gitlab.example.com/admin/logs 其中application.log记录了git用户的记录，production.log实时查看所有的访问链接 https://gitlab.example.com/admin/users/new 创建用户https://gitlab.example.com/root/test-repo/project_members 修改指定项目的成员，在项目的manage access中，修改登录密码 rm -rf test-repo/ git -c http.sslVerify=false clone https://gitlab.example.com/root/test-repo.git dev 12345678 cd test-repo/ git checkout -b release-1.0 git add . git commit -m &#39;release-1.0&#39; git -c http.sslVerify=false push origin release-1.0 dev登录后create merge request lead登录将受到release-1.0的merge申请，点击merge后可以填写comment并提交 Skywalkingmkdir /data2/skywalking vim docker-compose.yml version: &#39;3.3&#39; services: elasticsearch: image: wutang/elasticsearch-shanghai-zone:6.3.2 container_name: elasticsearch restart: always ports: - 191:9200 - 192:9300 environment: cluster.name: elasticsearch docker-compose up -d https://mirrors.huaweicloud.com/apache/incubator/skywalking/6.0.0-beta/apache-skywalking-apm-incubating-6.0.0-beta.tar.gz tar zxf apache-skywalking-apm-incubating-6.0.0-beta.tar.gz cd apache-skywalking-apm-incubating vim apache-skywalking-apm-bin/config/application.yml 注释h2,打开es并修改clusterNodes地址 # h2: # driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource} # url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db} # user: ${SW_STORAGE_H2_USER:sa} elasticsearch: nameSpace: ${SW_NAMESPACE:&quot;&quot;} clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:192.168.2.7:191} indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2} indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:2000} # Execute the bulk every 2000 requests bulkSize: ${SW_STORAGE_ES_BULK_SIZE:20} # flush the bulk every 20mb flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests apache-skywalking-apm-incubating/webapp/webapp.yml port 193 ./apache-skywalking-apm-incubating/bin/startup.shSentinelcd /data2/ &amp;&amp; git clone https://github.com/alibaba/Sentinel.git cd Sentinel/ mvn clean package -DskipTests cd sentinel-dashboard/target/ nohup java -Dserver.port=190 -Dcsp.sentinel.dashboard.server=localhost:190 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar &amp;安装黑体字体yum -y install fontconfig fc-list :lang=zh cd /usr/share/fonts &amp;&amp; mkdir chinese chmod -R 755 /usr/share/fonts/chinese cd chinese/ &amp;&amp; rz simhei.ttf fs_GB2312.ttf fzxbsjt.ttf yum -y install ttmkfdir ttmkfdir -e /usr/share/X11/fonts/encodings/encodings.dir vim /etc/fonts/fonts.conf &lt;dir&gt;/usr/share/fonts&lt;/dir&gt; &lt;dir&gt;/usr/share/fonts/chinese&lt;/dir&gt; &lt;dir&gt;/usr/share/X11/fonts/Type1&lt;/dir&gt; &lt;dir&gt;/usr/share/X11/fonts/TTF&lt;/dir&gt; &lt;dir&gt;/usr/local/share/fonts&lt;/dir&gt; &lt;dir prefix=&quot;xdg&quot;&gt;fonts&lt;/dir&gt; &lt;!-- the following element will be removed in the future --&gt; &lt;dir&gt;~/.fonts&lt;/dir&gt; fc-cache fc-list :lang=zh RocketMQmkdir /data2/RocketMQ vim docker-compose.yml version: &#39;3.5&#39; services: rmqnamesrv: image: foxiswho/rocketmq:server container_name: rmqnamesrv ports: - 9876:9876 volumes: - ./data/logs:/opt/logs - ./data/store:/opt/store networks: rmq: aliases: - rmqnamesrv rmqbroker: image: foxiswho/rocketmq:broker container_name: rmqbroker ports: - 10909:10909 - 10911:10911 volumes: - ./data/logs:/opt/logs - ./data/store:/opt/store - ./data/brokerconf/broker.conf:/etc/rocketmq/broker.conf environment: NAMESRV_ADDR: &quot;rmqnamesrv:9876&quot; JAVA_OPTS: &quot; -Duser.home=/opt&quot; JAVA_OPT_EXT: &quot;-server -Xms128m -Xmx128m -Xmn128m&quot; command: mqbroker -c /etc/rocketmq/broker.conf depends_on: - rmqnamesrv networks: rmq: aliases: - rmqbroker rmqconsole: image: styletang/rocketmq-console-ng container_name: rmqconsole ports: - 8088:8080 environment: JAVA_OPTS: &quot;-Drocketmq.namesrv.addr=rmqnamesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false&quot; depends_on: - rmqnamesrv networks: rmq: aliases: - rmqconsole networks: rmq: name: rmq driver: bridge vim /data2/RocketMQ/data/brokerconf/broker.conf brokerClusterName=DefaultCluster brokerName=broker-a brokerId=0 brokerIP1=192.168.2.7 defaultTopicQueueNums=4 autoCreateTopicEnable=true autoCreateSubscriptionGroup=true listenPort=10911 deleteWhen=04 fileReservedTime=120 mapedFileSizeCommitLog=1073741824 mapedFileSizeConsumeQueue=300000 diskMaxUsedSpaceRatio=88 maxMessageSize=65536 brokerRole=ASYNC_MASTER flushDiskType=ASYNC_FLUSH docker-compose up -d docker-compose down http://192.168.2.7:8088/RabbitMQdocker-compose.yml version: &#39;3&#39; services: rabbitmq: image: rabbitmq:management-alpine container_name: rabbitmq environment: - RABBITMQ_DEFAULT_USER=admin - RABBITMQ_DEFAULT_PASS=admin restart: always ports: - &quot;15672:15672&quot; - &quot;5672:5672&quot; logging: driver: &quot;json-file&quot; options: max-size: &quot;200k&quot; max-file: &quot;10&quot;docker-compose up -d,5672为rabbitmq的服务端口，15672为rabbitmq的web管理界面端口。 jenkinsrpm -qa|grep jenkins 搜索已安装 rpm -e --nodeps jenkins-2.83-1.1.noarch find / -name jenkins*|xargs rm -rf rpm -ivh jdk-8u171-linux-x64.rpm 安装java http://mirrors.jenkins.io/redhat/jenkins-2.180-1.1.noarch.rpm rpm -ivh jenkins-2.180-1.1.noarch.rpm 安装jenkins新版本 vi /etc/sysconfig/jenkins JENKINS_USER=&quot;root&quot; JENKINS_PORT=&quot;181&quot; vim /etc/rc.d/init.d/jenkins 修改candidates /data2/jdk/bin/java systemctl daemon-reload systemctl restart jenkins http://192.168.2.7:181 cat /var/lib/jenkins/secrets/initialAdminPassword 初始密码串并安装默认的插件 vim /var/lib/jenkins/hudson.model.UpdateCenter.xml 必须在填写完密码后修改 改https为http或者改为http://mirror.xmission.com/jenkins/updates/update-center.json systemctl restart jenkins 若页面空白/var/lib/jenkins/config.xml &lt;authorizationStrategy class=&quot;hudson.security.AuthorizationStrategy$Unsecured&quot;/&gt; &lt;securityRealm class=&quot;hudson.security.SecurityRealm$None&quot;/&gt; 系统管理-全局工具配置:/data2/maven /data2/jdk /data2/maven/conf/settings.xml 安装插件：Maven Integration，GitHub plugin，Git plugin 新建任务时，丢弃旧的构建，保持构建的天数3，保持构建的最大个数5 定时删除none的docker镜像手动执行：docker rmi $(docker images -f “dangling=true” -q)定时构建语法： 每天凌晨2:00跑一次 H 2 * * * 每隔5分钟构建一次 H/5 * * * * 每两小时构建一次 H H/2 * * * 每天中午12点定时构建一次 H 12 * * * 或0 12 * * *（0这种写法也被H替代了） 每天下午18点前定时构建一次 H 18 * * * 每15分钟构建一次 H/15 * * * * 或*/5 * * * *(这种方式已经被第一种替代了，jenkins也不推荐这种写法了) 周六到周日，18点-23点，三小时构建一次 H 18-23/3 * * 6-7 shell脚本 echo ---------------Stop-Rm-Containers...------------------ docker stop `docker ps -a| grep expire | awk &#39;{print $1}&#39;`|xargs docker rm echo ---------------Clear-Images...------------------ clearImagesList=$(docker images -f &quot;dangling=true&quot; -q) if [ ! -n &quot;$clearImagesList&quot; ]; then echo &quot;no images need clean up.&quot; else docker rmi $(docker images -f &quot;dangling=true&quot; -q) echo &quot;clear success.&quot; fi cron 每隔5秒执行一次：*/5 * * * * ? 每隔1分钟执行一次：0 */1 * * * ? 每天23点执行一次：0 0 23 * * ? 每天凌晨1点执行一次：0 0 1 * * ? 每月1号凌晨1点执行一次：0 0 1 1 * ? 每月最后一天23点执行一次：0 0 23 L * ? 每周星期天凌晨1点实行一次：0 0 1 ? * L 在26分、29分、33分执行一次：0 26,29,33 * * * ? 每天的0点、13点、18点、21点都执行一次：0 0 0,13,18,21 * * ? toptop -d 2 -c -p 123456 //每隔2秒显示pid是12345的进程的资源使用情况，并显式该进程启动的命令行参数 M —根据驻留内存大小进行排序 P —根据CPU使用百分比大小进行排序 T —根据时间/累计时间进行排序 c —切换显示命令名称和完整命令行 t —切换显示进程和CPU信息 m —切换显示内存信息 l —切换显示平均负载和启动时间信息 o —改变显示项目的顺序 f —从当前显示中添加或删除项目 S —切换到累计模式 s —改变两次刷新之间的延迟时间。系统将提示用户输入新的时间，单位为s。如果有小数，就换算成ms。 q —退出top程序 i —忽略闲置和僵尸进程。这是一个开关式的命令 k —终止一个进程更改显示内容通过 f 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z 即可显示或隐藏对应的列，最后按回车键确定。 Exampletop - 01:06:48 up 1:22, 1 user, load average: 0.06, 0.60, 0.48 Tasks: 29 total, 1 running, 28 sleeping, 0 stopped, 0 zombie Cpu(s): 0.3% us, 1.0% sy, 0.0% ni, 98.7% id, 0.0% wa, 0.0% hi, 0.0% si Mem: 191272k total, 173656k used, 17616k free, 22052k buffers Swap: 192772k total, 0k used, 192772k free, 123988k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND root 16 0 7976 2456 1980 S 0.7 1.3 0:11.03 sshd root 16 0 2128 980 796 R 0.7 0.5 0:02.72 top root 16 0 1992 632 544 S 0.0 0.3 0:00.90 init root 34 19 0 0 0 S 0.0 0.0 0:00.00 ksoftirqd/0 root RT 0 0 0 0 S 0.0 0.0 0:00.00 watchdog/0 统计信息区前五行是系统整体的统计信息。第一行是任务队列信息，同 uptime 命令的执行结果。其内容如下： 01:06:48 当前时间 up 1:22 系统运行时间，格式为时:分 1 user 当前登录用户数 load average: 0.06, 0.60, 0.48 系统负载，即任务队列的平均长度。三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。 第二、三行为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下： total 进程总数 running 正在运行的进程数 sleeping 睡眠的进程数 stopped 停止的进程数 zombie 僵尸进程数 Cpu(s): 0.3% us 用户空间占用CPU百分比 1.0% sy 内核空间占用CPU百分比 0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比 98.7% id 空闲CPU百分比 0.0% wa 等待输入输出的CPU时间百分比 0.0%hi：硬件CPU中断占用百分比 0.0%si：软中断占用百分比 0.0%st：虚拟机占用百分比最后两行为内存信息。内容如下： Mem: 191272k total 物理内存总量 173656k used 使用的物理内存总量 17616k free 空闲内存总量 22052k buffers 用作内核缓存的内存量 Swap: 192772k total 交换区总量 0k used 使用的交换区总量 192772k free 空闲交换区总量 123988k cached 缓冲的交换区总量,内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，该数值即为这些内容已存在于内存中的交换区的大小,相应的内存再次被换出时可不必再对交换区写入。进程信息区统计信息区域的下方显示了各个进程的详细信息。首先来认识一下各列的含义 序号 列名 含义 a PID 进程id b PPID 父进程id c RUSER Real user name d UID 进程所有者的用户id e USER 进程所有者的用户名 f GROUP 进程所有者的组名 g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? h PR 优先级 i NI nice值。负值表示高优先级，正值表示低优先级 j P 最后使用的CPU，仅在多CPU环境下有意义 k %CPU 上次更新到现在的CPU时间占用百分比 l TIME 进程使用的CPU时间总计，单位秒 m TIME+ 进程使用的CPU时间总计，单位1/100秒 n %MEM 进程使用的物理内存百分比 o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r CODE 可执行代码占用的物理内存大小，单位kb s DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb t SHR 共享内存大小，单位kb u nFLT 页面错误次数 v nDRT 最后一次写入到现在，被修改过的页面数。 w S 进程状态(D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程) x COMMAND 命令名/命令行 y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 z Flags 任务标志，参考 sched.h VIRT：virtual memory usage。Virtual这个词很神，一般解释是：virtual adj.虚的, 实质的,[物]有效的, 事实上的。到底是虚的还是实的？让Google给Define之后，将就明白一点，就是这东西还是非物质的，但是有效果的，不发生在真实世界的，发生在软件世界的等等。这个内存使用就是一个应用占有的地址空间，只是要应用程序要求的，就全算在这里，而不管它真的用了没有。写程序怕出错，又不在乎占用的时候，多开点内存也是很正常的。RES：resident memory usage。常驻内存。这个值就是该应用程序真的使用的内存，但还有两个小问题，一是有些东西可能放在交换盘上了（SWAP），二是有些内存可能是共享的。SHR：shared memory。共享内存。就是说这一块内存空间有可能也被其他应用程序使用着；而Virt － Shr似乎就是这个程序所要求的并且没有共享的内存空间。DATA：数据占用的内存。如果top没有显示，按f键可以显示出来。这一块是真正的该程序要求的数据空间，是真正在运行中要使用的。SHR是一个潜在的可能会被共享的数字，如果只开一个程序，也没有别人共同使用它；VIRT里面的可能性更多，比如它可能计算了被许多X的库所共享的内存；RES应该是比较准确的，但不含有交换出去的空间；但基本可以说RES是程序当前使用的内存量。 Q1:-bash: fork: Cannot allocate memory进程数满了,echo 1000000 &gt; /proc/sys/kernel/pid_max,echo “kernel.pid_max=1000000 “ &gt;&gt; /etc/sysctl.conf,sysctl -ptop:展示进程视图，监控服务器进程数值默认进入top时，各进程是按照CPU的占用量来排序的,-f查看实际内存占用量]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>jenkins</tag>
        <tag>sentinel</tag>
        <tag>linux</tag>
        <tag>rocketmq</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker]]></title>
    <url>%2F2019%2F08%2F20%2Fdocker%2F</url>
    <content type="text"><![CDATA[docker安装使用及镜像制作 安装docker基本配置yum install -y vim lrzsz git setenforce 0 vim /etc/selinux/config SELINUX=disabled systemctl stop firewalld systemctl disable firewalldcentosyum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine -y 移除旧版本 rm -rf /etc/systemd/system/docker.service.d /var/lib/docker /var/run/docker yum install -y yum-utils device-mapper-persistent-data lvm2 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum makecache fast yum list docker-ce --showduplicates | sort -r yum install -y docker-ce-18.09.5 systemctl restart docker yum update -y nss curl libcurl curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose docker-compose --versionubuntuapt-get update apt-get -y install apt-transport-https ca-certificates curl software-properties-common # step 2: 安装GPG证书 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - # Step 3: 写入软件源信息 sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; # Step 4: 更新并安装 Docker-CE sudo apt-get -y update sudo apt-get -y install docker-ce # 安装指定版本的Docker-CE: # Step 1: 查找Docker-CE的版本: # apt-cache madison docker-ce # docker-ce | 17.03.1~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages # docker-ce | 17.03.0~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages # Step 2: 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.1~ce-0~ubuntu-xenial) # sudo apt-get -y install docker-ce=[VERSION]Docker配置及基本使用vim ~/.bashrc alias dops=&#39;docker ps --format &quot;table {{.ID}}\t{{.Names}}\t{{.Image}}\t&quot;&#39; alias dopsa=&#39;docker ps -a --format &quot;table {{.ID}}\t{{.Names}}\t{{.Image}}\t&quot;&#39; alias dolo=&#39;docker logs -ft&#39; vim /etc/docker/daemon.json { &quot;registry-mirrors&quot;: [&quot;https://3gki6pei.mirror.aliyuncs.com&quot;], &quot;storage-driver&quot;:&quot;devicemapper&quot;, &quot;insecure-registries&quot;:[&quot;192.168.2.7:5000&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opt&quot;: { &quot;max-size&quot;: &quot;10m&quot;, &quot;max-file&quot;: &quot;10&quot; } } systemctl daemon-reload systemctl restart docker.service service docker stop 删除所有镜像 rm -rf /var/lib/docker systemctl start docker.service --restart=always 设置重启docker自动启动容器 docker update --restart=always es-node2 docker run -itd myimage:test /bin/bash -c &quot;命令1;命令2&quot; 启动容器自动执行命令 docker export registry &gt; /home/registry.tar 将容器打成tar包 scp /home/registry.tar root@192.168.2.7:/root cat ~/registry.tar | docker import - registry/2.5 将tar包打成镜像 docker save jdk1.8 &gt; /home/java.tar.gz 导出镜像 docker load &lt; /home/java.tar.gz 导入镜像 docker stop sentine1 | xargs docker rm docker rm -f redis-slave1|true docker logs -f -t --since=&quot;2018-02-08&quot; --tail=100 CONTAINER_ID 查看指定时间后的日志，只显示最后100行 docker logs --since 30m CONTAINER_ID 查看最近30分钟的日志 /var/lib/docker/containers/contain id 下rm -rf *.log 删除docker日志 进入https://homenew.console.aliyun.com/ 搜索容器镜像服务，进入侧边栏的镜像加速器获取自己的Docker加速镜像地址。 安装Registry私服方案1docker run -di --name=registry -p 5000:5000 docker.io/registry访问 http://192.168.2.5:5000/v2/_catalog 方案2vim config.yml version: 0.1 log: fields: service: registry storage: cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registry delete: enabled: true http: addr: :5000 headers: X-Content-Type-Options: [nosniff] health: storagedriver: enabled: true interval: 10s threshold: 3 vim /usr/local/docker/registry/docker-compose.yml version: &#39;3.1&#39; services: registry: image: registry restart: always container_name: registry ports: - 5000:5000 volumes: - ./data:/var/lib/registry - ./config.yml:/etc/docker/registry/config.yml frontend: image: konradkleine/docker-registry-frontend:v2 container_name: registry-frontend restart: always ports: - 184:80 volumes: - ./certs/frontend.crt:/etc/apache2/server.crt:ro - ./certs/frontend.key:/etc/apache2/server.key:ro environment: - ENV_DOCKER_REGISTRY_HOST=192.168.2.5 - ENV_DOCKER_REGISTRY_PORT=5000使用docker-compose up -d启动registry容器，http://192.168.2.5:184/ 访问私有镜像库 curl -I -H &quot;Accept: application/vnd.docker.distribution.manifest.v2+json&quot; 192.168.2.7:5000/v2/ht-micro-record-service-user/manifests/1.0.0-SNAPSHOT 查看镜像Etag curl -I -H &quot;Accept: application/vnd.docker.distribution.manifest.v2+json&quot; 192.168.2.5:5000/v2/ht-micro-record-commons/manifests/1.0.0-SNAPSHOT 查看镜像Etag curl -i -X DELETE 192.168.2.5:5000/v2/codewj-redis-cluster/manifests/sha256:d6d6fad1ac67310ee34adbaa72986c6b233bd713906013961c722ecb10a049e5 删除codewj-redis-cluster:latest镜像 curl -I -X DELETE http://192.168.2.7:5000/v2/ht-micro-record-service-user/manifests/sha256:a6d4e02fa593f0ae30476bda8d992dcb0fc2341e6fef85a9887444b5e4b75a04 删除user镜像 docker exec -it registry registry garbage-collect /etc/docker/registry/config.yml 垃圾回收blob docker exec registry rm -rf /var/lib/registry/docker/registry/v2/repositories/codewj-redis-cluster 强制删除 docker exec registry rm -rf /var/lib/registry/docker/registry/v2/repositories/ht-micro-record-service-user 强制删除JDK镜像制作环境配置vim /etc/docker/daemon.json { &quot;registry-mirrors&quot;: [&quot;https://3gki6pei.mirror.aliyuncs.com&quot;], &quot;storage-driver&quot;:&quot;devicemapper&quot;, &quot;insecure-registries&quot;:[&quot;192.168.2.7:5000&quot;] } vim /lib/systemd/system/docker.service 开放访问 ExecStart 新增 -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock \ systemctl daemon-reload systemctl restart docker docker start registry制作镜像mkdir -p /usr/local/dockerjdk8 &amp;&amp; cd /usr/local/dockerjdk8sz jdk-8u60-linux-x64.tar.gz 传到该目录下vim Dockerfile #依赖镜像名称和ID FROM docker.io/centos:7 #指定镜像创建者信息 MAINTAINER OneJane #切换工作目录 WORKDIR /usr RUN mkdir /usr/local/java #ADD 是相对路径jar,把java添加到容器中 ADD jdk-8u60-linux-x64.tar.gz /usr/local/java/ ENV LANG en_US.UTF-8 #配置java环境变量 ENV JAVA_HOME /usr/local/java/jdk1.8.0_60 ENV JRE_HOME $JAVA_HOME/jre ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH ENV PATH $JAVA_HOME/bin:$PATHdocker build -t='onejane-jdk1.8' .安装中文环境 yum -y install fontconfig fc-list :lang=zh cd /usr/share/fonts &amp;&amp; mkdir chinese chmod -R 755 /usr/share/fonts/chinese cd chinese/ &amp;&amp; rz simhei.ttf fs_GB2312.ttf fzxbsjt.ttf yum -y install ttmkfdir ttmkfdir -e /usr/share/X11/fonts/encodings/encodings.dir vim /etc/fonts/fonts.conf &lt;dir&gt;/usr/share/fonts&lt;/dir&gt; &lt;dir&gt;/usr/share/fonts/chinese&lt;/dir&gt; &lt;dir&gt;/usr/share/X11/fonts/Type1&lt;/dir&gt; &lt;dir&gt;/usr/share/X11/fonts/TTF&lt;/dir&gt; &lt;dir&gt;/usr/local/share/fonts&lt;/dir&gt; &lt;dir prefix=&quot;xdg&quot;&gt;fonts&lt;/dir&gt; &lt;!-- the following element will be removed in the future --&gt; &lt;dir&gt;~/.fonts&lt;/dir&gt; fc-cache fc-list :lang=zh 上传到私服docker commit 6ea1085dfc2a pxc:v1.0 将镜像保存本地 docker commit -m &quot;容器说明&quot; -a &quot;OneJane&quot; [CONTAINER ID] [给新的镜像命名] 将容器打包成镜像 docker tag onejane-jdk1.8 192.168.2.7:5000/onejane-jdk1.8 docker push 192.168.2.7:5000/onejane-jdk1.8 将镜像推到仓库Redis镜像制作vim entrypoint.sh #!/bin/sh #只作用于当前进程,不作用于其创建的子进程 set -e #$0--Shell本身的文件名 $1--第一个参数 $@--所有参数列表 # allow the container to be started with `--user` if [ &quot;$1&quot; = &#39;redis-server&#39; -a &quot;$(id -u)&quot; = &#39;0&#39; ]; then sed -i &#39;s/REDIS_PORT/&#39;$REDIS_PORT&#39;/g&#39; /usr/local/etc/redis.conf chown -R redis . #改变当前文件所有者 exec gosu redis &quot;$0&quot; &quot;$@&quot; #gosu是sudo轻量级”替代品” fi exec &quot;$@&quot; vim redis.conf #端口 port REDIS_PORT #开启集群 cluster-enabled yes #配置文件 cluster-config-file nodes.conf cluster-node-timeout 5000 #更新操作后进行日志记录 appendonly yes #设置主服务的连接密码 # masterauth #设置从服务的连接密码 # requirepassvi Dockerfile #基础镜像 FROM redis #修复时区 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN echo &#39;Asia/Shanghai&#39; &gt;/etc/timezone #环境变量 ENV REDIS_PORT 8000 #ENV REDIS_PORT_NODE 18000 #暴露变量 EXPOSE $REDIS_PORT #EXPOSE $REDIS_PORT_NODE #复制 COPY entrypoint.sh /usr/local/bin/ COPY redis.conf /usr/local/etc/ #for config rewrite RUN chmod 777 /usr/local/etc/redis.conf RUN chmod +x /usr/local/bin/entrypoint.sh #入口 ENTRYPOINT [&quot;/usr/local/bin/entrypoint.sh&quot;] #命令 CMD [&quot;redis-server&quot;, &quot;/usr/local/etc/redis.conf&quot;]docker build -t codewj/redis-cluster:1.0 . 上传到私服docker tag codewj/redis-cluster:1.0 192.168.2.5:5000/codewj-redis-cluster docker push 192.168.2.5:5000/codewj-redis-cluster上传到docker hubdocker login 输入https://hub.docker.com/账户密码 docker tag onejane-jdk1.8 onejane/onejane-jdk1.8 docker push onejane/onejane-jdk1.8:latest docker logout Redisdocker run -d –privileged=true -p 6379:6379 -v $PWD/redis.conf:/etc/redis/redis.conf -v $PWD/data:/data –name redis redis redis-server /etc/redis/redis.conf –appendonly yeshttp://download.redis.io/redis-stable/redis.conf bind 0.0.0.0 port 6379 daemonize no appendonly yes protected-mode no 手动部署 mvn clean install deploy docker:build -DpushImage docker run -di --name=panchip -v /tmp/saas:/tmp/saas --net=host 192.168.2.7:5000/panchip:1.0.0-SNAPSHOT docker export panchip &gt; /home/panchip.tar 容器打成tar cat panchip.tar | docker import - panchip tar转镜像Q1 Failed to start Docker Application Container Engine的解决办法 vim /etc/docker/daemon.json vim /usr/lib/systemd/system/docker.service]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab+jenkins+docker]]></title>
    <url>%2F2019%2F08%2F20%2FGitLab-jenkins-docker%2F</url>
    <content type="text"><![CDATA[GitLab+jenkins+docker自动发布 http://192.168.2.5:181/view/all/newJob 构建一个maven项目ht-micro-record-service-note-provider添加jenkins主机公钥到gitlab，并生成全局凭据1.Username with password root/1234562.SSH Username with private key Enter Directly,添加gitlab服务器私钥 parent.relativePath修改为，发布单个服务时设定一个空值将始终从仓库中获取，不从本地路径获取 vim /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix://var/run/docker.sock 基础服务&lt;build&gt; &lt;finalName&gt;ht-micro-record-commons-domain&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;!--被依赖的包加该配置--&gt; &lt;mainClass&gt;com.ht.micro.record.commons.CommonsMapperApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 微服务提供者 &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://192.168.2.7:182/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; &lt;build&gt; &lt;finalName&gt;ht-micro-record-service-note-consumer&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--被其他服务引用必须增加该配置--&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;mainClass&gt;com.ht.micro.record.service.consumer.NoteConsumerServiceApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- docker的maven插件，官网 https://github.com/spotify/docker-maven-plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;192.168.2.5:5000/${project.artifactId}:${project.version}&lt;/imageName&gt; &lt;baseImage&gt;jdk1.8&lt;/baseImage&gt; &lt;entryPoint&gt;[&quot;java&quot;, &quot;-jar&quot;,&quot;/${project.build.finalName}.jar&quot;]&lt;/entryPoint&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;dockerHost&gt;http://192.168.2.5:2375&lt;/dockerHost&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; Jenkinsexport app_name=”ht-micro-record-service-note-consumer”export app_version=”1.0.0-SNAPSHOT”sh /usr/local/docker/ht-micro-record/deploy.sh #!/bin/bash # 判断项目是否在运行 DATE=`date +%s` last_app_name=`echo &quot;$app_name-expire-$DATE&quot;` if docker ps | grep $app_name;then docker stop $app_name docker rename $app_name $last_app_name docker run -di --name=$app_name -v /opt/template/:/opt/template/ -e JAVA_OPTS=&#39;-Xmx3g -Xms3g&#39; --net=host 192.168.2.7:5000/$app_name:$app_version # 判断项目是否存在 elif docker ps -a | grep $app_name;then docker start $app_name else docker run -di --name=$app_name -v /opt/template/:/opt/template/ -e JAVA_OPTS=&#39;-Xmx3g -Xms3g&#39; --net=host 192.168.2.7:5000/$app_name:$app_version fi vim /usr/local/bin/dokill docker images | grep -e $*|awk &#39;{print $3}&#39;|sed &#39;2p&#39;|xargs docker rmi chmod a+x /usr/local/bin/dokill dokill tensquare_recruit Build时必须clean，项目名必须小写 Q1:Failed to execute goal on project : Could not resolve dependencies for 对最父级项目clean install，再最子项目clean install Q2: repackage failed: Unable to find main class -&gt; [Help 1] 构建显示缺少主类 @SpringBootApplication public class CommonsApplication { public static void main(String[] args) { } }分布式构建192.168.2.7:181 访问jenkins，系统管理-节点管理-新建节点ln -s /data2/jdk/bin/java /usr/bin/java 分布式部署通过网关负载时，需要重新部署网关gateway服务。 免密登陆192.168.2.7 ssh-keygen -t rsa ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.2.5 ssh root@192.168.2.5 新建jenkins任务192.168.2.7ht-micro-record-service-user-2.5vim /data2/deploy2.5.sh #!/bin/bash echo &quot;------------------服务信息---------------&quot; echo $1 $2 echo &quot;------------------开始部署---------------&quot; ssh root@192.168.2.5 sh /data2/deploy.sh $1 $2 192.168.2.5vim /data2/deploy.sh #!/bin/bash # 判断项目是否在运行 if docker ps | grep $1;then docker stop $1|xargs docker rm docker rmi 192.168.2.7:5000/$1:$2 # 判断项目是否存在 elif docker ps -a | grep $1;then docker rm $1 docker rmi 192.168.2.7:5000/$1:$2 elif docker images|grep $1;then docker rmi 192.168.2.7:5000/$1:$2 fi docker run -di --name=$1 -v /opt/:/opt/ -e JAVA_OPTS=&#39;-Xmx3g -Xms3g&#39; --net=host 192.168.2.7:5000/$1:$2]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>jenkins</tag>
        <tag>docker</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch]]></title>
    <url>%2F2019%2F08%2F20%2FElasticSearch%2F</url>
    <content type="text"><![CDATA[ElasticSearch基础及数据迁移 https://github.com/medcl/esm-abandoned/releases/download/v0.4.1/linux64-esm--2019.4.20.tar.gz 基本原理 写：发送一个请求到协调节点，对document进行hash路由到对应由primary shard的节点上，处理请求并同步到replica shard，协调节点检测同步后返回相应给客户端。读：发送一个请求到协调节点，根据doc id对document进行hash路由到对应node，通过随机轮询算法从primary和replica的shard中随机选择让读请求负载均衡，返回document给协调节点后给客户端。一个索引拆分为多个shard存储部分数据，每个shard由primary shard和replica shard组成，primary写入将同步到replica，类似kafka的partition副本。保证高可用。Es多个节点选举一个为master，管理和切换主副shard，若宕机则重新选举，并将宕机节点primary shard身份转移到其他机器的replica shard。重启将修改原primary为replica同步数据。 每个在文档上执行的写操作，包括删除，都会使其版本增加。 真正的删除时机： deleting a document doesn’t immediately remove the document from disk; it just marks it as deleted. Elasticsearch will clean up deleted documents in the background as you continue to index more data. 删除索引是会立即释放空间的，不存在所谓的“标记”逻辑。 删除文档的时候，是将新文档写入，同时将旧文档标记为已删除。 磁盘空间是否释放取决于新旧文档是否在同一个segment file里面，因此ES后台的segment merge在合并segment file的过程中有可能触发旧文档的物理删除。但因为一个shard可能会有上百个segment file，还是有很大几率新旧文档存在于不同的segment里而无法物理删除。想要手动释放空间，只能是定期做一下force merge，并且将max_num_segments设置为1。多机器集群搭建 vi /etc/sysctl.conf vm.max_map_count=262144 sysctl -pNode1 192.168.2.5最好挂载到大磁盘上 mkdir /usr/local/docker/ElasticSearch/data -p &amp;&amp; chmod 777 /usr/local/docker/ElasticSearch/data mkdir /usr/local/docker/ElasticSearch/config/ -p &amp;&amp; cd /usr/local/docker/ElasticSearch/config/ vi es.yml cluster.name: elasticsearch-cluster node.name: es-node1 network.bind_host: 0.0.0.0 network.publish_host: 192.168.2.5 http.port: 1800 transport.tcp.port: 1801 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; node.master: true node.data: true discovery.zen.ping.unicast.hosts: [&quot;192.168.2.5:1801&quot;,&quot;192.168.2.6:1801&quot;] # 可配置多个 discovery.zen.minimum_master_nodes: 1 修改/usr/share/elasticsearch/config/jvm.options中-Xms10g -Xmx10g docker run -d -v /data3/elasticsearch/config/jvm.options:/usr/share/elasticsearch/config/jvm.options -v /data3/elasticsearch/config/es.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /data3/elasticsearch/data:/usr/share/elasticsearch/data --name es-node1 --net host --privileged elasticsearch:6.6.0 docker exec -it es-node1 bash elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.6.0/elasticsearch-analysis-ik-6.6.0.zip docker restart es-node1Node2 192.168.2.6mkdir /usr/local/docker/ElasticSearch/data -p &amp;&amp; chmod 777 /usr/local/docker/ElasticSearch/data mkdir /usr/local/docker/ElasticSearch/config/ -p &amp;&amp; cd /usr/local/docker/ElasticSearch/config/ vi es.yml cluster.name: elasticsearch-cluster node.name: es-node2 network.bind_host: 0.0.0.0 network.publish_host: 192.168.2.6 http.port: 1800 transport.tcp.port: 1801 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; node.master: true node.data: true discovery.zen.ping.unicast.hosts: [&quot;192.168.2.5:1801&quot;,&quot;192.168.2.6:1801&quot;] # 可配置多个 discovery.zen.minimum_master_nodes: 1 # 集群最少需要有两个 node , 才能保证既可以不脑裂, 又可以高可用 修改/usr/share/elasticsearch/config/jvm.options中-Xms10g -Xmx10g docker run -d -v /data2/elasticsearch/config/jvm.options:/usr/share/elasticsearch/config/jvm.options -v /data2/elasticsearch/config/es.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /data3/elasticsearch/data:/usr/share/elasticsearch/data --name es-node2 --net host --privileged elasticsearch:6.6.0 docker exec -it es-node2 bash elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.6.0/elasticsearch-analysis-ik-6.6.0.zip docker restart es-node2http://192.168.2.5:1800/_cat/plugins 查看插件信息 esm数据迁移./esm -s http://192.168.2.6:9200 -d http://192.168.2.7:1800 -x p_answer_handle_alarm -w=5 -b=10 -c 10000; 同步数据 curl 192.168.2.7:1800/_cat/indices?v 查看所有索引信息 常见参数使用： ./esm -s http://192.168.2.6:9200 -d http://192.168.2.7:1800 -x t_record_analyze -y record_test --copy_settings --copy_mappings --shards=4 -w=5 -b=10 -c 10000;数据迁移完美方案通过两集群都建立同样索引，保证mappings和settings一致，再同步数据 curl -XGET 192.168.2.7:1800/p_answer_handle_alarm 查看索引信息 curl -XGET 192.168.2.7:1800/p_answer_handle_alarm/_search; curl -XGET http://192.168.2.5:1800/record_test/_settings?pretty 查看settings信息 PUT http://192.168.2.5:1800/record_set/_settings 修改副本数，片的信息分又重新做了调整，同curl -XPUT &#39;192.168.2.7:1800/record_set/_settings&#39; -d&#39;{&quot;index&quot;:{&quot;number_of_replicas&quot;:1}}&#39; { &quot;index&quot;:{ &quot;number_of_replicas&quot;:1 } } index.blocks.read_only //设置为 true 使索引和索引元数据为只读，false 为允许写入和元数据更改。 index.blocks.read // 设置为 true 可禁用对索引的读取操作 index.blocks.write //设置为 true 可禁用对索引的写入操作。 index.blocks.metadata // 设置为 true 可禁用索引元数据的读取和写入 index.mapping.total_fields.limit //1000 防止字段过多引起崩溃 curl -XGET http://192.168.2.5:1800/record_set/_mappings?pretty 查看mappings信息 http://192.168.2.5:1800/_cluster/settings?pretty 查看settings信息 PUT http:///192.168.2.5:1800/record_set/doc/_mapping 新增字段 { &quot;properties&quot;: { &quot;col1&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: false } } } PUT 192.168.2.6:9200/test 新建索引 { &quot;mappings&quot;:{ &quot;doc&quot;:{ &quot;properties&quot;:{ &quot;jjbh&quot;:{&quot;type&quot;: &quot;keyword&quot;,&quot;index&quot;: &quot;true&quot;}, &quot;bccljg&quot;:{&quot;type&quot;:&quot;text&quot;,&quot;index&quot;:&quot;true&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;,&quot;search_analyzer&quot;: &quot;ik_max_word&quot;}, &quot;bjnr&quot;:{&quot;type&quot;: &quot;text&quot;,&quot;index&quot;: &quot;true&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;,&quot;search_analyzer&quot;:&quot;ik_max_word&quot;}, &quot;cjlb&quot;:{&quot;type&quot;: &quot;keyword&quot;,&quot;index&quot;: &quot;false&quot;} } } } } 192.168.2.7:1800/test/doc/{_id} 插入数据，_id不加默认随机字符串 { &quot;jjbh&quot;: &quot;4654132465&quot;, &quot;bccljg&quot;: &quot;我是一名合格的程序员&quot;, &quot;bjnr&quot;: &quot;今天天气真的好啊&quot;, &quot;cjlb&quot;: &quot;天上地下飞禽走兽&quot; } 192.168.2.7:1800/test/doc/{_id} 更新 { &quot;jjbh&quot;: &quot;11&quot;, &quot;bccljg&quot;: &quot;我是一名合格的程序员&quot;, &quot;bjnr&quot;: &quot;今天天气真的好啊&quot;, &quot;cjlb&quot;: &quot;天上地下飞禽走兽&quot; } PUT 192.168.2.5:1800/test 新建索引 { &quot;mappings&quot;:{ &quot;doc&quot;:{ &quot;properties&quot;:{ &quot;jjbh&quot;:{&quot;type&quot;: &quot;keyword&quot;,&quot;index&quot;: &quot;true&quot;}, &quot;bccljg&quot;:{&quot;type&quot;:&quot;text&quot;,&quot;index&quot;:&quot;true&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;,&quot;search_analyzer&quot;: &quot;ik_max_word&quot;}, &quot;bjnr&quot;:{&quot;type&quot;: &quot;text&quot;,&quot;index&quot;: &quot;true&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;,&quot;search_analyzer&quot;:&quot;ik_max_word&quot;}, &quot;cjlb&quot;:{&quot;type&quot;: &quot;keyword&quot;,&quot;index&quot;: &quot;false&quot;} } } } } ./esm -s http://192.168.2.6:9200 -d http://192.168.2.5:1800 -x test -y test -w=5 -b=10 -c 10000; 同步数据 POST 192.168.2.5:1800/test/doc 全局加ik分词器 { &quot;settings&quot;:{ &quot;analysis&quot;:{ &quot;analyzer&quot;:{ &quot;ik&quot;:{&quot;tokenizer&quot;: &quot;ik_max_keyword&quot;} } } } } POST 192.168.2.5:1800/test/doc/_search 查询 POST 192.168.2.5:1800/test/doc/_delete_by_query 删除 精确查询/删除 { &quot;query&quot;:{ &quot;term&quot;:{ &quot;bccljg.keyword&quot;:&quot;我是一名合格的程序员&quot; } } } 模糊查询/删除 { &quot;query&quot;: { &quot;match&quot;: { &quot;bccljg&quot;: &quot;合格&quot; } } } 正则模糊查询 { &quot;query&quot;: { &quot;regexp&quot;: { &quot;bccljg.keyword&quot;: &quot;.*我是.*&quot; } } } 文本开头查询 { &quot;query&quot;: { &quot;prefix&quot;: { &quot;bccljg.keyword&quot;: &quot;我是&quot; } } } Q1:若数据结果不一致，可能是磁盘不足。Q2:”caused_by”:{“type”:”search_context_missing_exception”,”reason”:”No search context found for id [69218326]”}} ./esm -s http://192.168.2.6:9200 -d http://192.168.2.7:1800 -x t_record_analyze -y t_record_analyze -w=5 -b=10 -c 10000; ./esm -s http://192.168.2.6:9200 -d http://192.168.2.7:1800 -x t_neo4j_data -y t_neo4j_data -w=5 -b=10 -c 10000; ./esm -s http://192.168.2.6:9200 -d http://192.168.2.7:1800 -x t_data_analysis -y t_data_analysis -w=5 -b=10 -c 10000; ./esm -s http://192.168.2.6:9200 -d http://192.168.2.7:1800 -x t_cjjxq -y t_cjjxq -w=5 -b=10 -c 10000; ./esm -s http://192.168.1.225:9200 -d http://192.168.2.7:1800 -x t_alarm_analysis_result -y t_alarm_analysis_result -w=5 -b=10 -c 10000; ./esm -s http://192.168.2.6:9200 -d http://192.168.2.7:1800 -x p_answer_handle_alarm -y p_answer_handle_alarm -t=10m -w=5 -b=10 -c 5000; ./esm -s http://192.168.2.6:9200 -d http://192.168.2.7:1800 -x city_answer_handle_alarm -y city_answer_handle_alarm -t=10m -w=5 -b=10 -c 5000;scroll time 超时，设置-t参数，默认是1m 同步后的数据结构 logstashES单节点安装docker run -di --name=tensquare_es -p 9200:9200 -p 9300:9300 --privileged docker.io/elasticsearch:6.6.0 docker cp tensquare_es:/usr/share/elasticsearch/config/elasticsearch.yml /usr/share/elasticsearch.yml docker stop tensquare_es docker rm tensquare_es vim /usr/share/elasticsearch.yml transport.host: 0.0.0.0 docker restart tensquare_es vim /etc/security/limits.conf * soft nofile 65536 * hard nofile 65536 nofile是单个进程允许打开的最大文件个数 soft nofile 是软限制 hard nofile是硬限制 vim /etc/sysctl.conf vm.max_map_count=655360 sysctl -p 修改内核参数立马生效 我们需要以文件挂载的 方式创建容器才行，这样我们就可以通过修改宿主机中的某个文件来实现对容器内配置 文件的修改 docker run -di --name=tensquare_es -p 9200:9200 -p 9300:9300 --privileged -v /usr/share/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml docker.io/elasticsearch:6.6.0 docker restart tensquare_es 才可以远程连接使用 同步mysqlhttps://www.elastic.co/cn/downloads/past-releases/logstash-6-6-0tar zxf logstash-6.6.0.tar.gz &amp;&amp; cd /root/logstash-6.6.0/binmkdir mysql &amp;&amp; cd mysql &amp;&amp; vim mysql.conf jdbc { # mysql jdbc connection string to our backup databse jdbc_connection_string =&gt; &quot;jdbc:mysql://192.168.2.5:185/ht_micro_record?characterEncoding=UTF8&quot; # the user we wish to excute our statement as jdbc_user =&gt; &quot;root&quot; jdbc_password =&gt; &quot;123456&quot; # the path to our downloaded jdbc driver jdbc_driver_library =&gt; &quot;/root/logstash-6.6.0/bin/mysql/mysql-connector-java-5.1.47.jar&quot; # the name of the driver class for mysql jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot; jdbc_paging_enabled =&gt; &quot;true&quot; jdbc_page_size =&gt; &quot;500000&quot; #以下对应着要执行的sql的绝对路径。 #statement_filepath =&gt; &quot;select id,title,content from tb_article&quot; statement =&gt; &quot;SELECT id,applyer_police_num,applyer_name FROM t_apply&quot; #定时字段 各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新（测试结果，不同的话请留言指出） schedule =&gt; &quot;* * * * *&quot; } } output { elasticsearch { #ESIP地址与端口 hosts =&gt; &quot;192.168.3.224:9200&quot; #ES索引名称（自己定义的） index =&gt; &quot;t_apply&quot; #自增ID编号 document_id =&gt; &quot;%{id}&quot; document_type =&gt; &quot;article&quot; } stdout { #以JSON格式输出 codec =&gt; json_lines } } nohup ./logstash -f mysql/mysql.conf &amp; 同步es/root/logstash-6.6.0/bin/es/es.conf input { elasticsearch { hosts =&gt; [&quot;192.168.2.5:1800&quot;,&quot;192.168.2.7:1800&quot;] index =&gt; &quot;t_neo4j_data&quot; size =&gt; 1000 scroll =&gt; &quot;1m&quot; codec =&gt; &quot;json&quot; docinfo =&gt; true } } filter { mutate { remove_field =&gt; [&quot;@timestamp&quot;, &quot;@version&quot;] } } output { elasticsearch { hosts =&gt; [&quot;192.168.3.224:9200&quot;] index =&gt; &quot;%{[@metadata][_index]}&quot; } stdout { codec =&gt; rubydebug { metadata =&gt; true } } } ./logstash -f es/es.conf –path.data ../logs/ elasticdumpwget https://nodejs.org/dist/v8.11.2/node-v8.11.2-linux-x64.tar.xz tar xf node-v8.11.2-linux-x64.tar.xz -C /usr/local/ ln -s /usr/local/node-v8.11.2-linux-x64/bin/npm /usr/local/bin/npm ln -s /usr/local/node-v8.11.2-linux-x64/bin/node /usr/local/bin/node npm install -g cnpm --registry=https://registry.npm.taobao.org ln -s /usr/local/node-v8.11.2-linux-x64/bin/cnpm /usr/local/bin/cnpm cnpm init -f cnpm install elasticdump cd node_modules/elasticdump/bin ./elasticdump \ --input=http://192.168.2.6:9200/t_record_analyze \ --output=http://192.168.3.224:9200/t_record_analyze \ --type=analyzer ./elasticdump \ --input=http://192.168.2.6:9200/t_record_analyze \ --output=http://192.168.3.224:9200/t_record_analyze \ --type=mapping ./elasticdump \ --input=http://192.168.2.6:9200/t_record_analyze \ --output=http://192.168.3.224:9200/t_record_analyze \ --type=data ./elasticdump \ --input=http://192.168.2.6:9200:9200/t_record_analyze \ --output=data.json \ --searchBody &#39;{&quot;query&quot;:{&quot;term&quot;:{&quot;username&quot;: &quot;admin&quot;}}} ./elasticdump \ --input=./data.json \ --output=http://192.168.2.7:1800整合springboot父pom &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt;子pom &lt;!--elasticsearch--&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.java.dev.jna&lt;/groupId&gt; &lt;artifactId&gt;jna&lt;/artifactId&gt; &lt;!-- &lt;version&gt;3.0.9&lt;/version&gt; --&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/dependency&gt;配置文件bootstrap.yml es: nodes: 192.168.2.5:1800,192.168.2.7:1800 host: 192.168.2.6,192.168.2.7 port: 1801,1801 types: doc clusterName: elasticsearch-cluster #笔录分析库 blDbName: t_record_analyze #接警信息库 jjDbName: p_answer_alarm #处警信息库 cjDbName: p_handle_alarm #警情分析结果信息库 jqfxDbName: t_alarm_analysis_result #标准化分析 cjjxqDbName: t_cjjxq #接处警整合库 jcjDbName: p_answer_handle_alarm #警情分析 daDbName: t_data_analysis #警情结果表(neo4j使用) neo4jData: t_neo4j_data #市局接处警表 cityDbName: city_answer_handle_alarm配置类com/ht/micro/record/service/dubbo/provider/utils/EsConfig.java @Service public class EsConfig { @Value(&quot;${es.nodes}&quot;) private String nodes; @Value(&quot;${es.host}&quot;) private String host; @Value(&quot;${es.port}&quot;) private String port; @Value(&quot;${es.blDbName}&quot;) private String blDbName; @Value(&quot;${es.jjDbName}&quot;) private String jjDbName; @Value(&quot;${es.cjDbName}&quot;) private String cjDbName; @Value(&quot;${es.jqfxDbName}&quot;) private String jqfxDbName; @Value(&quot;${es.clusterName}&quot;) private String clusterName; @Value(&quot;${es.jjDbName}&quot;) private String answerDbName; @Value(&quot;${es.cjDbName}&quot;) private String handleDbName; @Value(&quot;${es.cjjxqDbName}&quot;) private String cjjxqDbName; @Value(&quot;${es.jcjDbName}&quot;) private String jcjDbName; @Value(&quot;${es.daDbName}&quot;) private String daDbName; @Value(&quot;${es.daDbName}&quot;) private String fxDbName; @Value(&quot;${es.types}&quot;) private String types; @Value(&quot;${es.neo4jData}&quot;) private String neo4jData; @Value(&quot;${es.cityDbName}&quot;) private String cityDbName; } 配置类 com/ht/micro/record/service/dubbo/provider/utils/ElasticClientSingleton.java @Service public class ElasticClientSingleton { protected final Logger logger = LoggerFactory.getLogger(ElasticClientSingleton.class); private AtomicInteger atomicPass = new AtomicInteger(); // 0 未初始化, 1 已初始化 private TransportClient transportClient; private BulkRequestBuilder bulkRequest; public synchronized void init(EsConfig esConfig) { try { String ipArray = esConfig.getHost(); String portArray = esConfig.getPort(); String cluster = esConfig.getClusterName(); Settings settings = Settings.builder() .put(&quot;cluster.name&quot;, cluster) //连接的集群名 .put(&quot;client.transport.ignore_cluster_name&quot;, true) .put(&quot;client.transport.sniff&quot;, false)//如果集群名不对，也能连接 .build(); transportClient = new PreBuiltTransportClient(settings); String[] ips = ipArray.split(&quot;,&quot;); String[] ports = portArray.split(&quot;,&quot;); for (int i = 0; i &lt; ips.length; i++) { transportClient.addTransportAddress(new TransportAddress(InetAddress.getByName(ips[i]), Integer .parseInt(ports[i]))); } atomicPass.set(1); } catch (Exception e) { e.printStackTrace(); logger.error(e.getMessage()); atomicPass.set(0); destroy(); } } public void destroy() { if (transportClient != null) { transportClient.close(); transportClient = null; } } public BulkRequestBuilder getBulkRequest(EsConfig esConfig) { if (atomicPass.get() == 0) { // 初始化 init(esConfig); } bulkRequest = transportClient.prepareBulk(); return bulkRequest; } public TransportClient getTransportClient(EsConfig esConfig) { if (atomicPass.get() == 0) { // 初始化 init(esConfig); } return transportClient; } }配置类 com/ht/micro/record/service/dubbo/provider/utils/ElasticClient.java @Service public class ElasticClient { @Autowired private EsConfig esConfig; private static final Logger logger = LoggerFactory.getLogger(ElasticClient.class); private static BulkRequestBuilder bulkRequest; @Autowired private ElasticClientSingleton elasticClientSingleton; @PostConstruct public void init() { bulkRequest = elasticClientSingleton.getBulkRequest(esConfig); } public static String postRequest(String url, String query) { RestTemplate restTemplate = new RestTemplate(); MediaType type = MediaType.parseMediaType(&quot;application/json; charset=UTF-8&quot;); HttpHeaders headers = new HttpHeaders(); headers.setContentType(type); headers.add(&quot;Accept&quot;, MediaType.APPLICATION_JSON.toString()); HttpEntity&lt;String&gt; formEntity = new HttpEntity&lt;String&gt;(query, headers); String result = restTemplate.postForObject(url, formEntity, String.class); return result; } /** * action 提交操作 */ // public void action() { // int reqSize = bulkRequest.numberOfActions(); // //读不到数据了，默认已经全部读取 // if (reqSize == 0) { // bulkRequest.request().requests().clear(); // } // bulkRequest.setTimeout(new TimeValue(1000 * 60 * 5)); //超时30秒 // BulkResponse bulkResponse = bulkRequest.execute().actionGet(); // //持久化异常 // if (bulkResponse.hasFailures()) { // logger.error(bulkResponse.buildFailureMessage()); // bulkRequest.request().requests().clear(); // } // logger.info(&quot;import over....&quot; + bulkResponse.getItems().length); // } }测试com/ht/micro/record/service/dubbo/provider/controller/ProviderController.java @Autowired ElasticClientSingleton elasticClientSingleton; @Autowired EsConfig esConfig; @GetMapping(&quot;/test&quot;) public void test(){ SearchRequestBuilder srb = elasticClientSingleton.getTransportClient(esConfig).prepareSearch(esConfig.getCityDbName()).setTypes(esConfig.getTypes()); TermsQueryBuilder cjbsBuilder = QueryBuilders.termsQuery(&quot;cjbs&quot;, &quot;4&quot;); SearchResponse weekSearchResponse = srb.setQuery(cjbsBuilder).execute().actionGet(); System.out.println(weekSearchResponse.getHits().getTotalHits()); } ElasticSearch-SQL使用sql操作elasticsearch https://github.com/NLPchina/elasticsearch-sqlhttps://artifacts.elastic.co/maven/org/elasticsearch/client/x-pack-transport/6.6.0/x-pack-transport-6.6.0.jar 在github上查找相关案例，需要相关的jar并没有找到，后去elasticsearch-sql-6.6.0.0.zip插件包中找到elasticsearch-sql-6.6.0.0.jar，启动测试程序 Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org/elasticsearch/xpack/client/PreBuiltXPackTransportClient at com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:686) at com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:632) at com.alibaba.druid.pool.ElasticSearchDruidDataSource.init(ElasticSearchDruidDataSource.java:579) at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:930) at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:926) at com.ht.micro.record.service.dubbo.provider.controller.Test.main(Test.java:20) Caused by: java.lang.ClassNotFoundException: org.elasticsearch.xpack.client.PreBuiltXPackTransportClient at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 6 more x-pack-transportx-pack-core后继续报错，陆续加入x-pack-core，unboundid-ldapsdk，bcpkix-jdk15on，bcprov-jdk15on等依赖才跑通流程。 安装elasticsearch-sqldocker exec -it es-node1 bash elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.6.0.0/elasticsearch-sql-6.6.0.0.zip docker restart es-node1 本地安装jarmvn install:install-file -DgroupId=org.elasticsearch.plugin -DartifactId=x-pack-core -Dversion=6.6.0 -Dpackaging=jar -Dfile=x-pack-core-6.6.0.jarmvn install:install-file -DgroupId=org.elasticsearch.client -DartifactId=x-pack-transport -Dversion=6.6.0 -Dpackaging=jar -Dfile=x-pack-transport-6.6.0.jarmvn install:install-file -DgroupId=org.nlpcn -DartifactId=elasticsearch-sql -Dversion=6.6.0.0 -Dpackaging=jar -Dfile=elasticsearch-sql-6.6.0.0.jar 引入依赖&lt;dependency&gt; &lt;groupId&gt;org.nlpcn&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-sql&lt;/artifactId&gt; &lt;version&gt;6.6.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.15&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-client&lt;/artifactId&gt; &lt;version&gt;6.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;6.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;6.6.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.elasticsearch.plugin&lt;/groupId&gt; &lt;artifactId&gt;transport-netty4-client&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;elasticsearch-rest-client&lt;/artifactId&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.plugin&lt;/groupId&gt; &lt;artifactId&gt;transport-netty4-client&lt;/artifactId&gt; &lt;version&gt;6.6.0&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.unboundid&lt;/groupId&gt; &lt;artifactId&gt;unboundid-ldapsdk&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcprov-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.58&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.58&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;x-pack-transport&lt;/artifactId&gt; &lt;version&gt;6.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.plugin&lt;/groupId&gt; &lt;artifactId&gt;x-pack-core&lt;/artifactId&gt; &lt;version&gt;6.6.0&lt;/version&gt; &lt;/dependency&gt; 测试@RunWith(SpringRunner.class) @SpringBootTest(classes={DubboProviderApplication .class})// 指定启动类 public class ElasticSearchSql { @Test public void testselect() throws Exception { Properties properties = new Properties(); properties.put(&quot;url&quot;, &quot;jdbc:elasticsearch://192.168.2.7:1801,192.168.2.5:1801/&quot;); properties.put(PROP_CONNECTIONPROPERTIES, &quot;client.transport.ignore_cluster_name=true&quot;); DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties); dds.setInitialSize(1); Connection connection = dds.getConnection(); String sql2 = &quot;select * FROM t_word_freq limit 10&quot;; PreparedStatement ps = connection.prepareStatement(sql2); ResultSet resultSet = ps.executeQuery(); while (resultSet.next()) { //sql对应输出 System.out.println(resultSet.getString(&quot;jjbh&quot;) ); } ps.close(); connection.close(); dds.close(); } } 由于springboot启动时自动加载druid autoconfigration,而低版本druid配合springboot2.x报错ClassNotFoundException Log4j2Filter，需要手动exclude druid包 &lt;dependency&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-commons-service&lt;/artifactId&gt; &lt;version&gt;${project.parent.version}&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.16&lt;/version&gt; &lt;/dependency&gt; Q1:重启服务 停止所有index服务 执行curl -XPUT $url/_cluster/settings?pretty -d ‘{“transient” : {“cluster.routing.allocation.enable” : “none”}}’ 执行curl -XPOST $url/_flush/synced?pretty 重启ES集群 等待集群分片全部分配成功，执行curl -XPUT $url/_cluster/settings?pretty -d ‘{“transient” : {“cluster.routing.allocation.enable” : “all”}}’ 开启所有index服务 PUT http://192.168.2.7:1800/_cluster/settings 禁止分片分配。这一步阻止 Elasticsearch 再平衡缺失的分片，直到你告诉它可以进行了。 { &quot;transient&quot; : { &quot;cluster.routing.allocation.enable&quot; : &quot;none&quot; } }启动完毕后PUT http://192.168.2.7:1800/_cluster/settings 重启分片分配 { &quot;transient&quot; : { &quot;cluster.routing.allocation.enable&quot; : &quot;all&quot; } }Q2Elasticsearch默认安装后设置的内存是1GB，这是远远不够用于生产环境的。有两种方式修改Elasticsearch的堆内存： 设置环境变量：export ES_HEAP_SIZE=10g 在es启动时会读取该变量； 启动时作为参数传递给es： ./bin/elasticsearch -Xmx10g -Xms10gQ3 operations are blocked on license expiration. All data operations (read and curl -XPOST -u elastic:changeme &#39;http://192.168.2.5:1800/_xpack/license/start_basic?acknowledge=true&#39; -H &quot;Content-Type: application/json&quot; -d @one-jane-b9ac97b5-0b80-4d0d-9f1d-363b6fb3ce3c-v5.json]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>springboot</tag>
        <tag>elastisearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-Cluster]]></title>
    <url>%2F2019%2F08%2F20%2FRedis-Cluster%2F</url>
    <content type="text"><![CDATA[redis-cluster集群搭建使用 支撑多个master node，每个master挂载多个slave，master写对应slave读，每个master都有slave节点，若挂掉则将某个slave转为master。与相比Sentinel（哨兵）实现的高可用，集群（cluster）更多的是强调数据的分片或者是节点的伸缩性，如果在集群的主节点上加入对应的从节点，集群还可以自动故障转移。主从复制： 通过把这个RDB文件或AOF文件传给slave服务器，slave服务器重新加载RDB文件，来实现复制的功能！当建立一个从服务器后，从服务器会想主服务器发送一个SYNC的命令，主服务器接收到SYNC命令之后会执行BGSAVE，然后保存到RDB文件，然后发送到从服务器！收到RDB文件然后就载入到内存！ Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点 集群中所有master参与,如果半数以上master节点与master节点通信超过(cluster-node-timeout),认为当前master节点挂掉.如果集群任意master挂掉,且当前master没有slave.集群进入fail状态,也可以理解成集群的slot映射[0-16383]不完成时进入fail状态如果集群超过半数以上master挂掉，无论是否有slave集群进入fail状态. Sentinel和Cluster区别 Redis-Sentinel(哨兵模式)是Redis官方推荐的高可用性(HA)解决方案，当用Redis做Master-slave的高可用方案时，假如master宕机了，Redis本身(包括它的很多客户端)都没有实现自动进行主备切换，而Redis-sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能进行自动切换。 Redis-Cluster当遇到单机内存、并发、流量等瓶颈时，可以采用Cluster架构达到负载均衡的目的。分布式集群首要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整个数据的一个子集。 多机集群redis-cluster，也叫分布式redis集群，可以有多个master，数据分片分布在这些master上。systemctl stop firewalld.servicesystemctl disable firewalld.service 192.168.2.5vim /usr/local/docker/redis/docker-compose.yml version: &#39;3&#39; services: redis1: image: publicisworldwide/redis-cluster container_name: redis1 network_mode: host restart: always volumes: - ./8001/data:/data environment: - REDIS_PORT=8001 redis2: image: publicisworldwide/redis-cluster container_name: redis2 network_mode: host restart: always volumes: - ./8002/data:/data environment: - REDIS_PORT=8002 redis3: image: publicisworldwide/redis-cluster container_name: redis3 network_mode: host restart: always volumes: - ./8003/data:/data environment: - REDIS_PORT=8003docker-compose up -d 192.168.2.7vim /usr/local/docker/redis/docker-compose.yml version: &#39;3&#39; services: redis1: image: publicisworldwide/redis-cluster network_mode: host container_name: redis4 restart: always volumes: - ./8004/data:/data environment: - REDIS_PORT=8004 redis2: image: publicisworldwide/redis-cluster network_mode: host container_name: redis5 restart: always volumes: - ./8005/data:/data environment: - REDIS_PORT=8005 redis3: image: publicisworldwide/redis-cluster network_mode: host container_name: redis6 restart: always volumes: - ./8006/data:/data environment: - REDIS_PORT=8006docker-compose up -d 启动方式直接启动docker run --rm -it inem0o/redis-trib create --replicas 1 192.168.2.5:8001 192.168.2.5:8002 192.168.2.5:8003 192.168.2.7:8004 192.168.2.7:8005 192.168.2.7:8006 docker exec -it redis1 redis-cli -h 127.0.0.1 -p 8001 -c set a 100 cluster info cluster nodes 自动指定master slave 指定masterdocker run --rm -it inem0o/redis-trib create 192.168.2.5:8001 192.168.2.5:8002 192.168.2.5:8003 docker run --rm -it inem0o/redis-trib add-node --slave --master-id 84c3b7ecbc4933e1368a6927f26c79ecc76810b3 192.168.2.7:8004 192.168.2.5:8001 docker run --rm -it inem0o/redis-trib add-node --slave --master-id 716f11f2971e9494183937abd61f7a4baf0b3959 192.168.2.7:8005 192.168.2.5:8002 docker run --rm -it inem0o/redis-trib add-node --slave --master-id c93060613a8f1531c82b97d97eeac402048f0b25 192.168.2.7:8006 192.168.2.5:8003 docker run --rm -it inem0o/redis-trib info 192.168.2.5:8001 docker run --rm -it inem0o/redis-trib help 若同一台宿主机，不想使用host模式同一台，也可以把network_mode去掉，但就要加ports映射。redis-cluster的节点端口共分为2种，一种是节点提供服务的端口，如6379；一种是节点间通信的端口，固定格式为：10000+6379。 docker-compose.yml version: &#39;3&#39; services: redis1: image: publicisworldwide/redis-cluster restart: always volumes: - /app/app/redis/8001/data:/data environment: - REDIS_PORT=8001 ports: - &#39;8001:8001&#39; - &#39;18001:18001&#39; redis2: image: publicisworldwide/redis-cluster restart: always volumes: - /app/app/redis/8002/data:/data environment: - REDIS_PORT=8002 ports: - &#39;8002:8002&#39; - &#39;18002:18002&#39; redis3: image: publicisworldwide/redis-cluster restart: always volumes: - /app/app/redis/8003/data:/data environment: - REDIS_PORT=8003 ports: - &#39;8003:8003&#39; - &#39;18003:18003&#39; redis4: image: publicisworldwide/redis-cluster restart: always volumes: - /app/app/redis/8004/data:/data environment: - REDIS_PORT=8004 ports: - &#39;8004:8004&#39; - &#39;18004:18004&#39; redis5: image: publicisworldwide/redis-cluster restart: always volumes: - /app/app/redis/8005/data:/data environment: - REDIS_PORT=8005 ports: - &#39;8005:8005&#39; - &#39;18005:18005&#39; redis6: image: publicisworldwide/redis-cluster restart: always volumes: - /app/app/redis/8006/data:/data environment: - REDIS_PORT=8006 ports: - &#39;8006:8006&#39; - &#39;18006:18006&#39;自定义Redis集群制作redis镜像vim entrypoint.sh #!/bin/sh #只作用于当前进程,不作用于其创建的子进程 set -e #$0--Shell本身的文件名 $1--第一个参数 $@--所有参数列表 # allow the container to be started with `--user` if [ &quot;$1&quot; = &#39;redis-server&#39; -a &quot;$(id -u)&quot; = &#39;0&#39; ]; then sed -i &#39;s/REDIS_PORT/&#39;$REDIS_PORT&#39;/g&#39; /usr/local/etc/redis.conf chown -R redis . #改变当前文件所有者 exec gosu redis &quot;$0&quot; &quot;$@&quot; #gosu是sudo轻量级”替代品” fi exec &quot;$@&quot;vim redis.conf #端口 port REDIS_PORT #开启集群 cluster-enabled yes #配置文件 cluster-config-file nodes.conf cluster-node-timeout 5000 #更新操作后进行日志记录 appendonly yes #设置主服务的连接密码 # masterauth #设置从服务的连接密码 # requirepassvi Dockerfile #基础镜像 FROM redis #修复时区 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN echo &#39;Asia/Shanghai&#39; &gt;/etc/timezone #环境变量 ENV REDIS_PORT 8000 #ENV REDIS_PORT_NODE 18000 #暴露变量 EXPOSE $REDIS_PORT #EXPOSE $REDIS_PORT_NODE #复制 COPY entrypoint.sh /usr/local/bin/ COPY redis.conf /usr/local/etc/ #for config rewrite RUN chmod 777 /usr/local/etc/redis.conf RUN chmod +x /usr/local/bin/entrypoint.sh #入口 ENTRYPOINT [&quot;/usr/local/bin/entrypoint.sh&quot;] #命令 CMD [&quot;redis-server&quot;, &quot;/usr/local/etc/redis.conf&quot;] docker build -t codewj/redis-cluster:1.0 .docker tag codewj/redis-cluster:1.0 192.168.2.5:5000/codewj-redis-clusterdocker push 192.168.2.5:5000/codewj-redis-cluster 192.168.2.5version: &#39;3&#39; services: redis1: image: 192.168.2.7:5000/onejane-redis-cluster container_name: redis1 network_mode: host restart: always volumes: - ./8001/data:/data environment: - REDIS_PORT=8001 redis2: image: 192.168.2.7:5000/onejane-redis-cluster container_name: redis2 network_mode: host restart: always volumes: - ./8002/data:/data environment: - REDIS_PORT=8002 redis3: image: 192.168.2.7:5000/onejane-redis-cluster container_name: redis3 network_mode: host restart: always volumes: - ./8003/data:/data environment: - REDIS_PORT=8003192.168.2.7version: &#39;3&#39; services: redis1: image: 192.168.2.7:5000/onejane-redis-cluster network_mode: host container_name: redis4 restart: always volumes: - ./8004/data:/data environment: - REDIS_PORT=8004 redis2: image: 192.168.2.7:5000/onejane-redis-cluster network_mode: host container_name: redis5 restart: always volumes: - ./8005/data:/data environment: - REDIS_PORT=8005 redis3: image: 192.168.2.7:5000/onejane-redis-cluster network_mode: host container_name: redis6 restart: always volumes: - ./8006/data:/data environment: - REDIS_PORT=8006]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>redis-cluster</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven]]></title>
    <url>%2F2019%2F08%2F20%2Fmaven%2F</url>
    <content type="text"><![CDATA[maven基本用法 一个GroupId（项目）下面可以有很多个ArtifactId（模块），每个ArtifactId（模块）会有很多个Version（版本），每个Version（版本）一般被Packaging（打包）为jar、war、pom中的一种。 父模块的packaging必须为pom,packaging的默认值为jar module“组织”子模块,基于父模块pom的子模块相对目录名，不是子模块的artifactId 多模块deploy的时候，根据子模块的相互依赖关系整理一个build顺序，然后依次build，独立模块之间根据配置顺序build 子pom 会直接继承 父pom 中声明的属性 父pom 中仅仅使用dependencies 中dependency 依赖的包，会被 子pom 直接继承（不需要显式依赖） 父pom 中仅仅使用plugins 中plugin依赖的插件，会被 子pom 直接继承（不需要显式依赖） 父pom中可以使用dependecyManagement和pluginManagement来统一管理jar包和插件pugin，不会被子pom 直接继承。子pom如果希望继承该包或插件，则需要显式依赖，同时像 等配置项可以不被显式写出，默认从父pom继承,同pluginManagement mvn 命令对应着maven项目生命周期，顺序为compile、test、package、install、depoly，执行其中任一周期，都会把前面周期 统一执行 具有依赖传递性，而不具有依赖传递性 安装jar包到本地 mvn install:install-file -DgroupId=org.csource.fastdfs -DartifactId=fastdfs -Dversion=1.2 -Dpackaging=jar -Dfile=D:\Project\pinyougou\fastDFSdemo\src\main\webapp\WEB-INF\lib\fastdfs_client_v1.20.jar properties&lt;properties&gt; &lt;spring.version&gt;2.5&lt;/spring.version&gt; &lt;/properties&gt; &lt;version&gt;${spring.version}&lt;/version&gt; pluginManagement父 &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; 子 &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; 由于 Maven 内置了 maven-compiler-plugin 与生命周期的绑定，因此子模块就不再需要任何 maven-compiler-plugin 的配置了。 资源打包配置 &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;${project.build.directory}/classes&lt;/targetPath&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.txt&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; dependencyManagement&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.juvenxu.sample&lt;/groupId&gt; &lt;artifactid&gt;sample-dependency-infrastructure&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 优势 Parent的dependencyManagement节点的作用是管理整个项目所需要用到的第三方依赖。只要约定了第三方依赖的坐标（GroupId:ArtifactId:version），后代模块即可通过GroupId:ArtifactId进行依赖的引入。其它元素如 version 和 scope 都能通过继承父 POM 的 dependencyManagement 得到这样能够避免依赖版本的冲突。当然，这里只是进行约定，并不会真正地引用依赖。 依赖统一管理(parent中定义，需要变动dependency版本，只要修改一处即可)； 代码简洁(子model只需要指定groupId、artifactId即可) dependencyManagement只会影响现有依赖的配置，但不会引入依赖，即子model不会继承parent中dependencyManagement所有预定义的depandency，只引入需要的依赖即可，简单说就是“按需引入依赖”或者“按需继承”；因此，在parent中严禁直接使用depandencys预定义依赖，坏处是子model会自动继承depandencys中所有预定义依赖；劣势单继承：maven的继承跟java一样，单继承，也就是说子model中只能出现一个parent标签；parent模块中，dependencyManagement中预定义太多的依赖，造成pom文件过长，而且很乱； 通过父pom的parent继承的方法，只能继承一个parent。实际开发中，用户很可能需要继承自己公司的标准parent配置，这个时候可以使用 scope=import 来实现多继承。 解决：scope=import只能用在dependencyManagement里面,且仅用于type=pom的dependency,要继承多个，可以在dependencyManagement通过非继承的方式来引入这段依赖管理配置，添加依赖scope=import，type=pom &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.3.3.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.test.sample&lt;/groupId&gt; &lt;artifactid&gt;base-parent1&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;自己的项目里面就不需要继承SpringBoot的module了，而可以继承自己项目的module了。 Scope provided 被依赖项目理论上可以参与编译、测试、运行等阶段，相当于compile，但是再打包阶段做了exclude的动作。,servlet-api和jsp-api都是由tomcat等servlet容器负责提供的包,这个 jar 包已由应用服务器提供,这里引入只用于开发,不进行打包 runtime被依赖项目无需参与项目的编译，但是会参与到项目的测试和运行,在编译的时候我们不需要 JDBC API 的 jar 包，而在运行的时候我们才需要 JDBC 驱动包。 compile（默认）被依赖项目需要参与到当前项目的编译，测试，打包，运行等阶段。打包的时候通常会包含被依赖项目。 test 被依赖项目仅仅参与测试相关的工作，包括测试代码的编译，执行,Junit 测试。 system 被依赖项不会从 maven 仓库中查找，而是从本地系统中获取，systemPath 元素用于制定本地系统中 jar 文件的路径发布 &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;!-- ID 名称必须要与 settings.xml 中 Servers 配置的 ID 名称保持一致。--&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://192.168.2.5:182/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://192.168.2.5:182/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; mvn deploy发布到私服,在项目 pom.xml 中设置的版本号添加 SNAPSHOT 标识的都会发布为 SNAPSHOT 版本，没有 SNAPSHOT 标识的都会发布为 RELEASE 版本Nexus 3.0 不支持页面上传，可使用 maven 命令： mvn deploy:deploy-file -DgroupId=com.github.axet -DartifactId=kaptcha -Dversion=0.0.9 -Dpackaging=jar -Dfile=E:\kaptcha-0.0.9.jar -Durl=http://192.168.2.5:182/repository/maven-releases/ -DrepositoryId=nexus-releases 要求jar的pom中的repository.id和settings.xml中一致 上传第三方jarproxy：即你可以设置代理，设置了代理之后，在你的nexus中找不到的依赖就会去配置的代理的地址中找hosted：你可以上传你自己的项目到这里面group：它可以包含前面两个，是一个聚合体。一般用来给客户一个访问nexus的统一地址。 你可以上传私有的项目到hosted，以及配置proxy以获取第三方的依赖（比如可以配置中央仓库的地址）。前面两个都 弄好了之后，在通过group聚合给客户提供统一的访问地址。 settings.xml&lt;server&gt; &lt;id&gt;3rdParty&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt; &lt;/server&gt; &lt;repository&gt; &lt;id&gt;3rdParty&lt;/id&gt; &lt;url&gt;http://192.168.2.7:182/repository/3rdParty/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; mvn deploy:deploy-file -DgroupId=org.nlpcn -DartifactId=elasticsearch-sql -Dversion=6.6.0.0 -Dpackaging=jar -Dfile=elasticsearch-sql-6.6.0.0.jar -Durl=http://192.168.2.7:182/repository/3rdParty/ -DrepositoryId=3rdParty pom.xml &lt;repository&gt; &lt;id&gt;3rdParty&lt;/id&gt; &lt;name&gt;3rdParty Repository&lt;/name&gt; &lt;url&gt;http://192.168.2.7:182/repository/3rdParty/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; parent 必须放在group Id 上]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xxl-job]]></title>
    <url>%2F2019%2F08%2F20%2Fxxl-job%2F</url>
    <content type="text"><![CDATA[springboot整合xxl-job定时器 搭建wget https://github.com/xuxueli/xxl-job/archive/2.1.0.tar.gz tar zxf xxl-job-2.1.0.tar.gz docker cp xxl-job-2.1.0/doc/db/tables_xxl_job.sql ht-mysql-slave:/root/ docker exec -it ht-mysql-slave mysql -u root -p use xxl_job; source /root/tables_xxl_job.sql docker run -d --rm \ -e PARAMS=&quot;--spring.datasource.url=jdbc:mysql://192.168.2.7:186/xxl_job?Unicode=true&amp;characterEncoding=UTF-8 --spring.datasource.username=root --spring.datasource.password=123456&quot; \ -p 183:8080 \ --name xxl-job-admin xuxueli/xxl-job-admin:2.1.0http://192.168.2.7:183/xxl-job-admin/ admin 123456 开发&lt;dependency&gt; &lt;groupId&gt;com.xuxueli&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt;ht-micro-record-service-job/pom.xml &lt;parent&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../ht-micro-record-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;ht-micro-record-service-job&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ht-micro-record-service-job&lt;/name&gt; &lt;url&gt;http://www.htdatacloud.com/&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuxueli&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.code.findbugs&lt;/groupId&gt; &lt;artifactId&gt;jsr305&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.objenesis&lt;/groupId&gt; &lt;artifactId&gt;objenesis&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Projects Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.htdc&lt;/groupId&gt; &lt;artifactId&gt;ht-micro-record-commons-service&lt;/artifactId&gt; &lt;version&gt;${project.parent.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Projects End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;ht.micro.record.service.job.JobServiceApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;application.yaml spring: application: name: ht-micro-record-service-job datasource: druid: url: jdbc:mysql://192.168.2.88:189/ht-micro-record?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 initial-size: 1 min-idle: 1 max-active: 20 test-on-borrow: true driver-class-name: com.mysql.jdbc.Driver cloud: nacos: discovery: server-addr: 192.168.2.5:8848,192.168.2.5:8849,192.168.2.5:8850 config: server-addr: 192.168.2.5:8848,192.168.2.5:8849,192.168.2.5:8850 sentinel: transport: port: 8719 dashboard: 192.168.2.5:190 server: port: 9701 xxl: job: executor: logpath: logs/xxl-job/jobhandler appname: xxl-job-executor port: 9999 logretentiondays: -1 ip: 192.168.3.233 admin: addresses: http://192.168.2.7:183/xxl-job-admin accessTokencom.ht.micro.record.service.job.JobServiceApplication @SpringBootApplication(scanBasePackages = &quot;com.ht.micro.record&quot;) @EnableDiscoveryClient @MapperScan(basePackages = &quot;com.ht.micro.record.commons.mapper&quot;) public class JobServiceApplication { public static void main(String[] args) { SpringApplication.run(JobServiceApplication.class, args); } }com.ht.micro.record.service.job.config.XxlJobConfig @Configuration @ComponentScan(basePackages = &quot;com.ht.micro.record.service.job.handler&quot;) public class XxlJobConfig { private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class); @Value(&quot;${xxl.job.admin.addresses}&quot;) private String adminAddresses; @Value(&quot;${xxl.job.executor.appname}&quot;) private String appName; @Value(&quot;${xxl.job.executor.ip}&quot;) private String ip; @Value(&quot;${xxl.job.executor.port}&quot;) private int port; @Value(&quot;${xxl.job.accessToken}&quot;) private String accessToken; @Value(&quot;${xxl.job.executor.logpath}&quot;) private String logPath; @Value(&quot;${xxl.job.executor.logretentiondays}&quot;) private int logRetentionDays; @Bean(initMethod = &quot;start&quot;, destroyMethod = &quot;destroy&quot;) public XxlJobSpringExecutor xxlJobExecutor() { logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init.&quot;); XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor(); xxlJobSpringExecutor.setAdminAddresses(adminAddresses); xxlJobSpringExecutor.setAppName(appName); xxlJobSpringExecutor.setIp(ip); xxlJobSpringExecutor.setPort(port); xxlJobSpringExecutor.setAccessToken(accessToken); xxlJobSpringExecutor.setLogPath(logPath); xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays); return xxlJobSpringExecutor; } }com.ht.micro.record.service.job.handler.TestJobHandler @JobHandler(value=&quot;testJobHandler&quot;) @Component public class TestJobHandler extends IJobHandler { @Override public ReturnT&lt;String&gt; execute(String param) throws Exception { XxlJobLogger.log(&quot;XXL-JOB, Hello World.&quot;); for (int i = 0; i &lt; 5; i++) { XxlJobLogger.log(&quot;beat at:&quot; + i); TimeUnit.SECONDS.sleep(2); } return SUCCESS; } }]]></content>
      <categories>
        <category>定时器</category>
      </categories>
      <tags>
        <tag>xxl-job</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot2-multi-druid]]></title>
    <url>%2F2019%2F08%2F20%2Fspringboot2-multi-druid%2F</url>
    <content type="text"><![CDATA[基于springboot2+druid实现多数据源 配置application.yml server: port: 10205 spring: datasource: base: #监控统计拦截的filters filters: stat type: com.alibaba.druid.pool.DruidDataSource jdbc-url: jdbc:mysql://192.168.1.250:3306/htbl_test?useUnicode=true&amp;characterEncoding=UTF-8 username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver max-idle: 10 max-wait: 10000 min-idle: 5 initial-size: 5 validation-query: SELECT 1 test-on-borrow: false test-while-idle: true time-between-eviction-runs-millis: 18800 dic: #监控统计拦截的filters filters: stat type: com.alibaba.druid.pool.DruidDataSource jdbc-url: jdbc:mysql://192.168.1.48:3306/ht_nlp?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false username: root password: Sonar@1234 driver-class-name: com.mysql.jdbc.Driver max-idle: 10 max-wait: 10000 min-idle: 5 initial-size: 5 validation-query: SELECT 1 test-on-borrow: false test-while-idle: true time-between-eviction-runs-millis: 18800数据源1配置BaseMybatisConfig @Configuration @MapperScan(basePackages = {&quot;com.ht.micro.record.commons.mapper.baseMapper&quot;}, sqlSessionTemplateRef = &quot;baseSqlSessionTemplate&quot;) public class BaseMybatisConfig { @Value(&quot;${spring.datasource.base.filters}&quot;) String filters; @Value(&quot;${spring.datasource.base.driver-class-name}&quot;) String driverClassName; @Value(&quot;${spring.datasource.base.username}&quot;) String username; @Value(&quot;${spring.datasource.base.password}&quot;) String password; @Value(&quot;${spring.datasource.base.jdbc-url}&quot;) String url; @Bean(name=&quot;baseDataSource&quot;) @Primary//必须加此注解，不然报错，下一个类则不需要添加 spring.datasource @ConfigurationProperties(prefix=&quot;spring.datasource.base&quot;)//prefix值必须是application.properteis中对应属性的前缀 public DataSource baseDataSource() throws SQLException { DruidDataSource druid = new DruidDataSource(); // 监控统计拦截的filters druid.setFilters(filters); // 配置基本属性 druid.setDriverClassName(driverClassName); druid.setUsername(username); druid.setPassword(password); druid.setUrl(url); return druid; } @Bean(name=&quot;baseSqlSessionFactory&quot;) @Primary public SqlSessionFactory baseSqlSessionFactory(@Qualifier(&quot;baseDataSource&quot;)DataSource dataSource)throws Exception{ // 创建Mybatis的连接会话工厂实例 SqlSessionFactoryBean bean=new SqlSessionFactoryBean(); bean.setDataSource(dataSource);//// 设置数据源bean //添加XML目录 ResourcePatternResolver resolver=new PathMatchingResourcePatternResolver(); try{ bean.setMapperLocations(resolver.getResources(&quot;classpath:baseMapper/*Mapper.xml&quot;));//// 设置mapper文件路径 return bean.getObject(); }catch(Exception e){ e.printStackTrace(); throw new RuntimeException(e); } } @Bean(name=&quot;baseSqlSessionTemplate&quot;) @Primary public SqlSessionTemplate baseSqlSessionTemplate(@Qualifier(&quot;baseSqlSessionFactory&quot;)SqlSessionFactory sqlSessionFactory)throws Exception{ SqlSessionTemplate template=new SqlSessionTemplate(sqlSessionFactory);//使用上面配置的Factory return template; } } 数据源2配置@Configuration @MapperScan(basePackages = {&quot;com.ht.micro.record.commons.mapper.dicMapper&quot;}, sqlSessionTemplateRef = &quot;dicSqlSessionTemplate&quot;) public class DicMybatisConfig { @Value(&quot;${spring.datasource.dic.filters}&quot;) String filters; @Value(&quot;${spring.datasource.dic.driver-class-name}&quot;) String driverClassName; @Value(&quot;${spring.datasource.dic.username}&quot;) String username; @Value(&quot;${spring.datasource.dic.password}&quot;) String password; @Value(&quot;${spring.datasource.dic.jdbc-url}&quot;) String url; @Bean(name = &quot;dicDataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.datasource.dic&quot;) public DataSource dicDataSource() throws SQLException { DruidDataSource druid = new DruidDataSource(); // 监控统计拦截的filters // druid.setFilters(filters); // 配置基本属性 druid.setDriverClassName(driverClassName); druid.setUsername(username); druid.setPassword(password); druid.setUrl(url); /* //初始化时建立物理连接的个数 druid.setInitialSize(initialSize); //最大连接池数量 druid.setMaxActive(maxActive); //最小连接池数量 druid.setMinIdle(minIdle); //获取连接时最大等待时间，单位毫秒。 druid.setMaxWait(maxWait); //间隔多久进行一次检测，检测需要关闭的空闲连接 druid.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); //一个连接在池中最小生存的时间 druid.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis); //用来检测连接是否有效的sql druid.setValidationQuery(validationQuery); //建议配置为true，不影响性能，并且保证安全性。 druid.setTestWhileIdle(testWhileIdle); //申请连接时执行validationQuery检测连接是否有效 druid.setTestOnBorrow(testOnBorrow); druid.setTestOnReturn(testOnReturn); //是否缓存preparedStatement，也就是PSCache，oracle设为true，mysql设为false。分库分表较多推荐设置为false druid.setPoolPreparedStatements(poolPreparedStatements); // 打开PSCache时，指定每个连接上PSCache的大小 druid.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize); */ return druid; } @Bean(name = &quot;dicSqlSessionFactory&quot;) public SqlSessionFactory dicSqlSessionFactory(@Qualifier(&quot;dicDataSource&quot;)DataSource dataSource)throws Exception{ SqlSessionFactoryBean bean=new SqlSessionFactoryBean(); bean.setDataSource(dataSource); //添加XML目录 ResourcePatternResolver resolver=new PathMatchingResourcePatternResolver(); try{ bean.setMapperLocations(resolver.getResources(&quot;classpath:dicMapper/*Mapper.xml&quot;)); return bean.getObject(); }catch(Exception e){ e.printStackTrace(); throw new RuntimeException(e); } } @Bean(name=&quot;dicSqlSessionTemplate&quot;) public SqlSessionTemplate dicSqlSessionTemplate(@Qualifier(&quot;dicSqlSessionFactory&quot;)SqlSessionFactory sqlSessionFactory)throws Exception{ SqlSessionTemplate template=new SqlSessionTemplate(sqlSessionFactory);//使用上面配置的Factory return template; } }启动类NoteProviderServiceApplication @SpringBootApplication(scanBasePackages = &quot;com.ht.micro.record&quot;) @EnableDiscoveryClient @MapperScan(basePackages = &quot;com.ht.micro.record.commons.mapper&quot;) @EnableSwagger2 public class NoteProviderServiceApplication { public static void main(String[] args) { SpringApplication.run(NoteProviderServiceApplication.class, args); } }测试服务层WebDicController @RestController @RequestMapping(value = &quot;webdic&quot;) public class WebDicController extends AbstractBaseController&lt;TbUser&gt; { @Autowired private WebDicService webDicService; @ApiOperation(value = &quot;获取所有字典&quot;) @RequestMapping public List&lt;WebDic&gt; getAll() { return webDicService.getAll(); } }TApplyController @RestController @RequestMapping(value = &quot;apply&quot;) public class TApplyController extends AbstractBaseController { @Autowired private TApplyService tApplyService; /** http://localhost:10105/apply/asked/任大龙 * @param name * @return */ @ApiImplicitParams({ @ApiImplicitParam(name = &quot;askedName&quot;, value = &quot;被询问人名&quot;, required = true, paramType = &quot;path&quot;) }) @GetMapping(value = &quot;asked/{name}&quot;) public List&lt;TApply&gt; getByAskedName(@PathVariable String name){ return tApplyService.getByAskedName(name); } }WebDicService @Service public class WebDicService { @Autowired WebDicMapper webDicMapper; public List&lt;WebDic&gt; getAll() { return webDicMapper.selectAll(); } }TApplyService public interface TApplyService extends BaseCrudService&lt;TApply&gt; { List&lt;TApply&gt; getByAskedName(String name); }TApplyServiceImpl @Service public class TApplyServiceImpl extends BaseCrudServiceImpl&lt;TApply, TApplyMapper&gt; implements TApplyService { @Autowired private TApplyMapper tApplyMapper; public List&lt;TApply&gt; getByAskedName(String name) { return tApplyMapper.selectByAskedName(name); } }mapper层com.ht.micro.record.commons.mapper.baseMapper.TApplyMapper public interface TApplyMapper extends MyMapper&lt;TApply&gt; { /** * 根据名称查找 * @param name * @return */ List&lt;TApply&gt; selectByAskedName(String name); }com.ht.micro.record.commons.mapper.dicMapper.WebDicMapper public interface WebDicMapper extends MyMapper&lt;WebDic&gt; { }tk.mybatis.mapper.MyMapper public interface MyMapper&lt;T&gt; extends Mapper&lt;T&gt;, MySqlMapper&lt;T&gt; { }baseMapper/TApplyMapper.xml &lt;mapper namespace=&quot;com.ht.micro.record.commons.mapper.baseMapper.TApplyMapper&quot;&gt; &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;com.ht.micro.record.commons.domain.TApply&quot;&gt; &lt;!-- WARNING - @mbg.generated --&gt; &lt;id column=&quot;id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;applyer_police_num&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;applyerPoliceNum&quot; /&gt; &lt;result column=&quot;applyer_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;applyerName&quot; /&gt; &lt;result column=&quot;asked_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;askedName&quot; /&gt; &lt;result column=&quot;applyer_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;applyerId&quot; /&gt; &lt;result column=&quot;unit_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;unitId&quot; /&gt; &lt;result column=&quot;case_info_ids&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;caseInfoIds&quot; /&gt; &lt;result column=&quot;case_count&quot; jdbcType=&quot;INTEGER&quot; property=&quot;caseCount&quot; /&gt; &lt;result column=&quot;apply_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;applyTime&quot; /&gt; &lt;result column=&quot;apply_state&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;applyState&quot; /&gt; &lt;result column=&quot;apply_goal&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;applyGoal&quot; /&gt; &lt;result column=&quot;approve_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;approveTime&quot; /&gt; &lt;result column=&quot;approve_state&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;approveState&quot; /&gt; &lt;result column=&quot;approver_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;approverId&quot; /&gt; &lt;result column=&quot;approve_prop&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;approveProp&quot; /&gt; &lt;/resultMap&gt; &lt;select id=&quot;selectByAskedName&quot; parameterType=&quot;string&quot; resultMap=&quot;BaseResultMap&quot;&gt; select * from t_apply where asked_name = #{name,jdbcType=VARCHAR} &lt;/select&gt; &lt;/mapper&gt;dicMapper/WebDicMapper.xml &lt;mapper namespace=&quot;com.ht.micro.record.commons.mapper.dicMapper&quot;&gt; &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;com.ht.micro.record.commons.domain.WebDic&quot;&gt; &lt;!-- WARNING - @mbg.generated --&gt; &lt;id column=&quot;id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;name&quot; /&gt; &lt;result column=&quot;type&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;type&quot; /&gt; &lt;/resultMap&gt; &lt;/mapper&gt;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd+overlay+pxc集群搭建]]></title>
    <url>%2F2019%2F08%2F20%2Fetcd-overlay-pxc%2F</url>
    <content type="text"><![CDATA[etcd+overlay+pxc实现基于swarm自定义网络数据库高可用 curl -L https://github.com/coreos/etcd/releases/download/v2.2.1/etcd-v2.2.1-linux-amd64.tar.gz -o etcd-v2.2.1-linux-amd64.tar.gz etcd集群tar xzvf etcd-v2.2.1-linux-amd64.tar.gz &amp;&amp; cd etcd-v2.2.1-linux-amd64 {NODE_NAME}:etcd节点名称，需要和命令中的-initial-cluster的对应的{NODE1_NAME}或{NODE2_NAME}对应 {NODE_IP}/{NODE1_IP}/{NODE2_NAME}：节点的IP ./etcd -name {NODE_NAME} -initial-advertise-peer-urls [http://{NODE_IP}:2380](http://NODE_IP:2380) \ -listen-peer-urls &lt;http://0.0.0.0:2380&gt; \ -listen-client-urls [http://0.0.0.0:2379,http://127.0.0.1:4001](http://0.0.0.0:2379,http:/127.0.0.1:4001) \ -advertise-client-urls &lt;http://0.0.0.0:2379&gt; \ -initial-cluster-token etcd-cluster \ -initial-cluster {NODE1_NAME}=http://{NODE1_IP}:2380,{NODE2_NAME}=http://{NODE2_IP}:2380 \ -initial-cluster-state new 单机tar xzvf etcd-v2.2.1-linux-amd64.tar.gz &amp;&amp; cd etcd-v2.2.1-linux-amd64 nohup ./etcd --advertise-client-urls &#39;http://192.168.3.226:2379&#39; --listen-client-urls &#39;http://0.0.0.0:2379&#39; &amp; ./etcdctl member list 查看启动情况 ./etcdctl mk name OneJane ./etcdctl get name 其他主机 ./etcdctl -endpoint http://192.168.3.226:2379 get name ./etcdctl -endpoint http://192.168.3.226:2379 mk age 22 swarmdocker配置192.168.3.224 vim /lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://192.168.3.224:2379 --cluster-advertise=192.168.3.224:2375 systemctl daemon-reload service docker start 192.168.3.227 vim /lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://192.168.3.224:2379 --cluster-advertise=192.168.3.227:2375 systemctl daemon-reload service docker start overlay192.168.3.224 docker swarm init --advertise-addr 192.168.3.224 192.168.3.227 docker swarm join --token SWMTKN-1-4qdkodh0g0c73iw5oehhn4rmsxxxca1cdfushtujspjsn1i827-3x1zyoo4tm4d4qm9x8f4o658q 192.168.3.227:2377 192.168.3.224 docker network create --driver overlay --attachable overnet docker run -itd --name=worker-1 --net=overnet ubuntu docker exec worker-1 apt-get update docker exec worker-1 apt-get install net-tools docker exec worker-1 ifconfig 10.0.0.5 192.168.3.227 docker run -itd --name=worker-2 --net=overnet ubuntu docker exec worker-2 apt-get update docker exec worker-2 apt-get install net-tools docker exec worker-2 apt-get install -y inetutils-ping docker exec worker-2 ifconfig docker exec worker-2 ping 10.0.0.5 PXC多机器集群vim /lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock systemctl daemon-reload service docker start 192.168.3.224 docker swarm init --advertise-addr 192.168.3.224 192.168.3.227 docker swarm join --token SWMTKN-1-4qdkodh0g0c73iw5oehhn4rmsxxxca1cdfushtujspjsn1i827-3x1zyoo4tm4d4qm9x8f4o658q 192.168.3.227:2377 192.168.3.224 docker network create --driver overlay --attachable overnet 192.168.3.224 docker volume create v01 docker run -d \ -p 3306:3306 \ -e MYSQL_ROOT_PASSWORD=123456 \ -e CLUSTER_NAME=PXC \ -e XTRABACKUP_PASSWORD=123456 \ -v v01:/var/lib/mysql \ --privileged \ --name=node1 \ --net=overnet \ percona/percona-xtradb-cluster:5.6 192.168.3.227 docker volume create v02 docker run -d \ -p 3306:3306 \ -e MYSQL_ROOT_PASSWORD=123456 \ -e CLUSTER_NAME=PXC \ -e XTRABACKUP_PASSWORD=123456 \ -e CLUSTER_JOIN=node1 \ -v v02:/var/lib/mysql \ --name=node2 \ --net=overnet \ percona/percona-xtradb-cluster:5.6]]></content>
      <categories>
        <category>高可用</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>pxc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux-partition]]></title>
    <url>%2F2019%2F08%2F20%2Flinux-partition%2F</url>
    <content type="text"><![CDATA[parted实现linux大磁盘分区 已挂载磁盘分区分区需先把磁盘unmount /dev/mapper/centos_ht05-homeQ1:Error: /dev/dm-2: unrecognised disk labelmklabel gpt 转成gpt格式再分区 开始分区du -h –max-depth=1 查看各文件夹大小 parted /dev/dm-2 查看/dev/mapper/centos_ht05-home是l文件属性，链接到dm-2,分区dm-2磁盘 (parted) mkpart Partition name? []? data1 File system type? [ext2]? ext4 Start? 0 End? 3584GB (parted) mkpart Partition name? []? data2 File system type? [ext2]? ext4 Start? 3584GB End? 7168GB (parted) mkpart Partition name? []? data3 File system type? [ext2]? ext4 Start? 7168GB End? -1 (parted) p Model: Linux device-mapper (linear) (dm) Disk /dev/dm-2: 11.9TB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 17.4kB 3584GB 3584GB data1 2 3584GB 7168GB 3584GB data2 3 7168GB 11.9TB 4745GB data3 若分区错误：rm 1 挂载目录mkdir /data1 /data2 /data3 ll -t /dev/dm-* 发现 dm-2 dm-17 dm-28 dm-27最新 mkfs -t ext4 /dev/dm-2 mkfs -t ext4 /dev/dm-17 mkfs -t ext4 /dev/dm-27 mkfs -t ext4 /dev/dm-28 fdisk -l 查看/dev/mapper/centos_ht05-home3 /dev/mapper/centos_ht05-home2 /dev/mapper/centos_ht05-home1生成 mount /dev/mapper/centos_ht05-home1 /data1 mount /dev/mapper/centos_ht05-home2 /data2 mount /dev/mapper/centos_ht05-home3 /data3 开机自动挂载vi /etc/fstab /dev/mapper/centos_ht05-home1 /data1 ext4 defaults 0 0 /dev/mapper/centos_ht05-home2 /data2 ext4 defaults 0 0 /dev/mapper/centos_ht05-home3 /data3 ext4 defaults 0 0 df -hl 查看磁盘分区挂载情况]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>partition</tag>
        <tag>sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-sentinel]]></title>
    <url>%2F2019%2F08%2F20%2Fredis-sentinel%2F</url>
    <content type="text"><![CDATA[基于redis-sentinel实现redis哨兵集群 redis-sentinel，只有一个master，各实例数据保持一致； 单个redis-sentinel进程来监控redis集群是不可靠的，由于redis-sentinel本身也有single-point-of-failure-problem(单点问题)，当出现问题时整个redis集群系统将无法按照预期的方式切换主从。官方推荐：一个健康的集群部署，至少需要3个Sentinel实例。另外，redis-sentinel只需要配置监控redis master，而集群之间可以通过master相互通信。 首先Sentinel是集群部署的，Client可以链接任何一个Sentinel服务所获的结果都是一致的。其次，所有的Sentinel服务都会对Redis的主从服务进行监控，当监控到Master服务无响应的时候，Sentinel内部进行仲裁，从所有的 Slave选举出一个做为新的Master。并且把其他的slave作为新的Master的Slave。 name ip port redis-master 192.168.2.5 6300 redis-slave1 192.168.2.7 6301 redis-slave2 192.168.2.7 6302 sentinel1 192.168.2.5 26000 sentinel2 192.168.2.7 26001 sentinel3 192.168.2.7 26002 Redis部署在192.168.2.5上运行 docker run -it --name redis-master --network host -d redis --appendonly yes --port 6300 在192.168.2.7上运行 docker run -it --name redis-slave1 --network host -d redis --appendonly yes --port 6301 --slaveof 192.168.2.5 6300 docker run -it --name redis-slave2 --network host -d redis --appendonly yes --port 6302 --slaveof 192.168.2.5 6300 Sentinel部署wget http://download.redis.io/redis-stable/sentinel.conf mkdir /app/{sentine1,sentine2,sentine3}/{data,conf} -p 并复制sentinel1.conf，sentinel2.conf，sentinel3.conf /app├── sentine1│ ├── conf│ └── data├── sentine2│ ├── conf│ └── data└── sentine3 ├── conf └── data 192.168.2.5主节点chmod a+w -R /app/ port 26000 pidfile /var/run/redis-sentinel.pid logfile &quot;&quot; daemonize no dir /tmp sentinel monitor mymaster 192.168.2.5 6300 2 sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000 sentinel deny-scripts-reconfig yes创建主节点 docker run -d --network host --name sentine1 \ -v /app/sentine1/data:/var/redis/data \ -v /app/sentine1/conf/sentinel.conf:/usr/local/etc/redis/sentinel.conf \ redis /usr/local/etc/redis/sentinel.conf --sentinel 192.168.2.7 从节点sentinel2.conf port 26001 daemonize no dir /tmp sentinel monitor mymaster 192.168.2.5 6300 2 sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000 sentinel deny-scripts-reconfig yes创建从节点1 docker run -d --network host --name sentine2 \ -v /app/sentine2/data:/var/redis/data \ -v /app/sentine2/conf/sentinel.conf:/usr/local/etc/redis/sentinel.conf \ redis /usr/local/etc/redis/sentinel.conf --sentinel 192.168.2.7 从节点sentinel3.conf port 26002 daemonize no dir /tmp sentinel monitor mymaster 192.168.2.5 6300 2 sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000 sentinel deny-scripts-reconfig yes创建从节点2 docker run -d --network host --name sentine3 \ -v /app/sentine3/data:/var/redis/data \ -v /app/sentine3/conf/sentinel.conf:/usr/local/etc/redis/sentinel.conf \ redis /usr/local/etc/redis/sentinel.conf --sentinel 测试[root@centoss2 app]# redis-cli -p 26000 127.0.0.1:26000&gt; sentinel master mymaster]]></content>
      <categories>
        <category>高可用</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Replication+Haproxy+Keepalived]]></title>
    <url>%2F2019%2F08%2F20%2FReplication-Haproxy-Keepalived%2F</url>
    <content type="text"><![CDATA[基于Replication+Haproxy+Keepalived实现数据库高可用 Haproxy 负载均衡haproxy提供负载均衡，并自动切换故障容器vim /usr/local/docker/mysql/haproxy/haproxy.cfg 编写配置文件 global #工作目录 chroot /usr/local/etc/haproxy #日志文件，使用rsyslog服务中local5日志设备（/var/log/local5），等级info log 127.0.0.1 local5 info #守护进程运行 daemon defaults log global mode http #日志格式 option httplog #日志中不记录负载均衡的心跳检测记录 option dontlognull #连接超时（毫秒） timeout connect 5000 #客户端超时（毫秒） timeout client 50000 #服务器超时（毫秒） timeout server 50000 #监控界面 listen admin_stats #监控界面的访问的IP和端口 bind 0.0.0.0:8888 #访问协议 mode http #URI相对地址 stats uri /dbs #统计报告格式 stats realm Global\ statistics #登陆帐户信息 stats auth admin:abc123456 #数据库负载均衡 listen proxy-mysql #访问的IP和端口 bind 0.0.0.0:185 #网络协议 mode tcp #负载均衡算法（轮询算法） #轮询算法：roundrobin #权重算法：static-rr #最少连接算法：leastconn #请求源IP算法：source balance roundrobin #日志格式 option tcplog #在MySQL中创建一个没有权限的haproxy用户，密码为空。Haproxy使用这个账户对MySQL数据库心跳检测 option mysql-check user haproxy server MySQL_1 192.168.3.226:3317 check weight 1 maxconn 2000 server MySQL_2 192.168.3.225:3318 check weight 1 maxconn 2000 #使用keepalive检测死链 option tcpka 在两台Replication组建的mysql集群同时创建mysql_cluster的haproxy容器，形成集群。 docker run -itd -v /data2/haproxy:/usr/local/etc/haproxy --name mysql-haproxy --privileged --net host haproxy docker exec -it ht-mysql-master mysql -u root -p drop user &#39;haproxy&#39;@&#39;%&#39;; create user &#39;haproxy&#39;@&#39;%&#39; IDENTIFIED BY &#39;&#39;;http://192.168.3.226:4001/dbs admin abc123456 实时查看haproxy监控页面 admin:abc123456192.168.3.226 185 root 123456 访问数据库，与Replication数据同步一致。 Keepalived双机热备高可用应用程序向宿主机65的发起请求，宿主机的Keepalived路由到docker内部的虚拟IP15。Haproxy容器内Keepalived抢占虚拟IP，接收到所有数据库请求将被转发到抢占虚拟IP的Haproxy，keepalived互相心跳检测，一旦主服务器挂了，备用服务器将有权抢到虚拟ip，再通过负载均衡分发到某一个PXC节点，并通过主从复制实现数据同步。 192.168.3.226docker exec -it mysql_cluster bash 进入h1 echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty main restricted&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty-updates main restricted&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty universe&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty-updates universe&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty multiverse&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty-updates multiverse&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty-backports main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list echo &quot;# deb http://security.ubuntu.com/ubuntu zesty-security main restricted&quot; &gt;&gt; /etc/apt/sources.list echo &quot;# deb http://security.ubuntu.com/ubuntu zesty-security universe&quot; &gt;&gt; /etc/apt/sources.list echo &quot;# deb http://security.ubuntu.com/ubuntu zesty-security multiverse&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://archive.canonical.com/ubuntu zesty partner&quot; &gt;&gt; /etc/apt/sources.list apt-get update apt-get install gnupg -y --allow-unauthenticated apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 3B4FE6ACC0B21F32 apt-get update apt-get install keepalived vim -y vim /etc/keepalived/keepalived.conf vrrp_instance VI_1 { state MASTER interface enp1s0f0 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 123456 } virtual_ipaddress { 192.168.2.88 } } virtual_server 192.168.2.88 3306 { delay_loop 3 lb_algo rr lb_kind NAT persistence_timeout 50 protocol TCP real_server 192.168.2.5 185 { weight 1 } } service keepalived start ping 192.168.2.88192.168.3.225docker exec -it mysql_cluster bash 进入h2 echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty main restricted&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty-updates main restricted&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty universe&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty-updates universe&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty multiverse&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty-updates multiverse&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://old-releases.ubuntu.com/ubuntu/ zesty-backports main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list echo &quot;# deb http://security.ubuntu.com/ubuntu zesty-security main restricted&quot; &gt;&gt; /etc/apt/sources.list echo &quot;# deb http://security.ubuntu.com/ubuntu zesty-security universe&quot; &gt;&gt; /etc/apt/sources.list echo &quot;# deb http://security.ubuntu.com/ubuntu zesty-security multiverse&quot; &gt;&gt; /etc/apt/sources.list echo &quot;deb http://archive.canonical.com/ubuntu zesty partner&quot; &gt;&gt; /etc/apt/sources.list apt-get update apt-get install gnupg -y --allow-unauthenticated apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 3B4FE6ACC0B21F32 apt-get update apt-get install keepalived vim -y vim /etc/keepalived/keepalived.conf vrrp_instance VI_1 { state BACKUP interface enp1s0f0 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 123456 } virtual_ipaddress { 192.168.2.88 } } virtual_server 192.168.2.88 3306 { delay_loop 3 lb_algo rr lb_kind NAT persistence_timeout 50 protocol TCP real_server 192.168.2.7 186 { weight 1 } } service keepalived start ping 192.168.2.88访问192.168.3.222 189 root 123456]]></content>
      <categories>
        <category>高可用</category>
      </categories>
      <tags>
        <tag>haproxy</tag>
        <tag>replication</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Replication主从复制]]></title>
    <url>%2F2019%2F08%2F20%2FReplication%2F</url>
    <content type="text"><![CDATA[基于Replication实现mysql主从复制 简单介绍本文具体讲述mysql基于多机器的数据库高可用的一些解决方案。 主从复制：常见方案有PXC以及Replication。 Replication的主从在主库中操作，速度较快，弱一致性，单向异步，一旦stop slave将无法同步；PXC集群速度慢，强一致性，高价值数据，双向同步。 负载均衡：Nginx更适用于HTTP协议的应用负载，刚刚支持TCP；Haproxy提供负载，故障自动切换。 双机热备：Keepalived通过虚拟IP将请求分发，让抢占到虚拟IP的Haproxy通过负载分发给某一数据库节点。 Replication单机Masterdocker run -di --name=mysql_master -p 3300:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql docker cp mysql_master:/etc/mysql/my.cnf /usr/share/mysql/my_master.cnf docker cp mysql_master:/etc/mysql/my.cnf /usr/share/mysql/my_slaver.cnf docker stop mysql_master docker rm mysql_master docker run -di --name=mysql_master -p 3300:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /usr/share/mysql/my_master.cnf:/etc/mysql/my.cnf mysql:5.7.25 mkdir -p /usr/local/mysql_master chown -R 777 /usr/local/mysql_master/ 以上主要取出配置文件模板类型 vim /usr/share/mysql/my_master.cnf basedir = /usr/local/mysql_master port = 3306 server_id = 98 log_bin=zlinux01 docker restart mysql_master docker exec -it mysql_master /bin/bash mysql -u root -p ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;; GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION; FLUSH PRIVILEGES; grant replication slave on *.* to &#39;root&#39;@&#39;192.168.12.98&#39; identified by &#39;123456&#39;; flush tables with read lock; show master status; +-----------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +-----------------+----------+--------------+------------------+-------------------+ | zlinux01.000004 | 154 | | | | +-----------------+----------+--------------+------------------+-------------------+ Slavedocker run -di --name=mysql_slaver -p 3301:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /usr/share/mysql/my_slaver.cnf:/etc/mysql/my.cnf mysql:5.7.25 mkdir -p /usr/local/mysql_slaver chown -R mysql.mysql /usr/local/mysql_slaver/ vim /usr/share/mysql/my_slaver.cnf basedir = /usr/local/mysql_slaver port = 3306 server_id = 89 log_bin=zlinux02 docker restart mysql_slaver docker exec -it mysql_slaver /bin/bash mysql -u root -p ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;; stop slave; change master to master_host=&#39;192.168.12.98&#39;,master_user=&#39;root&#39;, master_password=&#39;123456&#39;,master_port=3300, master_log_file=&#39;zlinux01.000004&#39;,master_log_pos=154; start slave; show slave status\G Slave_IO_Running: Yes Slave_SQL_Running: Yes则成功单机集群在实际应用中毫无意义，仅供参考。 多机一主多从Master 192.168.3.226mkdir -p /usr/local/mysql_master chown -R 777 /usr/local/mysql_master docker run -di --name=mysql_master -p 3300:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql docker cp mysql_master:/etc/mysql/my.cnf /usr/share/mysql/my_master.cnf 并修改 basedir = /usr/local/mysql_master port = 3306 server_id = 98 log_bin=zlinux01 docker stop mysql_master docker rm mysql_master docker run -di --name=mysql_master -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /usr/share/mysql/my_master.cnf:/etc/mysql/my.cnf mysql:5.7.25 docker exec -it mysql_master /bin/bash mysql -u root -p ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;; GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION; FLUSH PRIVILEGES; grant replication slave on *.* to &#39;root&#39;@&#39;192.168.3.225&#39; identified by &#39;123456&#39;; flush tables with read lock; show master status; +-----------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +-----------------+----------+--------------+------------------+-------------------+ | zlinux01.000004 | 1135 | | | | +-----------------+----------+--------------+------------------+-------------------+Slaver 192.168.3.225mkdir -p /usr/local/mysql_slaver chown -R 777 /usr/local/mysql_slaver docker cp mysql_master:/etc/mysql/my.cnf /usr/share/mysql/my_slaver.cnf 并修改 basedir = /usr/local/mysql_slaver port = 3306 server_id = 89 log_bin=zlinux02 docker run -di --name=mysql_slaver -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /usr/share/mysql/my_slaver.cnf:/etc/mysql/my.cnf mysql:5.7.25 docker exec -it mysql_slaver /bin/bash mysql -u root -p ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;; stop slave; change master to master_host=&#39;192.168.3.226&#39;,master_user=&#39;root&#39;, master_password=&#39;123456&#39;,master_port=3306, master_log_file=&#39;zlinux01.000004&#39;,ster_logmaster_log_pos=1135; start slave; show slave status\G 证明主从复制实现 Slave_IO_Running: Yes Slave_SQL_Running: Yes以上即Replication的主从复制，单向复制，只可作为热备使用。 最终方案Master_1 192.168.3.226/root └── test └── mysql_test1 ├── haproxy │ └── haproxy.cfg ├── log ├── mone │ ├── conf │ │ └── my.cnf │ └── data └── mtwo ├── conf │ └── my.cnf └── data mkdir test/mysql_test1/{mone,mtwo}/{data,conf} -p vim test/mysql_test1/mone/conf/my.cnf [mysqld] server_id = 1 log-bin= mysql-bin replicate-ignore-db=mysql replicate-ignore-db=sys replicate-ignore-db=information_schema replicate-ignore-db=performance_schema read-only=0 relay_log=mysql-relay-bin log-slave-updates=on auto-increment-offset=1 auto-increment-increment=2 !includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/ vim test/mysql_test1/mysql/mtwo/conf/my.cnf [mysqld] server_id = 2 log-bin= mysql-bin replicate-ignore-db=mysql replicate-ignore-db=sys replicate-ignore-db=information_schema replicate-ignore-db=performance_schema read-only=0 relay_log=mysql-relay-bin log-slave-updates=on auto-increment-offset=2 auto-increment-increment=2 !includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/ scp -r test root@192.168.3.225:/root/ docker run --name monemysql -d -p 3317:3306 -e MYSQL_ROOT_PASSWORD=root -v ~/test/mysql_test1/mone/data:/var/lib/mysql -v ~/test/mysql_test1/mone/conf/my.cnf:/etc/mysql/my.cnf mysql:5.7 docker exec -it monemysql mysql -u root -p 输入root stop slave; GRANT REPLICATION SLAVE ON *.* to &#39;slave&#39;@&#39;%&#39; identified by &#39;123456&#39;; 创建一个slave同步账号slave，允许访问的IP地址为%，%表示通配符用来同步数据 show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000003 | 443 | | | | +------------------+----------+--------------+------------------+-------------------+ docker inspect monemysql | grep IPA 查看容器ip &quot;SecondaryIPAddresses&quot;: null, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPAMConfig&quot;: null, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,Master_2 192.168.3.225docker run --name mtwomysql -d -p 3318:3306 -e MYSQL_ROOT_PASSWORD=root -v ~/test/mysql_test1/mtwo/data:/var/lib/mysql -v ~/test/mysql_test1/mtwo/conf/my.cnf:/etc/mysql/my.cnf mysql:5.7 docker exec -it mtwomysql mysql -u root -p 输入root stop slave; change master to master_host=&#39;192.168.3.226&#39;,master_user=&#39;slave&#39;, master_password=&#39;123456&#39;,master_log_file=&#39;mysql-bin.000003&#39;, master_log_pos=443,master_port=3317; GRANT REPLICATION SLAVE ON *.* to &#39;slave&#39;@&#39;%&#39; identified by &#39;123456&#39;; 创建一个用户来同步数据 start slave ; 启动同步 show master status; 查看状态 +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000003 | 443 | | | | +------------------+----------+--------------+------------------+-------------------+双向同步Master_1 192.168.3.226 stop slave; change master to master_host=&#39;192.168.3.225&#39;,master_user=&#39;slave&#39;, master_password=&#39;123456&#39;,master_log_file=&#39;mysql-bin.000003&#39;, master_log_pos=443,master_port=3318; start slave ; 在两个容器中查看 show slave status\G; Slave_IO_Running: Yes Slave_SQL_Running: Yes 双向验证，数据同步 实例 映射路径data为空 2.7docker run --name ht-mysql-master -d -p 3317:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /data3/replication/data:/var/lib/mysql -v /data2/replication/conf/my.cnf:/etc/mysql/my.cnf mysql:5.7 docker exec -it ht-mysql-master mysql -u root -p GRANT REPLICATION SLAVE ON *.* TO &#39;repl_user&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;; FLUSH PRIVILEGES; reset master; #清空master的binlog，平时慎用，可选 flush tables with read lock; #只读 flush logs; show master status; 2.5docker run --name ht-mysql-slave -d -p 3318:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /data3/replication/data:/var/lib/mysql -v /data3/replication/conf/my.cnf:/etc/mysql/my.cnf mysql:5.7 docker exec -it ht-mysql-slave mysql -u root -p GRANT REPLICATION SLAVE ON *.* TO &#39;repl_user&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;; FLUSH PRIVILEGES; stop slave; CHANGE MASTER TO MASTER_HOST=&#39;192.168.2.7&#39;,MASTER_PORT=3317, MASTER_USER=&#39;repl_user&#39;, MASTER_PASSWORD=&#39;123456&#39;, MASTER_LOG_FILE=&#39;mysql-bin.000002&#39;, MASTER_LOG_POS=154; start slave; show slave status\G reset master;(清空master的binlog，平时慎用，可选) flush tables with read lock; flush logs; show master status;2.7unlock stop slave; CHANGE MASTER TO MASTER_HOST=&#39;192.168.2.5&#39;,MASTER_PORT=3318, MASTER_USER=&#39;repl_user&#39;, MASTER_PASSWORD=&#39;123456&#39;, MASTER_LOG_FILE=&#39;mysql-bin.000002&#39;, MASTER_LOG_POS=154; start slave; show slave status\G2.5unlock tables;Semisync半同步配置nodeA和nodeB上执行： mysql&gt; INSTALL PLUGIN rpl_semi_sync_master SONAME &#39;semisync_master.so&#39;; mysql&gt; INSTALL PLUGIN rpl_semi_sync_slave SONAME &#39;semisync_slave.so&#39;; mysql&gt; show variables like &#39;%semi%&#39;; rpl_semi_sync_master_timeout=10000 表示主库在某次事务中，如果等待时间超过10秒，则降级为普通模式，不再等待备库。如果主库再次探测到备库恢复了，则会自动再次回到semisync模式。 rpl_semi_sync_master_wait_point=AFTER_SYNCAFTER_SYNC工作流程： 客户端提交一个事务，master将事务写入binlog并刷新到磁盘，发送到slave，master等待slave反馈。 slave接收master的binlog，写到本地的relaylog里。发送确认信息给master。 当接收到slave反馈，master提交事务并返回结果给客户端。这样就保证了主从数据一致。 mysql&gt; SET GLOBAL rpl_semi_sync_master_enabled = 1; mysql&gt; SET GLOBAL rpl_semi_sync_slave_enabled = 1; mysql&gt; stop slave;start slave; mysql&gt; show status like &#39;%semi%&#39;; +--------------------------------------------+-------+ | Variable_name | Value | +--------------------------------------------+-------+ | Rpl_semi_sync_master_clients | 1 | | Rpl_semi_sync_master_net_avg_wait_time | 0 | | Rpl_semi_sync_master_net_wait_time | 0 | | Rpl_semi_sync_master_net_waits | 0 | | Rpl_semi_sync_master_no_times | 0 | | Rpl_semi_sync_master_no_tx | 0 | | Rpl_semi_sync_master_status | ON | (master同步） | Rpl_semi_sync_master_timefunc_failures | 0 | | Rpl_semi_sync_master_tx_avg_wait_time | 0 | | Rpl_semi_sync_master_tx_wait_time | 0 | | Rpl_semi_sync_master_tx_waits | 0 | | Rpl_semi_sync_master_wait_pos_backtraverse | 0 | | Rpl_semi_sync_master_wait_sessions | 0 | | Rpl_semi_sync_master_yes_tx | 0 | | Rpl_semi_sync_slave_status | ON |（从同步） +--------------------------------------------+-------+ 15 rows in set (0.00 sec)并修改my.cnf，添加下面两行： rpl_semi_sync_master_enabled = 1 rpl_semi_sync_slave_enabled = 1]]></content>
      <categories>
        <category>高可用</category>
      </categories>
      <tags>
        <tag>replication</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人博客]]></title>
    <url>%2F2019%2F08%2F20%2Fblog%2F</url>
    <content type="text"><![CDATA[基于Nexmoe的搭建的个人博客 Hexohttps://nodejs.org/download/release/v10.15.3/ 安装node npm install -g cnpm --registry=https://registry.npm.taobao.org 安装cnpm npm config set registry https://registry.npm.taobao.org 使用npm淘宝源 npm install -g hexo-cli hexo init blog cd blog npm installNexmoecd themes git clone https://github.com/nexmoe/hexo-theme-nexmoe.git nexmoe cd nexmoe git checkout master npm i --save hexo-wordcount npm i hexo-deployer-git --save npm i -g gulp --save cp -i _config.example.yml _config.ymlvim package.json &quot;scripts&quot;: { &quot;build&quot;: &quot;hexo clean &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp; hexo d &amp; git add * &amp; git commit -m &#39;加油&#39; &amp; git push origin master&quot;, &quot;test&quot;: &quot;hexo clean &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp; hexo s&quot;, &quot;dev&quot;: &quot;hexo clean &amp;&amp; hexo g &amp;&amp; hexo s&quot; },默认自动开启github pages 使用npm install gulp npm install --save-dev gulp npm install gulp-htmlclean gulp-htmlmin gulp-minify-css gulp-uglify gulp-imagemin --savegulpfile.js var gulp = require(&#39;gulp&#39;); var minifycss = require(&#39;gulp-minify-css&#39;); var uglify = require(&#39;gulp-uglify&#39;); var htmlmin = require(&#39;gulp-htmlmin&#39;); var htmlclean = require(&#39;gulp-htmlclean&#39;); var imagemin = require(&#39;gulp-imagemin&#39;); // 压缩html gulp.task(&#39;minify-html&#39;, function() { return gulp.src(&#39;./public/**/*.html&#39;) .pipe(htmlclean()) .pipe(htmlmin({ removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, })) .pipe(gulp.dest(&#39;./public&#39;)) }); // 压缩css gulp.task(&#39;minify-css&#39;, function() { return gulp.src(&#39;./public/**/*.css&#39;) .pipe(minifycss({ compatibility: &#39;ie8&#39; })) .pipe(gulp.dest(&#39;./public&#39;)); }); // 压缩js gulp.task(&#39;minify-js&#39;, function() { return gulp.src(&#39;./public/js/**/*.js&#39;) .pipe(uglify()) .pipe(gulp.dest(&#39;./public&#39;)); }); // 压缩图片 gulp.task(&#39;minify-images&#39;, function() { return gulp.src(&#39;./public/images/**/*.*&#39;) .pipe(imagemin( [imagemin.gifsicle({&#39;optimizationLevel&#39;: 3}), imagemin.jpegtran({&#39;progressive&#39;: true}), imagemin.optipng({&#39;optimizationLevel&#39;: 7}), imagemin.svgo()], {&#39;verbose&#39;: true})) .pipe(gulp.dest(&#39;./public/images&#39;)) }); // 默认任务 gulp.task(&#39;default&#39;, [ &#39;minify-html&#39;,&#39;minify-css&#39;,&#39;minify-js&#39;,&#39;minify-images&#39; ]);hexo g &amp;&amp; gulp _config.ymltitle: OneJane subtitle: 码农养成记 description: keywords: Spring Cloud,Docker,Dubbo author: OneJane language: zh-CN timezone: Hongkong url: https://onejane.github.io/ theme: nexmoe deploy: type: git repo: github: git@github.com:OneJane/OneJane.github.io.git branch: master message: github highlight: enable: false line_number: true auto_detect: false tab_replace: themes/nexmoe/_config.ymlavatar: https://i.loli.net/2019/08/20/UIhTqdQiPasxLtr.jpg # 网站 Logo background: https://i.loli.net/2019/01/13/5c3aec85a4343.jpg # 既是博客的背景，又是文章默认头图 favicon: href: /img/a.ico # 网站图标 type: image/png # 图标类型，可能的值有(image/png, image/vnd.microsoft.icon, image/x-icon, image/gif) social: zhihu: - https://www.zhihu.com/people/codewj/activities - icon-zhihu - rgb(231, 106, 141) - rgba(231, 106, 141, .15) GitHub: - https://github.com/OneJane - icon-github - rgb(25, 23, 23) - rgba(25, 23, 23, .15) analytics: la_site_id: 20279757 comment: gitment gitment: owner: onejane # 持有该 repo 的 GitHub username repo: onejane.github.io # 存放评论的 issue 所在的 repo clientID: e677e59382e1c7a468fd # GitHub Client ID clientSecret: 717d041bc4ab749f069314862232cfb6ec8adc15 # GitHub Client Secret 打赏themes/nexmoe/layout/_partial/donate.ejs &lt;! -- 添加捐赠图标 --&gt; &lt;div class =&quot;post-donate&quot;&gt; &lt;div id=&quot;donate_board&quot; class=&quot;donate_bar center&quot;&gt; &lt;a id=&quot;btn_donate&quot; class=&quot;btn_donate&quot; href=&quot;javascript:;&quot; title=&quot;打赏&quot;&gt;&lt;/a&gt; &lt;span class=&quot;donate_txt&quot;&gt; ↑&lt;br&gt; &lt;%=theme.donate_message%&gt; &lt;/span&gt; &lt;br&gt; &lt;/div&gt; &lt;div id=&quot;donate_guide&quot; class=&quot;donate_bar center hidden&quot; &gt; ![](/images/alipay.jpg) ![](/images/alipay.jpg) &lt;!-- 支付宝打赏图案 --&gt; &lt;img src=&quot;&lt;%- theme.root_url %&gt;/images/alipay.jpg&quot; alt=&quot;支付宝打赏&quot;&gt; 666 &lt;!-- 微信打赏图案 --&gt; &lt;img src=&quot;&lt;%- theme.root_url %&gt;/images/wechatpay.png&quot; alt=&quot;微信打赏&quot;&gt; &lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; document.getElementById(&#39;btn_donate&#39;).onclick = function(){ $(&#39;#donate_board&#39;).addClass(&#39;hidden&#39;); $(&#39;#donate_guide&#39;).removeClass(&#39;hidden&#39;); } &lt;/script&gt; &lt;/div&gt; &lt;! -- 添加捐赠图标 --&gt; themes/nexmoe/source/css/_partial/donate.styl .donate_bar { text-align: center; margin-top: 5% } .donate_bar a.btn_donate { display: inline-block; width: 82px; height: 82px; margin-left: auto; margin-right: auto; background: url(http://img.t.sinajs.cn/t5/style/images/apps_PRF/e_media/btn_reward.gif)no-repeat; -webkit-transition: background 0s; -moz-transition: background 0s; -o-transition: background 0s; -ms-transition: background 0s; transition: background 0s } .donate_bar a.btn_donate:hover { background-position: 0 -82px } .donate_bar .donate_txt { display: block; color: #9d9d9d; font: 14px/2 &quot;Microsoft Yahei&quot; } .donate_bar.hidden{ display: none } .post-donate{ margin-top: 80px; } #donate_guide{ height: 210px; width: 420px; margin: 0 auto; } #donate_guide img{ height: 200px; height: 200px; } 在source\css\style.styl中添加@import ‘_partial/donate’themes/nexmoe/layout/post.ejs &lt;% if (theme.donate){ %&gt; &lt;%- partial(&#39;donate&#39;) %&gt; &lt;% } %&gt; themes/nexmoe/_config.yml #是否开启打赏功能 donate: true #打赏文案 donate_message: 欣赏此文？求鼓励，求支持！404插入音乐hexo new page 404 生成source/404.md --- title: 404 permalink: /404 cover: https://i.loli.net/2019/08/20/DMuWHOGTq4AR1iQ.png --- &lt;div class=&quot;aplayer&quot; data-id=&quot;439625244&quot; data-server=&quot;netease&quot; data-type=&quot;song&quot; data-autoplay=&quot;true&quot; data-mode=&quot;single&quot;&gt;&lt;/div&gt;themes/nexmoe/layout/layout.ejs &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css&quot;&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js&quot;&gt;&lt;/script&gt; ... &lt;script src=&quot;https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js&quot;&gt;&lt;/script&gt; windows右键复制路径Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\Directory\shell\copypath] @=&quot;copy path of dir&quot; [HKEY_CLASSES_ROOT\Directory\shell\copypath\command] @=&quot;mshta vbscript:clipboarddata.setdata(\&quot;text\&quot;,\&quot;%1\&quot;)(close)&quot; [HKEY_CLASSES_ROOT\*\shell\copypath] @=&quot;copy path of file&quot; [HKEY_CLASSES_ROOT\*\shell\copypath\command] @=&quot;mshta vbscript:clipboarddata.setdata(\&quot;text\&quot;,\&quot;%1\&quot;)(close)&quot;windows定时任务此电脑–&gt;管理–&gt;任务计划管理–&gt;任务计划程序 –&gt;任务计划程序库–&gt;Microsoft –&gt;windows vim C:\Users\codewj\Desktop\build-blog.bat E: &amp;&amp; cd E:\Project\blog &amp;&amp; npm run build robots.txtUser-agent: * Disallow: Disallow: /bin/ Sitemap: https://onejane.github.io/sitemap.txt 加入blog\themes\nexmoe\source google收录 https://search.google.com/search-console 添加资源 将google验证文件放入blog\themes\nexmoe\source，发布校验 站点地图 将生成的站点地图放入blog\themes\nexmoe\source bing收录https://www.bing.com/toolbox/webmaster/ 登陆后进入https://www.bing.com/webmaster/home/mysites#https://www.bing.com/webmaster/home/dashboard?url=https%3A%2F%2Fonejane.github.io%2F 使用小书匠小书匠 新建github reository为blog，并初始化 新建token:https://github.com/settings/tokens/new 并Generate token得到129483a01745abe39ed1ac109ec09f1d71b9e8c3数据存储&amp;图床服务 QuestionAssertionError [ERR_ASSERTION]: Task function must be specified?&quot;devDependencies&quot;: { &quot;gulp&quot;: &quot;^3.9.1&quot; } npm install GulpUglifyError:unable to minify JavaScriptnpm install gulp-util –save-dev var gutil = require(&#39;gulp-util&#39;); // 压缩public目录下的所有js gulp.task(&#39;minify-js&#39;, function() { return gulp.src(&#39;./public/**/*.js&#39;) .pipe(uglify()) .on(&#39;error&#39;, function (err) { gutil.log(gutil.colors.red(&#39;[Error]&#39;), err.toString()); }) //增加这一行 .pipe(gulp.dest(&#39;./public&#39;)); }); gittalk Error：validation failedgitalk.ejs id: window.location.pathname改为id: decodeURI(window.location.pathname)]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>nexmoe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单机Nacos集群]]></title>
    <url>%2F2019%2F08%2F20%2Fnacos%2F</url>
    <content type="text"><![CDATA[基于docker的单机nacos集群安装配置 环境搭建yum update -y nss curl libcurl curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose docker-compose --version git clone https://github.com/nacos-group/nacos-docker.git cd nacos-docker 映射cluster-hostname启动脚本 - ../docker-startup.sh:/home/nacos/bin/docker-startup.sh 修改docker-startup.sh中环境变量 JAVA_OPT=&quot;${JAVA_OPT} -server -Xms512m -Xmx512m -Xmn256m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot; vim ~/.bashrc alias dofo=&#39;docker ps --format &quot;table {{.Names}}\t{{.Ports}}\t{{.Image}}\t&quot;&#39; alias dolo=&#39;docker logs -ft&#39; source ~/.bashrc #docker-compose up -d #docker-compose logs -ft #docker-compose down docker-compose -f example/cluster-hostname.yaml up -d docker stop nacos1 nacos2 nacos3 docker start nacos1 nacos2 nacos3 docker-compose -f example/cluster-hostname.yaml downhttp://192.168.2.7:9503/actuator/nacos-discoveryhttp://192.168.2.5:8848/nacos http://192.168.2.5:8849/nacos http://192.168.2.5:8850/nacos nacos/nacos Nginx负载均衡mkdir /usr/local/docker/nginx/nacos -p vim n1.conf upstream nacos { # 配置负载均衡 server 192.168.2.5:8848; server 192.168.2.5:8849; server 192.168.2.5:8850; } server { listen 8841; server_name 192.168.2.5; location / { proxy_pass http://nacos; index index.html index.htm; } vim n2.conf upstream nacos { # 配置负载均衡 server 192.168.2.5:8848; server 192.168.2.5:8849; server 192.168.2.5:8850; } server { listen 8842; server_name 192.168.2.5; location / { proxy_pass http://nacos; index index.html index.htm; } docker run -it -d –name nginx2 -v /usr/local/docker/nginx/nacos/n2.conf:/etc/nginx/nginx.conf –net=host –privileged nginxdocker run -it -d –name nginx1 -v /usr/local/docker/nginx/nacos/n1.conf:/etc/nginx/nginx.conf –net=host –privileged nginx http://192.168.2.5:8841/nacos/#/login http://192.168.2.5:8842/nacos/#/login docker pause nacos1 测试页面维持访问 Keepalive双机热备docker exec -it nginx1 bash mv /etc/apt/sources.list sources.list.bak echo &quot;deb http://mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse&quot;&gt;&gt;/etc/apt/sources.list echo &quot;deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse&quot;&gt;&gt;/etc/apt/sources.list echo &quot;deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse&quot;&gt;&gt;/etc/apt/sources.list echo &quot;deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse&quot;&gt;&gt;/etc/apt/sources.list apt-get update apt-get install gnupg -y --allow-unauthenticated apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 3B4FE6ACC0B21F32 apt-get update apt-get install keepalived vim -y vim /etc/keepalived/keepalived.conf vrrp_instance VI_1 { state MASTER interface docker0 # 填写docker网卡名 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 123456 } virtual_ipaddress { 172.17.0.100 # 定义该网卡下的虚拟ip地址段地址 } } service keepalived start docker exec -it nginx2 bash mv /etc/apt/sources.list sources.list.bak echo &quot;deb http://mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse&quot;&gt;&gt;/etc/apt/sources.list echo &quot;deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse&quot;&gt;&gt;/etc/apt/sources.list echo &quot;deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse&quot;&gt;&gt;/etc/apt/sources.list echo &quot;deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse&quot;&gt;&gt;/etc/apt/sources.list apt-get update apt-get install gnupg -y --allow-unauthenticated apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 3B4FE6ACC0B21F32 apt-get update apt-get install keepalived vim -y vim /etc/keepalived/keepalived.conf vrrp_instance VI_1 { state BACKUP interface docker0 # 填写docker网卡名 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 123456 } virtual_ipaddress { 172.17.0.100 # 定义虚拟ip地址段地址 } } service keepalived start 由于docker内的虚拟ip不能被外界访问借助宿主机keepalived映射外网可以访问的虚拟ip， exit yum install keepalived -y mv /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak vim /etc/keepalived/keepalived.conf vrrp_instance VI_1 { state MASTER interface enp1s0f0 # 宿主机网卡 virtual_router_id 51 # 保持一致 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.2.155 # 宿主机虚拟ip } } virtual_server 192.168.2.155 183 { # 宿主机虚拟ip及开放端口 delay_loop 3 lb_algo rr lb_kind NAT persistence_timeout 50 protocol TCP real_server 172.17.0.100 8841 { # nginx1容器虚拟ip及开放nacos端口 weight 1 } } virtual_server 192.168.2.155 183 { delay_loop 3 lb_algo rr lb_kind NAT persistence_timeout 50 protocol TCP real_server 172.17.0.100 8842 { # nginx2容器虚拟ip及开放nacos端口 weight 1 } } #apt-get --purge remove keepalived -y #/sbin/ip addr del 192.168.12.100/32 dev enp1s0f0 删除虚拟ip 如docker0没有则重启docker，再次检查创建systemctl daemon-reloadsystemctl restart docker 访问 http://192.168.2.155:183/nacos/#/login nacos nacos 关闭nacos心跳日志logging: level: com.alibaba.nacos.client.naming: error]]></content>
      <categories>
        <category>注册中心</category>
      </categories>
      <tags>
        <tag>spring cloud alibaba</tag>
        <tag>docker</tag>
      </tags>
  </entry>
</search>
